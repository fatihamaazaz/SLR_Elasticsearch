Document Type,Authors,Title,Source,Year,Link,Abstract,Keywords
Conference Paper,Kumar S,Diabetic Retinopathy Diagnosis with Ensemble Deep-Learning,Association for Computing Machinery,2020,https://doi.org/10.1145/3387168.3387206;http://dx.doi.org/10.1145/3387168.3387206,"Diabetic retinopathy is an eye disease, is a condition in which retina is damaged due to diabetes mellitus. It is a major cause of blindness. Although many artificial intelligence methods has been applied to diabetic retinopathy diagnosis. This method is a new approach in this problem domain. It's early detection can help in tackling the future damages due to the disease. Here, model is ensemble of pre-existing GoogleNet, AlexNet and ResNet50 architectures. The best machine learning models that were used was GoogLeNet achieving highest accuracy for this job. Here, The results are standing out with the GoogLeNet's accuracy.","AI in healthcare, Deep learning, Computer vision, Transfer Learning, Ensemble learning"
Conference Paper,"Nguyen QH,Muthuraman R,Singh L,Sen G,Tran AC,Nguyen BP,Chua M",Diabetic Retinopathy Detection Using Deep Learning,Association for Computing Machinery,2020,https://doi.org/10.1145/3380688.3380709;http://dx.doi.org/10.1145/3380688.3380709,"Diabetic Retinopathy (DR) is an eye disease associated with chronic diabetes. DR is the leading cause of blindness among working aged adults around the world and estimated it may affect more than 93 million people. Progression to vision impairment can be slowed or controlled if DR is detected in time, however this can be difficult as the disease often shows few symptoms until it is too late to provide effective treatment.Currently, detecting DR is a time-consuming and manual process, which requires an ophthalmologist or trained clinician to examine and evaluate digital color fundus photographs of the retina, to identify DR by the presence of lesions associated with the vascular abnormalities caused by the disease.The automated method of DR screening will speed up the detection and decision-making process, which will help to control or manage DR progression. This paper presents an automated classification system, in which it analyzes fundus images with varying illumination and fields of view and generates a severity grade for diabetic retinopathy (DR) using machine learning models such as CNN, VGG-16 and VGG-19.This system achieves 80% sensitivity, 82% accuracy, 82% specificity, and 0.904 AUC for classifying images into 5 categories ranging from 0 to 4, where 0 is no DR and 4 is proliferative DR.","segmentation, severity grade, deep learning, Diabetic retinopathy, image processing, classification"
Conference Paper,"Lee CH,Ke YH",Fundus Images Classification for Diabetic Retinopathy Using Deep Learning,Association for Computing Machinery,2021,https://doi.org/10.1145/3474963.3475849;http://dx.doi.org/10.1145/3474963.3475849,"Diabetes is a worldwide chronic disease, which can even affect life and has several complications. Diabetic Retinopathy is the most serious complication of diabetes. Early detection still has a chance of cure, but there are many cases of serious blindness. Today's machine learning and deep learning are significant technology, where perform excellently in many classification fields. In this paper, we modify the architecture of the VGG-16 and ResNet-50 models to classify the severity grading of Diabetic Retinopathy with the dropout concept. In addition, contrast-limited adaptive histogram equalization (CLAHE) is used in data pre-processing to improve the quality of the fundus image of diabetic retinopathy, and data expansion is used to solve the problem of data imbalance and improve training over-fitting. After the pre-processing of the fundus image and the models are modified with dropout, the confusion matrix is used to evaluate the model. The classification accuracy of the two models is 94.03% and 97.21%. The average sensitivity is over 70%, and the specificity is over 90%.","Diabetic Retinopathy, Deep Learning, Image Processing, Convolution Neural Network, Contrast-Limited Adaptive Histogram Equalization"
Conference Paper,"Xiao Z,Zhang Y,Wu J,Zhang X",SE-MIDNet Based on Deep Learning for Diabetic Retinopathy Classification,Association for Computing Machinery,2021,https://doi.org/10.1145/3467707.3467720;http://dx.doi.org/10.1145/3467707.3467720,"Diabetic Retinopathy (DR) is one of the most serious complications of diabetes. At present, DR detection mainly relies on detailed analysis by ophthalmologists. However, manual diagnosis is time-consuming and low efficiency. Aiming at the task of DR automatic classification, this paper proposes a classification method of DR based on deep learning. In view of the different sizes of the lesion area, firstly, an improved Inception module is proposed, which enables the network to efficiently extract multi-scale features of DR images. Then, the dense connection method is used to splice the output feature maps of the improved Inception module and send them to the subsequent layers to realize the multi-scale feature reuse of DR images and enhance the feature representation of small targets. Finally, the Squeeze-and-Excitation (SE) module is used to obtain the global information of the feature map on each channel, and the dynamic nonlinear modeling of each channel is carried out to improve the generalization ability of the network. The experimental results show that the network structure designed in this paper has good generalization ability, and the accuracy of DR automatic classification reaches 88.24%, the sensitivity reaches 99.43%, and the specificity reaches 97.6%, which can meet the needs of hospitals for DR classification.","DR classification, Inception, Deep learning, SE module"
Conference Paper,Zhang Z,Deep-Learning-Based Early Detection of Diabetic Retinopathy on Fundus Photography Using EfficientNet,Association for Computing Machinery,2020,https://doi.org/10.1145/3390557.3394303;http://dx.doi.org/10.1145/3390557.3394303,"Diabetic retinopathy, which is the leading cause of blindness among working aged adults, is a serious health problem worldwide. As millions of people suffer from diabetic retinopathy, the need for an automated method of diabetic retinopathy detection to prevent lifelong blindness has long been recognized. Therefore, it's a key challenge to build an automated diagnosis system to detect such disease early and efficiently. For that purpose, we propose a deep-learning-based method to early detect diabetic retinopathy on fundus photography in this paper. The dataset of fundus images is provided by Aravind Eye Hospital in India through a featured competition on the Kaggle platform. Deep convolutional neural networks based on EfficientNet-B3 are utilized to simultaneously extract features from fundus images, where the severity level of diabetic retinopathy is subsequently identified through a regression method. The results show that our deep learning model can achieve an expert-level performance on diagnosing the severity level of diabetic retinopathy, with a quadratic weighted kappa score 0.935 on the private dataset. Such performance locates at the top 1% among all teams and can get a gold medal prize in the Kaggle competition.","Deep learning, Various applications, Diabetic retinopathy, EfficientNet, Computer vision"
Journal Article,"Shorfuzzaman M,Hossain MS,El Saddik A",An Explainable Deep Learning Ensemble Model for Robust Diagnosis of Diabetic Retinopathy Grading,Association for Computing Machinery,2021,https://doi.org/10.1145/3469841;http://dx.doi.org/10.1145/3469841,"Diabetic retinopathy (DR) is one of the most common causes of vision loss in people who have diabetes for a prolonged period. Convolutional neural networks (CNNs) have become increasingly popular for computer-aided DR diagnosis using retinal fundus images. While these CNNs are highly reliable, their lack of sufficient explainability prevents them from being widely used in medical practice. In this article, we propose a novel explainable deep learning ensemble model where weights from different models are fused into a single model to extract salient features from various retinal lesions found on fundus images. The extracted features are then fed to a custom classifier for the final diagnosis of DR severity level. The model is trained on an APTOS dataset containing retinal fundus images of various DR grades using a cyclical learning rates strategy with an automatic learning rate finder for decaying the learning rate to improve model accuracy. We develop an explainability approach by leveraging gradient-weighted class activation mapping and shapely adaptive explanations to highlight the areas of fundus images that are most indicative of different DR stages. This allows ophthalmologists to view our model's decision in a way that they can understand. Evaluation results using three different datasets (APTOS, MESSIDOR, IDRiD) show the effectiveness of our model, achieving superior classification rates with a high degree of precision (0.970), sensitivity (0.980), and AUC (0.978). We believe that the proposed model, which jointly offers state-of-the-art diagnosis performance and explainability, will address the black-box nature of deep CNN models in robust detection of DR grading.","ensemble model, transfer learning, Explainable deep CNN, retinal fundus images, diabetic retinopathy diagnosis"
Conference Paper,"Li X,Xia H,Lu L",ECA-CBAM: Classification of Diabetic Retinopathy: Classification of Diabetic Retinopathy by Cross-Combined Attention Mechanism,Association for Computing Machinery,2022,https://doi.org/10.1145/3529466.3529468;http://dx.doi.org/10.1145/3529466.3529468,"Although there is no distinctive header, this is the abstract. Diabetic retinopathy is an ophthalmological disease that causes bleeding in the fundus and loss of vision due to damage to blood vessels in the retina. It is one of the main causes of vision loss in the world. To slow down the development of the disease, early screening of the eyeball is needed. This paper proposes a new method of classification, automatic screening and accurate diagnosis of diabetic retinopathy based on convolutional neural network. Specifically, five attention mechanisms such as BAM, CBAM, ECA, CA and SeNet are used to classify diabetic retinopathy. Through comparative experiments, it is found that ECA-CBAM cross-combination model has the best classification performance.","Cross Combination, Fundus Image Classification, Convolutional Neural Network, Attention Mechanism"
Conference Paper,"Lian C,Liang Y,Kang R,Xiang Y",Deep Convolutional Neural Networks for Diabetic Retinopathy Classification,Association for Computing Machinery,2018,https://doi.org/10.1145/3239576.3239589;http://dx.doi.org/10.1145/3239576.3239589,"Diabetic retinopathy (DR) is one of the leading cause of blindness, but the classification of DR requires experienced ophthalmologist to distinguish the presence of various small features, which is time-consuming and difficult. Convolution neural network (CNN), which enables learning hierarchical and discriminative features without experiences of clinicians, is an alternative method to address the above issue. In this paper, we investigate four factors of employing deep CNN to DR classification problem, including network architectures, preprocessing, class imbalance and fine-tuning. The best performance we achieved is an accuracy of 79% opposed to an accuracy of 75% for Harry's scheme [14].","component, Deep Learning, Convolutional Neural Networks, Diabetic Retinopathy, Digital Fundus Images, Medical Image Classification"
Conference Paper,"Tang X,Huang Y,Lin L,Li M,Yuan J",Automated Diabetic Retinopathy Identification via Lesion Guided Network,Association for Computing Machinery,2021,https://doi.org/10.1145/3451421.3451452;http://dx.doi.org/10.1145/3451421.3451452,"In this paper, we propose and validate a novel neural network named Lesion Guided Network (LGN) for automatic diagnosis of Diabetic Retinopathy (DR) from fundus images. RetinaNet is first adopted and trained on a coarsely-annotated dataset for rough lesion detection. Lesion-Aware Module (LAM) in LGN is proposed to highlight regions of interest in fundus images utilizing the coarse lesion maps. Then, the outputs of LAM are fed into a covolutional neural network (CNN) for DR identification. The proposed method is evaluated on a private dataset consisting of 4465 fundus images. Experimental results demonstrate the superiority of the proposed LGN, achieving comparable performance with ophthalmologists.","lesion guided network, Diabetic retinopathy"
Conference Paper,"Rao S,Tang J,Huang Y,Cui K,Wang S",Grouping and Decoupling Mechanism for Diabetic Retinopathy Image Grading,Association for Computing Machinery,2021,https://doi.org/10.1145/3500931.3501002;http://dx.doi.org/10.1145/3500931.3501002,"Automatic detection of diabetic retinopathy (DR) by fundus images can help a lot of patients to get diagnosis. However, many excellent deep learning models for image classification do not equally achieve good results on DR detection since fundus image classification is different from typical image classification problem. The lesions are usually small and reflected in the part rather than the whole image. In this paper, we investigate the effect of network depth and the relationship between different DR grades. Then we propose a novel attention network to group and classify DR. Our contributions are mainly in three aspects: 1. Find a suitable network depth for DR detection by experiments. 2.Propose a grouping and decoupling mechanism for DR grading. 3. Design a novel deep convolutional neural network to classify DR, which also generates attention map indicating the location of lesions. Experiments show that our network outperforms other methods on the Messidor dataset. We reach the AUC of 96.9% and the accuracy of 92.7% on binary classification and the accuracy of 81.7% on 4-class grading.","Diabetic retinopathy, Convolutional neural network, Attention mechanism, Network depth"
Conference Paper,"Al-Antary M,Hassouna M,Arafa Y,Khalifah R",Automated Identification of Diabetic Retinopathy Using Pixel-Based Segmentation Approach,Association for Computing Machinery,2020,https://doi.org/10.1145/3369973.3369979;http://dx.doi.org/10.1145/3369973.3369979,"Diabetic retinopathy is a condition that occurs in human eyes due to diabetes mellitus. It causes progressive damages in the retina. Due to changes in blood vessels of the retina, several clinical features are observed in the fundus images. Microaneurysms, soft exudates, hard exudates, and haemorrhages are common types of clinical lesions present in fundus images of damaged retina. In this study, an automated diabetic retinopathy detection method was developed to identify such lesions from fundus images. The proposed approach adopted a pixel-based image segmentation model with supervised classifier. Multiple linear and non-linear image filtering algorithms were applied to each fundus image to generate feature dataset, which was used in Random Forest classifier training. The trained classifier model performed the classification-cum-segmentation of each pixel presents in an image. The proposed detection system achieved 98.87% accuracy.","feature extraction, Diabetic retinopathy, random forest, pixel-based segmentation"
Journal Article,"Masud M,Alhamid MF,Zhang Y",A Convolutional Neural Network Model Using Weighted Loss Function to Detect Diabetic Retinopathy,Association for Computing Machinery,2022,https://doi.org/10.1145/3470976;http://dx.doi.org/10.1145/3470976,"Nowadays, artificial intelligence (AI) provides tremendous prospects for driving future healthcare while empowering patients and service providers. The extensive use of digital healthcare produces a massive amount of multimedia healthcare data continuously (e.g., MRI, X-Ray, ultrasound images, etc.). Hence, it needs special data analytics techniques to provide a smart diagnosis to the patients. Recent advancements in artificial intelligence and machine learning techniques, particularly Deep learning (DL) methods, have demonstrated tremendous medical diagnosis progress and achievements. Diabetic Retinopathy (DR), cataract, macular degeneration, and glaucoma are the most common eye problems due to diabetes. Numerous models have been proposed using deep learning models to diagnose diabetic retinopathy, but no model is perfect for detecting DR diseases. This article presents a deep learning model to analyze diabetic retinopathy images to classify DR patients’ severity levels. The model applies a custom-weighted loss function in the model’s training and achieves 92.49% accuracy and a 0.945 Cohen Kappa score on test data. The model’s weighted average precision was 93%, recall 92%, and f1 score 93%. The model is compared with several state-of-the-art pre-trained models. We observe that the proposed model performs better in accuracy results and Cohen Kappa score.","diabetic retinopathy, computer vision, convolutional neural network, Deep learning"
Conference Paper,"Shrivastava U,Joshi MV",Automated Multiclass Diagnosis of Diabetic Retinopathy Using Hierarchical Learning,Association for Computing Machinery,2020,https://doi.org/10.1145/3293353.3293412;http://dx.doi.org/10.1145/3293353.3293412,"Diabetic Retinopathy (DR) is the leading cause of blindness in the modern world. Diagnosis of DR requires an experienced ophthalmologist and it is a tedious and time-consuming process. In this paper, we propose a Convolutional Neural Network (CNN) based automated diagnosis system that can classify various stages of DR accurately. A hierarchical approach is adopted for classification in which we break down our classification task into two stages. In the first stage we perform binary classification obtaining the true positive and negative samples and in the second stage, five class classification is performed on those images classified as true positive, false positive and false negative in the first stage of classification. Our approach of classifying hierarchically takes care of the class imbalance in the data by removing the most dominant class 0 (No-DR) from the dataset at the binary classification stage. The proposed method uses the Inception-v3 CNN for feature extraction in which we use the features from second last layer of both main and auxiliary classifiers. The extracted features are concatenated into a single feature vector to train a Support Vector Machine (SVM). We use SVM with Radial Basis Function (RBF) kernel for both binary and multiclass classifications. Experiments are conducted on ""Kaggle"" dataset and our approach attains an accuracy of 87.7% on validation data for binary classification and 81.8% for multiclass classification. Our results are better than the recently proposed approach using CNN indicating that the hierarchical classification performs better for multiclass classification.",Not Found
Conference Paper,"Beede E,Baylor E,Hersch F,Iurchenko A,Wilcox L,Ruamviboonsuk P,Vardoulakis LM",A Human-Centered Evaluation of a Deep Learning System Deployed in Clinics for the Detection of Diabetic Retinopathy,Association for Computing Machinery,2020,https://doi.org/10.1145/3313831.3376718;http://dx.doi.org/10.1145/3313831.3376718,"Deep learning algorithms promise to improve clinician workflows and patient outcomes. However, these gains have yet to be fully demonstrated in real world clinical settings. In this paper, we describe a human-centered study of a deep learning system used in clinics for the detection of diabetic eye disease. From interviews and observation across eleven clinics in Thailand, we characterize current eye-screening workflows, user expectations for an AI-assisted screening process, and post-deployment experiences. Our findings indicate that several socio-environmental factors impact model performance, nursing workflows, and the patient experience. We draw on these findings to reflect on the value of conducting human-centered evaluative research alongside prospective evaluations of model accuracy.","deep learning, human-centered ai, health, diabetes"
Conference Paper,"Sakaguchi A,Wu R,Kamata SI",Fundus Image Classification for Diabetic Retinopathy Using Disease Severity Grading,Association for Computing Machinery,2019,https://doi.org/10.1145/3326172.3326198;http://dx.doi.org/10.1145/3326172.3326198,"Diabetic Retinopathy (DR) is ranked at the top of blindness causes. It progresses without subjective symptoms and leads to blindness in the worst case. However early detections and proper treatments can prevent visual disturbance. Because it takes time and cost for diagnoses by clinicians, research and development of diagnostic support systems has actively been conducted. This research aims to establish a fundus image classification method based on disease severity assessment for a diagnostic support by a fundus image analysis. In this paper, we propose a Graph Neural Network (GNN)-based method to improve accuracy for severity classification. Our method has two features. The first is to extract Region-Of-Interest (ROI) sub-images focusing on regions locally capturing lesions in order to minimize background noise in image preprocessing for the classification. The second is to utilize the GNN which is not yet applied for fundus image classification. In order to evaluate our proposed method, we use Indian Diabetic Retinopathy Image Dataset (IDRiD) utilized in ""Diabetic Retinopathy: Segmentation and Grading Challenge"" on Biomedical Imaging held at the IEEE International Symposium in 2018. We verified that the accuracy of our method improved 2.9% over the conventional method in this contest.","Sparse graph, Graph neural network, Diabetic retinopathy"
Conference Paper,"Prasanna P,Jain S,Bhagat N,Madabhushi A",Decision Support System for Detection of Diabetic Retinopathy Using Smartphones,"ICST (Institute for Computer Sciences, Social-Informatics and Telecommunications Engineering)",2013,https://doi.org/10.4108/icst.pervasivehealth.2013.252093;http://dx.doi.org/10.4108/icst.pervasivehealth.2013.252093,"Certain retinal disorders, if not detected in time, can be serious enough to cause blindness in patients. This paper proposes a low-cost and portable smartphone-based decision support system for initial screening of diabetic retinopathy using sophisticated image analysis and machine learning techniques. It requires a smartphone to be attached to a direct hand-held ophthalmoscope. The phone is used to capture fundus images as seen through the direct ophthalmoscope. We deploy pattern recognition on the captured images to develop a classifier that distinguishes normal images from those with retinal abnormalities. The algorithm performance is characterized by testing on an existing database. We were able to diagnose conditions with an average sensitivity of 86%.Our system has been designed to be used by ophthalmologists, general practitioners, emergency room physicians, and other health care personnel alike. The emphasis of this paper is not only on devising a detection algorithm for diabetic retinopathy, but more so on the development and utility of a novel system for diagnosis. Through this mobile eye-examination system, we envision making the early screening of diabetic retinopathy accessible, especially to rural regions in developing countries, where dedicated ophthalmology centers are expensive, and to alleviate detection in early stages.","pattern recognition, retinal diseases, mobile system, image processing, diabetic retinopathy"
Conference Paper,"Zeng M,Fang J,Miao H,Zhang T,Liu J",A Multi-Scale Self-Attention Network for Diabetic Retinopathy Retrieval,Association for Computing Machinery,2021,https://doi.org/10.1145/3484274.3484290;http://dx.doi.org/10.1145/3484274.3484290,"Diabetic retinopathy (DR), a complication due to diabetes, is a common cause of progressive damage to the retina. The mass screening of populations for DR is time-consuming. Therefore, computerized diagnosis is of great significance in the clinical practice, which providing evidence to assist clinicians in decision making. Specifically, hemorrhages, microaneurysms, hard exudates, soft exudates, and other lesions are verified to be closely associated with DR. These lesions, however, are scattered in different positions and sizes in fundus images, the internal relation of which are hard to be reserved in the ultimate features due to a large number of convolution layers that reduce the detail characteristics. In this paper, we present a deep-learning network with a multi-scale self-attention module to aggregate the global context to learned features for DR image retrieval. The multi-scale fusion enhances, in terms of scale, the efficacious latent relation of different positions in features explored by the self-attention. For the experiment, the proposed network is validated on the Kaggle DR dataset, and the result shows that it achieves state-of-the-art performance.","Diabetic retinopathy, Deep learning, Self-attention, Image retrieval"
Conference Paper,"Chandakkar PS,Venkatesan R,Li B,Li HK",A Machine-Learning Approach to Retrieving Diabetic Retinopathy Images,Association for Computing Machinery,2012,https://doi.org/10.1145/2382936.2383030;http://dx.doi.org/10.1145/2382936.2383030,"Diabetic retinopathy (DR) is a vision-threatening complication that affects people suffering from diabetes. Diagnosis of DR during early stages can significantly reduce the risk of severe vision loss. The process of DR severity grading is prone to human error and it also depends on the expertise of the ophthalmologist. As a result, many researchers have started exploring automated detection and evaluation of diabetic retinal lesions. Unfortunately, to date there is no automated system that can perform DR lesion detection with the accuracy that is comparable to a human expert. In this poster, we present a novel way of employing content-based image retrieval for providing a clinician with instant reference to archival and standardized DR images that are used for assisting the ophthalmologist with the diagnosis of a given DR image. The focus of the poster is on retrieving DR images with two significant DR clinical findings, namely, microaneurysm (MA) and neovascularization (NV). We propose a multi-class multiple-instance DR image retrieval framework that makes use of a modified color correlogram (CC) and statistics of steerable Gaussian filter (SGF) responses. Experiments using real DR images with comparisons to other prior-art methods demonstrate the improved performance of the proposed approach.","image retrieval, color correlogram, diabetic retinopathy, multiple-instance learning, fast radial symmetric transform, steerable gaussian filters"
Conference Paper,"Swan B,Nambiar S,Koutouan P,Mayorga ME,Ivy J,Fransen S",Evaluating Diabetic Retinopathy Screening Interventions in a Microsimulation Model,IEEE Press,2021,Not Found,"Diabetic retinopathy (DR) is the leading cause of blindness for working age Americans. Early detection, timely treatment, and appropriate follow-up care reduce the risk of severe vision loss from DR by 95%, yet, less than 50% of people with diabetes adhere to the recommended screening guidelines. Diabetes is a complicated disease for patients and their physicians to manage. We developed a microsimulation integrating the natural history model of DR with a patient's interaction with the care system. We introduced a DR screening device in primary care, with and without care coordination by a medical professional, in two interventions to the current care path. We found the interventions increased adherence of patients with vision-threatening DR (VTDR) to follow-up eye care, decreased the number of `unnecessary' visits in specialty eye care from patients without VTDR, and decreased the total years spent blind.",Not Found
Conference Paper,"Khaled O,El-Sahhar M,El-Dine MA,Talaat Y,Hassan YM,Hamdy A",Cascaded Architecture for Classifying the Preliminary Stages of Diabetic Retinopathy,Association for Computing Machinery,2021,https://doi.org/10.1145/3436829.3436854;http://dx.doi.org/10.1145/3436829.3436854,"Diabetes Mellitus is one of the modern world's most dominant diseases. This condition leads to a dangerous eye disease called Diabetic Retinopathy (DR), which eventually causes total blindness. The purpose of this research is the early detection of this condition to prevent further complications in the future. Over the past few years, Convolutional Neural Networks (CNNs) became very popular in resolving image processing and object detection problems for huge datasets. A cascaded model was proposed to detect the presence of DR and classify it into 4 stages, taking into consideration using a large dataset. Furthermore, preprocessing techniques such as normalization are applied, and finally, the input images are fed into a multi-layer Convolutional Neural Network. This method was utilized on 61,248 retinal images, which are a portion of the (EyePACS) dataset. It achieved a specificity of 96.1% for detecting the presence of the disease and 63.1% for determining its stage.","Image Processing, Neural Network (CNN)"
Conference Paper,"Bhatkar AP,Kharat G",FFT Based Detection of Diabetic Retinopathy in Fundus Retinal Images,Association for Computing Machinery,2016,https://doi.org/10.1145/2905055.2905107;http://dx.doi.org/10.1145/2905055.2905107,"We presented neural network based classifier for diabetic retinopathy detection in fundus images. The Multi Layer Perception Neural Network (MLPNN) based classifier is used to categorize fundus retinal images as normal and abnormal. Feature vector is composed of transform domain features and different statistical parameters of fundus retinal images. 64-point Fast Fourier Transform (FFT) is used as transform domain feature and Entropy, mean, standard deviation, average, Euler number, contrast, correlation, energy and homogeneity are used as statistical parameters. This feature vector is used as input to MLPNN based classifier. The classifier performance is calculated on DIARETDB0 database. The % classification accuracy on train and CV data sets is 99.48% and 100 respectively.","Retinal images database DIARETDB0, Diabetic Retinopathy (DR), Multi layer perception Neural Network (MLPNN)"
Conference Paper,"Hossen MS,Reza AA,Mishu MC",An Automated Model Using Deep Convolutional Neural Network for Retinal Image Classification to Detect Diabetic Retinopathy,Association for Computing Machinery,2020,https://doi.org/10.1145/3377049.3377067;http://dx.doi.org/10.1145/3377049.3377067,"Diabetic Retinopathy is considered as one of the significant reasons for vision impairment. Its identification involves detecting the presence of some features in retinal fundus images by clinicians which is a time and resource consuming procedure and a difficult manual diagnosis. In this article, a deep learning-based approach using Deep Convolutional Neural Network is developed for the diagnosis of Diabetic Retinopathy. By classifying from retinal fundus images with its severity level, it is possible to detect Diabetic Retinopathy. A Diabetic Retinopathy classifier is constructed followed by a transfer learning technique, DenseNet architecture based pre-trained model. Identification of Diabetic Retinopathy is done by detecting the presence of features like micro-aneurysms, exudates, hemorrhages in retinal images. We have also shown the preprocessing and augmentation of image data that benefits the model to detect retinopathy. After the training and validating procedure, the developed classifier achieves significant training accuracy of 96.3% and validation accuracy of 94.9% along with 0.88 quadratic weighted kappa.","Deep Learning, Convolutional Neural Network, Diabetic Retinopathy, Transfer Learning"
Conference Paper,"Singh N,Kumar A,Tripathi RC",An Automated Hybrid Technique for Detecting the Stage of Non-Proliferative Diabetic Retinopathy,Association for Computing Machinery,2011,https://doi.org/10.1145/1963564.1963576;http://dx.doi.org/10.1145/1963564.1963576,"Diabetes is fast becoming a scourge in the modern day society both in the developing and the developed societies. Diabetes related complications lead to a lot of morbidity and Diabetic Retinopathy is fast becoming the cause of preventable blindness. Early detection and treatment with Laser will go a long way in checking this disease.Non-proliferative Diabetic Retinopathy (NPDR) is the set of early changes that take place in the Retina. It is divided into 3 categories into mild, moderate and severe. Initial changes when the microaneurysms (MA) start appearing. Then it is followed by hemorrhages. Finally appearance of cotton wool spots and hard exudates categorize it into severe NPDR. The stage of neo vascularization (NV) when new blood vessels begin to appear (to compensate for the reduced blood supply and nutrition to the retina) finally qualifies for proliferative Diabetic Retinopathy.The idea is to extract the features of NPDR and depending on their intensity and frequency they can be graded into mild, moderate and severe. This automated grading can be matched with the specialist's perception and its accuracy can be tested. In this work, we have proposed a computer based automated hybrid technique for the detection of stages of Non-Proliferative Diabetic Retinopathy (NPDR) retinopathy stage using the color fundus images. The features are extracted from the Sample images using the image processing techniques and fed to the support vector machine (SVM). After color normalization preprocessing stage, an evidence value for every pixel is calculated by SVM. Then a mathematical morphological technique, a fuzzy c-means clustering technique, PCA, a support vector machine and a nearest neighbor classifier for further processing. The SVM classifier uses features extracted by combined 2DPCA instead of explicit image features as the input vector Combined 2DPCA is proposed and virtual SVM is applied to achieve the higher accuracy of classification. We demonstrate a Sensitivity of 97.1% for the classifier with the Specificity of 98.3%.Thus, an automated system for diagnosis of NPDR can be a useful tool for the Specialist to support in screening an detection of early Diabetic Retinopathy changes and hence timely intervention leading to reduced DR(Diabetic retinopathy) related blindness.","non-proliferative diabetic retinopathy (NPDR), diabetic retinopathy (DR)"
Conference Paper,"Wang L,Shang Y,Weng X,Yang X,Sang A,Dong J,Jiang K,Wu H",The Development of Standardized and Sharable Computer Interpretable Guidelines for Diabetic Retinopathy,Association for Computing Machinery,2019,https://doi.org/10.1145/3348416.3348418;http://dx.doi.org/10.1145/3348416.3348418,"The deployment of computer-interpretable guidelines (CIGs) is of significance for diabetic retinopathy (DR) clinical decision making (CDS) since the traditional management relied on amount of trained health care professionals. The propriety-based CDS models are not interoperable among different EHR vendors, limiting the implementation efficiency of such CDS models. This study aims to develop standardized and sharable CIGs for DR prevention. In this study, DR specific virtual medical record (vMR) was designed and data mapping was conducted from patient's continual care document (CCD). Several published guidelines on DR screening, diagnosis and treatment have been referred for DR CIG modeling via Gello, GLIF, OpenCDS editors. The CIGs were developed and testified in each editor and the results were compared. In conclusion, the developed CIG for DR is actionable and shareable, which is favorable to the management and prevention of DR.","diabetic retinopathy, clinical decision making, virtual medical record, Computer-interpretable guideline"
Conference Paper,"Xiao Y,Li J,Huang S,Shen N,Zhang J,Mi F,Xu T",Dealing with Long-Tail Issue in Diabetic Retinopathy and Diabetic Macular Edema Grading,Association for Computing Machinery,2022,https://doi.org/10.1145/3543081.3543088;http://dx.doi.org/10.1145/3543081.3543088,"Diabetic Retinopathy (DR) is a multiply occurring complication induced by prolonged course of diabetes. Diabetic Macular Edema (DME) is the most common complication of DR which is the major threat of vision loss. Hence, it is urgently needed to expand the early screening and diagnosis via computer-assisted therapy. However, prior works mainly focus on investigating DR and DME in isolation, largely ignoring their inherent relationships. Besides, the fundus data distribution is typically long-tailed, with tail classes concentrating on critical levels of DME. Motivated by the distinctive complexion above, this work presents a novel position-guided attention block (PGAB) as well as an innovative label-sensitive (LS) loss, which are respectively in charge of extracting position-sensitive features to exploit interactions between hard exudate and macular and encouraging the model to embrace tail classes to lift the accuracy on critical levels of DME. Comprehensive experiments on popular Messidor and IDRiD datasets well demonstrate the superiority of our approach in achieving competitive performance compared to state-of-the-arts.","Long-tail, Diabetic macular edema, Multi-disease grading, Diabetic retinopathy"
Conference Paper,"Umapathy A,Sreenivasan A,Nairy DS,Natarajan S,Rao BN","Image Processing, Textural Feature Extraction and Transfer Learning Based Detection of Diabetic Retinopathy",Association for Computing Machinery,2019,https://doi.org/10.1145/3314367.3314376;http://dx.doi.org/10.1145/3314367.3314376,"Diabetic Retinopathy (DR) is one of the most common causes of blindness in adults. The need for automating the detection of DR arises from the deficiency of ophthalmologists in certain regions where screening is done, and this paper is aimed at mitigating this bottleneck. Images from publicly available datasets STARE, HRF, and MESSIDOR along with a novel dataset of images obtained from the Retina Institute of Karnataka are used for training the models. This paper proposes two methods to automate the detection. The first approach involves extracting features using retinal image processing and textural feature extraction, and uses a Decision Tree classifier to predict the presence of DR. The second approach applies transfer learning to detect DR in fundus images. The accuracies obtained by the two approaches are 94.4% and 88.8% respectively, which are competent to current automation methods. A comparison between these models is made. On consultation with Retina Institute of Karnataka, a web application which predicts the presence of DR that can be integrated into screening centres is made.","Biomedical Image Processing, Computer Aided Diagnosis, Textural Feature Extraction, Transfer Learning"
Conference Paper,"Jiang Y,Wu H,Dong J",Automatic Screening of Diabetic Retinopathy Images with Convolution Neural Network Based on Caffe Framework,Association for Computing Machinery,2017,https://doi.org/10.1145/3107514.3107523;http://dx.doi.org/10.1145/3107514.3107523,"Objective Diabetic retinopathy (DR) is a serious complication of eye in diabetes mellitus (DM) patients. In order to automatically screen DR, we aim to use convolutional neural network (CNN) to screen DR fundus images automatically.Methods A total of 10,551 fundus images from Kaggle fundus image dataset were collected for this experiment. Firstly, the images were preprocessed by histogram equalization and image augmentation. Then, the CNN was constructed and trained with Caffe framework. Our designed CNN models were trained by 8,626 images. Finally, the performance of the trained CNN model was validated by classifying 1,925 fundus images into DR and non-DR ones.Results The performance results indicated that the CNN achieved accuracy of 75.70% in 1,925 test fundus images.Conclusions CNN model is useful to classify the DR fundus images, thus might be applicable in further DR screening program for larger DM population.","Caffe, diabetic retinopathy, deep learning, Convolutional neural network"
Conference Paper,"Kulkarni P,Stranieri A,Jelinek H",Comparing Pixel N-Grams and Bag of Visual Word Features for the Classification of Diabetic Retinopathy,Association for Computing Machinery,2019,https://doi.org/10.1145/3290688.3290726;http://dx.doi.org/10.1145/3290688.3290726,"The extraction of Bag of Visual Words (BoVW) features from retinal images for automated classification has been shown to be effective but computationally expensive. Histogram and co-variance matrix features do not generally result in models that have the same predictive accuracy as BoVW and are still computationally expensive. The discovery of features that result in accurate image classification on computationally constrained devices such as smartphones would enable new and promising applications for image classification. For example, smartphone retinal cameras can conceivably make diabetic retinopathy widely available and potentially reduce undiagnosed retinopathy if it could be achieved with computationally simple classification algorithms.A novel image feature extraction technique inspired by N-grams in text mining, called 'Pixel N-grams' is described that can serve this purpose. Results on mammogram and texture classification have shown high accuracy despite the reduced computational complexity. However retinal scan classification results using Pixel N-grams lag behind BoVW approaches. An explanation for the relative poor performance of Pixel N-grams with diabetic retinopathy that draws on concepts associated with the No Free Lunch theorem are presented.","Image classification, Image feature extraction, Diabetic retinopathy, Pixel N-gram, No Free Lunch Theorem"
Conference Paper,"Kazakh-British NS,Pak AA,Abdullina D",Automatic Detection of Blood Vessels and Classification in Retinal Images for Diabetic Retinopathy Diagnosis with Application of Convolution Neural Network,Association for Computing Machinery,2018,https://doi.org/10.1145/3290589.3290596;http://dx.doi.org/10.1145/3290589.3290596,"Described for the first time by MacKenzie (1879), diabetic retinopathy (DR) and today is the most common cause of blindness among persons of working age in most countries of the world. Prevention of DR is the early detection of a violation of morphology and a deterioration in the light sensitivity of the retina associated with this disease. To do this, highly informative methods of non-invasive retinal research are needed, with predictive capabilities. In this article, we propose an autonomous algorithm for such diagnostics, based on the training of the Artificial Neural Network (ANN) and the preprocessing of the image by an anisotropic diffusion filter. It allows not only to detect pathologies moreover to provide them with probabilistic evaluation of a possible variant of the disease.","Artificial Neural Networks, Diabetic Retinopathy, Medical Diagnostics, Blood Vessel Segmentation, Frang & Sato Filter"
Conference Paper,"Zhang B,Yue W,Liu Q,Hu S",Application of Artificial Intelligence in Medical Imaging Diagnosis,Association for Computing Machinery,2021,https://doi.org/10.1145/3448748.3448810;http://dx.doi.org/10.1145/3448748.3448810,"The development of artificial intelligence promotes the great progress of medical imaging diagnosis. Based on this, this paper reviews and discusses the medical image diagnosis based on artificial intelligence in recent years, introduces the procedure of medical image diagnosis, the algorithms involved and the key progress, analyzes the shortcomings of the current technology, and the possible development direction in the future.","deep learing, medical imaging diagnosis, artificial intelligence, image processing"
Conference Paper,"Chang EY,Wu MH,Tang KF,Kao HC,Chou CN",Artificial Intelligence in XPRIZE DeepQ Tricorder,Association for Computing Machinery,2017,https://doi.org/10.1145/3132635.3132637;http://dx.doi.org/10.1145/3132635.3132637,"The DeepQ tricorder device developed by HTC from 2013 to 2016 was entered in the Qualcomm Tricorder XPRIZE competition and awarded the second prize in April 2017. This paper presents DeepQ»s three modules powered by artificial intelligence: symptom checker, optical sense, and vital sense. We depict both their initial design and ongoing enhancements.","deepq, xprize tricorder, medical iot, artificial intelligence"
Conference Paper,"Ben Rjab A,Mellouli S",Artificial Intelligence in Smart Cities: Systematic Literature Network Analysis,Association for Computing Machinery,2019,https://doi.org/10.1145/3326365.3326400;http://dx.doi.org/10.1145/3326365.3326400,"The adoption of artificial intelligence (AI) has recently gained increasing attention in the smart cities context. Given the relevance of this topic, the aim of this paper is to conduct a literature review to investigate the role of AI in the different sectors of smart cities. The methodology used in this study combines the systematic literature review in order to identify the most relevant studies, and the citation network analysis to unfold the dynamics of the field under study. The results of this research show not only the importance of this technology that plays a key role in several applications within a smart city but also the challenges that it brings to cities and to citizens.","citation network analysis, systematic literature review, Artificial intelligence, smart cities"
Book,Not Found,SETN '22: Proceedings of the 12th Hellenic Conference on Artificial Intelligence,Association for Computing Machinery,2022,Not Found,Not Found,Not Found
Conference Paper,"Phong TD,Duong HN,Nguyen HT,Trong NT,Nguyen VH,Van Hoa T,Snasel V",Brain Hemorrhage Diagnosis by Using Deep Learning,Association for Computing Machinery,2017,https://doi.org/10.1145/3036290.3036326;http://dx.doi.org/10.1145/3036290.3036326,"We propose an approach to diagnosing brain hemorrhage by using deep learning. In particular, three types of convolutional neural networks that are LeNet, GoogLeNet, and Inception-ResNet are employed. In the training phase, we only train the last fully-connected layers of GoogLeNet and Inception-ResNet, but do train all layers of LeNet. We build a dataset consisting of 100 cases collected from the 115 Hospital, Ho Chi Minh City, Vietnam. The experimental results show that LeNet, GoogLeNet, and Inception-ResNet achieve accuracy of 0.997, 0.982, and 0.992 respectively on the dataset. Through experimental results, we found that convolutional neural networks are pre-trained with non-medical images like GoogLeNet or Inception-ResNet can be used in medical image diagnosis, particularly in brain hemorrhage diagnosis. And, we confirm that among the three deep models, LeNet is the most time-consuming model.","brain hemorrhage, Computer-aided detection, convolutional neural networks, deep learning"
Conference Paper,"Sajeev S,Prem Senthil M",Classifying Infective Keratitis Using a Deep Learning Approach,Association for Computing Machinery,2021,https://doi.org/10.1145/3437378.3437388;http://dx.doi.org/10.1145/3437378.3437388,"Early diagnosis of infective keratitis is critical as it is a vision-threatening condition that can lead to significant vision loss and ocular morbidity. Diagnosis of infective keratitis done through clinical findings and slit- lamp examination is intricate and requires high expertise. Most infective keratitis cases are challenging to the clinicians. This paper proposes a deep learning approach enabling a more accurate diagnoses and treatment of infective keratitis. As a first step towards developing a comprehensive deep learning-based disease detection tool, we have classified bacterial and viral keratitis based on slit-lamp images and convolutional neutral network. A total of 446 keratitis images (bacterial – 271 and viral - 175) were available for the study. The experiment was conducted with different CNN configurations: with different input shape (image sizes: 64x64, 128x128, 256x256, 400x400) with two and three convolution layers. Image size 64x64 with three convolutional layer and no pooling achieved the highest performance (sensitivity =0.715, specificity= 0.880, precision= 0.807, accuracy= 0.812 and AUC=0.856). Experimental results show that even with a small dataset CNN was able to produce a good classification result.","deep learning, keratitis, classification, convolutional neutral network"
Conference Paper,Zhuang L,Deep-Learning-Based Diagnosis of Cassava Leaf Diseases Using Vision Transformer,Association for Computing Machinery,2022,https://doi.org/10.1145/3508259.3508270;http://dx.doi.org/10.1145/3508259.3508270,"Viral diseases are major causes leading to the poor yields of cassava, which is the second-largest source of food carbohydrates in Africa. As symptoms of these diseases can usually be identified by inspecting cassava leafs, visual diagnosis of cassava leaf diseases is of significant importance in food security and agriculture development. Considering the shortage of qualified agricultural experts, automatic approaches for the image-based detection of cassava leaf diseases are in great demand. In this paper, on the basis of Vision Transformer, we propose a deep learning method to identify the type of viral disease in a cassava leaf image. The image dataset of cassava leaves is provided by the Makerere Artificial Intelligence Lab in a Kaggle competition, consisting of 4 subtypes of diseases and healthy cassava leaves. Our results show that Vision-Transformer-based model can effectively achieve an excellent performance regarding the classification of cassava leaf diseases. After applying the K-Fold cross validation technique, our model reaches a categorization accuracy 0.9002 on the private test set. This score ranks top 3% in the leaderboard, and can get a silver medal prize in the Kaggle competition. Our method can be applied for the identification of diseased plants, and potentially prevent the irreparable damage of crops.","Cassava leaf disease, Kaggle competition, Deep learning, Vision Transformer"
Book,Not Found,ISAIMS '22: Proceedings of the 3rd International Symposium on Artificial Intelligence for Medicine Sciences,Association for Computing Machinery,2022,Not Found,Not Found,Not Found
Journal Article,"Ghosh S,Das N,Das I,Maulik U",Understanding Deep Learning Techniques for Image Segmentation,Association for Computing Machinery,2019,https://doi.org/10.1145/3329784;http://dx.doi.org/10.1145/3329784,"The machine learning community has been overwhelmed by a plethora of deep learning--based approaches. Many challenging computer vision tasks, such as detection, localization, recognition, and segmentation of objects in an unconstrained environment, are being efficiently addressed by various types of deep neural networks, such as convolutional neural networks, recurrent networks, adversarial networks, and autoencoders. Although there have been plenty of analytical studies regarding the object detection or recognition domain, many new deep learning techniques have surfaced with respect to image segmentation techniques. This article approaches these various deep learning techniques of image segmentation from an analytical perspective. The main goal of this work is to provide an intuitive understanding of the major techniques that have made a significant contribution to the image segmentation domain. Starting from some of the traditional image segmentation approaches, the article progresses by describing the effect that deep learning has had on the image segmentation domain. Thereafter, most of the major segmentation algorithms have been logically categorized with paragraphs dedicated to their unique contribution. With an ample amount of intuitive explanations, the reader is expected to have an improved ability to visualize the internal dynamics of these processes.","convolutional neural networks, semantic image segmentation, Deep learning"
Conference Paper,"Wang L,Huang Y,Lin B,Wu W,Chen H,Pu J",Automatic Classification of Exudates in Color Fundus Images Using an Augmented Deep Learning Procedure,Association for Computing Machinery,2019,https://doi.org/10.1145/3364836.3364843;http://dx.doi.org/10.1145/3364836.3364843,"Automatic classification of hard and soft exudates in color fundus images is very helpful for computer-aided diagnosis of retina related diseases, such as diabetic retinopathy (DR). In this study, we developed a novel method for this purpose based on the emerging deep learning technology known as convolutional neural networks (CNNs) by leveraging its strength of explicitly extracting the underlying image textures. We specifically investigate whether the emphasis of the image characteristic within an exudate spot could improve the classification performance. To verify this, we collected a database of fundus image that contains soft and hard exudates. The exudate regions were cropped from fundus images. There are a total of 550 cropped image patches (275 hard and 275 soft) with a fixed dimension of 128×128 pixels. These patches were further thresholded to exclude image background, resulting in another version of image patches merely containing exudate regions. Each version of image patches was randomly divided into 440 for training and 110 for testing, and then fed into the developed deep learning network in a separate or combinatorial way. Experimental results showed that the classification accuracy of this method was 93.41% when the thresholded version of the dataset was used as an augmented learning procedure, as compared to 90.80% and 87.41% when the original and background excluded datasets were used for training, respectively. This suggests that the augmented CNN can provide more accurate classification performance when the region-of-interest (ROI) and the original images were integrated.","convolutional neural networks, color fundus images, Exudate classification, diabetic retinopathy"
Conference Paper,"Jia DM,Yuan CF,Guo S,Jiang Z,Xu D,Wang A","Application of ""Artificial Intelligence and Big Data"" in Sports Rehabilitation for Chinese Judicial Administrative Drug Addicts",Association for Computing Machinery,2019,https://doi.org/10.1145/3358331.3358336;http://dx.doi.org/10.1145/3358331.3358336,"Under the background of ""Wisdom Drug Rehabilitation"", we introduced ""Artificial Intelligence and Big Data"" into ""exercise rehabilitation"" work of drug addicts in judicial administrative system. It is a practical innovation of drug treatment in China. This article will elaborate this innovation of the construction and application of ""Exercise Rehabilitation"" intelligence platform system. This system will improve mental status, alleviate physical and psychological symptoms, ensure safety in places, lighten the burden of professional police officers, make rapid analysis, make accurate decisions and improve the integrity rate of the addict.","big data, Sports rehabilitation, rehabilitation training, artificial intelligence, judicial administrative"
Conference Paper,"Cao Q,Liao SS,Meng X,Ye H,Yan Z,Wang P",Identification of Viable Embryos Using Deep Learning for Medical Image,Association for Computing Machinery,2018,https://doi.org/10.1145/3309129.3309143;http://dx.doi.org/10.1145/3309129.3309143,"Identifying viable embryos for implantation is one of the most relevant aspects in assisted reproductive technology. However, embryo selection highly depends on visual examination by embryologists via microscopy, and their evaluations are often subjective. The rapid growth of image processing technology has resulted in increased interest in the use of machine learning methods for embryo selection in in vitro fertilization (IVF) programs. The present study uses deep learning method for the morphological classification of embryos based on medical images. The proposed system is trained and tested on a real data set of 1,310 images from 344 embryos and evaluated by comparison with other traditional machine learning methods to solve similar classification problems. The results indicate that our new deep learning model significantly outperforms other methods. Our work contributes immensely to the fields of assisted reproductive technology, medical image processing, and decision support system design.","Medical image classification, Assisted reproduction technology, Deep learning"
Conference Paper,"Jeanneret Medina M,Lalanne D,Baudet C",Human-Computer Interaction in Artificial Intelligence for Blind and Vision Impairment: An Interpretative Literature Review Based on Bibliometrics: L’interaction Humain-Machine En Intelligence Artificielle Pour Les Aveugles et Déficients Visuels : Une Revue de Littérature Interprétative Fondée Sur La Bibliométrie,Association for Computing Machinery,2022,https://doi.org/10.1145/3502178.3529111;http://dx.doi.org/10.1145/3502178.3529111,"The rise of artificial intelligence and particularly machine learning conduct to an emerging landscape of intelligent interactive systems. Such technologies help clinicians to detect diseases from medical imaging, and allow to describe the visual world to people with visual impairment. However, this new technological landscape comes with a set of HCI challenges. To better understand the importance of HCI in AI, we focused on blind and vision impairment as a representative application domain. Using bibliometric techniques, we retained 187 scientific publications organized in three clusters. Our findings show that HCI is absent in research related to medical computer systems but has moderate importance when the aim is to assist BVI in their daily life.","Revue, Intelligence Artificielle, Visual Impairment, Artificial Intelligence, Interaction-Humain Machine, Human-Computer Interaction, Déficience Visuelle, Bibliométrie, Bibliometrics, Blind, Review"
Conference Paper,Teeyapan K,Deep Learning-Based Approach for Corneal Ulcer Screening,Association for Computing Machinery,2021,https://doi.org/10.1145/3486713.3486734;http://dx.doi.org/10.1145/3486713.3486734,"Corneal ulcer is a common corneal symptom that, upon infection, can lead to destruction of the corneal tissues, resulting in corneal blindness. To ease the corneal ulcer screening process, this paper introduces a deep transfer learning architecture based on various backbone networks to help identify two severity levels of the symptom: early stage and advanced stage. The total of 15 well-known deep convolutional neural networks are used as the base model. The proposed transfer learning-based architectures are trained, validated, and tested on 426, 143, and 143 fluorescein staining slit-lamp images from the public SUSTech-SYSU dataset. The experimental results show that ResNet50 is the best model achieving the best accuracy, sensitivity, F1 score, and Cohen’s kappa of 95.10%, 94.37%, 95.04%, and 0.9021, respectively, on the blind test set of the cropped corneal images. This model is further evaluated on an external dataset and its prediction is also explained using Integrated Gradients to provide an insight into its generalization performance.","convolutional neural networks, deep learning, cornea ulcers, transfer learning, keratitis"
Conference Paper,"Suo Q,Xue H,Gao J,Zhang A",Risk Factor Analysis Based on Deep Learning Models,Association for Computing Machinery,2016,https://doi.org/10.1145/2975167.2975208;http://dx.doi.org/10.1145/2975167.2975208,"Accurate rendering of diagnosis and prognosis for a disease with respect to a patient requires analysis of complicated, diverse, yet correlated risk factors (RFs). Most of the existing methods for this purpose are based on handcraft RFs by calculating their statistical significance to the disease. However, such methods not only incur intensive labor but also lack capability to discover or infer previously unknown complex relationships and combined effects among correlated RFs.Nowadays, deep learning models have emerged as a hot topic, due to its ability to automatically extract useful and complex features from raw data. In this paper, we explore the effectiveness of deep learning on medical data by building a deep learning based framework to analyze risk factors and study its prediction performance in disease diagnosis. Specifically, we investigate the application of deep learning with a special focus on interpreting the latent features extracted or created from raw data by the model. Experimental results demonstrate that deep learning based methods are able to aggregate features sharing same characteristics, and reduce effects from unimportant and uncorrelated RFs. The abstract features obtained by deep learning methods can represent the essentials of raw inputs, and give a good prediction performance in disease diagnosis.","Risk factor analysis, Integrated features, Osteoporosis, Deep learning"
Conference Paper,"Oumaima G,Lotfi E,Fatiha E,Mohammed B",Deep Learning Approach as New Tool for Type 2 Diabetes Detection,Association for Computing Machinery,2019,https://doi.org/10.1145/3320326.3320359;http://dx.doi.org/10.1145/3320326.3320359,"The use of intelligent techniques in medical diagnosis is gradually increasing, among these techniques, we have deep learning algorithms that can help us detect the onset of diabetes. Early detection of diabetes can reduce the complications associated with the disease.This paper aims to present the ""Deep Learning"" technology to predict whether a patient is likely to develop diabetes within five years, it is based on diagnostic measures of eight simple characteristics. We propose models for the diagnosis of diabetes disease by applying deep learning architecture namely DNN.","Deep Learning, DNN, diagnostic"
Book,Not Found,iWOAR '22: Proceedings of the 7th International Workshop on Sensor-Based Activity Recognition and Artificial Intelligence,Association for Computing Machinery,2022,Not Found,Not Found,Not Found
Conference Paper,"Iftikhar S,Golec M,Chowdhury D,Gill SS,Uhlig S",FogDLearner: A Deep Learning-Based Cardiac Health Diagnosis Framework Using Fog Computing,Association for Computing Machinery,2022,https://doi.org/10.1145/3511616.3513108;http://dx.doi.org/10.1145/3511616.3513108,"The application of the Internet of Things (IoT) and Artificial Intelligence (AI) in healthcare is an emerging domain. In Healthcare applications, relying on both IoT and AI requires paying attention to latency, responsiveness and management of data loads. Most of the healthcare applications are based on Cloud computing and use Cloud platforms such as Google Cloud and Microsoft Azure. With the increased adoption of IoT in various domains, the data generation rate and volume by IoT devices has tremendously increased, making the Cloud insufficient for latency sensitive healthcare applications. Fog computing, complementing the Cloud services, can be deployed close to the data source to better utilize distributed resources and meet the Quality of Service (QoS) requirements of healthcare application. In this paper, we propose a Fog-based cardiac health detection framework, called FogDLearner. FogDLearner utilizes distributed resources to diagnose cardiac health of a person without compromising QoS and accuracy. FogDLearner uses a deep learning based classifier to predict the cardiac health of the user. The performance of the proposed framework is evaluated on the PureEdgeSim simulator, in terms of resource utilization under overload and under-load scenarios, mobility support, and power consumption. The experimental results show the validity of proposed work for support of mobile applications.","Cardiac disease detection, Deep learning, Smart healthcare, Fog computing, IoT"
Journal Article,"Lv Z,Yu Z,Xie S,Alamri A",Deep Learning-Based Smart Predictive Evaluation for Interactive Multimedia-Enabled Smart Healthcare,Association for Computing Machinery,2022,https://doi.org/10.1145/3468506;http://dx.doi.org/10.1145/3468506,"Two-dimensional1 arrays of bi-component structures made of cobalt and permalloy elliptical dots with thickness of 25 nm, length 1 mm and width of 225 nm, have been prepared by a self-aligned shadow deposition technique. Brillouin light scattering has been exploited to study the frequency dependence of thermally excited magnetic eigenmodes on the intensity of the external magnetic field, applied along the easy axis of the elements.This study aims to enhance the security for people's health, improve the medical level further, and increase the confidentiality of people's privacy information. Under the trend of wide application of deep learning algorithms, the convolutional neural network (CNN) is modified to build an interactive smart healthcare prediction and evaluation model (SHPE model) based on the deep learning model. The model is optimized and standardized for data processing. Then, the constructed model is simulated to analyze its performance. The results show that accuracy of the constructed system reaches 82.4%, which is at least 2.4% higher than other advanced CNN algorithms and 3.3% higher than other classical machine algorithms. It is proved based on comparison that the accuracy, precision, recall, and F1 of the constructed model are the highest. Further analysis on error shows that the constructed model shows the smallest error of 23.34 pixels. Therefore, it is proved that the built SHPE model shows higher prediction accuracy and smaller error while ensuring the safety performance, which provides an experimental reference for the prediction and evaluation of smart healthcare treatment in the later stage.","healthcare prediction and evaluation model, convolutional neural network, Deep learning, smart healthcare, precision"
Conference Paper,"Osmani V,Li L,Danieletto M,Glicksberg B,Dudley J,Mayora O",Automatic Processing of Electronic Medical Records Using Deep Learning,Association for Computing Machinery,2018,https://doi.org/10.1145/3240925.3240961;http://dx.doi.org/10.1145/3240925.3240961,"Background. Availability of large amount of clinical data is opening up new research avenues in a number of fields. An exciting field in this respect is healthcare, where secondary use of healthcare data is beginning to revolutionize healthcare. Except for availability of Big Data, both medical data from healthcare institutions (such as EMR data) and data generated from health and wellbeing devices (such as personal trackers), a significant contribution to this trend is also being made by recent advances on machine learning, specifically deep learning algorithms.Objectives. The objective of this work was to provide an overview of how automatic processing of Electronic Medical Records (EMR) data using Deep Learning techniques is contributing to understating of evolution of chronic diseases and prediction of risk of developing these diseases and associated complications.Methods. A review of the scientific literature was conducted using scientific databases Google Scholar, PubMed, IEEE, and ACM. Searches were focused on publications containing terms related to both Electronic Medical Records and Deep Learning and their synonyms.Results. The review has shown that a number of studies have reported results that provide unprecedented insights into chronic diseases through the use of deep learning methods to analyze EMR data. However, a major roadblock that may limit how effectively these paradigms can be utilized and adopted into clinical practice is in the interpretability of these models by medical professionals for whom many of them are designed.Conclusions. Despite the identified challenges automatic processing of EMR data with state-of-the-art machine learning approaches, such as deep learning, will push predictive power well beyond the current success rates. Hopefully, we will continue to see findings from these works to continue to transform clinical practices, leading to more cost effective and efficient hospital systems along with better patient outcomes and satisfaction.",Not Found
Conference Paper,"Wittler I,Liu X,Dong A",Deep Learning Enabled Predicting Modeling of Mortality of Diabetes Mellitus Patients,Association for Computing Machinery,2019,https://doi.org/10.1145/3332186.3333262;http://dx.doi.org/10.1145/3332186.3333262,"Diabetes mellitus (DM) is a major public health concern that requires continuing medical care. It is also a leading cause of other serious health complications associated with longer hospital stays and increased mortality rates. Fluctuation of blood glucose levels are easy to monitor. Physicians manage patients' blood glucose to prevent or slow the progress of diabetes. In this paper, the MIMIC-III data set is used to develop and train multiple models that aim to predict the mortality of DM patients. Our deep learning model of convolutional neural network produced a 0.885 AUC score, above all baseline models we constructed, which include decision trees, random forests, and fully connected neural networks. The inputs for each model were comprised of admission type, age, Elixhauser comorbidity score, blood glucose measurements, and blood glucose range. The results obtained from these models are valuable for physicians, patients, and insurance companies. By analyzing the features that drive these models, care management for diabetic patients in an ICU setting can be improved resulting in lowered motality rate.","diabetes, data mining, convolutional neural networks, supervised classification"
Conference Paper,"Wittler I,Liu X,Dong A",Deep Learning Enabled Predicting Modeling of Mortality of Diabetes Mellitus Patients,Association for Computing Machinery,2019,https://doi.org/10.1145/3332186.3333262;http://dx.doi.org/10.1145/3332186.3333262,"Diabetes mellitus (DM) is a major public health concern that requires continuing medical care. It is also a leading cause of other serious health complications associated with longer hospital stays and increased mortality rates. Fluctuation of blood glucose levels are easy to monitor. Physicians manage patients' blood glucose to prevent or slow the progress of diabetes. In this paper, the MIMIC-III data set is used to develop and train multiple models that aim to predict the mortality of DM patients. Our deep learning model of convolutional neural network produced a 0.885 AUC score, above all baseline models we constructed, which include decision trees, random forests, and fully connected neural networks. The inputs for each model were comprised of admission type, age, Elixhauser comorbidity score, blood glucose measurements, and blood glucose range. The results obtained from these models are valuable for physicians, patients, and insurance companies. By analyzing the features that drive these models, care management for diabetic patients in an ICU setting can be improved resulting in lowered motality rate.","convolutional neural networks, data mining, diabetes, supervised classification"
Conference Paper,He J,Automated Detection of Intracranial Hemorrhage on Head Computed Tomography with Deep Learning,Association for Computing Machinery,2020,https://doi.org/10.1145/3397391.3397436;http://dx.doi.org/10.1145/3397391.3397436,"Intracranial hemorrhage is a serious health problem worldwide requiring rapid and often intensive medical treatment. However, the diagnosis process of intracranial hemorrhage is complicated and often time consuming when looking for the presence, location and type of hemorrhage on head computed tomography (CT), even for highly trained specialists. Therefore, it's a key challenge to achieve automated detection of intracranial hemorrhage on head CT with a promising detection accuracy at the examination level, leaving an urgent and critical issue to be addressed. In this paper, to accomplish this crucial task, we utilize a series of deep convolutional neural networks based on SE-ResNeXt50 and EfficientNet-B3 to simultaneously extract features from head CT and learn the classification for 5 subtypes of intracranial hemorrhage. The image dataset of head CT is provided by Radiological Society of North America through a featured competition on the Kaggle platform. The results show that the ensemble of SE-ResNeXt50 and EfficientNet-B3 trained with weighted multi-label logarithmic loss achieves an expert-level performance regarding the classification accuracy of intracranial hemorrhage. Our deep learning model obtain a score 0.0548 on the test set, which locates at the top 4% among all teams and can get a silver medal prize in the Kaggle competition.","computer aided diagnosis, head computed tomography, automated detection, deep learning, Intracranial hemorrhage"
Journal Article,"Messina P,Pino P,Parra D,Soto A,Besa C,Uribe S,Andía M,Tejos C,Prieto C,Capurro D",A Survey on Deep Learning and Explainability for Automatic Report Generation from Medical Images,Association for Computing Machinery,2022,https://doi.org/10.1145/3522747;http://dx.doi.org/10.1145/3522747,"Every year physicians face an increasing demand of image-based diagnosis from patients, a problem that can be addressed with recent artificial intelligence methods. In this context, we survey works in the area of automatic report generation from medical images, with emphasis on methods using deep neural networks, with respect to (1) Datasets, (2) Architecture Design, (3) Explainability, and (4) Evaluation Metrics. Our survey identifies interesting developments but also remaining challenges. Among them, the current evaluation of generated reports is especially weak, since it mostly relies on traditional Natural Language Processing (NLP) metrics, which do not accurately capture medical correctness.","Medical report generation, natural language report, medical image captioning, medical images, deep learning, explainable artificial intelligence"
Journal Article,"Morid MA,Sheng OR,Dunbar J",Time Series Prediction Using Deep Learning Methods in Healthcare,Association for Computing Machinery,2023,https://doi.org/10.1145/3531326;http://dx.doi.org/10.1145/3531326,"Traditional machine learning methods face unique challenges when applied to healthcare predictive analytics. The high-dimensional nature of healthcare data necessitates labor-intensive and time-consuming processes when selecting an appropriate set of features for each new task. Furthermore, machine learning methods depend heavily on feature engineering to capture the sequential nature of patient data, oftentimes failing to adequately leverage the temporal patterns of medical events and their dependencies. In contrast, recent deep learning (DL) methods have shown promising performance for various healthcare prediction tasks by specifically addressing the high-dimensional and temporal challenges of medical data. DL techniques excel at learning useful representations of medical concepts and patient clinical data as well as their nonlinear interactions from high-dimensional raw or minimally processed healthcare data.In this article, we systematically reviewed research works that focused on advancing deep neural networks to leverage patient structured time series data for healthcare prediction tasks. To identify relevant studies, we searched MEDLINE, IEEE, Scopus, and ACM Digital Library for relevant publications through November 4, 2021. Overall, we found that researchers have contributed to deep time series prediction literature in 10 identifiable research streams: DL models, missing value handling, addressing temporal irregularity, patient representation, static data inclusion, attention mechanisms, interpretation, incorporation of medical ontologies, learning strategies, and scalability. This study summarizes research insights from these literature streams, identifies several critical research gaps, and suggests future research opportunities for DL applications using patient time series data.","Systematic review, patient time series, healthcare predictive analytics, deep learning methods"
Conference Paper,"Li J,Shao J,Wu J,Fang J,Zhou T,Wu H",The Development and Implementation of Deep Learning Assisted Interoperable Retinal Image Structured Report Module in PACS,Association for Computing Machinery,2022,https://doi.org/10.1145/3545729.3545753;http://dx.doi.org/10.1145/3545729.3545753,"With the increasing incidence of retinal fundus disease, more attention has been paid to the screening and prevention of fundus diseases. However, the low efficiency and interoperability issues hinder the application of retinal disease reporting. In this study, we developed an intelligent classification module for retina based on inception V3 pre-trained model. The top rank of eight classification scores was output as recommendation for image reader reviewing, and the other structured report (SR) module was designed to generate FHIR-compliant retinal diagnostic SRs by customizing existing FHIR DiagnosticReport and Observation resources. The results demonstrated the artificial intelligence (AI) classification pop-up window and the validation of produced SR via a public HAPI FHIR server. The results suggested that the SR was easily shared and could be accurately and integrated with other hospitals or clinical research institutions. In summary, our developed AI assisted SRs module is clinical workflow friendly, and the produced SRs could be easily shared and integrated, which can provide a meaningful use way for further analytic research.","structured report, picture archiving and communication systems, Deep learning, retina, interoperability"
Conference Paper,"Hao F,Li M,Liu X,Li X,Yue J,Han W",Classification of Glomeruli with Membranous Nephropathy on Renal Digital Pathological Images with Deep Learning,Association for Computing Machinery,2020,https://doi.org/10.1145/3433996.3434486;http://dx.doi.org/10.1145/3433996.3434486,"Membranous nephropathy (MN) is the one of the most common pathological types that cause adult nephrotic syndrome (NS). Recently, the incidence of MN has shown a clear upward trend. Nevertheless, there is no more accurate and fast artificial intelligence algorithm for diagnose of MN which work is laborintensive and time-consuming if it is done manually. In this article, MN-Net, a CNN-based method, is applied to glomeruli detection and classification on whole slide images (WSIs). This work is mainly divided into two parts, a glomerulus detection network and a classification network. The detection network is utilized to locate glomeruli on WSIs. Multiple instance learning (MIL), a weakly supervised classification network following detection network classifies the glomeruli detected earlier. Our network is training on PASM-stained WSIs of 1281 cases collected from multi-centers. Experimental results prove that our method is effective with a high precision of 99.66% for glomeruli detection and 99.53% for MN glomeruli classification on this dataset. In summary, this method has been proved to be an effective method with advantages of speed, high accuracy, strong robustness, and low cost of data annotation that can be applied to the diagnosis of renal pathology. In the future, this method can also be extended to the classification of other glomerular diseases under light microscope (LM). The introduction of glomerular basement membrane (GBM) segmentation and measurement models can further improve the reliability of this model.","Artificial intelligence, Deep learning, Classification, Membranous Nephropathy"
Journal Article,"Xie J,Zhang B,Ma J,Zeng D,Lo-Ciganic J",Readmission Prediction for Patients with Heterogeneous Medical History: A Trajectory-Based Deep Learning Approach,Association for Computing Machinery,2021,https://doi.org/10.1145/3468780;http://dx.doi.org/10.1145/3468780,"Hospital readmission refers to the situation where a patient is re-hospitalized with the same primary diagnosis within a specific time interval after discharge. Hospital readmission causes $26 billion preventable expenses to the U.S. health systems annually and often indicates suboptimal patient care. To alleviate those severe financial and health consequences, it is crucial to proactively predict patients’ readmission risk. Such prediction is challenging because the evolution of patients’ medical history is dynamic and complex. The state-of-the-art studies apply statistical models which use static predictors in a period, failing to consider patients’ heterogeneous medical history. Our approach – Trajectory-BAsed DEep Learning (TADEL) – is motivated to tackle the deficiencies of the existing approaches by capturing dynamic medical history. We evaluate TADEL on a five-year national Medicare claims dataset including 3.6 million patients per year over all hospitals in the United States, reaching an F1 score of 87.3% and an AUC of 88.4%. Our approach significantly outperforms all the state-of-the-art methods. Our findings suggest that health status factors and insurance coverage are important predictors for readmission. This study contributes to IS literature and analytical methodology by formulating the trajectory-based readmission prediction problem and developing a novel deep-learning-based readmission risk prediction framework. From a health IT perspective, this research delivers implementable methods to assess patients’ readmission risk and take early interventions to avoid potential negative consequences.","computational design science, Hospital readmission, predictive analytics, deep learning"
Conference Paper,"Sukor AS,Zakaria A,Rahim NA,Kamarudin LM,Nishizaki H",Abnormality Detection Approach Using Deep Learning Models in Smart Home Environments,Association for Computing Machinery,2019,https://doi.org/10.1145/3330180.3330185;http://dx.doi.org/10.1145/3330180.3330185,"The rising number of elderly populations has become a common concern in many countries. As one of the solutions, smart homes have been developed to help them live independently in their own homes. However, the accurate interpretation in monitoring human situations is still limited. This paper presents an abnormality detection approach that can monitor smart home residents' behavior and identify any abnormalities regarding their daily routines. In particular, this study investigates the use of two deep learning models that are commonly used in the pattern recognition communities, which are known as Multi-Layer Perceptron (MLP) and Recurrent Neural Network (RNN). The learned models are used to classify between normal and abnormal situations and their performance are then compared using a publicly available smart home dataset. Experimental results show that MLP has significant performance and outperforms RNN in terms of accuracy.","deep learning, abnormality detection, Smart homes, pattern recognition, neural network"
Conference Paper,"Rani G,Sinha A,Anup M,Dhaka VS","Deep Learning-Based Tool for Automatic Feature Marking, Cropping, Visualization, and Classification of Chest Radiographs",Association for Computing Machinery,2022,https://doi.org/10.1145/3484824.3484922;http://dx.doi.org/10.1145/3484824.3484922,"The prime objective of this research is to develop an automatic tool 'Lung-Infection Visualizer' for marking the Region of Infection and cropping of the marked region in chest radiographs. The tool is also integrated with the feature extractor, feature visualization algorithm, and deep learning-based classifier. Thus, it facilitates the radiology experts where they can easily mark the infected region and visualize the region of infection. In this manuscript, the authors employ the template-based and Brute Force approach of feature mapping. Further, they applied the ResNet, Faster Recurrent Neural Network, XceptionNet, and VGG-16 deep learning-based classifiers for classifying the chest radiographs into bacterial pneumonia, viral pneumonia, COVID-19, and Normal classes. The authors also fine-tune the model parameters and hyperparameters for optimizing the performance of the deep learning-based models. The comparison in the performance proves that the VGG-16 model reports the highest accuracy of 90.07% and outperforms the other models on the dataset of 5,499 chest radiographs used for this research. The cropping tool is registered as Intellectual Property Rights in the name of authors with the registration number SW-14092/2021. And the title 'AutoCrop Tool'.","Chest Radiograph, Feature, Visualization, Classification, Deep Learning"
Conference Paper,"Davradou A,Protopapadakis E,Kaselimi M,Doulamis A,Doulamis N",Diabetic Foot Ulcers Monitoring by Employing Super Resolution and Noise Reduction Deep Learning Techniques,Association for Computing Machinery,2022,https://doi.org/10.1145/3529190.3529214;http://dx.doi.org/10.1145/3529190.3529214,"Diabetic foot ulcers (DFUs) constitute a serious complication for people with diabetes. The care of DFU patients can be substantially improved through self-management, in order to achieve early-diagnosis, ulcer prevention, and complications management in existing ulcers. In this paper, we investigate two categories of image-to-image translation techniques (ItITT), which will support decision making and monitoring of diabetic foot ulcers: noise reduction and super-resolution. In the former case, we investigated the capabilities on noise removal, for convolutional neural network stacked-autoencoders (CNN-SAE). CNN-SAE was tested on RGB images, induced with Gaussian noise. The latter scenario involves the deployment of four deep learning super-resolution models. The performance of all models, for both scenarios, was evaluated in terms of execution time and perceived quality. Results indicate that applied techniques consist a viable and easy to implement alternative that should be used by any system designed for DFU monitoring.","super-resolution, diabetic foot ulcer, neural networks, noise removal"
Journal Article,"Gupta M,Phan TL,Bunnell HT,Beheshti R",Obesity Prediction with EHR Data: A Deep Learning Approach with Interpretable Elements,Association for Computing Machinery,2022,https://doi.org/10.1145/3506719;http://dx.doi.org/10.1145/3506719,"Childhood obesity is a major public health challenge. Early prediction and identification of the children at an elevated risk of developing childhood obesity may help in engaging earlier and more effective interventions to prevent and manage obesity. Most existing predictive tools for childhood obesity primarily rely on traditional regression-type methods using only a few hand-picked features and without exploiting longitudinal patterns of children’s data. Deep learning methods allow the use of high-dimensional longitudinal datasets. In this article, we present a deep learning model designed for predicting future obesity patterns from generally available items on children’s medical history. To do this, we use a large unaugmented electronic health records dataset from a large pediatric health system in the United States. We adopt a general LSTM network architecture and train our proposed model using both static and dynamic EHR data. To add interpretability, we have additionally included an attention layer to calculate the attention scores for the timestamps and rank features of each timestamp. Our model is used to predict obesity for ages between 3 and 20 years using the data from 1 to 3 years in advance. We compare the performance of our LSTM model with a series of existing studies in the literature and show it outperforms their performance in most age ranges.","Childhood obesity, transfer learning, deep learning, temporal data, long short-term memory, electronic health records"
Journal Article,"Mena J,Pujol O,Vitrià J",A Survey on Uncertainty Estimation in Deep Learning Classification Systems from a Bayesian Perspective,Association for Computing Machinery,2021,https://doi.org/10.1145/3477140;http://dx.doi.org/10.1145/3477140,"Decision-making based on machine learning systems, especially when this decision-making can affect human lives, is a subject of maximum interest in the Machine Learning community. It is, therefore, necessary to equip these systems with a means of estimating uncertainty in the predictions they emit in order to help practitioners make more informed decisions. In the present work, we introduce the topic of uncertainty estimation, and we analyze the peculiarities of such estimation when applied to classification systems. We analyze different methods that have been designed to provide classification systems based on deep learning with mechanisms for measuring the uncertainty of their predictions. We will take a look at how this uncertainty can be modeled and measured using different approaches, as well as practical considerations of different applications of uncertainty. Moreover, we review some of the properties that should be borne in mind when developing such metrics. All in all, the present survey aims at providing a pragmatic overview of the estimation of uncertainty in classification systems that can be very useful for both academic research and deep learning practitioners.","Classification, uncertainty, machine learning, deep learning"
Conference Paper,"Devnath L,Luo S,Summons P,Wang D",Performance Comparison of Deep Learning Models for Black Lung Detection on Chest X-Ray Radiographs,Association for Computing Machinery,2020,https://doi.org/10.1145/3378936.3378968;http://dx.doi.org/10.1145/3378936.3378968,"Black Lung (BL) is an incurable respiratory disease caused by long term inhalation of respirable coal dust. Confidentiality restrictions and disease incidence limit the availability of BL datasets, which presents significant challenges in the training of deep learning (DL) models. This paper presents the implementations and detailed performance comparison of seven DL models for BL detection with small datasets. The models include VGG16, VGG19, InceptionV3, Xception, ResNet50, DenseNet121 and CheXNet. A small BL dataset of real and synthetic images was used to train the seven deep learning models. Segmented lung X-ray images, with and without BL, were used as training images to establish a benchmark. To increase the number of images required for training a deep learning system the training data set was augmented, using a Cycle-Consistent Adversarial Networks (CycleGAN) and the Keras Image Data Generator, to generate additional augmented and synthetic radiographs. The effects of different dropout nodes as a blocking factor was also investigated on all seven models. The best sensitivity (Normal Prediction Rate), specificity (BL prediction Rate), error rate (ERR or incorrect prediction rate), accuracy (1-ERR), as well as total execution time for binary classification for each model, with and without augmentation, was compared for optimal BL detection. On average, the CheXNet model gave the best performance of all seven DL models.","Deep Learning, CycleGAN, Coal Workers' Pneumoconiosis, Computer-Aided Diagnosis, Black Lung, Keras, Pneumoconiosis"
Conference Paper,"Lyu B,Haque A",Deep Learning Based Tumor Type Classification Using Gene Expression Data,Association for Computing Machinery,2018,https://doi.org/10.1145/3233547.3233588;http://dx.doi.org/10.1145/3233547.3233588,"The differential analysis is the most significant part of RNA-Seq analysis. Conventional methods of the differential analysis usually match the tumor samples to the normal samples, which are both from the same tumor type. Such method would fail in differentiating tumor types because it lacks the knowledge from other tumor types. The Pan-Cancer Atlas provides us with abundant information on 33 prevalent tumor types which could be used as prior knowledge to generate tumor-specific biomarkers. In this paper, we embedded the high dimensional RNA-Seq data into 2-D images and used a convolutional neural network to make classification of the 33 tumor types. The final accuracy we got was 95.59%. Furthermore, based on the idea of Guided Grad Cam, as to each class, we generated significance heat-map for all the genes. By doing functional analysis on the genes with high intensities in the heat-maps, we validated that these top genes are related to tumor-specific pathways, and some of them have already been used as biomarkers, which proved the effectiveness of our method. As far as we know, we are the first to apply a convolutional neural network on Pan-Cancer Atlas for the classification of tumor types, and we are also the first to use gene's contribution in classification to the importance of genes to identify candidate biomarkers. Our experiment results show that our method has a good performance and could also apply to other genomics data.","pan-cancer atlas, deep learning, convolutional neural network, tumor type classification"
Conference Paper,"Yan C,Yao J,Li R,Xu Z,Huang J",Weakly Supervised Deep Learning for Thoracic Disease Classification and Localization on Chest X-Rays,Association for Computing Machinery,2018,https://doi.org/10.1145/3233547.3233573;http://dx.doi.org/10.1145/3233547.3233573,"Chest X-rays is one of the most commonly available and affordable radiological examinations in clinical practice. While detecting thoracic diseases on chest X-rays is still a challenging task for machine intelligence, due to 1) the highly varied appearance of lesion areas on X-rays from patients of different thoracic disease and 2) the shortage of accurate pixel-level annotations by radiologists for model training. Existing machine learning methods are unable to deal with the challenge that thoracic diseases usually happen in localized disease-specific areas. In this article, we propose a weakly supervised deep learning framework equipped with squeeze-and-excitation blocks, multi-map transfer and max-min pooling for classifying common thoracic diseases as well as localizing suspicious lesion regions on chest X-rays. The comprehensive experiments and discussions are performed on the ChestX-ray14 dataset. Both numerical and visual results have demonstrated the effectiveness of proposed model and its better performance against the state-of-the-art pipelines.","chest x-ray, weakly-supervised learning, computer-aided diagnosis"
Conference Paper,"Ukaegbu UF,Tartibu LK,Okwu MO,Olayode IO",Deep Learning Application in Diverse Fields with Plant Weed Detection as a Case Study,Association for Computing Machinery,2021,https://doi.org/10.1145/3487923.3487926;http://dx.doi.org/10.1145/3487923.3487926,"Machine learning applications have gained popularity over the years as more advanced algorithms like the deep learning (DL) algorithm are being employed in signal identification, classification and detection of cracks or faults in structures. The DL algorithm has broader applications compared to other machine learning systems and it is a creative algorithm capable of processing data, creating pattern, interpreting information due to its high level of accuracy in pattern recognition under stochastic conditions. This research gives an exposition of DL in diverse areas of operations with a focus on plant weed detection which is inspired by the need to treat a specific class of weed with a particular herbicide. A Convolutional Neural Network (CNN) model was trained through transfer learning on a pre-trained ResNet50 model and the performance was evaluated using a random forest (RF) classifier, the trained model was deployed on a raspberry pi for prediction of the test data. Training accuracies of 99% and 93% were obtained for the CNN and RF classifier respectively. Some recommendations have been proffered to improve inference time such as the use of better embedded systems such as the Nvidia Jetson TX2, synchronizing DL hardware accelerators with appropriate optimization techniques. A prospect of this work would be to incorporate an embedded system, deployed with DL algorithms, on an unmanned aerial vehicle or ground vehicle. Overall, it is revealed from this study that DL is highly efficient in every sector and can improve the accuracy on automatic detection of systems in especially in this era of Industry 4.0.","Agriculture, fourth industrial revolution, Convolutional neural network, Deep learning algorithm, Random forest"
Conference Paper,"Pan Q,Sun K,Le J,Chen D,Li H",An Intelligent Decision-Making Method for Graded Diagnosis and Treatment of Thyroid Disease Based on Deep Learning,Association for Computing Machinery,2018,https://doi.org/10.1145/3231884.3231893;http://dx.doi.org/10.1145/3231884.3231893,"Hierarchical medical system is the concerned medical system today, which is of great significance for reducing the pressure on the patient and tertiary institutions. A large number of ordinary patients go to the experts in tertiary institutions because they don't trust the basic-level hospital and worry about misdiagnose, which results in shortage of medical resources in tertiary institutions and waste of medical resources in the basic medical institution. In this paper, we design a thyroid disease evaluation model based on deep learning for blood tests and thyroid ultrasound report by analyzing the clinical data of thyroid patients in a top three comprehensive hospital. The model can assess the severity of the thyroid disease and give referral advice which can help doctor in the basic medical institution to make decision, so as to improve the accuracy of the doctor's judgment and guide patients to basic medical institution. This is a new way to promote the implementation of hierarchical medical system.","machine learning, character vector, thyroid disease, hierarchical diagnosis, deep learning"
Conference Paper,"Ahmed I,Qasim F,Ali MN",Analysis & Automated Prediction of Myocardial Infarction Disease Using Optimized Deep Learning Architecture,Association for Computing Machinery,2019,https://doi.org/10.1145/3348445.3348459;http://dx.doi.org/10.1145/3348445.3348459,"Myocardial infarction (MI) leads to heart attack which is a potentially fatal threat. Therefore, early, automated, efficient and accurate determination of this fatal disease can save thousands of lives throughout the world. Efficient incorporation of data mining and machine learning techniques can contribute a lot to reduce negative impact of this disease. Realizing the worth of this situation, this paper proposes an automated approach by incorporating machine learning and data mining techniques for classification as well as illustration of the relationships between the key parameters of this disease. For classification purpose, Convolutional Neural Network architecture has been optimized using Ant Colony Optimization (ACO) by replacing back propagation. Moreover, for conducting comparison between CNN optimized with ACO and other well know existing approaches; Support vector machine, multilayer perceptron, random forest and additive regression have also been implemented. Additionally, for rule generation, filtered association and J48 approaches have been implemented and applied on the dataset. Overall analysis and experiment depicts accurate classification ability of our approach (CNN-ACO) than other approaches predicting accuracy of 95.78%.","Ant Colony Optimization, Deep Learning, Multilayer Perceptron, J48, Myocardial Infarction (MI)"
Conference Paper,"Rahaman MA,Ali MM,Ahmed K,Bui FM,Mahmud SM",Performance Analysis between YOLOv5s and YOLOv5m Model to Detect and Count Blood Cells: Deep Learning Approach,Association for Computing Machinery,2022,https://doi.org/10.1145/3542954.3543000;http://dx.doi.org/10.1145/3542954.3543000,"Blood cell identification and counting are essential nowadays for healthcare professionals and therapists treating a variety of diseases. Platelet detection and counting are commonly performed for various disorders such as COVID-19 and others. However, it is the most costly and time-consuming. Furthermore, it is not available everywhere. From that standpoint, it is necessary to develop an effective technological model for detecting and counting three fundamental kinds of blood cells: Platelets, Red Blood Cells (RBCs), and White Blood Cells (WBCs). So, a deep learning-based model is proposed in this study comparing two versions of YOLOv5 model such as YOLOv5s and YOLOv5m. It is found that the YOLOv5m model outperforms with 0.799 precision, where YOLOv5s produces 0.797 precision. The study suggests that the YOLOv5m model is highly capable of detecting and counting the blood cells individually. Doctors, physicians, and other clinicians will be capable to identify and quantify blood cells from real-time photos. It will save money and time by identifying and counting blood cells using real-time blood photos.","Deep Learning, WBC and RBC, Platelets, YOLOV5 Model"
Conference Paper,"Haudenschild C,Vaickus L,Levy J",Configuring a Federated Network of Real-World Patient Health Data for Multimodal Deep Learning Prediction of Health Outcomes,Association for Computing Machinery,2022,https://doi.org/10.1145/3477314.3507007;http://dx.doi.org/10.1145/3477314.3507007,"Vast quantities of electronic patient medical data are currently being collated and processed in large federated data repositories. For instance, TriNetX, Inc., a global health research network, has access to more than 300 million patients, sourced from healthcare organizations, biopharmaceutical companies, and contract research organizations. As such, pipelines that are able to algorithmically extract huge quantities of patient data from multiple modalities present opportunities to leverage machine learning and deep learning approaches with the possibility of generating actionable insight. In this work, we present a modular, semi-automated end-to-end machine and deep learning pipeline designed to interface with a federated network of structured patient data. This proof-of-concept pipeline is disease-agnostic, scalable, and requires little domain expertise and manual feature engineering in order to quickly produce results for the case of a user-defined binary outcome event. We demonstrate the pipeline's efficacy with three different disease workflows, with high discriminatory power achieved in all cases.","comorbidity, federated data network, electronic health records, deep learning, lab measurements"
Conference Paper,"Wang Y,Kang G,Liu L,Huang Q",Automatic Assistance Method for Disease Diagnosis Based on a Deep Learning Fusion Model and Chinese Electronic Medical Record,Association for Computing Machinery,2021,https://doi.org/10.1145/3448340.3448341;http://dx.doi.org/10.1145/3448340.3448341,"Extracting disease characteristics from large-scale Electronic Medical Records and achieving disease-assisted diagnoses have significant research value. Due to the complex multi-feature items and unbalanced data distribution of Electronic Medical Records, feature representation and disease diagnosis are difficult. Our study proposes a deep feature fusion (DFF) model based on the feature partition and deep feature extraction. First, the feature partition is performed, and different feature representation algorithms are adopted for different types of data. The discrete feature items are directly mapped into real-valued vectors, and the continuous feature items are represented by GCNN-based VAE. Then, the two parts are fused. Finally, the assisted diagnosis results are output through a supervised learning classification method based on the XGBoost framework. The dataset of our study is from the 18,590 real and effective clinical Electronic Medical Record of Huangshi Central Hospital. The experimental results show that the method can perform clinical Assisted diagnosis accurately and efficiently, which are superior to some other state-of-the-art approaches, can better meet the needs of practical clinical diagnosis applications.","Chinese electronic medical record, Deep learning, Automatic assistance, Features partition"
Conference Paper,"Mubashir M,Ahmed MR,Ahmad M,Siddiqui SA,Ahmad M",A Novel Deep Learning Approach for Lung Cancer Recognition Based on 1-D Deep Convolutional Neural Network,Association for Computing Machinery,2019,https://doi.org/10.1145/3325730.3325755;http://dx.doi.org/10.1145/3325730.3325755,"Pulse diagnosis has been a requisite facet in traditional Chinese medicine as well as in western medicine, yet the prognosis of lung cancer hinged on wrist pulse analysis entails the quotidian approaches. In spite of diagnosing the lung cancer, in traditional methods, the identification stratagem is divaricated into assorted steps: analysis of signals procured, synthetic extraction and selection of features, and subsequently the classification. However, the vague and mundane feature selection and signal analysis steers to the inadequate classification accuracy due to intrinsic deficiencies. In this study, we have proposed a novel deep convolutional neural network (DCNN) based approach to discern the lung cancer against the acquired wrist pulse signals. In order to ensnare the features, vanquishing the overfitting, a 1-dimensional 15-layers DCNN model is devised hinged on 1-D convolutional, batch normalization, and pooling layers. Considering the instinctive feature extraction, from the experimental data comprised of 45,969 samples of 16 lung cancer and 20 healthy individuals, assorted units are heaped in the lodged DCNN. The experimental comparison with the state-of-art deep neural networks (DNNs) and conventional methods evinced that our lodged approach conquer the deficiencies of conventional signal processing and manual feature selection approaches. Finally, the results, with the validation precision of 97.67%, outperform the recent existing approach for lung cancer recognition.","feature extraction, signal processing, deep convolutional neural networks, deep neural networks, Lung cancer recognition, 1-D Deep CNN"
Conference Paper,"Xue Q,Chuah MC",ACM Notice of Article Removal: Deep Learning Based Medical Diagnosis System Using Multiple Data Sources - Originally Published in the ACM Digital Library on 29-Aug-2018,Association for Computing Machinery,2018,https://doi.org/10.1145/3233547.3233730;http://dx.doi.org/10.1145/3233547.3233730,"Recently, many researchers have conducted data mining over medical data to uncover hidden patterns and use them to learn prediction models for clinical decision making and personalized medicine. While such healthcare learning models can achieve encouraging results, they seldom incorporate existing expert knowledge into their frameworks and hence prediction accuracy for individual patients can still be improved. However, expert knowledge spans across various websites and multiple databases with heterogeneous representations and hence is difficult to harness for improving learning models. In addition, patients' queries at medical consult websites are often ambiguous in their specified terms and hence the returned responses may not contain the information they seek. To tackle these problems, we first design a knowledge extraction framework that can generate an aggregated dataset to characterize diseases by integrating heterogeneous medical data sources. Then, based on the integrated dataset, we propose an end-to-end deep learning based medical diagnosis system (DL-MDS) to provide disease diagnosis for authorized users. Evaluations on real-world data demonstrate that our proposed system achieves good performance on diseases diagnosis with a diverse set of patients' queries.","deep learning, medical diagnosis, heterogeneous representation, query processing, knowledge extraction"
Conference Paper,"Li Y,Hua J,Wang H,Chen C,Liu Y",DeepPayload: Black-Box Backdoor Attack on Deep Learning Models through Neural Payload Injection,IEEE Press,2021,https://doi.org/10.1109/ICSE43902.2021.00035;http://dx.doi.org/10.1109/ICSE43902.2021.00035,"Deep learning models are increasingly used in mobile applications as critical components. Unlike the program bytecode whose vulnerabilities and threats have been widely-discussed, whether and how the deep learning models deployed in the applications can be compromised are not well-understood since neural networks are usually viewed as a black box. In this paper, we introduce a highly practical backdoor attack achieved with a set of reverse-engineering techniques over compiled deep learning models. The core of the attack is a neural conditional branch constructed with a trigger detector and several operators and injected into the victim model as a malicious payload. The attack is effective as the conditional logic can be flexibly customized by the attacker, and scalable as it does not require any prior knowledge from the original model. We evaluated the attack effectiveness using 5 state-of-the-art deep learning models and real-world samples collected from 30 users. The results demonstrated that the injected backdoor can be triggered with a success rate of 93.5%, while only brought less than 2ms latency overhead and no more than 1.4% accuracy decrease. We further conducted an empirical study on real-world mobile deep learning apps collected from Google Play. We found 54 apps that were vulnerable to our attack, including popular and security-critical ones. The results call for the awareness of deep learning application developers and auditors to enhance the protection of deployed models.","reverse engineering, Deep learning, mobile application, malicious payload, backdoor attack"
Conference Paper,"Zhang F,Miao J,Wang W,Xiao Z,Xu X",Automatic Discrimination of Fundus DR Based on Improved Residual Dense Block Network,Association for Computing Machinery,2021,https://doi.org/10.1145/3468945.3468954;http://dx.doi.org/10.1145/3468945.3468954,"Diabetic retinopathy is the most serious complication of diabetes. In hospital treatment or telemedicine, experts analyze and treat patients with Diabetic Retinopathy (DR) based on the retinal images captured by the fundus camera. However, large number of non-pathological fundus images occupy too much time for the ophthalmologist to diagnose, and delay the timely treatment of patients with fundus DR. Therefore, it is a very urgent task to automatically and objectively screen whether the fundus has DR. Based on deep learning, we proposes an improved residual-dense module convolutional neural network structure (Modified Residual Dense Block Convolution Neural Network, MRDB-CNN). DR fundus images and non-DR fundus images are used for model training and the overall accuracy of the network structure is assessed by test set. Experiments have proved that the module can extract the detailed features of the fundus DR. The MRDB-CNN network structure can obtain a better generalization ability and a higher-precision network classification model while avoiding the complex image preprocessing. The accuracy of DR discrimination reached 94.90%, which reaches the needs of initial screening of fundus DR in hospital treatment and telemedicine.","Fundus DR discrimination, Retinal images, Deep learning, MRDB-CNN"
Conference Paper,"Berend D,Xie X,Ma L,Zhou L,Liu Y,Xu C,Zhao J",Cats Are Not Fish: Deep Learning Testing Calls for out-of-Distribution Awareness,Association for Computing Machinery,2021,https://doi.org/10.1145/3324884.3416609;http://dx.doi.org/10.1145/3324884.3416609,"As Deep Learning (DL) is continuously adopted in many industrial applications, its quality and reliability start to raise concerns. Similar to the traditional software development process, testing the DL software to uncover its defects at an early stage is an effective way to reduce risks after deployment. According to the fundamental assumption of deep learning, the DL software does not provide statistical guarantee and has limited capability in handling data that falls outside of its learned distribution, i.e., out-of-distribution (OOD) data. Although recent progress has been made in designing novel testing techniques for DL software, which can detect thousands of errors, the current state-of-the-art DL testing techniques usually do not take the distribution of generated test data into consideration. It is therefore hard to judge whether the ""identified errors"" are indeed meaningful errors to the DL application (i.e., due to quality issues of the model) or outliers that cannot be handled by the current model (i.e., due to the lack of training data). Tofill this gap, we take the first step and conduct a large scale empirical study, with a total of 451 experiment configurations, 42 deep neural networks (DNNs) and 1.2 million test data instances, to investigate and characterize the impact of OOD-awareness on DL testing. We further analyze the consequences when DL systems go into production by evaluating the effectiveness of adversarial retraining with distribution-aware errors. The results confirm that introducing data distribution awareness in both testing and enhancement phases outperforms distribution unaware retraining by up to 21.5%.","out of distribution, deep learning testing, quality assurance"
Conference Paper,"Nugroho HA,Oktoeberza WK,Budiani RL,Adji TB",Analysis of Texture-Based Features for Image Classification of Retinal Exudates,Association for Computing Machinery,2017,https://doi.org/10.1145/3132300.3132333;http://dx.doi.org/10.1145/3132300.3132333,"Diabetic retinopathy is one of the primary causes of blindness as complication of long term diabetes. The permanent vision loss can be avoided by conducting early detection of retinopathy symptoms such as retinal exudates. This paper proposes a scheme to classify fundus images whether containing exudates based on analysis of extracted texture features. Removal of optic disc and detection of exudate candidate area were firstly conducted. Afterwards, some texture features consisting of five features of grey level co-occurrence matrices (GLCM), eleven features of grey level of run-length matrices (GLRLM) and six histogram-based features were extracted from candidate exudates detected. These extracted features subsequently underwent classification process by using multi-layer perceptron (MLP) classifier. The performance of proposed scheme was evaluated on 80 fundus images taken from DIARETDB1 comprising of 38 images with exudates and 42 images without exudates. The best evaluation result of classification was achieved by using five GLCM features with 95% of accuracy, 97.37% of sensitivity and 92.86% of specificity. These results indicate that the proposed scheme successfully detects exudates and also classifies fundus images either containing exudates or no exudates. In addition, the implementation of the proposed scheme is expected to assist the ophthalmologists in monitoring and diagnosing diabetic retinopathy especially on the presence of retinal exudates.","histogram features, grey level of run-length matrices (GLRLM), Diabetic retinopathy, retinal exudates, texture analysis, grey level co-occurrence matrices (GLCM), fundus images"
Journal Article,"Chuan CH,Morgan S",Creating and Evaluating Chatbots as Eligibility Assistants for Clinical Trials: An Active Deep Learning Approach towards User-Centered Classification,Association for Computing Machinery,2021,https://doi.org/10.1145/3403575;http://dx.doi.org/10.1145/3403575,"Clinical trials are important tools to improve knowledge about the effectiveness of new treatments for all diseases, including cancers. However, studies show that fewer than 5% of cancer patients are enrolled in any type of research study or clinical trial. Although there is a wide variety of reasons for the low participation rate, we address this issue by designing a chatbot to help users determine their eligibility via interactive, two-way communication. The chatbot is supported by a user-centered classifier that uses an active deep learning approach to separate complex eligibility criteria into questions that can be easily answered by users and information that requires verification by their doctors. We collected all the available clinical trial eligibility criteria from the National Cancer Institute's website to evaluate the chatbot and the classifier. Experimental results show that the active deep learning classifier outperforms the baseline k-nearest neighbor method. In addition, an in-person experiment was conducted to evaluate the effectiveness of the chatbot. The results indicate that the participants who used the chatbot achieved better understanding about eligibility than those who used only the website. Furthermore, interfaces with chatbots were rated significantly better in terms of perceived usability, interactivity, and dialogue.","eligibility criteria, Chatbots, active learning, convolution neural networks, clinical trials"
Conference Paper,"Kumar M,Manikandan,Nath MK",Detection of Microaneurysms and Exudates from Color Fundus Images by Using SBGFRLS Algorithm,Association for Computing Machinery,2016,https://doi.org/10.1145/2980258.2980337;http://dx.doi.org/10.1145/2980258.2980337,"Different pathological features such as microaneurysms, hemorrhages, cotton wool spots and exudates appear over the retina due to the progression of diabetic retinopathy and causes vision loss. Microaneurysms are the first clinical symptom of diabetic retinopathy, which causes fluid leakage at a latter stage. It is very tiny and has similar contrast to that of the blood vessel. Exudates consist of lipids and protein deposit comes from the damaged blood vessels and leads to diabetic macular edema. Exudates are brighter and having similar contrast to that of the optic disc. Microaneurysms and exudates are the features for estimating the vision degradation. Due to the appearance it is difficult to detect the microaneurysms and exudates from the color fundus images. In this paper, microaneurysms and exudates have been extracted using selective binary and Gaussian filtering regularized level set (SBGFRLS) algorithm on the pre-processed fundus image. The SBGFRLS uses the level set function and Gaussian smoothing kernel. Signed pressure force (SPF) is used for stopping the contours at weak or blurred edges. This can able to detect the boundaries automatically and help in global segmentation. The SBGFRLS algorithm is applied to the pre-processed image for detection of microaneurysms and exudates. The proposed method has been tested on standard diabetic retinopathy i.e., DIARETDB1 database. The average accuracy and specificity for the detection exudates are found to be 93.41% and 97.42%, respectively. The box plot for accuracy and specificity of the detection of exudates are plotted to show the distribution of performance values for different images in the database. The proposed method for detection of exudates provides better result as compared to the method discussed in the literature. Microaneurysms are extracted by using h extended minima algorithm to the blood vessel, optic disc and exudates inpainted image. The effect of blood vessel, optic disc and the exudates are suppressed in this inpainted image. The accuracy for detection of microaneurysms is found to be 90%. Along with the microaneurysms some spurious signals are detected which can be reduced by some post processing step.","selective binary and Gaussian filtering regularized level set (SBGFRLS), specificity, exudates, diabetic retinopathy (DR), signed pressure force (SPF), Microaneurysms"
Conference Paper,"Lin JW,Weng Q,Yu L",Fast Fundus Optic Disc Localization Based on Main Blood Vessel Extraction,Association for Computing Machinery,2018,https://doi.org/10.1145/3195106.3195162;http://dx.doi.org/10.1145/3195106.3195162,"Optic disc (OD) is one of the most important structures in retina. The automatic detection of OD is essential to make Diabetic retinopathy examination more effective. In this paper, a fast optic disc localization algorithm is described. Our approach begins with pre-processing, and then the main vessels in fundus images are extracted based on morphology methods. In the next step, parabolic fitting algorithm by the least square method is applied to express the main vessels. Finally, we judge the fitting result and defined the apex as the OD center. The proposed method was evaluated in 3 public datasets. An average accuracy of 99.05% at the average time of 1.08 second was achieved.","optic disc (OD) localization, fundus image, parabolic fitting, medical image analysis, Diabetic retinopathy"
Conference Paper,"Fang X,Shen Y,Zheng B,Zhu S,Wu M",Optic Disc Segmentation Based on Phase-Fusion PSPNet,Association for Computing Machinery,2021,https://doi.org/10.1145/3500931.3500959;http://dx.doi.org/10.1145/3500931.3500959,"In the analysis of fundus images, optic disc segmentation is vital to judge eye diseases such as diabetic retinopathy and glaucoma. Improving the accuracy of optic disc segmentation is of great significance to the diagnosis of the above diseases. Based on the PSPNet model, the Phase-Fusion PSPNet network structure is proposed. The network is connected to the phase upsampling module after the pyramid pooling module, which reduces information loss and makes the network suitable for segmentation tasks with fuzzy edges. The principle of phase upsampling module is to upsample the larger size span step by step and combine it with the corresponding size feature map. iChallenge-PM, iChallenge-AMD, and iChallenge-GON as the training and validation datasets in the paper. The IoU and PA of Phase-fusion PSPNet are 89.93% and 94.94%. Compared with PSPNet, the IoU and PA increased by 1.22% and 1.62% respectively. Experiments show that adding the phase upsampling module makes the model have a better segmentation performance.","Phase upsampling, PSPNet, Intelligent medical, Optic disc segmentation, Deep learning"
Conference Paper,"Rodtook A,Chucherd S","Automated Optic Disc Localization Algorithm by Combining A Blob of Corner Patterns, Brightness and Circular Structures Models",Association for Computing Machinery,2019,https://doi.org/10.1145/3355402.3355420;http://dx.doi.org/10.1145/3355402.3355420,"Automatic localization of optic disc (OD) is an important step of diabetic retinopathy (DR) detection. This paper presents a methodology to locate the optic disc within the field of view (FOV) of retina image. The information taken from corner patterns of branching and cross-over points of blood vessels, the brightness and circular structure are combined to identify the location of OD. Moreover, a step of the FOV background estimation is designed to increase robustness of the proposed method due to the incomplete circular shape of OD caused by vascular tortuosity effect. The method was evaluated on the three public datasets as DIARETDB0, DIARETDB1, and MESSIDOR. The accuracy rate was 99.23%, 100%, and 99.25%, respectively. It obtained valid locations of OD in 615 out of the 619 images of the three datasets.","Vessel approximation, circular-like filtering, optic disc localization, blob detection, skeleton"
Conference Paper,"Madurapperumage A,Wang WY,Michael M",A Systematic Review on Extracting Predictors for Forecasting Complications of Diabetes Mellitus,Association for Computing Machinery,2021,https://doi.org/10.1145/3472813.3473211;http://dx.doi.org/10.1145/3472813.3473211,"The high global prevalence, irreversible health burden, and expenditures of diabetes mellitus lead to a proliferative research area of prognosis and diagnosis of diabetes and its complications through machine learning techniques. Although the risk scoring and prediction models have been proposed for decades, challenges still persist. Feature selection is one challenging problem that is still remains when building accurate models. Since each risk factor's contribution in predicting complications of diabetes vary with the recognition of novel risk factors, it is a requirement to make an up-to-date standard feature subset that can predict the risk of complications of diabetes mellitus. This research in progress paper proposes a systematic review study that aims to extract frequent feature subsets for predicting complications of diabetes. Diabetic retinopathy, neuropathy, nephropathy, and cardiovascular diseases have been considered as the most common complications of diabetes. PRISMA guidelines will be used to conduct the systematic review. Further, the proposed study will be strengthened by selecting credible journal repositories, optimising the search query, utilising inclusion and exclusion criteria, and determining top-ranked journals. The paper presents data analysis design with feature subsets to predict the aforementioned four complications of diabetes, which is directly beneficial for clinicians, researchers, and model developers to assist their clinical decisions, research purposes, and feature selection phase in model designing respectively.","Additional Keywords and Phrases Diabetes mellitus, Risk factors, Complications of diabetes, Systematic review, PRISMA"
Conference Paper,"Hussain MA,Rehman Uur,Islam SO,Sheikh MF,Javaid A",Detection and Classification of Retinal Red Lesions via Regional Spatial Transformations and Neural Network,Association for Computing Machinery,2019,https://doi.org/10.1145/3330482.3330486;http://dx.doi.org/10.1145/3330482.3330486,"The worldwide loss in human vision is primarily associated with Diabetic Retinopathy (DR). It occurs due to accelerated levels of blood sugar thereby causing perforation, bulging and leakage of retinal blood vessels (BVs). DR commences with the emergence of small blood spots on the retinal surface known as Microaneurysms (MAs) that are subsequently transformed into heavy blood deposits called Hemorrhages (HGs). This paper proposes an optimized and computationally inexpensive digital image processing (DIP) technique for detection and classification of 'Retinal Red Lesions' (RRLs) i.e. MAs and HGs using green channel of the digital fundus images. The basic essence of the proposed technique revolves around regional spatial transformations detection performed through region based spatial filtering, matching features and neural networks classification. The proposed technique comprises of five main stages i.e. Pre-processing, Regional Spatial Transformations, Optimization, Features extraction and Classification. Speed Up Robust Features (SURF) algorithm has been used for features selection & extraction while Feed-forward Back-propagation Artificial Neural Network (FFBP ANN) has been used for classification. The proposed technique has been successfully applied on commercially available digital fundus image data-set and has yielded 98.4% 'Sensitivity' (SE), 94% 'Specificity' (SP) and 98% 'Accuracy' (AC). The SE, SP and AC have also been compared with other RRLs detection methods and has shown highly promising and encouraging results.","Diabetic Retinopathy, Linear Regression, Artificial Neural Networks, Back-propagation, Retinal Red Lesions, Regional Spatial Transformations"
Conference Paper,"Mihalov V,Andreev D,Lazarova M",Software Platform for Retinal Disease Diagnosis Through Deep Convolutional Neural Networks,Association for Computing Machinery,2020,https://doi.org/10.1145/3407982.3408011;http://dx.doi.org/10.1145/3407982.3408011,"The paper presents a deep learning (DL) based software platform for retinal diseases diagnosis. The multi-class disease classification is based on convolutional neural network trained with OCT B-scan images. Data augmentation and transfer training is used in order to overcome some limitations and requirements of DL usage in ophthalmology. The DL classification is integrated in a software platform that is easily accessible, usable, reliable and secure. The software platform is aimed at providing a tool for decision support of retinal diseases diagnosis and meets all the requirements in patient screening and monitoring as report generation, diagnostics, statistics collection.","transfer training, deep learning, retinal diseases diagnosis, convolutional neural network, data augmentation"
Conference Paper,"Singh A,Srivastava S,Yadav A,Dutta MK,Travieso CM",Automatic Framework for Extraction of Red Lesion Using Gabor Filter from Fundus Image,Association for Computing Machinery,2019,https://doi.org/10.1145/3309772.3309785;http://dx.doi.org/10.1145/3309772.3309785,"The paper proposes an automated computer vision method for detection of red lesions present in the fundus images. In case of Diabetic Retinopathy, red lesions constitute of both microaneurysms and haemorrhages. In the proposed work, the possible candidate pixels similar to red lesions with respect to intensity levels are identified and subjected to a logical subtraction operation that leads to desirable result in segmenting out the lesions only. Strategic use of Gabor filter helps in identification of blood vessels and geometrical features-based thresholding is applied to extract red lesions efficiently and make the algorithm effective. Developed algorithm is tested on a comprehensive digital fundus image database and the obtained results are encouraging with a high accuracy and has low computation cost and can be deployed for the detection of the red lesions from fundus images.","morphological operations, extraction, image processing, red lesions, fundus image"
Conference Paper,"Kim M,Zuallaert J,De Neve W",Few-Shot Learning Using a Small-Sized Dataset of High-Resolution FUNDUS Images for Glaucoma Diagnosis,Association for Computing Machinery,2017,https://doi.org/10.1145/3132635.3132650;http://dx.doi.org/10.1145/3132635.3132650,"Deep learning has recently attracted a lot of attention, mainly thanks to substantial gains in terms of effectiveness. However, there is still room for significant improvement, especially when dealing with use cases that come with a limited availability of data, as is often the case in the area of medical image analysis. In this paper, we introduce a novel approach for early diagnosis of glaucoma in high-resolution FUNDUS images, only requiring a small number of training samples. In particular, we developed a predictive model based on a matching neural network architecture, integrating a high-resolution deep convolutional network that allows preserving the high-fidelity nature of the medical images. Our experimental results show that our predictive model is able to obtain higher levels of effectiveness than vanilla deep convolutional neural networks.","medical image analysis, glaucoma diagnosis, one-shot learning, deep learning, matching networks"
Conference Paper,"Gong J,Guo L,Jiang J,Wu C,Pei M,Liu W",Automatic Diagnosis of Multiple Lesions in Fundus Images Based on Dual Attention Mechanism,Association for Computing Machinery,2021,https://doi.org/10.1145/3500931.3500975;http://dx.doi.org/10.1145/3500931.3500975,"Glaucomatous optic neuropathy (GON), retinal exudates and retinal hemorrhage are the main basis for the diagnosis of fundus diseases. Traditional methods can diagnose fundus diseases and their severity, but there are few studies on the characteristics of fundus diseases, which cannot give a reasonable explanation for the diagnosis of fundus diseases. Therefore, a convolutional neural network based on dual attention mechanism was proposed to realize automatic diagnosis of multiple fundus lesions with high accuracy. Convolutional neural network uses a residual structure with jumping connections, and channels and spatial attention mechanisms are embedded after each group of convolution to improve the accuracy of fundus lesions diagnosis. The model was tested on the clinical data of Ningbo Eye Hospital Affiliated to Wenzhou Medical University. The diagnostic accuracy of GON, retinal exudates and retinal hemorrhage were 98.17%, 97.49% and 97.15%, respectively. The experimental results showed that: the model showed good feature extraction ability and diagnostic performance in multi-lesion diagnosis of fundus, which provided reference value for subsequent medical artificial intelligence diagnosis research.","Spatial attention mechanism, Multilesion diagnosis, Channeled attention mechanism, Residual network"
Conference Paper,"Rangrej SB,Sivaswamy J",A Biologically Inspired Saliency Model for Color Fundus Images,Association for Computing Machinery,2016,https://doi.org/10.1145/3009977.3010041;http://dx.doi.org/10.1145/3009977.3010041,"Saliency computation is widely studied in computer vision but not in medical imaging. Existing computational saliency models have been developed for general (natural) images and hence may not be suitable for medical images. This is due to the variety of imaging modalities and the requirement of the models to capture not only normal but also deviations from normal anatomy. We present a biologically inspired model for colour fundus images and illustrate it for the case of diabetic retinopathy. The proposed model uses spatially-varying morphological operations to enhance lesions locally and combines an ensemble of results, of such operations, to generate the saliency map. The model is validated against an average Human Gaze map of 15 experts and found to have 10% higher recall (at 100% precision) than four leading saliency models proposed for natural images. The F-score for match with manual lesion markings by 5 experts was 0.4 (as opposed to 0.532 for gaze map) for our model and very poor for existing models. The model's utility is shown via a novel enhancement method which employs saliency to selectively enhance the abnormal regions and this was found to boost their contrast to noise ratio by ∼ 30%.","gaze map, diabetic retinopathy (DR), colour fundus image, spatially-varying morphology, saliency, selective-enhancement"
Conference Paper,Ferreira MF,Extracting Architectural Patterns of Deep Neural Networks for Disease Detection: Student Research Abstract,Association for Computing Machinery,2020,https://doi.org/10.1145/3341105.3374224;http://dx.doi.org/10.1145/3341105.3374224,"The importance of early detection of diseases with high-mortality is crucial to save lives. Deep Learning algorithms are recurrently used by many researchers that aim to model the progression and treatment of these conditions.There is growing evidence that the complexity of a Deep Learning model is correlated to its performance: the deeper the network, the more accurate it is. However, as the topology deepens, training gets more demanding: (1) increased need of data, (2) increased computational costs, and (3) increased time for evaluation, fine-tuning, and subsequent feedback-based activities inherent to Data Science, with direct impact on the exploration towards finding the best model, due to an inherent trial-and-error approach.We hypothesize that there exist (domain-specific) architectural patterns that, if applied during the model exploration phase, allow an overall improvement of the training performance. Should it be true, it would significantly reduce the exploration phase length, contributing to both Medicine and Computer Science fields.","classification, neural networks, disease detection, deep learning, patterns"
Journal Article,"Chai Y,Liu H,Xu J,Samtani S,Jiang Y,Liu H",A Multi-Label Classification with an Adversarial-Based Denoising Autoencoder for Medical Image Annotation,Association for Computing Machinery,2023,https://doi.org/10.1145/3561653;http://dx.doi.org/10.1145/3561653,"Medical image annotation aims to automatically describe the content of medical images. It helps doctors to understand the content of medical images and make better informed decisions like diagnoses. Existing methods mainly follow the approach for natural images and fail to emphasize the object abnormalities, which is the essence of medical images annotation. In light of this, we propose to transform the medical image annotation to a multi-label classification problem, where object abnormalities are focused directly. However, extant multi-label classification studies rely on arduous feature engineering, or do not solve label correlation issues well in medical images. To solve these problems, we propose a novel deep learning model where a frequent pattern mining component and an adversarial-based denoising autoencoder component are introduced. Extensive experiments are conducted on a real retinal image dataset to evaluate the performance of the proposed model. Results indicate that the proposed model significantly outperforms image captioning baselines and multi-label classification baselines.","medical image annotation, denoising autoencoder, Deep learning, adversarial learning, multi-label classification"
Conference Paper,"Yang B,Zhao S,Ye K,Zhang R",Distribution Consistency Penalty in the Quadratic Kappa Loss for Ordinal Regression of Imbalanced Datasets,Association for Computing Machinery,2022,https://doi.org/10.1145/3507548.3507612;http://dx.doi.org/10.1145/3507548.3507612,"Ordinal regression is a typical deep learning problem, which involves inherently ordered labels that are common in practical applications, especially in medical diagnosis tasks. To overcome the neglect of ordered or non-stationary property by merely exploiting classification or regression, quadratic weighted kappa (QWK) is proposed to be employed in the QWK loss function design as an efficient evaluation metric for ordinal regression. However, the paradox that kappa will be higher with an asymmetrical marginal histogram leads the QWK loss function to get the local optimal solution with all-zero-column in the confusion matrices during training. In practice, the all-zero column problem will result in a certain category not being detected at all, which can have serious consequences for the exclusion of pathology. To address this limitation, a new form of penalty term is proposed for the QWK loss function by penalizing the distance of marginal histogram to effectively avoid all-zero-column of the models. The experiments on the category-imbalanced datasets demonstrate that our penalty terms solve all-zero-column problem. On Adience dataset our penalty terms achieve 0.915 QWK, 0.446 MAE and 0.612 accuracy, while on DR dataset our penalty terms achieve 0.744 QWK, 0.281 MAE and 0.810 accuracy. Besides, experiments on the category-balanced datasets HCI show that our penalty terms achieve 0.810 QWK, 0.499 MAE and 0.610 accuracy.","Weighted kappa, Deep learning, Ordinal regression, Loss function"
Conference Paper,"Hatanaka Y,Mizukami A,Muramatsu C,Hara T,Fujita H",Automated Lesion Detection in Retinal Images,Association for Computing Machinery,2011,https://doi.org/10.1145/2093698.2093789;http://dx.doi.org/10.1145/2093698.2093789,"This paper describes automated lesion detection in retinal images. Physicians and ophthalmologists assess retinal images for several kinds of lesions, including hemorrhages, exudates, and arteriolar narrowing. Hemorrhage is a major sign of diabetic retinopathy, which is the second most common cause of vision loss. Arteriolar narrowing is a major sign of hypertensive retinopathy. The aim of this study was to measure arteriolar-to-venular diameter ratio for the detection of arteriolar narrowing and to develop a hemorrhage detection method. Blood vessels and hemorrhages were extracted using a double-ring filter. This filter device calculates the difference between the average pixel values of the inside and outside regions. Arteriolar narrowing is determined based on major arteriolar-to-venular diameter ratios. Thus, the major blood vessels were extracted and the arteriolar-to-venular diameter ratio was automatically calculated based on the artery and vein diameter measurements. Finally, the hemorrhage candidates remained after the blood vessels were ""erased"" from the image and hemorrhages were detected by machine learning methods using 64 texture features. We tested 20 retinal images from the DRIVE database to evaluate our proposed arteriolar-to-venular diameter ratio measurement method. Both the average error and the standard deviation of the arteriolar-to-venular diameter ratio measurements were 0.07 ± 0.06. We evaluated the proposed method for hemorrhage detection by testing 71 retinal images, including 53 images with hemorrhages and 18 normal ones. The sensitivity and specificity for the detection of abnormal cases were 83% and 67%, respectively.","medical image detection, pixel classification, retinopathy, arteriolar narrowing, hemorrhage"
Conference Paper,"Helms M,Ault SV,Mao G,Wang J",An Overview of Google Brain and Its Applications,Association for Computing Machinery,2018,https://doi.org/10.1145/3206157.3206175;http://dx.doi.org/10.1145/3206157.3206175,"Machine learning is quickly becoming a major field of research for many technology companies. Google, perhaps, is at the forefront of this movement and have instituted an entire research team called Google Brain to explore the technical aspect and applications of large scale neural networks. Thus far, the group has developed advancements in the areas of natural language recognition, open-source deep learning software, and healthcare related uses for computer vision assisted diagnosis.","Google, natural language recognition, TensorFlow, diabetic retinopathy, neural network, Google Brain, deep learning, machine learning"
Conference Paper,"Cen X,Tang H,Wu Y",Assisting Ultrasound Examination Based on Transfer Learning Method,Association for Computing Machinery,2019,https://doi.org/10.1145/3349341.3349501;http://dx.doi.org/10.1145/3349341.3349501,"Ultrasound examination is the preferred method for related diseases. The transfer learning method is considered to be a feasible and automatic method for optimizing the ultrasound examination. This paper uses the transfer learning method the diagnosis of hepatic hemanguimas. First, establish an optimized deep learning technology model. A stacking convolutional self-coded depth model is designed to deal with the lack of label image dataset Based on CNN. Second, External transfer learning technology model is established to the automatic classification diagnosis of ultrasound images according to the transfer learning technique. Comparing with the two results and combined with the artificial examination in our experiments, the diagnosis based on the transfer learning method can achieve an acceptable result.","Artificial intelligence, Ultrasound imaging, Transfer learning"
Conference Paper,"Bjaoui M,Sakly H,Said M,Kraiem N,Bouhlel MS",Depth Insight for Data Scientist with RapidMiner « an Innovative Tool for AI and Big Data towards Medical Applications»,Association for Computing Machinery,2020,https://doi.org/10.1145/3423603.3424059;http://dx.doi.org/10.1145/3423603.3424059,"RapidMiner tool is considered among the advanced analytics and powerful platform services in the field of artificial intelligence besides the Big Data storage. This solution has emerged towards several industries such as Financial Services, Energy, Logistics, Life Science and Healthcare and has shown a crucial impact for predictive decisions in this area. This work seeks to describe the solution strategy of this tool for data scientist by depicting a depth insight of this concept which contains more 1500 native algorithms, data preparation and data science functions. This features allows professionals to support any machine learning libraries and integrate python and R codes. RapidMiner offers three different modalities to access to their products which are the main Platform, the automated data science and the AI cloud.","artificial intelligence, security policies, advanced analytics, data science, big data, RapidMiner tool"
Conference Paper,Wang Y,A Comparison of Machine Learning Algorithms in Blood Glucose Prediction for People with Type 1 Diabetes,Association for Computing Machinery,2021,https://doi.org/10.1145/3500931.3500993;http://dx.doi.org/10.1145/3500931.3500993,"Diabetes is a metabolic disease with the characteristic of hyperglycemia. The pathogenic principle is derived from the defect of insulin secretion or the impairment of biological effects, or both. We use machine learning models and deep learning models for forecasting future blood glucose levels in this paper, and study the efficiency of detecting hypoglycemia and hyperglycemia events. The data set used is in-silico data generated from the UVA/PADOVA type 1 diabetes simulator. We aim to compare support vector machines, random forests, linear regression, K-Nearest Neighbors regression (KNN), XGBoosted trees and other deep learning models in terms of Root Mean Squared Error (RMSE), and other several evaluation metrics to study their effectiveness in predicting future blood sugar, and the accuracy rate of predicting hypoglycemia and hyperglycemia events. In this work, we found a bidirectional long-short term memory (LSTM) model with the best prediction effect, which can predict the blood glucose level of simulated patients with leading accuracy within 30 minutes (RMSE = 7.55±0.19 [mg/dl], R2-SCORE=0.96). The hopeful results show that this method could have practical application value for self-management of blood glucose in patients with type 1 diabetes.","type 1 diabetes, machine learning, deep neural networks, artificial intelligence, reinforcement learning, deep learning"
Conference Paper,"Katsamenis I,Protopapadakis E,Voulodimos A,Doulamis A,Doulamis N",Transfer Learning for COVID-19 Pneumonia Detection and Classification in Chest X-Ray Images,Association for Computing Machinery,2021,https://doi.org/10.1145/3437120.3437300;http://dx.doi.org/10.1145/3437120.3437300,"We introduce a deep learning framework that can detect COVID-19 pneumonia in thoracic radiographs, as well as differentiate it from bacterial pneumonia infection. Deep classification models, such as convolutional neural networks (CNNs), require large-scale datasets in order to be trained and perform properly. Since the number of X-ray samples related to COVID-19 is limited, transfer learning (TL) appears as the go-to method to alleviate the demand for training data and develop accurate automated diagnosis models. In this context, networks are able to gain knowledge from pretrained networks on large-scale image datasets or alternative data-rich sources (i.e. bacterial and viral pneumonia radiographs). The experimental results indicate that the TL approach outperforms the performance obtained without TL, for the COVID-19 classification task in chest X-ray images.","COVID-19, transfer learning, chest X-ray, deep learning, CNN"
Conference Paper,"Deka A,Sarma KK",SVD and PCA Features for ANN Based Detection of Diabetes Using Retinopathy,Association for Computing Machinery,2012,https://doi.org/10.1145/2381716.2381725;http://dx.doi.org/10.1145/2381716.2381725,"Retinopathy based techniques are preferred for diabetes detection due to their advantage of bloodless diagnosis. In concert to similar works currently going on, we propose, such a diabetes detection method using Artificial Neural Network (ANN) and a feature set formed by adopting Singular Value Decomposition (SVD) and Principal Component Analysis (PCA). A robust and computationally efficient approach for the localization of the different features in a fundus retinal image is presented in this work. The work proposes certain approaches for extraction of diabetes retinopathy features using SVD and PCA and applying the composite form to ANN for training. The detection of hemorrhages and exudates are important in order to diagnose diabetes retinopathy for preventing loss of eye sight. Experimental results show that the ANN-SVD+PNN composition is a reliable means of diabetes detection with less computational complexity and high accuracy.","ANN, SVD, PCA, image processing"
Conference Paper,"R AL,G SK",Abnormality Detection and Classification of Macular Diseases from Optical Coherence Tomography Images: Using Feature Space Comparison,Association for Computing Machinery,2021,https://doi.org/10.1145/3490035.3490265;http://dx.doi.org/10.1145/3490035.3490265,"Optical Coherence Tomography (OCT) is a non-invasive imaging technology for diagnosing various macular pathologies. It assists ophthalmologists to detect abnormalities in the retina and thereby avoid many sight-threatening conditions. However, manual detection process depends on the experience of the clinical practitioner and it is a time-consuming process. Automatic detection of abnormalities using computer algorithms allows the clinical practitioner to detect the abnormalities in a faster and accurate manner. Here, a Deep learning-based approach is proposed which can detect abnormal retinal images in various disease classes which are not limited to classes present in the training data-set. The performance of the Abnormality detector is tested on UCSD, Kaggle & OCTID data-sets and obtained an accuracy of 99.80%, 99.90% & 94.59%, respectively. The performance of Classifier is also tested on UCSD & Kaggle data-sets and obtained an accuracy of 97.7%, 99.79%, respectively.","CLmodel, FEmodel, CDnmodel, OCT similarity detection, feature space comparison, ADmodel, DISmodel, OCT classification, abnormality detection"
Conference Paper,"Bouchareb A,Boulaalam A,Bellamine I",IoT and AI Based Intelligent System to Fight against COVID-19,Association for Computing Machinery,2021,https://doi.org/10.1145/3454127.3457618;http://dx.doi.org/10.1145/3454127.3457618,"In this global health crisis, several efforts have been launched to monitor and control the spread of the COVID-19 pandemic. Those efforts require the support of new technologies like the Internet of Things, Artificial Intelligence, Image and Video Processing, Big Data, and Machine Learning to tackle various problems related to this viral pandemic. In these circumstances, public places such as hospitals, public transportation, and supermarkets need a more scientific and practical system/guidance to identify the probable COVID-19 cases. In this paper, we design an Internet of Things-Artificial Intelligence IoT-AI based intelligent system to monitor the suspect cases in public places. Based on implicit/Explicit data acquisition flow, the system provides information to public authorities. In a public place, the actions of suspicious people are collected by sensors such as thermal cameras, connected cameras, and Smartphone embedded sensors. Subsequently, this data is sent to the system for analysis. Thanks to artificial intelligence technology, the system can extract useful information to determine suspicious COVID-19 cases. In this article, we will describe the proposed global system. The design of this type of system is a trend for the future wider application to deal with COVID-19.","Artificial intelligence, IoT, COVID-19, Action recognition, Coronavirus"
Conference Paper,Yuan Y,ACU-Net: Adaptive Context Network Based on U-Net for Retinal Vessel Segmentation,Association for Computing Machinery,2022,https://doi.org/10.1145/3505711.3505722;http://dx.doi.org/10.1145/3505711.3505722,"The accurate segmentation of retinal vessels is essential for the diagnosis of various ophthalmic diseases. However, the manual segmentation approaches are time-consuming and seriously affected by individual subjective factors. In addition, retinal vessel segmentation is confronted with challenges such as complex shape, low image contrast and uneven thickness of vessels, which is not conducive to the automatic segmentation of vessels by computer. To meet the challenges of retinal vessel segmentation, this paper proposes an adaptive context-enhanced network based on U-Net (i.e., ACU-Net). On the basis of the fully convoluted encoder-decoder infrastructure, a multi-scale Adaptive Context Module is added with dilated convolution between the encoder and decoder, which can increase the accuracy of the segmentation results by adaptively capturing the spatial information of high-level feature and multi-scale. The multi-branch dilated convolution is used to divide the features acquired by the encoder into four groups, which are subsequently input into the four branches of the Adaptive Context Module. In addition, the output of each branch is weighted during the feature fusion before fused to improve the sensitivity of different feature extraction branches. Results showed that this module could not only significantly improve the segmentation performance of retinal vessels, but also exceed other advanced deep learning-based approaches in multiple indicators when applied to the DRIVE and CHASE-DB1 fundus image data sets. For the DRIVE data set, ACU-Net achieved excellent performance in a number of test indicators, with accuracy (AC) of 0.9591, area under the curve (AUC) of 0.9839, and sensitivity (SE) of 0.8220. Besides, the Adaptive Context Module of the network can be exploited as a reference for other medical segmentation tasks.","Retinal Vessel, Deep Neural Network, Medical Image Segmentation, Adaptive Context"
Conference Paper,"Jain N,Nandakumar K,Ratha N,Pankanti S,Kumar U",CryptInfer: Enabling Encrypted Inference on Skin Lesion Images for Melanoma Detection,Association for Computing Machinery,2021,https://doi.org/10.1145/3486001.3486233;http://dx.doi.org/10.1145/3486001.3486233,"Deep learning models such as Convolutional Neural Networks (CNNs) have shown the potential to classify medical images for accurate diagnosis. These techniques will face regulatory compliance challenges related to privacy of user data, especially when they are deployed as a service on a cloud platform. Fully Homomorphic Encryption (FHE) can enable CNN inference on encrypted data and help mitigate such concerns. However, encrypted CNN inference faces the fundamental challenge of optimizing the computations to achieve an acceptable trade-off between accuracy and practical computational feasibility. Current approaches for encrypted CNN inference demonstrate feasibility typically on smaller images (e.g., MNIST and CIFAR-10 datasets) and shallow neural networks. This work is the first to show encrypted inference results on a real-world dataset for melanoma detection with large-sized images of skin lesions based on the Cheon-Kim-Kim-Song (CKKS) encryption scheme available in the open-source HElib library. The practical challenges related to encrypted inference are first analyzed and inference experiments are conducted on encrypted MNIST images to evaluate different optimization strategies and their role in determining the throughput and latency of the inference process. Using these insights, a modified LeNet-like architecture is designed and implemented to achieve the end goal of enabling encrypted inference on melanoma dataset. The results demonstrate that 80% classification accuracy can be achieved on encrypted skin lesion images (security of 106 bits) with a latency of 51 seconds for single image inference and a throughput of 18,000 images per hour for batched inference, which shows that privacy-preserving machine learning as a service (MLaaS) based on encrypted data is indeed practically feasible.","multi-threading, non-linear activation function, Convolutional neural network, optimization, ciphertext packing, melanoma, skin cancer, homomorphic encryption"
Journal Article,"Mehrabi N,Morstatter F,Saxena N,Lerman K,Galstyan A",A Survey on Bias and Fairness in Machine Learning,Association for Computing Machinery,2021,https://doi.org/10.1145/3457607;http://dx.doi.org/10.1145/3457607,"With the widespread use of artificial intelligence (AI) systems and applications in our everyday lives, accounting for fairness has gained significant importance in designing and engineering of such systems. AI systems can be used in many sensitive environments to make important and life-changing decisions; thus, it is crucial to ensure that these decisions do not reflect discriminatory behavior toward certain groups or populations. More recently some work has been developed in traditional machine learning and deep learning that address such challenges in different subdomains. With the commercialization of these systems, researchers are becoming more aware of the biases that these applications can contain and are attempting to address them. In this survey, we investigated different real-world applications that have shown biases in various ways, and we listed different sources of biases that can affect AI applications. We then created a taxonomy for fairness definitions that machine learning researchers have defined to avoid the existing bias in AI systems. In addition to that, we examined different domains and subdomains in AI showing what researchers have observed with regard to unfair outcomes in the state-of-the-art methods and ways they have tried to address them. There are still many future directions and solutions that can be taken to mitigate the problem of bias in AI systems. We are hoping that this survey will motivate researchers to tackle these issues in the near future by observing existing work in their respective fields.","representation learning, Fairness and bias in artificial intelligence, machine learning, deep learning, natural language processing"
Conference Paper,"Miao Y,Zhao PF,Tang XF,Li YQ,Zhang LY,Shi WL,Zhang K,Yang HM,Liu JH",A Method for Detecting Femur Fracture Based on SK-DenseNet,Association for Computing Machinery,2019,https://doi.org/10.1145/3358331.3358402;http://dx.doi.org/10.1145/3358331.3358402,"In clinical diagnosis, automatic fracture detection can reduce misdiagnosis which caused by fatigue and inexperience of radiologists, and provide support for reducing patient suffering and preventing disease progression. This paper proposes a SK-DenseNet model to detect femur fracture based on DenseNet network. It uses SK module to adjust the size of receptive fields adaptively, adopts Focal loss function to update parameter, and uses Grad-CAM method to visualize the femoral detection results. It can improve the interpretability of the fracture detection model. This paper used the femoral dataset to verify the performance of the mode. Our model achieves an accuracy of 0.9117, with the kappa coefficient is 0.8228. The experimental results show that the performance of the proposed model is better than the traditional deep learning model.","Deep learning, Femoral fracture, SK-DenseNet, CAD"
Conference Paper,"Ji-hong Y,Sun-hao Z,Chun-yu F",Design of Offsite Diagnosis and Treatment Platform in the Yangtze River Delta Based on Information Sharing,Association for Computing Machinery,2019,https://doi.org/10.1145/3341069.3342973;http://dx.doi.org/10.1145/3341069.3342973,"To improve the collaborative service level of specialized diseases diagnosis and treatment in the Yangtze River Delta region, an offsite diagnosis and treatment platform based on information sharing in the Yangtze River Delta region is designed. It uses big data techniques and machine learning algorithms. It also combines with medical clinical data. Above all, it designs medical knowledge graph, which can compose massive heterogeneous data into a complete structured medical knowledge warehouse. It is convenient for users to understand the information and to provide good knowledge navigation for users.Furthermore, it designs a function module, which defines the platform Business flow. Last it designs a four-tier network architecture to provide network support for platform implementation. The implementation can effectively improve the medical technology level and promote the coordinated development of medical integration in the Yangtze River Delta region.","knowledge graph, collaborative services, machine learning, offsite diagnosis and treatment"
Journal Article,"Lian S,Li L,Lian G,Xiao X,Luo Z,Li S",A Global and Local Enhanced Residual U-Net for Accurate Retinal Vessel Segmentation,IEEE Computer Society Press,2019,https://doi.org/10.1109/TCBB.2019.2917188;http://dx.doi.org/10.1109/TCBB.2019.2917188,"Retinal vessel segmentation is a critical procedure towards the accurate visualization, diagnosis, early treatment, and surgery planning of ocular diseases. Recent deep learning-based approaches have achieved impressive performance in retinal vessel segmentation. However, they usually apply global image pre-processing and take the whole retinal images as input during network training, which have two drawbacks for accurate retinal vessel segmentation. First, these methods lack the utilization of the local patch information. Second, they overlook the geometric constraint that retina only occurs in a specific area within the whole image or the extracted patch. As a consequence, these global-based methods suffer in handling details, such as recognizing the small thin vessels, discriminating the optic disk, etc. To address these drawbacks, this study proposes a Global and Local enhanced residual U-nEt (GLUE) for accurate retinal vessel segmentation, which benefits from both the globally and locally enhanced information inside the retinal region. Experimental results on two benchmark datasets demonstrate the effectiveness of the proposed method, which consistently improves the segmentation accuracy over a conventional U-Net and achieves competitive performance compared to the state-of-the-art.",Not Found
Conference Paper,"Hou R,Ye Z,Yang C,Fu L,Liu C,Liu Q",Immunofluorescence Capillary Imaging Segmentation: Cases Study,Association for Computing Machinery,2022,https://doi.org/10.1145/3503161.3548429;http://dx.doi.org/10.1145/3503161.3548429,"Nonunion is one of the challenges faced by orthopedics clinics for the technical difficulties and high costs in photographing interosseous capillaries. Segmenting vessels and filling capillaries are critical in understanding the obstacles encountered in capillary growth. However, existing datasets for blood vessel segmentation mainly focus on the large blood vessels of the body, and the lack of labeled capillary image datasets greatly limits the methodological development and applications of vessel segmentation and capillary filling. Here, we present a benchmark dataset, named IFCIS-155, consisting of 155 2D capillary images with segmentation boundaries and vessel fillings annotated by biomedical experts, and 19 large-scale, high-resolution 3D capillary images. To obtain better images of interosseous capillaries, we leverage state-of-the-art immunofluorescence imaging techniques to highlight the rich vascular morphology of interosseous capillaries. We conduct comprehensive experiments to verify the effectiveness of the dataset and the benchmarking deep learning models (e.g. UNet/UNet++ and the modified UNet/UNet++). Our work offers a benchmark dataset for training deep learning models for capillary image segmentation and provides a potential tool for future capillary research. The IFCIS-155 dataset and code are all publicly available at https://github.com/ncclabsustech/IFCIS-55.","unet, ifcis-155, immunofluorescence capillary, image segmentation"
Conference Paper,"Baldauf M,Fröehlich P,Endl R","Trust Me, I’m a Doctor – User Perceptions of AI-Driven Apps for Mobile Health Diagnosis",Association for Computing Machinery,2020,https://doi.org/10.1145/3428361.3428362;http://dx.doi.org/10.1145/3428361.3428362,"First consumer-facing apps for medical self-diagnosis through Artificial Intelligence have hit the market only recently. These promise to detect malicious skin changes from photos or respiratory diseases from cough noises captured by the smartphone microphone, for example. While there is a large body of research on HCI-related aspects of mobile health applications, knowledge about the user perceptions of such novel AI-driven self-diagnosis apps and factors affecting their acceptance and adoption is scarce. In an online survey, we investigated the participants’ overall willingness-to-use (considering four types of captured and processed data) and identified trust factors and desirable features. We found that more than half of the participants would use AI-driven self-diagnosis apps, yet mainly integrated into prevailing general practitioner care. Based on the results, we draw conclusions which can guide the design, development, and launch of AI-driven self-diagnosis apps.","health assessment, artificial intelligence, self-diagnosis, mhealth"
Conference Paper,"Mahmud SM,Hossin MA,Ahmed MR,Noori SR,Sarkar MN",Machine Learning Based Unified Framework for Diabetes Prediction,Association for Computing Machinery,2018,https://doi.org/10.1145/3297730.3297737;http://dx.doi.org/10.1145/3297730.3297737,"Machine learning gained a significant position in healthcare services (HCS) due to its ability to improve the disease prediction in HCS. Machine learning techniques and artificial intelligence have already been worked in the HCS area. Recently, diabetes is a notable public chronic disease worldwide. It is growing rapidly because of bad lifestyles, taking more junk food and also lake of health awareness. Therefore, there is a need of framework that can effectively track and monitor people's diabetes and health condition within an application view. In this study, we proposed a framework for real time diabetes prediction, monitoring and application (DPMA). Our objective is to develop an optimized and efficient machine learning (ML) application which can effectually recognize and predict the condition of the diabetes. In this work, five most important machine learning classification techniques were considered for predicting diabetes. However, we use different evaluation criteria to investigate the performance of these classification techniques. In addition, performance measurement of the classification techniques was evaluated by applying the 10-fold cross validation method. The analysis results show that Naïve Bayes achieved highest performance than the other classifiers, obtaining the F1 measure of 0.74.","Diabetes Prediction, Machine Learning, Disease Prediction, Supervised Learning, Classification"
Journal Article,"Nguyen DC,Pham QV,Pathirana PN,Ding M,Seneviratne A,Lin Z,Dobre O,Hwang WJ",Federated Learning for Smart Healthcare: A Survey,Association for Computing Machinery,2022,https://doi.org/10.1145/3501296;http://dx.doi.org/10.1145/3501296,"Recent advances in communication technologies and the Internet-of-Medical-Things (IOMT) have transformed smart healthcare enabled by artificial intelligence (AI). Traditionally, AI techniques require centralized data collection and processing that may be infeasible in realistic healthcare scenarios due to the high scalability of modern healthcare networks and growing data privacy concerns. Federated Learning (FL), as an emerging distributed collaborative AI paradigm, is particularly attractive for smart healthcare, by coordinating multiple clients (e.g., hospitals) to perform AI training without sharing raw data. Accordingly, we provide a comprehensive survey on the use of FL in smart healthcare. First, we present the recent advances in FL, the motivations, and the requirements of using FL in smart healthcare. The recent FL designs for smart healthcare are then discussed, ranging from resource-aware FL, secure and privacy-aware FL to incentive FL and personalized FL. Subsequently, we provide a state-of-the-art review on the emerging applications of FL in key healthcare domains, including health data management, remote health monitoring, medical imaging, and COVID-19 detection. Several recent FL-based smart healthcare projects are analyzed, and the key lessons learned from the survey are also highlighted. Finally, we discuss interesting research challenges and possible directions for future FL research in smart healthcare.","smart healthcare, Federated learning, privacy"
Conference Paper,"Wang Z,Lin J,Wang R,Zheng W",Data Augmentation is More Important Than Model Architectures for Retinal Vessel Segmentation,Association for Computing Machinery,2019,https://doi.org/10.1145/3348416.3348425;http://dx.doi.org/10.1145/3348416.3348425,"While various deep learning models have recently been proposed or applied to improve the segmentation of vessels in retinal images, the performance gap between different models are often quite small. Such small difference may come from their limited generalization capabilities due to small training data. By simply augmenting data with oriented image patches extracted from the limited training images, we are surprised to observe that even a very simple U-Net with these augmented training patches can outperform the state-of-the-art models with much more complicated architectures or training schemes, and initial gaps between models have become negligible or disappeared. This suggests that it might be more crucial to explore effective data augmentations to extract richer visual information from limited training data, rather than solely focusing on developing other novel deep learning techniques for retinal vessel segmentation.","Retinal vessel segmentation, U-Nets, rotation augmentation"
Conference Paper,"Hou F,Cheng Z,Kang L,Zheng W",Prediction of Gestational Diabetes Based on LightGBM,Association for Computing Machinery,2020,https://doi.org/10.1145/3433996.3434025;http://dx.doi.org/10.1145/3433996.3434025,"Gestational diabetes mellitus (GDM) is associated with an increased risk of both short-term and long-term complications in mothers and infants. However, if lifestyle interventions are initiated at or before the 15th week of pregnancy, the risk of GDM could be reduced by 20% during pregnancy. Therefore, it is important to explore the risk factors for the disease and to identify women at high risk for GDM in early pregnancy. In this study, the data of Tianchi Precision Medical Competition-artificial intelligence assisted diabetes genetic risk prediction rematch is selected to construct the LightGBM prediction model and compare with Random Forest and XGBoost on the ROC curve. The results show that the AUC of LightGBM is 85.2%. Compared with other prediction models, LightGBM prediction model has more advantages and a better classification effect.Important features are constructed by LightGBM and analyzed statistically. It was found that when the value of single nucleotide polymorphism gene 37 (SNP37) is 3, it could inhibit the single nucleotide polymorphism gene 34 (SNP34), resulting in reduced risk of disease. When the value of single nucleotide polymorphism gene 34 (SNP34) and single nucleotide polymorphism gene 37 (SNP37) is 2 at the same time, they may promote each other and increase the risk of disease. Pregnant women with high insulin resistance (VAR00007) and older women are at increased risk of developing gestational diabetes. The results of this study indicate that LightGBM and other machine learning techniques play an important role in the auxiliary diagnosis of gestational diabetes and the mining of risk factors.","LightGBM, Factors mining, Risk, Gestational diabetes, Auxiliary diagnosis"
Conference Paper,"Ranjan E,Paul S,Kapoor S,Kar A,Sethuraman R,Sheet D",Jointly Learning Convolutional Representations to Compress Radiological Images and Classify Thoracic Diseases in the Compressed Domain,Association for Computing Machinery,2020,https://doi.org/10.1145/3293353.3293408;http://dx.doi.org/10.1145/3293353.3293408,"Deep learning models trained in natural images are commonly used for different classification tasks in the medical domain. Generally, very high dimensional medical images are down-sampled by using interpolation techniques before feeding them to deep learning models that are ImageNet compliant and accept only low-resolution images of size 224 x 224 px. This popular technique may lead to the loss of key information thus hampering the classification. Significant pathological features in medical images typically being small sized and highly affected. To combat this problem, we introduce a convolutional neural network (CNN) based classification approach which learns to reduce the resolution of the image using an autoencoder and at the same time classify it using another network, while both the tasks are trained jointly. This algorithm guides the model to learn essential representations from high-resolution images for classification along with reconstruction. We have used the publicly available dataset of chest x-rays to evaluate this approach and have outperformed state-of-the-art on test data. Besides, we have experimented with the effects of different augmentation approaches in this dataset and report baselines using some well known ImageNet class of CNNs.","X-Ray classification, compression, Convolutional autoencoder"
Journal Article,"Ogunleye A,Wang QG",XGBoost Model for Chronic Kidney Disease Diagnosis,IEEE Computer Society Press,2020,https://doi.org/10.1109/TCBB.2019.2911071;http://dx.doi.org/10.1109/TCBB.2019.2911071,"Chronic Kidney Disease (CKD) is a menace that is affecting 10 percent of the world population and 15 percent of the South African population. The early and cheap diagnosis of this disease with accuracy and reliability will save 20,000 lives in South Africa per year. Scientists are developing smart solutions with Artificial Intelligence (AI). In this paper, several typical and recent AI algorithms are studied in the context of CKD and the extreme gradient boosting (XGBoost) is chosen as our base model for its high performance. Then, the model is optimized and the optimal full model trained on all the features achieves a testing accuracy, sensitivity, and specificity of 1.000, 1.000, and 1.000, respectively. Note that, to cover the widest range of people, the time and monetary costs of CKD diagnosis have to be minimized with fewest patient tests. Thus, the reduced model using fewer features is desirable while it should still maintain high performance. To this end, the set-theory based rule is presented which combines a few feature selection methods with their collective strengths. The reduced model using about a half of the original full features performs better than the models based on individual feature selection methods and achieves accuracy, sensitivity and specificity, of 1.000, 1.000, and 1.000, respectively.",Not Found
Conference Paper,"Wang Z,Lin J,Wang R,Zheng W",Retinal Artery/Vein Classification via Rotation Augmentation and Deeply Supervised U-Net Segmentation,Association for Computing Machinery,2019,https://doi.org/10.1145/3354031.3354050;http://dx.doi.org/10.1145/3354031.3354050,"Automatic classification of artery and vein vessels in retinal images is still a challenging task. Recent work mainly focuses on the graph analysis of retinal vessels or intensity based feature extraction. In this study, we use one stage multiclass segmentation without any graph-based or vote-based post processing to solve the artery/vein classification problem directly and effectively. We experimentally showed that with limited training data, data augmentation may be at least as crucial as designing complicated deep model architectures in improving the performance of artery/vein classification. In particular, simply with rotation augmentation, the popular deeply supervised U-Net (DS-Unet) is already comparable to or even outperforms the state-of-the-art methods on DRIVE dataset. Our experiments on two datasets show that artery-vein-background segmentation based on deep learning can be used as a promising method for arteriovenous classification and can be combined with conventional methods for better results.","Artery and vein classification, Deep supervised Unet, Semantic segmentation, Rotation augmentation"
Journal Article,"Guo K,Zhu F,Zhou X,Zhang L,Wang Y,Kang J",LesionTalk: Core Data Extraction and Multi-Class Lesion Detection in IoT Based Intelligent Healthcare,Association for Computing Machinery,2022,https://doi.org/10.1145/3526194;http://dx.doi.org/10.1145/3526194,"With the development of intelligent medicine, lesion detection supported by Internet of Things (IoT), big data, and deep learning has become a hotspot. However, lesion detection technology based on deep learning requires huge amounts of high-quality medical image data, and the data from social IoT has the problems of uneven quality and lack of lesion labeling. Current studies usually ignore the unstable quality of IoT data and the interpretability of diagnostic results, resulting in deeper model layers, larger models, poor real-time performance, and lack of persuasion. To address the problems, this paper first proposes a core data extraction method for multi-class lesion detection based on unlabeled medical image from social IoT. Then, we propose an ensemble algorithm based on lightweight models to improve the detection accuracy. Finally, we visualize pathological features to enhance the interpretability of core data and detection results. The experimental results show that our method can effectively extract the core data of multiple lesions from low-quality medical images, and improve the accuracy of the lightweight lesion detection model as well as the interpretation of detection results.","ensemble learning, Lesion detection, core data extraction, social IoT"
Conference Paper,"Maistry A,Pillay A,Jembere E",Improving the Accuracy of Diabetes Retinopathy Image Classification Using Augmentation,Association for Computing Machinery,2020,https://doi.org/10.1145/3410886.3410914;http://dx.doi.org/10.1145/3410886.3410914,"Diabetes retinopathy (DR) is a disease that afflicts diabetic patients and is caused by damage to the blood vessels in the retina of the eye. This disease is a leading cause of blindness and is a common complication of diabetes. Regular screening and early detection are crucial to treatment. Automated classification with machine learning techniques has shown promise in this regard. Previous work has not addressed the imbalances in the datasets used. In this paper, we report on the effectiveness of data augmentation techniques for balancing the datasets and thus improving the accuracy of automated diagnosis of DR from fundus images. We achieve state of the art results – an F1 score of 0.8 and an accuracy of 86.96% by using data augmentation to balance the dataset.","data augmentation, fundus images, convolutional neural networks, diabetes retinopathy"
Conference Paper,"Li C,Fu H,Cong R,Li Z,Xu Q",NuI-Go: Recursive Non-Local Encoder-Decoder Network for Retinal Image Non-Uniform Illumination Removal,Association for Computing Machinery,2020,https://doi.org/10.1145/3394171.3413928;http://dx.doi.org/10.1145/3394171.3413928,"Retinal images have been widely used by clinicians for early diagnosis of ocular diseases. However, the quality of retinal images is often clinically unsatisfactory due to eye lesions and imperfect imaging process. One of the most challenging quality degradation issues in retinal images is non-uniform which hinders the pathological information and further impairs the diagnosis of ophthalmologists and computer-aided analysis. To address this issue, we propose a non-uniform illumination removal network for retinal image, called NuI-Go, which consists of three Recursive Non-local Encoder-Decoder Residual Blocks (NEDRBs) for enhancing the degraded retinal images in a progressive manner. Each NEDRB contains a feature encoder module that captures the hierarchical feature representations, a non-local context module that models the context information, and a feature decoder module that recovers the details and spatial dimension. Additionally, the symmetric skip-connections between the encoder module and the decoder module provide long-range information compensation and reuse. Extensive experiments demonstrate that the proposed method can effectively remove the non-uniform illumination on retinal images while well preserving the image details and color. We further demonstrate the advantages of the proposed method for improving the accuracy of retinal vessel segmentation.","retinal image enhancement, deep learning, non-uniform illumination removal"
Journal Article,"Hossain MS,Cucchiara R,Muhammad G,Tobón DP,Saddik AE",Special Section on AI-Empowered Multimedia Data Analytics for Smart Healthcare,Association for Computing Machinery,2022,https://doi.org/10.1145/3505281;http://dx.doi.org/10.1145/3505281,Not Found,Not Found
Conference Paper,"Ding H,Yan K,Tu Z,Wang P",Exploring a Universal Training Method for Medical Image Classification,Association for Computing Machinery,2022,https://doi.org/10.1145/3545729.3545731;http://dx.doi.org/10.1145/3545729.3545731,"In recent years, with the application of deep learning technology in the field of medical image analysis, computer-aided medical image classification can help doctors diagnose and treat patients better. However, due to the particularity of medical images, the performance of traditional image processing is not satisfactory to all medical images. Self-supervised pretraining followed by supervised finetuning has seen success in image recognition, but has received limited attention in medical image classification. In this paper, we propose a method based on self-supervised pretraining and supervised finetuning. In the pretraining step, we train our backbone on unlabeled ImageNet and MedMNIST to learn different types of image features. In the finetuning step, we carefully compare our training method in two modalities with several mainstream methods. Our pretraining method outperforms supervised baselines pretrained on ImageNet. In addition, we show that with suitable pretraining method adopted, our proposed method could be reused on several similar tasks with little modification.","self-supervised pretraining, medical image classification, deep learning"
Journal Article,"Nakandala S,Nagrecha K,Kumar A,Papakonstantinou Y",Incremental and Approximate Computations for Accelerating Deep CNN Inference,Association for Computing Machinery,2020,https://doi.org/10.1145/3397461;http://dx.doi.org/10.1145/3397461,"Deep learning now offers state-of-the-art accuracy for many prediction tasks. A form of deep learning called deep convolutional neural networks (CNNs) are especially popular on image, video, and time series data. Due to its high computational cost, CNN inference is often a bottleneck in analytics tasks on such data. Thus, a lot of work in the computer architecture, systems, and compilers communities study how to make CNN inference faster. In this work, we show that by elevating the abstraction level and re-imagining CNN inference as queries, we can bring to bear database-style query optimization techniques to improve CNN inference efficiency. We focus on tasks that perform CNN inference repeatedly on inputs that are only slightly different. We identify two popular CNN tasks with this behavior: occlusion-based explanations (OBE) and object recognition in videos (ORV). OBE is a popular method for “explaining” CNN predictions. It outputs a heatmap over the input to show which regions (e.g., image pixels) mattered most for a given prediction. It leads to many re-inference requests on locally modified inputs. ORV uses CNNs to identify and track objects across video frames. It also leads to many re-inference requests. We cast such tasks in a unified manner as a novel instance of the incremental view maintenance problem and create a comprehensive algebraic framework for incremental CNN inference that reduces computational costs. We produce materialized views of features produced inside a CNN and connect them with a novel multi-query optimization scheme for CNN re-inference. Finally, we also devise novel OBE-specific and ORV-specific approximate inference optimizations exploiting their semantics. We prototype our ideas in Python to create a tool called Krypton that supports both CPUs and GPUs. Experiments with real data and CNNs show that Krypton reduces runtimes by up to 5× (respectively, 35×) to produce exact (respectively, high-quality approximate) results without raising resource requirements.","systems for machine learning, Incremental view maintenance, multi-query optimization, convolutional neural network explainability"
Conference Paper,"Ghalwash M,Yao Z,Chakraporty P,Codella J,Sow D",Phenotypical Ontology Driven Framework for Multi-Task Learning,Association for Computing Machinery,2021,https://doi.org/10.1145/3450439.3451881;http://dx.doi.org/10.1145/3450439.3451881,"Despite the large number of patients in Electronic Health Records (EHRs), the subset of usable data for modeling outcomes of specific phenotypes are often imbalanced and of modest size. This can be attributed to the uneven coverage of medical concepts in EHRs. We propose OMTL, an Ontology-driven Multi-Task Learning framework, that is designed to overcome such data limitations.The key contribution of our work is the effective use of knowledge from a predefined well-established medical relationship graph (ontology) to construct a novel deep learning network architecture that mirrors this ontology. This enables common representations to be shared across related phenotypes, and was found to improve the learning performance. The proposed OMTL naturally allows for multi-task learning of different phenotypes on distinct predictive tasks. These phenotypes are tied together by their semantic relationship according to the external medical ontology. Using the publicly available MIMIC-III database, we evaluate OMTL and demonstrate its efficacy on several real patient outcome predictions over state-of-the-art multi-task learning schemes. The results of evaluating the proposed approach on six experiments show improvement in the area under ROC curve by 9% and by 8% in the area under precision-recall curve.","embedding, multitask, knowledge-driven"
Conference Paper,"Lee MH,Siewiorek DP,Smailagic A,Bernardino A,Bermúdez i Badia S",A Human-AI Collaborative Approach for Clinical Decision Making on Rehabilitation Assessment,Association for Computing Machinery,2021,https://doi.org/10.1145/3411764.3445472;http://dx.doi.org/10.1145/3411764.3445472,"Advances in artificial intelligence (AI) have made it increasingly applicable to supplement expert’s decision-making in the form of a decision support system on various tasks. For instance, an AI-based system can provide therapists quantitative analysis on patient’s status to improve practices of rehabilitation assessment. However, there is limited knowledge on the potential of these systems. In this paper, we present the development and evaluation of an interactive AI-based system that supports collaborative decision making with therapists for rehabilitation assessment. This system automatically identifies salient features of assessment to generate patient-specific analysis for therapists, and tunes with their feedback. In two evaluations with therapists, we found that our system supports therapists significantly higher agreement on assessment (0.71 average F1-score) than a traditional system without analysis (0.66 average F1-score, p < 0.05). After tuning with therapist’s feedback, our system significantly improves its performance from 0.8377 to 0.9116 average F1-scores (p < 0.01). This work discusses the potential of a human-AI collaborative system to support more accurate decision making while learning from each other’s strengths.","Stroke Rehabilitation Assessment, Human-AI Interaction/Collaboration, Personalization, Decision Support Systems, Explainable and Interactive Machine Learning"
Conference Paper,"Bin Rafiq R,Modave F,Guha S,Albert MV",Validation Methods to Promote Real-World Applicability of Machine Learning in Medicine,Association for Computing Machinery,2021,https://doi.org/10.1145/3441369.3441372;http://dx.doi.org/10.1145/3441369.3441372,"The impact of Artificial Intelligence (AI) on health care has been dramatic; however, there is a considerable degree of skepticism among clinicians about the real-world applicability of advanced predictive models; for this reason, it is particularly important to emphasize the need for proper model validation in machine learning. Often model skepticism is well-placed as modelers may overclaim the real-world replicability for their models, understate the known limitations, or simply not be aware of the hidden limits of the modeling approach. Educational approaches limited to rigorous and thorough justification of all model design decisions may not be practical given model complexity. This also becomes more challenging as state-of-the-art models with the highest benchmark accuracy are becoming less interpretable, e.g. ensemble methods or deep learning. However, in the same way that test-driven development has been a successful paradigm to navigate the complex coding landscape through a focus on testable results, we have observed a similar improvement in modeling strategy when the focus of a predictive model is driven by validation targets rather than more abstract, theoretical concerns. In this study, we provide an overview of the common limitations of model validation methods in medicine. We then present solutions to address such limitations, with a focus on strengthening the validity of predictive models.","Precision medicine, Evaluation metrics, Validation methods, Natural variability"
Conference Paper,"Wu J,Chen J,Xiao Z,Geng L",Automatic Layering of Retinal OCT Images with Dual Attention Mechanism,Association for Computing Machinery,2021,https://doi.org/10.1145/3468945.3468956;http://dx.doi.org/10.1145/3468945.3468956,"At present, there are more and more people suffering from retinal diseases. Doctors can diagnose and prevent eye diseases by observing the changes in the thickness of the retinal layer in OCT images. Due to the low contrast of the retinal layer boundary of the OCT image, manual segmentation is time-consuming and laborious. Moreover, most of the current automatic retinal layer segmentation methods are based on traditional methods and the segmentation result is not good. Therefore, in this paper, we proposed an end-to-end automatic retinal layer segmentation method based on deep learning, called DA-PSPNet, which can accurately segment seven retinal layers in OCT images. DA-PSPNet integrates a dual attention mechanism based on the PSPNet network, aiming to extract richer layer boundary information. It merges features of various levels to aggregate contextual information in different regions. The experimental results show that the proposed method achieves better performance in several evaluation indexes compared with the other four mainstream segmentation networks.","Retina, PSPNet, OCT, Dual attention mechanism, Deep learning"
Conference Paper,"Akundi P,Sivaswamy J",Manifold Learning to Address Catastrophic Forgetting,Association for Computing Machinery,2021,https://doi.org/10.1145/3490035.3490287;http://dx.doi.org/10.1145/3490035.3490287,"A major challenge that deep learning systems face is the Catastrophic Forgetting (CF) phenomenon that is observed when fine-tuning is used to try and adapt a system to a new task or a sequence of datasets with different distributions. CF refers to the significant degradation in performance on the old task/dataset. In this paper, a novel approach is proposed to address CF in computer aided diagnosis (CAD) system design in the medical domain. CAD systems often need to handle a sequence of datasets collected over time from different sites with different imaging parameters/populations. The solution we propose is to move samples from all the datasets closer to a common manifold via a reformer at the front end of a CAD system. The utility of this approach is demonstrated on two common tasks, namely segmentation and classification, using publicly available datasets. Results of extensive experiments show that manifold learning can yield about 74% improvement on an average in the reduction of CF over the baseline fine-tuning process and the state-of-the-art regularization based methods. The results also indicate that a Reformer when used in conjunction with the state-of-the-art regularization methods, has the potential to yield further improvement in CF reduction.","continual learning, autoencoders, manifold learning, castastrophic forgetting, medical image analysis"
Conference Paper,"Okolo CT,Kamath S,Dell N,Vashistha A",“It Cannot Do All of My Work”: Community Health Worker Perceptions of AI-Enabled Mobile Health Applications in Rural India,Association for Computing Machinery,2021,https://doi.org/10.1145/3411764.3445420;http://dx.doi.org/10.1145/3411764.3445420,"Recent advances in Artificial Intelligence (AI) suggest that AI applications could transform healthcare delivery in the Global South. However, as researchers and technology companies rush to develop AI applications that aid the health of marginalized communities, it is critical to consider the needs and perceptions of the community health workers (CHWs) who will have to integrate these AI applications into the essential healthcare services they provide to rural communities. We describe a qualitative study examining CHWs’ perceptions of an AI application for automated disease diagnosis. Drawing on data from 21 interviews with CHWs in rural India, we characterize (1) CHWs’ knowledge, perceptions, and understandings of AI; and (2) the benefits and challenges that CHWs anticipate as AI applications are integrated into their workflows, including their opinions on automation of their work, possible misdiagnosis and errors, data access and surveillance issues, security and privacy challenges, and questions concerning trust. We conclude by discussing the implications of our work for HCI and AI research in low-resource environments.","CHW, Artificial Intelligence, mHealth, ICTD, HCI4D, Community health worker, AI"
Journal Article,Sadri F,Ambient Intelligence: A Survey,Association for Computing Machinery,2011,https://doi.org/10.1145/1978802.1978815;http://dx.doi.org/10.1145/1978802.1978815,"In this article we survey ambient intelligence (AmI), including its applications, some of the technologies it uses, and its social and ethical implications. The applications include AmI at home, care of the elderly, healthcare, commerce, and business, recommender systems, museums and tourist scenarios, and group decision making. Among technologies, we focus on ambient data management and artificial intelligence; for example planning, learning, event-condition-action rules, temporal reasoning, and agent-oriented technologies. The survey is not intended to be exhaustive, but to convey a broad range of applications, technologies, and technical, social, and ethical challenges.","assisted living, multiagent systems, social and ethical issues, Ambient intelligence, agents"
Conference Paper,"Wambura S,Li H",Deep and Confident Image Analysis for Disease Detection,Association for Computing Machinery,2021,https://doi.org/10.1145/3442705.3442720;http://dx.doi.org/10.1145/3442705.3442720,"This paper proposes an efficient deep learning classifier built on Bayesian deep neural network framework for general probabilistic disease detection along with reliable principled uncertainty estimation. Specifically we harness the expressiveness and temporal nature of Seq-2-Seq Convolutional neural networks (CNNs) to model explicitly disease detection problem via deep and confident image processing. The work in this paper shows that the uncertainty informed decision making can improve the diagnostic performance considerably. Furthermore, we deploy a Memory Network in order to memorize detected images representing infected cells in historical records. We demonstrate and validate empirically the effectiveness of the proposed framework via extensive experimental and rigorous evaluation on large-scale real world data sets. Experiments across different tasks and datasets show robust generalization, accurate and superior performance of proposed method compared to the well-known state-of-the-art diseases detectors.","image analysis, stochastic dropout, Bayesian neural networks, detection"
Conference Paper,"AlHuwail D,Barnes R",Diabetes Care in the Age of Informatics: Kuwait-Scotland Health Innovation Network,Association for Computing Machinery,2011,https://doi.org/10.1145/2107556.2107572;http://dx.doi.org/10.1145/2107556.2107572,"In this paper, we describe the initial experience of implementing informatics support for the treatment of chronic conditions in Kuwait, including diabetes. We consider the broad requirements of service improvement and provision of clinical data. We describe work undertaken in the foundation and pilot phases of the Kuwait Scotland Health Innovation Network programme.","informatics, health, diabetes, service-oriented architecture"
Journal Article,"Cheng WH,Liu J,Sebe N,Yuan J,Shuai HH",Introduction to the Special Issue on Explainable AI on Multimedia Computing,Association for Computing Machinery,2021,https://doi.org/10.1145/3489522;http://dx.doi.org/10.1145/3489522,Not Found,Not Found
Conference Paper,"Li X,Zhou Y,Wang J,Lin H,Zhao J,Ding D,Yu W,Chen Y",Multi-Modal Multi-Instance Learning for Retinal Disease Recognition,Association for Computing Machinery,2021,https://doi.org/10.1145/3474085.3475418;http://dx.doi.org/10.1145/3474085.3475418,"This paper attacks an emerging challenge of multi-modal retinal disease recognition. Given a multi-modal case consisting of a color fundus photo (CFP) and an array of OCT B-scan images acquired during an eye examination, we aim to build a deep neural network that recognizes multiple vision-threatening diseases for the given case. As the diagnostic efficacy of CFP and OCT is disease-dependent, the network's ability of being both selective and interpretable is important. Moreover, as both data acquisition and manual labeling are extremely expensive in the medical domain, the network has to be relatively lightweight for learning from a limited set of labeled multi-modal samples. Prior art on retinal disease recognition focuses either on a single disease or on a single modality, leaving multi-modal fusion largely underexplored. We propose in this paper Multi-Modal Multi-Instance Learning (MM-MIL) for selectively fusing CFP and OCT modalities. Its lightweight architecture (as compared to current multi-head attention modules) makes it suited for learning from relatively small-sized datasets. For an effective use of MM-MIL, we propose to generate a pseudo sequence of CFPs by over sampling a given CFP. The benefits of this tactic include well balancing instances across modalities, increasing the resolution of the CFP input, and finding out regions of the CFP most relevant with respect to the final diagnosis. Extensive experiments on a real-world dataset consisting of 1,206 multi-modal cases from 1,193 eyes of 836 subjects demonstrate the viability of the proposed model.","multi-modal feature fusion, deep multi-instance learning, multi-modal retinal imaging, retinal disease recognition"
Conference Paper,"Janizek JD,Erion G,DeGrave AJ,Lee SI",An Adversarial Approach for the Robust Classification of Pneumonia from Chest Radiographs,Association for Computing Machinery,2020,https://doi.org/10.1145/3368555.3384458;http://dx.doi.org/10.1145/3368555.3384458,"While deep learning has shown promise in the domain of disease classification from medical images, models based on state-of-the-art convolutional neural network architectures often exhibit performance loss due to dataset shift. Models trained using data from one hospital system achieve high predictive performance when tested on data from the same hospital, but perform significantly worse when they are tested in different hospital systems. Furthermore, even within a given hospital system, deep learning models have been shown to depend on hospital- and patient-level confounders rather than meaningful pathology to make classifications. In order for these models to be safely deployed, we would like to ensure that they do not use confounding variables to make their classification, and that they will work well even when tested on images from hospitals that were not included in the training data. We attempt to address this problem in the context of pneumonia classification from chest radiographs. We propose an approach based on adversarial optimization, which allows us to learn more robust models that do not depend on confounders. Specifically, we demonstrate improved out-of-hospital generalization performance of a pneumonia classifier by training a model that is invariant to the view position of chest radiographs (anterior-posterior vs. posterior-anterior). Our approach leads to better predictive performance on external hospital data than both a standard baseline and previously proposed methods to handle confounding, and also suggests a method for identifying models that may rely on confounders.","Covariate Shift, Adversarial Training, Chest Radiograph, Radiology, Deep Learning, Robustness, Distributional Robustness, Domain Adaptation, Domain Shift, Pneumonia"
Conference Paper,Skopal T,On Visualizations in the Role of Universal Data Representation,Association for Computing Machinery,2020,https://doi.org/10.1145/3372278.3390743;http://dx.doi.org/10.1145/3372278.3390743,"The deep learning revolution changed the world of machine learning and boosted the AI industry as such. In particular, the most effective models for image retrieval are based on deep convolutional neural networks (DCNN), outperforming the traditional ""hand-engineered"" models by far. However, this tremendous success was redeemed by a high cost in the form of an exhaustive gathering of labeled data, followed by designing and training the DCNN models. In this paper, we outline a vision of a framework for instant transfer learning, where a generic pre-trained DCNN model is used as a universal feature extraction method for visualized unstructured data in many (non-visual) domains. The deep feature descriptors are then usable in similarity search tasks (database queries, joins) and in other parts of the data processing pipeline. The envisioned framework should enable practitioners to instantly use DCNN-based data representations in their new domains without the need for the costly training step. Moreover, by use of the framework the information visualization community could acquire a versatile metric for measuring the quality of data visualizations, which is generally a difficult task.","transfer learning, deep learning, classification, pre-trained models, data visualization, image retrieval, data representations"
Conference Paper,"Tzortzis IN,Davradou A,Protopapadakis E,Kaselimi M,Doulamis N,Angeli A,Lazaris A",Unsupervised Diabetic Foot Monitoring Techniques,Association for Computing Machinery,2022,https://doi.org/10.1145/3529190.3534723;http://dx.doi.org/10.1145/3529190.3534723,"A significant amount of research, involving computerized methods, has been initiated the last few years regarding the identification and prevention of Diabetes Foot Ulceration (DFU). In this paper, the spatial analysis of the raw data is investigated. The major expectations were the indication of regions of interest and the extraction of a more reliable understanding, regarding the captured information. Towards this direction, unsupervised learning approaches were used for image segmentation purposes. According to the experimental results, high-level features can be used to segment coarse images, grouping together areas with skin irregularities on patient’s foot. In practice, there are (or can be calculated) appropriate features, over RGB images, that will facilitate the detection of problematic/high-risk regions on a foot. Yet, unsupervised approaches should not be considered as viable monitoring solutions both in terms of time and accuracy. However, the proposed approach could potentially be used to assist the detection process resulted by supervised Deep Learning techniques.","diabetic foot ulcer, low-level features, neural networks, high-level features, clustering"
Conference Paper,"Daanouni O,Cherradi B,Tmiri A",Diabetes Diseases Prediction Using Supervised Machine Learning and Neighbourhood Components Analysis,Association for Computing Machinery,2020,https://doi.org/10.1145/3386723.3387887;http://dx.doi.org/10.1145/3386723.3387887,"Diabetes mellitus (DM) is a chronic disease, which can affect the entire body system. Early Diagnosis of patient's diabetics can help improve their health quality or reducing the risk factors. The main objective of this study is to evaluate the performance of some Machine Learning algorithms, used to predict diabetes diseases, for this purpose we apply and evaluate four Machine Learning algorithms (Decision Tree, K-Nearest Neighbours, Artificial Neural Network and Deep Neural Network) to predict diabetes mellitus. These techniques have been trained and tested on Pima Indian dataset. The performances of the experimented algorithms have been evaluated after removing noisy data and using features selection with Neighbourhood components Analysis in order to reduce the number of features and mitigate the complexity of dimensionality in favour of speeds up the learning process, enhances data understanding. Different similarity metrics used to compare model performance like Accuracy, Sensitivity, and Specificity.","Diabetes diseases, Computer aided diagnosis (CAD), features Selection, deep learning, prediction systems, machine learning"
Conference Paper,Qaddoum K,Looking at Alzheimer's Disease Using Enhanced Algorithm for Feature Collection,Association for Computing Machinery,2018,https://doi.org/10.1145/3290818.3290820;http://dx.doi.org/10.1145/3290818.3290820,"Machine learning technology has taken substantial leaps in the past few years. From the rise of voice recognition as an interface to interact with our computers to self-organizing photo albums and self-driving cars. Neural networks and deep learning contributed significantly to drive this revolution. Biomedicine is one of the research areas that have yet to fully embrace the possibilities of deep learning. The ability to learn hierarchical features makes deep learning models highly applicable to biomedicine and researchers have started to notice this. Deeper understanding can be enabled by the hierarchical features that marked in deep models. This paper explores the use of neural networks and deep learning models for the qualitative assessment of biomedical datasets using a non-iterative, data feature collection algorithm to preserve original features and provide qualitative analysis on their importance. This algorithm is employed in numerous areas including Pima Indian diabetes and children tumor detection. The learning coefficients found to contain clinically significant features. When combined, in a hierarchical way, these features reveal useful insights for the evaluation of treatment effectivity.","Deep learning, Biomedicine, Neural networks, Feature collection"
Conference Paper,"De Goma JC,Binsol OJ,Nadado AM,Casela JP",Age-Related Macular Degeneration Detection through Fundus Image Analysis Using Image Processing Techniques,Association for Computing Machinery,2020,https://doi.org/10.1145/3374549.3374577;http://dx.doi.org/10.1145/3374549.3374577,"Age-Related Macular Degeneration (AMD) is a leading retinal disease that causes vision loss affect people from age fifty five(55) and older. The disease is characterized by the formation of drusen or the yellow deposits containing lipids forming within the macula region of the eye. One of the various ways to diagnose AMD is through obtaining fundus photography using a specialized retinal camera. This study assesses the accuracy of the proposed methodology in recognizing AMD-positive fundus images using Digital Image Processing and various Machine Learning models such as Naïve Bayes (NB), Neural Network (NN), Support Vector Machine (SVM) and Random Forest (RF). The fundus images undergo intensity adjustment and bilateral filter it is then followed by optic disc extraction and Superpixel segmentation using Simple Linear Iterative Clustering. Features, such as Intensity-based statistics and Texton-map Histogram, are extracted and normalized. The resulting values are classified by various Machine Learning algorithms as positive or negative for AMD. The proposed methodology is able to determine Healthy and AMD-positive images while also providing accuracy comparison among Machine Learning models.","Simple Linear Iterative Clustering, Machine Learning, Bilateral Filtering, Macular Degeneration, Image Processing"
Conference Paper,"Joo Y,Lee S,Kim H,Kim P,Hwang S,Choi C",Efficient Healthcare Service Based on Stacking Ensemble,Association for Computing Machinery,2021,https://doi.org/10.1145/3440943.3444727;http://dx.doi.org/10.1145/3440943.3444727,"Recently, research using medical big data to predict patients with high probability of disease are receiving a lot of attention. Due to the advancement of artificial intelligence, continuous research is essential in that diseases can be predicted only by computational numbers and can be prevented before they occur. Therefore, machine learning and deep learning research using medical big data for disease prediction are actively progressing. Due to the nature of medical data, diseases are rare, so there is a tendency to oversampling or under sampling that can lead to information distortion. Also, given that most machine learning-based research is based on certain predictive models, there is a risk that the predictions themselves will reflect the biases that exist. So, if you generalize the data your model will train on, or adjust the model's bias, you can get better predictions. In this white paper, we use diabetes, heart disease, and breast cancer data through several individual classifiers to get predicted values and use them as training data for one meta-model to get the final predictions. That is, by constructing a stacking ensemble model, the presence or absence of a disease is predicted, and its performance is analysed through experiments. This model trains multiple classifiers on the same data, so there is a possibility that the model will overfit the data. So, when training multiple classifiers, we compare the model with and without cross validation. In the experiment, the model using cross-validation for training showed an average of 1.4% higher performance than that of the individual single model. On the other hand, the meta-model without cross-validation shows lower performance than that of individual single models. In other words, when constructing a stacking ensemble model, high performance could be obtained only by essentially cross-validating individual single classifiers. Performing one final prediction on the predicted values of high-performance individual models will yield more stable and reliable predictions. The cross-learning-based cumulative ensemble model proposed in this paper predicts the presence or absence of a disease and can be used for medical service development and disease prevention.","Health care, Overfitting, Ensemble Learning"
Conference Paper,"Hidalgo JI,Colmenar JM,Risco-Martín JL,Maqueda E,Botella M,Rubio JA,Cuesta-Infante A,Garnica O,Lanchares J",Clarke and Parkes Error Grid Analysis of Diabetic Glucose Models Obtained with Evolutionary Computation,Association for Computing Machinery,2014,https://doi.org/10.1145/2598394.2609856;http://dx.doi.org/10.1145/2598394.2609856,"Diabetes mellitus is a disease that affects to hundreds of millions of people worldwide. Maintaining a good control of the disease is critical to avoid severe long-term complications. In recent years, a lot of research has been made to improve the quality of life of the diabetic patient, especially in the automation of glucose level control. One of the main problems that arises in the (semi) automatic control of diabetes, is to obtain a model that explains the behavior of blood glucose levels with insulin, food intakes and other external factors, fitting the characteristics of each individual or patient. Recently, Grammatical Evolution (GE), has been proposed to solve this lack of models. A proposal based on GE was able to obtain customized models of five in-silico patient data with a mean percentage average error of 13.69%, modeling well also both hyper and hypoglycemic situations. In this paper we have extended the study of Error Grid Analysis (EGA) to prediction models in up to 8 in-silico patients. EGA is commonly used in Endocrinology to test the clinical significance of differences between measurements and real value of blood glucose, but has not been used before as a metric in obtention of glycemia models.","diabetes, grammatical evolution, modeling"
Conference Paper,"Intriago-Pazmiño M,Ibarra-Fiallo J,Alonso-Calvo R,Crespo J",Segmenting Retinal Vascular Net from Retinopathy of Prematurity Images Using Convolutional Neural Network,Association for Computing Machinery,2019,https://doi.org/10.1145/3368691.3368711;http://dx.doi.org/10.1145/3368691.3368711,"In this paper, we describe the experimentation with a convolutional neural network for segmenting retinal net from pathological fundus images of preterm born children. Segmenting retinal net from pathological fundus images is a fundamental task to aid computer diagnosis. We used U-net architecture for training and testing. Testing with ROPFI dataset, we obtained an area under the receiver operating curve equal to 0.9180; when average sensitivity is equal to 0.700, the average specificity is equal to 0.9710. This performance is higher than prior works using a similar dataset.","retinopathy of prematurity, medical image processing, convolutional neural network"
Conference Paper,"Yang Z,Zhou Y,Gong C",Diagnosis of Diabetes Based on Improved Support Vector Machine and Ensemble Learning,Association for Computing Machinery,2019,https://doi.org/10.1145/3319921.3319954;http://dx.doi.org/10.1145/3319921.3319954,"Diabetes is a complicated disease and a public health problem in the world. It has been shown that 50% of patients with diabetes in the world are not properly diagnosed. In this paper, a novel improved SVM based ensemble learning model is proposed for diagnosis of diabetes. Firstly, the given constraints reduction strategy are used to reduce the number of constraints in the classic SVM method. Secondly, the penalty method is used to transform the original problem into an unconstrained optimization problem. Then, the improved SVM results are obtained by gradient descent algorithm. Finally, an ensemble learning framework, which combines the improved SVM, logistic regression and CART is developed for diagnosis of diabetes. The results of experiment, which is carried out using the real-work datasets, show the proposed model outperforms other benchmark methods.","diabetes diagnosis, penalty method, support vector machine, ensemble learning"
Conference Paper,"Wedagu MA,Chen D,Hussain MA,Gebremeskel T,Orlando MT,Manzoor A",Medicine Recommendation System For Diabetes Using Prior Medical Knowledge,Association for Computing Machinery,2021,https://doi.org/10.1145/3448823.3448872;http://dx.doi.org/10.1145/3448823.3448872,"Medicine recommendation system could assist doctors in making an accurate diagnosis and predict medicine. According to CDC reports, more than 250,000 people die by medication error; for that matter, many deep learning models were previously proposed to solve the high order correlations of diabetic medicine for diabetic patients. However, they are failed to address the benefit of prior medical knowledge from experienced doctors. This study proposes a recommendation method called (Diabetes Medicine Recommendation System) DIMERS model, which combines a prior medical knowledge of doctors with bidirectional Long Short-Term Memory (BiLSTM). In this study, DIMERS, first, preprocesses general tests of diabetic patient test results and medicines with a complex data achievement strategy. After that, we use a weighted block with prior medical knowledge to enhance the learning and explainable abilities of deep neural networks (DNN). Our study's overall performance was excellent. We train and validate using the real world Ruijin hospital and drug bank datasets that contain 25,280 patients within three months gaps and 63 types of diabetes medicines.","Diabetes, Prior knowledge, Medicine recommendation"
Conference Paper,"Li Y,Cao W,Chang W,Zhou S,Zhang R",An XGBoost Risk Prediction Model of Cardiovascular and Cerebrovascular Diseases with Plateau Healthcare Dataset,Association for Computing Machinery,2023,https://doi.org/10.1145/3573834.3574558;http://dx.doi.org/10.1145/3573834.3574558,This paper aims to build an XGBoost risk prediction model of cardiovascular and cerebrovascular diseases (CVDs) with plateau healthcare dataset. The incidence of cardiovascular and cerebrovascular diseases is very high in plateau areas. And it is difficult to detect partly due to the high cost of professional test. It will have high practical value to build a model to predict the risk of cardiovascular and cerebrovascular diseases by using the common healthcare data (e.g. fundus data). The paper proposes an XGBoost prediction model of CVDs risk with the fundus disease and other healthcare data set. The influence of various fundus disease factors on cardiovascular and cerebrovascular diseases is analyzed in the study. The result suggests that the proposed XGBoost prediction model performs better in terms of accuracy and recall rate compared with other models.,"Healthcare Dataset, XGBoost, Prediction Model, CVDs"
Conference Paper,"Wei X,Jiang F,Wei F,Zhang J,Liao W,Cheng S",An Ensemble Model for Diabetes Diagnosis in Large-Scale and Imbalanced Dataset,Association for Computing Machinery,2017,https://doi.org/10.1145/3075564.3075576;http://dx.doi.org/10.1145/3075564.3075576,"Diabetes is becoming a more and more serious health challenge worldwide with the yearly rising prevalence, especially in developing countries. The vast majority of diabetes are type 2 diabetes, which has been indicated that about 80% of type 2 diabetes complications can be prevented or delayed by timely detection. In this paper, we propose an ensemble model to precisely diagnose the diabetic on a large-scale and imbalance dataset. The dataset used in our work covers millions of people from one province in China from 2009 to 2015, which is highly skew. Results on the real-world dataset prove that our method is promising for diabetes diagnosis with a high sensitivity, F3 and G --- mean, i.e, 91.00%, 58.24%, 86.69%, respectively.","Diabetes diagnosis, Ensemble model, Imbalanced data"
Journal Article,"Singh A,Dhillon A,Kumar N,Hossain MS,Muhammad G,Kumar M",EDiaPredict: An Ensemble-Based Framework for Diabetes Prediction,Association for Computing Machinery,2021,https://doi.org/10.1145/3415155;http://dx.doi.org/10.1145/3415155,"Medical systems incorporate modern computational intelligence in healthcare. Machine learning techniques are applied to predict the onset and reoccurrence of the disease, identify biomarkers for survivability analysis depending upon certain health conditions of the patient. Early prediction of diseases like diabetes is essential as the number of diabetic patients of all age groups is increasing rapidly. To identify underlying reasons for the onset of diabetes in its early stage has become a challenging task for medical practitioners. Continuously increasing diabetic patient data has necessitated for the applications of efficient machine learning algorithms, which learns from the trends of the underlying data and recognizes the critical conditions in patients. In this article, an ensemble-based framework named eDiaPredict is proposed. It uses ensemble modeling, which includes an ensemble of different machine learning algorithms comprising XGBoost, Random Forest, Support Vector Machine, Neural Network, and Decision tree to predict diabetes status among patients. The performance of eDiaPredict has been evaluated using various performance parameters like accuracy, sensitivity, specificity, Gini Index, precision, area under curve, area under convex hull, minimum error rate, and minimum weighted coefficient. The effectiveness of the proposed approach is shown by its application on the PIMA Indian diabetes dataset wherein an accuracy of 95% is achieved.","XGBoost, decision tree, random forest, Diabetes prediction, ensembled models"
Book,Not Found,IHM '22 Adjunct: Adjunct Proceedings of the 33rd Conference on l'Interaction Humain-Machine,Association for Computing Machinery,2022,Not Found,Not Found,Not Found
Conference Paper,"Chekh V,Luan Ssean,Burge M,Carranza C,Soliz P,McGrew E,Barriga S",Quantitative Early Detection of Diabetic Foot,Association for Computing Machinery,2013,https://doi.org/10.1145/2506583.2506598;http://dx.doi.org/10.1145/2506583.2506598,"Diabetes afflicts an estimated 171 million people worldwide. Diabetic patients are at risk of a wide range of complications including peripheral neuropathy (or diabetic foot). The condition if left untreated will lead to ulcers and eventually lower extremity amputation. Current existing diagnostic techniques for peripheral neuropathy are mostly qualitative procedures based on patient sensations and exhibit significant inter- and intra-observer differences, and an economical quantitative diagnostic technique is still lacking. A system for quantitative early detection of diabetic peripheral neuropathy has been developed based the thermal response of the feet of diabetic patients following cold stimulus. This paper describes the details of the new system, which includes the following key components: (1) A new protocol of using thermal imaging as functional imaging to measure thermal response. (2) Segmentation and tracking of regions of interest (ROIs) for thermal videos. (3) A novel bio-heat transfer model based on thermoregulation. We also report our preliminary patient studies based on two classifiers, which gave strong evidence that the system can used for early quantitative detection of peripheral neuropathy for diabetics.","Bio-heat Transfer, Thermal Regulation, Diabetic Foot, Image Processing, Peripheral Neuropathy, Region of Interest Tracking, Thermal Imaging"
Conference Paper,"Liu L,Tang J,Cheng Y,Agrawal A,Liao WK,Choudhary A",Mining Diabetes Complication and Treatment Patterns for Clinical Decision Support,Association for Computing Machinery,2013,https://doi.org/10.1145/2505515.2505549;http://dx.doi.org/10.1145/2505515.2505549,"The fast development of hospital information systems (HIS) produces a large volume of electronic medical records, which provides a comprehensive source for exploratory analysis and statistics to support clinical decision-making. In this paper, we investigate how to utilize the heterogeneous medical records to aid the clinical treatments of diabetes mellitus. Diabetes mellitus, simply diabetes, is a group of metabolic diseases, which is often accompanied with many complications. We propose a Symptom-Diagnosis-Treatment model to mine the diabetes complication patterns and to unveil the latent association mechanism between treatments and symptoms from large volume of electronic medical records. Furthermore, we study the demographic statistics of patient population w.r.t. complication patterns in real data and observe several interesting phenomena. The discovered complication and treatment patterns can help physicians better understand their specialty and learn previous experiences. Our experiments on a collection of one-year diabetes clinical records from a famous geriatric hospital demonstrate the effectiveness of our approaches.","clinical decision support, symptom, health care data mining, treatment, diabetes complication"
Conference Paper,"Gu Z,Jiang S,Lee J,Xie J,Cheng J,Liu J",Automatic Localization of Optic Disc Using Modified U-Net,Association for Computing Machinery,2018,https://doi.org/10.1145/3232651.3232671;http://dx.doi.org/10.1145/3232651.3232671,"The optic disc (OD) localization plays an important role in the automatic retinal image analysis for many applications such as glaucoma detection, macular localization, and retinal vessel analysis. In this paper, we propose a method based on U-net and Depth-First-Select Graph to accurately and efficiently locate the optic disc. The adopted U-net architecture is based on ResNet-50, and it predicts the center of OD and produces a probability map. Then based on the probability map, we use the Depth-First-Select algorithm to select the brightest and largest region, which is most likely to be the OD. The proposed method is evaluated on the ORIGA and Messidor dataset. Our experiment shows that the proposed method achieves 100% accuracy in ORIGA and 99.83% accuracy in Messidor. It outperforms other optic disc localization algorithms.","Retinal Image Analysis, Deep Learning, U-Net, Deep-First-Select"
Conference Paper,"Oumaima S,Soulaimane K,Omar B",Latest Trends in Recommender Systems Applied in the Medical Domain: A Systematic Review,Association for Computing Machinery,2020,https://doi.org/10.1145/3386723.3387860;http://dx.doi.org/10.1145/3386723.3387860,"Recommender systems use algorithms to provide users with product or service recommendations. In recent times, these systems have been using Artificial Intelligence algorithms. However, choosing a suitable AI algorithm for a recommender system is difficult because of the number of algorithms described in the literature. Researchers and practitioners developing recommender systems are left with little information about the current approaches in algorithm usage. Moreover, the development of recommender systems using AI algorithms often faces problems and raises questions that must be resolved. In this context developing recommender system in the medical domain are presented as complementary tools in decision-making processes in healthcare services, it allows to increase the usability of technologies and reduce information overload in processes. This paper presents a systematic review of the literature that analyze the use of AI algorithms in recommender system and identify new research opportunities.The goals of this study are to (i) identify latest trends in the use or research of AI algorithms in recommender system applied in the medical domain;(ii)identify open questions in the use or research of AI algorithms, and (iii)assist new researchers to position new research activity in this domain appropriately.","systematic review, recommender system, Collaborative Filtering, AI algorithms"
Conference Paper,"Guan H,Zhang C",Predicting Diabetes in Imbalanced Datasets Using Neural Networks,Association for Computing Machinery,2022,https://doi.org/10.1145/3535508.3545540;http://dx.doi.org/10.1145/3535508.3545540,"Diabetes is a long-standing disease caused by high blood sugar over a long period of time and one in every ten Americans has diabetes. The neural networks have gained attention in large-scale genetic research because of its ability in non-linear relationships. However, the data imbalance problem, which is caused by the disproportion between the number of disease samples and the number of healthy samples, will decrease the prediction accuracy. In this project, we tackle the data imbalance problem when predicting diabetes with genotype SNP data and phenotype data provided by UK BioBank. The dataset is highly skewed with healthy samples with the ratio of 20. We build a phenotype neural network and a genotype neural network, which uses two sampling techniques and a data augmentation method by generative adversarial neural network (GAN) to counter the data imbalance problem before feeding the data to the neural networks. We found out that the phenotype neural network outperforms the genotype neural network and achieves 90% accuracy. We reach the conclusion that undersampling performs better than both oversampling and the GAN, and the phenotype is better than the genotype in terms of predicting diabetes. We have identified key phenotype and genotype features that contributed to the effectiveness of the prediction.","undersampling, neural networks, generative adversarial neural networks, oversampling, imbalance datasets"
Journal Article,"Zhang Q,Bai C,Yang LT,Chen Z,Li P,Yu H",A Unified Smart Chinese Medicine Framework for Healthcare and Medical Services,IEEE Computer Society Press,2019,https://doi.org/10.1109/TCBB.2019.2914447;http://dx.doi.org/10.1109/TCBB.2019.2914447,"Smart Chinese medicine has emerged to contribute to the evolution of healthcare and medical services by applying machine learning together with advanced computing techniques like cloud computing to computer-aided diagnosis and treatment in the health engineering and informatics. Specifically, smart Chinese medicine is considered to have the potential to treat difficult and complicated diseases such as diabetes and cancers. Unfortunately, smart Chinese medicine has made very limited progress in the past few years. In this paper, we present a unified smart Chinese medicine framework based on the edge-cloud computing system. The objective of the framework is to achieve computer-aided syndrome differentiation and prescription recommendation, and thus to provide pervasive, personalized, and patient-centralized services in healthcare and medicine. To accomplish this objective, we integrate deep learning and deep reinforcement learning into the traditional Chinese medicine. Furthermore, we propose a multi-modal deep computation model for syndrome recognition that is a crucial part of syndrome differentiation. Finally, we conduct experiments to validate the proposed model by comparing with the staked auto-encoder and multi-modal deep learning model for syndrome recognition of hypertension and cold.",Not Found
Conference Paper,"Ding X,Jiang Y,Qin X,Chen Y,Zhang W,Qi L","Reading Face, Reading Health: Exploring Face Reading Technologies for Everyday Health",Association for Computing Machinery,2019,https://doi.org/10.1145/3290605.3300435;http://dx.doi.org/10.1145/3290605.3300435,"With the recent advancement in computer vision, Artificial Intelligence (AI), and mobile technologies, it has become technically feasible for computerized Face Reading Technologies (FRTs) to learn about one's health in everyday settings. However, how to design FRT-based applications for everyday health practices remains unexplored. This paper presents a design study with a technology probe called Faced, a mobile health checkup application based on the facial diagnosis method from Traditional Chinese Medicine (TCM). A field trial of Faced with 10 participants suggests potential usage modes and highlights a number of critical design issues in the use of FRTs for everyday health, including adaptability, practicality, sensitivity, and trustworthiness. We end by discussing design implications to address the unique challenges of fully integrating FRTs into everyday health practices.","health monitoring, health, face reading technologies, tcm, self care, traditional chinese medicine, facial diagnosis, wellbeing, everyday healthcare, design study"
Journal Article,"Su Z,He L,Jariwala SP,Zheng K,Chen Y","""What is Your Envisioned Future?"": Toward Human-AI Enrichment in Data Work of Asthma Care",Association for Computing Machinery,2022,https://doi.org/10.1145/3555157;http://dx.doi.org/10.1145/3555157,"Patient-generated health data (PGHD) is crucial for healthcare providers' decision making, as it complements clinical data by providing a more holistic view of patients' daily conditions. We interviewed 20 healthcare providers in asthma care to envision future technologies to support their PGHD use. We found that healthcare providers want future artificial intelligence (AI) systems to enhance their ability to treat patients by analyzing PGHD for profiling risk and predicting deterioration. Despite the potential benefits of AI, providers perceived various challenges of AI use with PGHD, including AI-driven data inequity, added burden, lack of trust toward AI, and fear of being replaced by AI. Clinicians wished for a future of co-dependent human-AI collaboration, where AI will help them to improve their clinical practice. In turn, healthcare providers can improve AI systems by making AI outputs more trustworthy and humane. Through the lens of data feminism, we discuss the importance of considering context and aligning the complex human infrastructure before designing or deploying PGHD-based AI systems in clinical settings. We highlight the opportunity to design for human-AI enrichment, where humans and AI not only partner with each other for improved performance, but also enrich each other to enhance each other's work overtime.","patient-generated health data, data work, future of work, health datafication, healthcare, human-AI interaction, human-AI collaboration"
Conference Paper,"Catimbang Magboo VP,Abad Magboo MS",Imputation Techniques and Recursive Feature Elimination in Machine Learning Applied to Type II Diabetes Classification,Association for Computing Machinery,2022,https://doi.org/10.1145/3508259.3508288;http://dx.doi.org/10.1145/3508259.3508288,"Type II diabetes is a chronic metabolic disease secondary to elevated blood glucose levels. Complications of this disease include heart attack, stroke, blindness, renal failure, lower limb amputation and mortality. Due to its rising prevalence and consequent mortality, it is important to identify at an early stage those patients at high risk of developing diabetes. We applied 8 machine learning techniques namely: support vector machine, logistic regression, k-nearest neighbor, naïve Bayes, decision tree, random forest, AdaBoost and XGBoost in predicting diabetes using a publicly available diabetes dataset. In our study, Naïve Bayes with median imputation and recursive feature elimination obtained the highest performance with an accuracy rate of 81.0%. Although the results are very promising, one major limitation in this study is the small number of samples in the dataset. Early accurate detection can help patients to proactively monitor their lifestyle habits mitigating the risks of complications of uncontrolled diabetes.",Not Found
Conference Paper,"Meng H,Lin Z,Yang F,Xu Y,Cui L",Knowledge Distillation In Medical Data Mining: A Survey,Association for Computing Machinery,2022,https://doi.org/10.1145/3503181.3503211;http://dx.doi.org/10.1145/3503181.3503211,"In recent years, there have always been many problems in the medical field, such as a shortage of professionals and a shortage of medical resources. With the application of machine learning in the medical field, these problems have been alleviated to a certain extent, but these machine learning methods also have shortcomings, such as models are often too large to be deployed on lightweight equipment, and medical data sets are difficult to share, Many researchers have put forward many methods, and knowledge distillation is one of them. As a model compression and acceleration technology, knowledge distillation has been widely used in the medical field. The research of many researchers also shows that the use of knowledge distillation can effectively compress huge and complex models and improve the performance of models. Many studies show that the use of knowledge distillation can effectively solve many problems existing in models in the medical field, Aiming at the various applications of knowledge distillation in the medical field, this paper makes a comprehensive review from the perspectives of knowledge distillation, the problems that knowledge distillation can solve in the medical field and the practical application of knowledge distillation.","Model compression, Knowledge distillation, Medical image classification, Medical diagnosis"
Conference Paper,Miao Y,Using Machine Learning Algorithms to Predict Diabetes Mellitus Based on PIMA Indians Diabetes Dataset,Association for Computing Machinery,2021,https://doi.org/10.1145/3463914.3463922;http://dx.doi.org/10.1145/3463914.3463922,"Currently, there are still a great amount of people suffering from diabetes mellitus (DM). Although advanced facilities and technologies could support the diagnosis of diabetes, complicated procedures are not supposed to be neglected. Actually, the causes of diabetes are various, involving glucose, blood pressure, skin thickness, insulin, BMI and age. Hence, in this study, a variety of machine learning algorithms are applied on PIMA Indians Diabetes dataset (PIDD) to construct the prediction model with higher accuracy. Once the model could be trained with better accuracy, it is possible to diagnose diabetes or even other ailments in the future. According to the results of this research, glucose, insulin and BMI have a higher correlation with diabetes. By comparison, the support vector machine (SVM) will obtain the highest accuracy of 85.06% based on the standardized data. After adjustment, this SVM still predicts the diagnosis of DM with the highest accuracy of 87.01%. In this paper, it seems that the Support Vector Classifier is demonstrated to obtain the highest accuracy for PIMA Indians Diabetes dataset (PIDD).","medical diagnosis, PIMA Indians Diabetes dataset, KNN, SVM, Logistic Regression, Machine learning"
Conference Paper,"Daanouni O,Cherradi B,Tmiri A",Predicting Diabetes Diseases Using Mixed Data and Supervised Machine Learning Algorithms,Association for Computing Machinery,2019,https://doi.org/10.1145/3368756.3369072;http://dx.doi.org/10.1145/3368756.3369072,"Diabetes is considered as one of the deadliest and chronic diseases in several countries. All of them are working to prevent this disease at early stage by diagnosing and predicting the symptoms of diabetes using several methods. The motive of this study is to compare the performance of some Machine Learning algorithms, used to predict type 2 diabetes diseases. In this paper, we apply and evaluate four Machine Learning algorithms (Decision Tree, K-Nearest Neighbours, Artificial Neural Network and Deep Neural Network) to predict patients with or without type 2 diabetes mellitus. These techniques have been trained and tested on two diabetes databases: The first obtained from Frankfurt hospital (Germany), and the second is the well-known Pima Indian dataset. These datasets contain the same features composed of mixed data; risk factors and some clinical data. The performances of the experimented algorithms have been evaluated in both the cases i.e. dataset with noisy data (before pre-processing/some data with missing values) and dataset set without noisy data (after preprocessing). The results compared using different similarity metrics like Accuracy, Sensitivity, and Specificity gives best performance with respect to state of the art.","deep learning, prediction systems, diabetes diseases, machine learning, computer aided diagnosis (CAD)"
Conference Paper,"M. Saleh E,Elakeili S,Sallabi O,Elmajpri H",Rule-Based Expert System for Diagnosing Common Childhood Illnesses: Smartphone App to Assist in Curbing the Spread of COVID-19,Association for Computing Machinery,2021,https://doi.org/10.1145/3492547.3492609;http://dx.doi.org/10.1145/3492547.3492609,"Since the World Health Organization declared the COVID-19 outbreak a global pandemic, constraints on face-to-face clinical consultation have become more challenging to implement in healthcare institutions. In common childhood illnesses, inexperienced parents may have difficulties determining whether a child is in a severe condition that requires hospitalization, thus increasing the risk of catching the Coronavirus. During the current COVID-19 pandemic, information technologies play a significant role in maintaining social distancing, such as telemedicine applications. Developing expert systems using Artificial Intelligence techniques can substitute experts (doctors) for remote patient consultation and care in the medical field. This paper discusses the design and implementation of a Rule-Base Expert system based on a mobile application on the Android platform, a healthcare expert system for diagnosing common childhood illnesses. The proposed application acts as an intelligent medical assistant, providing remote medical consultations and detecting emergencies for pediatric patients undergoing treatment in areas where medical services are limited or curfew. The proposed application asks a series of questions regarding a group of frequent symptoms in children's diseases, the inference engine generates instant recommendations for performing specific basic medical treatment steps when necessary. The proposed approach is applicable, effective, and efficient when comparing the application's diagnostic results with a physician's diagnosis on pediatric patients.","Telemedicine Applications, Expert System, Mobile Computing, COVID-19 Pandemic, Childhood Illnesses, Forward Chaining, Artificial Intelligence"
Conference Paper,"Li K,Yao Z,Luo Y,Qi X,Liu P,Wang Z",Retinal Blood Vessel Segmentation via Attention Gate Network,Association for Computing Machinery,2020,https://doi.org/10.1145/3429889.3429936;http://dx.doi.org/10.1145/3429889.3429936,"Automatic retinal vessel segmentation is a challenging problem in the clinical diagnosis of eye diseases. Accurate segmentation of retinal vessel can efficiently assist the physicians to make a more precise symptom detection. However, there are various shapes and sizes, complex backgrounds and noise in the retinal vessel images. To address these problems, in this paper, we design an attention gate network to model long-range dependencies and capture rich contextual information. Specifically, we adopt an attention gate module, which includes a spatial attention module to model spatial long-range contextual information. Moreover, to improve the contrast of original retinal fundus images, we employ green channel extraction and contrast limited adaptive histogram equalization as pre-processing steps. Experiments on the DRIVE and STARE show the proposed AGNET achieves the outstanding performance with 0.8247/0.8361 sensitivity, 0.9871/0.9899 specificity, 0.9764/0.9791 accuracy, and 0.9881/0.9928 AUC respectively.","Retinal vessel segmentation, attention mechanism, deep learning, semantic segmentation"
Conference Paper,"Tian P,Guo Y,Kalpathy-Cramer J,Ostmo S,Campbell JP,Chiang MF,Dy J,Erdogmus D,Ioannidis S",A Severity Score for Retinopathy of Prematurity,Association for Computing Machinery,2019,https://doi.org/10.1145/3292500.3330713;http://dx.doi.org/10.1145/3292500.3330713,"Retinopathy of Prematurity (ROP) is a leading cause for childhood blindness worldwide. An automated ROP detection system could significantly improve the chance of a child receiving proper diagnosis and treatment. We propose a means of producing a continuous severity score in an automated fashion, regressed from both (a) diagnostic class labels as well as (b) comparison outcomes. Our generative model combines the two sources, and successfully addresses inherent variability in diagnostic outcomes. In particular, our method exhibits an excellent predictive performance of both diagnostic and comparison outcomes over a broad array of metrics, including AUC, precision, and recall.","learning from comparisons, retinopathy of prematurity, bradley-terry model, classification"
Conference Paper,Yang W,SF-U-Net: Using Accurate Shape Estimation and Feature Restoration to Improve Retinal Vessel Segmentation,Association for Computing Machinery,2021,https://doi.org/10.1145/3471287.3471377;http://dx.doi.org/10.1145/3471287.3471377,"The features of retinal blood vessels are very essential indicators playing an important part in the process of judging and diagnosing the eye diseases for doctors. Sometimes, these features can also be the indicators for the examination of hypertension, coronary heart disease and diabetes. However, retinal blood vessels are often very small and complex in distribution, which brings toughness to the doctors when doing the operations of the segmentation of retinal blood vessels. Although the deep learning manners represented by U-Net has performed very well in the field of the segmentation of the images of the retinal blood vessel in recent years, the above-mentioned inconvenience still cannot be effectively settled. For the purpose of improving the correct rate of the segmentation and settling the above-mentioned inconvenience we propose a network called SF-U-Net, which uses accurate shape estimation and feature restoration to achieve the improvement of the accuracy. We follow the structure of Fully Convolutional Networks (FCN) and Skip Connection of U-Net and use deformable convolution to accurately capture the shape of blood vessels when extracting features at the coding layer to overcome the problem of complex blood vessel distribution. At the decoding layer, we adopt a novel dual-stream up-sampling method to achieve accurate feature restoration. Experimental results show that our SF-U-Net is capable of improving the segmentation results of retinal blood vessels conspicuously. In the experiment, we use both fundus image datasets called DRIVE and CHASE-DB1 and the experimental results of multiple indicators on them surpass other deep-learning methods significantly. The experimental results of the SF-U-Net model on a variety of indicators on DRIVE dataset exceed the experimental performances of the currently most advanced methods. The mean accuracy is 0.9602 the area under the curve (AUC) is 0.9848 and the sensitivity is 0.8567.","Fundus Image Processing, Retinal Blood Vessel Segmentation"
Conference Paper,"George M,Chacko A,Kurien SK",Proactive Diabetes Management: Research Directions,Association for Computing Machinery,2019,https://doi.org/10.1145/3288599.3297119;http://dx.doi.org/10.1145/3288599.3297119,"More than 200 million people across the globe are affected by Diabetes Mellitus (DM), which is one of the most common endocrine disorders. DM progression is dangerous as it leads to several life-threatening complications within 5--15 years of onset, depending on the care and management that they receive for DM. Hence, it is important for the public and healthcare policymakers to look proactively at managing the onset of the disease and delay associated complications as far as possible. Proactive management would result in significant reductions in the healthcare expenses. The fight against DM is multidisciplinary and research-oriented. Computer and data scientists can collaborate with medical researchers to augment research and management by using the power of big data analytics, machine learning, IoT (Internet of Things), and cloud computing. Computing principles and techniques can be used to efficiently collect, manage, and analyse data to derive meaningful insights, which can then be used for efficient management of the health concerns of patients. This paper describes the need for diabetes management and reviews technological interventions and related research directions in proactive diabetes management.","diabetes mellitus, electronic health record (EHR), genomics, interoperability, big data analytics"
Conference Paper,"Chakraborty P,Farooq F",A Robust Framework for Accelerated Outcome-Driven Risk Factor Identification from EHR,Association for Computing Machinery,2019,https://doi.org/10.1145/3292500.3330718;http://dx.doi.org/10.1145/3292500.3330718,"Electronic Health Records (EHR) containing longitudinal information about millions of patient lives are increasingly being utilized by organizations across the healthcare spectrum. Studies on EHR data have enabled real world applications like understanding of disease progression, outcomes analysis, and comparative effectiveness research. However, often every study is independently commissioned, data is gathered by surveys or specifically purchased per study by a long and often painful process. This is followed by an arduous repetitive cycle of analysis, model building, and generation of insights. This process can take anywhere between 1 - 3 years. In this paper, we present a robust end-to-end machine learning based SaaS system to perform analysis on a very large EHR dataset. The framework consists of a proprietary EHR datamart spanning 55 million patient lives in USA and over 20 billion data points. To the best of our knowledge, this framework is the largest in the industry to analyze medical records at this scale, with such efficacy and ease. We developed an end-to-end ML framework with carefully chosen components to support EHR analysis at scale and suitable for further downstream clinical analysis. Specifically, it consists of a ridge regularized Survival Support Vector Machine (SSVM) with a clinical kernel, coupled with Chi-square distance-based feature selection, to uncover relevant risk factors by exploiting the weak correlations in EHR. Our results on multiple real use cases indicate that the framework identifies relevant factors effectively without expert supervision. The framework is stable, generalizable over outcomes, and also found to contribute to better out-of-bound prediction over known expert features. Importantly, the ML methodologies used are interpretable which is critical for acceptance of our system in the targeted user base. With the system being operational, all of these studies were completed within a time frame of 3-4 weeks compared to the industry standard 12-36 months. As such our system can accelerate analysis and discovery, result in better ROI due to reduced investments as well as quicker turn around of studies.","electronic health records, ml in health, risk analysis, health ai, health informatics"
Conference Paper,"Saha A,Saha A,Mittra T",Performance Measurements of Machine Learning Approaches for Prediction and Diagnosis of Chronic Kidney Disease (CKD),Association for Computing Machinery,2019,https://doi.org/10.1145/3348445.3348462;http://dx.doi.org/10.1145/3348445.3348462,"Chronic Kidney Disease (CKD) is indicated by gradual degradation of kidney function. Long time complications include heart disease, high blood pressure, bone disease and death of hundreds and thousands of people each year. However, automated early detection of this disease can diminish the mortality rate. More efficient and accurate analysis and models are mandatory to be implemented to negotiate with this situation. To do so, this paper analyzes the key parameters of this disease to be strengthened by incorporating machine learning and data mining approaches together. For early classification of this disease Random Forest, Naïve Bayes, Multilayer Perceptron, Logistic Regression and Neural Network optimized by Adam optimizer have been concentrated on. For further statistical analysis and induction of relationships between attributes, J48 and WEKA tool have been used. Moreover, association rules have been extracted to assist expertise to diagnose this disease. Comparative analysis and experiment depict that Adam-Deep learning outperforms all the approaches by predicting accuracy of 97.34% and J48 demonstrates accurate association rules.","blood glucose level, association rules, Deep Neural Network (DNN), J48, multilayer perceptron, Chronic Kidney Disease (CKD)"
Conference Paper,"Bachiller Y,Busch P,Kavakli M,Hamey L",Survey: Big Data Application in Biomedical Research,Association for Computing Machinery,2018,https://doi.org/10.1145/3192975.3192986;http://dx.doi.org/10.1145/3192975.3192986,"In recent years, the emergence of diverse applications created a plethora of data and immense sources that can be applied in varying areas of the industry worldwide escalating its capabilities including biomedicine. Subsequently, analytical tools loomed to leverage the availability of massive data to analyze and elicit meaningful information to improve biomedical research and enhance healthcare systems. Algorithms applied in these analytical tools supplements the prognosis of diseases and personalized treatment of fatal diseases. This survey will evaluate algorithms used in bio medical research for personalized precision medicine, dissect the characteristics that made breakthrough in improving the efficiency of the analytical tool and identify the possible applicability in other diseases. It will focus on the machine learning and deep learning algorithms, both supervised and unsupervised that is applied in terminal diseases.","disease diagnosis, biomedicine, machine learning, Big data, deep learning, algorithms"
Conference Paper,"Wang D,Yang Q,Abdul A,Lim BY",Designing Theory-Driven User-Centric Explainable AI,Association for Computing Machinery,2019,https://doi.org/10.1145/3290605.3300831;http://dx.doi.org/10.1145/3290605.3300831,"From healthcare to criminal justice, artificial intelligence (AI) is increasingly supporting high-consequence human decisions. This has spurred the field of explainable AI (XAI). This paper seeks to strengthen empirical application-specific investigations of XAI by exploring theoretical underpinnings of human decision making, drawing from the fields of philosophy and psychology. In this paper, we propose a conceptual framework for building human-centered, decision-theory-driven XAI based on an extensive review across these fields. Drawing on this framework, we identify pathways along which human cognitive patterns drives needs for building XAI and how XAI can mitigate common cognitive biases. We then put this framework into practice by designing and implementing an explainable clinical diagnostic tool for intensive care phenotyping and conducting a co-design exercise with clinicians. Thereafter, we draw insights into how this framework bridges algorithm-generated explanations and human decision-making theories. Finally, we discuss implications for XAI design and development.","intelligibility, explanations, explainable artificial intelligence, decision making, clinical decision making"
Conference Paper,"Liang Z,Liu H,Zhao X,Yu L",Segmentation of Retinal Vessels Based on DenseNet-Attention-Unet Model Network,Association for Computing Machinery,2020,https://doi.org/10.1145/3411016.3411167;http://dx.doi.org/10.1145/3411016.3411167,"The feature information of retinal vascular image is complex. There are some problems in the existing algorithms, such as poor segmentation effect of microvascular segmentation and pathological vascular misclassification. Therefore, a vascular segmentation model based on DenseNet-Attention-unet (DA-Unet) is proposed. Firstly, retinal blood vessels were enhanced by adaptive histogram equalization and gamma correction, and then the DA-Unet model was constructed by DenseNet, Convolutional Block Attention Module and U-Net for retinal blood vessel segmentation.The experimental results show that the average accuracy of retinal vascular segmentation is 97.01%, and the ROC is 98.65%, when it was tested on the DRIVE data set.","DenseNet, U-net, Retinal blood vessels segmentation, Convolutional Block Attention Module"
Conference Paper,"Sha Y,Wang MD",Interpretable Predictions of Clinical Outcomes with An Attention-Based Recurrent Neural Network,Association for Computing Machinery,2017,https://doi.org/10.1145/3107411.3107445;http://dx.doi.org/10.1145/3107411.3107445,"The increasing accumulation of healthcare data provides researchers with ample opportunities to build machine learning approaches for clinical decision support and to improve the quality of health care. Several studies have developed conventional machine learning approaches that rely heavily on manual feature engineering and result in task-specific models for health care. In contrast, healthcare researchers have begun to use deep learning, which has emerged as a revolutionary machine learning technique that obviates manual feature engineering but still achieves impressive results in research fields such as image classification. However, few of them have addressed the lack of the interpretability of deep learning models although interpretability is essential for the successful adoption of machine learning approaches by healthcare communities. In addition, the unique characteristics of healthcare data such as high dimensionality and temporal dependencies pose challenges for building models on healthcare data. To address these challenges, we develop a gated recurrent unit-based recurrent neural network with hierarchical attention for mortality prediction, and then, using the diagnostic codes from the Medical Information Mart for Intensive Care, we evaluate the model. We find that the prediction accuracy of the model outperforms baseline models and demonstrate the interpretability of the model in visualizations.","recurrent neural networks, deep learning, visualization, electronic health records, health care, attention, interpretability"
Journal Article,"Nakandala S,Kumar A,Papakonstantinou Y",Query Optimization for Faster Deep CNN Explanations,Association for Computing Machinery,2020,https://doi.org/10.1145/3422648.3422663;http://dx.doi.org/10.1145/3422648.3422663,"Deep Convolutional Neural Networks (CNNs) now match human accuracy in many image prediction tasks, resulting in a growing adoption in e-commerce, radiology, and other domains. Naturally, ""explaining"" CNN predictions is a key concern for many users. Since the internal workings of CNNs are unintuitive for most users, occlusion-based explanations (OBE) are popular for understanding which parts of an image matter most for a prediction. One occludes a region of the image using a patch and moves it around to produce a heatmap of changes to the prediction probability. This approach is computationally expensive due to the large number of re-inference requests produced, which wastes time and raises resource costs. We tackle this issue by casting the OBE task as a new instance of the classical incremental view maintenance problem. We create a novel and comprehensive algebraic framework for incremental CNN inference combining materialized views with multi-query optimization to reduce computational costs. We then present two novel approximate inference optimizations that exploit the semantics of CNNs and the OBE task to further reduce runtimes. We prototype our ideas in a tool we call Krypton. Experiments with real data and CNNs show that Krypton reduces runtimes by up to 5x (resp. 35x) to produce exact (resp. high-quality approximate) results without raising resource requirements.",Not Found
Journal Article,"Kaptein F,Kiefer B,Cully A,Celiktutan O,Bierman B,Rijgersberg-peters R,Broekens J,Van Vught W,Van Bekkum M,Demiris Y,Neerincx MA","A Cloud-Based Robot System for Long-Term Interaction: Principles, Implementation, Lessons Learned",Association for Computing Machinery,2021,https://doi.org/10.1145/3481585;http://dx.doi.org/10.1145/3481585,"Making the transition to long-term interaction with social-robot systems has been identified as one of the main challenges in human-robot interaction. This article identifies four design principles to address this challenge and applies them in a real-world implementation: cloud-based robot control, a modular design, one common knowledge base for all applications, and hybrid artificial intelligence for decision making and reasoning. The control architecture for this robot includes a common Knowledge-base (ontologies), Data-base, “Hybrid Artificial Brain” (dialogue manager, action selection and explainable AI), Activities Centre (Timeline, Quiz, Break and Sort, Memory, Tip of the Day, ( ldots ) ), Embodied Conversational Agent (ECA, i.e., robot and avatar), and Dashboards (for authoring and monitoring the interaction). Further, the ECA is integrated with an expandable set of (mobile) health applications. The resulting system is a Personal Assistant for a healthy Lifestyle (PAL), which supports diabetic children with self-management and educates them on health-related issues (48 children, aged 6–14, recruited via hospitals in the Netherlands and in Italy). It is capable of autonomous interaction “in the wild” for prolonged periods of time without the need for a “Wizard-of-Oz” (up until 6 months online). PAL is an exemplary system that provides personalised, stable and diverse, long-term human-robot interaction.","Cloud-based robots, pervasive lifestyle support, conversational agents, long-term human-robot interaction"
Conference Paper,"Prosperi M,Ghosh S,Chen Z,Salemi M,Lyu T,Zhao J,Bian J",Causal AI with Real World Data: Do Statins Protect from Alzheimer's Disease Onset?,Association for Computing Machinery,2021,https://doi.org/10.1145/3472813.3473206;http://dx.doi.org/10.1145/3472813.3473206,"Causal artificial intelligence aims at developing bias-robust models that can be used to intervene on, rather than just be predictive, of risks or outcomes. However, learning interventional models from observational data, including electronic health records (EHR), is challenging due to inherent bias, e.g., protopathic, confounding, collider. When estimating the effects of treatment interventions, classical approaches like propensity score matching are often used, but they pose limitations with large feature sets, nonlinear/nonparallel treatment group assignments, and collider bias. In this work, we used data from a large EHR consortium –OneFlorida– and evaluated causal statistical/machine learning methods for determining the effect of statin treatment on the risk of Alzheimer's disease, a debated clinical research question. We introduced a combination of directed acyclic graph (DAG) learning and comparison with expert's design, with calculation of the generalized adjustment criterion (GAC), to find an optimal set of covariates for estimation of treatment effects –ameliorating collider bias. The DAG/CAC approach was assessed together with traditional propensity score matching, inverse probability weighting, virtual-twin/counterfactual random forests, and deep counterfactual networks. We showed large heterogeneity in effect estimates upon different model configurations. Our results did not exclude a protective effect of statins, where the DAG/GAC point estimate aligned with the maximum credibility estimate, although the 95% credibility interval included a null effect, warranting further studies and replication.","Bayesian network, directed acyclic graph, generalized adjustment criterion, biomedical informatics, electronic medical records, treatment effect, machine learning, Causal artificial intelligence"
Journal Article,"Sun Z,Dong W,Shi J,He K,Huang Z",Attention-Based Deep Recurrent Model for Survival Prediction,Association for Computing Machinery,2021,https://doi.org/10.1145/3466782;http://dx.doi.org/10.1145/3466782,"Survival analysis exhibits profound effects on health service management. Traditional approaches for survival analysis have a pre-assumption on the time-to-event probability distribution and seldom consider sequential visits of patients on medical facilities. Although recent studies leverage the merits of deep learning techniques to capture non-linear features and long-term dependencies within multiple visits for survival analysis, the lack of interpretability prevents deep learning models from being applied to clinical practice. To address this challenge, this article proposes a novel attention-based deep recurrent model, named AttenSurv, for clinical survival analysis. Specifically, a global attention mechanism is proposed to extract essential/critical risk factors for interpretability improvement. Thereafter, Bi-directional Long Short-Term Memory is employed to capture the long-term dependency on data from a series of visits of patients. To further improve both the prediction performance and the interpretability of the proposed model, we propose another model, named GNNAttenSurv, by incorporating a graph neural network into AttenSurv, to extract the latent correlations between risk factors. We validated our solution on three public follow-up datasets and two electronic health record datasets. The results demonstrated that our proposed models yielded consistent improvement compared to the state-of-the-art baselines on survival analysis.","graph neural network, global attention mechanism, deep learning, Survival analysis, risk factor identification"
Conference Paper,"Wang Z,Tian S,Fu X,He J",An Effective Image Enhancement Method for Color Fundus Images,Association for Computing Machinery,2022,https://doi.org/10.1145/3508546.3508589;http://dx.doi.org/10.1145/3508546.3508589,"A method is proposed for adaptive fundus image enhancement so as to restore the color images that are with extremely low or nonuniform brightness. Our proposed method is capable of increasing the brightness, contrast of images without losing original color hue. It includes three steps: luminance enhancement, contrast improvement, and color restoration. All procedures are adapted and modified from conventional image processing algorithms, which are proved simple and less time-consuming. Two public and commonly used fundus image database were partially employed to evaluate the performance of our method. It is concluded that the brightness of images was enhanced by 86.35 % and the contrast was improved by 132.37 % without color distortion.","Fundus angiography, Image restoration, contrast enhancement, Biomedical imaging algorithms"
Conference Paper,"Pagan R,ElAarag H",Diabetic Assistant Tool,Association for Computing Machinery,2018,https://doi.org/10.1145/3190645.3190646;http://dx.doi.org/10.1145/3190645.3190646,"In this paper, we present the Diabetic Assistant Tool, a web application developed using the Vue framework. The application, as the name suggests, assists diabetics in maintaining a healthy lifestyle. The tool uses modern designs and gives the users features that have been requested for many years, an easy to use and pleasant to the eye package. The Diabetic Assistant Tool application differentiates itself from other such applications by simplifying the interface and only giving the user information they need in a clear and simple way.",Not Found
Conference Paper,"Choi J,Chang SJ,Bang JH,Park JS,Lee HR",The Miniaturized IoT Electronic Nose Device and Sensor Data Collection System for Health Screening by Volatile Organic Compounds Detection from Exhaled Breath,Association for Computing Machinery,2018,https://doi.org/10.1145/3287921.3287943;http://dx.doi.org/10.1145/3287921.3287943,"The recent convergence of ICT technology and biotechnology has led to an increasing number of areas in which machines take over what people do. The small sized medical electronic devices easily check health condition by simple test and confirm whether the bio signals are abnormal to advise medical treatment in the hospital. The role of such health screening devices is not to diagnose the disease precisely but to check bio-signal roughly. The conventional health screening devices pick blood sample to detect amount of specific component in blood but invasive blood sampling is painful and burdensome to the patient. Breath analysis is a technique that provides comfortable and easy health screening method unlike conventional techniques because it is non-invasive. However, it is difficult for people to use it because of its complex breath sampling procedures, huge system volume, and sensitive characteristics of gas sensors. We designed a smartphone-sized miniaturized electronic nose system and constructed database system to derive novel rules from various multi-sensors data. The experiment was conducted by applying the electronic nose system to actual diabetic patients and we confirmed the possibility of distinguishing the diseases had. If big data is collected, various artificial intelligence algorithms will be applied to find more accurate health screening methods.","Internet of Things, Breath Analysis, Electronics nose, Health screening"
Conference Paper,"Deepak KS,Joshi GD,Sivaswamy J",Content-Based Retrieval of Retinal Images for Maculopathy,Association for Computing Machinery,2010,https://doi.org/10.1145/1882992.1883013;http://dx.doi.org/10.1145/1882992.1883013,"A growing number of public initiatives for screening the population for retinal disorders along with widespread availability of digital fundus (retina) cameras is leading to large accumulation of color fundus images. The ability to retrieve images based on pathologic state is a powerful functionality that has wide applications in evidence-based medicine, automated computer assisted diagnosis and in training ophthalmologists. In this paper, we propose a new methodology for content-based retrieval of retinal images showing symptoms of maculopathy. Taking the view of a disease region as one which exhibits deviation from the normal image background, a model for the image background is learnt and used to extract disease-affected image regions. These are then analysed to assess the severity level of maculopathy. Symmetry-based descriptor is derived for the macula region and employed for retrieval of images according to severity of maculopathy. The proposed approach has been tested on a publicly available dataset. The results show that background learning is successful as images with or no maculopathy are detected with a mean precision of 0.98. An aggregate precision of 0.89 is achieved for retrieval of images at three severity-levels of macular edema, demonstrating the potential offered by the proposed disease-based retrieval system.","maculopathy, retinal image, diabetic retinopathy, image background learning, image retrieval"
Journal Article,"Jin Z,Cui S,Guo S,Gotz D,Sun J,Cao N",CarePre: An Intelligent Clinical Decision Assistance System,Association for Computing Machinery,2020,https://doi.org/10.1145/3344258;http://dx.doi.org/10.1145/3344258,"Clinical decision support systems are widely used to assist with medical decision making. However, clinical decision support systems typically require manually curated rules and other data that are difficult to maintain and keep up to date. Recent systems leverage advanced deep learning techniques and electronic health records to provide a more timely and precise result. Many of these techniques have been developed with a common focus on predicting upcoming medical events. However, although the prediction results from these approaches are promising, their value is limited by their lack of interpretability. To address this challenge, we introduce CarePre, an intelligent clinical decision assistance system. The system extends a state-of-the-art deep learning model to predict upcoming diagnosis events for a focal patient based on his or her historical medical records. The system includes an interactive framework together with intuitive visualizations designed to support diagnosis, treatment outcome analysis, and the interpretation of the analysis results. We demonstrate the effectiveness and usefulness of the CarePre system by reporting results from a quantities evaluation of the prediction algorithm, two case studies, and interviews with senior physicians and pulmonologists.","reasoning about belief and knowledge, user interface design, Personal health records, visual analytics, neural networks"
Conference Paper,"Erandathi MA,Wang WY,Mayo M",Predicting Diabetes Mellitus and Its Complications through a Graph-Based Risk Scoring System,Association for Computing Machinery,2020,https://doi.org/10.1145/3418094.3418115;http://dx.doi.org/10.1145/3418094.3418115,"It is vital to estimate and predict the chronological risk rate of individuals of diabetes mellitus and its complications through non-invasive or minimally invasive methods. Data mining and machine learning techniques are applied to health data repositories to achieve this goal. Although past studies have used various combinations of technologies for the assessment and prediction of diabetes and its complications, there is a lack of attention to combining temporal data with a visual representation assessment technique, which can be widely accepted. Further, prediction of risk throughout the lifetime of an individual in a chronological manner by considering their future changes with respect to the characteristics of a similar cohort is something worth contemplating for accurate risk prediction models. We aim to introduce a simple, powerful visualization technique to self-monitoring, which will be highly beneficial in enhancing the health care management sector through empowering self-care management and policymaking. The system will effectively impact the progression of diabetes and its complications by early forecasting the risk without the aid of professional physician knowledge which would help to reduce the burden of the disease while saving the expenditures of diabetes mellitus.","Complications of Diabetes, Prediction, Diabetes Mellitus, Risk scoring system"
Conference Paper,"Shi Z,Wang T,Xie F,Huang Z,Zheng X,Zhang W",MSU-Net: A Multi-Scale U-Net for Retinal Vessel Segmentation,Association for Computing Machinery,2020,https://doi.org/10.1145/3429889.3430295;http://dx.doi.org/10.1145/3429889.3430295,"Retinal vessel segmentation is widely used in the diagnosis of eye diseases, and the effect of segmentation plays a crucial role in whether doctors can correctly diagnose diseases. To further improve the accuracy of the automatic segmentation method, a network structure named Multi-Scale U-Net (MSU-Net) based on deep learning is proposed in this paper. The network combines Atrous Spatial Pyramid Pooling (ASPP) module to extract multi-scale information, making the U-Net more suitable for segmentation of complex and changeable vessel structures. We evaluate the network on two public databases, DRIVE and STARE. The Accuracy (ACC), Sensitivity (SEN), Specificity (SPE) and Dice coefficient on the DRIVE database are 0.9667, 0.8159, 0.9805 and 0.8059, respectively. These indicators are respectively 0.9732, 0.8272, 0.9866 and 0.8400 on the STARE database. Experiments show that the network has excellent segmentation results, and has state-of-the-art performance indicators on the STARE database, which fully proves the outstanding performance of the network.","Image processing, Deep learning, Retinal vessel segmentation, Fundus image, Convolutional neural network"
Conference Paper,Yousefi Y,Data Sharing as a Debiasing Measure for AI Systems in Healthcare: New Legal Basis,Association for Computing Machinery,2022,https://doi.org/10.1145/3560107.3560116;http://dx.doi.org/10.1145/3560107.3560116,"Healthcare data sharing is increasing through platforms devoted to the collection of personal health data; due to the sensitive nature of healthcare data, and the sensitivity of personal data in data protection law, ethical challenges are posed for the disclosure and sharing of healthcare data even in scientific research. However, if data sharing can be implemented as a debiasing measure to improve Machine Learning (ML) systems used in healthcare, the sharing and processing of sensitive healthcare data might pose as a solution most stakeholders seek. The questions regarding data sharing involve the balance we need, between protection of privacy and improving systems from biases; in other words, balancing individual versus collective rights. After the proposal for a regulation on the European Health Data Space (EHDS), the new legal basis for data sharing in the recently approved Data Governance Act (DGA) followed by the Data Act proposal, and with the provisions in the Artificial Intelligence Act (AIA), data sharing might take a different turn. This article examines the new legal basis for data sharing as a debiasing measure to improve Artificial Intelligence (AI) systems in healthcare.","Ethical Data Sharing, Big Data, Automated Discrimination, Healthcare Bias"
Conference Paper,"Festin PJ,Cortez RS,Villaverde JF",Non-Invasive Detection of Diabetes Mellitus by Tongue Diagnosis Using Convolutional Neural Network,Association for Computing Machinery,2020,https://doi.org/10.1145/3397391.3397427;http://dx.doi.org/10.1145/3397391.3397427,"Diabetes is a life-long disease and described by increased glucose level in the blood that results in either insulin shortage or failure to respond to insulin provided by the body. One early diagnosis used by examiners is detection by Traditional Chinese Medicine, which is based on subjective analysis which may be unreliable and inconsistent. This study is about developing a portable device that detects diabetes mellitus based on Convolutional Neural Network (CNN) and was implemented on Raspberry Pi 3 Model B using Python3 as its main programming language. Datasets for both diabetic and non-diabetic tongue were gathered and trained in the device. For the device's accuracy rate a confusion matrix was used, also for the misclassification of diabetic to a non-diabetic. The computed accuracy of the device was 88%, with the misclassification rate of 12% and the precision of 92.6%.","Convolution, Convolutional neural network architecture, Image processing, Diabetes mellitus"
Conference Paper,"Allaouzi I,Ben Ahmed M,Benamrou B,Ouardouz M",Automatic Caption Generation for Medical Images,Association for Computing Machinery,2018,https://doi.org/10.1145/3286606.3286863;http://dx.doi.org/10.1145/3286606.3286863,"With the increasing availability of medical images coming from different modalities (X-Ray, CT, PET, MRI, ultrasound, etc.), and the huge advances in the development of incredibly fast, accurate and enhanced computing power with the current graphics processing units. The task of automatic caption generation from medical images became a new way to improve healthcare and the key method for getting better results at lower costs. In this paper, we give a comprehensive overview of the task of image captioning in the medical domain, covering: existing models, the benchmark medical image-caption datasets, and evaluation metrics that have been used to measure the quality of the generated captions.","CNN, Attention mechanism, Computer Vision, RNN, Generative models, Retrieval-based models, Medical Image Captioning, LSTM, Natural Language Processing, Deep Neural Networks, Encoder-Decoder framework"
Conference Paper,"Nakandala S,Kumar A,Papakonstantinou Y",Incremental and Approximate Inference for Faster Occlusion-Based Deep CNN Explanations,Association for Computing Machinery,2019,https://doi.org/10.1145/3299869.3319874;http://dx.doi.org/10.1145/3299869.3319874,"Deep Convolutional Neural Networks (CNNs) now match human accuracy in many image prediction tasks, resulting in a growing adoption in e-commerce, radiology, and other domains. Naturally, explaining CNN predictions is a key concern for many users. Since the internal workings of CNNs are unintuitive for most users, occlusion-based explanations (OBE) are popular for understanding which parts of an image matter most for a prediction. One occludes a region of the image using a patch and moves it around to produce a heat map of changes to the prediction probability. Alas, this approach is computationally expensive due to the large number of re-inference requests produced, which wastes time and raises resource costs. We tackle this issue by casting the OBE task as a new instance of the classical incremental view maintenance problem. We create a novel and comprehensive algebraic framework for incremental CNN inference combining materialized views with multi-query optimization to reduce computational costs. We then present two novel approximate inference optimizations that exploit the semantics of CNNs and the OBE task to further reduce runtimes. We prototype our ideas in Python to create a tool we call Krypton that supports both CPUs and GPUs. Experiments with real data and CNNs show that Krypton reduces runtimes by up to 5X (resp. 35X) to produce exact (resp. high-quality approximate) results without raising resource requirements.","multi-query optimization, incremental view maintenance, systems for machine learning, convolution neural network explainability"
Journal Article,Anjum B,A Conversation with Kashyap Tumkur: The Promise and Challenges of Precision Medicine,Association for Computing Machinery,2021,https://doi.org/10.1145/3466883;http://dx.doi.org/10.1145/3466883,"Ubiquity's senior editor Dr. Bushra Anjum chats with Kashyap Tumkur, a software engineer at Verily Life Sciences, the healthcare and life sciences arm of Alphabet. They discuss how the notion of ""precision medicine"" has gained popularity in recent times. Next, the focus turns to Tumkur's work, where he, along with his team, is working on collecting and integrating continuous time-series data to create a map of human health.",Not Found
Conference Paper,"Bardos A,Mollas I,Bassiliades N,Tsoumakas G",Local Explanation of Dimensionality Reduction,Association for Computing Machinery,2022,https://doi.org/10.1145/3549737.3549770;http://dx.doi.org/10.1145/3549737.3549770,"Dimensionality reduction (DR) is a popular method for preparing and analyzing high-dimensional data. Reduced data representations are less computationally intensive and easier to manage and visualize, while retaining a significant percentage of their original information. Aside from these advantages, these reduced representations can be difficult or impossible to interpret in most circumstances, especially when the DR approach does not provide further information about which features of the original space led to their construction. This problem is addressed by Interpretable Machine Learning, a subfield of Explainable Artificial Intelligence that addresses the opacity of machine learning models. However, current research on Interpretable Machine Learning has been focused on supervised tasks, leaving unsupervised tasks like Dimensionality Reduction unexplored. In this paper, we introduce LXDR, a technique capable of providing local interpretations of the output of DR techniques. Experiment results and two LXDR use case examples are presented to evaluate its usefulness.","Model-Agnostic, Black Box Models, Local Interpretations, Dimensionality Reduction, Interpretable Machine Learning"
Conference Paper,"Xing N,Yeung SH,Cai CH,Ng TK,Wang W,Yang K,Yang N,Zhang M,Chen G,Ooi BC",SINGA-Easy: An Easy-to-Use Framework for MultiModal Analysis,Association for Computing Machinery,2021,https://doi.org/10.1145/3474085.3475176;http://dx.doi.org/10.1145/3474085.3475176,"Deep learning has achieved great success in a wide spectrum of multimedia applications such as image classification, natural language processing and multimodal data analysis. Recent years have seen the development of many deep learning frameworks that provide a high-level programming interface for users to design models, conduct training and deploy inference. However, it remains challenging to build an efficient end-to-end multimedia application with most existing frameworks. Specifically, in terms of usability, it is demanding for non-experts to implement deep learning models, obtain the right settings for the entire machine learning pipeline, manage models and datasets, and exploit external data sources all together. Further, in terms of adaptability, elastic computation solutions are much needed as the actual serving workload fluctuates constantly, and scaling the hardware resources to handle the fluctuating workload is typically infeasible. To address these challenges, we introduce SINGA-Easy, a new deep learning framework that provides distributed hyper-parameter tuning at the training stage, dynamic computational cost control at the inference stage, and intuitive user interactions with multimedia contents facilitated by model explanation. Our experiments on the training and deployment of multi-modality data analysis applications show that the framework is both usable and adaptable to dynamic inference loads. We implement SINGA-Easy on top of Apache SINGA and demonstrate our system with the entire machine learning life cycle.","distributed training, multimedia application, deep learning, dynamic inference, data analytics"
Conference Paper,"Nguyen NH,Nguyen PL,Nguyen TD,Nguyen TT,Nguyen DL,Nguyen TH,Pham HH,Truong TN",FedDRL: Deep Reinforcement Learning-Based Adaptive Aggregation for Non-IID Data in Federated Learning,Association for Computing Machinery,2023,https://doi.org/10.1145/3545008.3545085;http://dx.doi.org/10.1145/3545008.3545085,"The uneven distribution of local data across different edge devices (clients) results in slow model training and accuracy reduction in federated learning. Naive federated learning (FL) strategy and most alternative solutions attempted to achieve more fairness by weighted aggregating deep learning models across clients. This work introduces a novel non-IID type encountered in real-world datasets, namely cluster-skew, in which groups of clients have local data with similar distributions, causing the global model to converge to an over-fitted solution. To deal with non-IID data, particularly the cluster-skewed data, we propose FedDRL, a novel FL model that employs deep reinforcement learning to adaptively determine each client’s impact factor (which will be used as the weights in the aggregation process). Extensive experiments on a suite of federated datasets confirm that the proposed FedDRL improves favorably against FedAvg and FedProx methods, e.g., up to 4.05% and 2.17% on average for the CIFAR-100 dataset, respectively.","Data Heterogeneity, Federated Learning, Deep Reinforcement Learning"
Conference Paper,"Le L,Hao J,Xie Y,Priestley J",Deep Kernel: Learning Kernel Function from Data Using Deep Neural Network,Association for Computing Machinery,2016,https://doi.org/10.1145/3006299.3006312;http://dx.doi.org/10.1145/3006299.3006312,"Kernel function implicitly maps data from its original space to a higher dimensional feature space. Kernel based machine learning algorithms are typically applied to data that is not linearly separable in its original space. Although kernel methods are among the most elegant part of machine learning, it is challenging for users to define or select a proper kernel function with optimized parameter settings for their data. In this paper, we propose a novel method called Deep Kernel that can automatically learn a kernel function from data using deep learning. The deep kernel is currently utilized in classification, and dimension reduction and visualization. For the classification task, we evaluate the deep kernel method by comparing its performance with the optimized Gaussian kernels, both using support vector machines as the decision model, on different types of datasets. The experimental results show that the proposed deep kernel method outperforms the traditional methods with Gaussian kernels on most of the data sets. For the dimension reduction and visualization task, the deep kernel is used along with kernel PCA. The results are also compared and contrasted with using the RBF kernel with multiple parameters. The deep kernel is shown to be more powerful in dimension reduction and visualization than the RBF kernel.","visualization, deep learning, kernel methods, dimension reduction, support vector machines, deep kernel, classification"
Conference Paper,"Mairittha T,Okita T,Inoue S",Pre-Consulting Dialogue Systems for Telemedicine: Yes/No Intent Classification,Association for Computing Machinery,2018,https://doi.org/10.1145/3267305.3267704;http://dx.doi.org/10.1145/3267305.3267704,"Telemedicine is an emerging challenge for the shortage of qualified professionals, particularly in under-resourced regions. Physical assessment by a non-medical doctor is a practice in telemedicine which discovers essential symptom of a patient who needs to consult a doctor. We aim at facilitating this stage with a conversational chatbot which identifies the patient by conversation. Adopting the procedures of physical assessment one critical types of conversation involves in the self-diagnosis. Further, it turned out that useful kinds of questions in chatbot at this stage are related to Yes/No questions. We discovered that particular difficulties lie in the ambiguous replies by the patients: a patient modifies a question which makes them answer yes or no, a response does not the corresponding reply to the question, a reply involves some part yes and some part no, and so on. Focusing on this particular type of question we introduce a text classifier using Long Short-Term Memory (LSTM) and build a corpus using Twitter.","Telemedicine, Intent Classification, Dialogue Systems, Data Collection"
Conference Paper,"Guidotti R,Monreale A",Designing Shapelets for Interpretable Data-Agnostic Classification,Association for Computing Machinery,2021,https://doi.org/10.1145/3461702.3462553;http://dx.doi.org/10.1145/3461702.3462553,"Time series shapelets are discriminatory subsequences which are representative of a class, and their similarity to a time series can be used for successfully tackling the time series classification problem. The literature shows that Artificial Intelligence (AI) systems adopting classification models based on time series shapelets can be interpretable, more accurate, and significantly fast. Thus, in order to design a data-agnostic and interpretable classification approach, in this paper we first extend the notion of shapelets to different types of data, i.e., images, tabular and textual data. Then, based on this extended notion of shapelets we propose an interpretable data-agnostic classification method. Since the shapelets discovery can be time consuming, especially for data types more complex than time series, we exploit a notion of prototypes for finding candidate shapelets, and reducing both the time required to find a solution and the variance of shapelets. A wide experimentation on datasets of different types shows that the data-agnostic prototype-based shapelets returned by the proposed method empower an interpretable classification which is also fast, accurate, and stable. In addition, we show and we prove that shapelets can be at the basis of explainable AI methods.","decision support systems, interpretable machine learning, transparent classification method, explainable artificial intelligence"
Conference Paper,"Shu W,Wang S,Chen Q,Hu Y,Cai Z,Lin R",Pathological Image Classification of Breast Cancer Based on Residual Network and Focal Loss,Association for Computing Machinery,2020,https://doi.org/10.1145/3374587.3374634;http://dx.doi.org/10.1145/3374587.3374634,"This paper proposes an improved deep residual neural network for the classification of breast cancer as either benign or malignant. Inspired by the success of using focal loss in object detection, we present a new focal loss for pathological image classification to solve the class imbalance problem encountered during training stage. Furthermore, we introduce a multi-scale acquisition structure into ResNet to get a larger range of receptive fields for each network layer and represent features at multiple scales. Data enhancement and migration learning are also used to optimize the initial parameters solving the problem of overfitting in the network. Experimental results show that our approach achieves higher accuracy of classification compared to previous methods.","Residual Network, Deep Learning, Focal Loss Pathological Image"
Conference Paper,Wang H,"""SOS Signal"" in Breathing Sound - Rapid COVID-19 Diagnosis Based on Machine Learning",Association for Computing Machinery,2022,https://doi.org/10.1145/3569966.3570100;http://dx.doi.org/10.1145/3569966.3570100,"Abstract—The severe acute respiratory syndrome coronavirus 2 is a novel type of coronavirus that causes COVID-19. The COVID-19 virus has recently infected more than 590 million individuals, resulting in a global pandemic. Traditional diagnosis methods are no longer effective due to the exponential rise in infection rates. Quick and accurate COVID-19 diagnosis is made possible by machine learning (ML), which also assuages the burden on healthcare systems. After the effective utilization of Cough Audio Signal Classification in diagnosing a number of respiratory illnesses, there has been significant interest in using ML to enable universal COVID-19 screening. The purpose of the current study is to determine people's COVID-19 status through machine learning algorithms. We have developed a Random Forest based model and achieved an accuracy of 0.873 on the COUGHVID dataset, demonstrates the potential of using audio signals as a cheap, accessible, and accurate COVID-19 screening tool.","Keywords—machine learning, artificial intelligence, COVID-19"
Conference Paper,"Zhang R,Zhang R,Ma J,Zhang H",Analysis of Different Encoder-Decoder-Based Approaches for Biomedical Imaging Segmentation,Association for Computing Machinery,2021,https://doi.org/10.1145/3449301.3449320;http://dx.doi.org/10.1145/3449301.3449320,"Recently, CNNs (convolutional neural networks) have been widely used in the field of medical image segmentation. In particular, the encoder-decoder architectures represented by U-Net have achieved state-of-art segmentation effects and inspired many more elaborated networks, which adopt newer and more advanced network designs. To our knowledge, the comprehensive and detailed comparison among these improved versions from a multiplicity of points of view has not been conducted up to now.With U-Net as the baseline, we select the other four typical improvements for U-Net. For higher reliability, we finish the task of segmentation on four datasets and more experiments are performed to test the performance in various conditions. Finally, we evaluate their performance using multiple evaluation metrics.We find that attention U-Net achieves the best segmentation results in terms of F1-score but also owns the most trainable parameters and is most time-consuming. As training images decrease, the original U-Net is most robust even only less than 5 training samples are available. Besides, for any networks, adding auxiliary loss function with small weighting such as 0.01 or 0.01 whatever the cross-entropy loss and the dice-coefficient loss for the other one is beneficial as well.","Segmentation, Convolutional neural networks, Biomedical image, Encoder-decoder"
Conference Paper,"Banerjee R,Ghose A,Sinha A,Pal A,Mandana KM",A Multi-Modal Approach for Non-Invasive Detection of Coronary Artery Disease,Association for Computing Machinery,2019,https://doi.org/10.1145/3341162.3349331;http://dx.doi.org/10.1145/3341162.3349331,"Coronary Artery Disease (CAD) is a leading cause of death globally. Coronary angiography, the clinical diagnosis for CAD involves a surgery and admission to hospital. While this is a proven gold standard, having a less exact low-cost non-invasive screening method would be very helpful in mass diagnosis and pre-diagnosis. However, all physiological manifestations of CAD either appear late in the time-curve or are non-specific surrogate markers. With the advent of Artificial Intelligence (AI), there is new hope using multi-modal non-invasive sensing and analysis. In this paper, we combine domain knowledge with AI based data analysis to propose a novel two-stage approach that effectively incorporates multiple CAD markers in various non-invasive cardiovascular signals for an improved diagnosis system. At first stage, a hierarchical rule-engine identifies the high cardiac risk population using patient demography and medical history, who are further analysed at the second stage using numeric features from various cardiovascular signals. Results show that the proposed approach achieves sensitivity = 0.96 and specificity = 0.91 in classifying CAD patients on an in-house hospital dataset, recorded using commercially available sensors.","coronary artery disease, cardiovascular signals, feature extraction, classification"
Conference Paper,"Zhao S,Kong W,Shao J,Zhou Z,Chen W,Wu H",Automatic Retinal Structure Segmentation via U-Net Framework and Quantitative Analysis with ImageJ,Association for Computing Machinery,2020,https://doi.org/10.1145/3429889.3429908;http://dx.doi.org/10.1145/3429889.3429908,"Retina is a window reflecting the state of the general system and the condition of the eye. The traditional heavy-manual quantification of the morphological characteristics of retina is in need of improving. Therefore, we aim to automatically segment the retinal vessels and lesions and further analyze segmented results. Three public datasets including DRIVE, DIARETDB, IDRID were selected, and the images from them were preprocessed and augmented with a series of enhancements, random rotation and gamma transformation. Attention gate (AG) U-Net framework was used to segment retinal vessels, OD and exudates respectively. The performance of AG U-Net model was evaluated. Furthermore, the segmented results were analyzed with different shape descriptors using ImageJ. The geometric features such as width, length, area, circumference, and roundness were extracted and statistically analyzed in grade 2 and 3 DR images. The results approved the superiority of Attention-U-Net in retinal structure segmentation and the geometric features were successfully extracted and analyzed. In conclusion, the proposed AG U-Net empowered automatic segmentation and ImageJ based analytic framework are worthy of applications on retinal images, thus fostering the clinical science investigations.","quantitative analysis, U-Net, Key words: Retina, deep learning"
Conference Paper,"Li G,Wang X,Wang Z,Wu J,Kamiya T",Compare Derived U-Nets Using For Retinal Vessels Segmentation,Association for Computing Machinery,2022,https://doi.org/10.1145/3502803.3502804;http://dx.doi.org/10.1145/3502803.3502804,"U-Net frameworks reveal potential on image segmentation tasks of the complex morphologic objects, such as capillaries. To compare the performance of vessels segmentation in fundus images, in this paper, we review U-Net and its three derived architectures: Residual Spatial Attention Network, Generative Adversarial Networks and IterNet. The networks training and testing were completed using the same image datasets under the same configurations. We calculated the accuracy and precision of segmentation results. The results showed that the cascade U-Net architecture provided better results especially on the capillaries parts.","Deep learning, Computer Aided Diagnosis, Image segmentation"
Conference Paper,Watson D,Rational Shapley Values,Association for Computing Machinery,2022,https://doi.org/10.1145/3531146.3533170;http://dx.doi.org/10.1145/3531146.3533170,"Explaining the predictions of opaque machine learning algorithms is an important and challenging task, especially as complex models are increasingly used to assist in high-stakes decisions such as those arising in healthcare and finance. Most popular tools for post-hoc explainable artificial intelligence (XAI) are either insensitive to context (e.g., feature attributions) or difficult to summarize (e.g., counterfactuals). In this paper, I introduce rational Shapley values, a novel XAI method that synthesizes and extends these seemingly incompatible approaches in a rigorous, flexible manner. I leverage tools from decision theory and causal modeling to formalize and implement a pragmatic approach that resolves a number of known challenges in XAI. By pairing the distribution of random variables with the appropriate reference class for a given explanation task, I illustrate through theory and experiments how user goals and knowledge can inform and constrain the solution set in an iterative fashion. The method compares favorably to state of the art XAI tools in a range of quantitative and qualitative comparisons.","Shapley values, Counterfactuals, Explainable artificial intelligence, Decision theory, Interpretable machine learning"
Conference Paper,Watson D,Rational Shapley Values,Association for Computing Machinery,2022,https://doi.org/10.1145/3531146.3533170;http://dx.doi.org/10.1145/3531146.3533170,"Explaining the predictions of opaque machine learning algorithms is an important and challenging task, especially as complex models are increasingly used to assist in high-stakes decisions such as those arising in healthcare and finance. Most popular tools for post-hoc explainable artificial intelligence (XAI) are either insensitive to context (e.g., feature attributions) or difficult to summarize (e.g., counterfactuals). In this paper, I introduce rational Shapley values, a novel XAI method that synthesizes and extends these seemingly incompatible approaches in a rigorous, flexible manner. I leverage tools from decision theory and causal modeling to formalize and implement a pragmatic approach that resolves a number of known challenges in XAI. By pairing the distribution of random variables with the appropriate reference class for a given explanation task, I illustrate through theory and experiments how user goals and knowledge can inform and constrain the solution set in an iterative fashion. The method compares favorably to state of the art XAI tools in a range of quantitative and qualitative comparisons.","Shapley values, Counterfactuals, Explainable artificial intelligence, Decision theory, Interpretable machine learning"
Conference Paper,"Doulamis A,Doulamis N,Angeli A","A Cost -Effective Photonics-Based Device for Early Prediction, Monitoring and Management of Diabetic Foot Ulcers",Association for Computing Machinery,2020,https://doi.org/10.1145/3389189.3397994;http://dx.doi.org/10.1145/3389189.3397994,"Early prediction and management of Diabetic Foot Ulcers (DFUs) is an important health factor of Europe. Recent clinical trials have concluded that NIR sensing captures oxy(deoxy)haemoglobin (HbO2, Hb) and peripheral/ tissue oxygen saturations (StO2, SpO2), thermal Infrared-IR detects hyperthermia, among Regions of Interest (ROIs) and Mid-IR contains rich information about the proteomics, lipidomics and metabolomics (e.g., glucose). Current medical approaches are i) invasive (e.g., skin lesion biopsy), ii) requires consumables, and iii) being operated by certified physicians. Our research aims at developing a non-invasive, reliable and cost-effective photonics-driven device for DFU monitoring and management which can be applied for wide use. Hyper-spectral image data are exploited for this purpose. Cost-effectiveness is achieved by introducing i) targeted photonics technologies for DFU, ii) implementing advanced signal processing/learning algorithms to increase the discrimination accuracy while maintaining hardware cost-benefit, (iii) developing a user-friendly framework operated by non-certified physicians, and even by patients, and (iv) minimizing operational cost with our non-invasive device.","photonic devices, hyper-spectral imaging, diabetic foot ulcers"
Conference Paper,"Samonte MJ,Gerardo BD,Fajardo AC,Medina RP",ICD-9 Tagging of Clinical Notes Using Topical Word Embedding,Association for Computing Machinery,2018,https://doi.org/10.1145/3230348.3230357;http://dx.doi.org/10.1145/3230348.3230357,"Medical records, which contains text, has been dramatically increasing everyday. This means that there is a greater need of analyzing health information in a better way. And this can be done through document classification in natural language applications. In this study, we describe tagging of patient notes with ICD-9 codes through topical word embedding in deep learning called EnHANs. We formulate this paper as a multi-label, multi-class classification problem to categorize the ICD-9 codes of a dataset with 400,000 critical care unit medical records. Knowing accurate diagnosis using ICD-9 codes is a vital information for billing and insurance claims. We demonstrate that through the use of topical word embedding model, we learn to classify patient notes with their corresponding ICD-9 labels moderately well than single-label classification.","ICD-9 codes, Hierarchical Attention Networks, Topical Word Embedding, Recurrent Neural Network"
Conference Paper,"Zhao Y,Hu S,Li Y,Li Y,Chen X",Research Progress on Diagnostic Methods of Dry Eye,Association for Computing Machinery,2022,https://doi.org/10.1145/3524086.3524089;http://dx.doi.org/10.1145/3524086.3524089,"Dry eye is one of the most common chronic ophthalmic diseases, and the number of patients with dry eye is increasing. There is still no unified diagnostic standard in China. Understanding the pathophysiology of dry eye can help guide clinical treatment. Traditional clinical detection parameters can provide certain objective diagnostic indicators, but in actual clinical diagnosis, it is often necessary to combine auxiliary diagnostic instruments. This review introduces the definition, pathophysiology, clinical testing parameters, and clinical diagnostic methods of dry eye, and summarizes the application of diagnostic instruments and their advantages and disadvantages. This review will provide a more in-depth understanding of the research progress of dry eye and its diagnosis.","Dry eye, Instrument-assisted diagnosis, Diagnostic methods, Pathophysiology of dry eye"
Conference Paper,"Hou J,Sang Y,Liu Y,Lu L",Feature Selection and Prediction Model for Type 2 Diabetes in the Chinese Population with Machine Learning,Association for Computing Machinery,2020,https://doi.org/10.1145/3424978.3425085;http://dx.doi.org/10.1145/3424978.3425085,"Diabetes is a chronic disease characterized by hyperglycemia. Based on the rising incidence of the disease in recent years, diabetes is affecting more and more families. In 2017 alone, it caused 5 million deaths and cost $850 billion in global healthcare. In this paper, we proposed a method to predict the prevalence of diabetes based on a selected set of features from physical examination data. We used Fisher's score, RFE and decision tree to select features. Random forest, logistic regression, SVM and MLP were used to predict the prevalence of diabetes. EA and Fisher' s score helped us to reduce dimensions. We used random forest to classify diabetes accurately. Our results show that the highest accuracy (0.987) can be achieved by using random forest with 85 features. The prediction accuracy using Fisher's Score with 19 features also reached 0.986. We finally selected 5 features based on our method to form a new dataset for diabetes prediction. The 5 features are fasting plasma glucose, HbA1c, HDL, total cholesterol level and hypertension. The values of accuracy, precision, sensitivity, F1 score, MCC and AUC were 0.977, 0.968, 0.812, 0.883, 0.875, and 0.905, respectively. Results show that our method can be successfully used to select features for diabetes classifier and improve its performance, which will provide support for clinicians to quickly identify diabetes.","Random forest, Diabetes mellitus, Classification, Machine learning, Feature selection"
Conference Paper,"Brass I,Mkwashi A","Risk Assessment and Classification of Medical Device Software for the Internet of Medical Things: Challenges Arising from Connected, Intelligent Medical Devices",Association for Computing Machinery,2023,https://doi.org/10.1145/3567445.3571104;http://dx.doi.org/10.1145/3567445.3571104,"Although the medical device industry operates within a stringent regulatory environment, the growing deployment of connected, intelligent medical devices (CIMDs) in the healthcare sector is challenging these established regulatory frameworks. CIMDs come in a variety of forms, from implantables, to specialist IoMT devices deployed at the point-of-care, to AI-based medical devices, and AI as a medical device (AIaMDs). These devices raise several cybersecurity, data management, and algorithmic integrity concerns for patient safety and the delivery of reliable, responsible healthcare. The purpose of this article is to focus on a particular characteristic of CIMDs: their changing risk profile, several times throughout their lifecycle, with limited awareness from users, manufacturers, and regulators. Looking at the implications of these often subtle yet meaningful software modifications for current medical device regulations and for critical stakeholders in the CIMD ecosystem, the article highlights three main challenges to: i) risk assessment, classification and management frameworks that underpin current medical device regulations; ii) current medical device compliance frameworks, especially the post-market surveillance of medical devices; and iii) the detection, categorization, and reporting of compromised devices that might not perform according to their intended purpose. The article brings empirical evidence from a qualitative research study conducted with critical stakeholders in the medical device sector.","Medical device software, regulation"
Conference Paper,"Hannan B,Zhang X,Sethares K",IHANDs: Intelligent Health Advising and Decision-Support Agent,IEEE Computer Society,2014,https://doi.org/10.1109/WI-IAT.2014.180;http://dx.doi.org/10.1109/WI-IAT.2014.180,"This paper describes an intelligent health and decision support agent (iHANDs) built with various artificial intelligence mechanisms. Upon receiving the user's symptom descriptions, iHands conducts both web search and local medical knowledge database search, utilizing the user's electronic health records (EHR) to direct the search process. An information-fusion algorithm is developed based on Dempster-Shafer theory to merge the information from various sources with different reliabilities and generate the strength of support for each possible cause. A dynamic reference network is created and updated to record all information obtained during the interleaved search and reasoning process. Ihands performs a bi-directional search: from symptoms to possible causes and also from possible causes to most likely symptoms and risk factors. Bayesian inference mechanism is used to identify the confidence level for each possible cause given the user's symptoms and EHR. When needed, an iterative broaden search will be conducted to increase the confidence level to exceed a pre-set threshold or to further distinguish a few possible causes with very close confidence levels. The preliminary experiment results show the promise of iHands in assisting individuals in their healthcare decision-making process.","web knowledge mining, decision support, reasoning under uncertainty, intelligent agent, health informatics"
Conference Paper,Yu H,Health Causal Probability Knowledge Graph: Another Intelligent Health Knowledge Discovery Approach,Association for Computing Machinery,2021,https://doi.org/10.1145/3440067.3440077;http://dx.doi.org/10.1145/3440067.3440077,"Currently, most of the health-data research concentrates on applying Deep Learning technologies for prediction and reasoning. Deep Learning processes build the prediction model purely based on fitting weights on the raw data inside multiple neural layers, which is difficult to explain the prediction outputs. However, telling ‘WHY’ is crucial for healthcare research. The major difficulty to explain in Deep Learning models is a lack of knowledge-based analysis environment that not only can model the knowledge in a machine-understandable way but also can create causal probability relations inside the knowledge. In our research, we propose a Causal Probability Description Logic (CPDL) framework that extended the current Description Logic (DL). The key extension is to have a two-layer DL representation. One layer represents causality knowledge. The other layer takes observation inputs e.g. symptoms for generating a runtime probability knowledge graph based on the previous layer's knowledge. The CPDL framework can support probability-based causal reasoning tasks in a transparent and human-understandable way. CPDL can be easily implemented using existing programming standards such as OWL, RDF, SPARQL and probability network programming libraries. The experimental evaluations extract 383 common disease conditions from the UK NHS (National Healthcare Service) and enable automatically linked 418 condition terms from the DBpedia dataset. The CPDL-based knowledge graph can support disease prediction with traceable pieces of evidence behind the ranking results.","Information retrieval, Probability and causal analysis, Knowledge graph, Bioinformatics, Web of data, Healthcare, Machine learning"
Conference Paper,"Choi E,Bahadori MT,Song L,Stewart WF,Sun J",GRAM: Graph-Based Attention Model for Healthcare Representation Learning,Association for Computing Machinery,2017,https://doi.org/10.1145/3097983.3098126;http://dx.doi.org/10.1145/3097983.3098126,"Deep learning methods exhibit promising performance for predictive modeling in healthcare, but two important challenges remain: - Data insufficiency: Often in healthcare predictive modeling, the sample size is insufficient for deep learning methods to achieve satisfactory results.Interpretation: The representations learned by deep learning methods should align with medical knowledge.To address these challenges, we propose GRaph-based Attention Model (GRAM) that supplements electronic health records (EHR) with hierarchical information inherent to medical ontologies. Based on the data volume and the ontology structure, GRAM represents a medical concept as a combination of its ancestors in the ontology via an attention mechanism.We compared predictive performance (i.e. accuracy, data needs, interpretability) of GRAM to various methods including the recurrent neural network (RNN) in two sequential diagnoses prediction tasks and one heart failure prediction task. Compared to the basic RNN, GRAM achieved 10% higher accuracy for predicting diseases rarely observed in the training data and 3% improved area under the ROC curve for predicting heart failure using an order of magnitude less training data. Additionally, unlike other methods, the medical concept representations learned by GRAM are well aligned with the medical ontology. Finally, GRAM exhibits intuitive attention behaviors by adaptively generalizing to higher level concepts when facing data insufficiency at the lower level concepts.","predictive healthcare, attention model, electronic health records, graph"
Journal Article,"Kristiansen S,Nikolaidis K,Plagemann T,Goebel V,Traaen GM,Øverland B,Aakerøy L,Hunt TE,Loennechen JP,Steinshamn SL,Bendz CH,Anfinsen OG,Gullestad L,Akre H",Machine Learning for Sleep Apnea Detection with Unattended Sleep Monitoring at Home,Association for Computing Machinery,2021,https://doi.org/10.1145/3433987;http://dx.doi.org/10.1145/3433987,"Sleep apnea is a common and strongly under-diagnosed severe sleep-related respiratory disorder with periods of disrupted or reduced breathing during sleep. To diagnose sleep apnea, sleep data are collected with either polysomnography or polygraphy and scored by a sleep expert. We investigate in this work the use of supervised machine learning to automate the analysis of polygraphy data from the A3 study containing more than 7,400 hours of sleep monitoring data from 579 patients. We conduct a systematic comparative study of classification performance and resource use with different combinations of 27 classifiers and four sleep signals. The classifiers achieve up to 0.8941 accuracy (kappa: 0.7877) when using all four signal types simultaneously and up to 0.8543 accuracy (kappa: 0.7080) with only one signal, i.e., oxygen saturation. Methods based on deep learning outperform other methods by a large margin. All deep learning methods achieve nearly the same maximum classification performance even when they have very different architectures and sizes. When jointly accounting for classification performance, resource consumption and the ability to achieve with less training data high classification performance, we find that convolutional neural networks substantially outperform the other classifiers.","portable sleep monitor, unattended sleep monitoring, Sleep apnea, polygraphy, machine learning"
Conference Paper,"Rodrigues ME,Moura KH,Castelo Branco K,Lelli V,Viana W,Andrade RM,Santos IS",Medication Time? A User Experience Evaluation of Mobile Applications Targeting People with Diabetes,Association for Computing Machinery,2022,https://doi.org/10.1145/3539637.3558045;http://dx.doi.org/10.1145/3539637.3558045,"Diabetes is a chronic disease resulting from a lack of insulin, which permanently alters blood sugar levels. Research by the International Diabetes Federation (IDF) in the year 2021 shows that about 10% of adults aged between 20 and 79 years of the world population live with diabetes. In this context, the use of mobile apps has assisted in monitoring these patients. In this research, the experience of using mobile applications for healthcare patients with diabetes in their daily activities was investigated. For the evaluation, 5 Android mobile applications were selected for this purpose and 10 participants were invited who were people diagnosed with diabetes. To characterize the target audience, a questionnaire was applied to define the profile of the study participants. Subsequently, each participant chose two apps and followed the script for using the chosen apps. To evaluate the user experience (UX) used the User Experience Questionnaire (UEQ), which assesses aspects of usability (efficiency, perspicuity, and dependability) and user experience (novelty and stimulation). Among the 5 apps evaluated, one of the apps presented problems regarding the stimulus and novelty aspects. The aspect with the lowest Likert scale value among all the apps was a novelty. Thus, the results indicated that most apps present a creative design and an attractive interface according to the users.","User Experience, Evaluation, Mobile Health, Usability"
Conference Paper,"Yao HR,Chang C,Frieder O,Huang W,Liang IC,Hung CF",Cross-Global Attention Graph Kernel Network Prediction of Drug Prescription,Association for Computing Machinery,2020,https://doi.org/10.1145/3388440.3412459;http://dx.doi.org/10.1145/3388440.3412459,"We present an end-to-end, interpretable, deep-learning architecture to learn a graph kernel that predicts the outcome of chronic disease drug prescription. This is achieved through a deep metric learning collaborative with a Support Vector Machine objective using a graphical representation of Electronic Health Records. We formulate the predictive model as a binary graph classification problem with an adaptive learned graph kernel through novel cross-global attention node matching between patient graphs, simultaneously computing on multiple graphs without training pair or triplet generation. Results using the Taiwanese National Health Insurance Research Database demonstrate that our approach outperforms current start-of-the-art models both in terms of accuracy and interpretability.","Deep Graph Kernel Learning, Health informatics, Graph kernel, Predictive model"
Conference Paper,"Das S,Iyer R,Natarajan S",A Clustering Based Selection Framework for Cost Aware and Test-Time Feature Elicitation,Association for Computing Machinery,2021,https://doi.org/10.1145/3430984.3431008;http://dx.doi.org/10.1145/3430984.3431008,"Most learning algorithms are optimized with generalization and predictive performance as the goal. However, in most real-world machine learning applications, obtaining features at test time can incur a cost. For example, in clinical tasks, acquiring certain features such as FMRI or certain lab tests for patients can be expensive, while other features like patient demography or history are easily obtained and do not have a cost involved. Motivated by this, we address the problem of test-time elicitation of features. We formulate the problem of cost-aware feature elicitation as an optimization problem with trade-off between performance and feature acquisition cost. We assume that the cost of the features has already been paid in obtaining the training data. We propose a Clustering based Cost Aware Test-time Feature Elicitation (CATE) algorithm, which can select the relevant feature set given the observed attributes of the test instance. Our experiments on four real-world tasks demonstrate the efficacy and effectiveness of our proposed approach in both cost and performance.","classification, cost sensitive learning, supervised learning"
Conference Paper,"Delnevo G,Roccetti M,Mirri S",Modeling Patients' Online Medical Conversations: A Granger Causality Approach,Association for Computing Machinery,2020,https://doi.org/10.1145/3278576.3278593;http://dx.doi.org/10.1145/3278576.3278593,"Using AI-derived computerized techniques, we have modeled the large amount of online Reddit conversations exchanged among patients discussing around the prescriptions to take prenatal medical tests (both invasive and non-invasive). Our study has revealed that a patient's decision to take a specific test (thus possibly suffering medical implications) might significantly have a direct causal influence on her general everyday mood. Preliminary experimental results achieved exploiting the Granger causality analysis technique are discussed at length.","social media, prenatal testing, medicine, human-machine interaction, granger causality, big data"
Conference Paper,"Bordt S,Finck M,Raidl E,von Luxburg U",Post-Hoc Explanations Fail to Achieve Their Purpose in Adversarial Contexts,Association for Computing Machinery,2022,https://doi.org/10.1145/3531146.3533153;http://dx.doi.org/10.1145/3531146.3533153,"Existing and planned legislation stipulates various obligations to provide information about machine learning algorithms and their functioning, often interpreted as obligations to “explain”. Many researchers suggest using post-hoc explanation algorithms for this purpose. In this paper, we combine legal, philosophical and technical arguments to show that post-hoc explanation algorithms are unsuitable to achieve the law’s objectives. Indeed, most situations where explanations are requested are adversarial, meaning that the explanation provider and receiver have opposing interests and incentives, so that the provider might manipulate the explanation for her own ends. We show that this fundamental conflict cannot be resolved because of the high degree of ambiguity of post-hoc explanations in realistic application scenarios. As a consequence, post-hoc explanation algorithms are unsuitable to achieve the transparency objectives inherent to the legal norms. Instead, there is a need to more explicitly discuss the objectives underlying “explainability” obligations as these can often be better achieved through other mechanisms. There is an urgent need for a more open and honest discussion regarding the potential and limitations of post-hoc explanations in adversarial contexts, in particular in light of the current negotiations of the European Union’s draft Artificial Intelligence Act.","GDPR, Regulation, Transparency, Counterfactual Explanations, SHAP, Artificial Intelligence Act, LIME, Explainability"
Conference Paper,"Osman Andersen T,Nunes F,Wilcox L,Kaziunas E,Matthiesen S,Magrabi F",Realizing AI in Healthcare: Challenges Appearing in the Wild,Association for Computing Machinery,2021,https://doi.org/10.1145/3411763.3441347;http://dx.doi.org/10.1145/3411763.3441347,"The last several years have shown a strong growth of Artificial Intelligence (AI) technologies with promising results for many areas of healthcare. HCI has contributed to these discussions, mainly with studies on explainability of advanced algorithms. However, there are only few AI-systems based on machine learning algorithms that make it to the real world and everyday care. This challenging move has been named the “last mile” of AI in healthcare, emphasizing the sociotechnical uncertainties and unforeseen learnings from involving users in the design or use of AI-based systems. The aim of this workshop is to set the stage for a new wave of HCI research that accounts for and begins to develop new insights, concepts, and methods, for transitioning from development to implementation and use of AI in healthcare. Participants are invited to collaboratively define an HCI research agenda focused on healthcare AI in the wild, which will require examining end-user engagements and questioning underlying concepts of AI in healthcare.","human computer interaction, artificial intelligence"
Journal Article,Not Found,"Table of Contents: Online Supplement Volume 17, Number 2s-3s",Association for Computing Machinery,2022,https://doi.org/10.1145/3507468;http://dx.doi.org/10.1145/3507468,Not Found,Not Found
Conference Paper,"Hasan MI,Mahbub NI,Sarkar B",Identification of Black Fungus Diseases Using CNN and Transfer-Learning Approach,Association for Computing Machinery,2022,https://doi.org/10.1145/3542954.3542972;http://dx.doi.org/10.1145/3542954.3542972,"Black Fungus is a dangerous fungal illness, commonly referred to as ’mucormycosis’, usually infecting uncompromising people. Mucormycosis is generally rare, affecting less than two individuals per million each year, but it is currently 80 times more frequent in India. People of all ages, including prematurity infants, may be impacted. To minimize the time and effort required by medical experts to investigate black fungus disease and enhance the consistency of image identification of black fungus infections, we suggested a transfer learning based CNN model as the dataset for the black fungal disease is limited. The experimental outcomes of several different architectures, including VGG16, InceptionV3, and Xception, are compared and analyzed in this study, and it is observed that Xception has the best performance, with 97.92% training accuracy and 95.60% testing accuracy.","Black Fungus, Neural Networks, Pre-trained Network, Mucormycosis, Image Classification, CNN"
Journal Article,"Bossen C,Pine KH",Batman and Robin in Healthcare Knowledge Work: Human-AI Collaboration by Clinical Documentation Integrity Specialists,Association for Computing Machinery,2022,https://doi.org/10.1145/3569892;http://dx.doi.org/10.1145/3569892,"This paper describes the successful collaboration ‘in the wild’ between Clinical Documentation Integrity Specialists (CDIS) and an Artificial Intelligence (AI)-embedded software to conduct knowledge work. CDIS review patient charts in near real time to improve clinicians’ documentation, with the goal to make medical documentation more accurate, consistent and complete. CDIS collaborate with an AI-embedded “Computer Assisted Coding” (CAC) system that scans records from the Electronic Healthcare Record and auto-suggests codes based on natural language processing. CDIS find the CAC's suggestions are often inaccurate—often humorously so. Still, they find the CAC to be a useful helper, like Robin is to Batman. This human-AI collaboration is contingent on several factors: the flexible integration of the AI into the workflow similar to the notion of unremarkable AI; supporting the CDIS’ sensemaking; the CDIS’ knowledge about the CAC being predictably unreliable, an experience by the CDIS of the AI's value; humans remaining in control; and ability to experiment with the AI, which spurs reflection and learning for these knowledge workers.","Clinical Documentation, Ethnography, In the Wild, Knowledge Work, Healthcare, Artificial Intelligence, Data Work"
Journal Article,"Guzdial M,Zhang J","Teaching CS Humbly, and Watching the AI Revolution",Association for Computing Machinery,2020,https://doi.org/10.1145/3386312;http://dx.doi.org/10.1145/3386312,"The Communications Web site, http://cacm.acm.org, features more than a dozen bloggers in the BLOG@CACM community. In each issue of Communications, we'll publish selected posts or excerpts. twitter Follow us on Twitter at http://twitter.com/blogCACM http://cacm.acm.org/blogs/blog-cacm Mark Guzdial on a book that changed his thinking about teaching computer science, and Jiajie Zhang on the AI Revolution.",Not Found
Conference Paper,"Islam MD,Liu D,Wang K,Zhou P,Yu L,Wu D",A Case Study of HealthCare Platform Using Big Data Analytics and Machine Learning,Association for Computing Machinery,2019,https://doi.org/10.1145/3341069.3342980;http://dx.doi.org/10.1145/3341069.3342980,"The medical services in Bangladesh are shortage nowadays; people are suffering from getting the correct treatment from the hospital. With the low proportion of the doctors and the low per capita salary in Bangladesh, patients need to spend more money to get the appropriate treatments. Therefore, it is necessary to apply modern information technologies by which the scaffold between the patients and specialists can be reduced, and the patients can take proper treatment at a lower cost. Fortunately, we can solve this critical problem by utilizing interaction among electrical devices. With the big data collected from these devices, machine learning is a powerful tool for the data analytics because of its high accuracy, lower computational costs, and lower power consumption. This research is based on a case of study by the incorporation of the database, mobile application, web application and develops a novel platform through which the patients and the doctors can interact. In addition, the platform helps to store the patients' health data to make the final prediction using machine learning methods to get the proper healthcare treatment with the help of the machines and the doctors. The experiment result shows the high accuracy over 95% of the disease detection using machine learning methods, with the cost 90% lower than the local hospital in Bangladesh, which provides the strong support to implement of our platform in the remote area of the country.","Healthcare, Big Data, Machine Learning, Data Mining, Disease Prediction"
Journal Article,"Goldstein O,Kachuee M,Karkkainen K,Sarrafzadeh M",Target-Focused Feature Selection Using Uncertainty Measurements in Healthcare Data,Association for Computing Machinery,2020,https://doi.org/10.1145/3383685;http://dx.doi.org/10.1145/3383685,"Healthcare big data remains under-utilized due to various incompatibility issues between the domains of data analytics and healthcare. The lack of generalizable iterative feature acquisition methods under budget and machine learning models that allow reasoning with a model’s uncertainty are two examples. Meanwhile, a boost to the available data is currently under way with the rapid growth in the Internet of Things applications and personalized healthcare. For the healthcare domain to be able to adopt models that take advantage of this big data, machine learning models should be coupled with more informative, germane feature acquisition methods, consequently adding robustness to the model’s results. We introduce an approach to feature selection that is based on Bayesian learning, allowing us to report the level of uncertainty in the model, combined with false-positive and false-negative rates. In addition, measuring target-specific uncertainty lifts the restriction on feature selection being target agnostic, allowing for feature acquisition based on a target of focus. We show that acquiring features for a specific target is at least as good as deep learning feature selection methods and common linear feature selection approaches for small non-sparse datasets, and surpasses these when faced with real-world data that is larger in scale and sparseness.","machine learning, health informatics, healthcare big data, Healthcare feature selection, Bayesian learning, machine learning for health"
Journal Article,"Wood A,Najarian K,Kahrobaei D",Homomorphic Encryption for Machine Learning in Medicine and Bioinformatics,Association for Computing Machinery,2020,https://doi.org/10.1145/3394658;http://dx.doi.org/10.1145/3394658,"Machine learning and statistical techniques are powerful tools for analyzing large amounts of medical and genomic data. On the other hand, ethical concerns and privacy regulations prevent free sharing of this data. Encryption techniques such as fully homomorphic encryption (FHE) enable evaluation over encrypted data. Using FHE, machine learning models such as deep learning, decision trees, and Naive Bayes have been implemented for privacy-preserving applications using medical data. These applications include classifying encrypted data and training models on encrypted data. FHE has also been shown to enable secure genomic algorithms, such as paternity and ancestry testing and privacy-preserving applications of genome-wide association studies.This survey provides an overview of fully homomorphic encryption and its applications in medicine and bioinformatics. The high-level concepts behind FHE and its history are introduced, and details on current open-source implementations are provided. The state of fully homomorphic encryption for privacy-preserving techniques in machine learning and bioinformatics is reviewed, along with descriptions of how these methods can be implemented in the encrypted domain.","data privacy and security, machine learning, Fully homomorphic encryption, homomorphic encryption, secure outsourcing computation, neural networks, bioinformatics"
Journal Article,"Zeng Z,Deng Y,Li X,Naumann T,Luo Y",Natural Language Processing for EHR-Based Computational Phenotyping,IEEE Computer Society Press,2019,https://doi.org/10.1109/TCBB.2018.2849968;http://dx.doi.org/10.1109/TCBB.2018.2849968,"This article reviews recent advances in applying natural language processing NLP to Electronic Health Records EHRs for computational phenotyping. NLP-based computational phenotyping has numerous applications including diagnosis categorization, novel phenotype discovery, clinical trial screening, pharmacogenomics, drug-drug interaction DDI, and adverse drug event ADE detection, as well as genome-wide and phenome-wide association studies. Significant progress has been made in algorithm development and resource construction for computational phenotyping. Among the surveyed methods, well-designed keyword search and rule-based systems often achieve good performance. However, the construction of keyword and rule lists requires significant manual effort, which is difficult to scale. Supervised machine learning models have been favored because they are capable of acquiring both classification patterns and structures from data. Recently, deep learning and unsupervised learning have received growing attention, with the former favored for its performance and the latter for its ability to find novel phenotypes. Integrating heterogeneous data sources have become increasingly important and have shown promise in improving model performance. Often, better performance is achieved by combining multiple modalities of information. Despite these many advances, challenges and opportunities remain for NLP-based computational phenotyping, including better model interpretability and generalizability, and proper characterization of feature relations in clinical narratives.",Not Found
Conference Paper,"Nag U,Upadhayay M,Gupta T",Detecting Diabetic Foot Complications Using Infrared Thermography and Machine Learning,Association for Computing Machinery,2021,https://doi.org/10.1145/3474906.3474919;http://dx.doi.org/10.1145/3474906.3474919,"One in every ten adults suffers from diabetes. Diabetes Mellitus can cause foot ulcers which can lead to leg or foot amputation. Early identification depends on day-to-day risk assessment for diabetic patients. Healthy feet have an even temperature distribution while diabetic feet tend to have abnormal regions with higher temperatures. In our approach the abnormal regions of the foot plantar thermograms were segmented with lazy snapping. First Order Statistical features, GLCM based textural features and Wavelets based features were extracted from these regions of interest. Various classifiers were used to evaluate the proposed features. We concluded that the proposed features were able to discriminate normal and diabetic foot with an accuracy of 97.778%.","support vector machine, k-nearest neighbor, diabetes mellitus, infrared thermography, decision trees, automatic detection of foot ulcer"
Conference Paper,"Lee MK,Rich K",Who Is Included in Human Perceptions of AI?: Trust and Perceived Fairness around Healthcare AI and Cultural Mistrust,Association for Computing Machinery,2021,https://doi.org/10.1145/3411764.3445570;http://dx.doi.org/10.1145/3411764.3445570,"Emerging research suggests that people trust algorithmic decisions less than human decisions. However, different populations, particularly in marginalized communities, may have different levels of trust in human decision-makers. Do people who mistrust human decision-makers perceive human decisions to be more trustworthy and fairer than algorithmic decisions? Or do they trust algorithmic decisions as much as or more than human decisions? We examine the role of mistrust in human systems in people’s perceptions of algorithmic decisions. We focus on healthcare Artificial Intelligence (AI), group-based medical mistrust, and Black people in the United States. We conducted a between-subjects online experiment to examine people’s perceptions of skin cancer screening decisions made by an AI versus a human physician depending on their medical mistrust, and we conducted interviews to understand how to cultivate trust in healthcare AI. Our findings highlight that research around human experiences of AI should consider critical differences in social groups.","Healthcare AI, Group-Based Medical Mistrust Scale (GBMMS), Trust, Perceptions of Algorithmic Decisions, Black Perspectives, Fairness"
Conference Paper,"Marques G,Pires IM,Garcia NM",Diabetes Disease through Machine Learning: A Comparative Study,Association for Computing Machinery,2021,https://doi.org/10.1145/3445815.3445828;http://dx.doi.org/10.1145/3445815.3445828,"Diabetes is a critical problem in developed and developing countries. The early detection of this disease is crucial for efficient and effective treatment. Moreover, the application of machine learning for disease detection is a trending topic. There are numerous machine learning methods available in the literature. The main contribution of this paper is to present a preliminary study on the application of machine learning methods on a public and widely used diabetes dataset. The authors have applied eight different machine learning techniques using PIMA diabetes dataset. The data have been normalized, and Neural Networks, SGD, Random Forest, kNN, Naïve Bayes, AdaBoost, Decision Tree and SVM methods have been applied. First, the techniques have been validated using stratified 10-fold cross-validation. Second, the confusion matrix has been extracted for each method, and the accuracy, recall, precision and F1-score have been calculated. The three methods with better accuracy are Neural Networks, SGD and kNN. These methods report 77.47%, 76.43% and 73.96% of average accuracy between classes.",Not Found
Conference Paper,Bharkad S,Automatic Segmentation of Blood Vessels in Retinal Image Using Morphological Filters,Association for Computing Machinery,2017,https://doi.org/10.1145/3056662.3056710;http://dx.doi.org/10.1145/3056662.3056710,This paper presents the method for automatic segmentation of blood vessels in retinal image. Proposed approach makes use of morphological filter called top hat transform oriented at three directions for extraction of vessel network. Segmentation of vessel structure is done using single global threshold. This approach is tested on standard DRIVE database. Experimental results show better performance of the proposed method for segmentation of vessel structure. Proposed approach is superior over the algorithms available in literature with respect to accuracy and computation time.,"blood vessel, morphological filter, segmentation, top hat transform"
Conference Paper,"Sin J,Munteanu C",A Preliminary Investigation of the Role of Anthropomorphism in Designing Telehealth Bots for Older Adults,Association for Computing Machinery,2019,https://doi.org/10.1145/3290607.3312941;http://dx.doi.org/10.1145/3290607.3312941,"Autonomous virtual agents (VAs) are increasingly used commercially in critical information spaces such as healthcare. Existing VA research has focused on microscale interaction patterns such as usability and artificial intelligence. However, the macroscale patterns of users' information practices and their relationship with the design and adoption of VAs have been largely understudied, especially when it comes to older adults (OAs), who stand to benefit greatly from VAs. We conducted a preliminary investigation to understand the role design elements, such as anthropomorphic aspects of VAs, play in OAs' perception of VAs and in OAs' preferences for VAs' participation within their health information practices. Some unexpected findings indicate that the fidelity of anthropomorphic features influences perception in ways that are dependent on the context of the information tasks. This suggests that research on improving the design and increasing the adoption of VAs should factor the interplay between fidelity of VA representation and information context.","older adults, empirical study that tells us about how people use a system, health - wellbeing, embodied interaction"
Conference Paper,"Mitchell E,Elhadad N,Mamykina L",Examining AI Methods for Micro-Coaching Dialogs,Association for Computing Machinery,2022,https://doi.org/10.1145/3491102.3501886;http://dx.doi.org/10.1145/3491102.3501886,"Conversational interaction, for example through chatbots, is well-suited to enable automated health coaching tools to support self-management and prevention of chronic diseases. However, chatbots in health are predominantly scripted or rule-based, which can result in a stagnant and repetitive user experience in contrast with more dynamic, data-driven chatbots in other domains. Consequently, little is known about the tradeoffs of pursuing data-driven approaches for health chatbots. We examined multiple artificial intelligence (AI) approaches to enable micro-coaching dialogs in nutrition — brief coaching conversations related to specific meals, to support achievement of nutrition goals — and compared, reinforcement learning (RL), rule-based, and scripted approaches for dialog management. While the data-driven RL chatbot succeeded in shorter, more efficient dialogs, surprisingly the simplest, scripted chatbot was rated as higher quality, despite not fulfilling its task as consistently. These results highlight tensions between scripted and more complex, data-driven approaches for chatbots in health.","reinforcement learning, self-management, chatbots, conversational agents, Health coaching"
Conference Paper,"Dantas PC,Sarmento A,Sarmento A",A HW/SW Embedded System for Accelerating Diagnosis of Glaucoma from Eye Fundus Images,Association for Computing Machinery,2016,https://doi.org/10.1145/2990299.2990303;http://dx.doi.org/10.1145/2990299.2990303,"Glaucoma is an irreversible eye disease in which the optic nerve is progressively damaged leading to blindness. However, it is manageable if diagnosed early. The most common screening exam for glaucoma diagnosis is the eye fundus evaluation in which the ophthalmologist examines the optic nerve and estimates the Vertical Cup to Disc Ratio (VCDR). Currently, VCDR evaluation is performed by ophthalmologists based on their visual perception and experience. This paper explores different embedded architectures based on low power processors and describes a HW/SW embedded system that automatically calculates VCDR from eye fundus images using image processing techniques. Optic disc diameter is calculated by a HW accelerator, while optic cup diameter is calculated by SW. This resulted in an embedded system that reduces at least 30% of the execution time of a SW-only implementation and that is significantly faster than other related works based on desktop computers. The proposed system was tested on 70 eye fundus images and achieved a 97.72% accuracy rate.","architecture exploration, image processing, glaucoma, HW/SW embedded system, HW acceleration"
Conference Paper,"Ram Khanal S,Reis A,Paulino D,Bhandari D,Paredes H,Barroso J",Usage of Mobile Technologies for Diseases Inference: A Literature Review,Association for Computing Machinery,2021,https://doi.org/10.1145/3439231.3440618;http://dx.doi.org/10.1145/3439231.3440618,"The fields of artificial intelligence, knowledge inference, data science, etc. have been deeply studied over time and many theoretical approaches have been developed, including its application to health and diseases inference. The creation of prototype and consumer systems has been restrained by the technology limitations on data acquisition and processing, which has been greatly overcome with the new sensors and mobile devices technologies. So, in this work we go through a literature review of the current state of the art on record to the usage of mobile technologies for diseases inference. The review methodology is based on the Preferred Reporting Items for Systematic Reviews and Meta-Analyses (PRISMA) framework. The criteria were based on journal articles, prior to 2008, and using the defined keywords. A total of 14 selected articles were analyzed. A general conclusion was attained regarding the current state of maturity of the field, leading to fully functional consumer and professional market products.","Mobile devices, Disease Inference"
Conference Paper,"Ahmed HT,Zhang Q,Donnan R,Alomainy A",Framework of Unsupervised Based Denoising for Optical Coherence Tomography,Association for Computing Machinery,2022,https://doi.org/10.1145/3563737.3563741;http://dx.doi.org/10.1145/3563737.3563741,Not Found,"Optical Coherence Tomography, Image Denoising, Speckle Reduction, Deep Learning"
Conference Paper,"Chandrakar O,Saini JR",Development of Indian Weighted Diabetic Risk Score (IWDRS) Using Machine Learning Techniques for Type-2 Diabetes,Association for Computing Machinery,2016,https://doi.org/10.1145/2998476.2998497;http://dx.doi.org/10.1145/2998476.2998497,"Undetected pre-diabetes and late diagnosis is a major problem in East Asian countries. Diabetes screening tools such as Diabetes Risk Score (DRS) can effectively help in detecting and preventing the disease among pre-diabetes persons. Several Risk Scores for Type -2 Diabetes have been proposed and being used. In current research, researchers have observed certain issues in the available DRS and advocate the need to address the same. In this study researchers propose a novel Indian Weighted Diabetic Risk Score (IWDRS). Machine Learning Techniques such as distance based clustering with Euclidean distance, k-means algorithm and discretization is used to derive weighted risk score for diabetes risk factors like age, BMI, waist circumference, personal history, family history, diet, physical activity, stress and life quality. Result analysis shows that the proposed approach is better than existing approach in scientific literature.","Data Mining, Type -2 Diabetes, Weighted Diabetic Risk Score, Clustering, Discretization"
Conference Paper,"Ren H,Wang J,Zhao WX",Generative Adversarial Networks Enhanced Pre-Training for Insufficient Electronic Health Records Modeling,Association for Computing Machinery,2022,https://doi.org/10.1145/3534678.3539020;http://dx.doi.org/10.1145/3534678.3539020,"In recent years, automatic computational systems based on deep learning are widely used in medical fields, such as automatic diagnosing and disease prediction. Most of these systems are designed for data sufficient scenarios. However, due to the disease rarity or privacy, the medical data are always insufficient. When applying these data-hungry deep learning models with insufficient data, it is likely to lead to issues of over-fitting and cause serious performance problems. Many data augmentation methods have been proposed to solve the data insufficiency problem, such as using GAN (Generative Adversarial Networks) to generate training data. However, the augmented data usually contains lots of noise. Directly using them to train sensitive medical models is very difficult to achieve satisfactory results.To overcome this problem, we propose a novel deep model learning method for insufficient EHR (Electronic Health Record) data modeling, namely GRACE, which stands GeneRative Adversarial networks enhanCed prE-training. In the method, we propose an item-relation-aware GAN to capture changing trends and correlations among data for generating high-quality EHR records. Furthermore, we design a pre-training mechanism consisting of a masked records prediction task and a real-fake contrastive learning task to learn representations for EHR data using both generated and real data. After the pre-training, only the representations of real data is used to train the final prediction model. In this way, we can fully exploit useful information in generated data through pre-training, and also avoid the problems caused by directly using noisy generated data to train the final prediction model. The effectiveness of the proposed method is evaluated using extensive experiments on three healthcare-related real-world datasets. We also deploy our method in a maternal and child health care hospital for the online test. Both offline and online experimental results demonstrate the effectiveness of the proposed method. We believe doctors and patients can benefit from our effective learning method in various healthcare-related applications.","healthcare informatics, pre-training, representation learning"
Conference Paper,"Bai T,Vucetic S",Improving Medical Code Prediction from Clinical Text via Incorporating Online Knowledge Sources,Association for Computing Machinery,2019,https://doi.org/10.1145/3308558.3313485;http://dx.doi.org/10.1145/3308558.3313485,"Clinical notes contain detailed information about health status of patients for each of their encounters with a health system. Developing effective models to automatically assign medical codes to clinical notes has been a long-standing active research area. Despite a great recent progress in medical informatics fueled by deep learning, it is still a challenge to find the specific piece of evidence in a clinical note which justifies a particular medical code out of all possible codes. Considering the large amount of online disease knowledge sources, which contain detailed information about signs and symptoms of different diseases, their risk factors, and epidemiology, there is an opportunity to exploit such sources. In this paper we consider Wikipedia as an external knowledge source and propose Knowledge Source Integration (KSI), a novel end-to-end code assignment framework, which can integrate external knowledge during training of any baseline deep learning model. The main idea of KSI is to calculate matching scores between a clinical note and disease related Wikipedia documents, and combine the scores with output of the baseline model. To evaluate KSI, we experimented with automatic assignment of ICD-9 diagnosis codes to the emergency department clinical notes from MIMIC-III data set, aided by Wikipedia documents corresponding to the ICD-9 codes. We evaluated several baseline models, ranging from logistic regression to recently proposed deep learning models known to achieve the state-of-the-art accuracy on clinical notes. The results show that KSI consistently improves the baseline models and that it is particularly successful in assignment of rare codes. In addition, by analyzing weights of KSI models, we can gain understanding about which words in Wikipedia documents provide useful information for predictions.","attention mechanism, document similarity learning, Multi-label classification, healthcare"
Conference Paper,"Rochmawanti O,Utaminingrum F",Chest X-Ray Image to Classify Lung Diseases in Different Resolution Size Using DenseNet-121 Architectures,Association for Computing Machinery,2021,https://doi.org/10.1145/3479645.3479667;http://dx.doi.org/10.1145/3479645.3479667,"Chest radiography (CXR) is the most commonly used diagnostic tool in medical practice because of the low cost and easy operation. CXR contains much information about a patient's health, and radiologists often use it for disease detection. The diagnoses are often subjective for a few reasons, like illness looks, which might be unclear in CXR images or are often confused with different diseases. In this study, DenseNet-121 is a well-known convolutional neural network (CNN) model for diagnosing illness. The convolutional layers of these models are used as a base network. The pre-trained model is used because this study applied the transfer learning technique. The pre-trained model is built and trained using the public domain dataset ImageNet.Global Average Pooling (GAP) and dropout layers are added to reduce the overfitting problem of the network. The batch normalization layer is used for the rapid training of the pre-trained model. The output layer consists of 2 nodes that directly represent the two classes and a softmax activation function.This study analyzes the effects of varying image resolution for CXR images using four different datasets: tuberculosis dataset, pneumonia dataset, cardiomegaly dataset, and COVID-19 dataset. It is experimentally shown that DenseNet121 model achieves the highest accuracy in classification using image size 224x224 pixels. The best results were obtained with Tuberculosis dataset, Pneumonia dataset, Cardiomegaly dataset and COVID-19 dataset with 0,892, 0,904, 0,898 and 0,986, respectively.","DenseNet, accuracy, chestXRay, CXR, CNN"
Conference Paper,"Liu LJ,Ortiz-Soriano V,Neyra JA,Chen J",KGDAL: Knowledge Graph Guided Double Attention LSTM for Rolling Mortality Prediction for AKI-D Patients,Association for Computing Machinery,2021,https://doi.org/10.1145/3459930.3469513;http://dx.doi.org/10.1145/3459930.3469513,"With the rapid accumulation of electronic health record (EHR) data, deep learning (DL) models have exhibited promising performance on patient risk prediction. Recent advances have also demonstrated the effectiveness of knowledge graphs (KG) in providing valuable prior knowledge for further improving DL model performance. However, it is still unclear how KG can be utilized to encode highorder relations among clinical concepts and how DL models can make full use of the encoded concept relations to solve real-world healthcare problems and to interpret the outcomes. We propose a novel knowledge graph guided double attention LSTM model named KGDAL for rolling mortality prediction for critically ill patients with acute kidney injury requiring dialysis (AKI-D). KGDAL constructs a KG-based two-dimension attention in both time and feature spaces. In the experiment with two large healthcare datasets, we compared KGDAL with a variety of rolling mortality prediction models and conducted an ablation study to test the effectiveness, efficacy, and contribution of different attention mechanisms. The results showed that KGDAL clearly outperformed all the compared models. Also, KGDAL-derived patient risk trajectories may assist healthcare providers to make timely decisions and actions. The source code, sample data, and manual of KGDAL are available at https://github.com/lucasliu0928/KGDAL.","attention mechanism, deep learning, knowledge graph, rolling mortality prediction"
Conference Paper,"Gao Y,Sun M,Guo J",Mobile Apps for the Self-Management of Children and Adolescents with Type 1 Diabetes Mellitus: Systematic Search in App Stores and Quality Evaluation,Association for Computing Machinery,2021,https://doi.org/10.1145/3500931.3500974;http://dx.doi.org/10.1145/3500931.3500974,"The functions of the APP were evaluated according to the self-management requirements of the international authoritative diabetes guidelines, and the self-management smartphone APP of domestic children and adolescents with type 1 diabetes was systematically evaluated using the Mars scale. METHODS: Using the keywords ""type 1 diabetes"", ""T1DM"" and ""juvenile TIDM"", search, download and use the APP in the Android Market and App Store. The two investigators independently evaluated the APP using the MARS scale. RESULTS: A total of 22 mobile phone APPs were included. The results of APP function evaluation and Mars score showed that 100% of the APP had the function of blood glucose monitoring, 86.37% had the function of diet management, 90.91% had the function of exercise recording, 77.27% had the function of drug management, and only 22.73% had the function of emotion management. APP quality is generally not high (overall score is 3.30), patient participation is low, and information push lacks pertinence. CONCLUSIONS: At present, the function of self-management APP for children and adolescents with type 1 diabetes in China needs to be improved urgently, and there is a lack of self-management APP tailored for children and adolescents with type 1 diabetes.",type 1 diabetes Children and adolescents Mobile health APP Mobile App Rating Scale (MARS)
Journal Article,"Delgado F,Barocas S,Levy K",An Uncommon Task: Participatory Design in Legal AI,Association for Computing Machinery,2022,https://doi.org/10.1145/3512898;http://dx.doi.org/10.1145/3512898,"Despite growing calls for participation in AI design, there are to date few empirical studies of what these processes look like and how they can be structured for meaningful engagement with domain experts. In this paper, we examine a notable yet understudied AI design process in the legal domain that took place over a decade ago, the impact of which still informs legal automation efforts today. Specifically, we examine the design and evaluation activities that took place from 2006 to 2011 within the Text REtrieval Conference's (TREC) Legal Track, a computational research venue hosted by the National Institute of Standards and Technologies. The Legal Track of TREC is notable in the history of AI research and practice because it relied on a range of participatory approaches to facilitate the design and evaluation of new computational techniques-in this case, for automating attorney document review for civil litigation matters. Drawing on archival research and interviews with coordinators of the Legal Track of TREC, our analysis reveals how an interactive simulation methodology allowed computer scientists and lawyers to become co-designers and helped bridge the chasm between computational research and real-world, high-stakes litigation practice. In analyzing this case from the recent past, our aim is to empirically ground contemporary critiques of AI development and evaluation and the calls for greater participation as a means to address them.","participatory design, artificial intelligence, expertise, legal technology, co-design, iterative design"
Conference Paper,"Escudero-Marin P,Pidd M",Using ABMS to Simulate Emergency Departments,Winter Simulation Conference,2011,Not Found,"Computer simulation methods have enjoyed widespread use in healthcare system investigation and improvement. Most reported applications use discrete event simulation, though there are also many reports of the use of system dynamics. There are few reports of the use of agent-based simulations (ABS). This is curious, because healthcare systems are based on human interactions and the ability of ABS to represent human intention and interaction makes it an appealing approach. Tools exist to support both conceptual modelling and model implementation in ABS and these are illustrated with a simple example from an emergency department.",Not Found
Conference Paper,Deserno TM,Transforming Smart Vehicles and Smart Homes into Private Diagnostic Spaces,Association for Computing Machinery,2020,https://doi.org/10.1145/3379310.3379325;http://dx.doi.org/10.1145/3379310.3379325,"The aging societies require disruptive technologies and digitization of health is one of these. Similar to the controller area network bus of (smart) cars we have developed a bus-based system for smart homes. We consider both, vehicles and homes as private spaces, which, in contrast to smart wearables or smart clothes, provide sufficient power supply, computer, and storage hardware. Today's homes and cars are already equipped with a variety of sensors that deliver data relevant with respect to health. The daily delay between opening of bedroom and bathroom doors, or the time between opening the car's door and starting its engine indicates mobility. We further empower eHealth if private spaces are equipped with medical sensors (Step I of the required transforms). However, unobtrusive continuous monitoring of vital signs and biosignals is no yet explored clinically, and data to train artificial intelligence is missing. We propose steering wheel integrated electrocardiography (ECG) recording in smart vehicles and capacitive ECG recording in the chair and bed of the smart home for stroke prevention due to early detection of latent atrial fibrillation. Furthermore, the processing unit needs data warehousing and analytics (Step II). The communication interface needs semantic operability and secure channels, which we propose to establish using the international standard accident number (ISAN) (Step III). Finally, the combination with a medical application such as stroke prevention (Step IV) turns smart environments into private diagnostic spaces.","Stroke prevention, Health-enabling technology, Smart home, eHealth, mHealth, Smart car"
Conference Paper,"Ilango BS,Ramaraj N",A Hybrid Prediction Model with F-Score Feature Selection for Type II Diabetes Databases,Association for Computing Machinery,2010,https://doi.org/10.1145/1858378.1858391;http://dx.doi.org/10.1145/1858378.1858391,"The medical data are multidimensional, and are represented by a large number of features. Hundreds of independent features (parameters) in these high dimensional databases need to be simultaneously considered and analyzed, for valuable decision-making information in medical prediction. Most data mining methods depend on a set of features that define the behavior of the learning algorithm and directly or indirectly influence the complexity of the resulting models. Hence, to improve the efficiency and accuracy of mining task on high dimensional data, the data must be preprocessed by an efficient dimensionality reduction method. The aim of this study is to improve the diagnostic accuracy of diabetes disease by selecting informative features of Pima Indians Diabetes Dataset. This study proposes a Hybrid Prediction Model with F-score feature selection approach to identify the optimal feature subset of the Pima Indians Diabetes dataset. The features of diabetes dataset are ranked using F-score and the feature subset that gives the minimal clustering error is the optimal feature subset of the dataset. The correctly classified instances determine the pattern for diagnosis and are used for further classification process. The improved performance of the Support Vector Machine classifier measured in terms of Accuracy of the classifier, Sensitivity, Specificity and Area Under Curve (AUC) proves that the proposed feature approach indeed improves the performance of classification. The proposed prediction model achieves a predictive accuracy of 98.9427 and it is the highest predictive accuracy for diabetes dataset compared to other models in literature for this problem.","feature selection, data mining, medical data, Support Vector Machine, dimensionality reduction, F-score, accuracy sensitivity, specificity, Pima Indians diabetes dataset, AUC"
Conference Paper,"Zhang R,He J,Shi S,E H,Ou Z,Song M",BMM-Net: Automatic Segmentation of Edema in Optical Coherence Tomography Based on Boundary Detection and Multi-Scale Network,Association for Computing Machinery,2020,https://doi.org/10.1145/3368555.3384447;http://dx.doi.org/10.1145/3368555.3384447,"Retinal effusions and cysts caused by the leakage of damaged macular vessels and choroid neovascularization are symptoms of many ophthalmic diseases. Optical coherence tomography (OCT), which provides clear 10-layer cross-sectional images of the retina, is widely used to screen various ophthalmic diseases. A large number of researchers have carried out relevant studies on deep learning technology to realize the semantic segmentation of lesion areas, such as effusion on OCT images, and achieved good results. However, in this field, problems of the low contrast of the lesion area and unevenness of lesion size limit the accuracy of the deep learning semantic segmentation model. In this paper, we propose a boundary multi-scale multi-task OCT segmentation network (BMM-Net) for these two challenges to segment the retinal edema area, subretinal fluid, and pigment epithelial detachment in OCT images. We propose a boundary extraction module, a multi-scale information perception module, and a classification module to capture accurate position and semantic information and collaboratively extract meaningful features. We train and verify on the AI Challenger competition dataset. The average Dice coefficient of the three lesion areas is 3.058% higher than the most commonly used model in the field of medical image segmentation and reaches 0.8222.","optical coherence tomography, medical imaging analysis, semantic segmentation"
Journal Article,"Liu Y,Wang SL,Zhang JF,Zhang W,Zhou S,Li W",DMFMDA: Prediction of Microbe-Disease Associations Based on Deep Matrix Factorization Using Bayesian Personalized Ranking,IEEE Computer Society Press,2020,https://doi.org/10.1109/TCBB.2020.3018138;http://dx.doi.org/10.1109/TCBB.2020.3018138,"Identifying the microbe-disease associations is conducive to understanding the pathogenesis of disease from the perspective of microbe. In this paper, we propose a deep matrix factorization prediction model (DMFMDA) based on deep neural network. First, the disease one-hot encoding is fed into neural network, which is transformed into a low-dimensional dense vector in implicit semantic space via embedding layer, and so is microbe. Then, matrix factorization is realized by neural network with embedding layer. Furthermore, our model synthesizes the non-linear modeling advantages of multi-layer perceptron based on the linear modeling advantages of matrix factorization. Finally, different from other methods using square error loss function, Bayesian Personalized Ranking optimizes the model from a ranking perspective to obtain the optimal model parameters, which makes full use of the unobserved data. Experiments show that DMFMDA reaches average AUCs of 0.9091 and 0.9103 in the framework of 5-fold cross validation and Leave-one-out cross validation, which is superior to three the-state-of-art methods. In case studies, 10, 9 and 9 out of top-10 candidate microbes are verified by recently published literature for asthma, inflammatory bowel disease and colon cancer, respectively. In conclusion, DMFMDA is successful application of deep learning in the prediction of microbe-disease association.",Not Found
Conference Paper,"Orfanidis C,Darwich AS,Cheong R,Fafoutis X",Monitoring Neurological Disorders with AI-Enabled Wearable Systems,Association for Computing Machinery,2022,https://doi.org/10.1145/3539494.3542755;http://dx.doi.org/10.1145/3539494.3542755,"The age distribution has changed in Europe over the last decade. The group of 45 year-olds and above has increased and the median age in the EU is estimated to increase by 4.5 years during the next 3 decades reaching a median age of approximately 48.2 years according to Eurostat. A similar trend is noticeable in the United States, where the median age increased by 3.3 years from 2000 to 2020 according to Statista. Neurological diseases, such as Huntington disease, have a highly variable onset of 30 - 50 years but they are more prevalent to the older population. One of the first observable physical symptoms is chorea which includes random, uncontrollable and involuntary movements. Internet of Things and wearable systems can assist long-term monitoring of digital biomarkers such as plantar pressure and gait pattern which are associated with the aforementioned neurological disease. Emerging artificial intelligence models can be utilized to monitor the related digital biomarkers and check if these demonstrate a potential pattern denoting the presence or the development of a neurological disease. Enabling long-term monitoring by utilizing a unobtrusive wearable will increase the possibilities of early diagnosis, a longer life expectancy, and an improved quality of life for the patient.","embedded mobile learning, wearable systems, smart health, digital biomarkers"
Conference Paper,"Zeb B,Khan A,Khan Y,Masood MF,Tahir I,Asad M",Towards the Selection of the Best Machine Learning Techniques and Methods for Urinalysis,Association for Computing Machinery,2020,https://doi.org/10.1145/3383972.3384031;http://dx.doi.org/10.1145/3383972.3384031,"Urinalysis is a significant technique used for determining and inspecting the urinary system. Urine has numerous chemical materials secreted; these materials can be used to diagnose diseases and conditions such as urinary tract infection, diabetes, kidney diseases, and pregnancy, at the earliest. Accessing medical care and health screenings are quite essential, but it has become extremely difficult since screening techniques are either very expensive or convoluted for people of low-income communities. Despite the fact, that numerous urinalysis methods and techniques have been brought forth by researchers over the years, no research has been conducted to scrutinize and review state-of-the-art developments in the stated area. Hence, this research aims to conduct a Systematic Literature Review of urinalysis methods proposed and assessed from 2007 to 2019 and recognizes 33 studies. This leads to the identification of 10 methods, 8 technologies, 12 challenges, and 10 diseases. An insight analysis of the identified methods and models reveals that Genetic Based Fuzzy Classifying Method and Automatic Urinary Particle Recognition Method are the most optimum options due to the fact that their computational time is minimum as well as they do not require any supportive hardware. Moreover, the analysis of technologies reveals that Mobile App (Augmented Reality) is the best option among the identified technologies. It has also been discovered that machine/deep learning classification techniques have been used to classify the sample and provide reliable and accurate results within time. Nevertheless, a complete analysis of methods and technologies has been presented. The findings of this article are extremely useful for practitioners as well as academics of the area.","Urinalysis Technologies, Deep Learning, Urinalysis Methods, Urinalysis, Urinalysis Strips, Machine learning Application in Urinalysis"
Conference Paper,"Jiménez AS,Ramírez NA,Santana-Mancilla PC,Romero JC,Acosta-Díaz R",Heuristic Evaluation of a Gamified Application for Education in Patients with Diabetes,Association for Computing Machinery,2018,https://doi.org/10.1145/3293578.3293593;http://dx.doi.org/10.1145/3293578.3293593,"Diabetes is a chronic degenerative disease with increasing number of patients due to unhealthy lifestyles and the lack of information regarding the disease and its correct treatment. In this research work, we propose the design and development of an application to educate patients with diabetes, about their disease, using interactive gamified activities. This paper presents the results obtained from a heuristic evaluation of usability to the application, done by experts, where favorable results were presented in some heuristics such as ""Recognition rather than recall"". The app presented problems in the heuristic ""Help and documentation"" that should be improved to ensure a good usability and therefore a friendly experience for users.","usability evaluation, heuristic evaluation, health education, Diabetes, gamification"
Conference Paper,"Denecke K,Lutz Hochreutener S,Pöpel A,May R",Talking to Ana: A Mobile Self-Anamnesis Application with Conversational User Interface,Association for Computing Machinery,2018,https://doi.org/10.1145/3194658.3194670;http://dx.doi.org/10.1145/3194658.3194670,"Normally, a physician is collecting a patient's medical history under time pressure during the initial patient interview. This leads to incomplete, erroneous data with negative effects on treatment and patient safety. The objective of this work is to introduce a concept for a self-anamnesis realized as a mobile application for patients. We implement the concept for the concrete example of self-anamnesis in music therapy. For this purpose, requirements are collected in discussions with music therapists. A conversational user interface is chosen to simulate the patient-therapist conversation. The self-anamnesis application is equipped with 63 questions that are asked subsequently to the user. We have chosen a rule-based approach for realizing the chat conversation and used the Artificial Intelligence Markup Language (AIML) for encapsulating the questions and responses of the chatbot. In contrast to digital questionnaires, the application of a conversational user interface in the context of collecting information regarding a patient's medical history, provides several benefits: the user can be encouraged to complete all queries and can ask clarifying questions in case something is unclear.","decision support system, mobile application, patient empowerment, anamnesis, conversational user interface"
Conference Paper,"Vu H,Manh XH,Duc BQ,Ha K,Dao VH,Nguyen PB,Hoang BL,Vu TH",Labelling Stomach Anatomical Locations In Upper Gastrointestinal Endoscopic Images Using a CNN,Association for Computing Machinery,2019,https://doi.org/10.1145/3368926.3369704;http://dx.doi.org/10.1145/3368926.3369704,"In this paper, we aim to develop a diagnostic assistant system for labelling the stomach anatomical locations in upper GastroIntestinal Endoscopy (UGIE) examination. To address this task, we construct an appropriate manner which utilizes both ability of a convolutional neural network (CNN) and supportive interactions between machine and doctors. We solve the problem by a two-phase scheme. The first is a coarse-phase to classify seven major anatomical locations including cardiac orifice, gastric body, fundic, antrum, pyloric ring, lesser curvature and greater curvature using advances of a CNN. The constructed CNN network is compact with high performance and appropriate integration into a Graphic User Interface (GUI). In order to classify with 13 further detailed positions, a GUI is developed so that the endoscopists can conveniently specify the anatomical locations from results of the coarse-phase. In this the fine-phase, the doctors will prune the automatic results as well as specify the more detailed positions of each major location. In the experimental results, the developed application is shown as an efficient way in an UGIE diagnosis. It reduces a significant time from averagely 13:03 minutes in a manual procedure to 4:35 minutes by using the developed system when comparing with trainee endoscopists. The results of specifying anatomical locations satisfied accuracy requirements and showed promising research trend for future application as a computer-aided GIE diagnostic system.","Anatomical gastric image, Upper GastroIntestinal Endoscopy, Convolutional Neural Networks"
Conference Paper,"Mishra S,Chaudhury P,Mishra BK,Tripathy HK",An Implementation of Feature Ranking Using Machine Learning Techniques for Diabetes Disease Prediction,Association for Computing Machinery,2016,https://doi.org/10.1145/2905055.2905100;http://dx.doi.org/10.1145/2905055.2905100,"Disease diagnosis is an application area where machine learning tools are providing successful results. Diabetes disease is one of the crucial factors of death all over the world. The availability of huge amounts of medical data leads to the need for powerful learning tools to help medical experts to diagnose diabetes disease. Machine learning methods are helpful in the diagnosis of diabetes disease, showing a reasonable level of efficiency. But these data are redundant and are noisy in nature which negatively affects the process of observing knowledge and useful pattern. Machine learning techniques have attracted a big attention to researchers to turn such data into useful knowledge. Further relevant data can be extracted from huge records using filter based feature selection methods. In our study, a comparative analysis is drawn between four different filter based feature selection methods (Chisquare method, Information gain method, Cluster Variation method and Correlation method) based on Diabetes disease. Three classifiers (RBF, IBK and JRip) were implemented to estimate the performance of the algorithms. The study revealed that filter based feature selection methods enhance the performance of learning algorithms in effective prediction and diagnosis of diabetes disease.","Feature Ranking, Feature Selection, IBK, F-Score, RBF, Filters, JRip, RMSE"
Conference Paper,Ye C,Research and Analysis of Predictive Models for Diabetes Mellitus Using Machine Learning: Active Learning vs. Random Sampling,Association for Computing Machinery,2021,https://doi.org/10.1145/3500931.3500957;http://dx.doi.org/10.1145/3500931.3500957,"Diabetes Mellitus is one of the most significant chronic metabolic diseases characterized by persistent hyperglycemia affecting human beings in the last few decades. Currently, many research groups are working for building a predictive model to help prevent diabetes. However, the laboratory data and results are usually expensive to collect and are hard to access to. Thus, to reduce the size of the required dataset, this paper analyzes whether active learning can achieve higher effectiveness than random sampling when constructing a predictive model with fewer data to identify people at risk of having Diabetes Mellitus before diagnosis.Testing accuracy and the area under the receiver operating characteristic curve (AROC) were used to evaluate the discriminatory capability of these models. Through modeling experiments and comparisons of the two measurements, the results show that models of active learning methods can perform better than the ones using random sampling while only teaching them a small-size of the dataset.","Diabetes Mellitus, Random Sampling, Machine Learning, Active Learning"
Journal Article,"Ordookhanians A,Li X,Nakandala S,Kumar A",Demonstration of Krypton: Optimized CNN Inference for Occlusion-Based Deep CNN Explanations,VLDB Endowment,2019,https://doi.org/10.14778/3352063.3352093;http://dx.doi.org/10.14778/3352063.3352093,"In this demonstration, we present Krypton, a system for accelerating occlusion-based deep convolution neural network (CNN) explanation workloads. Driven by the success of CNNs in image understanding tasks, there is growing adoption of CNNs in various domains, including high stakes applications such as radiology. However, users of such applications often seek an ""explanation"" for why a CNN predicted a certain label. One of the most widely used approaches for explaining CNN predictions is the occlusion-based explanation (OBE) method. This approach is computationally expensive due to the large number of re-inference requests produced. Krypton reduces the runtime of OBE by up to 35x by enabling incremental and approximate inference optimizations that are inspired by classical database query optimization techniques. We allow the audience to interactively diagnose CNN predictions from several use cases, including radiology and natural images. A short video of our demonstration can be found here: https://youtu.be/1OWddbd4n6Y",Not Found
Conference Paper,"Sohn E,Noh KR,Lee B,Kwon OJ",Bibliometric Network Analysis and Visualization of Research and Development Trends in Precision Medicine,IEEE Press,2020,Not Found,"Precision medicine which refers to a new treatment and prevention method based on understanding of individual gene, environment and life style have emerged as a new healthcare paradigm to lead future medicine. With the rapid progress of the fourth industrial revolution technologies such as big data, artificial intelligence, and internet of things, it is drawing attention to the opportunities and challenges of precision medicine. There is currently no comprehensive overview of precision medicine of approaches to scientometric analysis, and this study aims to provide an overview of the research and development trends in precision medicine by bibliometric network analysis. Total 7,324 articles were retrieved and analyzed using some scientometric analysis tools such as KnowledgeMatrix Plus, Gephi and VOSviewer software. Particularly, each nation's research activities and their global relative positions, international research collaboration in this field have also been analyzed and identified by scientometric method through network and co-word analysis and visualization maps.","research trend, bibliometric analysis, network analysis, scientometric analysis, precision medicine, visualization map"
Conference Paper,"Marcos-Pablos S,Juanes Méndez JA,Walters ML",State-of-the-Art Technologies at the Service of Medical Training and Practice to Foster Digital Health Ecosystems,Association for Computing Machinery,2021,https://doi.org/10.1145/3434780.3436700;http://dx.doi.org/10.1145/3434780.3436700,"During the last decades, technological revolution is creating unprecedented opportunities and challenges. No industry is exempt from this revolution, and in the field of medicine and healthcare, the impact is even more remarkable. Each person, with only one mobile application can synchronize their habits and lifestyle.Technological advances are changing the structure and organization of the medical ecosystem through a transformation driven by developments in the areas including big data, Internet of Things (IoT), artificial intelligence (AI), robotics, 3D printing and virtual reality. The potential of these not-so-new technologies in the computer domain when applied to the health sector lies in the possibility of combining traditional medial approaches with other new forms of health data management and visualization, patient care, prosthetics, surgery, etc.The aim of this track is to collect some of the most innovative computer based technological developments applied to both the contexts of biomedical training and clinical practice, as well as in other fields related to Health Sciences training; providing an excellent opportunity for the promotion and exchange of innovative teaching experiences in the health field, especially those based on the use of state-of-the-art technology.","medical technologies, medical training and education, new technologies for health care, Digital Health Ecosystems"
Conference Paper,"Al-Sideiri A,Cob ZB,Drus SB",Machine Learning Algorithms for Diabetes Prediction: A Review Paper,Association for Computing Machinery,2020,https://doi.org/10.1145/3388218.3388231;http://dx.doi.org/10.1145/3388218.3388231,"The early diagnosis of the diabetes disease is a very important for cure process, and that provides an ease process of treatment for both the patient and the doctor. At this point, statistical methods and data mining algorithms can provide significance chances for early diagnosis of diabetes mellitus (DM). In the literature, many studies have been published for solution of this problem. Initially, these studies are analyzed in detail and classified according to their methodologies. The main aim of this paper is to provide the comprehensive and detailed review of the diagnosis of diabetes by machine learning algorithms. Also, this paper presents a literature review on the diagnosis diabetes up to the mid of 2019. This paper provides to guide future research and knowledge accumulation and creation of classification and prediction techniques in diagnosis of diabetes. This study shows that the Support Vector Machine (SVM) algorithm is the most used machine learning algorithms and it provide more accurate and powerful results.","SVM, decision tree, KNN, Machine learning, diabetes prediction"
Conference Paper,"Ismail A,Kumar N",AI in Global Health: The View from the Front Lines,Association for Computing Machinery,2021,https://doi.org/10.1145/3411764.3445130;http://dx.doi.org/10.1145/3411764.3445130,"There has been growing interest in the application of AI for Social Good, motivated by scarce and unequal resources globally. We focus on the case of AI in frontline health, a Social Good domain that is increasingly a topic of significant attention. We offer a thematic discourse analysis of scientific and grey literature to identify prominent applications of AI in frontline health, motivations driving this work, stakeholders involved, and levels of engagement with the local context. We then uncover design considerations for these systems, drawing from data from three years of ethnographic fieldwork with women frontline health workers and women from marginalized communities in Delhi (India). Finally, we outline an agenda for AI systems that target Social Good, drawing from literature on HCI4D, post-development critique, and transnational feminist theory. Our paper thus offers a critical and ethnographic perspective to inform the design of AI systems that target social impact.","India, Healthcare, Qualitative, AI, HCI4D, Social Good"
Journal Article,"Yadav S,Ramteke P,Ekbal A,Saha S,Bhattacharyya P",Exploring Disorder-Aware Attention for Clinical Event Extraction,Association for Computing Machinery,2020,https://doi.org/10.1145/3372328;http://dx.doi.org/10.1145/3372328,"Event extraction is one of the crucial tasks in biomedical text mining that aims to extract specific information concerning incidents embedded in the texts. In this article, we propose a deep learning framework that aims to identify the attributes (severity, course, temporal expression, and document creation time) associated with the medical concepts extracted from electronic medical records. The bi-directional long short-term memory network assisted by the attention mechanism is utilized to uncover the important aspects of the patient’s medical conditions. The attention mechanism specific to the medical disorder mention can focus on various parts of the sentence when different disorders are considered as input. The proposed methodology is evaluated on benchmark ShARe/CLEF eHealth Evaluation Lab 2014 shared task 2 datasets. In addition to the CLEF dataset, we also used the social media text, especially the medical blog posts. Experimental results of the proposed approach illustrate that our proposed approach achieves significant performance improvements over the state-of-the-art techniques and the highly competitive deep learning--based baseline methods.","attention, social media, clinical event extraction, Neural networks, temporal event extraction, event extraction"
Conference Paper,"Zafar F,Raza S,Khalid MU,Tahir MA",Predictive Analytics in Healthcare for Diabetes Prediction,Association for Computing Machinery,2019,https://doi.org/10.1145/3326172.3326213;http://dx.doi.org/10.1145/3326172.3326213,"Diabetes mellitus type 2 is a chronic disease which poses a serious challenge to human health worldwide. Globally, about 8.3% of the population is diagnosed with the disease. The applications of predictive analytics in diagnosis of diabetes are gaining significant momentum in medical research. The aim of this research paper is to aid medical professionals in the early detection and efficient diagnosis of Type 2 diabetes. We utilize bioinformatics theory and supervised machine learning techniques for improving the accuracy in predicting diabetes, based on 8 clinical measurements existing in the widely used PIMA dataset. We outline our methodology and highlight the implementation steps, while reviewing prominent past work in the field. Moreover, this paper fully exploits known machine learning algorithms and provides a detailed comparison of the results obtained from each method. The gradient boosting algorithm with parameter tuning proves to be the most successful, having an F1 Score of 0.853 and out of sample accuracy of 89.94%. Our prediction model focuses on computing the probability of the onset of diabetes in an individual based on their clinical data. The most crucial results of using this research within the healthcare sector are its cost-effectiveness and yielding of instant diagnosis. With this work, we intend to improve the process of diagnosing Type 2 diabetes and inspire other researchers to use machine learning based techniques for further inquiry into diabetes prediction.","Gradient Boosting, Machine Learning, Bioinformatics, Diabetes Prediction"
Conference Paper,"G. Mitchell E,M. Heitkemper E,Burgermaster M,E. Levine M,Miao Y,L. Hwang M,M. Desai P,Cassells A,N. Tobin J,G. Tabak E,J. Albers D,M. Smaldone A,Mamykina L",From Reflection to Action: Combining Machine Learning with Expert Knowledge for Nutrition Goal Recommendations,Association for Computing Machinery,2021,https://doi.org/10.1145/3411764.3445555;http://dx.doi.org/10.1145/3411764.3445555,"Self-tracking can help personalize self-management interventions for chronic conditions like type 2 diabetes (T2D), but reflecting on personal data requires motivation and literacy. Machine learning (ML) methods can identify patterns, but a key challenge is making actionable suggestions based on personal health data. We introduce GlucoGoalie, which combines ML with an expert system to translate ML output into personalized nutrition goal suggestions for individuals with T2D. In a controlled experiment, participants with T2D found that goal suggestions were understandable and actionable. A 4-week in-the-wild deployment study showed that receiving goal suggestions augmented participants’ self-discovery, choosing goals highlighted the multifaceted nature of personal preferences, and the experience of following goals demonstrated the importance of feedback and context. However, we identified tensions between abstract goals and concrete eating experiences and found static text too ambiguous for complex concepts. We discuss implications for ML-based interventions and the need for systems that offer more interactivity, feedback, and negotiation.","Personal Informatics, Machine learning, Goal setting, Diabetes self-management"
Conference Paper,"Marrugo AG,Šroubek F,Šorel M,Millán MS",Multichannel Blind Deconvolution in Eye Fundus Imaging,Association for Computing Machinery,2011,https://doi.org/10.1145/2093698.2093705;http://dx.doi.org/10.1145/2093698.2093705,"Eye fundus imaging is vital for modern ophthalmology. Due to the acquisition process, fundus images often suffer from blurring and uneven illumination. This hinders diagnosis and the evolution assessment of a disease. We present a method for fundus image deblurring by means of multichannel blind deconvolution. It consists of a series of preprocessing steps to adjust the images so they comply with the considered degradation model, followed by the estimation of the point spread function, and image deconvolution. Results show that our approach is capable of significant resolution improvement in degraded retinal images.","fundus image, blind deconvolution, medical image"
Conference Paper,"Xu H,Kong Y,Tan S",Predictive Modeling of Diabetic Kidney Disease Using Random Forest Algorithm along with Features Selection,Association for Computing Machinery,2020,https://doi.org/10.1145/3429889.3429894;http://dx.doi.org/10.1145/3429889.3429894,"At present, the number of diabetes mellitus patients in China ranks first in the world, and diabetic kidney disease is the most common disease in complications. Therefore, it is necessary to establish a predictive model for early diagnosis of diabetic kidney disease. The model predicts the risk of diabetic kidney disease in the general Asian population, and recognizes high-risk groups, then warns the onset of diabetes. The data were obtained from the electronic medical record of patients in Beijing Pinggu Hospital. Twenty-nine initial candidate indicators including age, ALB, and A/C were selected. The random forest algorithm was used to predict diabetic kidney disease, and the classification accuracy was 89.831%. The importance weight ratio of each factor index was also given, Microalbuminuria (ALB), albumin-to-creatinine ratio (A/C), serum creatinine (SCr), Serum albumin (umALB), and blood urea nitrogen (BUN) accounted for a relatively high proportion of the weight of the characteristic variables. So these five indicators can be the primary indicators of our classification prediction, and the accuracy can reach 87.453%. Some other typical classification algorithms, liking KNN, logistic regression, and decision tree, were compared to classify and predict diabetic kidney disease, and precision recall f1-score and area AUC under ROC curve were used to evaluate these models. By experiments, random forest model was better than other algorithm models on both the classification accuracy and the evaluation indicators. The results can be applied to the screening of patients with high risk of diabetic kidney disease and the guidance of risk intervention measures. Consequently, the detection rate of undiagnosed diabetic kidney disease in the population can be improved, and the prevention effect of diabetic kidney disease can be enhanced as well.","Random forest, diabetic kidney disease, risk prediction"
Conference Paper,"Ma F,Gao J,Suo Q,You Q,Zhou J,Zhang A",Risk Prediction on Electronic Health Records with Prior Medical Knowledge,Association for Computing Machinery,2018,https://doi.org/10.1145/3219819.3220020;http://dx.doi.org/10.1145/3219819.3220020,"Predicting the risk of potential diseases from Electronic Health Records (EHR) has attracted considerable attention in recent years, especially with the development of deep learning techniques. Compared with traditional machine learning models, deep learning based approaches achieve superior performance on risk prediction task. However, none of existing work explicitly takes prior medical knowledge (such as the relationships between diseases and corresponding risk factors) into account. In medical domain, knowledge is usually represented by discrete and arbitrary rules. Thus, how to integrate such medical rules into existing risk prediction models to improve the performance is a challenge. To tackle this challenge, we propose a novel and general framework called PRIME for risk prediction task, which can successfully incorporate discrete prior medical knowledge into all of the state-of-the-art predictive models using posterior regularization technique. Different from traditional posterior regularization, we do not need to manually set a bound for each piece of prior medical knowledge when modeling desired distribution of the target disease on patients. Moreover, the proposed PRIME can automatically learn the importance of different prior knowledge with a log-linear model.Experimental results on three real medical datasets demonstrate the effectiveness of the proposed framework for the task of risk prediction","healthcare informatics, prior medical knowledge, posterior regularization"
Conference Paper,"Serhani MA,Navaz AN,Al Ashwal H,Al Qirim N",ECG-Based Arrhythmia Classification & Clinical Suggestions: An Incremental Approach of Hyperparameter Tuning,Association for Computing Machinery,2020,https://doi.org/10.1145/3419604.3419787;http://dx.doi.org/10.1145/3419604.3419787,"Cardiovascular diseases (CVD) are the principal cause of death globally. Electrocardiography (ECG) is a widely adopted tool to quantify heart activities to detect any heart abnormalities. Arrhythmia is one of these CVDs that heavily relies on continuous ECG recordings in order to detect and predict irregularities in the heart rhythms. Various Deep Learning (DL) approaches has been heavily used to classify and predict different heart rhythms. However, most of the proposed works do not consider the various hyperparameter optimization and tuning to get the full potential of the DL model and achieve higher accuracy. Besides, very few works implemented the full monitoring cycle and close the loop to propose some clinical and non-clinical recommendations. Therefore, in this paper, we adopt the Convolutional Neural Network (CNN) model and we apply various parameter optimization to capture various properties of the data, the training, and the model. We also close the monitoring loop and suggest tailored recommendations for each category of arrhythmia that go beyond simple to more deeper diagnosis using the Global Registry of Acute Coronary Events (GRACE), and the European Guidelines on CVDs prevention in clinical practice (ESC/EAS 2016). We conducted a set of experiments to evaluate our model and the set of hyperparameter optimization we have experienced and the results we have obtained showed significant improvement in the prediction accuracy after a couple of optimization iterations.","CNN, Deep learning, prediction, hyperparameters, recommendations, CVDs, arrhythmia"
Conference Paper,"Wu H,Wang MD",Infer Cause of Death for Population Health Using Convolutional Neural Network,Association for Computing Machinery,2017,https://doi.org/10.1145/3107411.3107447;http://dx.doi.org/10.1145/3107411.3107447,"In biomedical data analysis, inferring the cause of death is a challenging and important task, which is useful for both public health reporting purposes, as well as improving patients' quality of care by identifying severer conditions. Causal inference, however, is notoriously difficult. Traditional causal inference mainly relies on analyzing data collected from experiment of specific design, which is expensive, and limited to a certain disease cohort, making the approach less generalizable. In our paper, we adopt a novel data-driven perspective to analyze and improve the death reporting process, to assist physicians identify the single underlying cause of death. To achieve this, we build state-of-the-art deep learning models, convolution neural network (CNN), and achieve around 75% accuracy in predicting the single underlying cause of death from a list of relevant medical conditions. We also provide interpretations for the black-box neural network models, so that death reporting physicians can apply the model with better understanding of the model.","causal inference, deep learning, interpretability"
Conference Paper,"Al Mehedi Hasan M,Shin J,Parvin F",Deep Transfer Learning Based Detection of COVID-19 from Chest X-Ray Images,Association for Computing Machinery,2021,https://doi.org/10.1145/3460238.3460249;http://dx.doi.org/10.1145/3460238.3460249,"The novel COVID-19 coronavirus has become an important threatening issue now for billions of humans. But lacking of available testing kits lead us to develop automatic detection system to prevent the spread of COVID-19. Since, most COVID-19 patients suffer the lung infection, chest X-ray can be used to be an effective imaging technique to detect COVID-19. Because of the limited number of COVID-19 chest X-ray images, it is efficient to use deep transfer learning that can provide a promising solution by transferring knowledge from generic object recognition task to domain-specific task. In this work, we aim to develop a deep transfer learning based detection of COVID-19 from chest X-ray images using imageNet pre-trained VGG-16 deep CNN model. We develop six binary classifiers for different chest X-ray image data and then integrate all the classifiers to produce a final classifier to predict COVID-19 from non COVID-19 cases (normal and other disease). To evaluate all the models, we have collected COVID-19 chest X-ray images from two open source GitHub repository and others chest X-ray images from RSNA Pneumonia Detection Challenge dataset. The experimental result shows the capability of our final classifier in the detection of COVID-19 by evaluating it with an independent testset. It also shows that our classifier achieved a high accuracy of 93% (with sensitivity of 87%, specificity of 94%, precision of 100% and F1-Score of 93%) in the detection of COVID-19 X-ray images from normal and other disease.","Convolutional Neural Network, Pneumonia, Deep Transfer Learning, Coronavirus, Chest X-ray images"
Conference Paper,"Goyal A,Kumar K",Analysis of Various Diabetic Prediction Methods of Machine Learning,Association for Computing Machinery,2022,https://doi.org/10.1145/3484824.3484898;http://dx.doi.org/10.1145/3484824.3484898,"The method that can derive valuable information from rough data is data mining. Prediction analysis is a data mining technique that predicts future possibilities from current knowledge. A range of statistical techniques (including machine learning, predictive modelling and data mining) are included in predictive analytics and statistics (both historical and current) to estimate, predict, and predict future results. There are different steps in the prediction analysis that include pre-processing, extraction of features and classification. This paper is focused on the use of machine learning techniques for diabetic prediction. In this paper, different techniques for diabetic prediction are reviewed based on machine learning.","data mining and classification, Machine learning, Prediction, Diabetic"
Conference Paper,"Zhang Y,Li J,Qu P,Yao W,Lu C",Analysis and Prediction of Diabetes Incidence Based on Big Data,Association for Computing Machinery,2022,https://doi.org/10.1145/3565291.3565292;http://dx.doi.org/10.1145/3565291.3565292,"Diabetes mellitus is a metabolic chronic disease caused by many reasons, which can not be eradicated. It can be judged by checking the blood sugar test. Due to the increasing development of big data technology, the application of big data related technologies in the medical field is also increasingly in-depth. Therefore, this paper analyzes and predicts the morbidity of diabetes based on the diabetes data set of Pima Indians. First, the data set is processed with missing values, outlier detection, data transformation, data segmentation and other operations. After the data preprocessing operation, the related models are cross-validated, among which the random forest prediction model has the best parameter performance, so the random forest model is determined to be constructed. Secondly, the hyperparameters of the random forest machine learning model are optimized, and the relevant indicators for model evaluation in the classification report are calculated by designing the confusion matrix parameters of the test set, so as to evaluate the performance of the random forest model. Finally, the accuracy of the model constructed by random forest machine learning algorithm is obtained, and the prediction results of diabetic patients are given. Through the visual comparative analysis of different attribute labels, the main influencing factors of diabetes are obtained, which provides an auxiliary reference for the treatment and early warning of diabetes.","random forest, machine learning, diabetes, visual analysis"
Conference Paper,"Shibly MM,Tisha TA,Islam MK,Uddin MM",Transfer Learning in Classifying Prescriptions and Keyword-Based Medical Notes,Association for Computing Machinery,2021,https://doi.org/10.1145/3428757.3429139;http://dx.doi.org/10.1145/3428757.3429139,"Medical text classification is one of the primary steps of health care automation. Diagnosing disease at the right time, and going to the right doctor is important for patients. To do that, two types of medical texts were classified into some medical specialties in this study. The first one is the keywords-based medical notes and the second one is the prescriptions. There are many methods and techniques to classify texts from any domain. But, textual resources of a specific domain can be inadequate to build a sustainable and accurate classifier. This problem can be solved by incorporating transfer learning. The objective of this study is to analyze the prospects of transfer learning in medical text classification. To do that, a transfer learning system has been created for classification tasks by fine-tuning Bidirectional Encoder Representations from Transformers aka the BERT language model, and its performance has been compared with three deep learning models - multi-layer perceptron, long short-term memory, and convolutional neural network. The fine-tuned BERT model has shown the best performance among all the other models in both classification tasks. It has 0.84 and 0.96 weighted f1-score in classifying medical notes and prescriptions respectively. This study has proved that transfer learning can be used in medical text classification, and significant improvement in performance can be achieved through it.","medical notes, Transfer learning, BERT, prescriptions, neural networks, natural language processing, medical text classification"
Conference Paper,"He W,Chen T",Scalable Online Disease Diagnosis via Multi-Model-Fused Actor-Critic Reinforcement Learning,Association for Computing Machinery,2022,https://doi.org/10.1145/3534678.3542672;http://dx.doi.org/10.1145/3534678.3542672,"For those seeking healthcare advice online, AI based dialogue agents capable of interacting with patients to perform automatic disease diagnosis are a viable option. This application necessitates efficient inquiry of relevant disease symptoms in order to make accurate diagnosis recommendations. This can be formulated as a problem of sequential feature (symptom) selection and classification for which reinforcement learning (RL) approaches have been proposed as a natural solution. They perform well when the feature space is small, that is, the number of symptoms and diagnosable disease categories is limited, but they frequently fail in assignments with a large number of features. To address this challenge, we propose a Multi-Model-Fused Actor-Critic (MMF-AC) RL framework that consists of a generative actor network and a diagnostic critic network. The actor incorporates a Variational AutoEncoder (VAE) to model the uncertainty induced by partial observations of features, thereby facilitating in making appropriate inquiries. In the critic network, a supervised diagnosis model for disease predictions is involved to precisely estimate the state-value function. Furthermore, inspired by the medical concept of differential diagnosis, we combine the generative and diagnosis models to create a novel reward shaping mechanism to address the sparse reward problem in large search spaces. We conduct extensive experiments on both synthetic and real-world datasets for empirical evaluations. The results demonstrate that our approach outperforms state-of-the-art methods in terms of diagnostic accuracy and interaction efficiency while also being more effectively scalable to large search spaces. Besides, our method is adaptable to both categorical and continuous features, making it ideal for online applications.","self-diagnosis, reinforcement learning, online disease diagnosis"
Conference Paper,"Chen G,Baghaei N,Sarrafzadeh A,Manford C,Marshall S,Court G",Designing Games to Educate Diabetic Children,Association for Computing Machinery,2011,https://doi.org/10.1145/2071536.2071546;http://dx.doi.org/10.1145/2071536.2071546,"The use of computer games as common vehicles for education, as opposed to pure entertainment, has gained popularity in recent years. Traditional method for diabetes education relies heavily on written materials and there is only a limited amount of resources targeted at educating diabetic children. In this paper, we present a novel approach for designing computer games aimed for educating children with diabetes. Our game design was applied to an existing open source game (Mario Brothers). The results of a pilot study showed that participants enjoyed playing the game and found it valuable for educating diabetic patients.","game design, engagement, diabetes, education"
Conference Paper,"Prange A,Sonntag D",Assessing Cognitive Test Performance Using Automatic Digital Pen Features Analysis,Association for Computing Machinery,2021,https://doi.org/10.1145/3450613.3456812;http://dx.doi.org/10.1145/3450613.3456812,"Most cognitive assessments, for dementia screening for example, are conducted with a pen on normal paper. We record these tests with a digital pen as part of a new interactive cognitive assessment tool with automatic analysis of pen input. The clinician can, first, observe the sketching process in real-time on a mobile tablet, e.g., in telemedicine settings or to follow Covid-19 distancing regulations. Second, the results of an automatic test analysis are presented to the clinician in real-time, thereby reducing manual scoring effort and producing objective reports. The presented research describes the architecture of our cognitive assessment tool and examines how accurately different machine learning (ML) models can automatically score cognitive tests, without a semantic content analysis. Our system uses a set of more than 170 pen features, calculated directly from the raw digital pen signal. We evaluate our system with 40 subjects from a geriatrics daycare clinic. Using standard ML techniques our feature set outperforms previous approaches on the cognitive tests we consider, i.e., the Clock Drawing, the Rey-Osterrieth Complex Figure, and the Trail Making Test, by automatically scoring tests with up to 82% accuracy in a binary classification task.","Neurocognitive Testing, Machine Learning, Deep Learning, Pen Features, Clock Drawing Test, Rey-Osterrieth Complex Figure, Digital Pen, Cognitive Assessments, Trail Making Test"
Conference Paper,Berend D,Distribution Awareness for AI System Testing,IEEE Press,2021,https://doi.org/10.1109/ICSE-Companion52605.2021.00045;http://dx.doi.org/10.1109/ICSE-Companion52605.2021.00045,"As Deep Learning (DL) is continuously adopted in many safety critical applications, its quality and reliability start to raise concerns. Similar to the traditional software development process, testing the DL software to uncover its defects at an early stage is an effective way to reduce risks after deployment. Although recent progress has been made in designing novel testing techniques for DL software, the distribution of generated test data is not taken into consideration. It is therefore hard to judge whether the identified errors are indeed meaningful errors to the DL application. Therefore, we propose a new distribution aware testing technique which aims to generate new unseen test cases relevant to the underlying DL system task. Our results show that this technique is able to filter up to 55.44% of error test case on CIFAR-10 and is 10.05% more effective in enhancing robustness.","deep learning, software testing, distribution awareness"
Conference Paper,"Ramesh V,Nguyen A,Agrawal K,Meyer BC,Cauwenberghs G,Weibel N",Assessing Clinicians' Reliance on Computational Aids for Acute Stroke Diagnosis,Association for Computing Machinery,2021,https://doi.org/10.1145/3421937.3422019;http://dx.doi.org/10.1145/3421937.3422019,"The rapid rise of computational aids for stroke diagnosis have led to important concerns about clinicians developing an over-dependence on technology. Other studies have assessed reliance on clinical decision support systems in fields like diabetes, but no such study exists for stroke diagnosis. In this work, we developed a high-fidelity user interface for a computational aid designed to support acute ischemic stroke diagnosis. Engaging with stroke practitioners at the UCSD Stroke Center, we conducted an experiment to determine how technology for identifying stroke symptoms may affect their diagnostic decision-making processes. By assessing how clinicians changed their video-based diagnosis of stroke when provided with data visualizations and predictions from a machine learning tool, we observed that such computational aids do in fact affect clinicians' decisions but only in cases when the aid directly supports or contradicts their prior beliefs. Future computational aids for stroke diagnosis should focus on helping clinicians solidify their decisions rather than only providing them with overly quantitative information that may impede or confuse their judgement.","Clinical Decision Support, Clinician Reliance, Computational Aids, Automation Bias, Machine Learning, Stroke Diagnosis, Ubiquitous Computing"
Conference Paper,"Cai Q,Yin H,Liu D,Liu P",Using Learnt Nakagami Parametric Mapping to Classify Fatty Liver in Rabbits,Association for Computing Machinery,2021,https://doi.org/10.1145/3451421.3451460;http://dx.doi.org/10.1145/3451421.3451460,"Abstract: Fatty liver disease is a condition where large vacuoles of fats accumulate in the liver cells. Based on statistical analysis of the backscattered signals, the ultrasound Nakagami image is an emerging technique for assessing FLD. In this study, we present a non-invasive deep learning method classifying liver steatosis based on ultrasonic Nakagami parametric mapping. Two different classifiers: convolutional neural network (CNN), the combination of CNN and multi-class support machine (MSVM), are used in this study. We use two sets of Nakagami parameters (constructed using the sliding window technique to process the raw backscattered fundamental and the second harmonic envelopes signal respectively) to train this classification model. Experimental results of 10-fold cross-validation show that the proposed improved classification model (CNN + MSVM with liner kernel) reaches a high classification accuracy (85.48%). Thus, such a method can be potentially beneficial to assist clinicians in diagnosis.","Fatty liver, Multi-class support vector machine, Ultrasound, Convolutional neural network, Nakagami"
Conference Paper,"Huang JH,Wu TW,Worring M",Contextualized Keyword Representations for Multi-Modal Retinal Image Captioning,Association for Computing Machinery,2021,https://doi.org/10.1145/3460426.3463667;http://dx.doi.org/10.1145/3460426.3463667,"Medical image captioning automatically generates a medical description to describe the content of a given medical image. Traditional medical image captioning models create a medical description based on a single medical image input only. Hence, an abstract medical description or concept is hard to be generated based on the traditional approach. Such a method limits the effectiveness of medical image captioning. Multi-modal medical image captioning is one of the approaches utilized to address this problem. In multi-modal medical image captioning, textual input, e.g., expert-defined keywords, is considered as one of the main drivers of medical description generation. Thus, encoding the textual input and the medical image effectively are both important for the task of multi-modal medical image captioning. In this work, a new end-to-end deep multi-modal medical image captioning model is proposed. Contextualized keyword representations, textual feature reinforcement, and masked self-attention are used to develop the proposed approach. Based on the evaluation of an existing multi-modal medical image captioning dataset, experimental results show that the proposed model is effective with an increase of +53.2% in BLEU-avg and +18.6% in CIDEr, compared with the state-of-the-art method. https://github.com/Jhhuangkay/Contextualized-Keyword-Representations-for-Multi-modal-Retinal-Image-Captioning","multi-modal medical image captioning, contextualized word representations, retinal images"
Journal Article,"Pichon A,Schiffer K,Horan E,Massey B,Bakken S,Mamykina L,Elhadad N",Divided We Stand: The Collaborative Work of Patients and Providers in an Enigmatic Chronic Disease,Association for Computing Machinery,2021,https://doi.org/10.1145/3434170;http://dx.doi.org/10.1145/3434170,"In chronic conditions, patients and providers need support in understanding and managing illness over time. Focusing on endometriosis, an enigmatic chronic condition, we conducted interviews with specialists and focus groups with patients to elicit their work in care specifically pertaining to dealing with an enigmatic disease, both independently and in partnership, and how technology could support these efforts. We found that the work to care for the illness, including reflecting on the illness experience and planning for care, is significantly compounded by the complex nature of the disease: enigmatic condition means uncertainty and frustration in care and management; the multi-factorial and systemic features of endometriosis without any guidance to interpret them overwhelm patients and providers; the different temporal resolutions of this chronic condition confuse both patients and providers; and patients and providers negotiate medical knowledge and expertise in an attempt to align their perspectives. We note how this added complexity demands that patients and providers work together to find common ground and align perspectives, and propose three design opportunities (considerations to construct a holistic picture of the patient, design features to reflect and make sense of the illness, and opportunities and mechanisms to correct misalignments and plan for care) and implications to support patients and providers in their care work. Specifically, the enigmatic nature of endometriosis necessitates complementary approaches from human-centered computing and artificial intelligence, and thus opens a number of future research avenues.","illness work, enigmatic disease, patient-provider partnership"
Conference Paper,"Ramazi R,Perndorfer C,Soriano E,Laurenceau JP,Beheshti R",Multi-Modal Predictive Models of Diabetes Progression,Association for Computing Machinery,2019,https://doi.org/10.1145/3307339.3342177;http://dx.doi.org/10.1145/3307339.3342177,"With the increasing availability of wearable devices, continuous monitoring of individuals' physiological and behavioral patterns has become significantly more accessible. Access to these continuous patterns about individuals' statuses offers an unprecedented opportunity for studying complex diseases and health conditions such as type 2 diabetes (T2D). T2D is a widely common chronic disease that its roots and progression patterns are not fully understood. Predicting the progression of T2D can inform timely and more effective interventions to prevent or manage the disease. In this study, we have used a dataset related to 63 patients with T2D that includes the data from two different types of wearable devices worn by the patients: continuous glucose monitoring (CGM) devices and activity trackers (ActiGraphs). Using this dataset, we created a model for predicting the levels of four major biomarkers related to T2D after a one-year period. We developed a wide and deep neural network and used the data from the demographic information, lab tests, and wearable sensors to create the model. The deep part of our method was developed based on the long short-term memory (LSTM) structure to process the time-series dataset collected by the wearables. In predicting the patterns of the four biomarkers, we have obtained a root mean square error of ±1.67% for HBA1c, ±6.22 mg/dl for HDL cholesterol, ±10.46 mg/dl for LDL cholesterol, and ±18.38 mg/dl for Triglyceride. Compared to existing models for studying T2D, our model offers a more comprehensive tool for combining a large variety of factors that contribute to the disease.","wearable medical devices, continuous glucose monitoring, recurrent neural networks, activity trackers, type 2 diabetes"
Conference Paper,"Ma F,Chitta R,Zhou J,You Q,Sun T,Gao J",Dipole: Diagnosis Prediction in Healthcare via Attention-Based Bidirectional Recurrent Neural Networks,Association for Computing Machinery,2017,https://doi.org/10.1145/3097983.3098088;http://dx.doi.org/10.1145/3097983.3098088,"Predicting the future health information of patients from the historical Electronic Health Records (EHR) is a core research task in the development of personalized healthcare. Patient EHR data consist of sequences of visits over time, where each visit contains multiple medical codes, including diagnosis, medication, and procedure codes. The most important challenges for this task are to model the temporality and high dimensionality of sequential EHR data and to interpret the prediction results. Existing work solves this problem by employing recurrent neural networks (RNNs) to model EHR data and utilizing simple attention mechanism to interpret the results. However, RNN-based approaches suffer from the problem that the performance of RNNs drops when the length of sequences is large, and the relationships between subsequent visits are ignored by current RNN-based approaches. To address these issues, we propose Dipole, an end-to-end, simple and robust model for predicting patients' future health information. Dipole employs bidirectional recurrent neural networks to remember all the information of both the past visits and the future visits, and it introduces three attention mechanisms to measure the relationships of different visits for the prediction. With the attention mechanisms, Dipole can interpret the prediction results effectively. Dipole also allows us to interpret the learned medical code representations which are confirmed positively by medical experts. Experimental results on two real world EHR datasets show that the proposed Dipole can significantly improve the prediction accuracy compared with the state-of-the-art diagnosis prediction approaches and provide clinically meaningful interpretation.","bidirectional recurrent neural networks, attention mechanism, healthcare informatics"
Journal Article,"Safi M,Dadkhah S,Shoeleh F,Mahdikhani H,Molyneaux H,Ghorbani AA","A Survey on IoT Profiling, Fingerprinting, and Identification",Association for Computing Machinery,2022,https://doi.org/10.1145/3539736;http://dx.doi.org/10.1145/3539736,"The proliferation of heterogeneous Internet of things (IoT) devices connected to the Internet produces several operational and security challenges, such as monitoring, detecting, and recognizing millions of interconnected IoT devices. Network and system administrators must correctly identify which devices are functional, need security updates, or are vulnerable to specific attacks. IoT profiling is an emerging technique to identify and validate the connected devices’ specific behaviour and isolate the suspected and vulnerable devices within the network for further monitoring. This article provides a comprehensive review of various IoT device profiling methods and provides a clear taxonomy for IoT profiling techniques based on different security perspectives. We first investigate several current IoT device profiling techniques and their applications. Next, we analyzed various IoT device vulnerabilities, outlined multiple features, and provided detailed information to implement profiling algorithms’ risk assessment/mitigation stage. By reviewing approaches for profiling IoT devices, we identify various state-of-the-art methods that organizations of different domains can implement to satisfy profiling needs. Furthermore, this article also discusses several machine learning and deep learning algorithms utilized for IoT device profiling. Finally, we discuss challenges and future research possibilities in this domain.","IoT fingerprinting, IoT device type identification, IoT profiling, IoT security, machine learning"
Conference Paper,"Moniruzzaman M,Zaman AG,Tasnia R,Biswas S,Khanam M",Early-Stage Diabetes Prediction Using Data Mining Algorithms,Association for Computing Machinery,2022,https://doi.org/10.1145/3542954.3542990;http://dx.doi.org/10.1145/3542954.3542990,"Diabetes is a very common disease nowadays. If not treated early diabetes can pose a profoundly serious health threat. Much research has been conducted to find out the optimal solution for diabetes detection by applying different data mining algorithms, where the dataset consists of different medicinal attributes. In this study, our aim is to examine whether diabetes can be detected at early-stage by applying different data mining algorithms to the non-medicinal dataset; as well as to investigate whether data normalization techniques can improve the classifiers accuracy.Naive Bayes, K-Nearest Neighbor (KNN), Support Vector Machines (SVM), Decision Tree, Random Forest, and Gradient Boosting Classifier (GBC) algorithms are applied to the Early Stage Diabetes Risk Prediction Dataset in conjunction with Decimal Point Scaling, Z-Score Normalization, Pareto Scaling, Variable Stability Scaling, Min-Max normalization, Max normalization, Maximum Absolute Scaling, Mean Centered Scaling, Soft-max normalization, Power Transformer, Median and Median Absolute Deviation Normalization, Robust Scaling and Log Scaling normalization methods. In this experiment, we discovered that early-stage diabetes detection is possible without any medical diagnosis data. The result shows that GBC performs better compared to other classification algorithms in combination with data normalization and achieved an impressive 99.038% prediction accuracy.","Normalization, Decision Tree, Machine Learning, Support Vector Machines (SVM), Early-Stage diabetes, Random Forest, Symptoms, Data Mining, K-Nearest Neighbor (KNN), Gradient Boosting Classifiers (GBC)"
Conference Paper,"Zaki Zadeh M,Ramesh Babu A,Jaiswal A,Kyrarini M,Bell M,Makedon F",Automated System to Measure Tandem Gait to Assess Executive Functions in Children,Association for Computing Machinery,2021,https://doi.org/10.1145/3453892.3453999;http://dx.doi.org/10.1145/3453892.3453999,"As mobile technologies have become ubiquitous in recent years, computer-based cognitive tests have become more popular and efficient. In this work, we focus on assessing motor function in children by analyzing their gait movements. Although there has been a lot of research on designing automated assessment systems for gait analysis, most of these efforts use obtrusive wearable sensors for measuring body movements. We have devised a computer vision-based assessment system that only requires a camera which makes it easier to employ in school or home environments. A dataset has been created with 27 children performing the test. Furthermore, in order to improve the accuracy of the system, a deep learning based model was pre-trained on NTU-RGB+D 120 dataset and then it was fine-tuned on our gait dataset. The results highlight the efficacy of proposed work for automating the assessment of children’s performances by achieving 76.61% classification accuracy.","deep learning, cognitive assessment, tandem gait, computer vision"
Conference Paper,"Ai L,Yang M,Xie Z",Improved Residual Connection Network for Diabetic Foot Ulcers Classification,Association for Computing Machinery,2022,https://doi.org/10.1145/3565387.3565433;http://dx.doi.org/10.1145/3565387.3565433,"Most existing image classification methods have achieved remarkable progress in the field of natural images. However, in the data-scarce and data-complex field of diabetic foot ulcer (DFU), accurate classification of data remains a thorny problem. In this paper, we propose an end-to-end network model for the multi-class (4-class) classification task of DFU. Specifically, in order to keep the network at a certain depth and avoid the gradient disappearing during the training process, we define the identity residual block as the basic module for building the model. For the purpose of improving the expressive ability of the network, we design an asymmetric convolution module to guide the network to focus on the central region that contains more information in the image. By alternately connecting identity residual blocks with asymmetric convolution modules, our model enables the network to better extract important features of the image, while ensuring that the network does not have gradients dissipating at a certain depth. The model is validated on the DFUC2021 test set, and the F1-score and AUC value are 0.585 and 0.850, respectively, which greatly outperforms the baseline results and can provide a reference for the doctor's diagnosis.","Diabetic foot ulcers, Residual connection network, Asymmetric convolution module, Image classification"
Journal Article,"Eardley R,Mackinnon S,Tonkin EL,Soubutts E,Ayobi A,Linington J,Tourte GJ,Gross ZB,Bailey DJ,Knights R,Gooberman-Hill R,Craddock I,O'Kane AA",A Case Study Investigating a User-Centred and Expert Informed 'Companion Guide' for a Complex Sensor-Based Platform,Association for Computing Machinery,2022,https://doi.org/10.1145/3534625;http://dx.doi.org/10.1145/3534625,"We present a case study that informs the creation of a 'companion guide' providing transparency to potential non-expert users of a ubiquitous machine learning (ML) platform during the initial onboarding. Ubiquitous platforms (e.g., smart home systems, including smart meters and conversational agents) are increasingly commonplace and increasingly apply complex ML methods. Understanding how non-ML experts comprehend these platforms is important in supporting participants in making an informed choice about if and how they adopt these platforms. To aid this decision-making process, we created a companion guide for a home health platform through an iterative user-centred-design process, seeking additional input from platform experts at all stages of the process to ensure the accuracy of explanations. This user-centred and expert informed design process highlights the need to present the platform's entire ecosystem at an appropriate level for those with differing backgrounds to understand, in order to support informed consent and decision making.","Health, Onboarding, Machine Learning, Case study, Smart home, Design process"
Conference Paper,"Guo X,Liang L,Liu Y,Weng H,Hao T",The Construction of a Diabetes-Oriented Frequently Asked Question Corpus for Automated Question-Answering Services,Association for Computing Machinery,2020,https://doi.org/10.1145/3433996.3434008;http://dx.doi.org/10.1145/3433996.3434008,"In recent years, the prevalence of diabetes has been increasing rapidly worldwide. With the advancement of information technology, automated question-answering services for healthcare, which are commonly based on annotated corpus in health domain, have positive effects on health knowledge spread and daily health management for high-risk populations. This paper proposes to construct a large scale diabetes corpus of frequently-asked questions for automated question-answering services and evaluations. Concentrating on the characteristics of diabetes-related factors that reflect conditions of diabetes, this work establishes an annotated dataset containing professional question & answer pairs about diabetes and their annotated question target categories. The corpus is applicable for various question-answering applications, supporting users to retrieve needed information, arrange diets, adhere to scientific medication as well as prevent and control disease complications.","visualization, Diabetes, corpus construction, frequently-asked questions"
Conference Paper,"Yuan Y,Yuan B,Mao H",Performance of Existing Predictor of SubCellular Localization of Long Non-Coding RNA on the New Database,Association for Computing Machinery,2021,https://doi.org/10.1145/3436369.3437447;http://dx.doi.org/10.1145/3436369.3437447,"Long non-coding RNAs (lncRNAs) have important functions in the regulation of life activities at multiple levels, such as chromatin remodeling, transcriptional and posttranscriptional regulation. They have different functions according to the different locations in the cell. Therefore, it is important to obtain the sub-cellular location information to understand the functions of lncRNAs. However, the biochemical experimental way of sub-cellular localization requires a long period and high cost. Currently, many methods of predicting sub-cellular location based on the machine learning and deep learning have been developed to ease the difficulty in detecting the sub-cellular location. We fetched the latest version RNA database to evaluate the performance of existing predictors, lncLocator and iLoc-lncRNA.","subcellular localization, prediction, Long non-coding RNA"
Journal Article,"Henao R,Lu JT,Lucas JE,Ferranti J,Carin L",Electronic Health Record Analysis via Deep Poisson Factor Models,JMLR.org,2016,Not Found,"Electronic Health Record (EHR) phenotyping utilizes patient data captured through normal medical practice, to identify features that may represent computational medical phenotypes. These features may be used to identify at-risk patients and improve prediction of patient morbidity and mortality. We present a novel deep multi-modality architecture for EHR analysis (applicable to joint analysis of multiple forms of EHR data), based on Poisson Factor Analysis (PFA) modules. Each modality, composed of observed counts, is represented as a Poisson distribution, parameterized in terms of hidden binary units. Information from different modalities is shared via a deep hierarchy of common hidden units. Activation of these binary units occurs with probability characterized as Bernoulli-Poisson link functions, instead of more traditional logistic link functions. In addition, we demonstrate that PFA modules can be adapted to discriminative modalities. To compute model parameters, we derive efficient Markov Chain Monte Carlo (MCMC) inference that scales efficiently, with significant computational gains when compared to related models based on logistic link functions. To explore the utility of these models, we apply them to a subset of patients from the Duke-Durham patient cohort. We identified a cohort of over 16,000 patients with Type 2 Diabetes Mellitus (T2DM) based on diagnosis codes and laboratory tests out of our patient population of over 240,000. Examining the common hidden units uniting the PFA modules, we identify patient features that represent medical concepts. Experiments indicate that our learned features are better able to predict mortality and morbidity than clinical features identified previously in a large-scale clinical trial.","phenotyping, electronic health records, multi-modality learning, poisson factor model, deep learning"
Conference Paper,"Scepanovic S,Martin-Lopez E,Quercia D,Baykaner K",Extracting Medical Entities from Social Media,Association for Computing Machinery,2020,https://doi.org/10.1145/3368555.3384467;http://dx.doi.org/10.1145/3368555.3384467,"Accurately extracting medical entities from social media is challenging because people use informal language with different expressions for the same concept, and they also make spelling mistakes. Previous work either focused on specific diseases (e.g., depression) or drugs (e.g., opioids) or, if working with a wide-set of medical entities, only tackled individual and small-scale benchmark datasets (e.g., AskaPatient). In this work, we first demonstrated how to accurately extract a wide variety of medical entities such as symptoms, diseases, and drug names on three benchmark datasets from varied social media sources, and then also validated this approach on a large-scale Reddit dataset.We first implemented a deep-learning method using contextual embeddings that upon two existing benchmark datasets, one containing annotated AskaPatient posts (CADEC) and the other containing annotated tweets (Micromed), outperformed existing state-of-the-art methods. Second, we created an additional benchmark dataset by annotating medical entities in 2K Reddit posts (made publicly available under the name of MedRed) and showed that our method also performs well on this new dataset.Finally, to demonstrate that our method accurately extracts a wide variety of medical entities on a large scale, we applied the model pre-trained on MedRed to half a million Reddit posts. The posts came from disease-specific subreddits so we could categorise them into 18 diseases based on the subreddit. We then trained a machine-learning classifier to predict the post's category solely from the extracted medical entities. The average F1 score across categories was .87. These results open up new cost-effective opportunities for modeling, tracking and even predicting health behavior at scale.","health discussions mining, Reddit, deep learning"
Journal Article,"Tang CI,Perez-Pozuelo I,Spathis D,Brage S,Wareham N,Mascolo C",SelfHAR: Improving Human Activity Recognition through Self-Training with Unlabeled Data,Association for Computing Machinery,2021,https://doi.org/10.1145/3448112;http://dx.doi.org/10.1145/3448112,"Machine learning and deep learning have shown great promise in mobile sensing applications, including Human Activity Recognition. However, the performance of such models in real-world settings largely depends on the availability of large datasets that captures diverse behaviors. Recently, studies in computer vision and natural language processing have shown that leveraging massive amounts of unlabeled data enables performance on par with state-of-the-art supervised models.In this work, we present SelfHAR, a semi-supervised model that effectively learns to leverage unlabeled mobile sensing datasets to complement small labeled datasets. Our approach combines teacher-student self-training, which distills the knowledge of unlabeled and labeled datasets while allowing for data augmentation, and multi-task self-supervision, which learns robust signal-level representations by predicting distorted versions of the input.We evaluated SelfHAR on various HAR datasets and showed state-of-the-art performance over supervised and previous semi-supervised approaches, with up to 12% increase in F1 score using the same number of model parameters at inference. Furthermore, SelfHAR is data-efficient, reaching similar performance using up to 10 times less labeled data compared to supervised approaches. Our work not only achieves state-of-the-art performance in a diverse set of HAR datasets, but also sheds light on how pre-training tasks may affect downstream performance.","self-training, unlabeled data, human activity recognition, semi-supervised training, self-supervised training, deep learning"
Conference Paper,"Le H,Tran T,Venkatesh S",Dual Memory Neural Computer for Asynchronous Two-View Sequential Learning,Association for Computing Machinery,2018,https://doi.org/10.1145/3219819.3219981;http://dx.doi.org/10.1145/3219819.3219981,"One of the core tasks in multi-view learning is to capture relations among views. For sequential data, the relations not only span across views, but also extend throughout the view length to form long-term intra-view and inter-view interactions. In this paper, we present a new memory augmented neural network that aims to model these complex interactions between two asynchronous sequential views. Our model uses two encoders for reading from and writing to two external memories for encoding input views. The intra-view interactions and the long-term dependencies are captured by the use of memories during this encoding process. There are two modes of memory accessing in our system: late-fusion and early-fusion, corresponding to late and early inter-view interactions. In the late-fusion mode, the two memories are separated, containing only view-specific contents. In the early-fusion mode, the two memories share the same addressing space, allowing cross-memory accessing. In both cases, the knowledge from the memories will be combined by a decoder to make predictions over the output space. The resulting dual memory neural computer is demonstrated on a comprehensive set of experiments, including a synthetic task of summing two sequences and the tasks of drug prescription and disease progression in healthcare. The results demonstrate competitive performance over both traditional algorithms and deep learning methods designed for multi-view problems.","healthcare, memory augmented neural networks, multi-view sequential learning"
Journal Article,"Ayobi A,Stawarz K,Katz D,Marshall P,Yamagata T,Santos-Rodriguez R,Flach P,O'Kane AA",Co-Designing Personal Health? Multidisciplinary Benefits and Challenges in Informing Diabetes Self-Care Technologies,Association for Computing Machinery,2021,https://doi.org/10.1145/3479601;http://dx.doi.org/10.1145/3479601,"Co-design is a widely applied design process with well-documented values, including mutual learning and collective creativity. However, the real-world challenges of conducting multidisciplinary co-design research to inform the design of self-care technologies are not well established. We provide a qualitative account of a multidisciplinary project that aimed to co-design machine learning applications for Type 1 Diabetes (T1D) self-management. Through interviews, we identify not only perceived social, technological and strategic benefits of co-design but also organisational, translational and pragmatic design challenges: participants with T1D experienced difficulties in co-designing systems that met their individual self-care needs as part of group activities; HCI and AI researchers described challenges resulting from applying co-design outcomes to data-driven ML work; and industry collaborators highlighted academic data sharing regulations as cross-organisational challenges that can impede co-design efforts. Based on this understanding, we discuss opportunities for supporting multidisciplinary collaborations and aligning individual health needs with collaborative co-design activities.","self-care, explainable artificial intelligence, personal health, diabetes, HCI-AI, self-management, participatory design, co-design, human-centred machine learning, T1D"
Conference Paper,"Yang HL,Li BY",A Hybrid Neural Network Based on Particle Swarm Optimization for Predicting the Diabetes,Association for Computing Machinery,2021,https://doi.org/10.1145/3457784.3457831;http://dx.doi.org/10.1145/3457784.3457831,"In recent years, more and more studies have applied hybrid models in order to improve the performance of traditional neural networks. By combining particle swarm optimization and neural network, this research proposes a new hybrid neural prediction algorithm named as PSONN. The algorithm was applied to Pima Indians Diabetes Database and compared with eight other algorithms including Logistic regression, Ridge regression, Lasso regression, Linear Discriminant Analysis, Quadratic Discriminant Analysis, Random Forest, Gradient Boosting Machine, and Adam (a neural network algorithm). The findings indicated that the proposed algorithm had higher accuracy and stability, but it took more time to execute. It is suggested that, future research could apply parallelization technology for reducing execution time.","Neural Network, Diabetes Dataset, Particle Swarm Optimization"
Journal Article,"Zou B,Dai Y,He Q,Zhu C,Liu G,Su Y,Tang R",Multi-Label Classification Scheme Based on Local Regression for Retinal Vessel Segmentation,IEEE Computer Society Press,2020,https://doi.org/10.1109/TCBB.2020.2980233;http://dx.doi.org/10.1109/TCBB.2020.2980233,"Segmenting small retinal vessels with width less than 2 pixels in fundus images is a challenging task. In this paper, in order to effectively segment the vessels, especially the narrow parts, we propose a local regression scheme to enhance the narrow parts, along with a novel multi-label classification method based on this scheme. We consider five labels for blood vessels and background in particular: the center of big vessels, the edge of big vessels, the center as well as the edge of small vessels, the center of background, and the edge of background. We first determine the multi-label by the local de-regression model according to the vessel pattern from the ground truth images. Then, we train a convolutional neural network (CNN) for multi-label classification. Next, we perform a local regression method to transform the previous multi-label into binary label to better locate small vessels and generate an entire retinal vessel image. Our method is evaluated using two publicly available datasets and compared with several state-of-the-art studies. The experimental results have demonstrated the effectiveness of our method in segmenting retinal vessels.",Not Found
Journal Article,"Wang S,Li X,Chang X,Yao L,Sheng QZ,Long G",Learning Multiple Diagnosis Codes for ICU Patients with Local Disease Correlation Mining,Association for Computing Machinery,2017,https://doi.org/10.1145/3003729;http://dx.doi.org/10.1145/3003729,"In the era of big data, a mechanism that can automatically annotate disease codes to patients’ records in the medical information system is in demand. The purpose of this work is to propose a framework that automatically annotates the disease labels of multi-source patient data in Intensive Care Units (ICUs). We extract features from two main sources, medical charts and notes. The Bag-of-Words model is used to encode the features. Unlike most of the existing multi-label learning algorithms that globally consider correlations between diseases, our model learns disease correlation locally in the patient data. To achieve this, we derive a local disease correlation representation to enrich the discriminant power of each patient data. This representation is embedded into a unified multi-label learning framework. We develop an alternating algorithm to iteratively optimize the objective function. Extensive experiments have been conducted on a real-world ICU database. We have compared our algorithm with representative multi-label learning algorithms. Evaluation results have shown that our proposed method has state-of-the-art performance in the annotation of multiple diagnostic codes for ICU patients. This study suggests that problems in the automated diagnosis code annotation can be reliably addressed by using a multi-label learning model that exploits disease correlation. The findings of this study will greatly benefit health care and management in ICU considering that the automated diagnosis code annotation can significantly improve the quality and management of health care for both patients and caregivers.","Diagnosis code annotation, MIMIC II database, ICU data mining, local correlation exploiting, multi-label learning, pattern discovery"
Conference Paper,"Casal-Guisande M,Cerqueiro-Pequeño J,Comesaña-Campos A,Bouza-Rodríguez JB",Proposal of a Methodology Based on Expert Systems for the Treatment of Diabetic Foot Condition,Association for Computing Machinery,2021,https://doi.org/10.1145/3434780.3436625;http://dx.doi.org/10.1145/3434780.3436625,"Diabetes is a chronical illness, commonly considered as the disease of the 21st Century. Diabetic foot is one of the several conditions associated to this disease, which in the most severe cases might be the cause of amputations on the lower limbs. Such condition involves a high social impact for patients and families, and puts an important burden on the health and care systems. It is essential to aim at an early detection of the pathology and at its continuous monitoring in order to perform a convenient follow-up of those patients’ condition, from both the preventive and the therapeutic viewpoints. Following this line, different decision support methodologies are nowadays under development within the remote medicine framework, that in this specific case might help to improve the process for monitoring and treating patients that are likely to develop wounds associated with diabetic foot condition.This communication, framed in the previously introduced context, aims to carry out the conceptual adaptation of the decision support methodology presented by the authors in a previous work, which addressed the prevention and monitoring of patients likely to develop wounds associated to diabetic foot condition. The revised methodology, complemented by the use of expert systems, will allow to generate alerts associated to the evolution of foot wounds in at-risk diabetic patients, by means of the interpretation and combined use of: a set of data coming from a test, a picture, and the opinions and considerations provided by an expert in the topic. Said information is fed into two concurrent inference systems, which produce a number of risk indicators that, after being appropriately combined, determine a final alert associated to a measurement of diabetic foot condition risk. Even if this system is at the moment at an active development stage, it is expected that its usage will make possible to improve the process for an early detection of the potential issues associated with diabetic foot condition, as well as the monitoring of its associated pathologies.","Diabetic foot condition, Decision support systems, Expert systems, Chronic wound"
Conference Paper,"Daukantas I,Bruni A,Schürmann C",Trimming Data Sets: A Verified Algorithm for Robust Mean Estimation,Association for Computing Machinery,2021,https://doi.org/10.1145/3479394.3479412;http://dx.doi.org/10.1145/3479394.3479412,"The operation of trimming data sets is heavily used in AI systems. Trimming is useful to make AI systems more robust against adversarial or common perturbations. At the core of robust AI systems lies the concept that outliers in a data set occur with low probability, and therefore can be discarded with little loss of precision in the result. The statistical argument that formalizes this concept of robustness is based on an extension of the Chebyshev’s inequality first proposed by Tukey in 1960. In this paper we present a mechanized proof of robustness of the trimmed mean algorithm, which is a statistical method underlying many complex applications of deep learning. For this purpose we use the Coq proof assistant to formalize Tukey’s extension to Chebyshev’s inequality, which allows us to verify the robustness of the trimmed mean algorithm. Our contribution shows the viability of mechanized robustness arguments for algorithms that are at the foundation of complex AI systems.","proof, robust mean estimation, formal verification, machine learning, robustness"
Journal Article,"Gu H,Liang Y,Xu Y,Williams CK,Magaki S,Khanlou N,Vinters H,Chen Z,Ni S,Yang C,Yan W,Zhang XR,Li Y,Haeri M,Chen Xanthony",Improving Workflow Integration with XPath: Design and Evaluation of a Human-AI Diagnosis System in Pathology,Association for Computing Machinery,2022,https://doi.org/10.1145/3577011;http://dx.doi.org/10.1145/3577011,"Recent developments in AI have provided assisting tools to support pathologists’ diagnoses. However, it remains challenging to incorporate such tools into pathologists’ practice; one main concern is AI’s insufficient workflow integration with medical decisions. We observed pathologists’ examination and discovered that the main hindering factor to integrate AI is its incompatibility with pathologists’ workflow. To bridge the gap between pathologists and AI, we developed a human-AI collaborative diagnosis tool — xPath— that shares a similar examination process to that of pathologists, which can improve AI’s integration into their routine examination. The viability of xPath is confirmed by a technical evaluation and work sessions with twelve medical professionals in pathology. This work identifies and addresses the challenge of incorporating AI models into pathology, which can offer first-hand knowledge about how HCI researchers can work with medical professionals side-by-side to bring technological advances to medical tasks towards practical applications.",Human-AI collaboration; digital pathology; medical AI; meningioma
Conference Paper,"He W,Mao X,Ma C,Huang Y,Hernàndez-Lobato JM,Chen T",BSODA: A Bipartite Scalable Framework for Online Disease Diagnosis,Association for Computing Machinery,2022,https://doi.org/10.1145/3485447.3512123;http://dx.doi.org/10.1145/3485447.3512123,"A growing number of people are seeking healthcare advice online. Usually, they diagnose their medical conditions based on the symptoms they are experiencing, which is also known as self-diagnosis. From the machine learning perspective, online disease diagnosis is a sequential feature (symptom) selection and classification problem. Reinforcement learning (RL) methods are the standard approaches to this type of tasks. Generally, they perform well when the feature space is small, but frequently become inefficient in tasks with a large number of features, such as the self-diagnosis. To address the challenge, we propose a non-RL Bipartite Scalable framework for Online Disease diAgnosis, called BSODA. BSODA is composed of two cooperative branches that handle symptom-inquiry and disease-diagnosis, respectively. The inquiry branch determines which symptom to collect next by an information-theoretic reward. We employ a Product-of-Experts encoder to significantly improve the handling of partial observations of a large number of features. Besides, we propose several approximation methods to substantially reduce the computational cost of the reward to a level that is acceptable for online services. Additionally, we leverage the diagnosis model to estimate the reward more precisely. For the diagnosis branch, we use a knowledge-guided self-attention model to perform predictions. In particular, BSODA determines when to stop inquiry and output predictions using both the inquiry and diagnosis models. We demonstrate that BSODA outperforms the state-of-the-art methods on several public datasets. Moreover, we propose a novel evaluation method to test the transferability of symptom checking methods from synthetic to real-world tasks. Compared to existing RL baselines, BSODA is more effectively scalable to large search spaces.","symptom checking, online disease diagnosis, self-diagnosis"
Conference Paper,"Ren H,Wang J,Zhao WX",RSD: A Reinforced Siamese Network with Domain Knowledge for Early Diagnosis,Association for Computing Machinery,2022,https://doi.org/10.1145/3511808.3557440;http://dx.doi.org/10.1145/3511808.3557440,"The availability of electronic health record data makes it possible to develop automatic disease diagnosis approaches. In this paper, we study the early diagnosis of diseases. As being a difficult task (even for experienced doctors), early diagnosis of diseases poses several challenges that are not well solved by prior studies, including insufficient training data, dynamic and complex signs of complications and trade-off between earliness and accuracy.To address these challenges, we propose a Reinforced Siamese network with Domain knowledge regularization approach, namely RSD, to achieve high performance for early diagnosis. The RSD approach consists of a diagnosis module and a control module. The diagnosis module adopts any EHR Encoder as a basic framework to extract representations, and introduces two improved training strategies. To overcome the insufficient sample problem, we design a Siamese network architecture to enhance the model learning. Furthermore, we propose a domain knowledge regularization strategy to guide the model learning with domain knowledge. Based on the diagnosis module, our control module learns to automatically determine whether making a disease alert to the patients based on the diagnosis results. Through carefully designed architecture, rewards and policies, it is able to effectively balance earliness and accuracy for diagnosis. Experimental results have demonstrated the effectiveness of our approach on both diagnosis prediction and early diagnosis. We also perform extensive analysis experiments to verify the robustness of the proposed approach.","early diagnosis, reinforcement learning, siamese network"
Conference Paper,"Jakhmola S,Pradhan T",A Computational Approach of Data Smoothening and Prediction of Diabetes Dataset,Association for Computing Machinery,2015,https://doi.org/10.1145/2791405.2791572;http://dx.doi.org/10.1145/2791405.2791572,"Data mining when applied on medical diagnosis can help doctors to take major decisions. Diabetes is a disease which has to be monitored by the patient so as not to cause severe damage to the body. Therefore to predict diabetes is an important task that is most important for the patient. In this study, a new data smoothening technique is proposed for noise removal from the data. It is very important for the user to have control over the smoothening of the data so that the information loss can be monitored. The proposed method allows the user to control the level of data smoothening by accepting the loss percentage on the individual data points. Allowable loss is calculated and a decision is made to smoothen the value or retain it to the level which is accurate. The proposed method will enable the user to get the output based on his requirements of preprocessing. The proposed algorithm will allow the user to interact with the data preprocessing system unlike the primitive algorithms. Different levels of smoothened output are obtained by different loss percentage. This preprocessed output produced will be of a better quality and will resemble more to the real world data. Furthermore, correlation and multiple regression is applied on the preprocessed diabetes dataset and a prediction is made on this basis.","Data Preprocessing, Correlation, Smoothening, Multiple Regression"
Conference Paper,"Zhang J,Gong J,Barnes L",HCNN: Heterogeneous Convolutional Neural Networks for Comorbid Risk Prediction with Electronic Health Records,IEEE Press,2017,https://doi.org/10.1109/CHASE.2017.80;http://dx.doi.org/10.1109/CHASE.2017.80,"The increasing adoption of electronic health record (EHR) systems has brought tremendous opportunities in medicine enabling more personalized prognostic models. However, most work to date has investigated the binary classification problem for predicting the onset of one chronic disease, but little attention has been given to assessing risk of developing comorbidities that are major causes of morbidity and mortality. For example, type 2 diabetes and chronic kidney disease frequently accompany congestive heart failure. This paper is motivated by the problem of predicting comorbid diseases and aims to answer the following question: can we predict the comorbid risk using a patient's medical history? We propose a new predictive learning framework, Heterogeneous Convolutional Neural Network (HCNN), that represents EHRs as graphs with heterogeneous attributes (e.g. diagnoses, procedures, and medication), and then develop a novel deep learning methodology for risk prediction of multiple comorbid diseases. The main innovation of the framework is that it defines the distance between the heterogeneous attributes of the graph representation extracted from the EHR and develops an appropriate learning infrastructure that is a composition of sparse convolutional layers and local pooling steps that match with the local structure of the space of the heterogeneous attributes. As a result, the new method is capable of capturing features about the relationships between heterogeneous attributes of the graphs. Through a comparative study on patient EHR data, HCNN achieves better performance than traditional convolutional neural networks on the risk prediction of comorbid diseases.","heterogeneous convolution, risk prediction, electronic health records, neural networks"
Conference Paper,"Jakhmola S,Pradhan T",A Computational Approach of Data Smoothening and Prediction of Diabetes Dataset,Association for Computing Machinery,2015,https://doi.org/10.1145/2791405.2791572;http://dx.doi.org/10.1145/2791405.2791572,"Data mining when applied on medical diagnosis can help doctors to take major decisions. Diabetes is a disease which has to be monitored by the patient so as not to cause severe damage to the body. Therefore to predict diabetes is an important task that is most important for the patient. In this study, a new data smoothening technique is proposed for noise removal from the data. It is very important for the user to have control over the smoothening of the data so that the information loss can be monitored. The proposed method allows the user to control the level of data smoothening by accepting the loss percentage on the individual data points. Allowable loss is calculated and a decision is made to smoothen the value or retain it to the level which is accurate. The proposed method will enable the user to get the output based on his requirements of preprocessing. The proposed algorithm will allow the user to interact with the data preprocessing system unlike the primitive algorithms. Different levels of smoothened output are obtained by different loss percentage. This preprocessed output produced will be of a better quality and will resemble more to the real world data. Furthermore, correlation and multiple regression is applied on the preprocessed diabetes dataset and a prediction is made on this basis.","Multiple Regression, Correlation, Smoothening, Data Preprocessing"
Conference Paper,"Motta D,de Matos L,de Souza AC,Marcato R,Paiva A,de Carvalho LA",All-in-Focus Imaging Technique Used to Improve 3D Retinal Fundus Image Reconstruction,Association for Computing Machinery,2015,https://doi.org/10.1145/2695664.2695845;http://dx.doi.org/10.1145/2695664.2695845,"In this paper we have applied the stacking technique on images from a medical device. There is an urgent need in ophthalmology for more cost effective instrumentation for the early diagnosis of glaucoma, one of the leading diseases in the cause of blindness worldwide. The current techniques involve expensive optical equipments generally called fundus camera, which most of the time capture a single high resolution frame for one eye at a time. In this research we have used stereoscopic videos of a state-of-the-art 3D retinal camera, which has simpler optics and electronics when compared to current monoscopic models. Nevertheless, the cross correlation algorithms for depth computation are very sensible to image noise and out of focus regions. We demonstrate the efficiency of our technique on experiments involving a sequence of images extracted from videos in simulations of optic nerves using artificial objects.","image processing, stacking technique, optic nerve"
Journal Article,"Dai Y,Wu J,Fan Y,Wang J,Niu J,Gu F,Shen S",MSEva: A Musculoskeletal Rehabilitation Evaluation System Based on EMG Signals,Association for Computing Machinery,2022,https://doi.org/10.1145/3522739;http://dx.doi.org/10.1145/3522739,"In order to better assist the rehabilitation treatment of patients with musculoskeletal injury, standard rehabilitation actions are needed to guide the musculoskeletal rehabilitation process. With more and more urgent demands, the musculoskeletal rehabilitation evaluation systems have attracted a high degree of attention. Experts have proposed a series of systems based on laser, ultrasound, and image, which can give reasonable recognition and judgment. However, these systems either require specialized and expensive equipment or can be affected by ionizing radiation. How to construct a musculoskeletal rehabilitation evaluation system with low cost, good effect, and little injury is still a great challenge. In this article, we propose MSEva, a musculoskeletal rehabilitation evaluation system based on EMG signals. Specifically, the system uses EMG sensors to collect a large amount of data for five rehabilitation actions. Secondly, MSEva uses Wavelet Transform (WT) to extract the signal features and then puts the processed data into the Long Short-Term Memory (LSTM) network for model training. Finally, the system uses the LSTM model to evaluate the normality of the EMG response of rehabilitation actions. The results show that the average accuracy of MSEva reaches 94.37%, which has important evaluation value in guiding the rehabilitation of musculoskeletal patients.","EMG signals, rehabilitation evaluation, LSTM network"
Conference Paper,"Ma H,Wang X,Zhao T,Sun H,Liu Z",The Research on Fractal Dimension of Diabetic Patients Based on ECG Signal,Association for Computing Machinery,2019,https://doi.org/10.1145/3325730.3325766;http://dx.doi.org/10.1145/3325730.3325766,"The cardiac system is a nonlinear system with aperiodic, complex fractal characteristics. In this paper, a new fractal dimension-center information dimension is proposed based on electrocardiogram (ECG) signals, which is used to quantitatively describe the fractal characteristics of ECG signals, and an automatic identification method for fractal scaleless band of center information dimension is proposed. The center information dimension of RR sequence, sRR sequence and pRRx sequence that were extracted from the ECG signal was calculated at different time scales. By analyzing the ECG data of diabetic patients collected in the Second People's Hospital of Shenzhen City and the ECG data of healthy students in the laboratory, it was found that the center information dimension shows good statistical difference in the two sets of sample data (p<0.05). What's more, in the fractal dimension analysis based on pRRx sequence, the center information dimension was significantly better than the correlation dimension. Therefore, the center information dimension based on ECG signals can reflect the fractal characteristics of the cardiac system to a great extent, and can be used as a novel and effective method for analyzing diabetes.","ECG signal, Fractal dimension, Central information dimension, Diabetes, Automatic identification, Fractal scaleless band"
Journal Article,"Lee HN,Ashok V,Ramakrishnan IV",Bringing Things Closer: Enhancing Low-Vision Interaction Experience with Office Productivity Applications,Association for Computing Machinery,2021,https://doi.org/10.1145/3457144;http://dx.doi.org/10.1145/3457144,"Many people with low vision rely on screen-magnifier assistive technology to interact with productivity applications such as word processors, spreadsheets, and presentation software. Despite the importance of these applications, little is known about their usability with respect to low-vision screen-magnifier users. To fill this knowledge gap, we conducted a usability study with 10 low-vision participants having different eye conditions. In this study, we observed that most usability issues were predominantly due to high spatial separation between main edit area and command ribbons on the screen, as well as the wide span grid-layout of command ribbons; these two GUI aspects did not gel with the screen-magnifier interface due to lack of instantaneous WYSIWYG (What You See Is What You Get) feedback after applying commands, given that the participants could only view a portion of the screen at any time. Informed by the study findings, we developed MagPro, an augmentation to productivity applications, which significantly improves usability by not only bringing application commands as close as possible to the user's current viewport focus, but also enabling easy and straightforward exploration of these commands using simple mouse actions. A user study with nine participants revealed that MagPro significantly reduced the time and workload to do routine command-access tasks, compared to using the state-of-the-art screen magnifier.","usability, screen magnifier, accessibility, word processor, office productivity software, low vision"
Conference Paper,"Bathina YB,Medathati MV,Sivaswamy J",Robust Matching of Multi-Modal Retinal Images Using Radon Transform Based Local Descriptor,Association for Computing Machinery,2010,https://doi.org/10.1145/1882992.1883108;http://dx.doi.org/10.1145/1882992.1883108,"Multi-Modal image registration is the primary step in fusing complementary information contained in different imaging modalities for diagnostic purposes. We focus on two specific retinal imaging modalities namely, Color Fundus Image(CFI) and Fluroscein Fundus Angiogram(FFA). In this paper we investigate a projection based method using Radon transform for accurate matching in multi-modal retinal images. A novel Radon Transform based descriptor is proposed, which is invariant to illumination, rotation and partially to scale. Our results show that our descriptor is well suited for retinal images as it is robust to lesions, and works well even in poor quality images. The descriptor has been tested on a dataset of 126 images and compared for matching application against gradient based descriptors. The results show that Radon based descriptor outperforms the gradient based ones in both being able to discriminate between true and false matches and under presence of lesions.","transformation estimation, radon descriptor, curvature orientations histogram, vessel enhancement, registration, multimodal feature descriptor., feature extraction, multimodal, retinal imaging, ophthalmic image processing, image mosaic, biomedical image processing"
Conference Paper,"Cai L,Chen C,Wang X,Yang X,Lin S,Huang J,Jiang J,Datta R,Du M,Jiang H,Zhu M,Huang J",Sleep Disorder Classification Method Based on Logistic Regression with Apnea-ECG Dataset,Association for Computing Machinery,2019,https://doi.org/10.1145/3358331.3358344;http://dx.doi.org/10.1145/3358331.3358344,"Adequate sleep is significant for human to actively pursue daily activity. On the other hand, insomnia is directly proportional to aging and health deterioration. Sleep disorder classification is important for medical scientists as well as machine learning researchers. In the paper, we have developed a sleep disorder classification method for Electrocardiogram (ECG) data. The data set have two labels; sleep disorder or not, which can be categorized as binary output. As a result, logistic regression is used as classification technique. For initial experimentation, an existing data set is used. The data set consists of every 10 second data up to 6000 seconds for 35 patients. We have used 70% data for training, and 30% data for testing purpose. Our results from logistic regression show that the logistic regression method is efficient to detect sleep disorders. The prediction result is found to be 59%. The future research in this direction would be to take data from hospitals and use our developed algorithm for sleep disorder classification and prediction.","Sleep disorder, ECG, Logistic regression"
Conference Paper,"Cai R,Bai F,Song S,Zhao D,Liu T,Xu Q",Study on the Relationship between BDNF and Electroacupuncture Analgesia under the Background of Intelligent Technology,Association for Computing Machinery,2021,https://doi.org/10.1145/3500931.3500949;http://dx.doi.org/10.1145/3500931.3500949,"Chronic pain is a serious threat to human health. Studies have shown that Brain-derived neurotrophic factor (BDNF) is closely related to pain and plays a crucial role in the induction to chronic pain. At present, the clinical treatment of neuropathic pain is mainly through drug treatment, but there are many adverse reactions, which limits their wide application. In recent years, electroacupuncture has been widely studied in the treatment of chronic pain, and has few adverse reactions. So it is worthy of application and promotion. Research conclusions show that electroacupuncture (EA) can effectively inhibit pain, promote the expression of BNDF and play an analgesic effect. At present, the combination of acupuncture treatment and intelligence technology is a hot topic, and it is also the trend of acupuncture treatment for the future. Today, with the rapid development of intelligent technology, we should make good use of the combination of intelligent technology and acupuncture analgesia to give better play to the advantages of acupuncture analgesia. This paper reviews the relationship between BDNF and electroacupuncture analgesia under the background of intelligent technology.","BDNF, electroacupuncture, intelligence technology, chronic pain"
Conference Paper,"Canino G,Suo Q,Guzzi PH,Tradigo G,Zhang A,Veltri P","Feature Selection Model for Diagnosis, Electronic Medical Records and Geographical Data Correlation",Association for Computing Machinery,2016,https://doi.org/10.1145/2975167.2985847;http://dx.doi.org/10.1145/2975167.2985847,"Electronic Medical Records (EMRs) collect and describe events and patient health history, related to his interaction with a healthcare facility or clinical trials. Raw data in EMRs are voluminous and heterogeneous. They need to be collected and stored to allow clinical management, treatment and to apply prevention protocols. Using informatics techniques (e.g., data mining models) allows to automatize the process of information extraction and to support health data management.We focus on biological data present in EMRs starting from blind data gathered from University Hospital of Catanzaro. In collaboration with Biochemical Laboratory of the University Hospital, we designed a workflow based system to analyze biological values. The system is able to relate biological data to diagnosis codes and with additional information integrated and correlated to EMRs data. Prediction models have been used and tested on 3 specific diagnosis, proving that system is able to: (i) identify blood test features that are important to detect a pathology and (ii) finding correlations among patients features.","Diagnosis, Electronic Medical Record, Feature Selection"
Conference Paper,"Fedorin I,Slyusarenko K,Nastenko M",Respiratory Events Screening Using Consumer Smartwatches,Association for Computing Machinery,2020,https://doi.org/10.1145/3410530.3414399;http://dx.doi.org/10.1145/3410530.3414399,"Respiratory related events (RE) during nocturnal sleep disturb the natural physiological pattern of sleep. This events may include all types of apnea and hypopnea, respiratory-event-related arousals and snoring. The particular importance of breath analysis is currently associated with the COVID-19 pandemic. The proposed algorithm is a deep learning model with long short-term memory cells for RE detection for each 1 minute epoch during nocturnal sleep. Our approach provides the basis for a smartwatch based respiratory-related sleep pattern analysis (accuracy of epoch-by-epoch classification is greater than 80 %), can be applied for a potential risk of respiratory-related diseases screening (mean absolute error of AHI estimation is about 6.5 events/h on the test set, which includes participants with all types of apnea severity; two class screening accuracy (AHI threshold is 15 events/h) is greater than 90 %).","respiration rate, neural networks, sleep stages, sleep apnea, heart rate"
Journal Article,"Roscoe S,Khatri M,Voshall A,Batra S,Kaur S,Deogun J",Formal Concept Analysis Applications in Bioinformatics,Association for Computing Machinery,2022,https://doi.org/10.1145/3554728;http://dx.doi.org/10.1145/3554728,"The bioinformatics discipline seeks to solve problems in biology with computational theories and methods. Formal concept analysis (FCA) is one such theoretical model, based on partial orders. FCA allows the user to examine the structural properties of data based on which subsets of the dataset depend on each other. This article surveys the current literature related to the use of FCA for bioinformatics. The survey begins with a discussion of FCA, its hierarchical advantages, several advanced models of FCA, and lattice management strategies. It then examines how FCA has been used in bioinformatics applications, followed by future prospects of FCA in those areas. The applications addressed include gene data analysis (with next-generation sequencing), biomarkers discovery, protein-protein interaction, disease analysis (including COVID-19, cancer, and others), drug design and development, healthcare informatics, biomedical ontologies, and phylogeny. Some of the most promising prospects of FCA are identifying influential nodes in a network representing protein-protein interactions, determining critical concepts to discover biomarkers, integrating machine learning and deep learning for cancer classification, and pattern matching for next-generation sequencing.","drug design and development, healthcare informatics, cancer classification, protein-protein interactions, formal concept analysis, next-generation sequencing data analysis, disease classification, Biomarkers discovery, biomedical ontologies, gene expression data, phylogeny"
Conference Paper,"Semenova L,Rudin C,Parr R",On the Existence of Simpler Machine Learning Models,Association for Computing Machinery,2022,https://doi.org/10.1145/3531146.3533232;http://dx.doi.org/10.1145/3531146.3533232,"It is almost always easier to find an accurate-but-complex model than an accurate-yet-simple model. Finding optimal, sparse, accurate models of various forms (linear models with integer coefficients, decision sets, rule lists, decision trees) is generally NP-hard. We often do not know whether the search for a simpler model will be worthwhile, and thus we do not go to the trouble of searching for one. In this work, we ask an important practical question: can accurate-yet-simple models be proven to exist, or shown likely to exist, before explicitly searching for them? We hypothesize that there is an important reason that simple-yet-accurate models often do exist. This hypothesis is that the size of the Rashomon set is often large, where the Rashomon set is the set of almost-equally-accurate models from a function class. If the Rashomon set is large, it contains numerous accurate models, and perhaps at least one of them is the simple model we desire. In this work, we formally present the Rashomon ratio as a new gauge of simplicity for a learning problem, depending on a function class and a data set. The Rashomon ratio is the ratio of the volume of the set of accurate models to the volume of the hypothesis space, and it is different from standard complexity measures from statistical learning theory. Insight from studying the Rashomon ratio provides an easy way to check whether a simpler model might exist for a problem before finding it, namely whether several different machine learning methods achieve similar performance on the data. In that sense, the Rashomon ratio is a powerful tool for understanding why and when an accurate-yet-simple model might exist. If, as we hypothesize in this work, many real-world data sets admit large Rashomon sets, the implications are vast: it means that simple or interpretable models may often be used for high-stakes decisions without losing accuracy.","Rashomon Set, Model Multiplicity, Simplicity, Interpretable Machine Learning, Generalization"
Conference Paper,"Aydin AS,Ko YJ,Uckun U,Ramakrishnan IV,Ashok V",Non-Visual Accessibility Assessment of Videos,Association for Computing Machinery,2021,https://doi.org/10.1145/3459637.3482457;http://dx.doi.org/10.1145/3459637.3482457,"Video accessibility is crucial for blind screen-reader users as online videos are increasingly playing an essential role in education, employment, and entertainment. While there exist quite a few techniques and guidelines that focus on creating accessible videos, there is a dearth of research that attempts to characterize the accessibility of existing videos. Therefore in this paper, we define and investigate a diverse set of video and audio-based accessibility features in an effort to characterize accessible and inaccessible videos. As a ground truth for our investigation, we built a custom dataset of 600 videos, in which each video was assigned an accessibility score based on the number of its wins in a Swiss-system tournament, where human annotators performed pairwise accessibility comparisons of videos. In contrast to existing accessibility research where the assessments are typically done by blind users, we recruited sighted users for our effort, since videos comprise a special case where sight could be required to better judge if any particular scene in a video is presently accessible or not. Subsequently, by examining the extent of association between the accessibility features and the accessibility scores, we could determine the features that significantly (positively or negatively) impact video accessibility and therefore serve as good indicators for assessing the accessibility of videos. Using the custom dataset, we also trained machine learning models that leveraged our handcrafted features to either classify an arbitrary video as accessible/inaccessible or predict an accessibility score for the video. Evaluation of our models yielded an F1 score of 0.675 for binary classification and a mean absolute error of 0.53 for score prediction, thereby demonstrating their potential in video accessibility assessment while also illuminating their current limitations and the need for further research in this area.","video accessibility, non-visual accessibility"
Conference Paper,"Kyfonidis C,Lennon M",Making Diabetes Education Interactive: Tangible Educational Toys for Children with Type-1 Diabetes,Association for Computing Machinery,2019,https://doi.org/10.1145/3290605.3300671;http://dx.doi.org/10.1145/3290605.3300671,"Younger children (under 9 years) with type-1 diabetes are often very passive in the management of their condition and can face difficulties in accessing and understanding basic diabetes related information. This can make transitioning to self-management in later years very challenging. Previous research has mostly focused on educational interventions for older children.To create an educational tool which can support the diabetes educational process of younger children, we conducted a multiphase and multi-stakeholder user-centred design process. The result is an interactive tool that illustrates diabetes concepts in an age-appropriate way with the use of tangible toys. The tool was evaluated inside a paediatric diabetes clinic with clinicians, children and parents and was found to be engaging, acceptable and effective. In addition to providing implications for the design and adoption of educational tools for children in a clinical setting, we discuss the challenges for conducting user-centred design in such a setting.","children, tangible interaction, user-centred design, diabetes education"
Conference Paper,"Killian JA,Wilder B,Sharma A,Choudhary V,Dilkina B,Tambe M",Learning to Prescribe Interventions for Tuberculosis Patients Using Digital Adherence Data,Association for Computing Machinery,2019,https://doi.org/10.1145/3292500.3330777;http://dx.doi.org/10.1145/3292500.3330777,"Digital Adherence Technologies (DATs) are an increasingly popular method for verifying patient adherence to many medications. We analyze data from one city served by 99DOTS, a phone-call-based DAT deployed for Tuberculosis (TB) treatment in India where nearly 3 million people are afflicted with the disease each year. The data contains nearly 17,000 patients and 2.1M dose records. We lay the groundwork for learning from this real-world data, including a method for avoiding the effects of unobserved interventions in training data used for machine learning. We then construct a deep learning model, demonstrate its interpretability, and show how it can be adapted and trained in three different clinical scenarios to better target and improve patient care. In the real-time risk prediction setting our model could be used to proactively intervene with 21% more patients and before 76% more missed doses than current heuristic baselines. For outcome prediction, our model performs 40% better than baseline methods, allowing cities to target more resources to clinics with a heavier burden of patients at risk of failure. Finally, we present a case study demonstrating how our model can be trained in an end-to-end decision focused learning setting to achieve 15% better solution quality in an example decision problem faced by health workers.","treatment adherence, machine learning, interpretability, tuberculosis, predictive modeling, digital adherence technology"
Conference Paper,"Khan Y,Qamar U,Yousaf N,Khan A",Machine Learning Techniques for Heart Disease Datasets: A Survey,Association for Computing Machinery,2019,https://doi.org/10.1145/3318299.3318343;http://dx.doi.org/10.1145/3318299.3318343,"Heart Failure (HF) has been proven one of the leading causes of death that is why an accurate and timely prediction of HF risks is extremely essential. Clinical methods, for instance, angiography is the best and most effective way of diagnosing HF, however, studies show that it is not only costly but has side effects as well. Lately, machine learning techniques have been used for the stated purpose. This survey paper aims to present a systematic literature review based on 35 journal articles published since 2012, where state of the art machine learning classification techniques have been implemented on heart disease datasets. This study critically analyzes the selected papers and finds gaps in the existing literature and is assistive for researchers who intend to apply machine learning in medical domains, particularly on heart disease datasets. The survey finds out that the most popular classification techniques are Support Vector Machine, Neural Networks, and ensemble classifiers.","deep learning, healthcare, neural network, heart diseases, machine learning, Heart failure, risk prediction"
Conference Paper,"Huang X,Tang X,Zhang W,Zhang J,Zhang M,Gan W,Pei S,Liu Z,Huang Y",A Generic Knowledge Based Medical Diagnosis Expert System,Association for Computing Machinery,2022,https://doi.org/10.1145/3487664.3487728;http://dx.doi.org/10.1145/3487664.3487728,"In this paper, we design and implement a generic medical knowledge based system (MKBS) for identifying diseases from several symptoms. In this system, some important aspects like knowledge bases system, knowledge representation, inference engine have been addressed. The system asks users different questions and inference engines will use the certainty factor to prune out low possible solutions. The proposed disease diagnosis system also uses a graphical user interface (GUI) to facilitate users to interact with the expert system. Our expert system is generic and flexible, which can be integrated with any rule bases system in disease diagnosis.",Not Found
Conference Paper,"V L,G SK",Deep Feature Fusion for Automated Retinal Disease Detection Using OCT Images,Association for Computing Machinery,2021,https://doi.org/10.1145/3490035.3490268;http://dx.doi.org/10.1145/3490035.3490268,"This paper proposes Deep Feature Fusion, a multi-layer feature fusion technique based on a deep convolutional neural network (DCNN), to build a fusion model for detecting retinal diseases from Optical Coherence Tomography (OCT) images. Although OCT has emerged as a potential imaging tool for retinal disease screening, automated disease detection remains a challenge. Most of the classification research concentrates on the DCNN feature map of the final convolution layer, ignoring the potential of internal layers. Hidden features information at different levels can be used to accomplish feature distinction. A DCNN model is created based on InceptionV3 which combines both local and global features. As a result, rather than depending solely on the final convolution layer, feature maps from multiple layers are combined using fusion techniques. The proposed approach appears to function effectively on publicly available retinal OCT data sets, according to the testing results.","OCT, DCNN, feature extraction, feature fusion, DME, AMD"
Conference Paper,"Zufferey D,Bromuri S,Schumacher M",Case-Based Retrieval of Similar Diabetic Patients,"ICST (Institute for Computer Sciences, Social-Informatics and Telecommunications Engineering)",2015,Not Found,"Patients suffering from diabetes often develop several comorbidities such as hypertension and dyslipidemia. The presence of the comorbidities leads to more complex patient profiles associated with specific patient treatments. In this paper we present a novel algorithm to help physicians, given a new case, in retrieving similar past patient cases. This novel algorithm is based on the bag-of-words (BoW) model to encode as features, the occurrence of each pre-computed cluster, for each patient, according to the approach of document classification. We then evaluate the algorithm on a real de-identified dataset of 3201 diabetic patients, demonstrating the advantage of our approach.","case-based retrieval, health records, comorbidities, diabetes, clustering"
Conference Paper,"Kyfonidis C,Lennon M","Mummy, Why Do I Have Diabetes? A Tangible Interface For Educating Children With Type-1 Diabetes",Association for Computing Machinery,2016,https://doi.org/10.1145/2930674.2935979;http://dx.doi.org/10.1145/2930674.2935979,"This paper presents the stakeholder centred design of an educational game for children, aged 3 to 8 years old, with type-1 diabetes. The novelty of the approach is the multi-stakeholder approach to design and evaluation (diabetes consultants, nurses, parents and children) and the creation of a tangible interface game for interactive learning of diabetes concepts for children aged 3-8.","Children, Tangible Interface, Diabetes Education"
Conference Paper,"Chen M,Wang Z,Zhao Z,Zhang W,Guo X,Shen J,Qu Y,Lu J,Xu M,Xu Y,Wang T,Li M,Tu W,Yu Y,Bi Y,Wang W,Ning G",Task-Wise Split Gradient Boosting Trees for Multi-Center Diabetes Prediction,Association for Computing Machinery,2021,https://doi.org/10.1145/3447548.3467123;http://dx.doi.org/10.1145/3447548.3467123,"Diabetes prediction is an important data science application in the social healthcare domain. There exist two main challenges in the diabetes prediction task: data heterogeneity since demographic and metabolic data are of different types, data insufficiency since the number of diabetes cases in a single medical center is usually limited. To tackle the above challenges, we employ gradient boosting decision trees (GBDT) to handle data heterogeneity and introduce multi-task learning (MTL) to solve data insufficiency. To this end, Task-wise Split Gradient Boosting Trees (TSGB) is proposed for the multi-center diabetes prediction task. Specifically, we firstly introduce task gain to evaluate each task separately during tree construction, with a theoretical analysis of GBDT's learning objective. Secondly, we reveal a problem when directly applying GBDT in MTL, i.e., the negative task gain problem. Finally, we propose a novel split method for GBDT in MTL based on the task gain statistics, named task-wise split, as an alternative to standard feature-wise split to overcome the mentioned negative task gain problem. Extensive experiments on a large-scale real-world diabetes dataset and a commonly used benchmark dataset demonstrate TSGB achieves superior performance against several state-of-the-art methods. Detailed case studies further support our analysis of negative task gain problems and provide insightful findings. The proposed TSGB method has been deployed as an online diabetes risk assessment software for early diagnosis.","health informatics, gradient tree boosting, diabetes prediction, multi-task learning"
Conference Paper,"Li G,Zhang S,Liang J,Cao Z,Guo C",An Embedding-Based Approach for Oral Disease Diagnosis Prediction from Electronic Medical Records,Association for Computing Machinery,2018,https://doi.org/10.1145/3239438.3239451;http://dx.doi.org/10.1145/3239438.3239451,"This paper reports a diagnosis prediction study from electronic medical records (EMRs) of oral diseases. We propose to learn continuous vector representations (embeddings) of symptoms and diagnoses through training neural networks. To the best of our knowledge, this is the first attempt to apply word embedding to predicting diagnoses from stomatologic EMR data. Evaluations on real-world EMR datasets from eleven departments in Peking University School and Hospital Stomatology demonstrate that our model has produced promising results in diagnosis prediction. Compared with classic machine learning algorithms, our model captures the correlation between symptoms and diagnoses, which leads to the best performance in terms of accuracy, precision, recall, F-score, and Cohen's kappa statistic. Visualizations illustrate the quality of the symptom and diagnosis embeddings generated by our approach.","Diagnosis prediction, Word embedding, Electronic medical record"
Conference Paper,"Luo J,Ye M,Xiao C,Ma F",HiTANet: Hierarchical Time-Aware Attention Networks for Risk Prediction on Electronic Health Records,Association for Computing Machinery,2020,https://doi.org/10.1145/3394486.3403107;http://dx.doi.org/10.1145/3394486.3403107,"Deep learning methods especially recurrent neural network based models have demonstrated early success in disease risk prediction on longitudinal patient data. Existing works follow a strong assumption to implicitly assume the stationary disease progression during each time period, and thus, take a homogeneous way to decay the information from previous time steps for all patients. However,in reality, disease progression is non-stationary. Besides, the key time steps for a target disease vary among patients. To leverage time information for risk prediction in a more reasonable way, we propose a new hierarchical time-aware attention network, named HiTANet, which imitates the decision making process of doctors inrisk prediction. Particularly, HiTANet models time information in local and global stages. The local evaluation stage has a time aware Transformer that embeds time information into visit-level embed-ding and generates local attention weight for each visit. The global synthesis stage further adopts a time-aware key-query attention mechanism to assign global weights to different time steps. Finally, the two types of attention weights are dynamically combined to generate the patient representations for further risk prediction. We evaluate HiTANet on three real-world datasets. Compared with the best results among twelve competing baselines, HiTANet achieves over 7% in terms of F1 score on all datasets, which demonstrates the effectiveness of the proposed model and the necessity of modeling time information in risk prediction task.","attention mechanism, risk prediction, transformer, healthcare informatics"
Conference Paper,"Nikoviotis R,Ringas D",Self-Care Diabetes: A Diabetes Self-Management Application Based on the Seven Self-Management Areas (AADE7) of the American Association of Diabetes Educators,Association for Computing Machinery,2022,https://doi.org/10.1145/3503823.3503910;http://dx.doi.org/10.1145/3503823.3503910,"The constant increase in the number of patients with chronic diseases, such as diabetes, over the last few decades and the high cost of their medical care for health systems have led to the development of applications that address such widespread health service challenges. Diabetes, in particular, has undoubtedly reached epidemic proportions as its incidence is constantly increasing at a particularly high rate worldwide. The purpose of this paper is to present a twofold application that will be an easy-to-use tool to improve the patient's quality of life through the effective self-management of diabetes and at the same time will provide the treating physician with a complete picture of the patient's health. In order to achieve these goals, the proposed application was based on the seven self-management areas (AADE7) of the American Association of Diabetes Educators, which are healthy eating, physical activity, blood glucose monitoring, medication, treating complications, reducing the risk of complications and healthy treatment to reduce stress. The application was made available for testing to a number of users suffering from diabetes; following the researchers asked the patients who used the application for a whole week to participate in a structured evaluation. Main findings include inferences about the application usability, technical issues that should be solved and ideas for future extensions. Bluetooth integration, data synchronization with other applications or devices, data encryption and data sharing with the treating physician, are some of the most important extensions that could be implemented.","Mobile applications, Mobile application frameworks, Firebase, Diabetes, Diabetes self-management, AADE7"
Conference Paper,"Xiao H,Gao J,Vu L,Turaga DS",Learning Temporal State of Diabetes Patients via Combining Behavioral and Demographic Data,Association for Computing Machinery,2017,https://doi.org/10.1145/3097983.3098100;http://dx.doi.org/10.1145/3097983.3098100,"Diabetes is a serious disease affecting a large number of people. Although there is no cure for diabetes, it can be managed. Especially, with advances in sensor technology, lots of data may lead to the improvement of diabetes management, if properly mined. However, there usually exists noise or errors in the observed behavioral data which poses challenges in extracting meaningful knowledge. To overcome this challenge, we learn the latent state which represents the patient's condition. Such states should be inferred from the behavioral data but unknown a priori. In this paper, we propose a novel framework to capture the trajectory of latent states for patients from behavioral data while exploiting their demographic differences and similarities to other patients. We conduct a hypothesis test to illustrate the importance of the demographic data in diabetes management, and validate that each behavioral feature follows an exponential or a Gaussian distribution. Integrating these aspects, we use a Demographic feature restricted hidden Markov model (DfrHMM) to estimate the trajectory of latent states by integrating the demographic and behavioral data. In DfrHMM, the latent state is mainly determined by the previous state and the demographic features in a nonlinear way. Markov Chain Monte Carlo techniques are used for model parameter estimation. Experiments on synthetic and real datasets show that DfrHMM is effective in diabetes management.","diabetes management, hidden markov model, hypothesis testing"
Conference Paper,"Dalveren GG,Mishra D",Software Engineering in Medical Informatics: A Systematic Literature Review,Association for Computing Machinery,2019,https://doi.org/10.1145/3357419.3357444;http://dx.doi.org/10.1145/3357419.3357444,"This study presents a systematic literature review to provide overall view of the application of Software Engineering (SE) in Medical Informatics (MI) field. Articles published from 2010 to 2019 from seven selected databases (Emerald, PubMed, IEEE, ACM, Taylor Francis, SAGE and Wiley) were investigated. The existing literature was analyzed, and the emerging areas of research in the medical informatics field have been identified. According to the findings of this study, medical informatics research has been applied in many fields but there is still potential of further research in different areas. Most of the reviewed studies were conducted on data mining, decision support, deep learning and IoT. Also, it can be said that most of the applications are provided as web-based instead of mobile applications. To conclude, the results of this study provides insights to the researchers about the research directions and the gaps in the literature in the MI and SE fields.","Software engineering, Health informatics, Medical informatics"
Journal Article,"Wu Y,Weimer J,Davidson SB",CHEF: A Cheap and Fast Pipeline for Iteratively Cleaning Label Uncertainties,VLDB Endowment,2021,https://doi.org/10.14778/3476249.3476290;http://dx.doi.org/10.14778/3476249.3476290,"High-quality labels are expensive to obtain for many machine learning tasks, such as medical image classification tasks. Therefore, probabilistic (weak) labels produced by weak supervision tools are used to seed a process in which influential samples with weak labels are identified and cleaned by several human annotators to improve the model performance. To lower the overall cost and computational overhead of this process, we propose a solution called CHEF (CHEap and Fast label cleaning), which consists of the following three components. First, to reduce the cost of human annotators, we use INFL, which prioritizes the most influential training samples for cleaning and provides cleaned labels to save the cost of one human annotator. Second, to accelerate the sample selector phase and the model constructor phase, we use Increm-INFL to incrementally produce influential samples, and DeltaGrad-L to incrementally update the model. Third, we redesign the typical label cleaning pipeline so that human annotators iteratively clean smaller batch of samples rather than one big batch of samples. This yields better overall model performance and enables possible early termination when the expected model performance has been achieved. Extensive experiments show that our approach gives good model prediction performance while achieving significant speed-ups.",Not Found
Conference Paper,"Chen Y,Li M,Hao F,Han W,Niu D,Wang C",Classification of Glomerular Spikes Using Convolutional Neural Network,Association for Computing Machinery,2020,https://doi.org/10.1145/3433996.3434043;http://dx.doi.org/10.1145/3433996.3434043,"Membranous nephropathy (MN) is a common cause of adult nephrotic syndrome. In clinical, MN is diagnosed by pathological biopsy. Under the light microscope, one of the main features is that a large number of immune complex deposits can be seen on the epithelial side of the glomerular capillary loop, which is called spikelike projections. However, the spikes are very small and the diagnosis of spikes requires pathologist's experience, so it is easy to cause missed diagnosis. In this paper, we proposed a model, SPIKE-NET, for the classification of glomeruli, which combine the U-Net and the ResNet. U-Net is used as a data preprocessing step to segment the glomeruli, and ResNet is used to classify the spiked glomeruli and normal glomeruli. We established a dataset containing 1267 images of glomeruli stained with PASM. The F1 of SPIKE-NET reaches 0.9448. The higher Recall of the model means a lower missed diagnosis rate, which is of great significance in clinical diagnosis and provides a good foundation for the intelligent auxiliary diagnosis of membranous nephropathy.","Classification, Glomerulus, Spikelike projections, Auxiliary diagnosis, Pathological diagnosis"
Conference Paper,"Faro A,Giordano D,Spampinato C,De Tommaso D,Ullo S",An Interactive Interface for Remote Administration of Clinical Tests Based on Eye Tracking,Association for Computing Machinery,2010,https://doi.org/10.1145/1743666.1743683;http://dx.doi.org/10.1145/1743666.1743683,"A challenging goal today is the use of computer networking and advanced monitoring technologies to extend human intellectual capabilities in medical decision making. Modern commercial eye trackers are used in many of research fields, but the improvement of eye tracking technology, in terms of precision on the eye movements capture, has led to consider the eye tracker as a tool for vision analysis, so that its application in medical research, e.g. in ophthalmology, cognitive psychology and in neuroscience has grown considerably. The improvements of the human eye tracker interface become more and more important to allow medical doctors to increase their diagnosis capacity, especially if the interface allows them to remotely administer the clinical tests more appropriate for the problem at hand. In this paper, we propose a client/server eye tracking system that provides an interactive system for monitoring patients eye movements depending on the clinical test administered by the medical doctors. The system supports the retrieval of the gaze information and provides statistics to both medical research and disease diagnosis.","opthalmology, cognitive psychology, vision research, neuroscience, eye tracking, medical research"
Conference Paper,"Aydin AS,Feiz S,Ashok V,Ramakrishnan IV",Towards Making Videos Accessible for Low Vision Screen Magnifier Users,Association for Computing Machinery,2020,https://doi.org/10.1145/3377325.3377494;http://dx.doi.org/10.1145/3377325.3377494,"People with low vision who use screen magnifiers to interact with computing devices find it very challenging to interact with dynamically changing digital content such as videos, since they do not have the luxury of time to manually move, i.e., pan the magnifier lens to different regions of interest (ROIs) or zoom into these ROIs before the content changes across frames.In this paper, we present SViM, a first of its kind screen-magnifier interface for such users that leverages advances in computer vision, particularly video saliency models, to identify salient ROIs in videos. SViM's interface allows users to zoom in/out of any point of interest, switch between ROIs via mouse clicks and provides assistive panning with the added flexibility that lets the user explore other regions of the video besides the ROIs identified by SViM.Subjective and objective evaluation of a user study with 13 low vision screen magnifier users revealed that overall the participants had a better user experience with SViM over extant screen magnifiers, indicative of the former's promise and potential for making videos accessible to low vision screen magnifier users.","screen magnifiers, low vision, video magnifiers, accessible videos"
Journal Article,"Marathe M,Toyama K","The Situated, Relational, and Evolving Nature of Epilepsy Diagnosis",Association for Computing Machinery,2021,https://doi.org/10.1145/3432916;http://dx.doi.org/10.1145/3432916,"An understanding of medical diagnosis as it is practiced is essential for those seeking to support it using intelligent systems. Through the case of epilepsy, we show that diagnosis is a situated, relational, and evolving process that accounts for information well beyond the patient's physiology, even for physiological phenomena like seizures. Through observations and interviews with neurologists, we show that the meaning of brainwaves and other physiological data depends upon a range of patient-specific and contextual factors, such as age, comorbidities, and mealtimes. Further, we show that diagnosis is partly determined by social factors such as the activities of caregivers and other clinicians, and environmental factors such as faulty electrical wiring. Additionally, diagnostic classifications can evolve in response to new information: events that were once considered seizures can be reinterpreted as clinically irrelevant and vice versa. We contribute a broader sociotechnical perspective to literature on intelligent decision making in healthcare and discuss implications for the design of decision support systems that can better support the work of medical diagnosis.","eeg, decision support systems, electroencephalogram, diagnosis, seizure detection, health, awareness, machine learning, workplace studies, medicine, context, epilepsy, ai"
Conference Paper,"Kamikubo R,Dwivedi U,Kacorri H",Sharing Practices for Datasets Related to Accessibility and Aging,Association for Computing Machinery,2021,https://doi.org/10.1145/3441852.3471208;http://dx.doi.org/10.1145/3441852.3471208,"Datasets sourced from people with disabilities and older adults play an important role in innovation, benchmarking, and mitigating bias for both assistive and inclusive AI-infused applications. However, they are scarce. We conduct a systematic review of 137 accessibility datasets manually located across different disciplines over the last 35 years. Our analysis highlights how researchers navigate tensions between benefits and risks in data collection and sharing. We uncover patterns in data collection purpose, terminology, sample size, data types, and data sharing practices across communities of focus. We conclude by critically reflecting on challenges and opportunities related to locating and sharing accessibility datasets calling for technical, legal, and institutional privacy frameworks that are more attuned to concerns from these communities.","repository, dataset, machine learning., sharing practices, disability"
Conference Paper,"Bomark P,Evertsen G,Brox E,Hirche J,Yliräisänen-Seppänen P",A Prototype Social Learning Platform for Children with Diabetes Type 1,Association for Computing Machinery,2012,https://doi.org/10.1145/2393132.2393174;http://dx.doi.org/10.1145/2393132.2393174,"Children diagnosed with diabetes type 1 are bombarded with information and have a hard time understanding it all. Existing information material consists mostly of brochures and textbooks, giving little opportunity for testing and trial-and-error without consequences. A social platform with learning games gives the children an opportunity to experiment and find peer support, which is important for coping with a life long disease.","health, user centric design, serious games, diabetes, social game, persuasive computing, multidisciplinary work, social computing"
Conference Paper,"Afshar A,Perros I,Park H,deFilippi C,Yan X,Stewart W,Ho J,Sun J",TASTE: Temporal and Static Tensor Factorization for Phenotyping Electronic Health Records,Association for Computing Machinery,2020,https://doi.org/10.1145/3368555.3384464;http://dx.doi.org/10.1145/3368555.3384464,"Phenotyping electronic health records (EHR)focuses on defining meaningful patient groups (e.g., heart failure group and diabetes group) and identifying the temporal evolution of patients in those groups. Tensor factorization has been an effective tool for phenotyping. Most of the existing works assume either a static patient representation with aggregate data or only model temporal data. However, real EHR data contain both temporal (e.g., longitudinal clinical visits) and static information (e.g., patient demographics), which are difficult to model simultaneously. In this paper, we propose Temporal And Static TEnsor factorization (TASTE) that jointly models both static and temporal information to extract phenotypes.TASTE combines the PARAFAC2 model with non-negative matrix factorization to model a temporal and a static tensor. To fit the proposed model, we transform the original problem into simpler ones which are optimally solved in an alternating fashion. For each of the sub-problems, our proposed mathematical re-formulations lead to efficient sub-problem solvers. Comprehensive experiments on large EHR data from a heart failure (HF) study confirmed that TASTE is up to 14× faster than several baselines and the resulting phenotypes were confirmed to be clinically meaningful by a cardiologist. Using 60 phenotypes extracted by TASTE, a simple logistic regression can achieve the same level of area under the curve (AUC) for HF prediction compared to a deep learning model using recurrent neural networks (RNN) with 345 features.","Tensor Factorization, Computational Phenotyping, Predictive modeling"
Journal Article,"Hynes N,Dao D,Yan D,Cheng R,Song D",A Demonstration of Sterling: A Privacy-Preserving Data Marketplace,VLDB Endowment,2018,https://doi.org/10.14778/3229863.3236266;http://dx.doi.org/10.14778/3229863.3236266,"In this work, we demonstrate Sterling, a decentralized marketplace for private data. Sterling enables privacy-preserving distribution and use of data by using privacy-preserving smart contracts which run on a permissionless blockchain. The privacy-preserving smart contracts, written by data providers and consumers, immutably and irrevocably represent the interests of their creators. In particular, we provide a mechanism for data providers to control the use of their data through automatic verification of data consumer contracts, allowing providers to express constraints such as pricing and differential privacy. Through smart contracts and trusted execution environments, Sterling enables privacy-preserving analytics and machine learning over private data in an efficient manner. The resulting economy ensures that the interests of all parties are aligned.For the demonstration, we highlight the use of Sterling for training machine learning models on individuals' health data. In doing so, we showcase novel approaches to automatically appraising training data, verifying and enforcing model privacy properties, and efficiently training private models on the blockchain using trusted hardware.",Not Found
Book,Not Found,ICIST '22: Proceedings of the 4th International Conference on Intelligent Science and Technology,Association for Computing Machinery,2022,Not Found,Not Found,Not Found
Book,Not Found,ICNSER '22: Proceedings of the 3rd International Conference on Industrial Control Network and System Engineering Research,Association for Computing Machinery,2022,Not Found,Not Found,Not Found
Conference Paper,"Tamvakis A,Anagnostopoulos CN,Tsekouras G,Anastassopoulos G",Optimizing Voting Classification Using Cluster Analysis on Medical Diagnosis Data,Association for Computing Machinery,2015,https://doi.org/10.1145/2797143.2797156;http://dx.doi.org/10.1145/2797143.2797156,"Voting ensemble method combines results of single classifiers aiming to offer improved classification performance. However, it is intuitively accepted that the combined classifiers during voting should be both diverse and accurate. In this study, we used the unsupervised method of cluster analysis in four datasets related to medical diagnosis in order to differentiate the single classifiers according to their individual results. Using this information we selected the most accurate among similar classifiers proposing the optimal classifier combination for each dataset. The results show that the estimated combination was actually the best performing during voting training for two of the datasets while in the other two it was one of those that outperformed single classifiers. The proposed methodology is a quick and easy tool for estimating classifier combinations that outperforms the single classifiers during voting.","classification, medical diagnosis, Voting ensemble method, cluster analysis"
Journal Article,"Tibo A,Jaeger M,Frasconi P",Learning and Interpreting Multi-Multi-Instance Learning Networks,JMLR.org,2022,Not Found,"We introduce an extension of the multi-instance learning problem where examples are organized as nested bags of instances (e.g., a document could be represented as a bag of sentences, which in turn are bags of words). This framework can be useful in various scenarios, such as text and image classification, but also supervised learning over graphs. As a further advantage, multi-multi instance learning enables a particular way of interpreting predictions and the decision function. Our approach is based on a special neural network layer, called bag-layer, whose units aggregate bags of inputs of arbitrary size. We prove theoretically that the associated class of functions contains all Boolean functions over sets of sets of instances and we provide empirical evidence that functions of this kind can be actually learned on semi-synthetic datasets. We finally present experiments on text classification, on citation graphs, and social graph data, which show that our model obtains competitive results with respect to accuracy when compared to other approaches such as convolutional networks on graphs, while at the same time it supports a general approach to interpret the learnt model, as well as explain individual predictions.","deep learning, relational learning, multi-multi instance learning"
Conference Paper,"Lee HN,Prakash Y,Sunkara M,Ramakrishnan IV,Ashok V",Enabling Convenient Online Collaborative Writing for Low Vision Screen Magnifier Users,Association for Computing Machinery,2022,https://doi.org/10.1145/3511095.3531274;http://dx.doi.org/10.1145/3511095.3531274,"Online collaborative editors have become increasingly prevalent in both professional and academic settings. However, little is known about how usable these editors are for low vision screen magnifier users, as existing research works have predominantly focused on blind screen reader users. An interview study revealed that it is arduous and frustrating for screen magnifier users to perform even the basic collaborative writing activities, such as addressing collaborators’ comments and reviewing document changes. Specific interaction challenges underlying these issues included excessive panning, content occlusion, large empty space patches, and frequent loss of context. To address these challenges, we developed MagDocs, a browser extension that assists screen magnifier users in conveniently performing collaborative writing activities on the Google Docs web application. MagDocs is rooted in two ideas: (i) a custom support interface that users can instantly access on demand and interact with collaborative interface elements, such as comments or collaborator edits, within the current magnifier viewport; and (ii) visual relationship preservation, where collaborative elements and the corresponding text in the document are shown close to each other within the magnifier viewport to minimize context loss and panning effort. A study with 15 low vision users showed that MagDocs significantly improved the overall user satisfaction and interaction experience, while also substantially reduced the time and effort to perform typical collaborative writing tasks.","Visual Impairment, Assistive Technology, Accessibility, Low Vision, Online Collaborative Writing, Screen Magnifier"
Conference Paper,"Luštrek M,Cvetković B,Mirchevska V,Kafalι Ö,Romero AE,Stathis K",Recognising Lifestyle Activities of Diabetic Patients with a Smartphone,"ICST (Institute for Computer Sciences, Social-Informatics and Telecommunications Engineering)",2015,Not Found,"Diabetes is both heavily affected by the patients' lifestyle, and it affects their lifestyle. Most diabetic patients can manage the disease without technological assistance, so we should not burden them with technology unnecessarily, but lifestyle-monitoring technology can still be beneficial both for patients and their physicians. Because of that we developed an approach to lifestyle monitoring that uses the smartphone, which most patients already have. The approach consists of three steps. First, a number of features are extracted from the data acquired by smartphone sensors, such as the user's location from GPS coordinates and visible wi-fi access points, and the physical activity from accelerometer data. Second, several classifiers trained by machine learning are used to recognise the user's activity, such as work, exercise or eating. And third, these activities are refined by symbolic reasoning encoded in Event Calculus. The approach was trained and tested on five people who recorded their activities for two weeks each. Its classification accuracy was 0.88.","sensors, lifestyle, diabetes, activity recognition, smartphone"
Conference Paper,"Brailsford SC,Viana J,Rossiter S,Channon Aamos,Lotery AJ","Hybrid Simulation for Health and Social Care: The Way Forward, or More Trouble than It's Worth?",IEEE Press,2013,Not Found,"This paper describes the process of developing a hybrid simulation model for a disease called age-related macular degeneration (AMD), a common cause of sight loss in people aged over 65. The model is implemented in the software AnyLogic, and combines discrete-event and agent-based simulation. Embedded in each agent there is also an individual compartmental model for disease progression. The overall aim of the hybrid model was to use the specific example of AMD to explore the wider links between the health and social care systems in the UK. We discuss the challenges of model development and the rationale for our modelling decisions, and reflect upon the advantages and disadvantages of using a hybrid model in this case.",Not Found
Conference Paper,"Wang Q,Wang S,Wu N,Xu LQ",An Automatic Sleep Staging Method Using a Multi-Head and Sequence Network,Association for Computing Machinery,2020,https://doi.org/10.1145/3403782.3403797;http://dx.doi.org/10.1145/3403782.3403797,"Sleep plays an important role in human life and sleep disorders are becoming a major public health issue. Identifying the sleep stages correctly with the polysomnogram, which is a collection of relevant physiological signals recorded during sleep, helps clinicians diagnose and treat sleep disorders. Nevertheless, the manual process of performing such a sleep staging task is very time consuming and prone to technicians' labeling errors. To tackle these issues, there have been many efforts in designing various machine learning/ deep learning-based automated methods for sleep staging over the past years, this paper proposed an innovative automatic sleep staging method based on a hybrid multi-head and sequence network architecture. Different from previous works, this method extracted multi-modality features from EEG and EOG with the multi-head CNNs and then integrated them with heuristic weights obtained through experiments. Moreover, the joint loss function based on cross entropy loss function was also applied, wherein multiple embedded losses were added simultaneously and propagated backward. We tested our method using the popular public dataset ""Sleep-EDF[Expanded]"" from the PhysioNet website. The best result showed an accuracy of 91.76% and Cohen's kappa value over 0.836 compared with human experts, which had competitive advantages over most of previous research results using automated methods on the same dataset.","Sleep stages classification, Polysomnography, Multi-modality, Multi-head network, Bi-LSTM"
Conference Paper,"Xue Y,Zhou D,Du N,Dai AM,Xu Z,Zhang K,Cui C",Deep State-Space Generative Model For Correlated Time-to-Event Predictions,Association for Computing Machinery,2020,https://doi.org/10.1145/3394486.3403206;http://dx.doi.org/10.1145/3394486.3403206,"Capturing the inter-dependencies among multiple types of clinically-critical events is critical not only to accurate future event prediction, but also to better treatment planning. In this work, we propose a deep latent state-space generative model to capture the interactions among different types of correlated clinical events (e.g., kidney failure, mortality) by explicitly modeling the temporal dynamics of patients' latent states. Based on these learned patient states, we further develop a new general discrete-time formulation of the hazard rate function to estimate the survival distribution of patients with significantly improved accuracy. Extensive evaluations over real EMR data show that our proposed model compares favorably to various state-of-the-art baselines. Furthermore, our method also uncovers meaningful insights about the latent correlations among mortality and different types of organ failures.","generative model, state space model, survival analysis"
Conference Paper,"Kaur H,Adar E,Gilbert E,Lampe C",Sensible AI: Re-Imagining Interpretability and Explainability Using Sensemaking Theory,Association for Computing Machinery,2022,https://doi.org/10.1145/3531146.3533135;http://dx.doi.org/10.1145/3531146.3533135,"Understanding how ML models work is a prerequisite for responsibly designing, deploying, and using ML-based systems. With interpretability approaches, ML can now offer explanations for its outputs to aid human understanding. Though these approaches rely on guidelines for how humans explain things to each other, they ultimately solve for improving the artifact—an explanation. In this paper, we propose an alternate framework for interpretability grounded in Weick’s sensemaking theory, which focuses on who the explanation is intended for. Recent work has advocated for the importance of understanding stakeholders’ needs—we build on this by providing concrete properties (e.g., identity, social context, environmental cues, etc.) that shape human understanding. We use an application of sensemaking in organizations as a template for discussing design guidelines for sensible AI, AI that factors in the nuances of human cognition when trying to explain itself.","explainability, interpretability, organizations, sensemaking"
Conference Paper,"Nneji GU,Cai J,Deng J,Monday HN,James EC,Lemessa BD,Yutra AZ,Leta YB,Nahar S",COVID-19 Identification Using Deep Capsule Network: A Perspective of Super-Resolution CNN on Low-Quality CXR Images,Association for Computing Machinery,2022,https://doi.org/10.1145/3507971.3507989;http://dx.doi.org/10.1145/3507971.3507989,"Chest X-ray has become a useful method in the detection of coronavirus disease-19 (COVID-19). Due to the extreme global COVID-19 crisis, using the computerized diagnosis method for COVID-19 classification upon CXR images could significantly decrease clinician workload. We explicitly addressed the issue of low CXR image resolution by using Super-Resolution Convolutional Neural Network (SRCNN) to effectively reconstruct high-resolution (HR) CXR images from low-resolution (LR) CXR correspondents. Then, the HRCXR images are fed into the modified capsule network to retrieve distinct features for the classification of COVID-19. We demonstrate the proposed model on a public dataset and achieve ACC of 97.3%, SEN of 97.8%, SPE of 96.9%, and AUC of 98.0%. This new conceptual framework is proposed to play a vital task in the issue facing COVID-19 and related ailments.","COVID-19, Convolutional Neural Network (CNN), capsule network, Deep learning, chest x-ray, super-resolution"
Conference Paper,"Visser L,Shahid S,Al Mahmud A",Point-of-Care Testing for Diabetes Patients: Investigating Diabetes Management by Older Adults,Association for Computing Machinery,2014,https://doi.org/10.1145/2559206.2581193;http://dx.doi.org/10.1145/2559206.2581193,"Point-of-care testing is an important phenomenon in contemporary healthcare. The opportunity of self-testing by patients provides quicker results and independence for patients, especially for people with chronic diseases, like diabetes mellitus. Glucometers are point-of-care testing devices that facilitate this controlling of the disease. This qualitative research focuses on how older adults manage their diabetes, what role the glucometers play in that management of it and how satisfied they are with that. Based on the results some suggestions for improvements are given.","self-management, diabetes, point-of-care testing (POCT), glucometers, elderly"
Book,Not Found,ICIIP '22: Proceedings of the 7th International Conference on Intelligent Information Processing,Association for Computing Machinery,2022,Not Found,Not Found,Not Found
Conference Paper,"Khan A,Uddin S,Srinivasan U",Adapting Graph Theory and Social Network Measures on Healthcare Data: A New Framework to Understand Chronic Disease Progression,Association for Computing Machinery,2016,https://doi.org/10.1145/2843043.2843380;http://dx.doi.org/10.1145/2843043.2843380,"Governments all over the world are concerned about the disease burden caused by chronic conditions. A significant portion of this comes from potentially preventable hospital admissions. By adopting preventive measures, these admissions can be avoided which in turn can reduce cost and health risk, further benefitting the funders, providers and patients as well. One potential approach can be to look at healthcare information system, more specifically - hospital admission data that carries rich semantic information. In this paper we present a novel framework to apply social network and graph theoretic methods on modern healthcare data to analyse and understand chronic disease progression to enable all stakeholders to take appropriate preventive measures.","health informatics, healthcare data, knowledge management, risk assessment, social network analysis, network theory, chronic disease, data science"
Book,Not Found,ICIIP '22: Proceedings of the 7th International Conference on Intelligent Information Processing,Association for Computing Machinery,2022,Not Found,Not Found,Not Found
Conference Paper,"Khan A,Uddin S,Srinivasan U",Adapting Graph Theory and Social Network Measures on Healthcare Data: A New Framework to Understand Chronic Disease Progression,Association for Computing Machinery,2016,https://doi.org/10.1145/2843043.2843380;http://dx.doi.org/10.1145/2843043.2843380,"Governments all over the world are concerned about the disease burden caused by chronic conditions. A significant portion of this comes from potentially preventable hospital admissions. By adopting preventive measures, these admissions can be avoided which in turn can reduce cost and health risk, further benefitting the funders, providers and patients as well. One potential approach can be to look at healthcare information system, more specifically - hospital admission data that carries rich semantic information. In this paper we present a novel framework to apply social network and graph theoretic methods on modern healthcare data to analyse and understand chronic disease progression to enable all stakeholders to take appropriate preventive measures.","health informatics, healthcare data, knowledge management, risk assessment, social network analysis, network theory, chronic disease, data science"
Journal Article,"Ibrahim R,Shafiq MO","Explainable Convolutional Neural Networks: A Taxonomy, Review, and Future Directions",Association for Computing Machinery,2022,https://doi.org/10.1145/3563691;http://dx.doi.org/10.1145/3563691,"Convolutional neural networks (CNNs) have shown promising results and have outperformed classical machine learning techniques in tasks such as image classification and object recognition. Their human-brain alike structure enabled them to learn sophisticated features while passing images through their layers. However, their lack of explainability led to the demand for interpretations to justify their predictions. Research on Explainable AI or XAI has gained momentum to provide knowledge and insights into neural networks. This study summarizes the literature to gain more understanding of explainability in CNNs (i.e., Explainable Convolutional Neural Networks). We classify models that made efforts to improve the CNNs interpretation. We present and discuss taxonomies for XAI models that modify CNN architecture, simplify CNN representations, analyze feature relevance, and visualize interpretations. We review various metrics used to evaluate XAI interpretations. In addition, we discuss the applications and tasks of XAI models. This focused and extensive survey develops a perspective on this area by addressing suggestions for overcoming XAI interpretation challenges, like models’ generalization, unifying evaluation criteria, building robust models, and providing interpretations with semantic descriptions. Our taxonomy can be a reference to motivate future research in interpreting neural networks.","Convolutional Neural Networks, Explainable AI, Survey, Interpretable AI"
Journal Article,"Liu R,Cornelius C,Rawassizadeh R,Peterson R,Kotz D",Vocal Resonance: Using Internal Body Voice for Wearable Authentication,Association for Computing Machinery,2018,https://doi.org/10.1145/3191751;http://dx.doi.org/10.1145/3191751,"We observe the advent of body-area networks of pervasive wearable devices, whether for health monitoring, personal assistance, entertainment, or home automation. For many devices, it is critical to identify the wearer, allowing sensor data to be properly labeled or personalized behavior to be properly achieved. In this paper we propose the use of vocal resonance, that is, the sound of the person's voice as it travels through the person's body -- a method we anticipate would be suitable for devices worn on the head, neck, or chest. In this regard, we go well beyond the simple challenge of speaker recognition: we want to know who is wearing the device. We explore two machine-learning approaches that analyze voice samples from a small throat-mounted microphone and allow the device to determine whether (a) the speaker is indeed the expected person, and (b) the microphone-enabled device is physically on the speaker's body. We collected data from 29 subjects, demonstrate the feasibility of a prototype, and show that our DNN method achieved balanced accuracy 0.914 for identification and 0.961 for verification by using an LSTM-based deep-learning model, while our efficient GMM method achieved balanced accuracy 0.875 for identification and 0.942 for verification.","wearable device, vocal resonance, Biometric, authentication, mobile system security"
Conference Paper,"Tang Z,Wu H,Li C",Research on IOT in the Environment of Intelligent Support for the Aged,Association for Computing Machinery,2022,https://doi.org/10.1145/3523286.3524509;http://dx.doi.org/10.1145/3523286.3524509,Not Found,"emotional support, intelligent medical care, artificial intelligence, Internet of things, intelligent aging"
Conference Paper,"Wei Y,Li H,Feng H,Zhou P,Lu X,Shen Y",Simultaneous Learning Algorithm for Multiple Sets of Synonyms with Different Semantics,Association for Computing Machinery,2021,https://doi.org/10.1145/3444370.3444561;http://dx.doi.org/10.1145/3444370.3444561,"Up to now, scholars have proposed some algorithms for learning synonyms of laboratory indicators. However, there is no report on learning multiple synonym sets at same time for outliers of laboratory indicators. Among the outliers of laboratory indicators of diseases, there are multiple synonym sets with various semantics such as high, higher, increase, low, lower, decrease, very low, significantly low. In this paper, a synonym set learning algorithm for different semantics of outliers of laboratory indicators is proposed. Firstly, using the sentence pattern laboratory indicators, outliers, and disease entities from medical texts are extracted; secondly, a set of synonyms for different semantics of laboratory indicators and outliers are learned; thirdly, the correspondences relation of laboratory indicators, outliers, and diseases are established. In the process of the first task, the algorithm is designed like a BERT model, that is, masking any one component and learning it with the other unmasked three parts, then updating the component sets that will include the learned components, and then with the new three unmasked components that includes the updated component sets to learn a new component that is included in the previous unmasked components. These steps run iteratively until every component sets do not varied. The experimental results show that the proposed algorithms is effective.","BERT, Medical Knowledge Graph, Information extraction, Synonyms"
Conference Paper,"Libed JM,Perreras R,Carpio J",Type II Diabetes Analysis Using Naïve Bayesian Classification Algorithm,Association for Computing Machinery,2020,https://doi.org/10.1145/3424311.3424327;http://dx.doi.org/10.1145/3424311.3424327,"Patients medical historical record has been extensively used in different data mining methods in order to provide a more reliable medical diagnosis. In this study, the researchers developed a type II diabetes analysis using Naïve Bayesian classification algorithm in constructing a map rule for the prediction process.","Data Mining, Map rule, Naïve Bayesian classification algorithm, Type II diabetes"
Conference Paper,"Zhang X,Qian B,Cao S,Li Y,Chen H,Zheng Y,Davidson I",INPREM: An Interpretable and Trustworthy Predictive Model for Healthcare,Association for Computing Machinery,2020,https://doi.org/10.1145/3394486.3403087;http://dx.doi.org/10.1145/3394486.3403087,"Building a predictive model based on historical Electronic Health Records (EHRs) for personalized healthcare has become an active research area. Benefiting from the powerful ability of feature extraction, deep learning (DL) approaches have achieved promising performance in many clinical prediction tasks. However, due to the lack of interpretability and trustworthiness, it is difficult to apply DL in real clinical cases of decision making. To address this, in this paper, we propose an interpretable and trustworthy predictive model (INPREM) for healthcare. Firstly, INPREM is designed as a linear model for interpretability while encoding non-linear relationships into the learning weights for modeling the dependencies between and within each visit. This enables us to obtain the contribution matrix of the input variables, which is served as the evidence of the prediction result(s), and help physicians understand why the model gives such a prediction, thereby making the model more interpretable. Secondly, for trustworthiness, we place a random gate (which follows a Bernoulli distribution to turn on or off) over each weight of the model, as well as an additional branch to estimate data noises. With the help of the Monto Carlo sampling and an objective function accounting for data noises, the model can capture the uncertainty of each prediction. The captured uncertainty, in turn, allows physicians to know how confident the model is, thus making the model more trustworthy. We empirically demonstrate that the proposed INPREM outperforms existing approaches with a significant margin. A case study is also presented to show how the contribution matrix and the captured uncertainty are used to assist physicians in making robust decisions.","model uncertainty, healthcare informatics, model interpretability, attention mechanism"
Conference Paper,"Jampani V,Ujjwal,Sivaswamy J,Vaidya V",Assessment of Computational Visual Attention Models on Medical Images,Association for Computing Machinery,2012,https://doi.org/10.1145/2425333.2425413;http://dx.doi.org/10.1145/2425333.2425413,"Several computational visual saliency models have been proposed in the context of viewing natural scenes. We aim to investigate the relevance of computational saliency models in medical images in the context of abnormality detection. We report on two studies aimed at understanding the role of visual saliency in medical images. Diffuse lesions in Chest X-Ray images, which are characteristic of Pneumoconiosis and high contrast lesions such as 'Hard Exudates' in retinal images were chosen for the study. These approximately correspond to conjunctive and disjunctive targets in a visual search task. Saliency maps were computed using three popular models namely Itti-Koch [7], GBVS [3] and SR [4]. The obtained maps were evaluated against gaze maps and ground truth from medical experts.Our results show that GBVS is seen to perform the best (Mdn. ROC area = 0.77) for chest X-Ray images while SR performs the best (ROC area = 0.73) for retinal images, thus asserting that searching for conjunctive targets calls for a more local examination of an image while disjunctive targets call for a global examination. Based on the results of the above study, we propose extensions for the two best performing models. The first extension makes use of top down knowledge such as lung segmentation. This is shown to improve the performance of GBVS to some extent. In the second case the extension is by way of including multi-scale information. This is shown to significantly (by 28.76%) improve abnormality detection. The key insight from these studies is that bottom saliency continues to play a predominant role in examining medical images.","retinal images, chest X-rays, visual attention, saliency models"
Conference Paper,"van der Drift EJ,Beun RJ,Looije R,Blanson Henkemans OA,Neerincx MA",A Remote Social Robot to Motivate and Support Diabetic Children in Keeping a Diary,Association for Computing Machinery,2014,https://doi.org/10.1145/2559636.2559664;http://dx.doi.org/10.1145/2559636.2559664,"Children with diabetes can benefit from keeping a diary, but seldom keep one. Within the European ALIZ-E project a robot companion is being developed that, among other things, will be able to support and motivate diabetic children to keep a diary. This paper discusses the study of a robot supporting the use of an online diary. Diabetic children kept an online diary for two weeks, both with and without remote support from the robot via webcam. The effect of the robot was studied on children's use of the diary and their relationship with the robot. Results show that children shared significantly more personal experiences in their diaries when they were interacting with the robot. Furthermore, they greatly enjoyed working with the robot and came to see it as a helpful and supportive friend.","diary, human-robot interaction, child-robot interaction, social robot, embodiment, adherence, relationship, diabetes, compliance, engagement, remote robot, bonding"
Journal Article,"Joshi M,Pal A,Sankarasubbu M","Federated Learning for Healthcare Domain - Pipeline, Applications and Challenges",Association for Computing Machinery,2022,https://doi.org/10.1145/3533708;http://dx.doi.org/10.1145/3533708,"Federated learning is the process of developing machine learning models over datasets distributed across data centers such as hospitals, clinical research labs, and mobile devices while preventing data leakage. This survey examines previous research and studies on federated learning in the healthcare sector across a range of use cases and applications. Our survey shows what challenges, methods, and applications a practitioner should be aware of in the topic of federated learning. This paper aims to lay out existing research and list the possibilities of federated learning for healthcare industries.","Federated learning, GDPR, transfer learning"
Conference Paper,"Jain P,Kaur A",A Fuzzy Expert System for Coronary Artery Disease Diagnosis,Association for Computing Machinery,2019,https://doi.org/10.1145/3339311.3339358;http://dx.doi.org/10.1145/3339311.3339358,"Medicinal services industry is the one of most rapidly developing industry in the world. As sicknesses growing rapidly, the information of the patients will be extended. Heart illness is the one of developing infection. Coronary artery heart disease is the huge purpose behind the grimness in the advanced society. The early diagnosis will be improve the therapeutic divisions. The aim of this study is to design a fuzzy expert system for diagnosis of coronary artery heart disease. With the assistance of this framework, the specialists will be finding the patient early and the chance of re-admission to the emergency clinics will be diminishes. The framework has nine information documented and one yield recorded.","fuzzy expert system, healthcare, coronary artery heart disease, fuzzy logic, rule based system"
Conference Paper,"Li T,Li G,Li F,Zhang C",A SuperPoint-Based Method for Automatic Stitching of Corneal Nerve Microscopy Images,Association for Computing Machinery,2022,https://doi.org/10.1145/3532213.3532314;http://dx.doi.org/10.1145/3532213.3532314,"This paper presents an end-to-end image stitching method for a large number of in vivo corneal confocal microscopy images. We firstly learn a feature point detector for self-labeling from a randomly generated synthetic shape dataset. And then the self-labeling detector is utilized to the confocal microscopic images to match the nerve structure. Finally the microscopic image data with pseudo-ground truth feature points is utilized to the training model again to obtain the stable and repeatable feature points. Images registration is carried out using the Brute-Force matching and the adapted affine transform. In the experiments, the effectiveness of the method is verified by comparing with the classical feature detection algorithm and existing stitching methods. A large scale of corneal confocal microscopy is obtained with accurate joint of corneal nerves.","images stitching, laser scanning in vivo confocal microscopy, computer aided diagnosis, corneal nerve"
Conference Paper,"Zhang K,Zhang C,Ye Y,Zan H,Liu X",Named Entity Recognition in Electronic Medical Records Based on Transfer Learning,Association for Computing Machinery,2022,https://doi.org/10.1145/3560071.3560086;http://dx.doi.org/10.1145/3560071.3560086,"Named entity recognition is the first step in clinical electronic medical record text mining, which is significant for clinical decision support and personalized medicine. However, the lack of annotated electronic medical record datasets limits the application of pre-trained language models and deep neural networks in this field. To alleviate the problem of data scarcity, we propose T-RoBERTa-BiLSTM-CRF, a transfer learning-based electronic medical record entity recognition model, which aggregates the characteristics of medical data from different sources and uses a small amount of electronic medical record data as target data for further training. Compared with existing models, our approach can model medical entities more effectively, and the extensive comparative experiments on the CCKS 2019 and DEMRC datasets show the effectiveness of our approach.","Transfer Learning, Named Entity Recognition, Electronic Medical Record"
Conference Paper,"Ramroach S,Dhanoo A,Cockburn B,Joshi A",CUDA Optimized Neural Network Predicts Blood Glucose Control from Quantified Joint Mobility and Anthropometrics,Association for Computing Machinery,2019,https://doi.org/10.1145/3325917.3325940;http://dx.doi.org/10.1145/3325917.3325940,"Neural network training entails heavy computation with obvious bottlenecks. The Compute Unified Device Architecture (CUDA) programming model allows us to accelerate computation by passing the processing workload from the CPU to the graphics processing unit (GPU). In this paper, we leveraged the power of Nvidia GPUs to parallelize all of the computation involved in training, to accelerate a backpropagation feed-forward neural network with one hidden layer using CUDA and C++. This optimized neural network was tasked with predicting the level of glycated hemoglobin (HbA1c) from non-invasive markers. The rate of increase in the prevalence of Diabetes Mellitus has resulted in an urgent need for early detection and accurate diagnosis. However, due to the invasiveness and limitations of conventional tests, alternate means are being considered. Limited Joint Mobility (LJM) has been reported as an indicator for poor glycemic control. LJM of the fingers is quantified and its link to HbA1c is investigated along with other potential non-invasive markers of HbA1c. We collected readings of 33 potential markers from 120 participants at a clinic in south Trinidad. Our neural network achieved 95.65% accuracy on the training and 86.67% accuracy on the testing set for male participants and 97.73% and 66.67% accuracy on the training and testing sets for female participants. Using 960 CUDA cores from a Nvidia GeForce GTX 660, our parallelized neural network was trained 50 times faster on both subsets, than its corresponding CPU implementation on an Intel® Core™ i7-3630QM 2.40 GHz CPU.","Neural Network, Diabetes Mellitus, Limited Joint Mobility, CUDA, Parallel Processing"
Conference Paper,"Liu S,Xu JC,Liu G,Xue H,Bishai D,Wang Y",Evaluating Cost-Effectiveness of Treatment Options for Diabetes Patients Using System Dynamics Modeling,IEEE Press,2018,Not Found,"The growing global diabetes epidemic is a serious public health problem. We developed a system dynamic model to study the cost-effectiveness of different diabetes treatment options. According to existing literature, we estimated dynamic costs and changes of hemoglobin A1c levels of two first-line monotherapies and a hypothetical innovation therapy for glycemic control over a 15-year horizon. Incremental cost-effectiveness ratios were expressed as dollars per HbA1c decrement from perspectives of the patient, insurance-payer, and society. Simulation results showed that better adherence with a more expensive and efficacious drug results in better control of HbA1c and cost-saving in the long-run. The results also showed that the cost-effectiveness ratio varied with patients' pre-determined out-of-pocket payment for health expenditure. The higher the rate of their out-of-pocket payment for extra health care expenditure to their household income, the more cost-effective it is for the innovative drug from the perspectives of the patient, insurance-payer, and society.",Not Found
Conference Paper,"Ismail L,Materwala H,Khan MA",Performance Evaluation of a Patient-Centric Blockchain-Based Healthcare Records Management Framework,Association for Computing Machinery,2020,https://doi.org/10.1145/3409934.3409941;http://dx.doi.org/10.1145/3409934.3409941,"Healthcare records management system has been revolutionized over the last decade aiming to provide accurate, efficient and enhanced patient care. The existing management system is either based on a client/server approach where each hospital maintains its own database or on a cloud approach where the health records are stored in a cloud server and managed by a third-party cloud service provider. However, these approaches suffer from the issues of security, privacy, data vulnerability and fragmentation. Furthermore, healthcare providers and patients are unable to have a unified view of a patient's medical history from all visited medical care centers. This results in additional treatment costs, repeated medical tests and increased time to diagnosis. The data traceability, immutability, transparency, replication, security and privacy traits of the emerging blockchain technology have a promising potential in the healthcare domain addressing these issues. In this paper, we propose BlockHR, a patient-centric healthcare records management system for efficient medical care at an optimal cost. The system enables healthcare providers to enter the patients' medical record data to the blockchain network and allows patients to enter their social data such as sleeping habits, physical activities, and current location. Consequently, BlockHR provides support to doctors for better diagnosis and prognosis. We evaluate the performance of BlockHR in terms of execution time and the total amount of data transferred for ledger update with an increasing number of hospitals and blocks in the network.","Prognosis, Diagnosis, Patient-centric; Privacy, Data security, Health data management system, Electronic health records, Blockchain"
Journal Article,"Hassantabar S,Zhang J,Yin H,Jha NK",MHDeep: Mental Health Disorder Detection System Based on Wearable Sensors and Artificial Neural Networks,Association for Computing Machinery,2022,https://doi.org/10.1145/3527170;http://dx.doi.org/10.1145/3527170,"Mental health problems impact the quality of life of millions of people around the world. However, diagnosis of mental health disorders is a challenging problem that often relies on self-reporting by patients about their behavioral patterns and social interactions. Therefore, there is a need for new strategies for diagnosis and daily monitoring of mental health conditions. The recent introduction of body-area networks consisting of a plethora of accurate sensors embedded in smartwatches and smartphones and edge-compatible deep neural networks (DNNs) points toward a possible solution. Such wearable medical sensors (WMSs) enable continuous monitoring of physiological signals in a passive and non-invasive manner. However, disease diagnosis based on WMSs and DNNs, and their deployment on edge devices, such as smartphones, remains a challenging problem. These challenges stem from the difficulty of feature engineering and knowledge distillation from the raw sensor data, as well as the computational and memory constraints of battery-operated edge devices. To this end, we propose a framework called MHDeep that utilizes commercially available WMSs and efficient DNN models to diagnose three important mental health disorders: schizoaffective, major depressive, and bipolar. MHDeep uses eight different categories of data obtained from sensors integrated in a smartwatch and smartphone. These categories include various physiological signals and additional information on motion patterns and environmental variables related to the wearer. MHDeep eliminates the need for manual feature engineering by directly operating on the data streams obtained from participants. Because the amount of data is limited, MHDeep uses a synthetic data generation module to augment real data with synthetic data drawn from the same probability distribution. We use the synthetic dataset to pre-train the weights of the DNN models, thus imposing a prior on the weights. We use a grow-and-prune DNN synthesis approach to learn both architecture and weights during the training process. We use three different data partitions to evaluate the MHDeep models trained with data collected from 74 individuals. We conduct two types of evaluations: at the data instance level and at the patient level. MHDeep achieves an average test accuracy, across the three data partitions, of 90.4%, 87.3%, and 82.4%, respectively, for classifications between healthy and schizoaffective disorder instances, healthy and major depressive disorder instances, and healthy and bipolar disorder instances. At the patient level, MHDeep DNN models achieve an accuracy of 100%, 100%, and 90.0% for the three mental health disorders, respectively, based on inference that uses 40, 16, and 22 minutes of sensor data collection from each patient.","mental health disorders, health monitoring, Disease diagnosis, wearable medical sensors, synthetic data generation, neural networks"
Conference Paper,"Yan J,Geng Y,Xu H,Yu Y,Tan S,He D",Research on Named Entity Recognition in Chinese EMR Based on Semi-Supervised Learning with Dual Selected Strategy,Association for Computing Machinery,2021,https://doi.org/10.1145/3446132.3446407;http://dx.doi.org/10.1145/3446132.3446407,"With the construction of the electronic medical record system, medical record data begins to accumulate, and how to extract essential information from these resources has become a concern. And named entity recognition(NER) is the first step. With the help of doctors, we built a small Chinese electronic medical record annotation corpus. But the NER supervision method requires a large amount of manually labeled corpus. So to reduce the cost of it and make better use of the unlabeled corpus, this paper proposes a semi-supervised Chinese electronic medical record NER model based on ALBERT-BiLSTM-CRF which named CEMRNER. The model uses a Bidirectional Long Short Term Memory network (BiLSTM) and a Conditional Random Field model (CRF) to train the data and introduces the pre-training language model ALBERT to solve the problem of Chinese representation. At the same time, we propose a dual selected strategy to select the high confidence samples and expand the training set. The dual strategy can ensure the accuracy i automatically labeled data, and reduce the error iteration in semi-supervised learning. The experiment and analysis show that compared with other models, this method is more accurate and comprehensive. The precision, recall rate, and F1Score are 85.45%, 87.81%, and 86.61%, respectively. The paper proves that using a semi-supervised method and pre-training ALBERT can improve the accuracy of recognition under the condition of less labeled data.","BiLSTM, semi-supervised learning, CRF, named entity recognition, ALBERT, dual selected strategy"
Conference Paper,"Ma J,Zhang Q,Lou J,Xiong L,Ho JC",Communication Efficient Federated Generalized Tensor Factorization for Collaborative Health Data Analytics,Association for Computing Machinery,2021,https://doi.org/10.1145/3442381.3449832;http://dx.doi.org/10.1145/3442381.3449832,"Modern healthcare systems knitted by a web of entities (e.g., hospitals, clinics, pharmacy companies) are collecting a huge volume of healthcare data from a large number of individuals with various medical procedures, medications, diagnosis, and lab tests. To extract meaningful medical concepts (i.e., phenotypes) from such higher-arity relational healthcare data, tensor factorization has been proven to be an effective approach and received increasing research attention, due to their intrinsic capability to represent the high-dimensional data. Recently, federated learning offers a privacy-preserving paradigm for collaborative learning among different entities, which seemingly provides an ideal potential to further enhance the tensor factorization-based collaborative phenotyping to handle sensitive personal health data. However, existing attempts to federated tensor factorization come with various limitations, including restrictions to the classic tensor factorization, high communication cost and reduced accuracy. We propose a communication efficient federated generalized tensor factorization, which is flexible enough to choose from a variate of losses to best suit different types of data in practice. We design a three-level communication reduction strategy tailored to the generalized tensor factorization, which is able to reduce the uplink communication cost up to 99.90%. In addition, we theoretically prove that our algorithm does not compromise convergence speed despite the aggressive communication compression. Extensive experiments on two real-world electronics health record datasets demonstrate the efficiency improvements in terms of computation and communication cost.","Electronic Health Records (EHR), Computational Phenotyping, Tensor Factorization, Federated Learning"
Conference Paper,"Corlu CG,Maleyeff J,Wang J,Yip K,Farris J",Real-Time Nurse Dispatching Using Dynamic Priority Decision Framework,IEEE Press,2021,Not Found,"The increase in medical treatment complexity can cause experienced nurses to have difficulty determining priorities among patient needs. Electronic health record systems will enable automated decision support to assist medical professionals in making these determinations. This article details a framework that uses a discrete-event simulation, programmed in Python, to determine how priorities should be assigned in real time based on characteristics of patient needs. The severity of patient needs is dynamic because severity increases over time until the need is addressed. The simulation framework is applied to a cardiac care unit with 14 patients, who collectively have 125 needs. Four different priority schemes are evaluated and their effectiveness compared under the assumption of an 8 or 9 nurse capacity. The results illustrate the importance of modeling the dispatching of nurses according to severity because, although fewer nurses result in longer average queue times, they can handle higher-severity needs effectively.",Not Found
Conference Paper,"Thakkar D,Ismail A,Kumar P,Hanna A,Sambasivan N,Kumar N",When is Machine Learning Data Good?: Valuing in Public Health Datafication,Association for Computing Machinery,2022,https://doi.org/10.1145/3491102.3501868;http://dx.doi.org/10.1145/3491102.3501868,"Data-driven approaches that form the foundation of advancements in machine learning (ML) are powered in large part by human infrastructures that enable the collection of large datasets. We study the movement of data through multiple stages of data processing in the context of public health in India, examining the data work performed by frontline health workers, data stewards, and ML developers. We conducted interviews with these stakeholders to understand their varied perspectives on valuing data across stages, working with data to attain this value, and challenges arising throughout. We discuss the tensions in valuing and how they might be addressed, as we emphasize the need for improved transparency and accountability when data are transformed from one stage of processing to the next.","Data work, public health, India, valuation"
Conference Paper,"Tsvyatkova D,Storni C",Adapting Design Probes to Explore Health Management Practices in Pediatric Type 1 Diabetes,Association for Computing Machinery,2014,https://doi.org/10.1145/2593968.2610471;http://dx.doi.org/10.1145/2593968.2610471,"We used Design Probes (DP) as a communication tool supporting designers to learn about users, collecting selfdocumentation data from children and parents about their everyday chronic disease management. DP are also applied as alternative strategies to perform ethnographic study in a domestic environment and to elicit inspirational data for the design of an educational interactive eBook for newly diagnosed children with type 1 diabetes mellitus (T1DM). Eight probe activities were designed for children between the ages of 812 years who have diabetes and their caregivers, which were then distributed to seven families. The main issue discussed in this paper is the adaptation of the DP to the users (children and parents) and the results produced by participants who used them.","children with type 1 diabetes, childcomputer interaction, design probes, participatory design, usercentred design"
Journal Article,"Hu H,Salcic Z,Sun L,Dobbie G,Yu PS,Zhang X",Membership Inference Attacks on Machine Learning: A Survey,Association for Computing Machinery,2022,https://doi.org/10.1145/3523273;http://dx.doi.org/10.1145/3523273,"Machine learning (ML) models have been widely applied to various applications, including image classification, text generation, audio recognition, and graph data analysis. However, recent studies have shown that ML models are vulnerable to membership inference attacks (MIAs), which aim to infer whether a data record was used to train a target model or not. MIAs on ML models can directly lead to a privacy breach. For example, via identifying the fact that a clinical record that has been used to train a model associated with a certain disease, an attacker can infer that the owner of the clinical record has the disease with a high chance. In recent years, MIAs have been shown to be effective on various ML models, e.g., classification models and generative models. Meanwhile, many defense methods have been proposed to mitigate MIAs. Although MIAs on ML models form a newly emerging and rapidly growing research area, there has been no systematic survey on this topic yet. In this article, we conduct the first comprehensive survey on membership inference attacks and defenses. We provide the taxonomies for both attacks and defenses, based on their characterizations, and discuss their pros and cons. Based on the limitations and gaps identified in this survey, we point out several promising future research directions to inspire the researchers who wish to follow this area. This survey not only serves as a reference for the research community but also provides a clear description for researchers outside this research domain. To further help the researchers, we have created an online resource repository, which we will keep updated with future relevant work. Interested readers can find the repository at https://github.com/HongshengHu/membership-inference-machine-learning-literature.","deep leaning, privacy risk, differential privacy, Membership inference attacks"
Conference Paper,"Chhiba L,Mustapha S,Marzak A",Design of a Non-Invasive Blood Glucose Meter Connected to an Android Diabetes Monitoring Application,Association for Computing Machinery,2019,https://doi.org/10.1145/3368756.3369022;http://dx.doi.org/10.1145/3368756.3369022,"In just a few years, diabetes has become an epidemic affecting 422 million people in world. This disease, with which one learns to live throughout one's life, is still frightened today. However, a properly supported diabetic can successfully live with his illness. This work involves the design of a device that allows the measurement of blood glucose in a non-invasive way from saliva. A device consisting of three stages, (sensors, amplifiers, filters), as well as a data acquisition process on the Arduino board and a transmission of these by a Bluetooth module, which will lead us to the implementation of our remote monitoring solution for diabetes, including the Android application performed in order to properly manage this disease and have an ongoing relationship with the attending physician to facilitate diagnosis.","noninvasive, diabetes, biosensor, saliva, glucose monitoring"
Conference Paper,"Pereira V,Matos S,Oliveira JL",Automated ICD-9-CM Medical Coding of Diabetic Patient's Clinical Reports,Association for Computing Machinery,2018,https://doi.org/10.1145/3279996.3280019;http://dx.doi.org/10.1145/3279996.3280019,"The assignment of ICD-9-CM codes to patient's clinical reports is a costly and wearing process manually done by medical personnel, estimated to cost about $25 billion per year in the United States. To develop a system that automates this process has been an ambition of researchers but is still an unsolved problem due to the inherent difficulties in processing unstructured clinical text.This problem is here formulated as a multi-label supervised learning one where the independent variable is the report's text and the dependent the several assigned ICD-9-CM labels. Different variations of two neural network based models, the Bag-of-Tricks and the Convolutional Neural Network (CNN) are investigated. The models are trained on the diabetic patient subset of the freely available MIMIC-III dataset.The results show that a CNN with three parallel convolutional layers achieves F1 scores of 44.51% for five digit codes and 51.73% for three digit, rolled up, codes. Although fully automated coding is not achievable, these results suggest that automated classification could be used to aid clinical staff by selecting the most probable codes.","supervised learning, classification, electronic health records"
Conference Paper,"Shamsuddin R,Wang Y,Prabhakaran B",Exploring Functional Clinical Attributes for Macular Dystrophy Detection,Association for Computing Machinery,2018,https://doi.org/10.1145/3191801.3191813;http://dx.doi.org/10.1145/3191801.3191813,"Macular Dystrophy is a rare, genetic eye disorder, which affects the retina. For example, Stargardt Disease (STGD) is a juvenile form of retina dystrophy that can result in loss of central vision, adversely affecting patients' daily activities. Often to catch the onset of eye diseases, such as STGD, or to track the disease progression, patients can do eye test evaluations at home via smartphone/tablet application. It would be extremely useful for people prone to eye diseases if the test evaluations came with an application such that it acted as an automatic home prediction system to alert users of a developing eye condition.Hence, in this paper, we explore the discriminatory power of five medical attributes that are used to study eye diseases, which are similar to STGD. Using these attributes, we want to examine how to differentiate between eyes that are affected with STGD (diseased) and those that are not. Our main aim is to find the attribute set that is most suitable for the automatic home prediction system. Experiments are also done to identify a suitable classification method for the application. The results we found are interesting and promising.","STGD, contrast detection threshold, contour integration perimetry, visual acuity"
Conference Paper,"Brox E,Hirche J,Evertsen G,Yliräisänen-Seppänen P,Bomark P",User Centric Social Diabetes Game Design for Children,Association for Computing Machinery,2012,https://doi.org/10.1145/2393132.2393196;http://dx.doi.org/10.1145/2393132.2393196,"Children recently diagnosed with diabetes type 1 require lots of information and feel scared, alone and different. Most of the existing educational material is on paper. Games with relevant learning content are mainly small minigames in English. There is a need for more material with a focus on user needs, particularly learning--by-doing material. Peer support is known to be important for this user group. We present a concept for a social learning game that is engaging and fun for diabetic children.","multidisciplinary work, persuasive computing, social game, social computing, serious games, health, diabetes, user centric design"
Conference Paper,"Tandori E,Beh J,Pedell S",It's on the Cards: Designing Technology Instructions for People Living with Dementia,Association for Computing Machinery,2020,https://doi.org/10.1145/3369457.3369502;http://dx.doi.org/10.1145/3369457.3369502,"This paper describes the creation of a set of dementia friendly instruction cards for participants engaged in a technology research project. The cards were designed to provide support after the research project was completed, so that participants could maintain continued and independent use of the technologies left with them. A literature review of guidelines for creating text, instructions and graphics for people with dementia is almost nonexistent. The iterative process of designing and refining easy to understand instructions, given both a lack of guidelines and the significant cognitive challenges presented by dementia, is described. We conclude that the creation of the cards themselves, and the insights we discovered in creating them are of significant value to assisting people in the uptake of technology. With clear, colourful, easily accessible and visually stimulating instructions, these cards act as a bridge between the technologies and their use, greatly enhancing the ability to support people with dementia in technology use.","Dementia, Technical support, Ageing, Technologies, Communication design"
Conference Paper,"Bromuri S,Schumacher MI,Stathis K,Ruiz J",Monitoring Gestational Diabetes Mellitus with Cognitive Agents and Agent Environments,IEEE Computer Society,2011,https://doi.org/10.1109/WI-IAT.2011.37;http://dx.doi.org/10.1109/WI-IAT.2011.37,"This paper presents an agent-based pervasive healthcare system (PHS) to support pregnant women with Gestational Diabetes Mellitus (GDM). Such an infrastructure uses a mobile application to monitor patients affected by GDM, whose parameters are then sent to and analysed by cognitive agents. We utilise a symbolic reasoning approach to formalise the events happening in the system, the entities participating in the interaction and the agent cognitive model for continuous monitoring of GDM. Such a cognitive model is based on deductive treatment adjustment rules to provide doctors with indications about the patient's treatment and on abductive rules to provide a diagnosis of the illness' current state. We evaluate our system by means of medical data to assess the precision of our infrastructure.","Multi-agent Systems, Agent Environments, Pervasive Health, Abduction Logic"
Conference Paper,"Liu JH,Wu CT,Chu TW,Jang,Roger JS",Data-Driven Feature Selection for Long Longitudinal Breadth and High Dimensional Dataset: Empirical Studies of Metabolic Syndrome Prediction,Association for Computing Machinery,2020,https://doi.org/10.1145/3383972.3383992;http://dx.doi.org/10.1145/3383972.3383992,"Diversified research focusing on early prediction of diseases based on small datasets and/or reducing the execution time on computer was published. However, no convincing evidence was showed that the conventional wrapper based feature selection was applicable for processing large-scale high-dimension dataset in an efficient way. In this study, our wrapper based feature selection method is designed to apply to a large-scale dataset with high dimension and long longitudinal breadth for predicting two types of metabolic syndrome diseases. Specifically, according to the components, the method adopts dimensionality reduction and/or feature selection to optimize subsets of features. Subsequently, the selected features will be further identified with statistics provided by clinic experts to exam the significance and accuracy. Accordingly, the method provides a sufficient mean for early diagnosis of metabolic diseases and achieves the efficiency by reducing notable computational time.","early prediction, fatty liver disease, feature selection, Machine learning, dimensionality reduction, hypertension"
Conference Paper,"Wang Z,Wen R,Chen X,Cao S,Huang SL,Qian B,Zheng Y",Online Disease Diagnosis with Inductive Heterogeneous Graph Convolutional Networks,Association for Computing Machinery,2021,https://doi.org/10.1145/3442381.3449795;http://dx.doi.org/10.1145/3442381.3449795,"We propose a Healthcare Graph Convolutional Network (HealGCN) to offer disease self-diagnosis service for online users based on Electronic Healthcare Records (EHRs). Two main challenges are focused in this paper for online disease diagnosis: (1) serving cold-start users via graph convolutional networks and (2) handling scarce clinical description via a symptom retrieval system. To this end, we first organize the EHR data into a heterogeneous graph that is capable of modeling complex interactions among users, symptoms and diseases, and tailor the graph representation learning towards disease diagnosis with an inductive learning paradigm. Then, we build a disease self-diagnosis system with a corresponding EHR Graph-based Symptom Retrieval System (GraphRet) that can search and provide a list of relevant alternative symptoms by tracing the predefined meta-paths. GraphRet helps enrich the seed symptom set through the EHR graph when confronting users with scarce descriptions, hence yield better diagnosis accuracy. At last, we validate the superiority of our model on a large-scale EHR dataset.","disease diagnosis, online healthcare service, graph neural network"
Conference Paper,"Erin B,Abiyev RH",Diagnosis of Common Diseases Using Type-2 Fuzzy System,Association for Computing Machinery,2019,https://doi.org/10.1145/3310986.3311028;http://dx.doi.org/10.1145/3310986.3311028,"High level of expertise is required for human disease diagnosis which is a complicated and difficult process. Each disease is characterised with the set of observable sign and symptoms. Based on these symptoms to understand patient health problems and to make a diagnosis of these diseases with their clear definition is difficult. The diagnosis of the disease is based on knowledge of doctor physicians. Fuzzy logic is one of the best approaches to design knowledge-based system for diagnosis of the diseases. In this paper, the design of a type-2 fuzzy system is performed for diagnosis of the common diseases using proper values of the inputs. The input symptoms and output diseases are defined for construction of the fuzzy rule base. The relationships are presented using type-2 IF-Then rules. Based on the fuzzy rules the design of type-2 fuzzy inference system is performed. The designed system will help the physician to diagnose common diseases such as common cold and flu.","Common disease, Fuzzy system, Diagnosis, Uncertainty"
Conference Paper,"AlThunayan L,AlSahdi N,Syed L",Comparative Analysis of Different Classification Algorithms for Prediction of Diabetes Disease,Association for Computing Machinery,2017,https://doi.org/10.1145/3018896.3036387;http://dx.doi.org/10.1145/3018896.3036387,"Diabetes Mellitus is fast becoming an endemic in the world, especially in developing countries. An efficient prediction methodology is needed to diagnose the diabetes disease, which can be helpful for health care professionals. Data mining techniques have been widely used in healthcare to mine knowledgeable information from medical data. Data mining is the process of analyzing data based on different perspectives and summarizing it into useful information. Data mining techniques are proven forearly prediction of several diseases with higher accuracy and lower error rate and cost. Classification is one of the generally used techniques in medical data mining. In this paper, we intend to explore various data mining techniques to show the comparison of different classification algorithms using Waikato Environment for Knowledge Analysis (WEKA) and analyze the results in order to find the best suitable classification algorithm for prediction of diabetes diseases. Various performance measures metrics such as sensitivity, specificity, accuracy and error rate are used for finding the accuracy of the classifier.","data mining, diabetes, WEKA, classification algorithms"
Conference Paper,Mott R,"Incorporating AR into a Multimodal UI for an Artificial Pancreas: The Interdisciplinary Nature of Integrating Augmented Reality (AR), Sound, and Touch into a User Interface (UI) for Diabetes Patients with Embedded Control Systems for an Artificial Pancreas (AP)",Association for Computing Machinery,2018,https://doi.org/10.1145/3233756.3233932;http://dx.doi.org/10.1145/3233756.3233932,"This paper explores the emerging field of human-embedded medical technology and its accompanying need for innovative user experience (UX) design. Specifically, the paper argues that, in the medium term, augmented reality (AR) can effectively serve as one part of a multimodal user interface (UI) for diabetes patients with embedded control systems for an artificial pancreas (AP). The paper explores what types of cross-disciplinary information UX designers will need in order to incorporate AR into an effective multimodal interface for diabetes patients with an AP. Currently, researchers are developing methods to embed continuous glucose monitors (CGM), model predictive control (MPC) systems, and AP systems into diabetes patients to regulate their blood sugar levels [30]. Ideally, an embedded control in a wearable medical device would remove the need for users to interact with the system because the system would self-regulate. However, once embedded, not only will a physician/technician need to initialize and adjust the system, but, ethically and practically, patients will also need access to the system. In the medium-term future (5-10 years), AR-with its emphasis on cross-disciplinary design needs-shows promise for conveying visual information most effectively to the patient. This paper addresses the interdisciplinary nature of conveying user information for embedded medical devices because it demonstrates the need for UX designers to integrate recent advancements in healthcare research, medical technology, cross-disciplinary design theory (e.g. human factors and effective use theory), and the rapidly changing nature of human-computer interaction (HCI).","embedded medical device, effective use theory, augmented reality (AR), artificial pancreas (AP), user experience (UX), human factors (HF)"
Conference Paper,"Marciniak M,Mykowiecka A",Towards Morphologically Annotated Corpus of Hospital Discharge Reports in Polish,Association for Computational Linguistics,2011,Not Found,The paper discuses problems in annotating a corpus containing Polish clinical data with low level linguistic information. We propose an approach to tokenization and automatic morphologic annotation of data that uses existing programs combined with a set of domain specific rules and vocabulary. Finally we present the results of manual verification of the annotation for a subset of data.,Not Found
Conference Paper,"Momotaz F,Billah SM",Tilt-Explore: Making Tilt Gestures Usable for Low-Vision Smartphone Users,Association for Computing Machinery,2021,https://doi.org/10.1145/3472749.3474813;http://dx.doi.org/10.1145/3472749.3474813,"People with low vision interact with smartphones using assistive technologies like screen magnifiers, which provide built-in touch gestures to pan and zoom onscreen content. These gestures are often cumbersome and require bimanual interaction. Of particular interest is panning gestures, which are issued frequently, which involve 2- or 3-finger dragging. This paper aims to utilize tilt-based interaction as a single-handed alternative to built-in panning gestures. To that end, we first identified our design space from the literature and conducted an exploratory user study with 12 low-vision participants to understand key challenges. Among many findings, the study revealed that built-in panning gestures are error-prone, and most tilt-based interaction techniques are designed for sighted users, which low vision users struggle to use as-is. We addressed these challenges by adapting low-vision users’ interaction behavior and proposed Tilt-Explore, a new screen magnifier mode that enables tilt-to-pan. A second study with 16 low-vision participants revealed that, compared to built-in gestures, the participants were significantly less error-prone; and for lower magnification scale (e.g., <4x), they were significantly more efficient with Tilt-Explore. These findings indicate Tilt-Explore is a promising alternative to built-in panning gestures.","low-vision, tilt-exploration., vision impairments, screen magnifier, motion sensor, IMU, panning, tilting, Smartphone"
Conference Paper,"Mamykina L,Miller AD,Mynatt ED,Greenblatt D",Constructing Identities through Storytelling in Diabetes Management,Association for Computing Machinery,2010,https://doi.org/10.1145/1753326.1753507;http://dx.doi.org/10.1145/1753326.1753507,"The continuing epidemics of diabetes and obesity create much need for information technologies that can help individuals engage in proactive health management. Yet many of these technologies focus on such pragmatic issues as collecting and presenting health information and modifying individuals' behavior. At the same time, researchers in clinical community argue that individuals' perception of their identity has dramatic consequences for their health behaviors. In this paper we discuss results of a deployment study of a mobile health monitoring application. We show how individuals with considerable diabetes experience found a unique way to adopt this health-monitoring application to construct and negotiate their identities as persons with a chronic disease. We argue that viewing health management from identity construction perspective opens new opportunities for research and design in technologies for health.","learning, diabetes, reflection, chronic disease management, ubiquitous computing"
Conference Paper,"Xie Y,Xu S,Guo L,Tian Y",Segmentation-Based Retinal Image Fusion for Hypertension Prediction,Association for Computing Machinery,2022,https://doi.org/10.1145/3507971.3507987;http://dx.doi.org/10.1145/3507971.3507987,"Retinal image vessel segmentation or artery/vein segmentation tasks have been investigated for a long time, and hypertension prediction based on statistical data or body indicators has been learned well. However, the gap between retinal image segmentation and retinal image hypertension prediction still exists. In this paper, we bridge the gap by introducing a model-agnostic cross attention module in segmentation part and a semantic image fusion module in hypertension prediction part thus to form a novel segmentation-based pipeline for hypertension prediction. Specifically, the cross attention module adopts cross multiplication to attend encoder and decoder features, which enhances the artery/vein segmentation ability in uncertain region and border region in retinal image. Then we design a semantic image fusion module to fuse segmented artery/vein vessel image and original image as the classifier input to predict hypertension. The experimental results demonstrate that our model can efficiently predict hypertension, and we achieve 94.87% accuracy, 94.74% specificity, 95.00% sensitivity respectively on 393 retinal images from Kaggle ODiR5k dataset at : https://www.kaggle.com/ocular-disease-recognition-odir5k.","Image fusion module, Hypertension prediction, Cross attention module, Artery and vein segmentation"
Conference Paper,"Ogwo O,Turabieh H,Sheta A,King S",Medical Data Classification Using Binary Brain Storm Optimization Algorithm,Association for Computing Machinery,2020,https://doi.org/10.1145/3388218.3388224;http://dx.doi.org/10.1145/3388218.3388224,"With the growing access to technology in the medical domain, an increased volume of medical data is recorded. The size and complexity of these data make the process of analysis of meaningful discoveries of beneficial patterns more challenging. This problem has attracted numerous researchers around the world. Statistical methods have been employed to handle medical data for diagnosis purposes. Unfortunately, these methods were less capable of dealing with these massive and complex datasets. To solve this problem, we suggest a process to classify medical data which includes feature selection and classification using a number of supervised learning techniques. Binary Brain Storm Optimization (BBSO) is used for feature selection, which is a population search approach that simulates the process of electing the best idea (solution), among others. We simulated six different classifiers: Naive-Bayes, K-Nearest Neighbor, Support Vector Machine, Linear Discriminant Analysis, Decision Tree and Random Forest. Five datasets adopted from the UCI Machine Learning Repository, (Breast Cancer, Diabetes, Heart Disease, Chronic Kidney, and SPECT), are employed as a benchmark test data. The performance of BBSO is evaluated using accuracy on the datasets using the various classifiers. Experimental results show that the proposed approach improves the classification performance for better medical diagnosis.","feature selection, classification, medical diagnosis"
Conference Paper,"Zhang B,Lu L,Hou J","A Comparison of Logistic Regression, Random Forest Models in Predicting the Risk of Diabetes",Association for Computing Machinery,2019,https://doi.org/10.1145/3364836.3364882;http://dx.doi.org/10.1145/3364836.3364882,"Diabetes mellitus has become one of the most harmful chronic diseases in the world, and China is the largest country of diabetes mellitus in the world. In recent years, the prevalence of diabetes mellitus has increased year by year, which seriously threatens human health. Diabetes is a chronic, lifelong disease. Therefore, early preventive measures for high-risk diabetic patients are an effective way to control the prevalence of diabetes. As the preferred tool for screening high-risk population, diabetes risk prediction model can help doctors and patients to identify the risk of diabetes early and take timely action. Preventing or delaying diabetes mellitus and its complications, however, there are few predictive models for the Chinese population at present. In response to the above problems, this study collected a medical examination data set from September 2014 to August 2018 in a third-tier hospital in Sichuan Province. A total of 22175 samples were collected. The variables included gender, age, high density lipoprotein, low density lipoprotein, total cholesterol, history of hypertension, smoking, alcohol consumption, BMI and triglyceride. The prediction model of diabetes mellitus was established based on Logistic regression and random forest. The prediction effect of the model was compared by calculating the area under ROC curve, sensitivity and accuracy. At the same time, the cross-validation method is used to improve the accuracy of model prediction and solve the problem of over-fitting.","Prediction mode, Logistic regression, Diabetes mellitus, Random forest"
Conference Paper,Kyfonidis C,Tangible Educational Toys for Children with Type-1 Diabetes,Association for Computing Machinery,2017,https://doi.org/10.1145/3027063.3027139;http://dx.doi.org/10.1145/3027063.3027139,"The aim of this research is to (i) provide diabetes educators with an interactive tool for age-appropriate, fun and engaging diabetes education, (ii) inform the research community about the effectiveness of tangible toys for health education and most importantly (iii) empower children with type-1 diabetes to have a more active role in the management of their condition and potentially a better quality of life. This paper presents the stakeholder centred design of tangible educational toys for children, aged 3 to 8 years old, with type-1 diabetes. These toys were co-designed with the help of diabetes professionals and are based an initial requirements gathering and scoping phase with all the diabetes stakeholders (clinicians, parents, children and policy makers). The paper concludes by discussing how the system is being built and how it will be evaluated in the clinic context.","children, diabetes education, tangible interface"
Conference Paper,"Ye M,Cui S,Wang Y,Luo J,Xiao C,Ma F",MedRetriever: Target-Driven Interpretable Health Risk Prediction via Retrieving Unstructured Medical Text,Association for Computing Machinery,2021,https://doi.org/10.1145/3459637.3482273;http://dx.doi.org/10.1145/3459637.3482273,"The broad adoption of electronic health record (EHR) systems and the advances of deep learning technology have motivated the development of health risk prediction models, which mainly depend on the expressiveness and temporal modeling capacity of deep neural networks (DNNs) to improve prediction performance. Some further augment the prediction by using external knowledge, however, a great deal of EHR information inevitably loses during the knowledge mapping. In addition, prediction made by existing models usually lacks reliable interpretation, which undermines their reliability in guiding clinical decision-making. To solve these challenges, we propose MedRetriever, an effective and flexible framework that leverages unstructured medical text collected from authoritative websites to augment health risk prediction as well as to provide understandable interpretation. Besides, MedRetriever explicitly takes the target disease documents into consideration, which provide key guidance for the model to learn in a target-driven direction, i.e., from the target disease to the input EHR. To specify, MedRetriever can flexibly choose its backbone from major predictive models to learn the EHR embedding for each visit. After that, the EHR embedding and features of target disease documents are aggregated into a query by self-attention to retrieve highly relevant text segments from the medical text pool, which is stored in the dynamically updated text memory. Finally, the comprehensive EHR embedding and the text memory are used for prediction and interpretation. We evaluate MedRetriever against nine state-of-the-art approaches across three real-world EHR datasets, which consistently achieves the best performance in AUC and recall metrics and outperforms the best baseline by at least 4.8% in recall on three test datasets. Furthermore, we conduct case studies to show the easy-to-understand interpretation by MedRetriever.","data mining, electronic health records, external knowledge, health risk prediction"
Conference Paper,"Zhang J,Yang X,Meng H,Lin Z,Xu Y,Cui L",A Survey on Knowledge Enhanced EHR Data Mining,Association for Computing Machinery,2022,https://doi.org/10.1145/3503181.3503202;http://dx.doi.org/10.1145/3503181.3503202,"EHR contains detailed information about a large number of patients. In the past ten years, EHR-related research has involved various fields, and research in various fields is inseparable from the acquisition of knowledge in EHR. The rapid development of various fields in recent years has brought new challenges to the acquisition of knowledge in EHR. At the same time, the knowledge enhancement technology that has emerged in recent years has effectively improved this problem. Therefore, more and more researches personnel applied knowledge enhancement technology to EHR. In this article, we summarized the literature in this area. We first summarized the knowledge types of EHR, and then made a sub-statement on knowledge extraction and modeling. Next, the correct representation method of knowledge is given, and finally, the specific application in each field is summarized. We hope this article can continue to promote the development of knowledge enhancement technology in EHR.","EHR, Knowledge Graph, Data Mining, Knowledge Enhancement"
Conference Paper,"Wang P,Shi T,Reddy CK",Text-to-SQL Generation for Question Answering on Electronic Medical Records,Association for Computing Machinery,2020,https://doi.org/10.1145/3366423.3380120;http://dx.doi.org/10.1145/3366423.3380120,"Electronic medical records (EMR) contain comprehensive patient information and are typically stored in a relational database with multiple tables. Effective and efficient patient information retrieval from EMR data is a challenging task for medical experts. Question-to-SQL generation methods tackle this problem by first predicting the SQL query for a given question about a database, and then, executing the query on the database. However, most of the existing approaches have not been adapted to the healthcare domain due to a lack of healthcare Question-to-SQL dataset for learning models specific to this domain. In addition, wide use of the abbreviation of terminologies and possible typos in questions introduce additional challenges for accurately generating the corresponding SQL queries. In this paper, we tackle these challenges by developing a deep learning based TRanslate-Edit Model for Question-to-SQL (TREQS) generation, which adapts the widely used sequence-to-sequence model to directly generate the SQL query for a given question, and further performs the required edits using an attentive-copying mechanism and task-specific look-up tables. Based on the widely used publicly available electronic medical database, we create a new large-scale Question-SQL pair dataset, named MIMICSQL, in order to perform the Question-to-SQL generation task in healthcare domain. An extensive set of experiments are conducted to evaluate the performance of our proposed model on MIMICSQL. Both quantitative and qualitative experimental results indicate the flexibility and efficiency of our proposed method in predicting condition values and its robustness to random questions with abbreviations and typos.","SQL query., Sequence-to-sequence model, attention mechanism, pointer-generator network, electronic medical records"
Journal Article,"Mitchell EG,Maimone R,Cassells A,Tobin JN,Davidson P,Smaldone AM,Mamykina L",Automated vs. Human Health Coaching: Exploring Participant and Practitioner Experiences,Association for Computing Machinery,2021,https://doi.org/10.1145/3449173;http://dx.doi.org/10.1145/3449173,"Health coaching can be an effective intervention to support self-management of chronic conditions like diabetes, but there are not enough coaching practitioners to reach the growing population in need of support. Conversational technology, like chatbots, presents an opportunity to extend health coaching support to broader and more diverse populations. However, some have suggested that the human element is essential to health coaching and cannot be replicated with technology. In this research, we examine automated health coaching using a theory-grounded, wizard-of-oz chatbot, in comparison with text-based virtual coaching from human practitioners who start with the same protocol as the chatbot but have the freedom to embellish and adjust as needed. We found that even a scripted chatbot can create a coach-like experience for participants. While human coaches displayed advantages expressing empathy and using probing questions to tailor their support, they also encountered tremendous barriers and frustrations adapting to text-based virtual coaching. The chatbot coach had advantages in being persistent, as well as more consistently giving choices and options to foster client autonomy. We discuss implications for the design of virtual health coaching interventions.","text messaging, type 2 diabetes, health coaching, chatbots, self-management, conversational agents, wizard-of-oz"
Journal Article,"Dai X,Jordan MI",Learning Strategies in Decentralized Matching Markets under Uncertain Preferences,JMLR.org,2022,Not Found,"We study the problem of decision-making in the setting of a scarcity of shared resources when the preferences of agents are unknown a priori and must be learned from data. Taking the two-sided matching market as a running example, we focus on the decentralized setting, where agents do not share their learned preferences with a central authority. Our approach is based on the representation of preferences in a reproducing kernel Hilbert space, and a learning algorithm for preferences that accounts for uncertainty due to the competition among the agents in the market. Under regularity conditions, we show that our estimator of preferences converges at a minimax optimal rate. Given this result, we derive optimal strategies that maximize agents' expected payoffs and we calibrate the uncertain state by taking opportunity costs into account. We also derive an incentive-compatibility property and show that the outcome from the learned strategies has a stability property. Finally, we prove a fairness property that asserts that there exists no justified envy according to the learned strategies.","reproducing kernel Hilbert spaces, uncertain preferences, stability, rairness, matching markets"
Conference Paper,"Chen J,Xu H,Liu M,Zhang L",Bayesian Matrix Completion for Planning Diabetes Treatment Based on Urban Cases,Association for Computing Machinery,2022,https://doi.org/10.1145/3546632.3546886;http://dx.doi.org/10.1145/3546632.3546886,"For patients in the early stages of diabetes, it is crucial for patients and doctors to make treatment decisions to prevent the condition from getting worse and developing complications such as diabetic eyes and feet. Both undertreatment and overtreatment can do harm to the patient. In this paper, the probability of taking each treatment option for different symptoms is complemented by a database of existing successful cases of diabetic treatment options to recommend an appropriate treatment for patients with specific symptoms. The matrix completion process adopts the assumption of high rank and completes the matrix based on the unique properties of Bayesian matrices. The results demonstrate the practicality and effectiveness of this algorithm.","diabetes treatment, matrix completion, Bayesian matrix, urban planning"
Conference Paper,"Mohd Yusof M,Mohamed R,Wahid N",Benchmark of Feature Selection Techniques with Machine Learning Algorithms for Cancer Datasets,Association for Computing Machinery,2016,https://doi.org/10.1145/2952744.2952753;http://dx.doi.org/10.1145/2952744.2952753,"Classification is a technique based on machine learning used to classify each item in a set of data into a set of predefined classes or group. It is widely used in medical field to classify the medical data. In producing better classification result, feature selection been applied in many of the classification work as part of preprocessing step, where a subset of feature been used rather than the whole features from particular dataset. Feature selection eliminates irrelevant attribute to obtain high quality features that may contribute in enhancing classification process and producing better classification results. This study is conducted with the intention to focus on feature selection techniques as a method that helps classifiers producing better classification performance with the most significant features. During the experiments, a comparison between benchmark feature selection methods based on three cancer datasets and four well recognized machine learning algorithms has been made. This paper then analyzes the performance of all classifiers with and without feature selection in term of ROC and F-Measure. The study found that although there are no single feature selection method can satisfy all datasets, the results still effectively support the fact that feature selection helps in increasing the classifier performance with existence of minimum number of features.","feature selection, data mining, classification"
Conference Paper,"Webster M,Foster E,Comber R,Bowen S,Cheetham T,Balaam M",Understanding the Lived Experience of Adolescents with Type 1 Diabetes: Opportunities for Design,Association for Computing Machinery,2015,https://doi.org/10.1145/2771839.2771854;http://dx.doi.org/10.1145/2771839.2771854,"Type 1 diabetes affects approximately 1 in every 500 children in the UK. Although it is a lifelong condition, there are few if any overt manifestations, which can make it more difficult to meet people with the same condition. To avoid the risk of health complications, an emphasis is placed on a routine of self-management behaviours. However, factors such as the desire to 'fit in' with the peer group may impede adherence and thus increase the probability of diminished health later in life. Creating appropriate peer support networks may be valuable in aiding a young person with diabetes to attend to their condition through interactions with otherwise unseen peers. Through a series of design workshops the context of living with type 1 diabetes and the value of peer support are explored from the perspective of an adolescent. Four types of support are reported: informational; emotional; tangible; and belonging/companionship, and design opportunities explored.","type 1 diabetes, adolescents, peer support"
Conference Paper,"Sharma A,Agrawal P,Madaan V,Goyal S",Prediction on Diabetes Patient's Hospital Readmission Rates,Association for Computing Machinery,2019,https://doi.org/10.1145/3339311.3339349;http://dx.doi.org/10.1145/3339311.3339349,"Hospital Readmission is considered as an effective measurement of service and care provided within the hospital. Emergency readmission to hospital is frequently used as a measure of the quality of a hospital because a high proportion of readmissions should be preventable if the preceding care is adequate. The objective of this study to develop a model to predict 30-day hospital readmission. We have data of 1-lac diabetes patients with 50 features. We used machine learning algorithms: Logistic Regression, Decision Tree, Random Forest, Adaboost and XGBoost for prediction. We achieved the highest accuracy 94% using Random forest among all other algorithms. The results from this study are encouraging and can help healthcare providers to improve their services.","patient, diabetes, healthcare, predictive modeling, hospital readmission"
Conference Paper,"Rawte V,Huang H,Morrison M,Wu J,Peterson T,Munasinghe T",Diabetes Tracker: An Information System to Assist and Track Nutritional Information,Association for Computing Machinery,2021,https://doi.org/10.1145/3462741.3466653;http://dx.doi.org/10.1145/3462741.3466653,"Chronic disease such as diabetes has become a genuine health concern in people’s lives. Millions of people are already diagnosed with it, and this number is only expected to continue growing along with the price of any kind of aid that can be provided for this disease. This makes being able to offer any kind of assistance to those that are suffering through this regardless of economic status that much more important. This paper will discuss a prototype information system being built to provide remote healthcare via informative assistance to anyone with diabetes. To reach as much of an audience as possible, this system will be implemented on both web and mobile application-based platforms. We intend to extend this information system can provide self-health management advice for users depending on any related information to them, their condition, and the information they enter, such as their diet intake and current body condition. At this stage, we are focusing on making an easy-to-use and understand application that does not include complicated warning systems and notifications. In the future, we intend to add carefully evaluated functionalities that are user-friendly for general users who are not tech-savvy. Thus, our objective for this work is two-fold. Firstly, we plan to implement successful web and mobile-based applications that are easy and helpful to use, providing relief to those who want and need it. Secondly, we hope to advance our research and assist others in the research community and inspire others trying to solve the same problem.","information system, diabetes, nutrition, semantics, user-interface, ontology, semiotics"
Conference Paper,"Brailsford SC,Carter MW,Jacobson SH",Five Decades of Healthcare Simulation,IEEE Press,2017,Not Found,"In this paper we have not attempted to produce any kind of systematic review of simulation in healthcare to compete with the dozen (at least) excellent and comprehensive survey papers on this topic that already exist. We begin with a glance back at the early days of Wintersim, but then proceed, in line with the theme of this special track, to reflect on general developments in healthcare simulation over the years from our own personal perspectives. We include some memories and reflections by several pioneers in this area, both academics and healthcare practitioners, on both sides of the Atlantic. We also asked four current simulation modelers, who all specialize in healthcare applications but from very diverse perspectives, to reflect on their experiences. We endeavor to identify some common or recurring themes across the years, and end with a glimpse into the future.",Not Found
Conference Paper,"Bhatia RS,Graystone A,Davies RA,McClinton S,Morin J,Davies RF",Extracting Information for Generating a Diabetes Report Card from Free Text in Physicians Notes,Association for Computational Linguistics,2010,Not Found,"Achieving guideline-based targets in patients with diabetes is crucial for improving clinical outcomes and preventing long-term complications. Using electronic heath records (EHRs) to identify high-risk patients for further intervention by screening large populations is limited because many EHRs store clinical information as dictated and transcribed free text notes that are not amenable to statistical analysis. This paper presents the process of extracting elements needed for generating a diabetes report card from free text notes written in English. Numerical measurements, representing lab values and physical examinations results are extracted from free text documents and then stored in a structured database. Extracting diagnosis information and medication lists are work in progress. The complete dataset for this project is comprised of 81,932 documents from 30,459 patients collected over a period of 5 years. The patient population is considered high risk for diabetes as they have existing cardiovascular complications. Experimental results validate our method, demonstrating high precision (88.8--100%).",Not Found
Conference Paper,"Karuppanan K,Vairasundaram AS,Sigamani M",A Comprehensive Machine Learning Approach to Prognose Pulmonary Disease from Home,Association for Computing Machinery,2012,https://doi.org/10.1145/2345396.2345482;http://dx.doi.org/10.1145/2345396.2345482,"This paper proposes a machine learning based prognosis for rehabilitating the COPD patients to be monitored from home in real time. Wearable sensor Technology (WST) is utilized to collect the physiological status of the pulmonary patient from home dynamically and communicated to the healthcare centre. The proposed approach applies a comprehensive predictive model employing a time series forecasting using condensed polynomial neural network with swarm intelligence. Discrete particle swarm optimization (DPSO) filters out the relevant neurons and continuous particle swarm optimization (CPSO) reduces the computational overheads. The time series prediction is further strengthened by using multimodal genetic algorithm. Control measures such as sensitivity, specificity and reliability are applied meticulously to validate the predicted state of the patient.","condensed polynomial neural network, time series prediction, fuzzy c-means, swarm intelligence, artificial intelligence, genetic algorithm"
Conference Paper,"Bai J,Li B,Nabavi S",Semi-Supervised Classification of Disease Prognosis Using CR Images with Clinical Data Structured Graph,Association for Computing Machinery,2022,https://doi.org/10.1145/3535508.3545548;http://dx.doi.org/10.1145/3535508.3545548,"Fast growing global connectivity and urbanisation increases the risk of spreading worldwide disease. The worldwide SARS-COV-2 disease causes healthcare system strained, especially for the intensive care units. Therefore, prognostic of patients' need for intensive care units is priority at the hospital admission stage for efficient resource allocation. In the early hospitalization, patient chest radiography and clinical data are always collected to diagnose. Hence, we proposed a clinical data structured graph Markov neural network embedding with computed radiography exam features (CGMNN) to predict the intensive care units demand for COVID patients. The study utilized 1,342 patients' chest computed radiography with clinical data from a public dataset. The proposed CGMNN outperforms baseline models with an accuracy of 0.82, a sensitivity of 0.82, a precision of 0.81, and an F1 score of 0.76.","deep learning, graph markov neural network, COVID, multimodal"
Conference Paper,Pillay N,Transfer Learning in Evolutionary Spaces,Association for Computing Machinery,2022,https://doi.org/10.1145/3520304.3533632;http://dx.doi.org/10.1145/3520304.3533632,Not Found,Not Found
Journal Article,"Bhoi S,Lee ML,Hsu W,Fang HS,Tan NC",Personalizing Medication Recommendation with a Graph-Based Approach,Association for Computing Machinery,2021,https://doi.org/10.1145/3488668;http://dx.doi.org/10.1145/3488668,"The broad adoption of electronic health records (EHRs) has led to vast amounts of data being accumulated on a patient’s history, diagnosis, prescriptions, and lab tests. Advances in recommender technologies have the potential to utilize this information to help doctors personalize the prescribed medications. However, existing medication recommendation systems have yet to make use of all these information sources in a seamless manner, and they do not provide a justification on why a particular medication is recommended. In this work, we design a two-stage personalized medication recommender system called PREMIER that incorporates information from the EHR. We utilize the various weights in the system to compute the contributions from the information sources for the recommended medications. Our system models the drug interaction from an external drug database and the drug co-occurrence from the EHR as graphs. Experiment results on MIMIC-III and a proprietary outpatient dataset show that PREMIER outperforms state-of-the-art medication recommendation systems while achieving the best tradeoff between accuracy and drug-drug interaction. Case studies demonstrate that the justifications provided by PREMIER are appropriate and aligned to clinical practices.","attention-based recommender system, Electronic health records"
Conference Paper,"Río NG,González-González CS,Martín-González R,Navarro-Adelantado V,Toledo-Delgado P,Marrero-Gordillo N,Barrios-Fleitas YC,Armas-Ramos H,Gacía-Peñalvo F",Treatment of Children Obesity and Diabetes through Gamification: A Case of Study,Association for Computing Machinery,2019,https://doi.org/10.1145/3362789.3362935;http://dx.doi.org/10.1145/3362789.3362935,"Childhood obesity is nowadays a global epidemic. This illness sometimes comes with another associated problem, like Diabetes type II. In this paper we present a case of study about the results of the application of a gamified educational program. A 3-year longitudinal and prospective study was conducted a patient with obesity and diabetes. Different assessments regarding the health state of the patient have been developed (family background, physical/medical, emotional state and physical activity). Using Positive outcomes have been obtained in their medical registers and also, in their health habits. Thus, the application of gamification strategies in the educational program has positive impact in the health.","Obesity, Gamification, Diabetes, Technology"
Conference Paper,"Mahmoud N,Elbeh H",IRS-T2D: Individualize Recommendation System for Type2 Diabetes Medication Based on Ontology and SWRL,Association for Computing Machinery,2016,https://doi.org/10.1145/2908446.2908495;http://dx.doi.org/10.1145/2908446.2908495,"Type 2 diabetes is a chronic and progressive disease with a large number of management strategies and treatment options. Doctors face a problem to concern many patients with different disease factors and many anti-diabetics drugs options to prescript treatment. Various researches have been considered the treatment of type 2 diabetes, but the individualization of the treatment that effectively control diabetes and avoids its complication has not been considered. In this paper, we present IRS-T2D, a recommendation system for individualizing the treatment of type 2 diabetes that utilized ontology and SWRL. The official documents management of type 2 diabetes were used as criteria and adapted to build ontologies. Thus, we built two OWL ontologies one for patient profiles and one for anti-diabetic drugs. The medication constraints were represented by Semantic Web Rule Language (SWRL). Finally, OWL/SWRL knowledge base is transformed to Jess reasoning engine format to build the IRS-T2D system.","Type 2 Diabetes Mellitus (T2DM), OWL, Ontology, Jess, Recommender System, SWRL"
Conference Paper,"Ko YJ,Putkonen A,Aydin AS,Feiz S,Wang Y,Ashok V,Ramakrishnan IV,Oulasvirta A,Bi X",Modeling Gliding-Based Target Selection for Blind Touchscreen Users,Association for Computing Machinery,2021,https://doi.org/10.1145/3447526.3472022;http://dx.doi.org/10.1145/3447526.3472022,"Gliding a finger on touchscreen to reach a target, that is, touch exploration, is a common selection method of blind screen-reader users. This paper investigates their gliding behavior and presents a model for their motor performance. We discovered that the gliding trajectories of blind people are a mixture of two strategies: 1) ballistic movements with iterative corrections relying on non-visual feedback, and 2) multiple sub-movements separated by stops, and concatenated until the target is reached. Based on this finding, we propose the mixture pointing model, a model that relates movement time to distance and width of the target. The model outperforms extant models, improving R2 from 0.65 for Fitts’ law to 0.76, and is superior in cross-validation and information criteria. The model advances understanding of gliding-based target selection and serves as a tool for designing interface layouts for screen-reader based touch exploration.","gliding-based target selection, pointing, accessibility"
Conference Paper,"Jain V,Agarwal P",Symptomatic Diagnosis and Prognosis of Psychiatric Disorders through Personal Gadgets,Association for Computing Machinery,2017,https://doi.org/10.1145/3027063.3048417;http://dx.doi.org/10.1145/3027063.3048417,"Mental disorder has been shrouded as a stigma and disregarded as a secondary issue to physical health. It has become a major contributor to morbidity, disability and at times, fatality. Through our research, we show that the data generated through our daily interaction with technology has consistent patterns to identify symptoms in prodromal phase of degrading mental health. We propose a methodological data driven system that will help to raise an early alarm on the onset of symptoms of potential psychiatric disorders. The system collects the user's data from different human-computer interfaces to create a fine-grain electronic health portfolio, which can assist doctors in differential diagnosis as well as prognosis.","design technique, data collection and processing, mental health symptoms"
Conference Paper,"Sethukkarasi R,Keerthika U,Kannan A",A Self Learning Rough Fuzzy Neural Network Classifier for Mining Temporal Patterns,Association for Computing Machinery,2012,https://doi.org/10.1145/2345396.2345415;http://dx.doi.org/10.1145/2345396.2345415,"This paper proposes a new approach that integrates neural networks with the fuzzy rough set to build a Rough Fuzzy Neural Network Classifier (RFNNC) in order to mine temporal patterns in clinical databases. The lower approximation hypothesis and fuzzy decision table with the fuzzy features are used to acquire the fuzzy decision classes for deciding on the attributes. By contemplating a subset of attributes, comprising of the temporal intervals, the lower approximations are devised in this work. Moreover the basic sets are attained from lower approximations are sorted into the decision classes. The discernibility of the decision classes is designed to delineate the temporal consistency degree between the objects of the sets, from which the reducts are acquired. Next, the attribute subset from the reducts is used for training the fuzzy neural network to infer fuzzy rules. The induced rules will result with temporal patterns for classification. The fuzzy neural network has completely used the competence of fuzzy rough set theory to condense huge quantity of superfluous data. The effectiveness of this method is compared with other classifiers such as fuzzy rule based classifier to evaluate the accuracy of the proposed fuzzy neural network classifier. Experiments have been performed on the diabetic dataset and the simulation results induced proves that the proposed fuzzy neural network classifier on medical diabetic dataset stays as a corroboration for predicting the severity of the disease and exactness in decision support system.","neural networks, lower approximations, fuzzy rough sets, fuzzy neural network, temporal patterns"
Journal Article,"Sharma S,Mandal PK",A Comprehensive Report on Machine Learning-Based Early Detection of Alzheimer's Disease Using Multi-Modal Neuroimaging Data,Association for Computing Machinery,2022,https://doi.org/10.1145/3492865;http://dx.doi.org/10.1145/3492865,"Alzheimer's Disease (AD) is a devastating neurodegenerative brain disorder with no cure. An early identification helps patients with AD sustain a normal living. We have outlined machine learning (ML) methodologies with different schemes of feature extraction to synergize complementary and correlated characteristics of data acquired from multiple modalities of neuroimaging. A variety of feature selection, scaling, and fusion methodologies along with confronted challenges are elaborated for designing an ML-based AD diagnosis system. Additionally, thematic analysis has been provided to compare the ML workflow for possible diagnostic solutions. This comprehensive report adds value to the further advancement of computer-aided early diagnosis system based on multi-modal neuroimaging data from patients with AD.","early detection, machine learning algorithms, feature scaling, multiple modal imaging, feature selection, Alzheimer disease, feature fusion"
Journal Article,"Gao Y,Chan RH,Chow TW,Zhang L,Bonilla S,Pang CP,Zhang M,Leung YF",A High-Throughput Zebrafish Screening Method for Visual Mutants by Light-Induced Locomotor Response,IEEE Computer Society Press,2014,https://doi.org/10.1109/TCBB.2014.2306829;http://dx.doi.org/10.1109/TCBB.2014.2306829,"Normal and visually-impaired zebrafish larvae have differentiable light-induced locomotor response (LLR), which is composed of visual and non-visual components. It is recently demonstrated that differences in the acute phase of the LLR, also known as the visual motor response (VMR), can be utilized to evaluate new eye drugs. However, most of the previous studies focused on the average LLR activity of a particular genotype, which left information that could address differences in individual zebrafish development unattended. In this study, machine learning techniques were employed to distinguish not only zebrafish larvae of different genotypes, but also different batches, based on their response to light stimuli. This approach allows us to perform efficient high-throughput zebrafish screening with relatively simple preparations. Following the general machine learning framework, some discriminative features were first extracted from the behavioral data. Both unsupervised and supervised learning algorithms were implemented for the classification of zebrafish of different genotypes and batches. The accuracy of the classification in genotype was over 80 percent and could achieve up to 95 percent in some cases. The results obtained shed light on the potential of using machine learning techniques for analyzing behavioral data of zebrafish, which may enhance the reliability of high-throughput drug screening.","zebrafish, machine learning, light-induced locomotor response, high-throughput drug screening, classification"
Conference Paper,"Gao F,Yuan K,Gu J,Liu Y",MRIGAT: Many-to-Many Recommendation Using Interaction Based Knowledge Graph Attention,Association for Computing Machinery,2022,https://doi.org/10.1145/3570773.3570888;http://dx.doi.org/10.1145/3570773.3570888,"Recommendation systems combining Graph Neural Networks and Knowledge Graphs have been successfully applied in various domains. However, most existing approaches only consider one-to-one or one-to-many user-item interactions and cannot cater to many-to-many recommendation scenarios, such as providing prescriptions based on clinical diagnosis and medical history. Providing such a recommendation requires considering the implicit interaction within input user features as well as output candidates. In this paper, we propose a two-stage knowledge graph attention aggregation mechanism that helps recommend drug combinations for a patient based on his conditions. First, a disease-drug interaction graph is constructed and integrated with the medical domain knowledge, forming a collaborative knowledge graph. Secondly, an intra-feature attention aggregation is performed to obtain the representations of diseases and drugs based on drug-drug and disease-disease interactions, respectively. Thirdly, an inter-feature attention aggregation is performed using the disease-drug interaction to better represent a user's condition. Finally, the user's condition representation is concatenated with other user features to generate the final user representation for the prescription recommendation. Experiments with realistic datasets show that our approach can outperform existing recommendation systems by 4.3% and 6.1% in precision and recall, respectively.","graph neural network, many-to-many recommendation, attention, knowledge graph"
Conference Paper,"Yao HR,Chang C,Frieder O,Huang W,Lee TS",Multiple Graph Kernel Fusion Prediction of Drug Prescription,Association for Computing Machinery,2019,https://doi.org/10.1145/3307339.3342134;http://dx.doi.org/10.1145/3307339.3342134,We present an end-to-end interpretable deep architecture that predicts the success of drug prescription based on multiple graph kernel fusion using a graphical representation of electronic health records. We formulate the predictive model as a binary graph classification problem with a set of graph kernels proposed to capture different aspects of graph structures through deep neural networks. Results using the Taiwanese National Health Insurance Research Database demonstrate that our approach outperforms current start-of-the-art models on accuracy and interpretability. The approach is in preliminary deployment.,"graph kernel, multiple kernel fusion, deep learning, health informatics, predictive model"
Journal Article,"Yu Z,Li T,Yu N,Pan Y,Chen H,Liu B",Reconstruction of Hidden Representation for Robust Feature Extraction,Association for Computing Machinery,2019,https://doi.org/10.1145/3284174;http://dx.doi.org/10.1145/3284174,"This article aims to develop a new and robust approach to feature representation. Motivated by the success of Auto-Encoders, we first theoretically analyze and summarize the general properties of all algorithms that are based on traditional Auto-Encoders: (1) The reconstruction error of the input cannot be lower than a lower bound, which can be viewed as a guiding principle for reconstructing the input. Additionally, when the input is corrupted with noises, the reconstruction error of the corrupted input also cannot be lower than a lower bound. (2) The reconstruction of a hidden representation achieving its ideal situation is the necessary condition for the reconstruction of the input to reach the ideal state. (3) Minimizing the Frobenius norm of the Jacobian matrix of the hidden representation has a deficiency and may result in a much worse local optimum value. We believe that minimizing the reconstruction error of the hidden representation is more robust than minimizing the Frobenius norm of the Jacobian matrix of the hidden representation. Based on the above analysis, we propose a new model termed Double Denoising Auto-Encoders (DDAEs), which uses corruption and reconstruction on both the input and the hidden representation. We demonstrate that the proposed model is highly flexible and extensible and has a potentially better capability to learn invariant and robust feature representations. We also show that our model is more robust than Denoising Auto-Encoders (DAEs) for dealing with noises or inessential features. Furthermore, we detail how to train DDAEs with two different pretraining methods by optimizing the objective function in a combined and separate manner, respectively. Comparative experiments illustrate that the proposed model is significantly better for representation learning than the state-of-the-art models.","unsupervised learning, reconstruction of hidden representation, auto-encoders, Deep architectures, feature representation"
Conference Paper,"Zhang J,Wang Y,Yang X,Wang F",Entity Recognition of Chinese Medical Literature Based on BiLSTM-CRF and Fusion Features,Association for Computing Machinery,2020,https://doi.org/10.1145/3422713.3422724;http://dx.doi.org/10.1145/3422713.3422724,"The entity recognition status of Chinese medical literature is introduced in the paper. On the foundation, we propose a method based on fusion-feature to solve problems of medical named entity recognition. Then, the BiLSTM-CRF model is constructed by combining the Conditional Random Field (CRF) of Bidirectional Long Short-Term Memory (BiLSTM) network. It is used to obtain long-distance context information and label entity types. We use Word2vec to build the embedding layer. The characters and words in the sentence are converted into dense vectors with fusing external dictionary features. The results show that compared with using traditional CRF model, the method based on fusion-feature BiLSTM-CRF has better effect, and the F-measure is increased by 7.51%.","Named entity recognition, Medical literature, BiLSTM-CRF neural network model, Conditional random field, Long short-term memory"
Journal Article,"Shang H,Liu ZP",Prioritizing Type 2 Diabetes Genes by Weighted PageRank on Bilayer Heterogeneous Networks,IEEE Computer Society Press,2021,https://doi.org/10.1109/TCBB.2019.2917190;http://dx.doi.org/10.1109/TCBB.2019.2917190,"The prevalence of diabetes mellitus has been increasing rapidly in recent years. Type 2 diabetes makes up about 90 percent cases of diabetes. The interacting mixed effects of genetics and environments build possible interpretable pathogenesis. Thus, finding the causal disease genes is crucial in its clinical diagnosis and medical treatment. Currently, network-based computational method becomes a powerful tool of systematically analyzing complex diseases, such as the identification of candidate disease genes from networks. In this paper, we propose a bioinformatics framework of prioritizing type 2 diabetes genes by leveraging the modified PageRank algorithm on bilayer biomolecular networks consisting an ensemble gene-gene regulatory network and an integrative protein-protein interaction network. We specifically weigh the networks by differential mutual information for measuring the context specificities between genes and between proteins by transcriptomic and proteomic datasets, respectively. After formulating the network into two components of known disease genes and the other normal healthy genes, we rank the diabetes genes and others by bringing the orders in the bilayer network via an improved PageRank algorithm. We conclude that these known disease genes achieve significantly higher ranks compared to these randomly-selected normal genes, and the ranks are robust and consistent in multiple validation scenarios. In functional analysis, these high-ranked genes are identified to perform relevant risks and dysfunctions of type 2 diabetes.",Not Found
Conference Paper,"Pradhan A,Mehta K,Findlater L","""Accessibility Came by Accident"": Use of Voice-Controlled Intelligent Personal Assistants by People with Disabilities",Association for Computing Machinery,2018,https://doi.org/10.1145/3173574.3174033;http://dx.doi.org/10.1145/3173574.3174033,"From an accessibility perspective, voice-controlled, home-based intelligent personal assistants (IPAs) have the potential to greatly expand speech interaction beyond dictation and screen reader output. To examine the accessibility of off-the-shelf IPAs (e.g., Amazon Echo) and to understand how users with disabilities are making use of these devices, we conducted two exploratory studies. The first, broader study is a content analysis of 346 Amazon Echo reviews that include users with disabilities, while the second study more specifically focuses on users with visual impairments, through interviews with 16 current users of home-based IPAs. Findings show that, although some accessibility challenges exist, users with a range of disabilities are using the Amazon Echo, including for unexpected cases such as speech therapy and support for caregivers. Richer voice-based applications and solutions to support discoverability would be particularly useful to users with visual impairments. These findings should inform future work on accessible voice-based IPAs.","intelligent personal assistants, accessibility, disability, speech, conversational interfaces"
Conference Paper,Cohen L,Impacts of Business Intelligence on Population Health: A Systematic Literature Review,Association for Computing Machinery,2017,https://doi.org/10.1145/3129416.3129441;http://dx.doi.org/10.1145/3129416.3129441,"""Business Intelligence"" is an area of Information Technology (IT) that involves the collection, analysis and presentation of large amounts of data. BI has been successfully applied to promote good decision making in a variety of environments, and has high potential to make a significant impact in the domain of population health. The promotion of population health is a key concern of government authorities and various health institutions and officials making decisions about interventions that may impact on population health would benefit from the use of information on population health. BI could clearly be a facilitator in this regard, but evidence of its current application and impact in this field is not easily accessible to policy makers. This systematic literature review explored the literature and provided a synthesis of information available on the current use of BI in this area, and evidence of the impact of its use on population health. An array of applications of BI for population health were found, including data warehouses, analytics, reports, data warehouse browsers, OLAP, GIS, Dashboards and Alerts. Evidence of the impact of these applications on population health was mainly anecdotal, with only one empirical study found. Issues and challenges encountered in the development and use of BI are Privacy and Security, Data Quality and Development and Maintenance of BI infrastructure","systematic literature review, business intelligence, population health"
Conference Paper,"Cha YJ,Saxena A,Wou A,Lee J,Newman MW,Park SY",Transitioning Toward Independence: Enhancing Collaborative Self-Management of Children with Type 1 Diabetes,Association for Computing Machinery,2022,https://doi.org/10.1145/3491102.3502055;http://dx.doi.org/10.1145/3491102.3502055,"Although child participation is required for successful Type 1 Diabetes (T1D) management, it is challenging because the child’s young age and immaturity make it difficult to perform self-care. Thus, parental caregivers are expected to be heavily involved in their child’s everyday illness management. Our study aims to investigate how children and parents collaborate to manage T1D and examine how the children become more independent in their self-management through the support of their parents. Through semi-structured interviews with children with T1D and their parents (N=41), our study showed that children’s knowledge of illness management and motivation for self-care were crucial for their transition towards independence. Based on these two factors, we identified four types of children’s collaboration (i.e., dependent, resistant, eager, and independent) and parents’ strategies for supporting their children’s independence. We suggest design implications for technologies to support collaborative care by improving children’s transition to independent illness management.","chronic illness management, pediatric patient, child-parent collaboration, type 1 diabetes, collaborative healthcare technology, child independence, child self-care"
Conference Paper,"Ren H,Wang J,Zhao WX,Wu N",RAPT: Pre-Training of Time-Aware Transformer for Learning Robust Healthcare Representation,Association for Computing Machinery,2021,https://doi.org/10.1145/3447548.3467069;http://dx.doi.org/10.1145/3447548.3467069,"With the development of electronic health records (EHRs), prenatal care examination records have become available for developing automatic prediction or diagnosis approaches with machine learning methods. In this paper, we study how to effectively learn representations applied to various downstream tasks for EHR data. Although several methods have been proposed in this direction, they usually adapt classic sequential models to solve one specific diagnosis task or address unique EHR data issues. This makes it difficult to reuse these existing methods for the early diagnosis of pregnancy complications or provide a general solution to address the series of health problems caused by pregnancy complications. In this paper, we propose a novel model RAPT, which stands for RepresentAtion by Pre-training time-aware Transformer. To associate pre-training and EHR data, we design an architecture that is suitable for both modeling EHR data and pre-training, namely time-aware Transformer. To handle various characteristics in EHR data, such as insufficiency, we carefully devise three pre-training tasks to handle data insufficiency, data incompleteness and short sequence problems, namely similarity prediction, masked prediction and reasonability check. In this way, our representations can capture various EHR data characteristics. Extensive experimental results for four downstream tasks have shown the effectiveness of the proposed approach. We also introduce sensitivity analysis to interpret the model and design an interface to show results and interpretation for doctors. Finally, we implement a diagnosis system for pregnancy complications based on our pre-training model. Doctors and pregnant women can benefit from the diagnosis system in early diagnosis of pregnancy complications.","pre-training, representation learning, healthcare informatics"
Conference Paper,Zhang J,Supporting Information Needs of Transitional Phases in Diabetes Management Through Online Health Communities,Association for Computing Machinery,2017,https://doi.org/10.1145/3022198.3024942;http://dx.doi.org/10.1145/3022198.3024942,"As of 2014, 29.1 million people in the US have diabetes. Diabetes has a substantial and increasing impact on the quality of life. Patients face the burden of self-management and the challenge of 'transitional' phases, when they need to find out about their options and the next course of action. The field has under-explored the specific information needs patients have during those transitional phases. I aim to investigate the information needs in the transitional phases and develop design requirements in providing balanced and comprehensive information to better support patient information needs.","information needs, chronic illness, health informatics, online health communities, diabetes"
Conference Paper,"Liu Y,Zheng Y,Zhang D,Chen H,Peng H,Pan S",Towards Unsupervised Deep Graph Structure Learning,Association for Computing Machinery,2022,https://doi.org/10.1145/3485447.3512186;http://dx.doi.org/10.1145/3485447.3512186,"In recent years, graph neural networks (GNNs) have emerged as a successful tool in a variety of graph-related applications. However, the performance of GNNs can be deteriorated when noisy connections occur in the original graph structures; besides, the dependence on explicit structures prevents GNNs from being applied to general unstructured scenarios. To address these issues, recently emerged deep graph structure learning (GSL) methods propose to jointly optimize the graph structure along with GNN under the supervision of a node classification task. Nonetheless, these methods focus on a supervised learning scenario, which leads to several problems, i.e., the reliance on labels, the bias of edge distribution, and the limitation on application tasks. In this paper, we propose a more practical GSL paradigm, unsupervised graph structure learning, where the learned graph topology is optimized by data itself without any external guidance (i.e., labels). To solve the unsupervised GSL problem, we propose a novel StrUcture Bootstrapping contrastive LearnIng fraMEwork (SUBLIME for abbreviation) with the aid of self-supervised contrastive learning. Specifically, we generate a learning target from the original data as an “anchor graph”, and use a contrastive loss to maximize the agreement between the anchor graph and the learned graph. To provide persistent guidance, we design a novel bootstrapping mechanism that upgrades the anchor graph with learned structures during model learning. We also design a series of graph learners and post-processing schemes to model the structures to learn. Extensive experiments on eight benchmark datasets demonstrate the significant effectiveness of our proposed SUBLIME and high quality of the optimized graphs.","unsupervised learning, graph structure learning, graph neural networks, contrastive learning"
Conference Paper,"Miller A,Panneerselvam J,Liu L","An Empirical Analysis of LADA Diabetes Case, Control and Variable Importance",Association for Computing Machinery,2022,https://doi.org/10.1145/3492323.3495632;http://dx.doi.org/10.1145/3492323.3495632,"Latent Autoimmune Diabetes in Adults (LADA) is a condition, which is rarely recognised as a complex disease within its own right and remains under researched. Completely over-shadowed by Type 1 and Type 2 diabetes, LADA is the second most prevalent genre of diabetes after Type 2. This paper investigates conventional (clinical and socio-demographic) risk factors including Age, Gender, BMI (Body Mass Index), Cholesterol, Waist Size and Family History, with the motivation of determining their respective significant predictive power in the classification of LADA Diabetes. Such conventional factors are analysed and modelled using a set of supervised machine-learning algorithms including Support Vector Machines with Radial Basis Function Kernel (SVM), Random Forest (RF), K-Nearest Neighbour (KNN), Monotone Multi-Layer Perceptron Neural Network (MONMLP), Neural-net (NN) and Naïve Bayes (NB) Classifier, with the objective of correctly classifying LADA diabetes. Results elucidated from the analysis demonstrate that the predictive capacity of the learning models is significantly enhanced with the utilisation of Neuralnet classifier, achieving a classification accuracy of 85.51%, sensitivity of 84.09%, and specificity of 86.93%, alongside a precision of 86.93%, a recall of 84.53% and an F1 score of 85.71%, thereby outperforming the other studied individual models. Further analysis on the variable importance determined that the conventional variable Waist Size is the most significant variable when using the Neuralnet classifier with a 100% importance for LADA diabetes classification.","conventional variables, classification, variable importance, LADA"
Conference Paper,"Tsoukas V,Boumpa E,Giannakas G,Kakarountas A",A Review of Machine Learning and TinyML in Healthcare,Association for Computing Machinery,2022,https://doi.org/10.1145/3503823.3503836;http://dx.doi.org/10.1145/3503823.3503836,"Healthcare is the field that can benefit from the large amount of raw data generated from portable and wearable devices. This data must be sent to the Cloud for processing due to the computationally intensive nature of current state-of-the-art implementations of Neural Networks. The emerging technology of TinyML is an alternative approach proposed by the scientific community to create autonomous and safe devices that can collect, process, and alert without transmitting data to external entities. This work is the review of the contribution of the emerging technology of TinyML in healthcare applications at the edge, requiring the integration of Machine Learning algorithms, followed by the solutions it can bring, especially in wearable devices. Moreover, it is discussed how TinyML can optimize Neural Networks to bring intelligence and autonomy in devices used in fields such as healthcare.","TinyML, Healthcare, Embedded systems, Neural Networks, Machine Learning"
Conference Paper,"Nayar N,Ahuja S,Jain S",Swarm Intelligence and Data Mining: A Review of Literature and Applications in Healthcare,Association for Computing Machinery,2019,https://doi.org/10.1145/3339311.3339323;http://dx.doi.org/10.1145/3339311.3339323,"Healthcare industry is evolving at a rapid pace across the world. Substantial amount of heterogeneous data is generated by healthcare industry. It is crucial for healthcare industries to attain, accumulate and mine the data in an effective manner. Thus, data mining can provide enormous opportunities for diagnosis, prediction and essential treatment. Data mining plays imperative role in the medical domain that facilitates the systems to analyze the massive data, so that finest practices can be applied for further research and evaluating the patients' reports. This paper explores various applications that employ Swarm Intelligence with data mining in healthcare in terms of methods and results obtained. Swarm Intelligence algorithms have been used for prognosis of major diseases like cancer, heart diseases, tumors, and cardiology. The Swarm Intelligence approaches have been applied in the areas of disease diagnosis and treatment.","medical, data mining, swarm intelligence, healthcare"
Conference Paper,"Lee D,Kim WC,Song M",Finding the Differences between the Perceptions of Experts and the Public in the Field of Diabetes,Association for Computing Machinery,2015,https://doi.org/10.1145/2740908.2742773;http://dx.doi.org/10.1145/2740908.2742773,"Automatic information extraction techniques such as named entity recognition and relation extraction have been developed but it is yet rare to apply them to various document types. In this paper, we applied them to academic literature and social media's contents in the field of diabetes to find distinctions between the perceptions of biomedical experts and the public. We analyzed and compared the experts' and the public's networks constituted by the extracted entities and relations. The results confirmed that there are some differences in their views, i.e., biomedical entities that interest them and relations within their knowledge range.","degree centrality, relation extraction, diabetes, semantic relatedness, named entity recognition, social media"
Conference Paper,"Braga O,Albuquerque G,Oliveira M,Monteiro O",Intelligent Solution for Classification of Diseases Transmitted by Vector Aedes Aegypti,Association for Computing Machinery,2018,https://doi.org/10.1145/3293614.3293640;http://dx.doi.org/10.1145/3293614.3293640,"Several physical or emotional factors can contribute negatively to critical moments in the health area, negatively influencing the diagnosis of diseases. Therefore, this work proposes an intelligent solution based on classifiers as an inference mechanism capable of assisting health professionals during the process of clinical management of diseases transmitted by the Aedes Aegypti mosquito, identifying the most probable diagnosis based on symptoms and outcome of exams. Thus, two learning models capable of inferring the probability of a patient being infected with a particular disease were applied, with an accuracy up to 91.6%. An intelligent API to support decision-making was then built during the clinical management of dengue and chikungunya. The solution allows several applications to access learning models. As proof of concept, a mobile application of popular consultation for the identification of dengue and chikungunya was also developed.","dengue, chikungunya, classification, data mining, health system, machine learning"
Conference Paper,"Oakden-Rayner L,Dunnmon J,Carneiro G,Re C",Hidden Stratification Causes Clinically Meaningful Failures in Machine Learning for Medical Imaging,Association for Computing Machinery,2020,https://doi.org/10.1145/3368555.3384468;http://dx.doi.org/10.1145/3368555.3384468,"Machine learning models for medical image analysis often suffer from poor performance on important subsets of a population that are not identified during training or testing. For example, overall performance of a cancer detection model may be high, but the model may still consistently miss a rare but aggressive cancer subtype. We refer to this problem as hidden stratification, and observe that it results from incompletely describing the meaningful variation in a dataset. While hidden stratification can substantially reduce the clinical efficacy of machine learning models, its effects remain difficult to measure. In this work, we assess the utility of several possible techniques for measuring hidden stratification effects, and characterize these effects both via synthetic experiments on the CIFAR-100 benchmark dataset and on multiple real-world medical imaging datasets. Using these measurement techniques, we find evidence that hidden stratification can occur in unidentified imaging subsets with low prevalence, low label quality, subtle distinguishing features, or spurious correlates, and that it can result in relative performance differences of over 20% on clinically important subsets. Finally, we discuss the clinical implications of our findings, and suggest that evaluation of hidden stratification should be a critical component of any machine learning deployment in medical imaging.","hidden stratification, machine learning, convolutional neural networks"
Conference Paper,"Wójcik D,Kozłowski E,Woundefined M,Rymarczyk T,Woundefinedko E",Machine Learning Pathology Detection with a Body Surface Potential Mapping,Association for Computing Machinery,2020,https://doi.org/10.1145/3410530.3414404;http://dx.doi.org/10.1145/3410530.3414404,"The development of technology has enabled the construction of various expert systems that can now assist experts in disease recognition. Nowadays, most of the expert systems are based on decision trees. The parameters inside a decision tree are based on experts' knowledge and scientific data which vary slightly depending on the expert and source. To deal with this problem, we developed a complete medical system in which electrical impedance tomography and body surface potential mapping are used to measure the patient biosignals. The system focuses on the cardiorespiratory biosignals. With the use of machine learning, we analyze each measured channel and show which channel should be taken into account in the detection of pathologies. We show that the channels that are important for machine learning are different from those used by experts in 12-channel ECG.","BSPM, ECG, machine learning, wearables"
Journal Article,"Yu C,Liu J,Nemati S,Yin G",Reinforcement Learning in Healthcare: A Survey,Association for Computing Machinery,2021,https://doi.org/10.1145/3477600;http://dx.doi.org/10.1145/3477600,"As a subfield of machine learning, reinforcement learning (RL) aims at optimizing decision making by using interaction samples of an agent with its environment and the potentially delayed feedbacks. In contrast to traditional supervised learning that typically relies on one-shot, exhaustive, and supervised reward signals, RL tackles sequential decision-making problems with sampled, evaluative, and delayed feedbacks simultaneously. Such a distinctive feature makes RL techniques a suitable candidate for developing powerful solutions in various healthcare domains, where diagnosing decisions or treatment regimes are usually characterized by a prolonged period with delayed feedbacks. By first briefly examining theoretical foundations and key methods in RL research, this survey provides an extensive overview of RL applications in a variety of healthcare domains, ranging from dynamic treatment regimes in chronic diseases and critical care, automated medical diagnosis, and many other control or scheduling problems that have infiltrated every aspect of the healthcare system. In addition, we discuss the challenges and open issues in the current research and highlight some potential solutions and directions for future research.","Reinforcement learning, healthcare, dynamic treatment regimes, critical care, chronic disease, automated diagnosis"
Conference Paper,"Pantazopoulos A,Maragoudakis M",Sports & Nutrition Data Science Using Gradient Boosting Machines,Association for Computing Machinery,2018,https://doi.org/10.1145/3200947.3201060;http://dx.doi.org/10.1145/3200947.3201060,"Throughout1 recent years, a significant amount of research has dealt with how humans could beat time. According to the extracted outcome, the main weapons in this battle are balanced nutrition and systematic exercise. Outdoor running, ranging from short distances up to even marathons, is gaining popularity, boosting the clothing, shoes and even gadget industry as well. The current rapid development of technology leads to the supply of a vast amount of information that enables us to properly process valuable knowledge. Smart watches, wristbands, mobile phone applications, shoes and clothes sensors, etc. have provided practitioners the tools to collect numerous data regarding their fitness levels. The recent challenge data mining is about to serve, lies to the fact of how one can combine and analyze the abundance of data from daily activities, nutrition habits and fitness activities into one, unified model that could explain the underlying patterns of a subject's physical capacity. The current work deals with collecting heterogeneous fitness and nutrition facts from students of various athletic background and skills within the University of the Aegean campus, using hi-tech GPS smartwatches and calories monitoring smartwatch applications. Upon data collection, we apply Gradient Boosting Machines to forecast the finishing time of two different running tasks, namely 800m and 5000m. The algorithm is trained and evaluated using different attribute sets, focusing on features that describe either fitness skills, nutrition habits or both. The results demonstrate an impressive ability of the aforementioned method to predict the finishing time which surpasses many other Machine Learning algorithms and traditional models such as Support Vector Machines, Random Forests, Deep Neural Networks and Linear Regression. Note that, based on current literature on the task at hand, prediction is almost exclusively relied to Linear Regression models, mentioning results far worse than GBM. Finally, feature importance functionalities of GBM are also exploited to reveal the factors that are considered to be most significant during the forecasting process. Such factors could be further utilized by professional or amateur athletes (with the assistant of professional trainers and experts of course), for improving their current fitness and health levels.","Gradient Boosting Machines, Sports Analysis, Nutrition, Data Mining, Running, Fitness"
Conference Paper,"Su CJ,Huang SF,Li Y",Case Based Reasoning Driven Ontological Intelligent Health Projection System,Association for Computing Machinery,2018,https://doi.org/10.1145/3239438.3239470;http://dx.doi.org/10.1145/3239438.3239470,"For the past few years, health-related issues are getting more and more attention. With regular health screening, disease detection and subsequent medical attention can proceed with far lesser chance of missing the critical period. The projection of health related issues from health screening has been studied by using statistical analysis methods. However, the results generally fail to alert the subjects regarding the potential risks involved due to lack of certainty. The potential health issues derived from statistical analysis of health screening data and medical general guidelines can only be presented to the subjects with probability and lack of supportive hard evidence. The efficacy of health screening consequently fails to be realized. In order to confront the dilemma, we have developed an Intelligent Health Projection System (IHPS) for providing an evidential health status projection and a more motivated health plan to the subjects. This study focuses on modelling Type 2 Diabetes Mellitus (T2DM) and associated factors as an example. Other cases can be analogously implemented. The IHPS adaptively provides the projection of potential risk of getting T2DM by exploring the similarity between the subject's health screening data and previous T2DM patients' cases. The main building blocks, the cases that serve as a knowledge base for IHPS are modelled using ontology technology. As the main functionality of IHPS, the T2DM projection uses the traces left by previous T2DM patients and works on top of case-based reasoning mechanism. The proposed IHPS aims to promote better self-health management by enhancing a subject's comprehension on risks revealed in health screening result. The cases retrieved can not only being used for risk projection of a subject but also serving as evidences for physicians to provide more accurate and convincing health advice.","Type 2 Diabetes Mellitus, Case-based Reasoning, Ontology, Analytic Hierarchy Process, Health Projection, Entropy"
Conference Paper,"Mancuso R,Settino M,Cannataro M",Data Mining for Electroencephalogram Signal Processing and Analysis,Association for Computing Machinery,2021,https://doi.org/10.1145/3459930.3470905;http://dx.doi.org/10.1145/3459930.3470905,"Electroencephalography (EEG) is a complex signal that requires advanced signal processing and feature extraction methodologies to be interpreted correctly. EEG, is usually utilized to estimate the trace and the electrical brain activity. It is employed in the discovery and forecast of epileptic and non-epileptic seizures and neurodegenerative pathologies. In this article, we give an overview of the various computational techniques used in the past, in the present and the future to preprocess and analyze EEG signals.In particular, this work aims to briefly review the state of research in this field, trying to understand the needs of EEG analysis in the medical field, with special focus on neurodegenerative pathologies, and epileptic and not-epileptic diseases. After presenting the main pre-processing, feature selection and extraction phases, we focus on classification processes and on Data Mining techniques applied to classify EEGs. Then, through the EEG analysis a discussion of the implementation is provided to investigate, predict and diagnose some cognitive diseases and epilepsy.","epilepsy seizure, electroencephalogram (EEG), machine learning (ML), deep learning (DL), feature extraction, cognitive diseases, data mining techniques"
Book,Not Found,AISS '22: Proceedings of the 4th International Conference on Advanced Information Science and System,Association for Computing Machinery,2022,Not Found,Not Found,Not Found
Conference Paper,"Aral KD,Chick SE,Grabosch A",Primary Preventive Care Model for Type 2 Diabetes: Input Calibration with Response Data,IEEE Press,2014,Not Found,"Type 2 Diabetes Mellitus (T2DM) and its complications account for 11% of the global health expenditure (IDF 2012). Different primary, secondary, and tertiary preventive interventions promise better health outcomes and cost savings but are often studied separately. This paper proposes a simulation model for T2DM that comprehends the nonlinear interactions of multiple interventions for various stages of T2DM on population dynamics, health outcomes, and costs. We summarize the model, then demonstrate how we addressed the important challenge of fitting input parameters given that data needed to be combined from disparate sources of data sources in a way that calibrates input parameters to output metrics over a range of decision variables (a form of model calibration to achieve a response model match to clinical data). We present preliminary numerical results to inform policies for T2DM prevention and management.",Not Found
Journal Article,"An Y,Huang N,Chen X,Wu F,Wang J",High-Risk Prediction of Cardiovascular Diseases via Attention-Based Deep Neural Networks,IEEE Computer Society Press,2019,https://doi.org/10.1109/TCBB.2019.2935059;http://dx.doi.org/10.1109/TCBB.2019.2935059,"High-risk prediction of cardiovascular disease is of great significance and impendency in medical fields with the increasing phenomenon of sub-health these years. Most existing pathological methods for the prognosis prediction are either costly or prone to misjudgement. Therefore, plenty of automated models based on machine learning have been proposed to predict the onset of cardiovascular disease with the premorbid information of patients extracted from their historical Electronic Health Records (EHRs). However, it is a tough job to select proper features from longitudinal and heterogeneous EHRs, and also a great challenge to obtain accurate and robust representations for patients. In this paper, we propose an entirely end-to-end model called DeepRisk based on attention mechanism and deep neural networks, which can not only learn high-quality features automatically from EHRs, but also efficiently integrate heterogeneous and time-ordered medical data, and finally predict patients’ risk of cardiovascular diseases. Experiments are carried out on a real medical dataset and results show that DeepRisk can significantly improve the high-risk prediction accuracy for cardiovascular disease compared with state-of-the-art approaches.",Not Found
Conference Paper,"Liu Q,Du J,Li Y,Peng G,Zhong Y,Du R",Detection of Nasopharyngeal Carcinoma Using Routine Medical Tests via Machine Learning,Association for Computing Machinery,2022,https://doi.org/10.1145/3524086.3524102;http://dx.doi.org/10.1145/3524086.3524102,"Nasopharyngeal carcinoma (NPC) is one of the most common types of cancers in South China and Southeast Asia. Clinical data has shown that early detection is essential for improving treatment effectiveness and survival rate. Unfortunately, because the early symptoms of NPC are rather similar to that of mild diseases such as rhinitis, it is common to miss early detection. Currently, the most common method for detecting NPC is based on Epstein-Barr Virus (EBV) antibodies. However, it is usually not included in the annual routine medical tests. This paper presents a study on the detection of NPC using routine medical tests via machine learning methods, namely Random Forest (RF), Support Vector Machine (SVM), and Artificial Neural Network (ANN). Machine learning can extract valuable but hidden information from complex medical test data. First, we use a dataset containing 523 NPC patients (first diagnosed before any medical treatment) as well as 600 healthy people as controls. The data consists of five categories of information: demographic features (gender, age), EBV antibodies (VCA-IgA, EA-IgA), blood test indices, liver function test indices, and urine sediment test indices. Our evaluation criteria consist of accuracy, sensitivity, specificity, Youden index, and Area Under the receiver operating characteristic Curve (AUC). The results show that RF outperforms both SVM and ANN. When using only EBV antibody data, the accuracy, sensitivity and specificity are 90.4%, 89.8% and 90.8% respectively, which is comparable to the results in the existing literature. When using only the routine medical test data, the accuracy, sensitivity and specificity are 95.0%, 93.3% and 96.5% respectively. When using both, the accuracy, specificity and sensitivity are 96.9%, 96.9% and 96.8% respectively. Second, we use another dataset containing 100 NPC patients and 100 healthy people for validation (use RF with only the routine medical test data). The prediction accuracy, sensitivity and specificity are 93.1%, 88.1% and 98.2% respectively. This demonstrates that NPC can be effectively detected using routine medical test data via machine learning. The new method will have a number of positive impacts, including ease of implementation, improved detection accuracy as well as reduced testing cost.","Nasopharyngeal Carcinoma, Random Forest, Support Vector Machine, Artificial Neural Network"
Conference Paper,"Shin JY,Holtz B",Identifying Opportunities and Challenges: How Children Use Technologies for Managing Diabetes,Association for Computing Machinery,2020,https://doi.org/10.1145/3392063.3394444;http://dx.doi.org/10.1145/3392063.3394444,"Type 1 diabetes (T1D) is one of the most common chronic diseases for children in the United States. Once diagnosed, the family must manage the disease to prevent further complications. Recent health technologies, like mobile phone health applications (mHealth apps), have become useful tools to support health monitoring, particularly for children living in the digital era. We used a narrative story to prompt 10 children with T1D to describe their diabetes management routines during semi-structured video interviews. Our results show that while the children feel a sense of ownership over their management routine, especially if they use newer monitoring technologies (e.g., continuous glucose monitor), they experience many challenges in managing their blood glucose (BG) levels, particularly during school. They also expressed emerging fears of security and privacy issues associated with technology use. By capturing these themes in T1D management from the children's perspective, we discuss design implications for developing supportive mHealth interventions.","diabetes, user-centered design, self-care, mHealth, health monitoring technology"
Book,Not Found,ICBIP '22: Proceedings of the 7th International Conference on Biomedical Signal and Image Processing,Association for Computing Machinery,2022,Not Found,Not Found,Not Found
Journal Article,"Arachie C,Huang B",A General Framework for Adversarial Label Learning,JMLR.org,2022,Not Found,We consider the task of training classifiers without fully labeled data. We propose a weakly supervised method--adversarial label learning--that trains classifiers to perform well when noisy and possibly correlated labels are provided. Our framework allows users to provide different weak labels and multiple constraints on these labels. Our model then attempts to learn parameters for the data by solving a zero-sum game for the binary problems and a non-zero sum game optimization for multi-class problems. The game is between an adversary that chooses labels for the data and a model that minimizes the error made by the adversarial labels. The weak supervision constrains what labels the adversary can choose. The method therefore minimizes an upper bound of the classifier's error rate using projected primal-dual subgradient descent. Minimizing this bound protects against bias and dependencies in the weak supervision. We first show the performance of our framework on binary classification tasks then we extend our algorithm to show its performance on multiclass datasets. Our experiments show that our method can train without labels and outperforms other approaches for weakly supervised learning.,"weak supervision, lagrangian optimization, adversarial learning, unsupervised learning, constraint learning"
Journal Article,"Qiu L,Gorantla S,Rajan V,Tan BC",Multi-Disease Predictive Analytics: A Clinical Knowledge-Aware Approach,Association for Computing Machinery,2021,https://doi.org/10.1145/3447942;http://dx.doi.org/10.1145/3447942,"Multi-Disease Predictive Analytics (MDPA) models simultaneously predict the risks of multiple diseases in patients and are valuable in early diagnoses. Patients tend to have multiple diseases simultaneously or develop multiple complications over time, and MDPA models can learn and effectively utilize such correlations between diseases. Data from large-scale Electronic Health Records (EHR) can be used through Multi-Label Learning (MLL) methods to develop MDPA models. However, data-driven approaches for MDPA face the challenge of data imbalance, because rare diseases tend to have much less data than common diseases. Insufficient data for rare diseases makes it difficult to leverage correlations with other diseases. These correlations are studied and recorded in biomedical literature but are rarely utilized in predictive analytics. This article presents a novel method called Knowledge-Aware Approach (KAA) that learns clinical correlations from the rapidly growing body of clinical knowledge. KAA can be combined with any data-driven MLL model for MDPA to refine the predictions of the model. Our extensive experiments, on real EHR data, show that the use of KAA improves the predictive performance of commonly used MDPA models, particularly for rare diseases. KAA is also found to be superior to existing general approaches of combining clinical knowledge with data-driven models. Further, a counterfactual analysis shows the efficacy of KAA in improving physicians’ ability to prescribe preventive treatments.","knowledge graph, biomedical literature, rare diseases, Electronic health records, multi-label learning, diagnosis prediction"
Conference Paper,"Currie CS,Monks T","Modeling Diseases: Prevention, Cure and Management",IEEE Press,2018,Not Found,"Diseases, like death and taxes, seem an inevitable part of life, with much of modern medicine acting to prevent, cure or manage them effectively. Modeling of diseases began over a century ago and has been one of the success stories of applied mathematics and, more recently, computer simulation. In this article, we describe modeling of both communicable and non-communicable diseases, and provide a review of the relevant literature. Two case studies are discussed, the first describing a modeling study of tuberculosis and HIV and the second capacity planning for stroke services. Our aim is to instigate a discussion of how modeling should be used in the future to answer the most up-to-date questions about global health, particularly those of disease prevention.",Not Found
Conference Paper,"Wang S,Ren P,Chen Z,Ren Z,Ma J,de Rijke M",Order-Free Medicine Combination Prediction with Graph Convolutional Reinforcement Learning,Association for Computing Machinery,2019,https://doi.org/10.1145/3357384.3357965;http://dx.doi.org/10.1145/3357384.3357965,"Medicine Combination Prediction (MCP) based on Electronic Health Record (EHR) can assist doctors to prescribe medicines for complex patients. Previous studies on MCP either ignore the correlations between medicines (i.e., MCP is formulated as a binary classifcation task), or assume that there is a sequential correlation between medicines (i.e., MCP is formulated as a sequence prediction task). The latter is unreasonable because the correlations between medicines should be considered in an order-free way. Importantly, MCP must take additional medical knowledge (e.g., Drug-Drug Interaction (DDI)) into consideration to ensure the safety of medicine combinations. However, most previous methods for MCP incorporate DDI knowledge with a post-processing scheme, which might undermine the integrity of proposed medicine combinations. In this paper, we propose a graph convolutional reinforcement learning model for MCP, named Combined Order-free Medicine Prediction Network (CompNet), that addresses the issues listed above. CompNet casts the MCP task as an order-free Markov Decision Process (MDP) problem and designs a Deep Q Learning (DQL) mechanism to learn correlative and adverse interactions between medicines. Specifcally, we frst use a Dual Convolutional Neural Network (Dual-CNN) to obtain patient representations based on EHRs. Then, we introduce the medicine knowledge associated with predicted medicines to create a dynamic medicine knowledge graph, and use a Relational Graph Convolutional Network (R-GCN) to encode it. Finally, CompNet selects medicines by fusing the combination of patient information and the medicine knowledge graph. Experiments on a benchmark dataset, i.e., MIMIC-III, demonstrate that CompNet signifcantly outperforms state-of-the-art methods and improves a recently proposed model by 3.74%pt, 6.64%pt in terms of Jaccard and F1 metrics.","reinforcement learning, relational graph convolutional network, medicine combination prediction, medicine knowledge graph"
Conference Paper,"MacAlpine R,Flatla DR",Real-Time Mobile Personalized Simulations of Impaired Colour Vision,Association for Computing Machinery,2016,https://doi.org/10.1145/2982142.2982170;http://dx.doi.org/10.1145/2982142.2982170,"Colour forms an essential element of day-to-day life for most people, but at least 5% of the world have Impaired Colour Vision (ICV) - seeing fewer colours than everyone else. Those with typical colour vision find it difficult to understand how people with ICV perceive colour, leading to misunderstanding and challenges for people with ICV. To help improve understanding, personalized simulations of ICV have been developed, but are computationally demanding (so limited to static images), which limits the value of these simulations. To address this, we extended personalized ICV simulations to work in real time on a mobile device to allow people with typical colour vision greater freedom in exploring ICV. To validate our approach, we compared our real-time simulation technique to an existing adjustable simulation technique and found general agreement between the two. We then deployed three real-time personalized ICV simulations to nine people with typical colour vision, encouraging them to take photos of interesting colour situations. In just over one week, participants recorded over 450 real-world images of situations where their simulation presented a distinct challenge for their respective ICV participant. Through a questionnaire and discussion of photos with participants, we found that our solution provides a valuable mechanism for building understanding of ICV for people with typical colour vision.","colour vision deficiency, mobile personalized simulation, colourblindness, impaired colour vision"
Conference Paper,"Tay D,Poh CL,Kitney R",An Evolutionary Data-Conscious Artificial Immune Recognition System,Association for Computing Machinery,2013,https://doi.org/10.1145/2463372.2463499;http://dx.doi.org/10.1145/2463372.2463499,"Artificial Immune Recognition System (AIRS) algorithm offers a promising methodology for data classification. It is an immune-inspired supervised learning algorithm that works efficiently and has shown comparable performance with respect to other classifier algorithms. For this reason, it has received escalating interests in recent years. However, the full potential of the algorithm was yet unleashed. We proposed a novel algorithm called the evolutionary data-conscious AIRS (EDC-AIRS) algorithm that accentuates and capitalizes on 3 additional immune mechanisms observed from the natural immune system. These mechanisms are associated to the phenomena exhibited by the antibodies in response to the concentration, location and type of foreign antigens. Bio-mimicking these observations empower EDC-AIRS algorithm with the ability to robustly adapt to the different density, distribution and characteristics exhibited by each data class. This provides competitive advantages for the algorithm to better characterize and learn the underlying pattern of the data. Experiments on four widely used benchmarking datasets demonstrated promising results -- outperforming several state-of-the-art classification algorithms evaluated. This signifies the importance of integrating these immune mechanisms as part of the learning process.","evolutionary computation, classification algorithm, artificial immune recognition system"
Conference Paper,"Al Mehedi Hasan M,Shin J,Das U,Yakin Srizon A",Identifying Prognostic Features for Predicting Heart Failure by Using Machine Learning Algorithm,Association for Computing Machinery,2021,https://doi.org/10.1145/3460238.3460245;http://dx.doi.org/10.1145/3460238.3460245,"Being one of the most common cardiovascular diseases, heart failure caused 40 million deaths worldwide in 2015. Previously, various studies have been conducted to predict heart failure at an early stage. Although each study has contributed and continued the development process, a significant breakthrough is still to be achieved. In this research, we focused on finding the features which can predict the death probability at an early stage due to heart failure. Firstly, the dataset was acquired and preprocessed. After that, two feature selection approaches, minimum redundancy maximum relevance, and recursive feature elimination based on Naïve Bayes were employed. Then, five machine learning classifiers, support vector machine, logistic regression, decision tree, naïve bayes and k-nearest neighbors, were utilized. Finally, the performance was measured in terms of accuracy, sensitivity, specificity, f1-score, MCC value and AUC value. It turned out two features which were selected by both feature selection techniques, achieved the highest overall accuracy of 80% for the decision tree classifier. Comparison with the previous best result of 58.5% proved that our proposed methodology can comment with much more certainty that Ejection Fraction and Serum Creatinine are indeed the two factors by which heart failure can be predicted.","Parameter Tuning, Cardiovascular Disease, Performance Measurement, Classification, Coronary Artery Disease, Feature Selection, Heart Attack"
Conference Paper,"Zheng K,Wang W,Gao J,Ngiam KY,Ooi BC,Yip WL",Capturing Feature-Level Irregularity in Disease Progression Modeling,Association for Computing Machinery,2017,https://doi.org/10.1145/3132847.3132944;http://dx.doi.org/10.1145/3132847.3132944,"Disease progression modeling (DPM) analyzes patients' electronic medical records (EMR) to predict the health state of patients, which facilitates accurate prognosis, early detection and treatment of chronic diseases. However, EMR are irregular because patients visit hospital irregularly based on the need of treatment. For each visit, they are typically given different diagnoses, prescribed various medications and lab tests. Consequently, EMR exhibit irregularity at the feature level. To handle this issue, we propose a model based on the Gated Recurrent Unit by decaying the effect of previous records using fine-grained feature-level time span information, and learn the decaying parameters for different features to take into account their different behaviours like decaying speeds under irregularity. Extensive experimental results in both an Alzheimer's disease dataset and a chronic kidney disease dataset demonstrate that our proposed model of capturing feature-level irregularity can effectively improve the accuracy of DPM.","healthcare, gated recurrent unit, time series, data analytics"
Conference Paper,"Zeng X,Lin S,Liu C",Transformer-Based Unsupervised Patient Representation Learning Based on Medical Claims for Risk Stratification and Analysis,Association for Computing Machinery,2021,https://doi.org/10.1145/3459930.3469519;http://dx.doi.org/10.1145/3459930.3469519,"The claims data, containing medical codes, services information, and incurred expenditure, can be a good resource for estimating an individual's health condition and medical risk level. In this study, we developed Transformer-based Multimodal AutoEncoder (TMAE), an unsupervised learning framework that can learn efficient patient representation by encoding meaningful information from the claims data. TMAE is motivated by the practical needs in healthcare to stratify patients into different risk levels for improving care delivery and management. Compared to previous approaches, TMAE is able to 1) model inpatient, outpatient, and medication claims collectively, 2) handle irregular time intervals between medical events, 3) alleviate the sparsity issue of the rare medical codes, and 4) incorporate medical expenditure information. We trained TMAE using a real-world pediatric claims dataset containing more than 600,000 patients and compared its performance with various approaches in two clustering tasks. Experimental results demonstrate that TMAE has superior performance compared to all baselines. Multiple downstream applications are also conducted to illustrate the effectiveness of our framework. The promising results confirm that the TMAE framework is scalable to large claims data and is able to generate efficient patient embeddings for risk stratification and analysis.","deep learning, claims data, risk stratification, representation learning"
Conference Paper,"Satyal S,Fletcher N,Ghosh S",Continuous Improvement of Medical Diagnostic Systems with Large Scale Patient Vignette Simulation,Association for Computing Machinery,2020,https://doi.org/10.1145/3340531.3412693;http://dx.doi.org/10.1145/3340531.3412693,"Differential diagnostic systems provide a ranked list of highly prob-able diseases given a patient's profile and symptoms. Evaluation of diagnostic algorithms in literature has been limited to a small set of hand-crafted patient vignettes. Testing with high coverage and gaining insights for improvements are challenging because of thesize and complexity of the knowledge base. Furthermore, scalable practical methodologies for evaluation and deployment of such systems are missing in the literature. Here, we address this challenge using a novel patient vignette simulation algorithm within an iterative clinician-in-the-loop methodology for semi-automatically evaluating and deploying medical diagnostic systems in production.We evaluate our algorithms and methodology through a case study of a real product and knowledge base curated by medical experts.We conduct multiple iterations of the methodology, report novel accuracy measures, and discuss insights from our experience in applying this method to production","clinical decision support, continuous improvement methodology, simulation, differential diagnosis, test automation, knowledge base, benchmarking"
Conference Paper,"Donahue K,Chouldechova A,Kenthapadi K",Human-Algorithm Collaboration: Achieving Complementarity and Avoiding Unfairness,Association for Computing Machinery,2022,https://doi.org/10.1145/3531146.3533221;http://dx.doi.org/10.1145/3531146.3533221,"Much of machine learning research focuses on predictive accuracy: given a task, create a machine learning model (or algorithm) that maximizes accuracy. In many settings, however, the final prediction or decision of a system is under the control of a human, who uses an algorithm’s output along with their own personal expertise in order to produce a combined prediction. One ultimate goal of such collaborative systems is complementarity: that is, to produce lower loss (equivalently, greater payoff or utility) than either the human or algorithm alone. However, experimental results have shown that even in carefully-designed systems, complementary performance can be elusive. Our work provides three key contributions. First, we provide a theoretical framework for modeling simple human-algorithm systems and demonstrate that multiple prior analyses can be expressed within it. Next, we use this model to prove conditions where complementarity is impossible, and give constructive examples of where complementarity is achievable. Finally, we discuss the implications of our findings, especially with respect to the fairness of a classifier. In sum, these results deepen our understanding of key factors influencing the combined performance of human-algorithm systems, giving insight into how algorithmic tools can best be designed for collaborative environments.",Not Found
Conference Paper,"Sambasivan N,Kapania S,Highfill H,Akrong D,Paritosh P,Aroyo LM","“Everyone Wants to Do the Model Work, Not the Data Work”: Data Cascades in High-Stakes AI",Association for Computing Machinery,2021,https://doi.org/10.1145/3411764.3445518;http://dx.doi.org/10.1145/3411764.3445518,"AI models are increasingly applied in high-stakes domains like health and conservation. Data quality carries an elevated significance in high-stakes AI due to its heightened downstream impact, impacting predictions like cancer detection, wildlife poaching, and loan allocations. Paradoxically, data is the most under-valued and de-glamorised aspect of AI. In this paper, we report on data practices in high-stakes AI, from interviews with 53 AI practitioners in India, East and West African countries, and USA. We define, identify, and present empirical evidence on Data Cascades—compounding events causing negative, downstream effects from data issues—triggered by conventional AI/ML practices that undervalue data quality. Data cascades are pervasive (92% prevalence), invisible, delayed, but often avoidable. We discuss HCI opportunities in designing and incentivizing data excellence as a first-class citizen of AI, resulting in safer and more robust systems for all.","application-domain experts, ML, high-stakes AI, USA, India, developers, Data, Kenya, Ghana, data politics, data cascades, data quality, AI, raters, Nigeria, Uganda, data collectors"
Conference Paper,"Wu J,Liu S,Xiao Z,Zhang F,Geng L",Region Segmentation of Retina OCT Image Layer Based on MS-UNet,Association for Computing Machinery,2022,https://doi.org/10.1145/3532213.3532288;http://dx.doi.org/10.1145/3532213.3532288,"The accurate segmentation of the retinal layer is a key link in the analysis of retinal OCT images. If the various tissue layers of the retina can be accurately segmented from the OCT image, it will help doctors make a more accurate and rapid diagnosis. Aiming at the high complexity of the features of each layer of the retinal OCT image and the low accuracy of the existing segmentation methods, this paper designs an improved U-Net model, MS-UNet (Multiscale Skip-UNet), which realizes the precise segmentation of seven retinal layers. To prevent problems such as over-fitting and gradient dispersion, this method uses the residual structure of deep over-parameterized convolution for feature extraction firstly. Then uses the multiscale skip structure to introduce global context information, and performs edge contour maintenance operations on the feature tensor. Finally, through a series of upsampling operations, the effective segmentation of each layer region is achieved. The experimental results proved that the method proposed in this paper improves MIoU by 1.39% compared with the method based on the original U-Net model. Compared with other semantic segmentation methods, this method effectively avoids the problems of layer edge blur and loss of details and has better segmentation performance.","Semantic segmentation, Retinal OCT image, Residual structure, Multiscale information, U-Net"
Journal Article,"Swedish T,Roesch K,Lee IH,Rastogi K,Bernstein S,Raskar R",EyeSelfie: Self Directed Eye Alignment Using Reciprocal Eye Box Imaging,Association for Computing Machinery,2015,https://doi.org/10.1145/2766970;http://dx.doi.org/10.1145/2766970,"Eye alignment to the optical system is very critical in many modern devices, such as for biometrics, gaze tracking, head mounted displays, and health. We show alignment in the context of the most difficult challenge: retinal imaging. Alignment in retinal imaging, even conducted by a physician, is very challenging due to precise alignment requirements and lack of direct user eye gaze control. Self-imaging of the retina is nearly impossible.We frame this problem as a user-interface (UI) challenge. We can create a better UI by controlling the eye box of a projected cue. Our key concept is to exploit the reciprocity, ""If you see me, I see you"", to develop near eye alignment displays. Two technical aspects are critical: a) tightness of the eye box and (b) the eye box discovery comfort. We demonstrate that previous pupil forming display architectures are not adequate to address alignment in depth. We then analyze two ray-based designs to determine efficacious fixation patterns. These ray based displays and a sequence of user steps allow lateral (x, y) and depth (z) wise alignment to deal with image centering and focus. We show a highly portable prototype and demonstrate the effectiveness through a user study.","retina, head mounted display, fundus photography, human computer interaction"
Conference Paper,Wang L,Evaluation of COVID-19 Epidemic Based on SIR Model,Association for Computing Machinery,2020,https://doi.org/10.1145/3429889.3429893;http://dx.doi.org/10.1145/3429889.3429893,"Based on the SIR model, this article evaluates the efficiency of certain measures regarding new coronavirus (COVID-19). The data from the Provincial Health Committee and WHO are used to establish SIR model and draw graphs for evaluation. Simulations and pictures of SIR-F model are cited to predict the efficiency of certain measures. This article analyzes how the epidemic was regulated in different regions. The result shows that it is necessary to introduce strict regulations and take immediate actions so as to reduce the further spread of the virus.","SIR model, COVID-19, evaluation"
Conference Paper,"Vassilakis N,Garneli V,Patiniotis K,Deliyannis I,Chorianopoulos K",Adapting a Classic Platform Video Game to the Carbohydrate Counting Method for Insulin-Dependent Diabetics,Association for Computing Machinery,2019,https://doi.org/10.1145/3342428.3342681;http://dx.doi.org/10.1145/3342428.3342681,"Digital games designed for children and adolescents in the Diabetics Education (DE) context aim at positively influencing diabetics' behavior or teaching DE knowledge and skills. Previous work has not considered playful learning of difficult content, such as the Carbohydrate Counting Method, which involves counting the number of carbohydrate grams in a meal and matching that to the appropriate dose of insulin in order to manage the blood glucose levels. Sugar Mario was designed to have a familiar and simple gameplay based on classical platform video games, such as Super Mario, Donkey Kong, and other similar games. The carbohydrate counting method was seamlessly integrated in the gameplay in order to provide an educating, entertaining, and compelling experience to diabetics of all ages, even family members and friends. Our implementation suggests that a classic and engaging platform video game is malleable to the infusion of serious content without significant dilution of the gameplay. Notably, a diabetic person has designed Sugar Mario and the source code has been shared online for inspection and contribution by interested parties.","Serious Game, Carbohydrate Counting Method, Diabetes Education, Health Games"
Conference Paper,"Zhou S,Sheng H,Ma J,Han X",Review of the Application of Blockchain Technology in Traditional Chinese Medicine Field,Association for Computing Machinery,2020,https://doi.org/10.1145/3429889.3429932;http://dx.doi.org/10.1145/3429889.3429932,"The concept of blockchain has received a lot of attention and research since it was first proposed in 2008. With the popularization and development of blockchain technology, its huge development opportunities in the field of Traditional Chinese Medicine(TCM) have gradually revealed. This article studies the development path and technical characteristics of blockchain, analyzes the current research status of application of blockchain technology in medical field. It also summarizes the application and future research directions of blockchain technology in four typical TCM fields: TCM big data safe storage, Chinese medicine traceability, TCM electronic medical record privacy protection, TCM cloud health system and wearable devices. It is hoped that this paper can provide useful reference for relevant research.","Data Safe Storage, Electronic Medical Record, TCM, Chinese Medicine Traceability, Cloud Health, Privacy Protection, Blockchain"
Book,Not Found,ICMHI '22: Proceedings of the 6th International Conference on Medical and Health Informatics,Association for Computing Machinery,2022,Not Found,Not Found,Not Found
Conference Paper,St. Jean B,"Participant Reactivity in a Longitudinal Mixed-Method Study of the Information Behavior of People with Type 2 Diabetes: Research Validity vs. ""Street Validity""",American Society for Information Science,2013,Not Found,"Participant reactivity -- a phenomenon in which the responses and/or behaviors of study participants are affected by their awareness that they are part of a study -- is often deemed to be a potential threat to the research validity of a study's findings. However, a growing number of studies report that research processes that engender participant reactivity may actually lead to important benefits both for participants (e.g., therapeutic benefits) and researchers (e.g., deeper understandings and more relevant and actionable findings). This mutually beneficial situation can help to maximize a different type of validity termed ""street validity"" by Greenwood (as cited in Boudah & Lenz, 2000; 2003), which directly relates to research impact.This paper reports findings from a longitudinal mixed-method investigation of the information behavior of people with type 2 diabetes, focusing on participants' self-reports regarding whether/how they felt that participating in the study had influenced (or will influence) their behavior. Many participants described specific ways in which they found their participation helpful. For example, they reported that it led to decreased denial, increased self-awareness, and improved motivation to look for and make use of diabetes-related information. This paper explores the potential trade-off between research validity and street validity within a qualitative study and posits that, as was the case with this study, important lessons can be learned as a result of directly questioning participants about whether/how their participation in the study influenced them and that these lessons can perhaps be implemented within the context of applying the research findings in assisting other people from the study population.","Hawthorne effect, information needs, consumer health information behavior, information seeking, participant reactivity"
Conference Paper,"Zhao JC,Cheung NM,Sosa R,Koh DC",Design Self-Diagnosis Applications for Non-Patients,Association for Computing Machinery,2015,https://doi.org/10.1145/2702613.2732865;http://dx.doi.org/10.1145/2702613.2732865,"Self-diagnosis applications refer to a type of accessible healthcare systems that help users detect illness at the early stages. Unlike self-monitoring applications, users of self-diagnosis applications are non-patients - people who do not have the explicit awareness of their potential diseases or health problems. It is not clear how to incentivize usage, how to best present results, and how to sustain habit formation for periodic long-term use. We conduct an exploratory case study to investigate the special design challenges of such systems. From our findings, we recommend self-diagnosis applications should: 1) be designed with less perceived harmfulness; 2) state the risk of diagnosed disease explicitly; 3) show the implicit diagnosis result with percentage; and 4) present the rationale behind the diagnosis result.","design challenges, self-diagnosis applications, tam, mobile health, preventive care"
Conference Paper,"Fu T,Gao T,Xiao C,Ma T,Sun J",PEARL: Prototype Learning via Rule Learning,Association for Computing Machinery,2019,https://doi.org/10.1145/3307339.3342159;http://dx.doi.org/10.1145/3307339.3342159,"Deep neural networks have demonstrated promising prediction performance on many health analytics tasks. However, the interpretability of the deep models is often lacking. In comparison, classical interpretable models such as decision rule learning do not lead to the same level of accuracy as deep neural networks (DNN) and can also be too complex to interpret (e.g., due to large tree depths). In this work, we propose Prototype LeArNing via Rule Learning (PEARL), which iteratively constructs a decision rule list to guide a neural network to learn representative prototypes that can be explained by the associated rules. The resulting prototype neural network inherits both the prediction power of DNNs and interpretability associated with rules, thus can provide accurate and interpretable predictions. Evaluated on real world health datasets, PEARL demonstrates state-of-the-art accuracy to various DNN baselines and interpretable results that are simpler than standard decision trees can provide.","deep learning, interpretable machine learning, healthcare"
Conference Paper,"Siddiqui S,Khan AA,Dev K,Dey I",Integrating Federated Learning with IoMT for Managing Obesity in Smart City,Association for Computing Machinery,2021,https://doi.org/10.1145/3477084.3484950;http://dx.doi.org/10.1145/3477084.3484950,"Wearable and ambient sensors have been increasingly used for unique remote health monitoring applications. In this work, we propose an Internet of Medical Things (IoMT) architecture based on automated sensing of physiological and ambient parameters, to detect the risk of obesity in individuals. Timely assessment of obesity risk could improve the quality of life for patients in future as it would help to reduce the probability of chronic diseases such as diabetes. The architecture uses Body Mass Index (BMI) of patient as an input parameter which is a key measure to indicate obesity. Furthermore, we also propose to integrate the proposed IoMT architecture with the emerging scheme of Federated Learning (FL). FL has been used to recommend the appropriate fitness routine for the users. MATLAB simulations for the proposed FL algorithm has been performed and the variations in the loss functions have been observed.","IoMT, fitness, body mass index, federated learning, ambient sensors, wearable devices"
Journal Article,"Naitzat G,Zhitnikov A,Lim LH",Topology of Deep Neural Networks,JMLR.org,2022,Not Found,"We study how the topology of a data set M = Ma∪Mb ⊆ ℝd, representing two classes a and b in a binary classification problem, changes as it passes through the layers of a well-trained neural network, i.e., one with perfect accuracy on training set and near-zero generalization error (≈ 0:01%). The goal is to shed light on two mysteries in deep neural networks: (i) a nonsmooth activation function like ReLU outperforms a smooth one like hyperbolic tangent; (ii) successful neural network architectures rely on having many layers, even though a shallow network can approximate any function arbitrarily well. We performed extensive experiments on the persistent homology of a wide range of point cloud data sets, both real and simulated. The results consistently demonstrate the following: Neural networks operate by changing topology, transforming a topologically complicated data set into a topologically simple one as it passes through the layers. No matter how complicated the topology of M we begin with, when passed through a well-trained neural network f : ℝd → ℝp, there is a vast reduction in the Betti numbers of both components Ma and Mb; in fact they nearly always reduce to their lowest possible values: βk(f(Mi))= 0 for k ≥ 1 and β0(f(Mi)) = 1, i = a, b. The reduction in Betti numbers is significantly faster for ReLU activation than for hyperbolic tangent activation as the former defines nonhomeomorphic maps that change topology, whereas the latter defines homeomorphic maps that preserve topology. Shallow and deep networks transform data sets differently--a shallow network operates mainly through changing geometry and changes topology only in its final layers, a deep one spreads topological changes more evenly across all layers.","persistent homology, topological complexity, Betti numbers, topology change, neural networks"
Journal Article,"Teddy-Ang S,Toh A",AI Singapore: Empowering a Smart Nation,Association for Computing Machinery,2020,https://doi.org/10.1145/3378416;http://dx.doi.org/10.1145/3378416,Not Found,Not Found
Conference Paper,"Desai PM,Mitchell EG,Hwang ML,Levine ME,Albers DJ,Mamykina L",Personal Health Oracle: Explorations of Personalized Predictions in Diabetes Self-Management,Association for Computing Machinery,2019,https://doi.org/10.1145/3290605.3300600;http://dx.doi.org/10.1145/3290605.3300600,"The increasing availability of health data and knowledge about computationally modeling human physiology opens new opportunities for personalized predictions in health. Yet little is known about how individuals interact and reason with personalized predictions. To explore these questions, we developed a smartphone app, GlucOracle, that uses self-tracking data of individuals with type 2 diabetes to generate personalized forecasts for post-meal blood glucose levels. We pilot-tested GlucOracle with two populations: members of an online diabetes community, knowledgeable about diabetes and technologically savvy; and individuals from a low socio-economic status community, characterized by high prevalence of diabetes, low literacy and limited experience with mobile apps. Individuals in both communities engaged with personal glucose forecasts and found them useful for adjusting immediate meal options, and planning future meals. However, the study raised new questions as to appropriate time, form, and focus of forecasts and suggested new research directions for personalized predictions in health.","predictive modeling, personal informatics, diabetes, technologies for health, self-care, self-management"
Conference Paper,"Silva LC,Machado VP,de Melo Sousa Veras R,de Sá Urtiga Aita KM,Monte SJ,Aldeman NL",A Hybrid Descriptor to Improve Kidney Pathologies Classification,Association for Computing Machinery,2022,https://doi.org/10.1145/3477314.3507321;http://dx.doi.org/10.1145/3477314.3507321,"The importance of glomerular function in kidney physiology characterizes glomerular diseases as the main problem in nephrology. So finding and classifying glomerular disorders are fundamental steps for diagnosing many kidney diseases. This paper conducted an extensive study to determine the best set of features for glomerular image representation. Our feature extraction methodology, which includes clinical data, texture, and global descriptors, resulted in 8486 features. Besides, we compared four classifiers to propose a method that helps the specialist define a renal pathology diagnosis. The proposed method achieved an accuracy of 98.46% and a Kappa index of 98.42% using the Random Forest Classifier. We concluded that a combination of clinical data and global image features facilitates accurate disease classification.","renal pathologies, machine learning, random forest, svm, decision tree, image descriptors, clinical data, mlp"
Conference Paper,"Lamiae E,Fatiha E,Mohammed B,Hicham GT",A Study on Smart Home for Medical Surveillance: Contribution to Smart Healthcare Paradigm,Association for Computing Machinery,2019,https://doi.org/10.1145/3368756.3368994;http://dx.doi.org/10.1145/3368756.3368994,"Nowadays, healthcare and human well-being in general have been profoundly flustered by the current novel technologies that have created a fresh ground for e-health and smart healthcare innovations. The key benefit of e-health and smart healthcare is the appropriate utilization, management and analysis of generated data from trending technologies like sensors, wearables, smartphones, Multi-Agent Systems (MAS) and Internet of Things (IoT) to improve people's quality of life. Hence, a smart home conception following specific architectures and using the appropriate technologies of medical surveillance would form an essential aspect for the smart healthcare paradigm. Accordingly, an optimal design and architecture for an intelligent home and an effective intelligent healthcare would consider a resilient balance of IoT, MAS and an adequate machine learning model for human behavior analysis. In this paper, a new smart home design for medical surveillance is proposed in order to contribute to the expansion of the number of smart healthcare users and providers on a winner-winner relationship that promotes individuals comfort and prosperity and drives-up the Information Technology contributions and business.","IoT, multi agent system, medical surveillance, artificial intelligence, smart healthcare, sensor, smart home"
Conference Paper,"Wang X,Wang H,Wu D,Wang Y,Zhou R",A Fuzzy Consensus Clustering Based Undersampling Approach for Class Imbalanced Learning,Association for Computing Machinery,2020,https://doi.org/10.1145/3377713.3377733;http://dx.doi.org/10.1145/3377713.3377733,"The class imbalance problem is widely studied in the machine learning community, it is present in many real world applications such as spam filtering, anomaly detection and medical diagnosis. In this paper, we propose an adaptive fuzzy c-means based consensus clustering approach for class imbalanced learning, the number of base clusters are determined through a balancing optimization approach while the initial starting points for each base partition is determined in a sequential manner. The final partition is constructed via the co-association matrix. Finally, the center samples in the final cluster partition are selected to form the reduced data set with the minority class samples. In this way, the most representative majority class samples are chosen while the boundary samples are eliminated. The validity of the proposed method is tested with real world data sets which demonstrates superior performance compared to other clustering based re-sampling schemes. Thus, the fuzzy consensus clustering based under-sampling method can be used for real life imbalanced problems.","Classification, Undersampling, Fuzzy c-means, Consensus clustering, Imbalanced learning"
Conference Paper,"Neuvirth H,Ozery-Flato M,Hu J,Laserson J,Kohn MS,Ebadollahi S,Rosen-Zvi M",Toward Personalized Care Management of Patients at Risk: The Diabetes Case Study,Association for Computing Machinery,2011,https://doi.org/10.1145/2020408.2020472;http://dx.doi.org/10.1145/2020408.2020472,"Chronic diseases constitute the leading cause of mortality in the western world, have a major impact on the patients' quality of life, and comprise the bulk of healthcare costs. Nowadays, healthcare data management systems integrate large amounts of medical information on patients, including diagnoses, medical procedures, lab test results, and more. Sophisticated analysis methods are needed for utilizing these data to assist in patient management and to enhance treatment quality at reduced costs. In this study, we take a first step towards better disease management of diabetic patients by applying state-of-the art methods to anticipate the patient's future health condition and to identify patients at high risk. Two relevant outcome measures are explored: the need for emergency care services and the probability of the treatment producing a sub-optimal result, as defined by domain experts. By identifying the high-risk patients our prediction system can be used by healthcare providers to prepare both financially and logistically for the patient needs. To demonstrate a potential downstream application for the identified high-risk patients, we explore the association between the physician treating these patients and the treatment outcome, and propose a system that can assist healthcare providers in optimizing the match between a patient and a physician.Our work formulates the problem and examines the performance of several learning models on data from several thousands of patients. We further describe a pilot system built on the results of this analysis. We show that the risk for the two considered outcomes can be evaluated from patients' characteristics and that features of the patient-physician match improve the prediction accuracy for the treatment's success. These results suggest that personalized medicine can be valuable for high risk patients and raise interesting questions for future improvements.","survival analysis, machine learning"
Journal Article,"Sharma P,Namasudra S,Chilamkurti N,Kim BG,Gonzalez Crespo R",Blockchain-Based Privacy Preservation for IoT-Enabled Healthcare System,Association for Computing Machinery,2022,https://doi.org/10.1145/3577926;http://dx.doi.org/10.1145/3577926,"Blockchain technology provides a secure and reliable platform for managing data in various application areas, such as supply chain management, multimedia, financial sector, food sector, Internet of Things (IoT), healthcare, and many more. The recent emergence of blockchain with IoT provides significant growth in the healthcare industry to improve security, privacy, efficiency, and transparency with more business opportunities. Nevertheless, conventional healthcare schemes suffer from various security attacks like collusion, phishing, masquerade, etc. Therefore, a privacy-preserving Distributed Application (DA) is proposed in this paper using blockchain technology to create and maintain healthcare certificates. Here, the distributed application provides an interface between the blockchain network and system objects like healthcare centers, verifiers, and regular authorities to generate and issue medical documents. In addition, it also ensures security by specifying rules using various smart contracts. To evaluate the performance of the proposed scheme, various experimental tests are conducted using the Etherscan tool for measuring operation cost, latency, and processing time. Here, the efficiency of the proposed system is also compared to the existing systems in terms of latency, throughput, and response time. The experimental results and comparative analysis show that the proposed work is more efficient than the existing techniques.","Smart Contract, Healthcare Certificate, Ethereum, Distributed Application"
Journal Article,"Sarwar T,Seifollahi S,Chan J,Zhang X,Aksakalli V,Hudson I,Verspoor K,Cavedon L",The Secondary Use of Electronic Health Records for Data Mining: Data Characteristics and Challenges,Association for Computing Machinery,2022,https://doi.org/10.1145/3490234;http://dx.doi.org/10.1145/3490234,"The primary objective of implementing Electronic Health Records (EHRs) is to improve the management of patients’ health-related information. However, these records have also been extensively used for the secondary purpose of clinical research and to improve healthcare practice. EHRs provide a rich set of information that includes demographics, medical history, medications, laboratory test results, and diagnosis. Data mining and analytics techniques have extensively exploited EHR information to study patient cohorts for various clinical and research applications, such as phenotype extraction, precision medicine, intervention evaluation, disease prediction, detection, and progression. But the presence of diverse data types and associated characteristics poses many challenges to the use of EHR data. In this article, we provide an overview of information found in EHR systems and their characteristics that could be utilized for secondary applications. We first discuss the different types of data stored in EHRs, followed by the data transformations necessary for data analysis and mining. Later, we discuss the data quality issues and characteristics of the EHRs along with the relevant methods used to address them. Moreover, this survey also highlights the usage of various data types for different applications. Hence, this article can serve as a primer for researchers to understand the use of EHRs for data mining and analytics purposes.","health analytics, EHR, data types, data challenges, data characteristic, data mining"
Conference Paper,"Ma M,Zhao X,Li Y,Jia H,Wang X,Shi Y,Cheng F",Accurate Classification of Tumor Text Based on Attention Mechanism and Transfer Learning,Association for Computing Machinery,2020,https://doi.org/10.1145/3433996.3434362;http://dx.doi.org/10.1145/3433996.3434362,"With the increase in the number of electronic medical records, precise classification of medical records can be use to accurately diagnose diseases. In medical texts, there are differences in the number of texts of different diseases, especially for specific diseases and a small number of samples have brought great challenges to medical text classification. In response to this problem, this paper proposes an accurate text classification model base on transfer learning combined with attention mechanism neural network, and finally obtains accurate category text through two-step classification. The model first uses the attention mechanism long-term and short-term cyclic neural network to extract the overall tumor sample from the mass of unbalanced medical record texts through the common characteristics of the tumor medical record, and uses the similarity between diseases to combine with the convolutional neural network through migration learning. The characteristics of each type of tumor disease are migrate to achieve the effect of precise classification training. The precise training model is used to finally realize the precise classification of tumor diseases. The model was tested on a private tumor medical data set, and the results showed that the accuracy of the tumor data set (precision) was increased by 5% compare to the average of the baseline optimal classification model. The increase in accuracy is important for accurate classification significance.","Transfer learning, Convolutional neural network, Accurate classification, Bidirectional attention long-short term neural network"
Conference Paper,Chi Y,Application and Research of Deep Mining of Health Medical Big Data Based on Internet of Things,Association for Computing Machinery,2022,https://doi.org/10.1145/3495018.3495462;http://dx.doi.org/10.1145/3495018.3495462,"Traditional data mining algorithms are mostly difficult to handle large data sets, but need to manage big data and discover hidden knowledge. Therefore, the combination of data mining algorithms and IoT technology is the development trend of data processing in the future, but because of the difficulty, not all algorithms can be implemented on the cloud platform, so the research results are not enough. The core idea of cloud computing is architecture. All data mining algorithm improvement strategies need to be designed according to the characteristics of the architecture, and each part must implement specific functions. It is difficult or impossible to implement an algorithm that cannot be decomposed into the above form in the architecture. With the widespread application of IoT technology, a large number of unstructured, distributed and even data mining requirements in mobile devices pose serious challenges to existing data mining technologies. How to use cloud computing technology to achieve large-scale distributed data collection, transmission and mining has become an important research direction. This paper investigates some health care big data, combines the Internet of Things cloud data platform, and introduces the traditional association rules algorithm and its interest level in mining technology. On this basis, the improved algorithm is improved and compared with other traditional algorithms. Establish a simulation platform to implement algorithms and mine training data. It proves that the improved algorithm has lower spatial complexity and faster processing rate in data mining, and analyzes the data mining technology in health medical data.",Not Found
Conference Paper,"Ghaisani FD,Wasito I,Faturrahman M,Mufidah R",Deep Belief Networks and Bayesian Networks for Prognosis of Acute Lymphoblastic Leukemia,Association for Computing Machinery,2017,https://doi.org/10.1145/3127942.3127947;http://dx.doi.org/10.1145/3127942.3127947,"Cancer is one of main non-communicable diseases. Acute Lymphoblastic Leukemia (ALL), a type of white blood cancer, is one of the most common pediatric cancers. Analysis of cancer prognosis is necessary to determine the proper treatment for each patient. However, cancer data analysis is challenging because multiple risk factors may influence the prognosis of cancer, including gene and clinical condition of patient. This study aims to develop prediction model for cancer prognosis using clinical and gene expression (microarray) data. In this research, manifold learning is applied to microarray data to reduce its dimension, then two Deep Belief Network (DBN) models for both clinical and microarray data are trained separately. Probabilities obtained from Clinical DBN model and Microarray DBN model are integrated using softmax nodes on Bayesian Network structure. Based on various experiments, the best integration model obtained is DBN+BN 32 with prediction accuracy 84.2% for 2-years survival, 70.2% for 3-years, 68.4% for 4-years, and 73.7% for 5-years. This prediction model can be used in cancer analysis and help doctor to decide proper treatment for patient.","data integration, bayesian network, microarray, acute lymphoblastic leukemia, Cancer, leukemia, dimensionality reduction, manifold learning, deep belief network"
Conference Paper,"Lu X,Zhang A,Gunter CA,Fabbri D,Liebovitz D,Malin B",Discovering de Facto Diagnosis Specialties,Association for Computing Machinery,2015,https://doi.org/10.1145/2808719.2808720;http://dx.doi.org/10.1145/2808719.2808720,"In health care institutions, medical specialty information may be lacking or inaccurate. Diagnosis histories offer information on which medical specialties may exist in practice, regardless of whether they have official codes. We refer to such specialties that are predicted with high certainty by diagnosis histories de facto diagnosis specialties. We aim to discover de facto diagnosis specialties under a general discovery--evaluation framework. Specifically, we employ a semi-supervised learning model and an unsupervised learning method for discovery. We further employ four supervised learning models for evaluation. We use one year of diagnosis histories from a major medical center, which consists of two data sets: one is fine-grained and the other is general. The semi-supervised learning model discovers a specialty for Breast Cancer on the fine-grained data set; while the unsupervised learning method confirms this discovery and suggests another specialty for Obesity on the larger general data set. The evaluation results reinforce that these two specialties can be recognized accurately by supervised learning models in comparison with 12 common diagnosis specialties defined by the Health Care Provider Taxonomy Code Set.","medical informatics, electronic health record, data mining"
Book Chapter,"Hornung R,Chen N,van der Smagt P",Early Integration for Movement Modeling in Latent Spaces,Association for Computing Machinery and Morgan & Claypool,2019,https://doi.org/10.1145/3233795.3233805;http://dx.doi.org/10.1145/3233795.3233805,Not Found,Not Found
Conference Paper,"Akyol E,Cabral Ramos Mota RC,Somanath S",DiaFit: Designing Customizable Wearables for Type 1 Diabetes Monitoring,Association for Computing Machinery,2021,https://doi.org/10.1145/3411763.3451716;http://dx.doi.org/10.1145/3411763.3451716,"Research has highlighted the need for customization of health-related technologies. However, few studies have examined its impact on wearable healthcare devices. We present a co-design study where we learned about people’s preferences and ideas for customized glucose monitors. We worked with people who have Type 1 Diabetes and learned about their challenges with current glucose monitors and ways to address them in physical product design. To understand people’s perception towards using customizable glucose monitors, we prototyped one simple example toolkit, DiaFit, consisting of multiple modular accessories for assembling glucose monitors. We invited participants to try DiaFit and learned about their acceptability of customizable glucose monitors. We conclude with preliminary lessons learned about customization as an approach to addressing individual differences in the context of health technologies.","customization, design for health, wearables"
Journal Article,"Antunes RS,André da Costa C,Küderle A,Yari IA,Eskofier B",Federated Learning for Healthcare: Systematic Review and Architecture Proposal,Association for Computing Machinery,2022,https://doi.org/10.1145/3501813;http://dx.doi.org/10.1145/3501813,"The use of machine learning (ML) with electronic health records (EHR) is growing in popularity as a means to extract knowledge that can improve the decision-making process in healthcare. Such methods require training of high-quality learning models based on diverse and comprehensive datasets, which are hard to obtain due to the sensitive nature of medical data from patients. In this context, federated learning (FL) is a methodology that enables the distributed training of machine learning models with remotely hosted datasets without the need to accumulate data and, therefore, compromise it. FL is a promising solution to improve ML-based systems, better aligning them to regulatory requirements, improving trustworthiness and data sovereignty. However, many open questions must be addressed before the use of FL becomes widespread. This article aims at presenting a systematic literature review on current research about FL in the context of EHR data for healthcare applications. Our analysis highlights the main research topics, proposed solutions, case studies, and respective ML methods. Furthermore, the article discusses a general architecture for FL applied to healthcare data based on the main insights obtained from the literature review. The collected literature corpus indicates that there is extensive research on the privacy and confidentiality aspects of training data and model sharing, which is expected given the sensitive nature of medical data. Studies also explore improvements to the aggregation mechanisms required to generate the learning model from distributed contributions and case studies with different types of medical data.","Electronic health records, systematic review, federated learning"
Journal Article,"Hossain ME,Khan A,Moni MA,Uddin S",Use of Electronic Health Data for Disease Prediction: A Comprehensive Literature Review,IEEE Computer Society Press,2021,https://doi.org/10.1109/TCBB.2019.2937862;http://dx.doi.org/10.1109/TCBB.2019.2937862,"Disease prediction has the potential to benefit stakeholders such as the government and health insurance companies. It can identify patients at risk of disease or health conditions. Clinicians can then take appropriate measures to avoid or minimize the risk and in turn, improve quality of care and avoid potential hospital admissions. Due to the recent advancement of tools and techniques for data analytics, disease risk prediction can leverage large amounts of semantic information, such as demographics, clinical diagnosis and measurements, health behaviours, laboratory results, prescriptions and care utilisation. In this regard, electronic health data can be a potential choice for developing disease prediction models. A significant number of such disease prediction models have been proposed in the literature over time utilizing large-scale electronic health databases, different methods, and healthcare variables. The goal of this comprehensive literature review was to discuss different risk prediction models that have been proposed based on electronic health data. Search terms were designed to find relevant research articles that utilized electronic health data to predict disease risks. Online scholarly databases were searched to retrieve results, which were then reviewed and compared in terms of the method used, disease type, and prediction accuracy. This paper provides a comprehensive review of the use of electronic health data for risk prediction models. A comparison of the results from different techniques for three frequently modelled diseases using electronic health data was also discussed in this study. In addition, the advantages and disadvantages of different risk prediction models, as well as their performance, were presented. Electronic health data have been widely used for disease prediction. A few modelling approaches show very high accuracy in predicting different diseases using such data. These modelling approaches have been used to inform the clinical decision process to achieve better outcomes.",Not Found
Conference Paper,"Lee HN,Uddin S,Ashok V",TableView: Enabling Efficient Access to Web Data Records for Screen-Magnifier Users,Association for Computing Machinery,2020,https://doi.org/10.1145/3373625.3417030;http://dx.doi.org/10.1145/3373625.3417030,"People with visual impairments typically rely on screen-magnifier assistive technology to interact with webpages. As screen-magnifier users can only view a portion of the webpage content in an enlarged form at any given time, they have to endure an inconvenient and arduous process of repeatedly moving the magnifier focus back-and-forth over different portions of the webpage in order to make comparisons between data records, e.g., comparing the available flights in a travel website based on their prices, durations, etc. To address this issue, we designed and developed TableView, a browser extension that leverages a state-of-the art information extraction method to automatically identify and extract data records and their attributes in a webpage, and subsequently presents them to a user in a compactly arranged tabular format that needs significantly less screen space compared to that currently occupied by these items in the page. This way, TableView is able to pack more items within the magnifier focus, thereby reducing the overall content area for panning, and hence making it easy for screen-magnifier users to compare different items before making their selections. A user study with 16 low vision participants showed that with TableView, the time spent on panning the data records in webpages was significantly reduced by 72.9% (avg.) compared to that with just a screen magnifier, and 66.5% compared to that with a screen magnifier using a space compaction method.","web accessibility, usability, screen magnifier, low vision"
Conference Paper,"Vasquez-Gonzaga H,Gutierrez-Cardenas J",Comparison of Supervised Learning Models for the Prediction of Coronary Artery Disease,Association for Computing Machinery,2021,https://doi.org/10.1145/3480433.3480451;http://dx.doi.org/10.1145/3480433.3480451,"Cardiovascular diseases and Coronary Artery Disease (CAD) are the leading causes of mortality among people of different ages and conditions. The use of different and not so invasive biomarkers to detect these types of diseases joined with Machine Learning techniques seems promising for early detection of these illnesses. In the present work, we have used the Sani Z-Alizadeh dataset, which comprises a set of different medical features extracted with not invasive methods and used with different machine learning models. The comparisons performed showed that the best results were using a complete set and a subset of features as input for the Random Forest and XGBoost algorithms. Considering the results obtained, we believe that using a complete set of features gives insights that the features should also be analyzed by considering the medical advances and findings of how these markers influence a CAD disease's presence.","classification algorithms, Boosting, Bagging, Regression methods, Coronary cardiopathy"
Conference Paper,"Shi T,Rakesh V,Wang S,Reddy CK",Document-Level Multi-Aspect Sentiment Classification for Online Reviews of Medical Experts,Association for Computing Machinery,2019,https://doi.org/10.1145/3357384.3357828;http://dx.doi.org/10.1145/3357384.3357828,"In the era of big data, online doctor review platforms, which enable patients to give feedback to their doctors, have become one of the most important components in healthcare systems. On one hand, they help patients to choose their doctors based on the experience of others. On the other hand, they help doctors to improve the quality of their service. Moreover, they provide important sources for us to discover common concerns of patients and existing problems in clinics, which potentially improve current healthcare systems. In this paper, we systematically investigate the dataset from one of such review platform, namely, ratemds.com, where each review for a doctor comes with an overall rating and ratings of four different aspects. A comprehensive statistical analysis is conducted first for reviews, ratings, and doctors. Then, we explore the content of reviews by extracting latent topics related to different aspects with unsupervised topic modeling techniques. As the core component of this paper, we propose a multi-task learning framework for the document-level multi-aspect sentiment classification. This task helps us to not only recover missing aspect-level ratings and detect inconsistent rating scores but also identify aspect-keywords for a given review based on ratings. The proposed model takes both features of doctors and aspect-keywords into consideration. Extensive experiments have been conducted on two subsets of ratemds dataset to demonstrate the effectiveness of the proposed model.","attention mechanism, online reviews, sentiment classification, multi-aspect, multi-task learning"
Conference Paper,"Shahrzad H,Hodjat B,Miikkulainen R",Evolving Explainable Rule Sets,Association for Computing Machinery,2022,https://doi.org/10.1145/3520304.3534023;http://dx.doi.org/10.1145/3520304.3534023,"Most AI systems work like black boxes tasked with generating reasonable outputs for given inputs. Many domains, however, have explainablity and trustworthiness requirements not fulfilled by these approaches. Various methods exist to analyze or interpret black-box models post training. When it comes down to sensitive domains in which there is a mandate for white-box models, a better choice would be to use transparent models. In this work, we present a method which evolves explainable rule-sets using inherently transparent ordinary logic to make models. We showcase some sample domains we tackled and discuss their major desirable properties like bias detection, knowledge discovery, and modifiablity, to name a few.","rule-set evolution, genetic algorithms, explainable AI, XAI"
Conference Paper,Luo X,Analyzing the Correlations between the Uninsured and Diabetes Prevalence Rates in Geographic Regions in the United States,IEEE Press,2017,https://doi.org/10.1109/CHASE.2017.58;http://dx.doi.org/10.1109/CHASE.2017.58,"The increasing prevalence of diagnosed diabetes has drawn attentions of researchers in recently years. Research has been done in finding the correlations between diabetes prevalence with socioeconomic factors, obesity, social behaviors and so on. Since 2010, diabetes preventive services have been covered under health insurance plans in order to reduce diabetes burden and control the increasing of diabetes prevalence. In this study, a hierarchical clustering model is proposed by using Expectation-Maximization algorithm to investigate the correlations between the uninsured and diabetes prevalence rates in 3142 counties in United States for years from 2009 to 2013. The results identified geographic disparities in the uninsured and diabetes prevalence rates of individual years and over consecutive years.",Not Found
Conference Paper,"Sorce S,Gentile V,Cascio D,Giuliano A,Tabacchi ME,Taormina V,Tegolo D,Valenti C,Raso G",A REST-Based Framework to Support Non-Invasive and Early Coeliac Disease Diagnosis,Association for Computing Machinery,2019,https://doi.org/10.1145/3345252.3345296;http://dx.doi.org/10.1145/3345252.3345296,"The health sector has traditionally been one of the early adopters of databases, from the most simple Electronic Health Record (formerly Computer-Based Patient Record) systems in use in general practice, hospitals and intensive care units to big data, multidata based systems used to support diagnosis and care decisions. In this paper we present a framework to support non-invasive and early diagnosis of coeliac disease. The proposed framework makes use of well-known technologies and techniques, both hardware and software, put together in a novel way. The main goals of our framework are: (1) providing users with a reliable and fast repository of a large amount of data; (2) to make such repository accessible by means of a suitable API in multiple modes, such as intuitive web-based or mobile visual interfaces; (3) to allow for data processing and analysis, as a basis for decision support systems.","coeliac disease diagnosis support, Health care systems, Databases"
Conference Paper,"Murugadas D,Sizov S",Do It Yourself Diagnosis: A Study on Acquiring Health-Related Information Online,Association for Computing Machinery,2016,https://doi.org/10.1145/2908131.2908147;http://dx.doi.org/10.1145/2908131.2908147,"The information age has influenced many aspects of the society, one of which is the health sector. In this work, it is investigated to what extent people acquire health-related information and if information literacy and medical expertise influence the search procedure and outcome. Therefore, to gather insights, domain experts and people who engage in searches for health-related information were interviewed. Using the resultant information, a study was conducted in which the participants were characterized regarding search behavior, medical expertise, and health consciousness, and were subsequently asked to conduct a search based on a description of symptoms a fictional character shows.It became apparent that health-related information in particular is overall viewed more critically than other information on the web. As expected, the participants with medical expertise performed better in the practical task in the second part of the study than the other case groups. The information literacy on the other hand did not have an impact on the accuracy of the diagnosis itself bur rather on the search strategy.","search strategy, online disease diagnosis, health-related information, information literacy"
Conference Paper,"Li S,Yin S,Deng H",Lipid Droplet Recognition Based on Watershed Algorithm and Convolutional Neural Network,Association for Computing Machinery,2021,https://doi.org/10.1145/3449388.3449400;http://dx.doi.org/10.1145/3449388.3449400,"Unbalanced storage and utilization of lipids in the liver can easily lead to non-alcoholic fatty liver, obesity and metabolic syndrome. Therefore, it is very significant to detect and classify lipids in cell pathology pictures. In order to achieve accurate identification of lipid droplets, we improved the watershed algorithm to achieve the segmentation of lipid droplets, and classified the lipid droplets based on transfer learning through a convolutional neural network. The experiment shows that the improved watershed algorithm is used to segment the lipid droplets and has achieved good results. The convolutional neural network transfer learning has achieved a classification accuracy of about 99%.","convolutional neural networks, transfer learning, Lipid droplet, watershed algorithm"
Conference Paper,"El Haddaoui B,Chiheb R,Faizi R,El Afia A",Toward a Sentiment Analysis Framework for Social Media,Association for Computing Machinery,2018,https://doi.org/10.1145/3230905.3230919;http://dx.doi.org/10.1145/3230905.3230919,"Nowadays, opinions and sentiments can be easily expressed through social media and have a strong social impact. Thus, the need for an automated way to analyze the generated data with less human effort and more accuracy. In this respect, sentiment analysis tasks such as; preprocessing, classification, etc. provides various techniques that achieves notable accuracy scores, but presents limitations depending on the experimental context.Through our literature review, only few studies focused on establishing a reference framework for sentiment analysis. In this paper, we provide a literature review for common sentiment analysis tasks with discussion about future research trends, then we propose an abstraction model of a generic framework architecture for sentiment analysis in the context of social media based on previous works and enhanced with new concepts.","Text Preprocessing, Social Media, Sentiment Analysis, Machine Learning Framework"
Conference Paper,"Islam MR,Rahim MA,Akter H,Kabir R,Shin J",Optimal IMF Selection of EMD for Sleep Disorder Diagnosis Using EEG Signals,Association for Computing Machinery,2018,https://doi.org/10.1145/3274856.3274876;http://dx.doi.org/10.1145/3274856.3274876,"Sleep disorders has a vital effect on mental depression and many other diseases of human body. Diagnosing the sleep disorder in an early curable stage may help to provide better treatment and save the life. The EEG (Electroencephalogram) signal is one of the most uses bio signal for capturing brain activities to detect and diagnosis the sleep disorders. Empirical mode decomposition (EMD) is an efficient time-frequency data analysis technique for diagnosing disease by analyzing EEG signal. However, it is a challenging issue to select the optimal intrinsic mode functions (IMFs) of Empirical mode decomposition (EMD) for extracting discriminant properties of EEG signals to diagnosis the sleep disorder. From this point of view, this paper presents a model to select optimal IMF of EMD for diagnosing the sleep disorder using EEG brain signal. In this proposed model, EMD is applied to decompose and analyze EEG signal for extracting biomarker/feature of sleep disorders. During the EMD decomposition process, different levels of IMF are extracted and features, i.e., Shannon Entropy, Spectral Entropy, Standard deviation, Skewness and Kurtosis are calculated from those IMFs for detecting the sleep disorders. In identification process, the multiclass support vector machine (MC-SVM) classification algorithm is used and sleep disorders are classified based on trained knowledge. Finally, the performance of proposed model is evaluated for different IMFs of EMD and find the optimal IMF for sleep disorder diagnosis. For evaluating the proposed model, a benchmark dataset including 4 types of data such as Apnea, REM, PLM and healthy subjects are used in experiment. According to the experimental result, the proposed model achieves the optimal classification performance for IMF 8, i.e., 93.24% average classification accuracy.","Empirical mode decomposition (EMD), EEG signal, Intrinsic mode functions (IMFs), Sleep disorder, Support vector machine (SVM)"
Conference Paper,"Khuat D,Tran TA,Nguyen MT,Le HC",A Study on Machine Learning Based Gene Selection for Pediatric Sepsis Classification,Association for Computing Machinery,2022,https://doi.org/10.1145/3568562.3568664;http://dx.doi.org/10.1145/3568562.3568664,"Nowadays, sepsis has been known as a serious health problem which becomes one of the major causes of mortality even in developed countries’ ICUs. The use of gene expression analysis and machine learning is an attractive and excellent solution to diagnose accurately the disease severity. Unfortunately, the collected dataset contains many genes among which highly correlated genes exist (redundant genes), which reduces the performance of diagnostics. Hence, efficient gene selection methods are necessary but challenging. In this paper, in order to verify the advantages of the machine learning technique and the gene expression analysis in pediatric sepsis classification, we evaluate and compare the performance of different gene selection methods combined with distinct machine learning models that are Filter, Wrapper, and Embedded approaches. In our work, a sequential gene selection procedure incorporates the differential gene expression analysis with the gene importance determined by the applied machine learning model to figure out the most informative differential gene expression. We also employ the cross-validation procedure in combination with different machine learning algorithms to verify the diagnosis performance. Numerical experiments demonstrate that the Embedded-based gene selection method incorporated with various machine learning models offers the highest diagnostic performance. In particular, the random forest-based gene selection algorithm combined with the SVM (Support Vector Machine) model that identifies a combination of 4 genes attains the best performance. The validation results have an accuracy of 89.6%, a sensitivity of 41.5%, and a specificity of 97.5%, showing the applicability of this approach in the clinic environment.","Differential expression analysis, Gene selection, Feature selection, Machine learning"
Conference Paper,"Mo J,Siddiqui S,Maudsley S,Cheung H,Martin B,Johnson CA",Classification of Alzheimer Diagnosis from ADNI Plasma Biomarker Data,Association for Computing Machinery,2013,https://doi.org/10.1145/2506583.2506637;http://dx.doi.org/10.1145/2506583.2506637,"Research into modeling the progression of Alzheimer's disease (AD) has made recent progress in identifying plasma proteomic biomarkers to identify the disease at the pre-clinical stage. In contrast with cerebral spinal fluid (CSF) biomarkers and PET imaging, plasma biomarker diagnoses have the advantage of being cost-effective and minimally invasive, thereby improving our understanding of AD and hopefully leading to early interventions as research into this subject advances. The Alzheimer's Disease Neuroimaging Initiative* (ADNI) has collected data on 190 plasma analytes from individuals diagnosed with AD as well subjects with mild cognitive impairment and cognitively normal (CN) controls. We propose an approach to classify subjects as AD or CN via an ensemble of classifiers trained and validated on ADNI data. Classifier performance is enhanced by an augmentation of a selective biomarker feature space with principal components obtained from the entire set of biomarkers. This procedure yields accuracy of 89% and area under the ROC curve of 94%.","feature clustering, feature augmentation, Alzheimer's Disease Neuroimaging Initiative (ADNI)"
Conference Paper,"Günay M,Orman Z",Disease Prediction Using Weighted Artificial Immune System,Association for Computing Machinery,2020,https://doi.org/10.1145/3386164.3389085;http://dx.doi.org/10.1145/3386164.3389085,"The Artificial Immune System (AIS) is a computational intelligence method inspired from the human immune system, which is applied to real-world problem solving related to classification, optimization and anomaly detection as an alternative approach to many data mining techniques. This paper presents a medical disease prediction system by using the AIS algorithm. The proposed system is implemented and tested on two different datasets which include breast cancer data and heart disease data with four different types of illness. Two other well-known data mining techniques that are Artificial Neural Networks (ANN) and K-Nearest Neighbor (KNN) are also tested on the same datasets to make a comparison in terms of their classification efficiency. By using AIS,. We also analyze accuracy obtained on breast cancer dataset is 98.08% and heart disease dataset is 70%. In addition to this, AIS algorithm gives the best classification results for both datasets the positive effect of preprocessing data before classification. Clearly, decreasing the number of different values that a class can be assigned for multivariate classes and assigning weights to each feature in heart disease dataset give prediction result with higher accuracy.","Data mining, Artificial Neural Networks, K-Nearest Neighbor, Artificial Immune System"
Conference Paper,"Prange A,Barz M,Heimann-Steinert A,Sonntag D",Explainable Automatic Evaluation of the Trail Making Test for Dementia Screening,Association for Computing Machinery,2021,https://doi.org/10.1145/3411764.3445046;http://dx.doi.org/10.1145/3411764.3445046,"The Trail Making Test (TMT) is a frequently used neuropsychological test for assessing cognitive performance. The subject connects a sequence of numbered nodes by using a pen on normal paper. We present an automatic cognitive assessment tool that analyzes samples of the TMT which we record using a digital pen. This enables us to analyze digital pen features that are difficult or impossible to evaluate manually. Our system automatically measures several pen features, including the completion time which is the main performance indicator used by clinicians to score the TMT in practice. In addition, our system provides a structured report of the analysis of the test, for example indicating missed or erroneously connected nodes, thereby offering more objective, transparent and explainable results to the clinician. We evaluate our system with 40 elderly subjects from a geriatrics daycare clinic of a large hospital.","multimodal, explainable, Trail Making Test, automatic scoring, cognitive assessment, digital pen"
Conference Paper,"Zhou Z,Yao J,Wang L",A Robust Optic Disc Localization Algorithm in Retinal Images Based on Support Vector Machine,Association for Computing Machinery,2020,https://doi.org/10.1145/3417519.3417552;http://dx.doi.org/10.1145/3417519.3417552,"Optic disk (OD) localization is a significant step when processing the retinal images in computer-aided diagnosis. In order to determine the location of OD precisely and robustly, an OD localization algorithm based on support vector machine (SVM) is proposed in this paper. According to some structural and intensity features of the bright regions in the retinal images, the SVM classifier is trained to recognize bright OD candidate regions. A convex hull is created on the basis of these candidate regions to locate the center of OD. Compared with OD localization methods in literatures, this proposed approach can locate the center of OD with higher accuracy because the application of machine learning algorithm improves the classification accuracy of bright regions. Three public databases with total 259 images were tested to evaluate the performance. The proposed method can achieve an accuracy of 100%, 96.9%, 97.8% for DRIVE database, DIARETDB0 database and DIARETDB1 database respectively.","convex hull, bright regions, SVM, Optic disk localization"
Journal Article,"Yadav P,Steinbach M,Kumar V,Simon G",Mining Electronic Health Records (EHRs): A Survey,Association for Computing Machinery,2018,https://doi.org/10.1145/3127881;http://dx.doi.org/10.1145/3127881,"The continuously increasing cost of the US healthcare system has received significant attention. Central to the ideas aimed at curbing this trend is the use of technology in the form of the mandate to implement electronic health records (EHRs). EHRs consist of patient information such as demographics, medications, laboratory test results, diagnosis codes, and procedures. Mining EHRs could lead to improvement in patient health management as EHRs contain detailed information related to disease prognosis for large patient populations. In this article, we provide a structured and comprehensive overview of data mining techniques for modeling EHRs. We first provide a detailed understanding of the major application areas to which EHR mining has been applied and then discuss the nature of EHR data and its accompanying challenges. Next, we describe major approaches used for EHR mining, the metrics associated with EHRs, and the various study designs. With this foundation, we then provide a systematic and methodological organization of existing data mining techniques used to model EHRs and discuss ideas for future research.","Healthcare analytics, data mining, machine learning, healthcare informatics, EHRs"
Conference Paper,"Zaouiat CE,Latif A",Internet of Things and Machine Learning Convergence: The E-Healthcare Revolution,Association for Computing Machinery,2017,https://doi.org/10.1145/3167486.3167551;http://dx.doi.org/10.1145/3167486.3167551,"The relationship between Machine learning and the Internet of things is manifested through many products in many sectors. One of the incarnations of these two technological trends is E-healthcare, which provide real-time data and allow continuous patient monitoring through prediction, anticipation and intelligent decision making. The convergence of Internet of Things IoT and Machine learning has lot of scope for research. In this paper we investigate the convergence of this two technologies in the medical healthcare area. Furthermore we present a survey of related works on IoT and ML in e-healthcare during the last five years in its general architecture and application.","E-healthcare, IoT, Machine Learning"
Conference Paper,"Bandukda M,Holloway C,Singh A,Barbareschi G,Berthouze N",Opportunities for Supporting Self-Efficacy Through Orientation & Mobility Training Technologies for Blind and Partially Sighted People,Association for Computing Machinery,2021,https://doi.org/10.1145/3441852.3471224;http://dx.doi.org/10.1145/3441852.3471224,"Orientation and mobility (O&M) training provides essential skills and techniques for safe and independent mobility for blind and partially sighted (BPS) people. The demand for O&M training is increasing as the number of people living with vision impairment increases. Despite the growing portfolio of HCI research on assistive technologies (AT), few studies have examined the experiences of BPS people during O&M training, including the use of technology to aid O&M training. To address this gap, we conducted semi-structured interviews with 20 BPS people and 8 Mobility and Orientation Trainers (MOT). The interviews were thematically analysed and organised into four overarching themes discussing factors influencing the self-efficacy belief of BPS people: Tools and Strategies for O&M training, Technology Use in O&M Training, Changing Personal and Social Circumstances, and Social Influences. We further highlight opportunities for combinations of multimodal technologies to increase access to and effectiveness of O&M training.","Orientation and mobility training, self-efficacy, blind and partially sighted people"
Journal Article,"Combi C,Liu J",Introduction to the ACM TIST Special Issue on Intelligent Healthcare Informatics,Association for Computing Machinery,2015,https://doi.org/10.1145/2791398;http://dx.doi.org/10.1145/2791398,Not Found,Not Found
Book Chapter,Not Found,"Introduction: Toward the Design, Construction, and Deployment of Multimodal-Multisensor Interfaces",Association for Computing Machinery and Morgan & Claypool,2019,https://doi.org/10.1145/3233795.3233797;http://dx.doi.org/10.1145/3233795.3233797,Not Found,Not Found
Conference Paper,"Roy DG,Majumder S,Alvi PA",Data Analytics for Quality-of-Life Monitoring and Control in the Era of Covid-19 Pandemic,Association for Computing Machinery,2022,https://doi.org/10.1145/3484824.3484879;http://dx.doi.org/10.1145/3484824.3484879,"Quality-of-life (QoL) is a multidimensional and complex issue that helps to develop an improved human civilization. In the era of COVID-19, a heightened negative impact has been observed in human lifestyle-related behaviors. A detailed analysis is required for the understanding of the mixed effect on human QoL in the ongoing pandemic outbreak. This study aims to establish an interrelationship between life evaluation factors and their effects on human QoL. Additionally, the role of data analytics has been discussed for monitoring and control of human QoL with the association of AI and statistical tools. However, AI-based analysis has provided a way to understand the mental state during this pandemic. In a similar fashion, the statistical-based analysis has helped to identify the most effective parameters that can improve overall human QoL.","Emotional manifestation analysis, Mental health monitoring, Data analytics, Quality-of-life and COVID-19"
Journal Article,"Nova FF,Pfafman R,Kardys K,Kerrigan C,Guha S,Pater J",Uncovering Adverse Childhood Experiences (ACEs) from Clinical Narratives within the Electronic Health Record,Association for Computing Machinery,2022,https://doi.org/10.1145/3555605;http://dx.doi.org/10.1145/3555605,"Adverse Childhood Events (ACEs) are potentially traumatic events that occur in childhood (e.g., sexual abuse and maternal violence). Clinical research highlights the significant impact ACEs have on youth's mental health similar to other youth-related issues like traditional bullying and cyberbullying. However, research focused on the intersection of these two are limited. We report the results from a qualitative study that used electronic health record (EHR) data and clinical narratives from Parkview Behavioral Health hospital (n=719) to better understand the presentation of ACEs in patients who indicated cyber/bullying contributed to their inpatient hospital admission. Our deductive thematic analyses on the clinical narratives/notes and diagnoses highlight the connection of ACEs with cyber/bullying and other clinical diagnoses like depression, anxiety, PTSD, and ADD/ADHD. Additionally, our results point to potential impacts of the gender spectrum and other non-ACE indicators like adoption and the need for Department of Child Services (DCS). The outcome of this study provides distinct computational and clinical design guidelines for better collaborative decision making in healthcare, including the need for ACEs screening as standard-of-care within acute mental health settings. CAUTION: This paper includes graphic contents about adverse childhood traumas and events.","adverse childhood events (aces), retrospective chart review, clinical narratives, cyberbullying, ehr"
Book Chapter,Not Found,Index,Association for Computing Machinery and Morgan & Claypool,2019,https://doi.org/10.1145/3233795.3233814;http://dx.doi.org/10.1145/3233795.3233814,Not Found,Not Found
Journal Article,"Schaekermann M,Beaton G,Habib M,Lim A,Larson K,Law E",Understanding Expert Disagreement in Medical Data Analysis through Structured Adjudication,Association for Computing Machinery,2019,https://doi.org/10.1145/3359178;http://dx.doi.org/10.1145/3359178,"Expert disagreement is pervasive in clinical decision making and collective adjudication is a useful approach for resolving divergent assessments. Prior work shows that expert disagreement can arise due to diverse factors including expert background, the quality and presentation of data, and guideline clarity. In this work, we study how these factors predict initial discrepancies in the context of medical time series analysis, examining why certain disagreements persist after adjudication, and how adjudication impacts clinical decisions. Results from a case study with 36 experts and 4,543 adjudicated cases in a sleep stage classification task show that these factors contribute to both initial disagreement and resolvability, each in their own unique way. We provide evidence suggesting that structured adjudication can lead to significant revisions in treatment-relevant clinical parameters. Our work demonstrates how structured adjudication can support consensus and facilitate a deep understanding of expert disagreement in medical data analysis.","adjudication, ambiguity, disagreement, medical time series"
Journal Article,"EL Shawi R,Al-Mallah MH",Interpretable Local Concept-Based Explanation with Human Feedback to Predict All-Cause Mortality,AI Access Foundation,2022,https://doi.org/10.1613/jair.1.14019;http://dx.doi.org/10.1613/jair.1.14019,"Machine learning models are incorporated in different fields and disciplines in which some of them require a high level of accountability and transparency, for example, the healthcare sector. With the General Data Protection Regulation (GDPR), the importance for plausibility and verifiability of the predictions made by machine learning models has become essential. A widely used category of explanation techniques attempts to explain models’ predictions by quantifying the importance score of each input feature. However, summarizing such scores to provide human-interpretable explanations is challenging. Another category of explanation techniques focuses on learning a domain representation in terms of high-level human-understandable concepts and then utilizing them to explain predictions. These explanations are hampered by how concepts are constructed, which is not intrinsically interpretable. To this end, we propose Concept-based Local Explanations with Feedback (CLEF), a novel local model agnostic explanation framework for learning a set of high-level transparent concept definitions in high-dimensional tabular data that uses clinician-labeled concepts rather than raw features. CLEF maps the raw input features to high-level intuitive concepts and then decompose the evidence of prediction of the instance being explained into concepts. In addition, the proposed framework generates counterfactual explanations, suggesting the minimum changes in the instance’s concept based explanation that will lead to a different prediction. We demonstrate with simulated user feedback on predicting the risk of mortality. Such direct feedback is more effective than other techniques, that rely on hand-labelled or automatically extracted concepts, in learning concepts that align with ground truth concept definitions.",Not Found
Conference Paper,"Xie M,Liu F",Overview of Machine Learning Methods for Genome-Wide Association Analysis,Association for Computing Machinery,2021,https://doi.org/10.1145/3469678.3469682;http://dx.doi.org/10.1145/3469678.3469682,"Genome-wide association studies (GWAS) is an effective way to reveal the pathogenic genes of complex diseases by analyzing the genotype information and related disease phenotype information on the SNP loci of the whole genome of a large number of living organisms. Machine learning (ML) is a method that allows computers to simulate human cognitive processes to solve problems. The advantage of using machine learning methods to carry out genome-wide association analysis research is that it does not require false anchor points or gene-gene interaction models in advance Instead of exhaustive search, computer algorithms that simulate human cognitive processes can learn from a large amount of data to discover the ability of nonlinear high-dimensional gene-gene interactions. In recent years, a large number of machine learning methods have been used in the study of genome-wide association analysis. This article will briefly introduct these methods.","Machine learning methods, Genome-wide association, Gene-gene interaction"
Conference Paper,Enriko IK,Comparative Study of Heart Disease Diagnosis Using Top Ten Data Mining Classification Algorithms,Association for Computing Machinery,2019,https://doi.org/10.1145/3338188.3338220;http://dx.doi.org/10.1145/3338188.3338220,"Data mining has been used for many purposes, especially for prediction system. In healthcare, data mining algorithms often used in disease diagnosis. Meanwhile, heart disease is known as a primary cause of death over the years. Many studies have been performed in heart disease diagnosis using data mining methods. There are some popular data mining algorithms that can be used in heart disease diagnosis, for example, k-Nearest Neighbor, CART, and AdaBoost. The algorithms are used to analyze a sample of cardiovascular patients data and predict the heart disease type that they suffer. Some parameters are taken from the patient, including EKG morphology, blood pressure, and information about the existence of chest pain, shortness of breath, palpitation, and cold sweat. In this study, medical records data are collected from Harapan Kita Hospital and utilized as a dataset sample in this research. Top ten data mining classification algorithms are used in diagnosing heart disease from Harapan Kita Hospital data and examining their performance by checking the accuracy and speed.","machine learning algorithms, k-Nearest Neighbor, machine learning, data mining"
Conference Paper,"Zheeng G,Zhang C,Li L",Bringing Business Intelligence to Healthcare Informatics Curriculum: A Preliminary Investigation,Association for Computing Machinery,2014,https://doi.org/10.1145/2538862.2538935;http://dx.doi.org/10.1145/2538862.2538935,"Business intelligence (BI) and healthcare analytics are emerging technologies that provide analytical capability to help healthcare industry improve service quality, reduce cost, and manage risks. However, such component on analytical healthcare data processing is largely missed from current healthcare information technology (HIT) or health informatics (HI) curricula. This paper conducts a preliminary analysis on how healthcare business intelligence can be incorporated into a HIT program. A general framework and several exemplar implementation strategies are presented. They can be used to guide the development and improvement of HIT curriculum.","business intelligence, curriculum development, health information technology, healthcare business intelligence, health informatics"
Book Chapter,Not Found,Preface,Association for Computing Machinery and Morgan & Claypool,2019,https://doi.org/10.1145/3233795.3233796;http://dx.doi.org/10.1145/3233795.3233796,Not Found,Not Found
Conference Paper,"Delnevo G,Mirri S,Monti L,Prandi C,Putra M,Roccetti M,Salomoni P,Sokol RJ",Patients Reactions to Non-Invasive and Invasive Prenatal Tests: A Machine-Based Analysis from Reddit Posts,IEEE Press,2020,Not Found,"Machine (learning)-based techniques have made substantial advances recently, and there is a general suggestion that they will drive major changes in health care within a few years. Yet, we all suffer from the lack of precise comparative studies on the accuracy of machine-based interpretations of medical data. To fill this gap, in this paper we investigate on the efficacy of using an automated mood analysis methodology to understand how patients react to the prescription to take different kinds of prenatal diagnostic tests (invasive vs non-invasive) and to the corresponding outcomes, based on conversations developed on Reddit. Our study essentially provides answers to research questions concerning: i) the popularity of prenatal diagnosis, ii) the patients' sentiment about different prenatal tests, iii) the existence of a cause-effect relationship between prenatal testing and patients' mood, and iv) the type of dialogues held by patients and physicians on this topic. Nonetheless, a general result emerging from our research is that a machine-based decision loop for now still needs human involvement, at least to alleviate the tension between empirical data and their correct medical interpretation.",Not Found
Book,Not Found,ICBDC '22: Proceedings of the 7th International Conference on Big Data and Computing,Association for Computing Machinery,2022,Not Found,Not Found,Not Found
Journal Article,"Wang Q,Zhou Y,Ding W,Zhang Z,Muhammad K,Cao Z",Random Forest with Self-Paced Bootstrap Learning in Lung Cancer Prognosis,Association for Computing Machinery,2020,https://doi.org/10.1145/3345314;http://dx.doi.org/10.1145/3345314,"Training gene expression data with supervised learning approaches can provide an alarm sign for early treatment of lung cancer to decrease death rates. However, the samples of gene features involve lots of noises in a realistic environment. In this study, we present a random forest with self-paced learning bootstrap for improvement of lung cancer classification and prognosis based on gene expression data. To be specific, we propose an ensemble learning with random forest approach to improving the model classification performance by selecting multi-classifiers. Then, we investigate the sampling strategy by gradually embedding from high- to low-quality samples by self-paced learning. The experimental results based on five public lung cancer datasets show that our proposed method could select significant genes exactly, which improves classification performance compared to that of existing approaches. We believe that our proposed method has the potential to assist doctors in gene selections and lung cancer prognosis.","self-paced learning, Lung cancer, classification, bootstrap, random forest"
Book Chapter,Sonntag D,Medical and Health Systems,Association for Computing Machinery and Morgan & Claypool,2019,https://doi.org/10.1145/3233795.3233808;http://dx.doi.org/10.1145/3233795.3233808,Not Found,Not Found
Conference Paper,"Shokri R,Strobel M,Zick Y",On the Privacy Risks of Model Explanations,Association for Computing Machinery,2021,https://doi.org/10.1145/3461702.3462533;http://dx.doi.org/10.1145/3461702.3462533,"Privacy and transparency are two key foundations of trustworthy machine learning. Model explanations offer insights into a model's decisions on input data, whereas privacy is primarily concerned with protecting information about the training data. We analyze connections between model explanations and the leakage of sensitive information about the model's training set. We investigate the privacy risks of feature-based model explanations using membership inference attacks: quantifying how much model predictions plus their explanations leak information about the presence of a datapoint in the training set of a model. We extensively evaluate membership inference attacks based on feature-based model explanations, over a variety of datasets. We show that backpropagation-based explanations can leak a significant amount of information about individual training datapoints. This is because they reveal statistical information about the decision boundaries of the model about an input, which can reveal its membership. We also empirically investigate the trade-off between privacy and explanation quality, by studying the perturbation-based model explanations.","model explanations, membership inference, privacy"
Journal Article,"Chancellor S,Baumer EP,De Choudhury M","Who is the ""Human"" in Human-Centered Machine Learning: The Case of Predicting Mental Health from Social Media",Association for Computing Machinery,2019,https://doi.org/10.1145/3359249;http://dx.doi.org/10.1145/3359249,"""Human-centered machine learning"" (HCML) combines human insights and domain expertise with data-driven predictions to answer societal questions. This area's inherent interdisciplinarity causes tensions in the obligations researchers have to the humans whose data they use. This paper studies how scientific papers represent human research subjects in HCML. Using mental health status prediction on social media as a case study, we conduct thematic discourse analysis on 55 papers to examine these representations. We identify five discourses that weave a complex narrative of who the human subject is in this research: Disorder/Patient, Social Media, Scientific, Data/Machine Learning, and Person. We show how these five discourses create paradoxical subject and object representations of the human, which may inadvertently risk dehumanization. We also discuss the tensions and impacts of interdisciplinary research; the risks of this work to scientific rigor, online communities, and mental health; and guidelines for stronger HCML research in this nascent area.","social media, human-centered machine learning, mental health, machine learning, research ethics"
Conference Paper,"Martínez-Velasco A,Martínez-Villaseñor L,Miralles-Pechuán L",Machine Learning Approach for Pre-Eclampsia Risk Factors Association,Association for Computing Machinery,2018,https://doi.org/10.1145/3284869.3284912;http://dx.doi.org/10.1145/3284869.3284912,"The preeclampsia/eclampsia syndrome is a multisystem disorder that usually includes cardiovascular changes, hematologic abnormalities, hepatic and renal impairment, and neurologic or cerebral manifestations. Preeclampsia (PE) is a clinical syndrome that afflicts 3--5% of pregnancies and it is a leading cause of maternal mortality, especially in developing countries. To understand in greater depth the preeclampsia/eclampsia syndrome, we applied some well-known Machine Learning (ML) techniques. ML has been successfully applied to medical research to improve the diagnosis and the prevention of complex diseases and syndromes. In our contribution, we have created a supervised model to predict if a patient suffers the disease. This model has been optimized by selecting the best features and by optimizing the threshold when predicting a class. We used these techniques to point out the most related features of the patients to the disease. Finally, we used interpretability techniques to extract and visualize through a decision tree the most relevant associations of the disease with the patients' features.","Risk Factors, Genetic Variants, Machine Learning, Preeclampsia"
Conference Paper,"Khosla A,Cao Y,Lin CC,Chiu HK,Hu J,Lee H",An Integrated Machine Learning Approach to Stroke Prediction,Association for Computing Machinery,2010,https://doi.org/10.1145/1835804.1835830;http://dx.doi.org/10.1145/1835804.1835830,"Stroke is the third leading cause of death and the principal cause of serious long-term disability in the United States. Accurate prediction of stroke is highly valuable for early intervention and treatment. In this study, we compare the Cox proportional hazards model with a machine learning approach for stroke prediction on the Cardiovascular Health Study (CHS) dataset. Specifically, we consider the common problems of data imputation, feature selection, and prediction in medical datasets. We propose a novel automatic feature selection algorithm that selects robust features based on our proposed heuristic: conservative mean. Combined with Support Vector Machines (SVMs), our proposed feature selection algorithm achieves a greater area under the ROC curve (AUC) as compared to the Cox proportional hazards model and L1 regularized Cox feature selection algorithm. Furthermore, we present a margin-based censored regression algorithm that combines the concept of margin-based classifiers with censored regression to achieve a better concordance index than the Cox model. Overall, our approach outperforms the current state-of-the-art in both metrics of AUC and concordance index. In addition, our work has also identified potential risk factors that have not been discovered by traditional approaches. Our method can be applied to clinical prediction of other diseases, where missing data are common and risk factors are not well understood.","data analysis, concordance index, medical data analysis, benchmark, SVM, prediction, classification, healthcare, stroke, ROC, feature selection, stroke prediction"
Conference Paper,"Ma F,You Q,Xiao H,Chitta R,Zhou J,Gao J",KAME: Knowledge-Based Attention Model for Diagnosis Prediction in Healthcare,Association for Computing Machinery,2018,https://doi.org/10.1145/3269206.3271701;http://dx.doi.org/10.1145/3269206.3271701,"The goal of diagnosis prediction task is to predict the future health information of patients from their historical Electronic Healthcare Records (EHR). The most important and challenging problem of diagnosis prediction is to design an accurate, robust and interpretable predictive model. Existing work solves this problem by employing recurrent neural networks (RNNs) with attention mechanisms, but these approaches suffer from the data sufficiency problem. To obtain good performance with insufficient data, graph-based attention models are proposed. However, when the training data are sufficient, they do not offer any improvement in performance compared with ordinary attention-based models. To address these issues, we propose KAME, an end-to-end, accurate and robust model for predicting patients' future health information. KAME not only learns reasonable embeddings for nodes in the knowledge graph, but also exploits general knowledge to improve the prediction accuracy with the proposed knowledge attention mechanism. With the learned attention weights, KAME allows us to interpret the importance of each piece of knowledge in the graph. Experimental results on three real world datasets show that the proposed KAME significantly improves the prediction performance compared with the state-of-the-art approaches, guarantees the robustness with both sufficient and insufficient data, and learns interpretable disease representations.","medical knowledge graph, knowledge attention mechanism, healthcare informatics"
Conference Paper,"Zhang X,Xiao C,Glass LM,Sun J",DeepEnroll: Patient-Trial Matching with Deep Embedding and Entailment Prediction,Association for Computing Machinery,2020,https://doi.org/10.1145/3366423.3380181;http://dx.doi.org/10.1145/3366423.3380181,"Clinical trials are essential for drug development but often suffer from expensive, inaccurate and insufficient patient recruitment. The core problem of patient-trial matching is to find qualified patients for a trial, where patient information is stored in electronic health records (EHR) while trial eligibility criteria (EC) are described in text documents available on the web. How to represent longitudinal patient EHR? How to extract complex logical rules from EC? Most existing works rely on manual rule-based extraction, which is time consuming and inflexible for complex inference. To address these challenges, we proposed a cross-modal inference learning model to jointly encode enrollment criteria (text) and patients records (tabular data) into a shared latent space for matching inference. pplies a pre-trained Bidirectional Encoder Representations from Transformers(BERT) model to encode clinical trial information into sentence embedding. And uses a hierarchical embedding model to represent patient longitudinal EHR. In addition, s augmented by a numerical information embedding and entailment module to reason over numerical information in both EC and EHR. These encoders are trained jointly to optimize patient-trial matching score. We evaluated n the trial-patient matching task with demonstrated on real world datasets. utperformed the best baseline by up to 12.4% in average F1.","Trial Recruitment, Attention Mechanism, Entailment Prediction, Machine Learning"
Book Chapter,"Bohus D,Horvitz E",Situated Interaction,Association for Computing Machinery and Morgan & Claypool,2019,https://doi.org/10.1145/3233795.3233800;http://dx.doi.org/10.1145/3233795.3233800,Not Found,Not Found
Conference Paper,Lan X,Risk Factors and Management Strategies of Liver Cancer,Association for Computing Machinery,2022,https://doi.org/10.1145/3570773.3570794;http://dx.doi.org/10.1145/3570773.3570794,"Liver cancer is one of the most common causes of global death, with a higher incidence in men than women. The morbidity of liver cancer is highest in East Asia and the Asia-Pacific region, and it is increasing gradually in other regions. The risk factors for liver cancer mainly include chronic HBV and HCV infection, alcoholism, obesity, aflatoxin exposure, diabetes, and other metabolic diseases. In addition, there is evidence that diet plays an important role in the development of liver cancer. Most of the primary liver cancer is hepatocellular carcinoma (HCC), while the rest is intrahepatic cholangiocarcinoma (ICC). Imaging and laboratory tests are effective diagnostic methods for HCC. Hepatectomy is the most preferred treatment for liver cancer, followed by liver transplantation, local ablation, chemotherapy, targeted therapy, radiotherapy, immunotherapy, and natural compound therapy. Monitoring high-risk individuals with chronic hepatitis C and cirrhosis could facilitate better long-term outcomes for HCC patients. This paper analyzes the etiology, diagnosis, and treatment of liver cancer to provide the research perspective for future studies.",Not Found
Journal Article,"Caro-Martínez M,Jiménez-Díaz G,Recio-García JA",Conceptual Modeling of Explainable Recommender Systems: An Ontological Formalization to Guide Their Design and Development,AI Access Foundation,2021,https://doi.org/10.1613/jair.1.12789;http://dx.doi.org/10.1613/jair.1.12789,"With the increasing importance of e-commerce and the immense variety of products, users need help to decide which ones are the most interesting to them. This is one of the main goals of recommender systems. However, users’ trust may be compromised if they do not understand how or why the recommendation was achieved. Here, explanations are essential to improve user confidence in recommender systems and to make the recommendation useful. Providing explanation capabilities into recommender systems is not an easy task as their success depends on several aspects such as the explanation’s goal, the user’s expectation, the knowledge available, or the presentation method. Therefore, this work proposes a conceptual model to alleviate this problem by defining the requirements of explanations for recommender systems. Our goal is to provide a model that guides the development of effective explanations for recommender systems as they are correctly designed and suited to the user’s needs. Although earlier explanation taxonomies sustain this work, our model includes new concepts not considered in previous works. Moreover, we make a novel contribution regarding the formalization of this model as an ontology that can be integrated into the development of proper explanations for recommender systems.","knowledge representation, ontologies"
Book Chapter,"Allen J,André E,Cohen PR,Hakkani-Tür D,Kaplan R,Lemon O,Traum D",Challenge Discussion: Advancing Multimodal Dialogue,Association for Computing Machinery and Morgan & Claypool,2019,https://doi.org/10.1145/3233795.3233802;http://dx.doi.org/10.1145/3233795.3233802,Not Found,Not Found
Journal Article,"Wu H,Wang K,Lu L,Xue Y,Lyu Q,Jiang M",Deep Conditional Random Field Approach to Transmembrane Topology Prediction and Application to GPCR Three-Dimensional Structure Modeling,IEEE Computer Society Press,2017,https://doi.org/10.1109/TCBB.2016.2602872;http://dx.doi.org/10.1109/TCBB.2016.2602872,"Transmembrane proteins play important roles in cellular energy production, signal transmission, and metabolism. Many shallow machine learning methods have been applied to transmembrane topology prediction, but the performance was limited by the large size of membrane proteins and the complex biological evolution information behind the sequence. In this paper, we proposed a novel deep approach based on conditional random fields named as dCRF-TM for predicting the topology of transmembrane proteins. Conditional random fields take into account more complicated interrelation between residue labels in full-length sequence than HMM and SVM-based methods. Three widely-used datasets were employed in the benchmark. DCRF-TM had the accuracy 95 percent over helix location prediction and the accuracy 78 percent over helix number prediction. DCRF-TM demonstrated a more robust performance on large size proteins >350 residues against 11 state-of-the-art predictors. Further dCRF-TM was applied to ab initio modeling three-dimensional structures of seven-transmembrane receptors, also known as G protein-coupled receptors. The predictions on 24 solved G protein-coupled receptors and unsolved vasopressin V2 receptor illustrated that dCRF-TM helped abGPCR-I-TASSER to improve TM-score 34.3 percent rather than using the random transmembrane definition. Two out of five predicted models caught the experimental verified disulfide bonds in vasopressin V2 receptor.",Not Found
Book,Not Found,ICCMS '22: Proceedings of the 14th International Conference on Computer Modeling and Simulation,Association for Computing Machinery,2022,Not Found,Not Found,Not Found
Conference Paper,"Sunday Julius M,Rita Alo U,Uchenna Onu F,Ihuoma Akobundu C",Machine Learning Framework to Predict Patient Non-Adherence to Medication Using Non-Clinical Data: A Prognosis Approach,Association for Computing Machinery,2021,https://doi.org/10.1145/3479162.3479177;http://dx.doi.org/10.1145/3479162.3479177,"The need for patient-centric medication adherence intervention system tailored towards addressing individual patient challenges of non-adherence has been well established by several studies. In recent times, many studies have applied machine learning predictive models in medication adherence system across specific chronic diseases using patient's clinical data. However, only a very few studies had attempted to leverage on patient's non-clinical data such as patient's belief, behavioral pattern, knowledge and others as input parameters in their predictive models. Studies outcomes have also shown that these non-clinical data have high influence on patient's non-adherence to medication thereby making them strong determinants. In this paper, we introduce a prognosis approach that can help to predict patient's non-adherence level to medication at the first clinic visit even before prescription commences. The prognosis approach is described by using Adaptive Neuro Fuzzy (ANF) predictive model that adopt the use of non-clinical data of patient to serve as input variables of the model. This study is a preliminary report of an ongoing innovative and intelligent healthcare project to improve patient adherence to medication. We developed a certified questionnaire based on health belief theory to collect the non-clinical data from out-patients with chronic disease who are receiving treatment so as to test the performance of the proposed framework. The predicted patient level of non-adherence output would be optimized and stratified to determine an appropriate intervention functions and delivery techniques towards the particular needs of the patient. Various components of the framework; features and functions; taxonomy of intervention techniques; design guidelines; and recommendations for efficient integrations and deployment in healthcare centers are presented. This would serve as a veritable prognosis and prediction tool to improve adherence to medication as the level of non-adherence to medication of the patient would be easily determined.","machine learning, medication adherence, neuro-fuzzy predictive model, prognosis approach"
Book,Not Found,ICCTA '22: Proceedings of the 2022 8th International Conference on Computer Technology Applications,Association for Computing Machinery,2022,Not Found,Not Found,Not Found
Book,Not Found,ICBRA '22: Proceedings of the 9th International Conference on Bioinformatics Research and Applications,Association for Computing Machinery,2022,Not Found,Not Found,Not Found
Book Chapter,"Cafaro A,Pelachaud C,Marsella SC",Nonverbal Behavior in Multimodal Performances,Association for Computing Machinery and Morgan & Claypool,2019,https://doi.org/10.1145/3233795.3233803;http://dx.doi.org/10.1145/3233795.3233803,Not Found,Not Found
Book,Not Found,ICEMC '22: Proceedings of the 2022 International Conference on E-Business and Mobile Commerce,Association for Computing Machinery,2022,Not Found,Not Found,Not Found
Conference Paper,"Creemers C,Guerti K,Geerts S,Van Cotthem K,Ledda A,Spruyt V",HEp-2 Cell Pattern Segmentation for the Support of Autoimmune Disease Diagnosis,Association for Computing Machinery,2011,https://doi.org/10.1145/2093698.2093726;http://dx.doi.org/10.1145/2093698.2093726,"The Indirect Immune Fluorescence Test (iIFT) is the most commonly used screening method for the diagnosis of autoimmune diseases. The presence of certain autoimmune diseases is proven by immunologically detecting their corresponding auto-antibodies using the HEp-2 cancer cell line. For this purpose HEp-2 cells are added to the patients' blood serum containing certain auto-antibodies which will bond with the HEp-2 cells leading to a wide variety of patterns that can be observed under a fluorescence microscope. Due to the disadvantages of manual testing, automation and standardization are necessary. This paper proposes an unsupervised segmentation algorithm as part of an ongoing research to develop a CAD system to digitally support iIFT testing.","HEp-2, Otsu, autoimmune diseases, segmentation"
Journal Article,"Sabharwal A,Barua S,Kerr D",A Systems Approach to Achieve Equity in Healthcare Research,Association for Computing Machinery,2022,https://doi.org/10.1145/3511285.3511287;http://dx.doi.org/10.1145/3511285.3511287,"Healthcare in the United States is inequitable. The consequence of inequity is that the burden of serious chronic disease, such as diabetes, falls disproportionately on populations experiencing health disparities, predominantly Black, Indigenous, and people of color. [1] The reasons for the inequity include the negative impact of the social determinants of health of individuals and families from these communities, being underrepresented as participants in clinical research, having limited access to technologies that support self-care, and a lack of researchers and clinicians from these same populations. [2] To achieve equity and fairness, there is a need for a paradigm shift in healthcare research and innovation based on improving access, trust, and self-efficacy [3] to convert new knowledge into positive health outcomes.",Not Found
Conference Paper,"Ma D,Li X,Mou S,Cheng Z,Yan X,Lu Y,Yan R,Cao S",Prediction of Chronic Kidney Disease Risk Using Multimodal Data,Association for Computing Machinery,2021,https://doi.org/10.1145/3456529.3456533;http://dx.doi.org/10.1145/3456529.3456533,"Chronic kidney disease (CKD) is a widespread public health problem and often leads to kidney failure which needs hemodialysis or even kidney transplantation. Undoubtedly, prediction of the risk of CKD among healthy people is highly desirable and very meaningful. However, most studies in this field used logistic regression (LR) and produced results with limited accuracy. Also, these studies ignored unstructured data which contained useful information. To improve CKD prediction, in this study, we built a novel multimodal data model that integrated Bidirectional Encoder Representations from Transformers with Light Gradient Boosting Machine (termed MD-BERT-LGBM model hereafter), and applied it to a group of 3295 participants for CKD prediction study. We collected medical data for over three months from each participant. We compared this novel integrated framework with three conventional models: the LR, LGBM, and Multimodal Disease Risk Prediction algorithm based on Convolutional Neural Networks (CNN-MDRP). The experimental results show that the new MD-BERT-LGBM model outperformed all the three conventional models in terms of accuracy, recall, and Area Under the ROC curve (AUC), which are 78.12%, 75.65%, and 85.15%, respectively. This result demonstrates the potential of this proposed method in the clinical application of CKD prediction and prevention.","Chronic Kidney Disease, Multimodal Data, Bidirectional Encoder Representations from Transformers, Light Gradient Boosting Machine"
Conference Paper,"Zhu W,Razavian N",Variationally Regularized Graph-Based Representation Learning for Electronic Health Records,Association for Computing Machinery,2021,https://doi.org/10.1145/3450439.3451855;http://dx.doi.org/10.1145/3450439.3451855,"Electronic Health Records (EHR) are high-dimensional data with implicit connections among thousands of medical concepts. These connections, for instance, the co-occurrence of diseases and lab-disease correlations can be informative when only a subset of these variables is documented by the clinician. A feasible approach to improving the representation learning of EHR data is to associate relevant medical concepts and utilize these connections. Existing medical ontologies can be the reference for EHR structures, but they place numerous constraints on the data source. Recent progress on graph neural networks (GNN) enables end-to-end learning of topological structures for non-grid or non-sequential data. However, there are problems to be addressed on how to learn the medical graph adaptively and how to understand the effect of medical graph on representation learning. In this paper, we propose a variationally regularized encoder-decoder graph network that achieves more robustness in graph structure learning by regularizing node representations. Our model outperforms the existing graph and non-graph based methods in various EHR predictive tasks based on both public data and real-world clinical data. Besides the improvements in empirical experiment performances, we provide an interpretation of the effect of variational regularization compared to standard graph neural network, using singular value analysis.","regularization, graph neural networks, singular value decomposition, Alzheimer's disease, electronic health records"
Conference Paper,"Boyd K,Lantz E,Page D",Differential Privacy for Classifier Evaluation,Association for Computing Machinery,2015,https://doi.org/10.1145/2808769.2808775;http://dx.doi.org/10.1145/2808769.2808775,"Differential privacy provides powerful guarantees that individuals incur minimal additional risk by including their personal data in a database. Most work in differential privacy has focused on differentially private algorithms that produce models, counts, and histograms. Nevertheless, even with a classification model produced by a differentially private algorithm, directly reporting the classifier's performance on a database has the potential for disclosure. Thus, differentially private computation of evaluation metrics for machine learning is an important research area. We find effective mechanisms for area under the receiver-operating characteristic (ROC) curve and average precision.","ROC curve, average precision, differential privacy"
Journal Article,"Rathore MM,Paul A,Ahmad A,Anisetti M,Jeon G",Hadoop-Based Intelligent Care System (HICS): Analytical Approach for Big Data in IoT,Association for Computing Machinery,2017,https://doi.org/10.1145/3108936;http://dx.doi.org/10.1145/3108936,"The Internet of Things (IoT) is increasingly becoming a worldwide network of interconnected things that are uniquely addressable, via standard communication protocols. The use of IoT for continuous monitoring of public health is being rapidly adopted by various countries while generating a massive volume of heterogeneous, multisource, dynamic, and sparse high-velocity data. Handling such an enormous amount of high-speed medical data while integrating, collecting, processing, analyzing, and extracting knowledge constitutes a challenging task. On the other hand, most of the existing IoT devices do not cooperate with one another by using the same medium of communication. For this reason, it is a challenging task to develop healthcare applications for IoT that fulfill all user needs through real-time monitoring of health parameters. Therefore, to address such issues, this article proposed a Hadoop-based intelligent care system (HICS) that demonstrates IoT-based collaborative contextual Big Data sharing among all of the devices in a healthcare system. In particular, the proposed system involves a network architecture with enhanced processing features for data collection generated by millions of connected devices. In the proposed system, various sensors, such as wearable devices, are attached to the human body and measure health parameters and transmit them to a primary mobile device (PMD). The collected data are then forwarded to intelligent building (IB) using the Internet where the data are thoroughly analyzed to identify abnormal and serious health conditions. Intelligent building consists of (1) a Big Data collection unit (used for data collection, filtration, and load balancing); (2) a Hadoop processing unit (HPU) (composed of Hadoop distributed file system (HDFS) and MapReduce); and (3) an analysis and decision unit. The HPU, analysis, and decision unit are equipped with a medical expert system, which reads the sensor data and performs actions in the case of an emergency situation. To demonstrate the feasibility and efficiency of the proposed system, we use publicly available medical sensory datasets and real-time sensor traffic while identifying the serious health conditions of patients by using thresholds, statistical methods, and machine-learning techniques. The results show that the proposed system is very efficient and able to process high-speed WBAN sensory data in real time.","IoT, healthcare, Big Data, intelligent building, PMD"
Journal Article,Mone G,"Machine Learning, Meet Whiskey",Association for Computing Machinery,2020,https://doi.org/10.1145/3381913;http://dx.doi.org/10.1145/3381913,Technologies are coming increasingly closer to approximating the human senses of taste and smell.,Not Found
Book Chapter,"Skantze G,Gustafson J,Beskow J",Multimodal Conversational Interaction with Robots,Association for Computing Machinery and Morgan & Claypool,2019,https://doi.org/10.1145/3233795.3233799;http://dx.doi.org/10.1145/3233795.3233799,Not Found,Not Found
Conference Paper,"Krisnabayu RY,Ridok A,Setia Budi A",Hepatitis Detection Using Random Forest Based on SVM-RFE (Recursive Feature Elimination) Feature Selection and SMOTE,Association for Computing Machinery,2021,https://doi.org/10.1145/3479645.3479668;http://dx.doi.org/10.1145/3479645.3479668,"Hepatitis is a dangerous disease because it is a contagious disease and it is not easy to diagnose the disease early. Due to the difficulty of making an early diagnosis, the disease has the potential to become even more severe and increase the mortality rate. Therefore, it is necessary to develop predictive methods that can be used for the early detection of this disease. In this study, a hepatitis prediction method was developed using a random forest (RF) algorithm combined with feature selection using SVM-RFE (recursive feature elimination). Then, because the dataset used does not have a balanced distribution between classes, which is only 20% for the minority class, SMOTE (synthetic minority oversampling technique) is used to deal with this problem. To determine the best parameters in the model, Grid-Search is used as the tuning hyper-parameters. The classifier built with this approach produces 0.879 accuracy, 0.902 precision, and 0.966 ROC performance. This classifier proved to be better than the other classifiers.","Synthetic minority oversampling technique, Random forest, Recursive feature elimination, Hepatitis prediction"
Conference Paper,"V. SA,Sivaswamy J",Shared Encoder Based Denoising of Optical Coherence Tomography Images,Association for Computing Machinery,2020,https://doi.org/10.1145/3293353.3293388;http://dx.doi.org/10.1145/3293353.3293388,"Optical coherence tomography (OCT) images are corrupted by speckle noise due to underlying coherence-based strategy. Speckle suppression/removal in OCT images plays a significant role in both manual and automatic detection of diseases, especially in early clinical diagnosis. In this paper, we propose a new method for denoising OCT images based on Convolutional Neural Network by learning common features from unpaired noisy and clean OCT images in an unsupervised, end-to-end manner. The proposed method consists of a combination of two autoencoders with shared encoder layers, which we call as Shared Encoder (SE) architecture. The SE is trained to reconstruct noisy and clean OCT images with respective autoencoders. The denoised OCT image is obtained using a cross-model prediction. The proposed method can be used for denoising OCT images with or without pathology from any scanner. The SE architecture was assessed using public datasets and found to perform better than baseline methods exhibiting a good balance of retaining anatomical integrity and speckle reduction.","unsupervised learning, deep learning, shared encoder, speckle, Optical coherence tomography (OCT) denoising"
Book Chapter,Valstar M,Multimodal Databases,Association for Computing Machinery and Morgan & Claypool,2019,https://doi.org/10.1145/3233795.3233807;http://dx.doi.org/10.1145/3233795.3233807,Not Found,Not Found
Book Chapter,"Schnelle-Walka D,Radomski S",Automotive Multimodal Human-Machine Interface,Association for Computing Machinery and Morgan & Claypool,2019,https://doi.org/10.1145/3233795.3233809;http://dx.doi.org/10.1145/3233795.3233809,Not Found,Not Found
Journal Article,"Wang J,Zhang H,Ren W,Guo M,Yu G",EpiMC: Detecting Epistatic Interactions Using Multiple Clusterings,IEEE Computer Society Press,2022,https://doi.org/10.1109/TCBB.2021.3080462;http://dx.doi.org/10.1109/TCBB.2021.3080462,"Detecting single nucleotide polymorphisms (SNPs) interactions is crucial to identify susceptibility genes associated with complex human diseases in genome-wide association studies. Clustering-based approaches are widely used in reducing search space and exploring potential relationships between SNPs in epistasis analysis. However, these approaches all only use a single measure to filter out nonsignificant SNP combinations, which may be significant ones from another perspective. In this paper, we propose a two-stage approach named EpiMC (Epistatic Interactions detection based on Multiple Clusterings) that employs multiple clusterings to obtain more precise candidate sets and more comprehensively detect high-order interactions based on these sets. In the first stage, EpiMC proposes a matrix factorization based multiple clusterings algorithm to generate multiple diverse clusterings, each of which divide all SNPs into different clusters. This stage aims to reduce the chance of filtering out potential candidates overlooked by a single clustering and groups associated SNPs together from different clustering perspectives. In the next stage, EpiMC considers both the single-locus effects and interaction effects to select high-quality disease associated SNPs, and then uses Jaccard similarity to get candidate sets. Finally, EpiMC uses exhaustive search on the obtained small candidate sets to precisely detect epsitatic interactions. Extensive simulation experiments show that EpiMC has a better performance in detecting high-order interactions than state-of-the-art solutions. On the Wellcome Trust Case Control Consortium (WTCCC) dataset, EpiMC detects several significant epistatic interactions associated with breast cancer (BC) and age-related macular degeneration (AMD), which again corroborate the effectiveness of EpiMC.",Not Found
Journal Article,"Ma X,Yang X,Gao J,Xu C",Health Status Prediction with Local-Global Heterogeneous Behavior Graph,Association for Computing Machinery,2021,https://doi.org/10.1145/3457893;http://dx.doi.org/10.1145/3457893,"Health management is getting increasing attention all over the world. However, existing health management mainly relies on hospital examination and treatment, which are complicated and untimely. The emergence of mobile devices provides the possibility to manage people’s health status in a convenient and instant way. Estimation of health status can be achieved with various kinds of data streams continuously collected from wearable sensors. However, these data streams are multi-source and heterogeneous, containing complex temporal structures with local contextual and global temporal aspects, which makes the feature learning and data joint utilization challenging. We propose to model the behavior-related multi-source data streams with a local-global graph, which contains multiple local context sub-graphs to learn short-term local context information with heterogeneous graph neural networks and a global temporal sub-graph to learn long-term dependency with self-attention networks. Then health status is predicted based on the structure-aware representation learned from the local-global behavior graph. We take experiments on the StudentLife dataset, and extensive results demonstrate the effectiveness of our proposed model.","graph neural networks, Health status prediction, individual behavior"
Book Chapter,"Cohen PR,Tumuluri R",Commercialization of Multimodal Systems,Association for Computing Machinery and Morgan & Claypool,2019,https://doi.org/10.1145/3233795.3233812;http://dx.doi.org/10.1145/3233795.3233812,Not Found,Not Found
Conference Paper,"Rodrigues SS,Scuracchio PE,de Mattos Fortes RP",A Support to Evaluate Web Accessibility and Usability Issues for Older Adults,Association for Computing Machinery,2018,https://doi.org/10.1145/3218585.3218597;http://dx.doi.org/10.1145/3218585.3218597,"The constant evolution of the Web has enabled that new online services in various segments be offered. Following this evolution, it is crucial that its content allows access to the different user's profiles. Older adults (age 60+) are users who typically have limited capacities due to ageing process and they have encountered difficulties in interacting with websites. Several accessibility and usability issues still have to be solved, despite the legislation and guidelines established for the development of accessible and usable web content. In particular, little attention has been devoted to the difficulties faced by older adults because most websites are not designed with these users in mind. This paper addresses the development of a checklist, a support to web accessibility and usability evaluations for the older adults profile and its validation. The checklist was elaborated from analysis of the state of the art, based on a literature review. During the checklist development we investigated the main barriers faced by older adults in web interaction. We conclude by highlighting the need for more studies on web interaction by older people and proposing new strategies for future research.","Web Usability, Evaluation of Web Accessibility and Usability, Web Accessibility, Evaluation Method, Older Adults"
Book Chapter,"Heloir A,Nunnari F,Bachynskyi M",Ergonomics for the Design of Multimodal Interfaces,Association for Computing Machinery and Morgan & Claypool,2019,https://doi.org/10.1145/3233795.3233804;http://dx.doi.org/10.1145/3233795.3233804,Not Found,Not Found
Book,"Jalali L,Jain R",Event Mining for Explanatory Modeling,Association for Computing Machinery,2021,Not Found,"This book introduces the concept of Event Mining for building explanatory models from analyses of correlated data. Such a model may be used as the basis for predictions and corrective actions. The idea is to create, via an iterative process, a model that explains causal relationships in the form of structural and temporal patterns in the data. The first phase is the data-driven process of hypothesis formation, requiring the analysis of large amounts of data to find strong candidate hypotheses. The second phase is hypothesis testing, wherein a domain expert’s knowledge and judgment is used to test and modify the candidate hypotheses.The book is intended as a primer on Event Mining for data-enthusiasts and information professionals interested in employing these event-based data analysis techniques in diverse applications. The reader is introduced to frameworks for temporal knowledge representation and reasoning, as well as temporal data mining and pattern discovery. Also discussed are the design principles of event mining systems. The approach is reified by the presentation of an event mining system called EventMiner, a computational framework for building explanatory models. The book contains case studies of using EventMiner in asthma risk management and an architecture for the objective self. The text can be used by researchers interested in harnessing the value of heterogeneous big data for designing explanatory event-based models in diverse application areas such as healthcare, biological data analytics, predictive maintenance of systems, computer networks, and business intelligence.",Not Found
Book Chapter,Waibel A,Multimodal Dialogue Processing for Machine Translation,Association for Computing Machinery and Morgan & Claypool,2019,https://doi.org/10.1145/3233795.3233811;http://dx.doi.org/10.1145/3233795.3233811,Not Found,Not Found
Conference Paper,"Cai R,Ren A,Liu N,Ding C,Wang L,Qian X,Pedram M,Wang Y",VIBNN: Hardware Acceleration of Bayesian Neural Networks,Association for Computing Machinery,2018,https://doi.org/10.1145/3173162.3173212;http://dx.doi.org/10.1145/3173162.3173212,"Bayesian Neural Networks (BNNs) have been proposed to address the problem of model uncertainty in training and inference. By introducing weights associated with conditioned probability distributions, BNNs are capable of resolving the overfitting issue commonly seen in conventional neural networks and allow for small-data training, through the variational inference process. Frequent usage of Gaussian random variables in this process requires a properly optimized Gaussian Random Number Generator (GRNG). The high hardware cost of conventional GRNG makes the hardware implementation of BNNs challenging. In this paper, we propose VIBNN, an FPGA-based hardware accelerator design for variational inference on BNNs. We explore the design space for massive amount of Gaussian variable sampling tasks in BNNs. Specifically, we introduce two high performance Gaussian (pseudo) random number generators: 1) the RAM-based Linear Feedback Gaussian Random Number Generator (RLF-GRNG), which is inspired by the properties of binomial distribution and linear feedback logics; and 2) the Bayesian Neural Network-oriented Wallace Gaussian Random Number Generator. To achieve high scalability and efficient memory access, we propose a deep pipelined accelerator architecture with fast execution and good hardware utilization. Experimental results demonstrate that the proposed VIBNN implementations on an FPGA can achieve throughput of 321,543.4 Images/s and energy efficiency upto 52,694.8 Images/J while maintaining similar accuracy as its software counterpart.","Bayesian neural network, FPGA, neural network"
Journal Article,"Cai R,Ren A,Liu N,Ding C,Wang L,Qian X,Pedram M,Wang Y",VIBNN: Hardware Acceleration of Bayesian Neural Networks,Association for Computing Machinery,2018,https://doi.org/10.1145/3296957.3173212;http://dx.doi.org/10.1145/3296957.3173212,"Bayesian Neural Networks (BNNs) have been proposed to address the problem of model uncertainty in training and inference. By introducing weights associated with conditioned probability distributions, BNNs are capable of resolving the overfitting issue commonly seen in conventional neural networks and allow for small-data training, through the variational inference process. Frequent usage of Gaussian random variables in this process requires a properly optimized Gaussian Random Number Generator (GRNG). The high hardware cost of conventional GRNG makes the hardware implementation of BNNs challenging. In this paper, we propose VIBNN, an FPGA-based hardware accelerator design for variational inference on BNNs. We explore the design space for massive amount of Gaussian variable sampling tasks in BNNs. Specifically, we introduce two high performance Gaussian (pseudo) random number generators: 1) the RAM-based Linear Feedback Gaussian Random Number Generator (RLF-GRNG), which is inspired by the properties of binomial distribution and linear feedback logics; and 2) the Bayesian Neural Network-oriented Wallace Gaussian Random Number Generator. To achieve high scalability and efficient memory access, we propose a deep pipelined accelerator architecture with fast execution and good hardware utilization. Experimental results demonstrate that the proposed VIBNN implementations on an FPGA can achieve throughput of 321,543.4 Images/s and energy efficiency upto 52,694.8 Images/J while maintaining similar accuracy as its software counterpart.","FPGA, Bayesian neural network, neural network"
Conference Paper,"Fuzyi EM,da Silva MC,Barbon S",M-Health Solution on Pre-Diagnosis of Larynx,Brazilian Computer Society,2015,Not Found,"The study of new approaches that seek to improve the diagnosis of pathologies in the vocal folds process, is one of the main motivators for health research based on voice. Not only by the creation of new techniques, but in the use of already existing technologies using new approaches, such as the mobile technologies in fields they were never fully explored, or barely explored at all. This article is intended to further increase the development of the m-health's field, specifically the early diagnosis of the vocal fold's diseases through analysis of the fundamental frequency of the speaker's vocalization improving the support in medical decision. The result shows 95% with a minimum of 10hz difference.","M-Health, Larinx, Mobile Application, Electronic Medical Record, Voice"
Journal Article,"Elibol HM,Nguyen V,Linderman S,Johnson M,Hashmi A,Doshi-Velez F",Cross-Corpora Unsupervised Learning of Trajectories in Autism Spectrum Disorders,JMLR.org,2016,Not Found,"Patients with developmental disorders, such as autism spectrum disorder (ASD), present with symptoms that change with time even if the named diagnosis remains fixed. For example, language impairments may present as delayed speech in a toddler and difficulty reading in a school-age child. Characterizing these trajectories is important for early treatment. However, deriving these trajectories from observational sources is challenging: electronic health records only reflect observations of patients at irregular intervals and only record what factors are clinically relevant at the time of observation. Meanwhile, caretakers discuss daily developments and concerns on social media.In this work, we present a fully unsupervised approach for learning disease trajectories from incomplete medical records and social media posts, including cases in which we have only a single observation of each patient. In particular, we use a dynamic topic model approach which embeds each disease trajectory as a path in RD. A Pólya-gamma augmentation scheme is used to efficiently perform inference as well as incorporate multiple data sources. We learn disease trajectories from the electronic health records of 13,435 patients with ASD and the forum posts of 13,743 caretakers of children with ASD, deriving interesting clinical insights as well as good predictions.","disease progression model, dynamic topic model"
Conference Paper,"Wu X,Mattingly S,Mirjafari S,Huang C,Chawla NV",Personalized Imputation on Wearable-Sensory Time Series via Knowledge Transfer,Association for Computing Machinery,2020,https://doi.org/10.1145/3340531.3411879;http://dx.doi.org/10.1145/3340531.3411879,"The analysis of wearable-sensory time series data (e.g., heart rate records) benefits many applications (e.g., activity recognition, disease diagnosis). However, sensor measurements usually contain missing values due to various factors (e.g., user behavior, lack of charging), which may degrade the performance of downstream analytical tasks (e.g., regression, prediction). Thus, time series imputation is desired, which is capable of making sensory time series complete. Existing time series imputation methods generally employ various deep neural network models (e.g., GRU and GAN) to fill missing values by leveraging temporal patterns extracted from the contextual observations. Despite their effectiveness, we argue that most existing models can only achieve sub-optimal imputation performance due to the fact that they are inherently limited in sharing only one single set of model parameters to perform imputation on all individuals. Relying on one set of parameters limits the expressiveness of the imputation model as such models are bound to fail in capturing various complex personal characteristics. Therefore, most existing models tend to achieve inferior imputation performance, especially when a long duration of missing values, i.e., a large gap, is observed in the time series data. To address the limitation, this work develops a new imputation framework--Personalized Wearable-Sensory Time Series Imputation framework (PTSI) to provide a fully personalized treatment for time series imputation via effective knowledge transfer. In particular, PTSI first leverages a meta-learning paradigm to learn a well-generalized initialization to facilitate the adaption process for each user. To make the time series imputation be reflective of an individual's unique characteristics, we further endow PTSI with the capability of learning personalized model parameters, which is achieved by designing a parameter initialization modulating component. Extensive experiments on real-world human heart rate datasets demonstrate that our PTSI framework outperforms various state-of-the-art methods by a large margin consistently.","meta-learning, wearable-sensory time series imputation, personalization"
Conference Paper,"Shrestha A,Fegaras L,Zikos D",Temporal Modification of Apriori to Find Seasonal Variations between Symptoms and Diagnoses,Association for Computing Machinery,2018,https://doi.org/10.1145/3197768.3201562;http://dx.doi.org/10.1145/3197768.3201562,"Medical data can be mined for patterns, which may be used to predict candidate diagnoses according to symptoms and other parameters of care. Our hypothesis is that the admission (initial) patient assessment, when combined with seasonal information can provide more accurate insights for the patient diagnosis. For instance, when cough is the symptom, the probability for flu could be higher during the winter (flu season). We hereby present a method to estimate the temporal variation of the probability for a diagnosis, when the initial patient assessment is known. In order to develop the model, we utilized a large synthetic medical claims dataset from the Centers for Medicare and Medicaid Services. We used the Apriori algorithm to calculate the support and confidence for each 'admission_diagnosis final_diagnosis' itemset. For each itemset, 52 rules were generated, one for each week of a calendar year. The Apriori output was filtered so that only itemsets with the 'admission diagnosis' on the Left Hand Side(LHS) are extracted. We furthermore smoothened, using the Exponentially Weighted Moving Average (EWMA) algorithm, and then visualized the week-by-week variability of confidence, for any 'admission_diagnosis fmal_diagnosis' pair of interest. With our approach, researchers can observe seasonal variations of the diagnosis element, and further study these variations for causal knowledge discovery.","Apriori, Association Rule Mining, Seasonal Variations, Clinical Decision Making, Health Informatics"
Conference Paper,"Fabris A,Messina S,Silvello G,Susto GA",Tackling Documentation Debt: A Survey on Algorithmic Fairness Datasets,Association for Computing Machinery,2022,https://doi.org/10.1145/3551624.3555286;http://dx.doi.org/10.1145/3551624.3555286,"A growing community of researchers has been investigating the equity of algorithms, advancing the understanding of risks and opportunities of automated decision-making for historically disadvantaged populations. Progress in fair Machine Learning (ML) hinges on data, which can be appropriately used only if adequately documented. Unfortunately, the research community, as a whole, suffers from a collective data documentation debt caused by a lack of information on specific resources (opacity) and scatteredness of available information (sparsity). In this work, we survey over two hundred datasets employed in algorithmic fairness research, producing standardized and searchable documentation for each of them. Moreover we rigorously identify the three most popular fairness datasets, namely Adult, COMPAS, and German Credit, for which we compile in-depth documentation. This unifying documentation effort targets documentation sparsity and supports multiple contributions. In the first part of this work, we summarize the merits and limitations of Adult, COMPAS, and German Credit, adding to and unifying recent scholarship, calling into question their suitability as general-purpose fairness benchmarks. To overcome this limitation, we document hundreds of available alternatives, annotating their domain and the algorithmic fairness tasks they support, along with additional properties of interest for fairness practitioners and researchers, including their format, cardinality, and the sensitive attributes they encode. In the second part, we summarize this information, zooming in on the domains and tasks supported by these resources. Overall, we assemble and summarize sparse information on hundreds of datasets into a single resource, which we make available to the community, with the aim of tackling the data documentation debt.","Algorithmic fairness, Documentation debt., Data studies"
Conference Paper,"Colella Y,De Lauri C,Maria Ponsiglione A,Giglio C,Lombardi A,Borrelli A,Amato F,Romano M",A Comparison of Different Machine Learning Algorithms for Predicting the Length of Hospital Stay for Pediatric Patients,Association for Computing Machinery,2022,https://doi.org/10.1145/3502060.3503648;http://dx.doi.org/10.1145/3502060.3503648,"Prolonged length of stay (LOS) is one of the most significant issues that hospitals must face since it can determine an increase of costs and risk of complications and a decrease of patient satisfaction. The capability of accurately predicting LOS is a valuable tool for helping hospital administrators in resource planning, encouraging quality improvement actions and providing support for medical practice. In particular, delayed hospital discharge in pediatric population is something that needs to be carefully considered because of their vulnerability and complexity from the medical viewpoint. Predicting the use of hospital resources and beds in pediatric departments could also help to better dimension hospitalizations management. This work has the aim to determine the predictive factors for the length of stay for patients admitted to the Complex Operative Units of Pediatrics and Pediatric Surgery at the “San Giovanni di Dio e Ruggi d'Aragona” University Hospital of Salerno and to build a classification model of LOS exploiting the potential of Machine Learning. Different algorithms are implemented, and their evaluation metrics are assessed and compared together to develop a prediction model with high performances.","Pediatric patients, Length of stay, Machine Learning"
Conference Paper,"Niu Y,Zhu D,Liu L,Tan W,Zhao W,Liu S",Regression Study on Influencing Factors of COVID-19 Diagnosis Rate and Mortality: A Global Perspective,Association for Computing Machinery,2022,https://doi.org/10.1145/3565291.3565350;http://dx.doi.org/10.1145/3565291.3565350,"The novel coronavirus pneumonia (COVID-19) refers to the pulmonary infection caused by the novel coronavirus (2019-nCoV), which has become an urgent public health event of global concern at present. In order to help local governments to find out the factors that curb the spread of COVID-19, we explored the influence factors that cause COVID-19 infection and death in the fields of economy, society, life, and health in this paper. Through correlation analysis, we found that COVID-19 transmission and mortality are relatively strongly associated with human development index (HDI), Median Age, human life expectancy, proportion of smokers, and GDP per capita. Further regression analysis and machine learning regression algorithms also confirmed that HDI, proportion of smokers, GDP per capita, and Median Age have significant effects on COVID-19 transmission and mortality, with GBDT performing best with R² of 0.585 and 0.415 per million confirmed cases and deaths, respectively. This study aims to explore the impact of relevant factors on COVID-19 in the international community, inform the development of measures to reduce diagnosis and mortality rates in countries, and improve the capacity to respond to such public health emergencies.","Regression analysis, GBDT, Data analysis, Correlation analysis, COVID-19"
Conference Paper,Noiret S,Assessing Algorithmic Fairness without Sensitive Information,Association for Computing Machinery,2021,https://doi.org/10.1145/3462203.3475894;http://dx.doi.org/10.1145/3462203.3475894,"As the prevalence of algorithmic decision-making increases, so does the study of algorithmic fairness. When this aspect is disregarded, bias and discrimination are created, reproduced or amplified. Accordingly, work has been done to harmonize definitions of fairness and categorize ways to improve it. While using demographic data about the protected group is a possible solution, in real-world applications privacy concerns as well as uncertainty about the relevant attributes make it unrealistic. Consequently, we seek in this work to provide an overview of the methods that do not require such data, to identify which areas might be under-researched and to propose research questions for the first phase of the PhD. The influence of datasets size in the discovery and mitigation of unknown biases appears to be such an area, one that we plan to explore more fully during the thesis.","sensitive data, fairness, machine learning, bias"
Conference Paper,"He J,Gao L,Wang B,Wang R,Cheng R",Construction of Perioperative Risk Assessment Model for Elderly Patients Based on Machine Learning,Association for Computing Machinery,2022,https://doi.org/10.1145/3544109.3544184;http://dx.doi.org/10.1145/3544109.3544184,"Elderly patients have low surgical tolerance, weak postoperative basic metabolism and recovery ability, often accompanied by chronic diseases, which not only increases the risk of perioperative complications, but also improves the mortality of patients. Clinically, APACHE II, possum, ASA, SRS, TS, MODS, NNIS and other scales are usually used for preoperative risk assessment. The existing quantitative evaluation methods are easily affected by the patients' own diseases, fail to focus to the elderly patients, and cannot consider all the influencing factors before, during and after operation. Machine learning model has the advantages of strong robustness and excellent generalization ability, which has been widely used in medical aided diagnosis. Therefore, based on the literature analysis and combined with the existing quantitative scoring methods and statistical analysis methods, the study extracts and screens out the elements of the clinical evaluation model, then constructs the perioperative risk evaluation model of elderly patients by the machine learning method, which can refer to not only the operation implementation process and recent post-operative factors, but also the basic state of patients, chronic diseases history, operation difficulty, degree of anesthesia, degree of recovery, etc. In test, the ANN model has the highest accuracy and recall in the prediction of perioperative complications in elderly patients, 96.77 percent and 98.33 percent respectively, which is better than 85.48 percent and 68.33 percent of the traditional possum method. The accuracy and recall rate of SVM model in predicting perioperative death of elderly patients are the highest, which can reach 84.56 percent and 90.48 percent respectively, which are better than APACHE II, ASA and P-POSSUM evaluation models. In study, the machine learning model has a good prediction effect in the perioperative risk assessment for elderly patients, and can also be used as an auxiliary decision-making tool for clinical perioperative risk assessment.","Forecast, Elderly patients, Perioperative period, Machine learning, Risks"
Book Chapter,"Tumuluri R,Dahl D,Paternò F,Zancanaro M",Standardized Representations and Markup Languages for Multimodal Interaction,Association for Computing Machinery and Morgan & Claypool,2019,https://doi.org/10.1145/3233795.3233806;http://dx.doi.org/10.1145/3233795.3233806,Not Found,Not Found
Book Chapter,"Feld M,Neβelrath R,Schwartz T",Software Platforms and Toolkits for Building Multimodal Systems and Applications,Association for Computing Machinery and Morgan & Claypool,2019,https://doi.org/10.1145/3233795.3233801;http://dx.doi.org/10.1145/3233795.3233801,Not Found,Not Found
Conference Paper,"Min Htike H,H. Margrain T,Lai YK,Eslambolchilar P",Augmented Reality Glasses as an Orientation and Mobility Aid for People with Low Vision: A Feasibility Study of Experiences and Requirements,Association for Computing Machinery,2021,https://doi.org/10.1145/3411764.3445327;http://dx.doi.org/10.1145/3411764.3445327,"People with low vision experience reduced mobility that affects their physical and mental wellbeing. With augmented reality (AR) glasses, there are new opportunities to provide visual and auditory information that can improve mobility for this vulnerable group. Current research into AR-based mobility aids has focused mainly on the technical aspects, and less emphasis has been placed on understanding the usability and suitability of these aids in people with various levels of visual impairment. In this paper, we present the results of qualitative interviews with 18 participants using HoloLens v1 and eight prototype augmentations to understand how these enhancements are perceived by people with low vision and how these aids should be adjusted to suit their needs. Our results suggested that participants with moderate vision loss could potentially perceive the most benefit from glasses and underlined the importance of extensive customizability to accommodate the needs of a highly varied low vision population.","mobility aids, vision enhancement, low vision, augmented reality"
Book Chapter,"Friedland G,Tschantz MC",Privacy Concerns of Multimodal Sensor Systems,Association for Computing Machinery and Morgan & Claypool,2019,https://doi.org/10.1145/3233795.3233813;http://dx.doi.org/10.1145/3233795.3233813,Not Found,Not Found
Conference Paper,"Zhou M,Zhang Y,Liu T,Yang Y,Yang P",Multi-Task Learning with Adaptive Global Temporal Structure for Predicting Alzheimer's Disease Progression,Association for Computing Machinery,2022,https://doi.org/10.1145/3511808.3557406;http://dx.doi.org/10.1145/3511808.3557406,"In this paper, we propose a multi-task learning approach for predicting the progression of Alzheimer's disease (AD), known as the most common form of dementia. The vital challenge is to identify how the tasks are related and build learning models to capture such task relatedness. Unlike previous methods that assume low-rank structure, chase the predefined local temporal relatedness or utilize local approximation, we propose a novel penalty termed L ongitudinal S tability A djustment (LSA) to adaptively capture the intrinsic global temporal correlation among multiple time points and thus utilize the accumulated disease progression information. We combine LSA with sparse group Lasso to present a novel multi-task learning formulation to identify biomarkers closely related to cognitive measurement and predict AD progression. Two efficient algorithms are designed for large-scale dataset. Experimental results conducted on two AD data sets demonstrate our framework outperforms competing methods in terms of overall and each task performances. We also perform stability selection to identify stable biomarkers from the MRI feature set and analyze their temporal patterns in disease progression.","disease progression, alzheimer's disease, identification of biomarkers, adaptive global temporal relation"
Book Chapter,Johnston M,Multimodal Integration for Interactive Conversational Systems,Association for Computing Machinery and Morgan & Claypool,2019,https://doi.org/10.1145/3233795.3233798;http://dx.doi.org/10.1145/3233795.3233798,Not Found,Not Found
Conference Paper,"Nolting M,Wittke U",OJO: Fuzzy Logic Based Digital Health Coaching for Scalable Diabetes Prevention,Association for Computing Machinery,2019,https://doi.org/10.1145/3329189.3329225;http://dx.doi.org/10.1145/3329189.3329225,"Prediabetes (the pre-diagnosis of type 2 diabetes) is at epidemic levels all over the world and still increasing. By 2030, 470 million people will suffer from this disease.Lifestyle interventions can significantly counteract the risk of developing type 2 diabetes. We present a scalable approach for lifestyle coaching by translating the American Diabetes Prevention Program into a dynamic, self-empowering, online-program, to which we have added a digital health coach based on fuzzy logic that will act like a nutrition coach. We conducted a 5-year study and concluded with enough evidence that the digital health coach is effective and that participants achieve an average weight loss of 5.6 kg over the course of 2 years.","Prediabetes, Lifestyle coaching, Fuzzy Logic, Diabetes Prevention Program"
Conference Paper,"Sheth A,Perera S,Wijeratne S,Thirunarayan K",Knowledge Will Propel Machine Understanding of Content: Extrapolating from Current Examples,Association for Computing Machinery,2017,https://doi.org/10.1145/3106426.3109448;http://dx.doi.org/10.1145/3106426.3109448,"Machine Learning has been a big success story during the AI resurgence. One particular stand out success relates to learning from a massive amount of data. In spite of early assertions of the unreasonable effectiveness of data, there is increasing recognition for utilizing knowledge whenever it is available or can be created purposefully. In this paper, we discuss the indispensable role of knowledge for deeper understanding of content where (i) large amounts of training data are unavailable, (ii) the objects to be recognized are complex, (e.g., implicit entities and highly subjective content), and (iii) applications need to use complementary or related data in multiple modalities/media. What brings us to the cusp of rapid progress is our ability to (a) create relevant and reliable knowledge and (b) carefully exploit knowledge to enhance ML/NLP techniques. Using diverse examples, we seek to foretell unprecedented progress in our ability for deeper understanding and exploitation of multimodal data and continued incorporation of knowledge in learning techniques.","personalized digital health, multimodal exploitation, emoji sense disambiguation, semantic-cognitive-perceptual computing, knowledge-enhanced NLP, knowledge-driven deep content understanding, understanding complex text, knowledge-enhanced machine learning, machine intelligence, implicit entity recognition"
Conference Paper,"Marques HO,Campello RJ,Zimek A,Sander J",On the Internal Evaluation of Unsupervised Outlier Detection,Association for Computing Machinery,2015,https://doi.org/10.1145/2791347.2791352;http://dx.doi.org/10.1145/2791347.2791352,"Although there is a large and growing literature that tackles the unsupervised outlier detection problem, the unsupervised evaluation of outlier detection results is still virtually untouched in the literature. The so-called internal evaluation, based solely on the data and the assessed solutions themselves, is required if one wants to statistically validate (in absolute terms) or just compare (in relative terms) the solutions provided by different algorithms or by different parameterizations of a given algorithm in the absence of labeled data. However, in contrast to unsupervised cluster analysis, where indexes for internal evaluation and validation of clustering solutions have been conceived and shown to be very useful, in the outlier detection domain this problem has been notably overlooked. Here we discuss this problem and provide a solution for the internal evaluation of top-n (binary) outlier detection results. Specifically, we propose an index called IREOS (Internal, Relative Evaluation of Outlier Solutions) that can evaluate and compare different candidate labelings of a collection of multivariate observations in terms of outliers and inliers. We also statistically adjust IREOS for chance and extensively evaluate it in several experiments involving different collections of synthetic and real data sets.","validation, outlier detection, unsupervised evaluation"
Conference Paper,"Santos K,Feistauer L,Carvalho M,Silva L,Rezende K",SiSPED 2.0: An Extension of a System to Monitor Diabetic Patients,Association for Computing Machinery,2012,https://doi.org/10.1145/2261605.2261607;http://dx.doi.org/10.1145/2261605.2261607,"Diabetes Mellitus is a chronic degenerative disease accepted as a worldwide epidemic. The diabetic foot is one of the most fearful complications of diabetic patients and is responsible for fifty percent of non-traumatic lower-extremity amputations in general hospitals. Foot complications in diabetic patients can be prevented, in most of the cases, by submitting patients to continuous foot examinations and to a personal reeducation process. This paper describes an extension of SiSPED, a system to monitor patients with the possibility of developing the diabetic foot. In this extension the system has been entirely redesigned and new technologies are used to improve performance and maintainability. In addition, the rules applied to generate automatically a diagnostic report are updated to follow international guidelines applied in the diabetic foot prevention. The system also allows the correlation of patient data, essential to measure the impact of the methodology for diabetic foot prevention on the assisted population.","web systems, diabetes mellitus, medical informatics"
Conference Paper,"Jiang S,Wu H,Luo L",Infusing Biomedical Knowledge into BERT for Chinese Biomedical NLP Tasks with Adversarial Training,Association for Computing Machinery,2022,https://doi.org/10.1145/3523181.3523197;http://dx.doi.org/10.1145/3523181.3523197,"Biomedical text mining is becoming increasingly important. Recently, biomedical pre-trained language models such as BioBERT and SciBERT, which can capture biomedical knowledge from text, have achieved promising results in biomedical NLP tasks. However, most biomedical pre-trained language models rely on the traditional masked language model (MLM) pre-training strategy, which cannot fully capture the semantic relations of context. It is challenging to learn biomedical knowledge via language models in the Chinese biomedical fields due to the lack of training resources and the extreme complexity and diversity of Chinese medical terminologies. To this end, we propose MedBERT-adv, which utilizes a biomedical knowledge infusion method that can effectively complement BERT-like models. Instead of using time-consuming medical expert annotation and inaccurate automatic annotation, we use the article structure in Baidu Encyclopedia as a weakly supervised signal, utilizing each medical term and its category as labels to pre-train the model. We also leverage adversarial training strategies like FGM for fine-tuning downstream tasks to further improve the performance of MedBERT-adv. We experimented with MedBERT-adv on the Chinese biomedical dataset CBLUE using eight NLP tasks. Among all of them, our proposed model obtained an average 1.8% improvement in average score than four baseline models, demonstrating the effectiveness of MedBERT-adv on Chinese biomedical text mining.",Not Found
Conference Paper,"Pal A,Prakash C",Personalized Knee Angle Prediction Models Using Machine Learning,Association for Computing Machinery,2022,https://doi.org/10.1145/3549206.3549233;http://dx.doi.org/10.1145/3549206.3549233,"Gait analysis had been traditionally used to diagnose underlying pathological conditions, but recently it has seen widespread applications in varied fields like bio-metrics, rehabilitation, sports, animation, etc. This study focuses on the rehabilitation prospects of lower limb amputees and to accurately predict their natural knee angle using easily available body parameters. This would ensure easier and better rehabilitation. The subjects included in the study belong to the MNIT Gait Dataset, collected by RAMAN Lab in MNIT Jaipur. For analysis, the study compares various supervised machine learning models across several regression evaluation metrics to achieve the final objective of predicting a subject’s knee angle accurately. The results from this study can be used in areas with low technology penetration for better patient rehabilitation.","machine learning, neural networks, knee angle, human gait"
Conference Paper,"Jagusch JB,Gonçalves I,Castelli M",Neuroevolution under Unimodal Error Landscapes: An Exploration of the Semantic Learning Machine Algorithm,Association for Computing Machinery,2018,https://doi.org/10.1145/3205651.3205778;http://dx.doi.org/10.1145/3205651.3205778,"Neuroevolution is a field in which evolutionary algorithms are applied with the goal of evolving Neural Networks (NNs). This paper studies different variants of the Semantic Learning Machine (SLM) algorithm, a recently proposed supervised learning neuroevolution method. Perhaps the most interesting characteristic of SLM is that it searches over unimodal error landscapes in any supervised learning problem where the error is measured as a distance to the known targets. SLM is compared with the NeuroEvolution of Augmenting Topologies (NEAT) algorithm and with a fixed-topology neuroevolution approach. Experiments are performed on a total of 9 real-world regression and classification datasets. The results show that the best SLM variants generally outperform the other neuroevolution approaches in terms of generalization achieved, while also being more efficient in learning the training data. The best SLM variants also outperform the common NN backpropagation-based approach under different topologies. The most efficient SLM variant used in combination with a recently proposed semantic stopping criterion is capable of evolving competitive neural networks in a few seconds on the vast majority of the datasets considered. A final comparison shows that a NN ensemble built with SLM is able to outperform the Random Forest algorithm in two classification datasets.","semantic learning machine, MLP, NEAT, neuroevolution"
Conference Paper,"Baldominos A,del Barrio C,Saez Y",Exploring the Application of Hybrid Evolutionary Computation Techniques to Physical Activity Recognition,Association for Computing Machinery,2016,https://doi.org/10.1145/2908961.2931732;http://dx.doi.org/10.1145/2908961.2931732,"This paper focuses on the problem of physical activity recognition, i.e., the development of a system which is able to learn patterns from data in order to be able to detect which physical activity (e.g. running, walking, ascending stairs, etc.) a certain user is performing.While this field is broadly explored in the literature, there are few works that face the problem with evolutionary computation techniques. In this case, we propose a hybrid system which combines particle swarm optimization for clustering features and genetic programming combined with evolutionary strategies for evolving a population of classifiers, shaped in the form of decision trees. This system would run the segmentation, feature extraction and classification stages of the activity recognition chain.For this paper, we have used the PAMAP2 dataset with a basic preprocessing. This dataset is publicly available at UCI ML repository. Then, we have evaluated the proposed system using three different modes: a user-independent, a user-specific and a combined one. The results in terms of classification accuracy were poor for the first and the last mode, but it performed significantly well for the user-specific case. This paper aims to describe work in progress, to share early results an discuss them. There are many things that could be improved in this proposed system, but overall results were interesting especially because no manual data transformation took place.","particle swarm optimization, classification, metaheuristics, hybrid evolutionary computation, activity recognition, physical activity, genetic programming"
Conference Paper,"Rathee D,Rathee M,Kumar N,Chandran N,Gupta D,Rastogi A,Sharma R",CrypTFlow2: Practical 2-Party Secure Inference,Association for Computing Machinery,2020,https://doi.org/10.1145/3372297.3417274;http://dx.doi.org/10.1145/3372297.3417274,"We present CrypTFlow2, a cryptographic framework for secure inference over realistic Deep Neural Networks (DNNs) using secure 2-party computation. CrypTFlow2 protocols are both correct -- i.e., their outputs are bitwise equivalent to the cleartext execution -- and efficient -- they outperform the state-of-the-art protocols in both latency and scale. At the core of CrypTFlow2, we have new 2PC protocols for secure comparison and division, designed carefully to balance round and communication complexity for secure inference tasks. Using CrypTFlow2, we present the first secure inference over ImageNet-scale DNNs like ResNet50 and DenseNet121. These DNNs are at least an order of magnitude larger than those considered in the prior work of 2-party DNN inference. Even on the benchmarks considered by prior work, CrypTFlow2 requires an order of magnitude less communication and 20x-30x less time than the state-of-the-art.","secure two-party computation, deep neural networks, privacy-preserving inference"
Conference Paper,Liu X,"Review of the Pathology, Diagnosis and Treatment for Alzheimer's Disease",Association for Computing Machinery,2021,https://doi.org/10.1145/3448748.3448767;http://dx.doi.org/10.1145/3448748.3448767,"Alzheimer's disease (AD), the leading cause of dementia--a continuous decline in thinking, behavioral and social skills--worldwide in the late ages, is becoming increasingly serious due to the fact that the global population is aging. However it is not a normal part of aging. It is now threatening public health systems. Countless families are suffering from older members' cognitive decline. Memory loss is typical of the symptoms. Although there are some medications that relieve the symptoms for AD patients, further research on a definitive cure of this disease is still in urgent necessity. This review is talking about updates on AD's pathology, diagnosis and treatment.","amyloid cascade hypothesis, beta amyloid, neuroinflammation, tau protein"
Book Chapter,"Kirchner EA,Fairclough SH,Kirchner F","Embedded Multimodal Interfaces in Robotics: Applications, Future Trends, and Societal Implications",Association for Computing Machinery and Morgan & Claypool,2019,https://doi.org/10.1145/3233795.3233810;http://dx.doi.org/10.1145/3233795.3233810,Not Found,Not Found
Conference Paper,"Junsomboon N,Phienthrakul T",Combining Over-Sampling and Under-Sampling Techniques for Imbalance Dataset,Association for Computing Machinery,2017,https://doi.org/10.1145/3055635.3056643;http://dx.doi.org/10.1145/3055635.3056643,"An important problem in medical data analysis is imbalance dataset. This problem is a cause of diagnostic mistake. The results of diagnostic affect to life of patients. If a doctor fails in diagnostic of patient who have disease that means he cannot treat patient in timely. However, the problem can be easily solved by adding or removing the data to closely balance for performance of diagnostic in medically. This paper proposed a solution to adjust imbalance dataset by combining Neighbor Cleaning Rule (NCL) and Synthetic Minority Over-Sampling Technique (SMOTE) techniques. The process of work is using NCL technique for removing sample data that are outliers in majority class and SMOTE technique is used for increasing sample data in minority class to closely balance dataset. After that, the balanced medical dataset is classified by Naive Bayes, SMO and KNN algorithm. The experimental results show that the recall rate can be improved from the models that were created from balanced dataset.","Medical Data, Data Mining, NCL, Imbalance Dataset, Classification, SMOTE"
Book,Not Found,CSSE '22: Proceedings of the 5th International Conference on Computer Science and Software Engineering,Association for Computing Machinery,2022,Not Found,Not Found,Not Found
Journal Article,"Ding H,Luo X",Attention-Based Unsupervised Keyphrase Extraction and Phrase Graph for COVID-19 Medical Literature Retrieval,Association for Computing Machinery,2021,https://doi.org/10.1145/3473939;http://dx.doi.org/10.1145/3473939,"Searching, reading, and finding information from the massive medical text collections are challenging. A typical biomedical search engine is not feasible to navigate each article to find critical information or keyphrases. Moreover, few tools provide a visualization of the relevant phrases to the query. However, there is a need to extract the keyphrases from each document for indexing and efficient search. The transformer-based neural networks—BERT has been used for various natural language processing tasks. The built-in self-attention mechanism can capture the associations between words and phrases in a sentence. This research investigates whether the self-attentions can be utilized to extract keyphrases from a document in an unsupervised manner and identify relevancy between phrases to construct a query relevancy phrase graph to visualize the search corpus phrases on their relevancy and importance. The comparison with six baseline methods shows that the self-attention-based unsupervised keyphrase extraction works well on a medical literature dataset. This unsupervised keyphrase extraction model can also be applied to other text data. The query relevancy graph model is applied to the COVID-19 literature dataset and to demonstrate that the attention-based phrase graph can successfully identify the medical phrases relevant to the query terms.","COVID-19, deep learning, medical information retrieval, Keyphrase extraction"
Conference Paper,"Alshawaqfeh M,Gharaibeh A,Wajid B",A Hybrid Feature Selection Method for Classifying Metagenomic Data in Relation to Inflammatory Bowel Disease,Association for Computing Machinery,2020,https://doi.org/10.1145/3369114.3371675;http://dx.doi.org/10.1145/3369114.3371675,"Due to the recent advances in high throughput metagenomic sequencing technologies, Microbial abundance profiles of environmental samples have become publicly available. Increasing number of metagenomic studies has associated the imbalance of bacterial abundance to health and disase state of the host. This suggests utilizing the bacterial profiles as a diagnostic tool to identify the bacterial-related disease state of individuals. However, the high dimensional nature of metagenomic datasets renders this process a challenging task. Therefore, an efficient framework that enables accurate classification of metagenomic samples belonging to different classes is of central important. In this work, a hybrid feature selection technique that combines the advantages of filter and wrapper feature selection algorithms is proposed. The experimental results demonstrate that the proposed algorithm outperforms widely used feature selection techniques in terms of classification accuracy and provide a significant reduction in the computation time.","Metagenomics, Classification, Hybrid Feature Selection"
Journal Article,"Ooi BC,Tan KL,Tran QT,Yip JW,Chen G,Ling ZJ,Nguyen T,Tung AK,Zhang M",Contextual Crowd Intelligence,Association for Computing Machinery,2014,https://doi.org/10.1145/2674026.2674032;http://dx.doi.org/10.1145/2674026.2674032,"Most data analytics applications are industry/domain specific, e.g., predicting patients at high risk of being admitted to intensive care unit in the healthcare sector or predicting malicious SMSs in the telecommunication sector. Existing solutions are based on ""best practices"", i.e., the systems' decisions are knowledge-driven and/or data-driven. However, there are rules and exceptional cases that can only be precisely formulated and identified by subject-matter experts (SMEs) who have accumulated many years of experience. This paper envisions a more intelligent database management system (DBMS) that captures such knowledge to effectively address the industry/domain specific applications. At the core, the system is a hybrid human-machine database engine where the machine interacts with the SMEs as part of a feedback loop to gather, infer, ascertain and enhance the database knowledge and processing. We discuss the challenges towards building such a system through examples in healthcare predictive analysis -- a popular area for big data analytics.",Not Found
Conference Paper,"Bai J,Song X,Cui S,Chang EC,Russello G",Scalable Private Decision Tree Evaluation with Sublinear Communication,Association for Computing Machinery,2022,https://doi.org/10.1145/3488932.3517413;http://dx.doi.org/10.1145/3488932.3517413,"Private decision tree evaluation (PDTE) allows a decision tree holder to run a secure protocol with a feature provider. By running the protocol, the feature provider will learn a classification result. Nothing more is revealed to either party. In most existing PDTE protocols, the required communication grows exponentially with the tree's depth d, which is highly inefficient for large trees. This shortcoming motivated us to design a sublinear PDTE protocol with $O(d)$ communication complexity. The core of our construction is a shared oblivious selection (SOS) functionality, allowing two parties to perform a secret-shared oblivious read operation from an array. We provide two SOS protocols, both of which achieve sublinear communication and propose optimizations to further improve their efficiency. Our sublinear PDTE protocol is based on the proposed SOS functionality and we prove its security under a semi-honest adversary. We compare our protocol with the state-of-the-art, in terms of communication and computation, under various network settings. The performance evaluation shows that our protocol is practical and more scalable over large trees than existing solutions.","decision tree, secure computation, sublinear communication"
Conference Paper,"Scala A,Loperto I,Carrano R,Federico S,Triassi M,Improta G",Assessment of Proteinuria Level in Nephrology Patients Using a Machine Learning Approach,Association for Computing Machinery,2021,https://doi.org/10.1145/3472813.3472816;http://dx.doi.org/10.1145/3472813.3472816,"Proteinuria represents an increase in the urinary excretion of proteins. It could also follow kidney transplantation and affects more than 40% of kidney transplant patients per year. It results from protein increases in their filtered load, due to alterations in the selectivity of the glomerular capillary wall, or from defects in their tubular uptake. Different parameters are associated with the various stages of proteinuria and therefore allow characterizing of its severity. For this purpose, the variation of proteinuria was evaluated by loading input two parameters: glycemia and the blood level of the m-Tor inhibitor. Through combination of data with different machine learning algorithms, the goal of this research work was to evaluate how blood glucose values and the use of immunosuppressive drugs can lead to prediction proteinuria classification in patients.",Not Found
Conference Paper,"Rumao P,Padole M","Alzheimer's Disease: Symptoms, Causes and Computer Science Applications as Help Guides",Association for Computing Machinery,2022,https://doi.org/10.1145/3484824.3484886;http://dx.doi.org/10.1145/3484824.3484886,"Alzheimer's disease (AD) is a specific type of irreversible dementia which again deteriorates the mental health of a person hence majorly hinder the way of life of an affected person. The purpose of this article is to focus on a brief introduction of Alzheimer's along with its life cycle. This article shows torch towards widely known as well as novel symptoms of Alzheimer's in addition to probable key causes of it. Moreover, the article catalogs computer science applications and technologies that can aid in either detecting or assisting a person suffering from Alzheimer's, which will further help computer science students to help understand Alzheimer's and build more such aids.","Deep Learning, CNN, neurons, Dementia, CS Applications, Alzheimers' Disease (AD)"
Journal Article,"Zaidi NA,Cerquides J,Carman MJ,Webb GI",Alleviating Naive Bayes Attribute Independence Assumption by Attribute Weighting,JMLR.org,2013,Not Found,"Despite the simplicity of the Naive Bayes classifier, it has continued to perform well against more sophisticated newcomers and has remained, therefore, of great interest to the machine learning community. Of numerous approaches to refining the naive Bayes classifier, attribute weighting has received less attention than it warrants. Most approaches, perhaps influenced by attribute weighting in other machine learning algorithms, use weighting to place more emphasis on highly predictive attributes than those that are less predictive. In this paper, we argue that for naive Bayes attribute weighting should instead be used to alleviate the conditional independence assumption. Based on this premise, we propose a weighted naive Bayes algorithm, called WANBIA, that selects weights to minimize either the negative conditional log likelihood or the mean squared error objective functions. We perform extensive evaluations and find that WANBIA is a competitive alternative to state of the art classifiers like Random Forest, Logistic Regression and A1DE.","classification, attribute independence assumption, weighted naive bayes classification, naive bayes"
Journal Article,"Tao Y,Yang C,Wang T,Coltey E,Jin Y,Liu Y,Jiang R,Fan Z,Song X,Shibasaki R,Chen SC,Shyu ML,Luis S",A Survey on Data-Driven COVID-19 and Future Pandemic Management,Association for Computing Machinery,2022,https://doi.org/10.1145/3542818;http://dx.doi.org/10.1145/3542818,"The COVID-19 pandemic has resulted in more than 440 million confirmed cases globally and almost 6 million reported deaths as of March 2022. Consequently, the world experienced grave repercussions to citizens’ lives, health, wellness, and the economy. In responding to such a disastrous global event, countermeasures are often implemented to slow down and limit the virus’s rapid spread. Meanwhile, disaster recovery, mitigation, and preparation measures have been taken to manage the impacts and losses of the ongoing and future pandemics. Data-driven techniques have been successfully applied to many domains and critical applications in recent years. Due to the highly interdisciplinary nature of pandemic management, researchers have proposed and developed data-driven techniques across various domains. However, a systematic and comprehensive survey of data-driven techniques for pandemic management is still missing. In this article, we review existing data analysis and visualization techniques and their applications for COVID-19 and future pandemic management with respect to four phases (namely, Response, Recovery, Mitigation, and Preparation) in disaster management. Data sources utilized in these studies and specific data acquisition and integration techniques for COVID-19 are also summarized. Furthermore, open issues and future directions for data-driven pandemic management are discussed.","COVID-19, Data analytics, pandemic management, data visualization"
Conference Paper,"Song S,Chen T,Antoniou G",ANFIS Models for Heart Disease Prediction,Association for Computing Machinery,2021,https://doi.org/10.1145/3461353.3461354;http://dx.doi.org/10.1145/3461353.3461354,"Coronary heart disease is the one of the most common diseases and a major cause of death internationally. The early detection and prediction of such disease is thus very important for human life. Currently, the Adaptive Neural Fuzzy Inference System (ANFIS) is increasingly becoming popular in the field of prediction and diagnosis of medical disease, because ANFIS can arrive at the definite conclusion by dealing with ambiguous, imprecise and vague information in activities or processes. This paper reviews the application of ANFIS in the field of heart disease prediction, as well as some innovative combinations of ANFIS and other techniques for clinical decision support on heart disease diagnosis. Finally, we identify ideas for future work aiming to improve ANFIS model.","Coronary heart disease, ANFIS, Heart disease prediction"
Conference Paper,"Hammer S,Kim J,André E",MED-StyleR: METABO Diabetes-Lifestyle Recommender,Association for Computing Machinery,2010,https://doi.org/10.1145/1864708.1864768;http://dx.doi.org/10.1145/1864708.1864768,Lifestyle plays an essential role in controlling diabetes and in both the prevention and management of diabetes. Many reports from clinical research support the theory that healthy eating and regular exercise are much more effective at managing diabetes than traditional medication. In this paper we introduce an innovative approach to the multimodal recommender system conceived in the EU METABO project. The most important feature of the METABO Diabetes-Lifestyle Recommender (MED-StyleR) is to generate highly personalized recommendations that satisfy medical prescriptions for patients' long-term health alongside and short-term preferences of patients in their daily lives.,"recommender system, clinical decision support system, rule-based recommendations, diabetes management"
Conference Paper,"Velasco JM,Winkler S,Hidalgo JI,Garnica O,Lanchares J,Colmenar JM,Maqueda E,Botella M,Rubio JA",Data-Based Identification of Prediction Models for Glucose,Association for Computing Machinery,2015,https://doi.org/10.1145/2739482.2768508;http://dx.doi.org/10.1145/2739482.2768508,"Diabetes mellitus is a disease that affects to hundreds of million of people worldwide. Maintaining a good control of the disease is critical to avoid severe long-term complications. One of the main problems that arise in the (semi) automatic control of diabetes, is to get a model explaining how glucose levels in blood vary with insulin, food intakes and other factors, fitting the characteristics of each individual or patient. In this paper we compare genetic programming techniques with a set of classical identification techniques: classical simple exponential smoothing, Holt's smoothing (linear, exponential and damped), classical Holt and Winters methods and auto regressive integrated moving average modeling. We consider predictions horizons of 30, 60, 90 and 120 minutes. Experimental results shows the difficulty of predicting glucose values for more than 60 minutes and the necessity of adapt GP techniques for those dynamic environments.","genetic programming, modeling, diabetes"
Journal Article,"Arabameri A,Asemani D,Teymourpour P",Detection of Colorectal Carcinoma Based on Microbiota Analysis Using Generalized Regression Neural Networks and Nonlinear Feature Selection,IEEE Computer Society Press,2020,https://doi.org/10.1109/TCBB.2018.2870124;http://dx.doi.org/10.1109/TCBB.2018.2870124,"To obtain a screening tool for colorectal cancer (CRC) based on gut microbiota, we seek here to identify an optimal classifier for CRC detection as well as a novel nonlinear feature selection method for determining the most discriminative microbial species. In this study, the intestinal microflora in feces of 141 patients were modeled using general regression neural networks (GRNNs) combined with the proposed feature selection method. The proposed model led to slightly higher accuracy $mathrm(AUC= mathrm0.911)$( AUC =0.911) than previous studies $mathrm(AUC( AUC 0.87). The results show that the Clostridium scindens and Bifidobacterium angulatum are indicators of healthy gut flora and CRC happens to reduce these bacterial species. In addition, Fusobacterium gonidiaformans was found to be closely correlated with the CRC. The occurrence of colorectal adenoma was not sufficiently discriminatory based on fecal microbiota implicating that the change of colonic flora happens in the advanced phase of CRC development rather than initial adenoma. Integrating the proposed model with fecal occult blood test (FOBT), the CRC detection accuracy remained nearly unchanged $mathrm(AUC= mathrm0.915)$( AUC =0.915). The performance of the proposed method is validated using independent cohorts from America and Austria. Our results suggest that the proposed feature selection method combined with GRNN is potentially an accurate method for CRC detection.",Not Found
Conference Paper,Mohammed Z,Machine Learning Algorithms for Oncology Big Data Treatment,Association for Computing Machinery,2017,https://doi.org/10.1145/3167486.3167565;http://dx.doi.org/10.1145/3167486.3167565,"Two-dimensional arrays of bi-component structures made of cobalt and permalloy elliptical dots with thickness of 25 nm, length 1 m and width of 225 nm, have been prepared by a self-aligned shadow deposition technique. Brillouin light scattering has been exploited to study the frequency dependence of thermally excited magnetic eigenmodes on the intensity of the external magnetic field, applied along the easy axis of the elements. Our work is part of user-centered healthcare decision-making systems based on a process of predicting cancer distribution. This process should lead to a set of knowledge in Datamining, Ontologies and Geographical Information Systems. It is in the same time iterative and interactive. Therefore, it seems essential to take into account principles and methods of Human-Machine Interaction in the development of such systems. In this respect, development of interactive decision-making systems is currently being approached using two opposing approaches. In the first one, technology is fundamental; the second one is user centered placing the human actors in a central position. Although the first approach is still present in healthcare organizations, the current trend is definitely the user centric. In our framework we propose an approach that aims to integrate the steps of the predicting future from data process into a development model enriched from human-machine interactions. Our application context is the fight against breast cancer in hospitals. We demonstrate that medical decision can be based on a spatial analysis of the geographical distribution of many cancers. Several factors explain our choice of datamining for assistance of health decision-makers for learning in the CART algorithm about patients who are future actors of suspicion.","GIS health, CART, datamining, Machine learning, Redundancy"
Conference Paper,"Bassilious E,DeChamplain A,McCabe I,Stephan M,Kapralos B,Mahmud FH,Dubrowski A",Power Defense: A Serious Game for Improving Diabetes Numeracy,Association for Computing Machinery,2012,https://doi.org/10.1145/2212776.2212449;http://dx.doi.org/10.1145/2212776.2212449,"Adolescents with T1D often have poor control of their disease. With the knowledge that the current generation appreciates and learns more from interactive approaches to teaching, we have developed Power Defense, a highly interactive video game aimed at improving one particular skill associated with managing diabetes -- numeracy. Diabetes-related numeracy encompasses the ability to understand and interpret results and then appropriately apply the results to the management of diabetes. Power Defense employs the principals of experiential learning and includes both implicit and explicit methods for teaching the player the necessary diabetes numeracy skills.","adolescent, diabetes, diabetes numeracy, type 1 diabetes, serious games, video game-based learning"
Journal Article,"Champaign J,Cohen R,Lam DY",Empowering Patients and Caregivers to Manage Healthcare Via Streamlined Presentation of Web Objects Selected by Modeling Learning Benefits Obtained by Similar Peers,Association for Computing Machinery,2015,https://doi.org/10.1145/2700480;http://dx.doi.org/10.1145/2700480,"In this article, we introduce a framework for selecting web objects (texts, videos, simulations) from a large online repository to present to patients and caregivers, in order to assist in their healthcare. Motivated by the paradigm of peer-based intelligent tutoring, we model the learning gains achieved by users when exposed to specific web objects in order to recommend those objects most likely to deliver benefit to new users. We are able to show that this streamlined presentation leads to effective knowledge gains, both through a process of simulated learning and through a user study, for the specific application of caring for children with autism. The value of our framework for peer-driven content selection of health information is emphasized through two additional roles for peers: attaching commentary to web objects and proposing subdivided objects for presentation, both of which are demonstrated to deliver effective learning gains, in simulations. In all, we are offering an opportunity for patients to navigate the deep waters of excessive online information towards effective management of healthcare, through content selection influenced by previous peer experiences.","e-communities for patients and caregivers, effective information retrieval for healthcare applications, Shareable health knowledge, computational support for patient-centred care, cyber-based empowering of patients, discovery of new knowledge for decision support"
Conference Paper,"Rodrigues JF,Pepin JL,Goeuriot L,Amer-Yahia S",An Extensive Investigation of Machine Learning Techniques for Sleep Apnea Screening,Association for Computing Machinery,2020,https://doi.org/10.1145/3340531.3412686;http://dx.doi.org/10.1145/3340531.3412686,"The identification of Obstructive Sleep Apnea (OSA) relies on laborious and expensive polysomnography (PSG) exams. However, it is known that other factors, easier to measure, can be good indicators of OSA and its severity. In this work, we extensively investigate the use of Machine Learning techniques in the task of determining which factors are more revealing with respect to OSA along with a discussion of the challenges to perform such a task. We ran extensive experiments over 1,042 patients from the Centre Hospitalier Universitaire of the city of Grenoble, France. The data included ordinary clinical information, and PSG results as baseline. We employed data preparation techniques including cleaning of outliers, imputation of missing values, and synthetic data generation. Following, we performed an exhaustive attribute selection scheme to find the most representative features. We found that the prediction of OSA depends largely on variables related to age, body mass, and sleep habits more than the ones related to alcoholism, tabagism, and depression. Next, we tested 60 regression/classification algorithms to predict the Apnea-Hypopnea Index (AHI), and the AHI-based severity of OSA. We achieved performances significantly superior to the state of the art both for AHI regression and classification. Our results can benefit the development of tools for the automatic screening of patients who should go through polysomnography and further treatments of OSA -- currently, our work in under consideration for production by the Centre Hospitalier Universitaire of Grenoble. Our thorough methodology enables experimental reproducibility on similar OSA-detection problems, and more generally, on other problems with similar data models.","decision trees, obstructive sleep apnea screening, machine learning, naive bayes"
Book,Not Found,"The Handbook of Multimodal-Multisensor Interfaces: Language Processing, Software, Commercialization, and Emerging Directions",Association for Computing Machinery and Morgan & Claypool,2019,Not Found,"The Handbook of Multimodal-Multisensor Interfaces provides the first authoritative resource on what has become the dominant paradigm for new computer interfaces---user input involving new media (speech, multi-touch, hand and body gestures, facial expressions, writing) embedded in multimodal-multisensor interfaces.This three-volume handbook is written by international experts and pioneers in the field. It provides a textbook, reference, and technology roadmap for professionals working in this and related areas.This third volume focuses on state-of-the-art multimodal language and dialogue processing, including semantic integration of modalities. The development of increasingly expressive embodied agents and robots has become an active test-bed for coordinating multimodal dialogue input and output, including processing of language and nonverbal communication. In addition, major application areas are featured for commercializing multimodal-multisensor systems, including automotive, robotic, manufacturing, machine translation, banking, communications, and others. These systems rely heavily on software tools, data resources, and international standards to facilitate their development. For insights into the future, emerging multimodal-multisensor technology trends are highlighted for medicine, robotics, interaction with smart spaces, and similar topics. Finally, this volume discusses the societal impact of more widespread adoption of these systems, such as privacy risks and how to mitigate them. The handbook chapters provide a number of walk-through examples of system design and processing, information on practical resources for developing and evaluating new systems, and terminology and tutorial support for mastering this emerging field. In the final section of this volume, experts exchange views on a timely and controversial challenge topic, and how they believe multimodal-multisensor interfaces need to be equipped to most effectively advance human performance during the next decade.",Not Found
Conference Paper,"Radhwan W,Alnahdi A",Towards Medical Ontology Construction Using Data Mining: An Approach for Creating a Diabetic Ontology Using Clustering,Association for Computing Machinery,2022,https://doi.org/10.1145/3545729.3545747;http://dx.doi.org/10.1145/3545729.3545747,"Ontologies are abstract representation of domain knowledge that encompasses the structures and relations between concepts. They are stored in a form that prompts sharing, reusing, and querying of the knowledge base. Ontologies use processing and reasoning technology to derive information implied by knowledge. In healthcare, intelligent decision support systems are increasingly employing ontologies for diseases diagnosis, prevention, and treatment. Early diagnosis of diseases such as diabetes helps prevent the progression of severe health problems. Due to the massive amount of diabetes-related data in the medical field, data mining and semantic techniques have been utilized in building automated systems for diabetes prediction and diagnosis. This work aims to implement a methodology for creating a fuzzy ontology for diabetes diagnosis. It proposes a method for constructing a fuzzy ontology based on data mining techniques to reduce the time and effort of ontology construction process. Expectation maximization (EM) clustering algorithm was applied on a diabetic dataset to group concepts and attributes.","Ontology, Semantic Web, Data mining"
Conference Paper,"den Akker Rop,Klaassen R,Bul K,Kato PM,van der Burg GJ,di Bitonto P",Let Them Play: Experiences in the Wild with a Gamification and Coaching System for Young Diabetes Patients,Association for Computing Machinery,2017,https://doi.org/10.1145/3154862.3154931;http://dx.doi.org/10.1145/3154862.3154931,"In this paper we describe a platform that integrates gaming and coaching for adolescent patients with type 1 diabetes and results from user evaluations of the platform. The purpose of the platform is to support patients in diabetes self-management through educational game playing, monitoring and motivational feedback, and to support patients' care givers. We describe the design of the platform referring to principles from health care, persuasive system design and game design. The virtual coach is a game guide that can also provide personalized feedback about the user's daily care related activities which have value for making progress in the game world. We report about user evaluations in the wild which revealed that some assumptions made about how users are connected to the platform were not satisfied in reality, resulting in less optimal user experiences. We discuss challenges with suggestions for further development of integrated pervasive coaching and gamification platforms.","self-management, diabetes education, gamification, digital coaching, user evaluations"
Journal Article,"Zou J,Kanoulas E",Towards Question-Based High-Recall Information Retrieval: Locating the Last Few Relevant Documents for Technology-Assisted Reviews,Association for Computing Machinery,2020,https://doi.org/10.1145/3388640;http://dx.doi.org/10.1145/3388640,"While continuous active learning algorithms have proven effective in finding most of the relevant documents in a collection, the cost for locating the last few remains high for applications such as Technology-assisted Reviews (TAR). To locate these last few but significant documents efficiently, Zou et al. [2018] have proposed a novel interactive algorithm. The algorithm is based on constructing questions about the presence or absence of entities in the missing relevant documents. The hypothesis made is that entities play a central role in documents carrying key information and that the users are able to answer questions about the presence or absence of an entity in the missing relevance documents. Based on this, a Sequential Bayesian Search-based approach that selects the optimal sequence of questions to ask was devised. In this work, we extend Zou et al. [2018] by (a) investigating the noise tolerance of the proposed algorithm; (b) proposing an alternative objective function to optimize, which accounts for user “erroneous” answers; (c) proposing a method that sequentially decides the best point to stop asking questions to the user; and (d) conducting a small user study to validate some of the assumptions made by Zou et al. [2018]. Furthermore, all experiments are extended to demonstrate the effectiveness of the proposed algorithms not only in the phase of abstract appraisal (i.e., finding the abstracts of potentially relevant documents in a collection) but also finding the documents to be included in the review (i.e., finding the subset of those relevant abstracts for which the article remains relevant). The experimental results demonstrate that the proposed algorithms can greatly improve performance, requiring reviewing fewer irrelevant documents to find the last relevant ones compared to state-of-the-art methods, even in the case of noisy answers. Further, they show that our algorithm learns to stop asking questions at the right time. Last, we conduct a small user study involving an expert reviewer. The user study validates some of the assumptions made in this work regarding the user’s willingness to answer the system questions and the extent of it, as well as the ability of the user to answer these questions.","interactive search, SBSTARext, SBSTAR, asking questions, Technology-assisted reviews"
 Journals,J. Wang; Y. Bai; B. Xia,Simultaneous Diagnosis of Severity and Features of Diabetic Retinopathy in Fundus Photography Using Deep Learning,IEEE,2020,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9151309,"Deep learning methods for diabetic retinopathy (DR) diagnosis are usually criticized as being lack of interpretability in the diagnostic result, thus limiting their application in clinic. Simultaneous prediction of DR related features during the DR severity diagnosis is able to resolve this issue by providing supporting evidence (i.e. DR related features) for the diagnostic result (i.e. DR severity). In this study, we propose a hierarchical multi-task deep learning framework for simultaneous diagnosis of DR severity and DR related features in fundus images. A hierarchical structure is introduced to incorporate the casual relationship between DR related features and DR severity levels. In the experiments, the proposed approach was evaluated on two independent testing sets using quadratic weighted Cohen's kappa coefficient, receiver operating characteristic analysis, and precision-recall analysis. A grader study was also conducted to compare the performance of the proposed approach with those of general ophthalmologists with different levels of experience. The results demonstrate that the proposed approach could improve the performance for both DR severity diagnosis and DR related feature detection when comparing with the traditional deep learning-based methods. It achieves performance close to general ophthalmologists with five years of experience when diagnosing DR severity levels, and general ophthalmologists with ten years of experience for referable DR detection.",Diabetic retinopathy (DR);DR severity;DR related features;deep learning
 Journals,L. Qiao; Y. Zhu; H. Zhou,Diabetic Retinopathy Detection Using Prognosis of Microaneurysm and Early Diagnosis System for Non-Proliferative Diabetic Retinopathy Based on Deep Learning Algorithms,IEEE,2020,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9091167,"Predicting the presence of Microaneurysms in the fundus images and the identification of diabetic retinopathy in early-stage has always been a major challenge for decades. Diabetic Retinopathy (DR) is affected by prolonged high blood glucose level which leads to microvascular complications and irreversible vision loss. Microaneurysms formation and macular edema in the retinal is the initial sign of DR and diagnosis at the right time can reduce the risk of non proliferated diabetic retinopathy. The rapid improvement of deep learning makes it gradually become an efficient technique to provide an interesting solution for medical image analysis problems. The proposed system analysis the presence of microaneurysm in fundus image using convolutional neural network algorithms that embeds deep learning as a core component accelerated with GPU(Graphics Processing Unit) which will perform medical image detection and segmentation with high-performance and low-latency inference. The semantic segmentation algorithm is utilized to classify the fundus picture as normal or infected. Semantic segmentation divides the image pixels based on their common semantic to identify the feature of microaneurysm. This provides an automated system that will assist ophthalmologists to grade the fundus images as early NPDR, moderate NPDR, and severe NPDR. The Prognosis of Microaneurysm and early diagnosis system for non - proliferative diabetic retinopathy system has been proposed that is capable to train effectively a deep convolution neural network for semantic segmentation of fundus images which can increase the efficiency and accuracy of NPDR (non proliferated diabetic retinopathy) prediction.",Microaneurysm;diabetic retinopathy;deep convolution neural network;semantic segmentation;non proliferated diabetic retinopathy
 Conferences,E. Kaya; I. Saritas,Performances of CNN Architectures on Diabetic Retinopathy Detection Using Transfer Learning,IEEE,2022,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9828576,"Deep Learning (DL) methods have become popular because they automatically extract and learn features without other feature extraction algorithms. Diabetic Retinopathy (DR) is a disease that is solely determined by blood vessel segmentation, but the diagnosis can differ from person to person. Thus, deep learning can simplify and improve the process of diagnosing DR. In this study, known Convolutional Neural Network (CNN) architectures were used as a transfer learning method to classify DRIVE dataset images of DR patients and healthy individuals to determine the most efficient architecture. In this study, CNN architectures were used both as classifiers and feature extraction methods. The most efficient CNN architecture was found to be ResNet18 with 100.0% accuracy when the classification was realized with ResNet18 itself and ANN which uses the activations of ResNet18 as features.",CNN;Diabetic Retinopathy;Transfer Learning;Deep Learning
 Conferences,Z. Qian; C. Wu; H. Chen; M. Chen,Diabetic Retinopathy Grading Using Attention based Convolution Neural Network,IEEE,2021,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9390963,"In this paper, an automatic diagnosis method based on deep learning algorithm is proposed, which will speed up the diagnosis of diabetic retinopathy and improve the efficiency of treatment. We built a convolutional neural network model called as ""AD2Net"". The network combines the advantages of Res2Net and DenseNet, which can not only learn multi-scale features, but also alleviate the vanishing-gradient problem and strengthen feature reuse. At the same time, this paper also uses attention mechanism method to encourage the network to focus on learning useful information in images, which can improve classification effect of the network to a certain extent. The results show that the method proposed in this paper can divide the fundus images into five stages of disease based on severity. The accuracy and Kappa values that the model has achieved are 83.2% and 0.8 respectively on testing set. Compared with the existing method, the method proposed in this paper has certain advantages.",diabetic retinopathy;deep learning;CNN;Kaggle
 Journals,M. Z. Atwany; A. H. Sahyoun; M. Yaqub,Deep Learning Techniques for Diabetic Retinopathy Classification: A Survey,IEEE,2022,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9729867,"Diabetic Retinopathy (DR) is a degenerative disease that impacts the eyes and is a consequence of Diabetes mellitus, where high blood glucose levels induce lesions on the eye retina. Diabetic Retinopathy is regarded as the leading cause of blindness for diabetic patients, especially the working-age population in developing nations. Treatment involves sustaining the patient’s current grade of vision since the disease is irreversible. Early detection of Diabetic Retinopathy is crucial in order to sustain the patient’s vision effectively. The main issue involved with DR detection is that the manual diagnosis process is very time, money, and effort consuming and involves an ophthalmologist’s examination of eye retinal fundus images. The latter also proves to be more difficult, particularly in the early stages of the disease when disease features are less prominent in the images. Machine learning-based medical image analysis has proven competency in assessing retinal fundus images, and the utilization of deep learning algorithms has aided the early diagnosis of Diabetic Retinopathy (DR). This paper reviews and analyzes state-of-the-art deep learning methods in supervised, self-supervised, and Vision Transformer setups, proposing retinal fundus image classification and detection. For instance, referable, non-referable, and proliferative classifications of Diabetic Retinopathy are reviewed and summarized. Moreover, the paper discusses the available retinal fundus datasets for Diabetic Retinopathy that are used for tasks such as detection, classification, and segmentation. The paper also assesses research gaps in the area of DR detection/classification and addresses various challenges that need further study and investigation.",Diabetic retinopathy;diabetes mellitus;diabetic macular edema;lesion;microaneurysms;haemorrhages;exudates;classification;supervised learning;self-supervised learning;transformers
 Conferences,Y. S. Taspinar,Diabetic Rethinopathy Phase Identification with Deep Features,IEEE,2022,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9797136,"One of the most prevalent diabetes symptoms is diabetic retinopathy. Pain is one of the most common causes of vision loss. Years of research have gone into finding a way to diagnose and treat this condition early. In this study (DR) Diabetic Rethinopathy dataset containing 35,126 images was used. The dataset includes 5 classes. Each class represents the diabetic retinopathy stage. For example, 0 was determined as no diagnosis, 4 as the last stage. The pre-trained SqueezeNet model was used to extract image features. 1000 features obtained for each image are given as input to the Logistic Regression (LR) and k-Nearest Neighbor (kNN) machine learning models. As a result of the classifications made with LR and kNN models, 74.4% classification accuracy was obtained from the LR model and 72.2 % from the kNN model. The F -1 Score, Precision, and Recall measures were used to assess the models' performance. ROC curve and The learning levels of the models were assessed using AUC values.",Diabetic retinopathy;deep features;early detection;transfer learning;classification
 Conferences,B. Kübra Karaca; B. Oltu; A. Özgür; H. Erdem,Comparison of Transfer Learning Strategies for Diabetic Retinopathy Detection,IEEE,2021,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9599002,"Diabetic Retinopathy (DR) is a common complication of diabetes, one of the leading causes of blindness worldwide. Diabetes and DR cases have been increasing at an alarming rate in recent years. However, early diagnosis of DR is difficult and the diagnostic procedure is time-consuming. Due to the importance of early detection of DR in terms of treatment, many approaches have been applied to DR detection in the last two decades. Recent research shows that deep learning-based convolutional neural network (CNN) structure and transfer learning are the most used approaches in DR detection. Accordingly, in the present study, DR images were classified considering their severity levels using the Messidor-2 + EyePac Balanced data set in Kaggle using two different transfer learning strategies: training from scratch and fine tuning. The results obtained using two different approaches were compared in terms of accuracy and training time. In the proposed study, AlexNet, VGG-16, DenseNet121, and ResNet50 architectures were used to compare the performance of these two approaches. According to the results, it was determined that the fine tuning approach for the classification of DR images performs better than CNN training from scratch.",diabetic retinopathy;deep learning;transfer learning;CNN
 Conferences,M. Ahmad; N. Kasukurthi; H. Pande,Deep Learning for Weak Supervision of Diabetic Retinopathy Abnormalities,IEEE,2019,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8759417,"Deep learning-based grading of the fundus images of the retina is an active area of research. Various existing studies use different deep learning architectures on different datasets. Results of some of the studies could not be replicated in other studies. Thus a benchmarking study across multiple architectures spanning both classification and localization is needed. We present a comparative study of different state-of-the-art architectures trained on a proprietary dataset and tested on the publicly available Messidor-2 dataset. Although evidence is of utmost importance in AI-based medical diagnosis, most studies limit themselves to the classification performance and do not report the quantification of the performance of the abnormalities localization. To alleviate this, using class activation maps, we also report a comparison of localization scores for different architectures. For classification, we found that as the number of parameters increase, the models perform better, with NASNet yielding highest accuracy and average precision, recall, and F1-scores of around 95%. For localization, VGG19 outperformed all the models with a mean Intersection over Minimum of 0.45. We also found that there is a trade-off between classification performance and localization performance. As the models get deeper, their receptive field increases, causing them to perform well on classification but underperform on the localization of fine-grained abnormalities.",Diabetic retinopathy;Messidor-2;Abnormality localization;Class activation maps
 Conferences,M. Yadav; R. Goel; D. Rajeswari,A Deep Learning Based Diabetic Retinopathy Detection from Retinal Images,IEEE,2021,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9498502,"Diabetes is increased tremendously due to metabolism. Lack of early detection, prolonged diabetics might lead to medical complications such as heart problems, eye vision problems, skin issues etc. Diabetic retinopathy (DR) is a frequent abnormality of diabetics. In this paper, we propose computer vision based technique to analyze and predict diabetes from the retinal input images. This helps in an early stage detection of DR. In this image processing steps such as pre-processing, segmentation, feature extraction steps are applied. After the image processing steps, machine learning based classification step is performed. For experimental results, we used python programming language for better results. For experimental results platform, we use jupyter for developing the coding. The framework developed was evaluated on open access public repository datasets, achieving an accuracy of 98.50% using CNN as compared to the accuracy of 87.40% achieved by SVM. These results perform better than several advanced unsupervised ML techniques. It results in decrease of procedural complexity and improved assessment metrics, hence making it suitable to be used in the diagnosis of DR using retinal image analysis.",Diabetic retinopathy;pre-processing;segmentation;feature extraction;machine learning algorithm
 Conferences,V. Vipparthi; D. R. Rao; S. Mullu; V. Patlolla,Diabetic Retinopathy Classification using Deep Learning Techniques,IEEE,2022,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9885687,"Diabetic Retinopathy is a disease that damages the eyes and is caused by a consequence of diabetes. If blood sugar levels aren't controlled for an extended period of time, the disease can develop. It is mainly caused due to the damage of blood vessels in the retina. Retinopathy is the main cause of blindness in the world. Doctors can diagnose blindness before it occurs using Artificial Intelligence and Deep Learning. Medical imaging plays a very crucial role in a variety of medical issues and at all major levels of health issues. Medical imaging can be used to identify a variety of common eye illnesses. However, for a variety of reasons, including uneven lighting, picture blurring, and low contrast and brightness, poor-quality retinal images are ineffective for further diagnosis, particularly in automated analyzing systems. Ophthalmologists' manual Diabetic Retinopathy diagnostic procedure is time-consuming, requires more work, costly, and might result in misdiagnosis. Basing on the vision like having trouble in reading distant objects or seeing distant objects, blindness or any other changes may happen in eye retina that affects diabetes. Diabetic retinopathy is one of the most frequent eye illnesses, affecting mostly diabetics. This model can assist the opthmologists for clinical diagnosis and detect and classify the diabetic retinopathy. There are three phases in this diabetic retinopathy detection and classification technique (i) enhancement (ii) Feature Extraction and (iii) Retinopathy Detection and Classification. Feature extraction involves blood vessels extraction and exudates extraction. First two phases assist the opthmologists by providing clear images of the retina and blood vessels and exudates extracted images. In this work, from the presented retinal fundus pictures, the Res-Block model is used to classify and diagnose diabetic retinopathy.",Diabetic Retinopathy;Deep Learning;Fundus;Artificial Intelligence;Medical Imaging
 Conferences,K. T. Islam; S. Wijewickrema; S. O'Leary,Identifying Diabetic Retinopathy from OCT Images using Deep Transfer Learning with Artificial Neural Networks,IEEE,2019,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8787419,"Diabetic retinopathy occurs when the blood vessels inside the retina are damaged as a result of diabetes. Early diagnosis and treatment of this disease is crucial to avoid blindness. Analysis of retinal images such as funduscopy, ultrasonography, and optical coherence tomography (OCT) is typically used in the diagnosis of diabetic retinopathy. In recent years, various automated techniques including deep learning have been used for this purpose. In this paper, we explore how to use deep transfer learning for the diagnosis of diabetic retinopathy using OCT images. We retrain existing deep learning models for this task and investigate how a retrained model can be optimized. We demonstrate that using an optimized pre-trained model as a feature extractor and training a conventional classifier on these features is an effective way to diagnose diabetic retinopathy using OCT images. We show through experiments that the proposed method outperforms similar existing methods with respect to accuracy and training time.",Diabetic Retinopathy;OCT Image;Deep Learning;Transfer Learning;Feature Extraction;Artificial Neural Networks
 Conferences,P. L. Jancy; B. Latha,Deep Learning Techniques for Diabetic Retinopathy Diagnosis using Optical Coherence Tomography: A Review,IEEE,2022,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9753418,"Diabetic Retinopathy is an eye disease that prevails among patients suffering from diabetic mellitus. Due to high glucose level in blood, the retina of the eye gets affected. Diabetic Retinopathy cause vision loss if left undiagnosed. Regular annual inspection is required for the Diabetic patients to prevent the disease. Optical Coherence Tomography, an non-invasive imaging modality that captures retina with high resolution. Deep learning Algorithms are showing successful solutions regarding medical images examinations. This paper reviews the deep learning methods used for the detection of Diabetic Retinopathy based on Optical Coherence Tomography for past four years. The segmentation of Optical Coherence Tomography images into retinal layer using deep learning methods are also reviewed. The features used for Diabetic Retinopathy classification are also reviewed.",Diabetic Retinopathy;Optical Coherence Tomography;Diabetic Mellitus;Deep learning applications;Retinal layer and fluid segmentation
 Conferences,M. R. Islam; M. A. M. Hasan; A. Sayeed,Transfer Learning based Diabetic Retinopathy Detection with a Novel Preprocessed Layer,IEEE,2020,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9230648,"one of the major reasons for impaired vision in the world nowadays is diabetic retinopathy (DR). Many people could be saved from permanent blindness with early detection. The manual diagnosis is erroneous and tedious. Hence, numerous computerized vision methods for the automatic detection of diabetic retinopathy and its distinctive stages from retinal images were proposed. Various image processing techniques have been developed besides deep learning methods. In image processing techniques, complex features are manually identified. Most of the earlier works used very small dataset which has a great chance to be over-fitting and worked with grayscale image after transforming color fundus images. In our paper, we developed a deep learning model with transfer learning from VGG16 model followed by a novel color version preprocessing technique. It reduced the training time and provided an average accuracy of 0.9132683 implemented to new Kaggle dataset “APTOS 2019 Blindness Detection”. Moreover, to avoid the over-fitting problem for long run we used Stratified K-fold cross validation.",diabetic retinopathy;transfer learning;deep learning;Convolution neural Network
 Conferences,S. Gulati; V. P. Singh; S. Shukla,Comparative Analysis of Deep Learning Approaches for the Diagnosis of Diabetic Retinopathy,IEEE,2022,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9887778,"High levels of blood sugar causes diabetes. Diabetes on the other hand leads to various other health issues like heart diseases, kidney damage, nerves damage and eye damage. Diabetic retinopathy is one such disease that is being caused by diabetes and without early treatment or diagnosis it might lead to vision loss as well. Various Computer aided systems have been used and developed for the diagnostics of diabetic retinopathy in the past where it uses the traditional techniques to get low level features such as shape, colors or textures which are handcrafted features. With the advancement in AI and deep learning methodologies especially in the field of medical image analysis, efficient and accurate results are produced as it performs automatic extraction of features. These features can include high level features or some of the low-level features as well. Most commonly used deep learning method for image detection is convolutional neural network. In this paper, three different CNN architectures such as ResNet50, DenseNet121 and VGG16 are used as transfer learning models to carry out a comparative analysis of deep learning approaches for the diagnosis of Diabetic Retinopathy (DR). These models are used to classify diabetic retinopathy into multi-class (5 class based) classification on the basis of severity level and further into binary (2 class based) classification as 0-No DR and 1-DR. The accuracy so obtained on validation set for multi-class classification for the models ResNet50, DenseNet121 and VGG16 is 94.11%,94.64% and 91.52% respectively and that on test set as 94%, 92% and 86% respectively. Whereas the accuracy for binary classification on validation set for the models ResNet50, DenseNet121 and VGG16 is 98.35%, 98.48% and 95.86% respectively.",Diabetic Retinopathy;Convolutional Neural Network;Deep Learning;Transfer learning
 Journals,Y. Zhou; B. Wang; L. Huang; S. Cui; L. Shao,"A Benchmark for Studying Diabetic Retinopathy: Segmentation, Grading, and Transferability",IEEE,2021,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9257400,"People with diabetes are at risk of developing an eye disease called diabetic retinopathy (DR). This disease occurs when high blood glucose levels cause damage to blood vessels in the retina. Computer-aided DR diagnosis has become a promising tool for the early detection and severity grading of DR, due to the great success of deep learning. However, most current DR diagnosis systems do not achieve satisfactory performance or interpretability for ophthalmologists, due to the lack of training data with consistent and fine-grained annotations. To address this problem, we construct a large fine-grained annotated DR dataset containing 2,842 images (FGADR). Specifically, this dataset has 1,842 images with pixel-level DR-related lesion annotations, and 1,000 images with image-level labels graded by six board-certified ophthalmologists with intra-rater consistency. The proposed dataset will enable extensive studies on DR diagnosis. Further, we establish three benchmark tasks for evaluation: 1. DR lesion segmentation; 2. DR grading by joint classification and segmentation; 3. Transfer learning for ocular multi-disease identification. Moreover, a novel inductive transfer learning method is introduced for the third task. Extensive experiments using different state-of-the-art methods are conducted on our FGADR dataset, which can serve as baselines for future research. Our dataset will be released in https://csyizhou.github.io/FGADR/.",Diabetic retinopathy;lesion segmentation;grading;transfer learning
 Conferences,K. C. Pathak; R. B. Shah; R. R. Tharakan; B. N. Patel; D. C. Jariwala,Diabetic Retinopathy Diagnosis and Categorization using Deep Learning - A Review,IEEE,2021,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9432312,"Diabetic Retinopathy (DR), the foremost root which leads to blindness is found among working-age adults. It is caused due to diabetes that affects human eye. When such a disease is detected, then at first it does not show any symptoms or shows only mild symptoms. Gradually, it leads to blindness. There are various symptoms of DR. They may include: fluctuating vision, blurred vision, spots floating in your vision, vision loss, empty areas in vision, impaired color vision. It is critical to detect this condition in its early stage for good diagnosis. In fact, earliest stage was unable to help in diagnosing of normal eye sight. Hence, requirement of finding a DR as early as possible increased which would prevent visual impairment for patients having elongated diabetes although one is suffering from young. Microaneurysms, exudates, neovascularization and hemorrhages all these parameters decide the acuteness of DR. DR is categorized in to five stages such as normal, mild, moderate, severe Non proliferative (NPDR) or Proliferative diabetic retinopathy patient (PDR). We aim to categorize early-stage DR for better clinical benefits with more useful means. In this project we aim to use Deep Learning algorithm. This paper comprises of analysis and evaluation of the different techniques of DR diagnosis and categorization using retinal images was regulated. Accordingly, 14 research papers were studied and analyzed to provide an examination related to extracted features, classification accuracy, and the usage of different data sets, such as Indian Diabetic Retinopathy Image Dataset (IDRiD), High-Resolution Fundus (HRF) Image Database, Kaggle dataset. IDRiD is an Indian dataset which is the first retinal database representative. It is the mixture of normal retinal dataset and diabetic retinopathy retinal eye image. All in all to show different issues and to provide results that can be helpful for researchers to obtain further research on diabetic retinopathy diagnosis and categorization.",Diabetic;Retinopathy;Classification;Detection;CNN;Deep learning;Glaucoma
 Conferences,N. S. Kumar; B. Ramaswamy Karthikeyan,"Diabetic Retinopathy Detection using CNN, Transformer and MLP based Architectures",IEEE,2021,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9651024,"Diabetic retinopathy is a chronic disease caused due to a long term accumulation of insulin in the retinal blood vessels. 2.6% of global blindness is a result of diabetic retinopathy (DR) with more than 150 million people affected. Early detection of DR plays an important role in preventing blindness. Use of deep learning is a long term solution to screen, diagnose and monitor patients within primary health centers. Attention based networks (Transformers), Convolutional neural networks (CNN) and multi-layered perceptrons (MPLs) are the current state-of-the-art architectures for addressing computer vision based problem statements. In this paper, we evaluate these three different architectures for the detection of DR. Model convegence time (training time), accuracy, model size are few of the metrics that have been used for this evaluation. State-of-the-art pre-trained models belonging to each of these architectures have been chosen for these experiments. The models include EfficientNet, ResNet, Swin-Transformer, Vision-Transformer (ViT) and MLP-Mixer. These models have been trained using Kaggle dataset, which contains more than 3600 annotated images with a resolution of 2416*1736. For fair comparisons, no augmentation techniques have been used to improve the performance. Results of the experiments indicate that the models based on Transformer based architecture are the most accurate and also have comparative model-convergence times compared to CNN and MLP architectures. Among all the state-of-the-art pre-trained models Swin-Transformer yields the best accuracy of 86.4% on test dataset and it takes around 12 minutes for training the model on a Tesla K80 GPU.",Diabetic Retinopathy;Convolutional Neural Networks;Transformers;MLP-Mixer;Swin-Transformer
 Journals,B. Goutam; M. F. Hashmi; Z. W. Geem; N. D. Bokde,A Comprehensive Review of Deep Learning Strategies in Retinal Disease Diagnosis Using Fundus Images,IEEE,2022,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9783206,"In recent years, there has been an unprecedented growth in computer vision and deep learning implementation owing to the exponential rise of computation infrastructure. The same was also reflected in retinal image analysis and successful artificial intelligence models were developed for various retinal disease diagnoses using a wide variety of visual markers obtained from eye fundus images. This article presents a comprehensive study of different deep learning strategies employed in recent times for the diagnosis of five major eye diseases, i.e., Diabetic retinopathy, Glaucoma, age-related macular degeneration, Cataract, and Retinopathy of prematurity. This article is organized according to the deep learning implementation process pipeline, where commonly used datasets, evaluation metrics, image pre-processing techniques, and deep learning backbone models are first illustrated followed by an extensive review of different strategies for each of the five mentioned retinal diseases is presented. Finally, this article summarizes eight major research directions available in the field of retinal disease diagnosis and outlines key challenges and future scope for the present research community.",Computer vision;deep learning;fundus image;retinal disease diagnosis;artificial intelligence;diabetic retinopathy;glaucoma;AMD;cataract;ROP
 Conferences,A. Sbai; A. Touil; L. Oukhouya,Diabetic retinopathy detection using a pretrained machine learning model,IEEE,2022,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9982836,"One of the possible side effects of diabetes is Diabetic Retinopathy. Early diagnosis of diabetic retinopathy is an important step toward healing and can prevent many patients from potential blindness. To identify diabetic retinopathy, practitioners may need an artificial intelligence tool to provide a second opinion to confirm or refute a diagnosis. In this article we use a pretrained machine learning model to find a solution to the issue of low-quality inputs by implementing, in the pre-processing step, the technique of Contrast Limited Adaptive Histogram Equalization to extract more features especially the blood vessels.",Diabetic Retinopathy;machine learning;pretrained model;abnormalities detection;fundus images;computer-aided diagnosis
 Conferences,N. Memari; S. Abdollahi; M. M. Ganzagh; M. Moghbel,Computer-assisted diagnosis (CAD) system for Diabetic Retinopathy screening using color fundus images using Deep learning,IEEE,2020,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9250986,"Diabetes is a serious medical condition and regular screening for diabetes is of great importance as treatment options are most effective in the early stages of diabetes. Digital imaging of retina is considered as a low-cost method for screening and could be used in conjunction with computer-based image processing techniques to automatically detect early signs of diabetes utilizing diabetes-related pathologies visible in retinal fundus images. This research proposes a novel computer-assisted diagnosis (CAD) system for assisting with the screening of the population as up to 50% of the affected population are not aware of having diabetes. Moreover, these screenings are often carried out by an optometrist who receives some training with the patients being referred to an ophthalmologist if they show symptoms. Having a computer-assisted diagnosis system assisting the optometrist during the screening can greatly increase the detection rate for patients with diabetes by providing a second opinion and highlighting any suspicious pathologies. For achieving the highest detection rate possible, a hybrid machine learning approach is proposed in this research by combining Deep Learning with the AdaBoost classifier. The proposed computer-assisted diagnosis system starts with the segmentation of the blood vessels. Then, microaneurysms and exudates are segmentation from the image. Statistical and regional features are then extracted utilizing first, second, and higher-order image features. A Deep Learning framework will be utilized for extracting additional statistical image descriptors as a Deep Learning has superior contextual analysis capabilities compared to other machine learning techniques. Finally, the most informative features are selected by a minimal-redundancy maximal-relevance feature selection approach with an AdaBoost classifier analyzing all the features and informing the operator regarding the patient’s condition. Ethereum Swarm blockchain-based decentralized cloud file storage provides the proposed CAD users with a secure storage olution to access the patient information and related images. The sensitivity, specificity, and accuracy of the classification will be measured under clinical conditions. Healthcare, government, and public users would receive the most benefit from this project.",Retinal vessel segmentation;Machine Learning;Deep Learning;Diabetic Retinopathy.
 Conferences,H. Chen; P. Cao,Deep Learning Based Data Augmentation and Classification for Limited Medical Data Learning,IEEE,2019,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8942411,"Deep learning methods, especially convolutional neural network (CNN), which have made breakthroughs in many fields of computer vision, and one of the most prominent features of deep learning is that large-scale dataset with annotations should be used. However, obtaining such a dataset in the medical field is really a challenge due to scarcity of annotated data. In our work, a deep learning based framework is proposed to generate more real data from the existing data with Generative Adversarial Networks (GAN) and classify the suspicious lesions with CNN. The proposed method is applied on the diagnosis of diabetic retinopathy. The experimental results show that our deep learning framework achieve a better classification performance than the traditional deep learning methods.",deep learning;generative adversarial networks;Convolution neural networks;data augmentation;diabetic retinopathy;lesion classification
 Conferences,S. Srivastava; S. Prabhu; S. Ramesh; S. Pratapneni; A. Abraham; S. V Bhandary,Visualizing the Indicators of Diabetic Retinopathy Learnt by Convolutional Neural Networks,IEEE,2017,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8524578,"This study proposes a novel application of visualizing features learnt by convolutional neural networks with the aim to further the understanding of Diabetic Retinopathy. A convolutional neural network is first trained to recognize and classify fundus images of diabetic and non-diabetic patients. The network is then visualized, using a technique of pixel optimization, to discover the features that the trained network looks for to classify the image. Through this novel application of network visualization, we show that critical features for diabetic retinopathy can be re-discovered, leaving great scope for its application in scarcely explored diseases using minimal resources.",convolutional networks;diabetic retinopathy;inceptionism;medical image analysis;neural networks;deep learning;disease classification;automated diagnosis
 Conferences,D. Das; S. K. Biswas; S. Bandyopadhyay; R. H. Laskar,Deep Learning Techniques for Early Detection of Diabetic Retinopathy: Recent Developments and Techniques,IEEE,2020,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9276781,"Diabetic Retinopathy (DR) is a health disorder in human retina, caused as a result of Diabetes Mellitus (DM). It leads to loss of vision and in severe cases it results in blindness, as a result of mutilation of the retina. Statistical data estimates that 80% of diabetic patients, suffering from prolonged diabetes, also suffer from DR. Hence, in the present time DR has become an imperative matter and requires primary stage evaluation and assessment such that loss of vision and blindness can be averted. However, the physical diagnosis of the disease is laborious and susceptible to error. Besides, the convenience of availing Ophthalmologist irrespective of place and time, is not possible. Thus, the necessity of an exceedingly enhanced and computerized intelligent system arises, that can be engaged for the initial stage detection of DR. A number of Machine Learning models are proposed by researchers since decades, for the diagnosis of DR. Various feature extraction techniques are also proposed for deriving prominent retinal lesions, for initial stage diagnosis of DR. However, traditional Machine Learning models showcase poor generalization during feature extraction because of smaller datasets. This can be overcome through use of Deep Learning models, larger dataset and high computing processing units for generalization. This paper aims to give an overview about DR, a brief description of the earlier works, and the current automated systems and advancements, for the purpose of early detection of DR. This paper also focuses on the state-of-the-art DR lesions, origin and signs of DR, categories of DR and state-of-the-art Deep Learning models, that are proposed and applied for DR detection, at the preliminary stage.",Diabetic Retinopathy;Diabetic Macular Edema;Image Processing;Deep Learning;Retinal Lesions
 Conferences,H. Y. Sam; S. A. Zikri B Sayed Aluwee; N. S. Bt Che Lah; C. M. Goh; C. M. Tyng; H. Ikhwan B Murat,Preliminary Study of Diabetic Retinopathy Classification from Fundus Images Using Deep Learning Model,IEEE,2022,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9918681,"The soaring of diabetes cases in Malaysia has resulted in the appearance of diabetic retinopathy among diabetic patients. Diabetic retinopathy is a chronic eye disease triggered by diabetes, which could worsen eyesight functions and even blindness. Even though the cases were found to be common, medical experts still diagnose the disease manually, which increase the risk of incorrect diagnosis. To overcome this, the preliminary study on severity levels classifications of diabetic retinopathy from fundus images has been conducted by applying a deep learning model. A Convolutional Neural Network (CNN) deep learning model architecture is used to train the dataset, which is DenseNet. Various image pre-processing techniques have been applied to enhance the trained images. Moreover, data augmentation and test-time augmentation (TTA) are implemented in evaluating the training results and lower the overfitting, respectively. Prediction evaluation on the images and the effects of data augmentation and TTA by observing the quadratic weighted kappa values were conducted. Ultimately, a prediction model that is to predict and classify the severity labels of fundus images was developed. The prediction model achieved the quadratic weighted kappa score of 0.9308, with the accuracy of 65% on the Messidor-2 dataset, which were moderately accurate.",Diabetic retinopathy;fundus image;disease scanning;deep learning;DenseNet;data augmentation;test-time augmentation (TTA);prediction model
 Conferences,Z. Yu; X. Yang; G. L. Sweeting; Y. Ma; S. E. Stolte; R. Fang; Y. Wu,Identify Diabetic Retinopathy-related Clinical Concepts Using Transformer-based Natural Language Processing Methods,IEEE,2021,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9565706,"Diabetic retinopathy (DR) is a leading cause of blindness in American adults. If detected early, DR can be treated to preventing further damage causing blindness, therefore, early detection is very important for the treatment of DR. There is an increasing interest in developing Al technologies to help early detection of DR using electronic health records (EHR). The detailed diagnoses information documented in image reports is a valuable resource that could help detect lesions from the medical image, thus helping early detection of DR. In this study, we examined two state-of-the-art transformer-based natural language processing models, including BERT and RoBERTa, to extract DR-related concepts from clinical narratives. We identified four different categories of DR-related clinical concepts including lesions, eye parts, laterality, and severity, developed annotation guidelines, annotated a DR-corpus of 536 image reports, and trained four transformer-based NLP models for clinical concept extraction. The experimental results show that the BERT model pretrained with the MIMIC III dataset achieved the best strict/lenient F1-score of 0.9503 and 0.9645, respectively.",Diabetic retinopathy;Natural language processing;named entity recognition;deep learning
 Conferences,A. Elzennary; M. Soliman; M. Ibrahim,Early Deep Detection for Diabetic Retinopathy,IEEE,2020,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9523650,"Diabetic retinopathy (DR) is a diabetic condition that affects the eyes and it could lead to blurry vision or complete vision loss. Convolutional neural networks (CNNs) have been used increasingly for computer vision projects and medical image analysis. Past work has been done using deep learning models and frameworks to automatically detect diabetic retinopathy. However, such techniques used very large CNNs requiring enormous computing resources. Therefore, it is necessary to develop more computationally efficient deep learning frameworks for automated DR diagnosis. The main objective of this project is to build a reliable and computationally efficient deep learning model for the automated DR diagnosis. In this paper, a computationally efficient deep learning CNN is presented based on the DenseNet-121 neural network architecture that provides very deep CNN with lower computational resources using the concept of transfer learning. The model also detects the severity of the disease. The proposed deep learning model is trained and tested using the commonly used labeled retinal images data set and the cloud GPU provided by the community of data scientists and machine learners, Kaggle.",Deep Learning;Diabetic Retinopathy Detection;Neural Networks;DenseNet
 Conferences,G. Nagaraj; S. C. Simha; H. G. R. Chandra; M. Indiramma,Deep Learning Framework for Diabetic Retinopathy Diagnosis,IEEE,2019,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8819663,"Diabetic Retinopathy (DR) is one of the foremost causes for the presence of blindness in the recent times. Ophthalmologists usually diagnose the presence and severity of DR through visual assessment of the retinal fundus images by manual examination. This process of manual diagnosis of DR is a very laborious and time consuming task. With the increasing rate of diabetic retinopathy patients in the world, the number of color fundus images generated has increased exponentially. Due to this large number, there is a huge delay in recognizing the early symptoms of DR and providing timely treatment. Hence, to address this unmet and increasing need, there is a need for developing an automated framework of Diabetic Retinopathy diagnosis. Hence, in this study, we have proposed a Deep Learning framework for DR diagnosis. The study uses a modified version of one of the standard Convolutional Neural Network (CNN) for solving DR fundus image classification problems. The proposed framework efficiently and quickly report whether the person has DR or not and if present, reports the severity of the disease. The framework implemented helps in giving timely treatment to the patients irrespective of geographical and economic constraints.",Diabetic Retinopathy;Deep Learning;Convolutional Neural Network
 Conferences,A. Juyal; P. Negi,Severity of Diabetic Retinopathy Detection for Early Prevention using Lightweight Deep Learning Model,IEEE,2022,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9972693,"There were 2.6 million visually impaired and blind people worldwide in 2015, and it is predicted that number would increase to 3.2 million by 2020. Although it is anticipated that diabetic retinopathy would become less common in high-income nations, low- and middle-income nations must prioritise the early diagnosis and treatment of the condition. Recent developments in deep learning technology have allowed researchers to demonstrate that automated diabetic retinopathy screening and grading are effective in reducing labour costs. Although ultra-wide-field fundus imaging may capture up to 82 percent of the retinal surface, traditional fundus imaging is still used by the majority of automated processes. In this article, we describe a deep learning- and ultra-wide-field fundus photography-based method for detecting diabetic retinopathy. In studies, we demonstrate that the utilisation of a 7-standard field imaging from ultra-wide-field fundus images, taken from initial treatment diabetic retinopathy research, surpasses the optic disc as well as macula-centered image in a statistical sense.",Diabetic Retinopathy;Lightweight Deep Learning Model;Severity Disease Classification;and Performance DR Evaluation
 Conferences,S. Ramchandre; B. Patil; S. Pharande; K. Javali; H. Pande,A Deep Learning Approach for Diabetic Retinopathy detection using Transfer Learning,IEEE,2020,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9298201,"Diabetic Retinopathy is a primary complication of diabetes which more often than not, affects both eyes and anyone with type-1 or type-2 diabetes can develop it. A Diabetic patient should undergo eye tests periodically as the pace of development of this condition is slow. A Dataset of Fundus Photographs of retina is considered. Thus, there is a notable value in automatically categorizing the Fundus Photographs. Therefore, to get a consolidated and objective medical diagnosis, this paper proposes a transfer learning based approach for Diabetic Retinopathy categorization. The resizing of the dataset is performed, which converts the varied images into 224x224 format. The images are augmented using AUGMIX and pooled using GeM. Then, we have used pretrained models, namely SEResNeXt32x4d and EfficientNetb3. The pretraining of the aforementioned neural networks has been done on the ImageNet dataset. Then, the Diabetic Retinopathy images are migrated to these models. Based on the dataset already available, the output is ultimately split up into 5 levels according to the seriousness of the degree of DR. The experimental results show that the training accuracy of this method can reach as high as 0.91. Hence, the retina images of the Diabetic and Healthy patients can be easily classified using our proposed methodology, consequently reducing the number of reviews by medical professionals.",deep learning;diabetic retinopathy;transfer learning
 Conferences,V. Srinadh; B. Maram; V. Gampala,Prediction of Retinopathy in Diabetic Affected Persons using Deep Learning algorithms,IEEE,2022,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9777193,"The worldwide incidence of diabetic retinopathy (DR) is increasing, and DR is still a major source of eyesight loss universally. Diabetic retinopathy is a small blood vessel side effect of type 2 diabetes. Diabetic retinopathy diagnosis is important for inhibiting blindness, but increasing diagnosis is difficult as there is vast increase in number of affected persons s effected with diabetes. Retinal diagnosis aids in the premature finding and cure of diabetic retinopathy. Appearing in many cases, DR is not diagnosed until there is threat to vision. Previous research has mainly focused on attempting to control one important threat factor, glucose level. Nearly 21% of new cases of type 2 diabetes affected persons s had a side effect of DR, while 70% of affected persons have prolonged history of diabetic retinopathy for 20 years were identified with diabetic retinopathy. To further enhance the diagnosis process, this research study has developed Deep DR, a technique that involves deep learning to diagnose all phases of diabetic retinopathy.",retinal diagnosis;diabetic retinopathy;deep learning
 Conferences,K. Sharma; P. Nagappan,Machine Learning/Deep Learning Algorithms & Variability in Grading Improves Early Detection of DR,IEEE,2022,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9865837,"Health condition which mainly influence human retina i.e. cognate by Diabetic Mellitus (DM) is a main thread of Diabetic Retinopathy (DR). As a result of the damage of the retina, it causes vision loss. In accordance with census diabetic individuals who had suffered from diabetics in a long time also have DR issues. As a result, DR has become a critical issue that needs a primary stage screening and assessment in order to prevent vision loss and blindness. Physical diagnosis of the condition is time-consuming and prone to inaccuracy. Furthermore, it is not possible to find an ophthalmologist regardless of location or time. As a result, the need for a highly advanced and computerized intelligent system arises, which can be used to diagnose DR in its early stages. Researchers have proposed a number of Machine Learning (ML) algorithms for the diagnosis of DR for decapods. For determining retinal lesion significantly and for initial stage DR diagnosis various feature extraction and analyzing approaches are recommended. Traditional Machine Learning models, on the other hand, suffer from poor generalization during feature extraction due to limited datasets. Using Deep Learning models, more datasets and high computer processing unit weak generalization problem can be reduced. This study intends to provide a DR overview as well as a brief explanation of previous efforts and current automated methods and improvements, in order to the staring exposure of DR. This paper also discusses the most up-to-date DR lesions as well as the causes and symptoms of DR and focus on how AI/ML approaches helpful in early diagnosis of DR and we have to study more on variability in grading to evaluate the best possible result for screening and improving eye disease mainly caused by diabetics.",Machine Learning;Deep Learning;Diabetic Retinopathy;Non-proliferative DR and proliferative DR
 Conferences,E. Mohamed; M. A. Elmohsen; T. Basha,Improved Automatic Grading of Diabetic Retinopathy Using Deep Learning and Principal Component Analysis,IEEE,2021,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9630919,"Diabetic retinopathy (DR) is one of the most common chronic diseases around the world. Early screening and diagnosis of DR patients through retinal fundus is always preferred. However, image screening and diagnosis is a highly time-consuming task for clinicians. So, there is a high need for automatic diagnosis. The objective of our study is to develop and validate a new automated deep learning-based approach for diabetic retinopathy multi-class detection and classification. In this study we evaluate the contribution of the DR features in each color channel then we pick the most significant channels and calculate their principal components (PCA) which are then fed to the deep learning model, and the grading decision is decided based on a majority voting scheme applied to the out of the deep learning model. The developed models were trained on a publicly available dataset with around 80K color fundus images and were tested on our local dataset with around 100 images. Our results show a significant improvement in DR multi-class classification with 85% accuracy, 89% sensitivity, and 96% specificity.",Not Found
 Conferences,M. M. Dharmana; A. M.S.,Pre-diagnosis of Diabetic Retinopathy using Blob Detection,IEEE,2020,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9183241,"Diabetic retinopathy is an ailment that harms to the retina because of diabetes mellitus. Starting at now, diagnosing DR is tedious and it is a manual procedure that requires a clinical master to review and break down the fundus pictures. While this strategy is feasible, as the number of individuals with diabetes continues expanding, raises the requirement for programmed DR screening strategies that guarantee serving the mass populace. The proposed method in this paper bring forward an effective feature extraction technique based on blob detection followed by classification of different stages of diabetic retinopathy using machine learning technique. This feature extraction technique could help automatic characterization of retina images for diabetic retinopathy with an accuracy of 83 per cent with the most efficient machine learning classification algorithm, which would help specialists to handily recognize the patient's condition in a progressively precise manner.",Diabetic retinopathy;machine learning;blob detection;image processing
 Conferences,S. Sridhar; S. Sanagavarapu,Detection and Prognosis Evaluation of Diabetic Retinopathy using Ensemble Deep Convolutional Neural Networks,IEEE,2020,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9231789,"Diabetic Retinopathy is a condition that occurs in the eye as a result of diabetes in patients. Due to uncontrolled blood sugar levels in patients, there would be a lack of blood flow and oxygen to the retina. This causes strain on blood vessels some extent without invasive treatment and when detected in its early stages. When the strain in the blood vessels increases, it may cause leakage of fluids from blood vessels and loss of proper vision in the eye. This system implements a deep learning model using ResNet to determine the performance for the detection of the various stages of the condition in individuals. Individual submodels are built using ResNet to detect the presence of Diabetic Retinopathy and are ensembled together using the AdaBoost Classifier. Multiclass classification ResNet models are built and stacked together to detect the prognosis of Diabetic Retinopathy. The implemented models showed a performance accuracy of 78.88% to detect the presence and 61.9% to evaluate the prognosis of Diabetic Retinopathy. The performance of the trained models is visualised with a Grad-CAM and the results are analysed.",Diabetic Retinopathy;ResNet;Ensemble;Deep Convolutional Neural Network;Stacked Generalization
 Conferences,R. H. Paradisa; D. Sarwinda; A. Bustamam; T. Argyadiva,Classification of Diabetic Retinopathy through Deep Feature Extraction and Classic Machine Learning Approach,IEEE,2020,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9332082,"Diabetic Retinopathy (DR) is a complication of diabetes, the leading cause of vision loss in working-age adults. An ophthalmologist can carry out the diagnosis of DR by examining color fundus images. However, the fundus image analysis process takes a long time. Automatic detection of DR is a challenging task. One of the deep learning approaches, Convolutional Neural Networks (CNN), is efficient in image classification tasks. In this research, a CNN architecture is used, namely ResNet-50, as feature extraction and classification. The ResNet-50 feature output at the feature extraction stage is also used as input for machine learning classifiers such as Support Vector Machine (SVM), Random Forest (RF), k-Nearest Neighbor (k-NN), and Extreme Gradient Boosting (XGBoost). The model works by using fundus images from the DIARETDBI dataset. Data augmentation and preprocessing are proposed in this study to facilitate the model in recognizing images. The performance of each classifier is evaluated based on accuracy, sensitivity, and specificity. The SVM classifier achieved 99% for accuracy and sensitivity in the 80:20 dataset composition. The k-NN classifier obtains the highest specificity for the same dataset's design by 100%.",Diabetic Retinopathy;Convolutional Neural Network;ResNet-50;Feature Extraction;Machine Learning Classifier
 Conferences,K. Bhatia; S. Arora; R. Tomar,Diagnosis of diabetic retinopathy using machine learning classification algorithm,IEEE,2016,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7877439,"Diabetic Retinopathy is human eye disease which causes damage to retina of eye and it may eventually lead to complete blindness. Detection of diabetic retinopathy in early stage is essential to avoid complete blindness. Many physical tests like visual acuity test, pupil dilation, optical coherence tomography can be used to detect diabetic retinopathy but are time consuming and affects patients as well. This review paper focuses on decision about the presence of disease by applying ensemble of machine learning classifying algorithms on features extracted from output of different retinal image processing algorithms, like diameter of optic disk, lesion specific (microaneurysms, exudates), image level (pre-screening, AM/FM, quality assessment). Decision making for predicting the presence of diabetic retinopathy was performed using alternating decision tree, adaBoost, Naive Bayes, Random Forest and SVM.",Diabetic retinopathy;machine learning;ensemble learning;exudate;decision tree;adaBoost;Naive Bayes;Random Forest;SVM
 Conferences,H. Ghebrechristos; G. Alaghband; R. Y. Hwang,RetiNet — Feature Extractor for Learning Patterns of Diabetic Retinopathy and Age-Related Macular Degeneration from Publicly Available Datasets,IEEE,2017,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8561051,"Diabetic Retinopathy (DR) and Age-related Macular Degeneration (AMD) are two common vision threatening eye conditions. In a large-scale screening environment DR and AMD can be assessed by detecting specific retinal findings in fundus images. In this paper, we introduce a new deep learning based feature extractor for automatic classification of DR and AMD from fundus images. We used a small dataset containing 60000 images with four severity levels of DR and two classes of AMD to design and fine-tune a deep learning model called RetiNet. This dataset, which consisted of two publicly available datasets (MESSIDOR and Kaggle), was augmented and employed to evaluate RetiNet. RetiNet can achieve diagnosis performance comparable to retina experts on the MESSIDOR dataset with cross-dataset testing (i.e., the feature extractor was trained on an independent dataset and tested on MESSIDOR). Our algorithm obtained an average accuracy of 88% on the validation set.",Age-related Macular Degeneration (AMD);Artificial Neural Network (ANN);Convolutional Neural Network(CNN);Deep Learning;Diabetic Retinopathy(DR)
 Conferences,Y. Wu; Z. Hu,Recognition of Diabetic Retinopathy Basedon Transfer Learning,IEEE,2019,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8725801,"Diabetic retinopathy (DR) is a kind of eyes disease caused by diabetes. With the development of science and technology, vision plays an increasingly important role in people's daily life. Therefore, how to automatically classify diabetic retinopathy images has significant value. The traditional manual classification method requires knowledge and time and it's difficult to obtain an objective and unified medical diagnosis. Therefore, this paper proposes a method for diabetic retinopathy recognition based on transfer learning. First, download data from Kaggle's official website, then perform data enhancement, include data amplification, flipping, folding, and contrast adjustment. Then, use pretrained model such asVGG19, InceptionV3, Resnet50 and so on. Each neural network has been trained by ImageNet dataset already. What we need to do is migrate the DR images to these models. Finally, the images are divided into 5 types by the serious degree of diabetic retinopathy. The experimental results shows that the classification accuracy of this method can reach at 0.60, which is better than the traditional direct training method and has better robustness and generalization.",diabetic retinopathy;neural network;transfer learning
 Conferences,H. Yeh; C. -J. Lin; C. -C. Hsu; C. -Y. Lee,Deep-learning based automated segmentation of Diabetic Retinopathy symptoms,IEEE,2020,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9394100,"Purpose: Retinal fundus images are an important basis for reflecting retinal health status, are widely used in clinical diagnosis, and have important significance in fundus image processing and analysis. At present, clinicians rely on manual examination of fundus images when diagnosing retinopathy, which is both time- and labor-consuming. However, the need for rapid auxiliary diagnostic imaging is increasing day by day. Therefore, this study evaluates deep learning as a preprocessing method for optic disc examination along with the method proposed in this study. Methods: During optic disc segmentation, the optic disc region in original images is blurry and unclear compared to the entire image. The halo around the optic disc causes boundaries to become unclear and makes examination difficult. In this paper, different preprocessing methods were used to solve the problem of blurry optic disc region and the effectiveness of the various preprocessing methods was evaluated. Preprocessing methods used in this study to identify optic disc regions that were not apparent in the original image include the original image, green channel, CLAHE, and subtraction of average filter from Gaussian filter (σ=1) using the original image. This preprocessing method is known as local differential filter and was uploaded to U-Net for training. Results: Evaluate the proposed method on the MICCAI REFUGE Challenge 2018 database. In the performance of Dice, the original image is 0.9473; the LDF image is 0.9521; the green channel image is 0.9429; CLAHE image is 0.9499. Conclusions: Currently, deep learning is used in many types of preprocessing for segmentation. In this study, we preprocessed fundus images and inputted them into the model for training. Finally, LDF image was used to obtain the best preprocessing method for optic disc segmentation in fundus images.",U-Net;Pre-processing;Optic disc;Fundus image;CLAHE;LDF;Contrast Limited Adaptive Histogram Equalization;Local differential filter
 Conferences,J. Cao; J. Chen,Comparison of Deep Learning Models on Detection and Classification of Diabetic Retinopathy,IEEE,2021,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9664179,"Diabetic retinopathy is a common complication to diabetes, also is the main cause of the current diabetic blindness. Traditional methods of manually classifying retinal pathological images have difficulty in feature extraction, and differences in the level of medical personnel also result in low classification efficiency. In this paper, four deep learning network models based on LeNet, AlexNet, GoogLeNet and Res-Net 50 are used to compare and study the automatic classification of diabetic retinopathy images. The experimental data set comes from the data modeling and data analysis competition platform (Kaggle). The experimental results show that RES-NET 50 can accurately classify the degree of retinopathy with an accuracy of 89.71%, but the convergence rate is slow, while AlexNet can quickly converge with a low accuracy of 63.21%. This research can provide a good research foundation for the diagnosis and treatment of retinal diseases and the classification of disease severity in the future.",Deep Learning;Diabetic retinopathy;Image recognition;Image Augment;Image classification
 Conferences,D. Rahhal; R. Alhamouri; I. Albataineh; R. Duwairi,Detection and Classification of Diabetic Retinopathy Using Artificial Intelligence Algorithms,IEEE,2022,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9811197,"Diabetic Retinopathy (DR) is considered as a sight-threatening complication of diabetes mellitus, the primary cause of blindness among working-age individuals. Ophthalmologists use fundus images to diagnose diabetic retinopathy and measure its severity by observing retinal lesions with high accuracy. However, diagnosing DR manually from fundus images requires a high level of expertise and effort from professional ophthalmologists. Early diagnosis of diabetes helps in saving the patient’s eye and preventing possible risky complications. In this context, the current paper proposed a model aims to detect DR using image processing and deep learning methods. A fully automatic diagnosis system that exceeds manual techniques to avoid misdiagnosis, reducing time, effort and cost were presented through this paper. A publicly available dataset of fundus images was used to apply the current paper’s proposed neural network model and transfer learning models, to classify each image into one of the five diabetic retinopathy stages. The simple proposed model achieved an accuracy of 66.68% in predicting the right label of the image. On the other hand, the second approach of fine-tuning the pre-trained models achieved higher testing accuracy (ranging from 93.13% to 100%,), which exceeds the current state-of-the-art results.",Diabetic Retinopathy;Deep Learning;Fundus;CNN;Classification;Transfer Learning
 Conferences,O. Dekhil; A. Naglah; M. Shaban; M. Ghazal; F. Taher; A. Elbaz,Deep Learning Based Method for Computer Aided Diagnosis of Diabetic Retinopathy,IEEE,2019,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9010333,"Diabetic retinopathy (DR) is a retinal disease caused by the high blood sugar levels that may damage and block the blood vessels feeding the retina. In the early stages of DR, the disease is asymptomatic; however, as the disease advances, a possible sudden loss of vision and blindness may occur. Therefore, an early diagnosis and staging of the disease is required to possibly slow down the progression of the disease and improve control of the symptoms. In response to the previous challenge, we introduce a computer aided diagnosis tool based on convolutional neural networks (CNN) to classify fundus images into one of the five stages of DR. The proposed CNN consists of a preprocessing stage, five stage convolutional, rectified linear and pooling layers followed by three fully connected layers. Transfer learning was adopted to minimize overfitting by training the model on a larger dataset of 3.2 million images (i.e. ImageNet) prior to the use of the model on the APTOS 2019 Kaggle DR dataset. The proposed approach has achieved a testing accuracy of 77% and a quadratic weighted kappa score of 78%, offering a promising solution for a successful early diagnose and staging of DR in an automated fashion.",Convolutional neural network;Image classification;Ophthalmoscopy
 Conferences,A. J. Zaylaa; G. I. Wehbe; A. M. Ouahabi,Bringing AI to Automatic Diagnosis of Diabetic Retinopathy from Optical Coherence Tomography Angiography,IEEE,2021,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9604812,"Artificial Intelligence (AI) is significantly gaining interest in the field of Diagnostic and Functional Optical Imaging. As cutting-edge algorithms for decision-making are vast and medical imaging machines are diverse, the choice of the ultimate algorithm remains challenging. As a breakthrough in the field, our aim is to explore the adequate machine and deep learning algorithms that improve the classification of Optical Coherence Tomography Angiography (OCTA) Images, between normal and Diabetic Retinopathy (DR) images. The target was to provide an automatic paradigm for the medical staff to detect the presence of DR Lesions from OCTA images for diagnostic and monitoring purposes. Data were collected prospectively over a year from a comprehensive medical center in Lebanon. The mixed Convolution Neural Network (CNN)-Support Vector Machine Network (CNN, SVM) algorithm was utilized in the new paradigm and compared to the feed forward backpropagation NN, to the SVM and to the modified SVM. Results were evaluated independently for the presence or absence of DR using statistical metrics. Experimental results showcased promising association of deep learning to the early diagnosis of DR. Results manifested the high performance of the new paradigm, where the mixed algorithm applied to the functional OCTA surpassed the performance of the feed forward backpropagation NN. The sensitivity of the mixed (CNN, SVM) algorithm was 22.22% higher than that obtained by the feed forward backpropagation NN. Moreover, the specificity of classification of DR from OCTA images using mixed (CNN, SVM) algorithm was 24.44% higher than that obtained by the feed forward backpropagation NN. The precision was 25.47% higher in the new paradigm than that obtained by the feed forward backpropagation network, and the accuracy was 23.35% higher in the mixed (CNN, SVM) than that obtained by the feed forward backpropagation NN. This high performance plays a massive role in improving the diagnosis of DR, and thus Healthcare system and processing of information. As a future prospect, we aim to consider more algorithms and variables in the diagnosis of DR from OCTA images.",Artificial Intelligence;Machine and Deep Learning;Functional Medical Imaging;Optical Coherence Tomography Angiography;Diabetic Retinopathy;Statistical Evaluation
 Conferences,Q. Li; C. Peng; Y. Ma; S. Du; B. Guo; Y. Li,Pixel-level Diabetic Retinopathy Lesion Detection Using Multi-scale Convolutional Neural Network,IEEE,2021,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9391891,"Diabetic retinopathy (DR) is one of the leading causes of preventable blindness. It's urgent to develop reliable methods for auto DR screening, the key of which is the detection of lesions. This paper presents an innovative method to detect DR lesions in pixel-level. We design a multi-scale Convolution Neural Network (CNN) that make the full use of multiple different scales with complementary image information. Experiments are carried out on both private and public datasets. Results show that multi-scale CNN model outperforms single-scale CNN model and other state-of-the-art approaches.",medical image processing;diabetic retinopathy;lesion detection;multi-scale CNN;computer-aided diagnosis
 Conferences,M. D. Shreyas; A. R. K. P; G. S,A Study on Machine Learning Based Diabetic Retinopathy,IEEE,2022,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9850729,"Diabetic Retinopathy (DR), one of the main causes of blindness in the eyes, is curable in its early stages. The first indicators are red lesions, which include both micro aneurysms (MAs) and hemorrhages (HEs). Diabetic Retinopathy diagnosis by color fundus images is challenging and time-consuming as it takes trained doctors to recognize the presence and significance of many characteristics, as well as a complex classification method. Even though various Machine Learning based automatic Diabetic Retinopathy diagnosis approaches exist, they are still unable to offer point-of-care diagnosis, which would allow one to upload an input image, segment the retinal blood vessels, examine each vessel's expansion, and provide accurate result. Machine Learning and Deep Learning techniques have swiftly gained traction to understand medical images with promising results. Machine Learning can quantify and get more accurate results for the challenges mentioned above, as well as calculate the severity level of the given input eye image as an accuracy rate or predict Diabetic Retinopathy through feature extraction. In this research, a study is conducted to aid in the development of better Diabetic Retinopathy based models, with the aim of enhancing the detection accuracy of Diabetic Retinopathy by evaluating existing Machine Learning models and mobile applications with multiple datasets.",Diabetic Retinopathy (DR);Machine Learning(ML);Deep Learning(DL);Image Processing;Mobile Systems;Survey
 Conferences,S. W. Aditi; F. Kabir; P. C. Shill,Diagnosis of Diabetic Retinopathy Using Deep Learning Techniques,IEEE,2021,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9733545,"Diabetic retinopathy (DR) is a critical eye malady and a severe cause of visual deficiency in diabetic patients. Diabetic retinopathy is the root cause of more than 1% of the visual deficiency around the world. DR affects blood vessels of retina which may lead to diabetic macular edema, neovascular glaucoma and retinal detachment. To prevent DR from progressing and causing severe damage, an early detection of diabetic retinopathy is crucial. The analysis of diabetic retinopathy (DR) through color fundus images needs skilled clinicians to discover the presence of DR. The grading system is also very hard. Overall the process is less optimal and very time consuming. In this paper, we propose different deep learning approaches to diagnose DR from digital retinal fundus images and precisely classify its severity. In order to build the best classification, simulate the various deep learning models such as ResNet50, ResNet152V2, VGG16 and VGG19. Different benchmark datasets with different characterizations and complexities have been used for training and testing the models. The simulation results illustrate that the proposed method gives better performance while comparing with other methods.",Diabetic Retinopathy;Pretrained models;Transfer learning;Image classification;ResNet50;ResNet152V2;VGG16;VGG19
 Conferences,S. S. Karki; P. Kulkarni,Diabetic Retinopathy Classification using a Combination of EfficientNets,IEEE,2021,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9397035,"Diabetic Retinopathy (DR) is a diabetes complication that affects vision. It is caused by damage to the blood vessels of retina. Early and accurate detection of DR is crucial to reduce likelihood of progression to proliferative retinopathy and blindness. This paper proposes a method for classifying the severity of DR using deep learning. Experiments were conducted by blending the members of EfficientNet for classification of the diabetic retinopathy image as no DR, mild, moderate, severe, or proliferative DR. The models have been trained using different datasets and best model achieved a quadratic kappa score of 0.924377 on the APTOS test dataset. The results are promising and warrant further investigation. The presented model has the potential aid in fast diagnosis for better early detection of DR.",CNN;Retinopathy;APTOS;EfficientNet;BCE loss
 Journals,H. Kaushik; D. Singh; M. Kaur; H. Alshazly; A. Zaguia; H. Hamam,Diabetic Retinopathy Diagnosis From Fundus Images Using Stacked Generalization of Deep Models,IEEE,2021,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9500222,"Diabetic retinopathy (DR) is a diabetes complication that affects the eye and can cause damage from mild vision problems to complete blindness. It has been observed that the eye fundus images show various kinds of color aberrations and irrelevant illuminations, which degrade the diagnostic analysis and may hinder the results. In this research, we present a methodology to eliminate these unnecessary reflectance properties of the images using a novel image processing schema and a stacked deep learning technique for the diagnosis. For the luminosity normalization of the image, the gray world color constancy algorithm is implemented which does image desaturation and improves the overall image quality. The effectiveness of the proposed image enhancement technique is evaluated based on the peak signal to noise ratio (PSNR) and mean squared error (MSE) of the normalized image. To develop a deep learning based computer-aided diagnostic system, we present a novel methodology of stacked generalization of convolution neural networks (CNN). Three custom CNN model weights are fed on the top of a single meta-learner classifier, which combines the most optimum weights of the three sub-neural networks to obtain superior metrics of evaluation and robust prediction results. The proposed stacked model reports an overall test accuracy of 97.92% (binary classification) and 87.45% (multi-class classification). Extensive experimental results in terms of accuracy, F-measure, sensitivity, specificity, recall and precision reveal that the proposed methodology of illumination normalization greatly facilitated the deep learning model and yields better results than various state-of-art techniques.",Convolutional neural networks;diabetic retinopathy;early diagnosis;fundus images;gray world algorithm;ensemble learning
 Conferences,S. Sooraj; M. Bedeeuzzaman,Automatic Classification of Diabetic Retinopathy Based on Deep Learning - A Review,IEEE,2020,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9249980,"India is home to approximately 70 million people with diabetes, and this epidemic is estimated to increase to 130 million by 2045. Diabetic retinopathy (DR) is a dangerous eye condition that affects diabetic persons. DR remains asymptomatic until vision is affected. Treatment is most likely to be effective when performed before progression to advanced disease. Therefore, early diagnosis of DR is crucial for its treatment as it can eventually cause permanent blindness. DR is the most common complication of diabetes and about 3 to 4.5 million people in India suffer from vision threatening DR. The treatment requires costly devices and medications and the disease requires regular follow-up from diagnosis to the end-of-life. Also, manual inspection of fundus images by experienced ophthalmologists to check morphological changes in microaneurysms, exudates, blood vessels, hemorrhages, and macula is a very time-consuming work. It is also subject to substantial inter-observer and intra-observer variability. Many deep learning algorithms are being used currently which can perform automatic classification of images that are input to the system. This paper is a review of deep learning techniques applied for the detection and classification of DR using retinal images. The factors that may influence the performance of a deep learning algorithm in detecting DR are also considered.",diabetic retinopathy;deep learning;medical image analysis;multiclass classification;data augmentation
 Journals,N. Liang; L. Yuan; X. Wen; H. Xu; J. Wang,End-To-End Retina Image Synthesis Based on CGAN Using Class Feature Loss and Improved Retinal Detail Loss,IEEE,2022,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9849644,"Retinal images are the most direct and effective basis for Diabetic Retinopathy (DR) diagnosis. With the rapid development of deep learning, the technology of retinal image-assisted diagnosis based on deep learning is widely used in the field of DR intelligent diagnosis. However, the training of deep neural network usually requires a large number of annotated samples, but retinal images annotated by professional doctors are cost-expensive and difficult to obtain, which limits the application of deep learning technology in DR intelligent diagnosis. In order to alleviate the scarcity of labelled retinal images, we propose an end-to-end conditional generative adversarial network with class feature loss and improved retinal detail loss. The network combines the above two losses with the adversarial loss, and jointly constrains the generator to generate high-quality retinal images. The proposed retinal detail loss is summed over physiological detail loss which is meant to preserve high-level semantic features of the physiological details contained in the fundus images and pixel loss which ensures the low-level features in synthesized image will not deviate from the real image. In addition, the class feature loss constrains the synthesized images to be consistent with the real images in class features representation, which further makes the synthesized images have pathological features of the corresponding grade. The generated images by the proposed network are evaluated from three objective metrics including the subjective effect and the FID, SWD, which are used to evaluate the quality and diversity of generated images, and the effect of retinal vessel segmentation, respectively. Experimental results demonstrate that our synthesized images have superior performance on both the quality and quantity.",Diabetic retinopathy;retinal image synthesis;conditional generative adversarial network;deep learning;DR~grading
 Conferences,M. S. Ali Mazumder; T. Hossain; F. M. J. Mehedi Shamrat; N. Jahan; Z. Tasnim; A. Khater,Deep Learning Approaches for Diabetic Retinopathy Detection by Image Classification,IEEE,2022,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9952159,"Diabetic retinopathy (DR) is among the most prevalent eye diseases that can result in blindness and vision loss if left untreated. Early detection of vision impairment might slow or stop its progression. Manual diagnosis using retinal fundus images, such as visual acuity testing, pupil dilation, and optical consistency tomography, calls for highly skilled clinicians to identify and assess the significance of numerous smallest details, making this a rigorous, time-consuming, and error-prone task. Consequently, a computer-aided automated process is definitely required. This study proposes an automated strategy for binary classification of DR versus normal retina using gaussian filtered color fundus retinal photos as input. The study employs the Diabetic Retinopathy dataset from Kaggle that includes 3,662 original retinal images with labelling for non-DR and DR. Using Convolutional Neural Network (CNN) architectures, the process can distinguish exudates, microaneurysms, and hemorrhages in retinal imaging by training with labelled data. The study trained and tested five models, InceptionV3, MobileNetV2, ResNet50, VGG16, and VGG19. It is observed that MobileNetV2 stands out as the most effective at detecting DR and Non-DR with and accuracy of 96.04% and Cohen Kappa Score of 92.08%. In the study, the models Resnet50, VGG16 and VGG19 have the same compilation time of 62 seconds for each epoch compared to which MobileNetv2 takes more time with 90 seconds, followed by InceptionV3 with 85 seconds.",Diabetic Retinopathy;Fundus Image;Deep Learning;Disease Detection;Convolutional Neural Network
 Conferences,I. Wijesinghe; C. Gamage; I. Perera; C. Chitraranjan,A Smart Telemedicine System with Deep Learning to Manage Diabetic Retinopathy and Foot Ulcers,IEEE,2019,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8818682,"Artificial intelligence in combination with modern technologies including medical screening devices has the potential to deliver better management services to deal with chronic diseases with higher accuracy, efficiency, and satisfaction. With the recent evolution in digitized data acquisition, computer vision and machine learning, AI solutions are spreading into areas which were previously examined by well-trained clinicians. Early diagnosis of diabetic retinopathy (DR) and foot ulcers (DFU) occurrence through image analysis is in high demand as many individuals are left without any supervision due to the limited resources such as trained clinicians or suitable equipment especially, in rural areas. Furthermore, the existing system will become even more insufficient as the number of people with diabetes increases. In this research paper, we propose a prototype that involves an autonomous system called an Intelligent Diabetic Assistant (IDA), which decides the diagnosis and the treatment prioritization depending upon the observations appeared in the screen. The IDA consists of knowledge-based modules for severity level-based classification, clinical decision support and near real-time foot ulcer detection and boundary screening. We use the System Usability Scale (SUS) in terms of performance, learnability, and satisfaction to measure the usability of the IDA. The mean SUS score was 88.5, demonstrating good but not exceptional system usability. We perform our experiments with clinicians who have been involved in diabetic care.",Retinopathy;foot ulcers;telemedicine;deep learning;transfer learning;image retrieval;instance based segmentation;classification
 Conferences,D. Das; S. Das; S. K. Biswas; B. Purkayastha,Deep Diabetic Retinopathy Feature eXtraction and Random Forest based ensemble Classification System (DDRFXRFCS),IEEE,2021,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9544899,"Diabetic Retinopathy (DR) is a severe eye disease caused due to diabetes mellitus and is mostly seen amongst patients suffering from prolonged diabetes. It causes vision problem and in the worst case it causes severe blindness due to formation of lesions in the retina triggered by the rupture of retinal blood vessels. It has become important to detect the disease at an early stage to avoid severity and to avoid difficulties in identification of subtle lesions during the progressive stages of the disease. The process of manual analysis is cumbersome for routine treatment. Hence, the importance of implementing intelligent systems using Deep Learning (DL) is realized. Various research works have been performed using DL and Convolutional Neural Networks for image related tasks, and DR is no different as it requires fundus images for diagnosis. Various single-model based feature extraction and classification systems are proposed earlier which have consistently shown a stagnant performance in DR detection with greater bias and variance. In order to reduce bias and variance and avoid overfitting of the model, researchers have proposed ensemble-based models for image classification based on deep features extracted using DL models. Such ensemble models have exhibited much better performance in aggregating diverse perspective for making predictions to obtain the average optimal prediction compared to a single classifier-based model. Thus, this paper proposes three different state-of-the-art DL Convolutional Network (DConvNet) for individual feature extraction and Random Forest (RF) based ensemble classification for obtaining various predictions and compute the average of all predictions, which is the optimal best solution, for the purpose of early DR detection.",Image;Ensemble;Feature Importance;Deep Learning;Random Forest;Diabetic Retinopathy
 Conferences,A. V. Kumar; A. S. Babu,Diabetic Retinopathy Detection using Deep Learning Methodology,IEEE,2022,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9971891,"Diabetic retinopathy is a human retinal sickness that makes harm the veins in the retina. Individuals with diabetics have high glucose level that harm the veins. These blood vessels can swell and leak, sometimes it can even block the blood flow. Eventually, this leads to partial or complete vision loss. Early diagnosis helps in timely treatment but it requires an efficient screening system. This work suggests detection of diabetic retinopathy using three deep learning techniques such as Densenet-169,ConvLSTM (proposed model) and Dense-LSTM (proposed hybrid model) and compare these models, which is required for early location and grouping as per the severity of diabetic retinopathy. The database for this work is publicly available MESSIDOR dataset. From the results obtained 94 percentage accuracy for Densenet-169 model, 99 percentage accuracy for ConvLSTM (proposed model)and 83 percentage accuracy for Dense-LSTM (proposed hybrid model). It is evident that Diabetic Retinopathy detection using proposed model, ConvLSTM outperformed the Densenet-169 and Dense-LSTM model.",Diabetic Retinopathy;Deep Learning;Densenet-169;Fundus images;ConvLSTM
 Conferences,P. Saranya; S. K. Devi; B. Bharanidharan,Detection of Diabetic Retinopathy in Retinal Fundus Images using DenseNet based Deep Learning Model,IEEE,2022,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9752065,"Diabetic Mellitus is one of the world’s most common diseases. Diabetes is quite prevalent, and it produces a variety of health issues such as Diabetic Retinopathy, nephropathy, diabetic foot, and so on. Diabetic Retinopathy is the most prominent problem (DR). DR starts with no symptoms or minor vision problems and escalates to the point when vision loss is a possibility. Since diagnosis takes time and ophthalmologists are scarce, patients endure vision loss even before they are diagnosed. So, an early detection of DR may help to mitigate the problem. To diagnose DR, however, numerous physical tests are required and in the early phases of the disease, it is difficult to diagnose by exams. As a result, a new diagnostic technique must be devised to detect the disease before it manifests itself in a test, allowing it to be treated sooner. The objective of the proposed model is to provide an automated diagnosis model for DR detection utilizing DenseNet-based deep learning models. As an input, the classification model was given a pre-processed retinal image that had not been enhanced with features. Only a few preprocessing steps are done on the noisy images to increase DR detection accuracy and achieved the maximum accuracy and precision of 0.83 and 0.99 respectively.",Diabetic Retinopathy;deep learning models;DenseNet;fundus images
 Conferences,D. Attota; D. N. Tadikonda; S. Pethe; M. A. Al Hafiz Khan,An Ensembled Method For Diabetic Retinopathy Classification using Transfer Learning,IEEE,2022,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9842565,"Diabetes affects 40–45% of Diabetic Retinopathy (DR) patients in the US. Early detection of DR may prevent or postpone vision deterioration, but it is difficult since the disorder often manifests with few symptoms until it is too late to treat. Clinically, DR is routinely treated using fundus images, with an estimated 200 million cases worldwide and over 400,000 deaths each year. A great deal of progress has been made by applying machine learning algorithms to the fundus images. As a result, image classification and detection have become reliable techniques for detecting the severity of diabetic retinopathy. Convolutional Neural Networks (CNNs) play a crucial role in the image classification and detection process by capturing various images' details, enabling a fast and efficient method for detecting diabetic retinopathy. CNN pre-trained models such as ResNet50, Inception V3,and EfficientNetB7 have substantially improved their performance in the ImageNet Large-Scale Visual Recognition Competition. In addition, these pre-trained models are more precise and inexpensive to train because of the shorter connections between their input and output layers. This work proposes an approach for image classification that ensembles three pre-trained models, namely: EfficientNetB7, ResNet50V2, and Inception V3,to perform the classification of the diabetic retinopathy subtypes. Our proposed method achieves 97.43 % accuracy by adjusting the weights of the pre-trained models in detecting D R using the EyePacs Dataset.",Convolutional Neural Network (CNN);Deep Transfer Learning;Diabetic Retinopathy (DR)
 Journals,L. Dai; R. Fang; H. Li; X. Hou; B. Sheng; Q. Wu; W. Jia,Clinical Report Guided Retinal Microaneurysm Detection With Multi-Sieving Deep Learning,IEEE,2018,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8263115,"Timely detection and treatment of microaneurysms is a critical step to prevent the development of vision-threatening eye diseases such as diabetic retinopathy. However, detecting microaneurysms in fundus images is a highly challenging task due to the low image contrast, misleading cues of other red lesions, and the large variation of imaging conditions. Existing methods tend to fail in face of the large intra-class variation and small inter-class variations for microaneurysm detection in fundus images. Recently, hybrid text/image mining computer-aided diagnosis systems have emerged to offer a promise of bridging the semantic gap between images and diagnostic information. In this paper, we focus on developing an interleaved deep mining technique to cope intelligently with the unbalanced microaneurysm detection problem. Specifically, we present a clinical report guided multi-sieving convolutional neural network, which leverages a small amount of supervised information in clinical reports to identify the potential microaneurysm regions via the image-to-text mapping in the feature space. These potential microaneurysm regions are then interleaved with fundus image information for multi-sieving deep mining in a highly unbalanced classification problem. Critically, the clinical reports are employed to bridge the semantic gap between low-level image features and high-level diagnostic information. We build an efficient microaneurysm detection framework based on the hybrid text/image interleaving and validate its performance on challenging clinical data sets acquired from diabetic retinopathy patients. Extensive evaluations are carried out in terms of fundus detection and classification. Experimental results show that our framework achieves 99.7% precision and 87.8% recall, comparing favorably with the state-of-the-art algorithms. Integration of expert domain knowledge and image information demonstrates the feasibility of reducing the difficulty of training classifiers under extremely unbalanced data distributions.;Notice of Violation of IEEE Publication Principles<br><br> ""Clinical Report Guided Retinal Microaneurysm Detection With Multi-Sieving Deep Learning,""<br> by Ling Dai, Ruogu Fang, Huating Li, Xuhong Hou, Bin Sheng, Qiang Wu, and Weiping Jia<br> in the IEEE Transactions on Medical Imaging, vol. 37, no. 5, May 2018, pp. 1149-1161<br><br> After careful and considered review of the content and authorship of this paper by a duly constituted expert committee, this paper has been found to be in violation of IEEE's Publication Principles.<br><br> This paper contains significant portions of original text from the paper cited below. The original text was copied without attribution (including appropriate references to the original author(s) and/or paper title) and without permission.<br><br> ""Mapping Visual Features to Semantic Profiles for Retrieval in Medical Imaging,""<br> by Johannes Hofmanninger ; Georg Langs<br> in the Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), June 2015, pp. 457-465.<br><br>",Diabetic retinopathy;fundus image analysis;multi-sieving CNN;microaneurysm detection;clinical reports;deep learning
 Journals,S. Majumder; N. Kehtarnavaz,Multitasking Deep Learning Model for Detection of Five Stages of Diabetic Retinopathy,IEEE,2021,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9526554,"Early diagnosis and treatment of diabetic retinopathy (DR) can reduce the risk of vision loss. There are five stages of DR consisting of no DR, mild DR, moderate DR, severe DR, and proliferate DR. This paper presents a multitask deep learning model to detect all the five stages of DR more accurately than existing methods. The developed multitask model consists of one classification model and one regression model, each with its own loss function. After training the regression model and the classification model separately, the features extracted by these two models are concatenated and inputted to a multilayer perceptron network to classify the five stages of DR. A modified Squeeze Excitation Densely Connected deep neural network is also developed as part of this multitasking approach. The developed multitask model is applied to the two large Kaggle datasets of APTOS and EyePACS. The results obtained indicate that the developed multitask model achieved a weighted Kappa score of 0.90 and 0.88 for the APTOS and EyePACS datasets, respectively. In addition, the micro and macro average area under the receiver operating characteristic (ROC) curve was found to be 0.96, and 0.93, respectively, which are higher than existing methods for detecting the five stages of DR.",Diabetic retinopathy (DR);eye fundus images;five stages of diabetic retinopathy;multitasking deep neural network;squeeze excitation densely connected network
 Journals,S. H. Abbood; H. N. A. Hamed; M. S. M. Rahim; A. Rehman; T. Saba; S. A. Bahaj,Hybrid Retinal Image Enhancement Algorithm for Diabetic Retinopathy Diagnostic Using Deep Learning Model,IEEE,2022,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9819926,"Diabetic Retinopathy (DR) is a prevalent acute stage of diabetes mellitus that causes vision-effecting abnormalities on the retina. This will cause blindness if not identified early. Because DR not an irreversible procedure, and only vision is preserved via care. Consequently, Early diagnosis and care with DR will significantly minimize the chance of vision loss. In modern ophthalmology, retinal image analysis has become a popular approach to disease diagnosis. The ophthalmologists and computerized systems extensively employ fundus angiography to detect DR-based clinical signs for early detection of DR. fundus photographs are commonly prone to low contrast, noise, and irregular illumination issues due to the complexity of imaging environments such as imaging variety of angles and light conditions. This research presents an Algorithm for improving the quality of images to strengthen the standard of color fundus images by reducing the noise and improving the contrast. The approach includes two main stages: cropping the images to remove insignificant content, then applying the shape crop and gaussian blurring for noise reduction and contrast improvement. The experimental results are evaluated using two standard datasets EyePACS and MESSIDOR. It’s clearly shown that the outcomes of feature extraction and classification of enhanced images is outperform the results without applying the enhancement approach. The improved algorithm is also tested in smart hospitals as an IoMT application.",Image enhancement;deep learning;diabetic retinopathy;retina;fundus image;healthcare;health risks
 Conferences,N. Zaaboub; A. Douik,Application of learning algorithm for Diabetic Retinopathy Diagnosis,IEEE,2020,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9364139,"One of the causes of blindness among working-age adults is the diabetic retinopathy (DR). The DR raise the damage of the retina if it is not early diagnosed and treated. In the present paper, we are focusing on the detection of the primary signs of the diabetic retinopathy which is the exudate. The exudate appeared in white or yellow color with different shapes, sizes and positions. More its position is close to the optic disk, more the percentage of blindness is increased. That's why the position and the size are two important information for an ophthalmologist to distinguish or diagnose the severity of the disease. For those reasons, we aim in this paper to detect and segment the exudate using Random Forest classifier. A DR database used with the application of a Random Forest classifier to segment these regions. The impact of varying the main parameter of the random forest algorithm is studied. We achieved the highest value of the specificity and the accuracy with 99.5% and 99.50% respectively. An area under curve (AUC) of 0.952 is obtained.",Fundus image;diabetic retinopathy;exudate;random forest
 Journals,S. Qummar; F. G. Khan; S. Shah; A. Khan; S. Shamshirband; Z. U. Rehman; I. Ahmed Khan; W. Jadoon,A Deep Learning Ensemble Approach for Diabetic Retinopathy Detection,IEEE,2019,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8869883,"Diabetic Retinopathy (DR) is an ophthalmic disease that damages retinal blood vessels. DR causes impaired vision and may even lead to blindness if it is not diagnosed in early stages. DR has five stages or classes, namely normal, mild, moderate, severe and PDR (Proliferative Diabetic Retinopathy). Normally, highly trained experts examine the colored fundus images to diagnose this fatal disease. This manual diagnosis of this condition (by clinicians) is tedious and error-prone. Therefore, various computer vision-based techniques have been proposed to automatically detect DR and its different stages from retina images. However, these methods are unable to encode the underlying complicated features and can only classify DR's different stages with very low accuracy particularly, for the early stages. In this research, we used the publicly available Kaggle dataset of retina images to train an ensemble of five deep Convolution Neural Network (CNN) models (Resnet50, Inceptionv3, Xception, Dense121, Dense169) to encode the rich features and improve the classification for different stages of DR. The experimental results show that the proposed model detects all the stages of DR unlike the current methods and performs better compared to state-of-the-art methods on the same Kaggle dataset.",CNN;diabetic retinopathy;deep learning;ensemble model;fundus images;medical image analysis
 Conferences,G. Mathew; S. Sindhu Ramachandran; S. V.S.,EdgeAI: Diabetic Retinopathy Detection in Intel Architecture,IEEE,2020,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9311036,"Diabetic retinopathy is a leading cause of blindness among working-age adults. Millions of people suffer from Diabetic Retinopathy in India. More dreaded situation is faced by the population in rural India where access to quality healthcare is limited. AI comes to the rescue in those situations where initial diagnosis can be performed without much manual intervention. Early detection of this condition is critical for good prognosis. In this paper we propose a solution using UP2 board (Edge device based on x86 architecture) where AI diagnosis can be performed on the local premise itself. We used PyTorch framework for training the model using EfficientNet-B4 network architecture. Trained model was optimized using Intel Distribution of Open-VINO, and hence there is no much compromise in execution time. Inference time for execution of single image in UP2 board is 0.2 sec. Our model achieved test metric performance comparable to baseline literature results, with sensitivity of 91.5% and specificity of 97.86%. For proof of concept we used open dataset from Kaggle 2019 competition hosted by Aravind Hospital, India.",Diabetic Retinopathy;PyTorch;Intel Distribution of OpenVINO;Edge Computing;UP2 board
 Conferences,S. G. Sandhya; A. Suhasini; M. D. Kumar,Detection and Scrutiny of Diabetic Retinopathy Using Machine Learning Modus,IEEE,2020,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9262296,"Diabetic retinopathy is a bypassed infection and a diabetes confusion that influences eyes. It's brought about by harm to the veins of the light-touchy tissue at the rear of the eye (retina). The tremendous populace of diabetic patients and their huge screening necessities have brought forth enthusiasm for PC supported and totally programmed discovery of DR. Early detection of DR is critical for diagnosis and treatment of DR, which has led to a great deal of research towards the research of abnormal features related to DR that can be microneurysms, haemorrhages, hard exudates, etc. Most of the currently used classification techniques increases screening time, human error, complexity and reduce the accuracy. The proposed method involves feature extraction, augmentation and calculation of accuracy using CNN. The proposed model is implemented using Conda, along with Tensorflow and Keras Framework utilizing the Messidor dataset.",Messidor dataset;Deep learning;Augmentation;DR detection framework;CNN
 Journals,S. Wang; X. Wang; Y. Hu; Y. Shen; Z. Yang; M. Gan; B. Lei,Diabetic Retinopathy Diagnosis Using Multichannel Generative Adversarial Network With Semisupervision,IEEE,2021,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9062342,"Diabetic retinopathy (DR) is one of the major causes of blindness. It is of great significance to apply deep-learning techniques for DR recognition. However, deep-learning algorithms often depend on large amounts of labeled data, which is expensive and time-consuming to obtain in the medical imaging area. In addition, the DR features are inconspicuous and spread out over high-resolution fundus images. Therefore, it is a big challenge to learn the distribution of such DR features. This article proposes a multichannel-based generative adversarial network (MGAN) with semisupervision to grade DR. The multichannel generative model is developed to generate a series of subfundus images corresponding to the scattering DR features. By minimizing the dependence on labeled data, the proposed semisupervised MGAN can identify the inconspicuous lesion features by using high-resolution fundus images without compression. Experimental results on the public Messidor data set show that the proposed model can grade DR effectively. Note to Practitioners—This article is motivated by the challenging problem due to the inadequacy of labeled data in medical image analysis and the dispersion of efficient features in high-resolution medical images. As for the inadequacy of labeled data in medical image analysis, the reasons mainly include the followings: 1) the high-quality annotation of medical imaging sample depends heavily on scarce medical expertise which is very expensive and 2) comparing with natural issues, it is more difficult to collect medical images because of privacy issues. It is of great significance to apply deep-learning techniques for diabetic retinopathy (DR) recognition. In this article, the multichannel generative adversarial network (GAN) with semisupervision is developed for DR-aided diagnosis. The proposed model can deal with DR classification problem with inadequacy of labeled data in the following ways: 1) the multichannel generative scheme is proposed to generate a series of subfundus images corresponding to the scattering DR features and 2) the proposed multichannel-based GAN (MGAN) model with semisupervision can make full use of both labeled data and unlabeled data. The experimental results demonstrate that the proposed model outperforms the other representative models in terms of accuracy, area under ROC curve (AUC), sensitivity, and specificity.",Computer-aided diagnosis (CAD);diabetic retinopathy (DR);generative adversarial network (GAN);multichannel;semisupervised learning
 Conferences,S. Cahoon; M. Shaban; A. Switala; A. Mahmoud; A. El-Baz,Diabetic Retinopathy Screening Using A Two-Stage Deep Convolutional Neural Network Trained on An Extremely Un-Balanced Dataset,IEEE,2022,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9764079,"Diabetes is a chronic condition characterized by elevated high sugar levels in blood. One of the serious complications of the disease is Diabetic Retinopathy (DR), where the minute retinal blood vessels are blocked causing several symptoms ranging from blurred vision to vision loss. Early diagnosis and detection are crucial to control the symptoms and possibly delay the progression of the disease. Fundus photography is a cheap and accurate diagnosis modality used by ophthalmologists. However, fundus photography datasets suffer an extreme imbalance among different classes of DR. In this paper, we introduce a two-stage Deep Convolutional Neural Network (DCNN) architecture that is able to successfully categorize DR into one of 3 groups (i.e. controls, moderate DR, and severe DR) using a fine-tuned ResNet-50. Furthermore, a fine-tuned ResNet-18 was used to further classify moderate DR and a fine-tuned ResNet-50 was deployed to classify severe DR. The proposed architecture utilizes a preprocessing stage with image resizing and data augmentation included. Training and 5-fold cross validation were executed on the Kaggle APTOS 2019 dataset of 3,648 fundus images for 10 epochs. The proposed architecture achieved a 5-fold cross validation accuracy of 91% in the first stage, 90%, and 80% in the second sub-stages outperforming the-state-of-the-art architectures.",Diabetic Retinopathy;Early Diagnosis;Fundus Photography;Convolutional Neural Networks
 Conferences,M. Di Giammarco; G. Iadarola; F. Martinelli; F. Mercaldo; A. Santone,Explainable Retinopathy Diagnosis and Localisation by means of Class Activation Mapping,IEEE,2022,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9891978,"Diabetic retinopathy is a disease afflicting the retina and currently is manually diagnosed by specialists through eye tomography inspection. In order to assist the clinician in this time-consuming task, in this paper, we propose a method aimed to automatically diagnose the (proliferative and non-proliferative) diabetic retinopathy by exploiting deep learning. Furthermore, we investigate the possibility to automatically localise the areas related to the disease by exploiting class activation maps. We evaluate different deep learning models from a quantitative point of view (i.e, using metrics like accuracy, precision and recall) and a qualitative point of view (by exploiting class activation maps and image similarity metrics) with the aim to understand the quality of predictions performed by a model in retinopathy diagnosis, reducing the amount of knowledge required to assess the model performance. From the experimental analysis is emerging that deep learning shows an interesting diagnostic potential in the retinopathy disease localisation and can effectively help the clinician in retinopathy diagnosis. Moreover, the adoption of the class activation maps and its comparison evaluation can help the developers to debug the training step of the model without medical expertise.",retinopathy;deep learning;transfer learning;classification;diagnosis
 Conferences,M. T. Rahman; A. Dola,Automated Grading of Diabetic Retinopathy using DenseNet-169 Architecture,IEEE,2021,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9733431,"Diabetic retinopathy (DR), a severe eye disease, is a diabetes complication, and one of the world’s leading causes of blindness. Early diagnosis of DR may enable timely treatment and prevent permanent vision loss. DR has five stages of severity, namely-no DR, mild, moderate, severe and proliferative. Retinal fundus images are widely used for DR diagnosis. For the task of an early diagnosis of DR from color fundus images in an automated way we propose the use of DenseNet-169 model, a pre-trained convolutional neural network (CNN). In this study we used the publicly available Kaggle APTOS 2019 Blindness Detection dataset. In order to achieve an adequate classification performance, hype-parameter tuning, and data augmentation techniques are used. The model was also compared with two other pre-trained models DenseNet-121 and ResNet-50. Our proposed method achieved a classification accuracy of 96.54%, sensitivity and specificity of 96.23% and 99.21%, respectively, on the test set.",Diabetic Retinopathy;Convolutional Neural Network;Color Fundus Images;DenseNet
 Conferences,S. M. Skariah; K. S. Arun,A Deep Learning Based Approach for Automated Diabetic Retinopathy Detection and Grading,IEEE,2021,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9487759,"Diabetic Retinopathy (DR) is an incurable eye disorder, caused due to prolonged diabetes mellitus and it leads to blindness on the go. As an effect, the veins in retina get impaired. Due to the lack of efficient automated DR screening systems, the diagnosis of DR and its grading are now performed by retinal experts. This paper proposes a technique intended for the automatic identification and grading of DR with more exact outcomes in contrast to the existing strategies. To this end, we adopted the ideas of transfer learning and ensemble learning. The pre-trained models used for DR identification are Xception, InceptionV3,and InceptionResnetV2 and that for grading purpose are ResNet-50, DenseNet-201, and DenseNet-169. IDRiD database is used to evaluate the proposed model. The accuracy obtained by the proposed model is 99.5% for DR identification and 99.6% for its grading.",diabetic retinopathy;deep neural networks;transfer learning;stacking
 Conferences,S. H. Kassani; P. H. Kassani; R. Khazaeinezhad; M. J. Wesolowski; K. A. Schneider; R. Deters,Diabetic Retinopathy Classification Using a Modified Xception Architecture,IEEE,2019,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9001846,"Diabetic retinopathy (DR) is one of the major causes of blindness worldwide. With proper treatment, early diagnosis of DR can prevent the progression of the disease. In this paper, we present a new feature extraction method using a modified Xception architecture for the diagnosis of DR disease. The proposed method is based on deep layer aggregation that combines multilevel features from different convolutional layers of Xception architecture. The extracted features are subsequently fed into a multi-layer perceptron (MLP) to be trained for DR severity classification. The performance of the proposed approach was assessed with four deep feature extractors, including Inception V3,MobileNet, and ResNet50 and original Xception architecture. Compared with typical Xception architecture, the aggregation of deep CNN layers can effectively fuse deep features and improve the learning process. Additionally, a transfer learning strategy and hyper-parameter tuning are adopted to further improve the overall classification performance. The performance of the proposed model was validated on the Kaggle APTOS 2019 contest dataset. Experiments demonstrate that the modified Xception deep feature extractor improves DR classification with a classification accuracy of 83.09% versus 79.59%, sensitivity of 88.24% versus 82.35% and specificity of 87.00% versus 86.32% when compared with the original Xception architecture.",Computer-aided diagnosis;Convolutional neural network;Deep learning;Diabetic retinopathy;Transfer learning
 Conferences,S. S. A. Alves; A. G. Matos; J. S. Almeida; C. A. Benevides; C. C. H. Cunha; R. V. C. Santiago; R. F. Pereira; P. P. Reboucas Filho,A New Strategy for the Detection of Diabetic Retinopathy using a Smartphone App and Machine Learning Methods Embedded on Cloud Computer,IEEE,2020,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9183361,"Diabetes is a major cause of blindness, kidney failure, heart attacks, stroke and lower limb amputation according to World Health Organization (WHO). Complications from poor diabetes management lead to the Diabetic Retinopathy (DR) which is a leading cause of acquired blindness in the working-age population worldwide. WHO estimated that DR accounts for ≈ 15-17% of all cases of total blindness in the US and Europe, 7% of all cases in China and Mongolia. In Brazil, according to the Ministry of Health, the disease affects 7.6% of the population. A cost saving intervention includes screening and treatment for retinopathy. Detecting the different lesions related to DR plays an important role towards the stage detection, prediction, and prevention. Our challenge here is to design a deep learning neural network able to fully detect such lesions in digital retinal fundus image to help building robust and scaled solutions to tackle this urgent diabetes scenario. These results show that the Diavision Portable device had a better performance using GLCM, LBP and SVM, presenting 100% for both evaluation metrics considered. Using Messidor dataset were obtained better performance with VGG16 and SVM, archiving 100% for all metrics. In terms of feature extraction time, the GLCM and VGG16 presented acceptable times, respectively, 17.63ms and 37.87ms.","Diabetic, Retinopathy, Deep Features, Machine Learning, Computer aided diagnosis, Color Fundus Photographs"
 Conferences,M. T. Hagos; S. Kant; S. A. Bala,Automated Smartphone Based System for Diagnosis of Diabetic Retinopathy,IEEE,2019,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8974492,"Early diagnosis of diabetic retinopathy for the treatment of the disease has been failing to reach diabetic people living in rural areas. The shortage of trained ophthalmologists, limited availability of healthcare centers, and expensiveness of diagnostic equipment are among the reasons. Although many deep learning-based automatic diagnosis of diabetic retinopathy techniques have been implemented in the literature, these methods still fail to provide a point-of-care diagnosis, and this raises the need for an independent diagnostic of diabetic retinopathy that can be used by a non-expert. Recently the usage of smartphones has been increasing across the world; automated diagnoses of diabetic retinopathy can be deployed on smartphones in order to provide an instant diagnosis to diabetic people residing in remote areas. In this paper, inception based convolutional neural network and binary decision tree-based ensemble of classifiers have been proposed and implemented to detect and classify diabetic retinopathy. The proposed method was imported to a smartphone application for further classification, which provides an easy and automatic system for diagnosis of diabetic retinopathy.",Diabetic Retinopathy;Inception Module;Smartphone Based Diagnosis;Convolutional Neural Network
 Conferences,R. Venkatesan; P. Chandakkar; B. Li; H. K. Li,Classification of diabetic retinopathy images using multi-class multiple-instance learning based on color correlogram features,IEEE,2012,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6346216,"All people with diabetes have the risk of developing diabetic retinopathy (DR), a vision-threatening complication. Early detection and timely treatment can reduce the occurrence of blindness due to DR. Computer-aided diagnosis has the potential benefit of improving the accuracy and speed in DR detection. This study is concerned with automatic classification of images with microaneurysm (MA) and neovascularization (NV), two important DR clinical findings. Together with normal images, this presents a 3-class classification problem. We propose a modified color auto-correlogram feature (AutoCC) with low dimensionality that is spectrally tuned towards DR images. Recognizing the fact that the images with or without MA or NV are generally different only in small, localized regions, we propose to employ a multi-class, multiple-instance learning framework for performing the classification task using the proposed feature. Extensive experiments including comparison with a few state-of-art image classification approaches have been performed and the results suggest that the proposed approach is promising as it outperforms other methods by a large margin.",Not Found
 Conferences,L. Tian; L. Ma; Z. Wen; S. Xie; Y. Xu,Learning Discriminative Representations for Fine-Grained Diabetic Retinopathy Grading,IEEE,2021,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9533344,"Diabetic retinopathy is one of the leading causes of blindness. However, no specific symptoms of early DR lead to a delayed diagnosis, which results in disease progression in patients. To determine the disease severity levels, ophthalmologists need to focus on the discriminative parts of the retinal images. In recent years, deep learning has achieved great success in medical image analysis. However, most works directly employ algorithms based on convolutional neural networks (CNNs), which ignore the fact that the difference among classes is subtle and gradual. Hence, we consider automatic image grading of DR as a fine-grained classification task, and construct a bilinear model to identify the pathologically discriminative areas. In order to leverage the ordinal information among classes, we put the soft labels with ordinal information among classes into the loss function rather than the most commonly used one-hot labels for the diabetic retinopathy classification. In addition, other than only using a categorical loss to train our network, we also introduce the metric loss to learn a more discriminative feature space which is beneficial to locate the finer discriminative lesion parts. Experimental results demonstrate the superior performance of the proposed method on publicly available IDRiD, DeepDRiD and FGADR datasets.",Diabetic retinopathy;fine-grained classification;ordinal regression;metric learning
 Conferences,M. F. Wahid; A. B. M. Aowlad Hossain,Classification of Diabetic Retinopathy from OCT Images using Deep Convolutional Neural Network with BiLSTM and SVM,IEEE,2021,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9579901,"Diabetic retinopathy (DR) is an eye disease that, if not diagnosed at an early stage, can cause vision loss and blindness in diabetic patients. Therefore, in the field of ophthalmology, optical coherence tomography (OCT) imaging is widely used in the early diagnosis and treatment of DR. However, it is arduous and time consuming to manually classify and detect DR from retinal OCT image. In this context, this paper proposed a deep convolutional neural network combined with Bidirectional long-short term memory and support vector machine (CNN-BiLSTM+SVM) for automatic DR classification from OCT image. Here, CNN-BiLSTM architecture is used as feature extractor where CNN extracts the local features and BiLSTM learns correlation among the extracted features. SVM is subsequently trained to diagnose diabetic retinopathy using the extracted features. The effectiveness of the proposed model is assessed on blind test dataset of 1000 images (250 per class) labeled into four classes. The proposed model has attained satisfactory results in the classification of diabetic retinopathy, with an accuracy of 99.30%, which also proves its competitiveness in comparison to other existing state-of-the-art.",Diabetic Retinopathy;Retinal OCT image;Deep Neural Convolutional Network;Feature Extraction;Biomedical Image Processing
 Conferences,D. Doshi; A. Shenoy; D. Sidhpura; P. Gharpure,Diabetic retinopathy detection using deep convolutional neural networks,IEEE,2016,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7914977,"Diabetic retinopathy is when damage occurs to the retina due to diabetes, which affects up to 80 percent of all patients who have had diabetes for 10 years or more. The expertise and equipment required are often lacking in areas where diabetic retinopathy detection is most needed. Most of the work in the field of diabetic retinopathy has been based on disease detection or manual extraction of features, but this paper aims at automatic diagnosis of the disease into its different stages using deep learning. This paper presents the design and implementation of GPU accelerated deep convolutional neural networks to automatically diagnose and thereby classify high-resolution retinal images into 5 stages of the disease based on severity. The single model accuracy of the convolutional neural networks presented in this paper is 0.386 on a quadratic weighted kappa metric and ensembling of three such similar models resulted in a score of 0.3996.",Diabetic Retinopathy;Computer vision;Deep learning;Convolutional Neural Networks;Quadratic weighted kappa metric
 Conferences,S. Gupta; A. Panwar; A. Kapruwan; N. Chaube; M. Chauhan,Real Time Analysis of Diabetic Retinopathy Lesions by Employing Deep Learning and Machine Learning Algorithms using Color Fundus Data,IEEE,2022,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9744228,"Diabetes is a rapidly spreading illness that has devastating consequences on human organs such as kidney, lungs, heart, eyes, etc. Diabetic Retinopathy (DR) is a condition caused by abiding diabetes that damages small vessels carrying blood and tissues in the eyes. The condition is characterized by the creation of inflated formations in the retinal region known as Micro-aneurysms, which if ignored can result in irreversible damage to the eye's blood vessels, eventually leading to blindness. In the early stages of the disease, such clinical manifestations do not appear. As a result, regular and timely checkups are foremost important. However, manual identification of diabetic retinopathy is time intensive and prone to human mistake. In the stated research, the color fundus dataset scans after processing are passed to multiple Deep Learning (DL) models employed to learn characteristics. These models trained on millions of different images from thousands of classes. Finally, several machine learning classifiers were used to classify lesions using the collected characteristics. The extracted result shows very eye catching performance. This enables experts to create architecture that fully address the problem of classifying unidentified scans into the right class or category.",Diabetes;Image classification;Random forest
 Journals,F. Saeed; M. Hussain; H. A. Aboalsamh,Automatic Diabetic Retinopathy Diagnosis Using Adaptive Fine-Tuned Convolutional Neural Network,IEEE,2021,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9374414,"Diabetic retinopathy (DR) is a complication of diabetes that leads to blindness. The manual screening of color fundus images to detect DR at early stages is expensive and time consuming. Deep learning (DL) techniques have been employed for automatic DR screening on fundus images due to their outstanding performance in many applications. However, training a DL model needs a huge amount of data, which are usually unavailable in the case of DR, and overfitting is unavoidable. Employing a two-stage transfer learning method, we developed herein an intelligent computer-aided system using a pre-trained convolutional neural network (CNN) for automatic DR screening on fundus images. A CNN model learns the domain-specific hierarchy of low- to high-level features. Given this, using the regions of interest (ROIs) of lesions extracted from the annotated fundus images, the first layer of a pre-trained CNN model is re-initialized. The model is then fine-tuned, such that the low-level layers learn the local structures of the lesion and normal regions. As the fully connected layer (FC) layers encode high-level features, which are global in nature and domain specific, we replace them with a new FC layer based on the principal component analysis PCA and use it in an unsupervised manner to extract discriminate features from the fundus images. This step reduces the model complexity, significantly avoiding the overfitting problem. This step also lets the model adopt the fundus image structures, making it suitable for DR feature detection. Finally, we add a gradient boosting-based classification layer. The evaluation of the proposed system using a 10-fold cross-validation on two challenging datasets (i.e., EyePACS and Messidor) indicates that it outperforms state-of-the-art methods. It will be useful for the initial screening of DR patients and will help graders in deciding quickly as regards patient referral to an ophthalmologist for further diagnosis and treatment.",Fundus images;diabetic retinopathy;classification;CNN
 Conferences,V. Liu; M. Y. Shalaginov; R. Liao; T. H. Zeng,A Deep Convolutional Neural Network For Diagnosis of Diabetic Retinopathy,IEEE,2022,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9994995,"Diabetic Retinopathy (DR) diagnosis is a time consuming and complex task, in addition to requiring experienced doctors. In this study, an advanced Convolution Neural Network (CNN) and data augmentation were successfully used to predict the stages of diabetic retinopathy. Specifically, we modified and trained this network with the publicly available Kaggle dataset and obtained promising results. On the validation of 1452 images using this classifier, an accuracy of 82%, average sensitivity of 80% over the three categories and average specificity of 91% over the three categories could be achieved, indicating the feasibility of our CCN model for the identification of different stages of the diabetic retinopathy. It implies the great potential of this artificial intelligent method for the diagnosis of diabetic retinopathy, especially for the early diagnosis for patients in the future.",convolutional neural network (CNN);Diabetic Retinopathy;image classification;diabetes;deep learning
 Conferences,A. C. Metan; A. Lambert; M. Pickering,Small Scale Feature Propagation Using Deep Residual Learning for Diabetic Retinopathy Classification,IEEE,2019,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8981096,"Automated diagnosis of diabetic retinopathy from fundus images involves detecting both small- and large-scale lesions, which makes this a difficult task for deep learning applications. In this paper we investigate the effects of small scale feature propagation for improving diabetic retinopathy classification. To accomplish this, we have utilized a publicly available dataset with 88,702 images, which contains unbalanced number of examples for different classes. A linear equation for class-specific gradient weighting has been proposed and has found to be beneficial. Three different residual architectures with residual and skip connections have been tested and their efficacy for this task is examined. The residual connections have been verified to improve the results for detecting small scale features for deep architectures. Skip connections within the current experimental setting have been found to be detrimental for the overall performance, potential solutions and their resulting effects have been discussed.",convolutional neural networks;small scale features;residual networks;diabetic retinopathy;fundus photography
 Conferences,U. B. Mahadevaswamy; H. T,Adaptive Prediction and Classification of Diabetic Retinopathy Using Machine Learning,IEEE,2022,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9972593,"Diabetic Retinopathy (DR) is a eye deformity causes due to chronic diabetes, and it is the root cause condition. Diabetic retinopathy does not display the early symptoms because internal bleeding may occur in the retina triggered by microaneurysms (MA) leading to the major reason for blindness earlier the age of 50. The medical images obtained using the diagnostic machines helps in accurate diagnosis and precise delivery of the treatment. Image Processing has a significance disease detection on medical images. The disease recognizing and classifying approaches are specific in human organs and image type. One of such a disease classes includes detecting of retinal disease such as diabetic detection. The objective of proposed project is to develop an algorithm which analyses the disease pattern and accurate diagnosis of disease. The convolution neural network is exploited for deep learning and retina images are classified into few categories using SVM. The algorithm used a total of 35,925 images obtained from Iweid. The proposed model achieves Accuracy of 97% which are better compared to existing work.",Diabetic retinopathy;feature selection;classification;machine learning;Image Processing
 Conferences,L. Yung-Hui; Y. Nai-Ning; K. Purwandari; L. Nabila Harfiya,Clinically Applicable Deep Learning for Diagnosis of Diabetic Retinopathy,IEEE,2019,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9049631,"Diabetic retinopathy (DR) is the kind of diabetes complication that affects eyes and can damage the blood vessels inside the retina. To diagnose the strength of DR disease based on examination of the retina. Nowadays, the common diagnosis process asks for experienced ophthalmologists to inspect both fundus image and OCT (optical coherence tomography) images, which is time-consuming and not very convenient for remote rural inhabitants. The research purpose in this paper is to propose a new paradigm of automatic DR diagnosis by using artificial intelligence and cloud computing. Inside the DCNN, we changed max-pooling layers with factional max-pooling. We trained using support vector machine (SVM) to learn the underlying boundary of distribution of each category. Using that proposed method, we achieved the results of the recognition up to 86.17%. We also develop an iPhone APP. It called 'Deep Retina' that equipped with a handheld ophthalmoscope, a layman can take fundus images and perform the diagnosis automatically without intervention from ophthalmologists. It is a practically applicable telemedicine system which benefits the home care, remote medical care, and self-examination.",Diabetic Retinopathy;deep learning;CNN;SVM;TLBO
 Conferences,R. N. Lazuardi; N. Abiwinanda; T. H. Suryawan; M. Hanif; A. Handayani,Automatic Diabetic Retinopathy Classification with EfficientNet,IEEE,2020,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9293941,"Using the recent known EfficientNet architecture of deep convolutional neural network (CNN), we present an automatic detection of diabetic retinopathy (DR) from given retinal images. We experiment with subsets of the Kaggle diabetic retinopathy dataset consisting of retinal images with varied diagnostic quality. To address the quality variation, we incorporate two preprocessing steps, i.e. contrast limited adaptive histogram equalization (CLAHE) and image central cropping. We trained EfficientNet-B4 and EfficientNet-B5 model on two Kaggle subsets with different class proportions. In this paper, we propose an automatic early diagnosis of diabetic retinopathy which gained 0.7922 / 83.87% and 0.7931 / 83.89% of quadratic weight kappa and accuracy score on EfficientNet-B4 and EfficientNet-B5 respectively.",Classification Task;Deep Learning;Diabetic Retinopathy;Progressive Resizing
 Conferences,V. K. B; S. M; T. Parekh; A. Sharma,A Multi-Stage Deep Transfer Learning Method for Classification of Diabetic Retinopathy in Retinal images,IEEE,2021,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9532991,"Diabetic Retinopathy (DR) is one among the most dangerous complications of polygenic disease, and if it is untreated, it can result in permanent disability. Early detection is critical for clinical progress and it is one of the most difficult challenges. Unfortunately, determining the stage of DR is prominently difficult as well as this calls for skillful rendition from humans on the structural images of body. The significance in simplifying this process of detecting cannot be overstated. Convolutional neural networks have been effectually used in a various fields, as well as in the detection of $D$ R. However, the increasing expense of huge labelled datasets and also variability among physicians, who are completely different block the effectiveness of these strategies. In this perspective, this research work has proposed a deep learning-based automated technique for DR stage classification and detection by utilizing sole photography of the fundus in human retina. Further, the proposed research work has suggested a multi-stage deep transfer learning technique that uses equivalent datasets for including labeling, which is completely different. The methodology suggested by this research work can be utilized as a screening method employed for early diagnosis of DR with a sensitivity and specificity of 0.99 as well as a quadratic weighted kappa grade at 0.925466 of blindness detection dataset.",Deep learning;quadratic weighted kappa(QWK);DR;test-time augmentation(TTA);convolutional neural network;ordinal regression;multi-target learning;classification
 Journals,J. Hu; H. Wang; L. Wang; Y. Lu,Graph Adversarial Transfer Learning for Diabetic Retinopathy Classification,IEEE,2022,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9943294,"Diabetic retinopathy (DR) is an essential factor that has caused vision loss and even blindness in middle-aged and older adults. A system that can automatically perform DR diagnosis can help ophthalmologists save a lot of tedious work, such as DR grading or lesion detection. At the same time, patients can find their diseases earlier and perform the correct treatment. However, most of the existing methods require many DR annotations to train the model, and the DR data will vary to different degrees due to various shooting tools. The above problems lead to the inefficient use of existing data in the experiment, limiting actual deployment. To alleviate this problem, we propose a novel Graph Adversarial Transfer Learning (GATL) for DR diagnosis in a deep model through transfer learning, including intra-domain alignment and inter-domain alignment. The proposed GATL enjoys several merits. First, our GATL adopts the self-supervised training to save the annotating cost in the target domain thus this domain adaptation method can significantly reduce annotation cost compared to the supervised approaches. Second, we introduce the graph neural network to extract potential features between unknown samples. Third, to enhance the robustness of the model, we use adversarial training to perform both inter-domain and intra-domain alignment to further improve the model’s classification accuracy. GATL achieved 94.3%, 97.5%, and 91.1% in accuracy, sensitivity, and specificity in the APTOS dataset and 92.7%, 95.7%, and 89.7% in the EyePACS dataset, respectively. Extensive experimental results on two challenging benchmarks, including APTOS 2019 and EyePACS, demonstrate that the proposed GATL performs favorably against baseline DR classification methods.",Diabetic retinopathy classification;graph adversarial network;transfer learning;intra-domain;inter-domain
 Conferences,H. A. Nugroho; E. L. Frannita,Intelligent Diabetic Retinopathy Detection using Deep Learning,IEEE,2021,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9702859,"Diabetic retinopathy (DR) is the most common illness related to diabetes caused by the increasing of glucose in human blood and has been dramatically increased in the last decade. Practically, DR is examined by conducting manual analysis on retina images resulted from fundus camera modality in which can lead to some problems such as time-consuming, need more thoroughness and properly skill and experience. Due to the insufficient number of ophthalmologists, especially in rural areas, an alternative solution in supporting diagnosis properly is needed. Regarding to those issues, some research communities have proposed intelligent system for detecting DR. Despite some previous intelligent DR detection have been developed, there still remained problem that quality of image was extremely affect the performance. Hence, in this study we proposed an intelligent DR detection completed with image enhancement process for maintaining the model performance. Our proposed solution was performed in 200 retina images consisting of two classes (normal and abnormal or DR). Our proposed solution successfully increased the performance with the highest accuracy, sensitivity, specificity, positive predictive value, and negative predictive value of 0.92, 0.95, 0.81, 0.95, 0.81, respectively. This result has increased by around of 40% in most of evaluation metrics of the model's performance without an image enhancement process. It indicates that conducting image enhancement process before training the model was important to increase the model performance and to prevent the miss-detection.",Diabetes;diabetic retinopathy;deep learning;image enhancement
 Conferences,N. Jiwani; K. Gupta; N. Afreen,A Convolutional Neural Network Approach for Diabetic Retinopathy Classification,IEEE,2022,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9787577,"Diabetic Retinopathy (DR) is a kind of problem which affects diabetic patients, particularly those at their age of working, and can result in vision impairment and possibly irreversible blindness. For diagnosis and to prevent blindness or degeneration, early detection is critical. When ophthalmologists execute the diagnosis step of DR manually, it takes more time, effort, and money, and there are more possibility of misdiagnosis. The scientific community is focusing on developing a computer-aided recognition system for early identification and grading of DR severity. Ongoing AI research has highlighted the growth of the deep learning technique, which is better technique for doing medical image analysis and classification.",Convolutional Neural Network;Deep Learning;Diabetic Retinopathy;IDRiD dataset
 Conferences,C. W. Dong; D. Xia; J. Jin; Z. Yang,Classification of diabetic retinopathy based on DSIRNet,IEEE,2019,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8845497,"The rapid development of deep learning in recent years has achieved great success in the fields of speech recognition, image recognition and natural language processing. At present, the automatic diagnosis of medical images is the focus of attention from all walks of life, and deep learning technology has shown good application prospects in this respect. In response to the screening of diabetic retinopathy, this paper proposes a deep supervision of the Inception-Residual network(DSIRNet) to classify DR images end-to-end. The network combines the advantages of Inception module and residual module, which can not only learn multi-scale features, but also ensure the transmission of feature information between network layers. At the same time, this paper also uses deep monitoring method to assist the training network, which can improve thermal classification effect of the network to a certain extent. In terms of data sets, data noise and sample distribution imbalances are also addressed. The effectiveness of the proposed model and method is verified by comparative experiments.",Deep learning;convolutional neural network;image processing;diabetic retinopathy
 Conferences,A. G. A. Padmanabha; M. A. Appaji; M. Prasad; H. Lu; S. Joshi,Classification of diabetic retinopathy using textural features in retinal color fundus image,IEEE,2017,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8258754,"Early, diagnosis is essential for diabetic patients to avoid partial or complete blindness. This work presents a new analysis method of texture features for classification of Diabetic Retinopathy (DR). The proposed method masks the blood vessels and optic disk segmented and directly extracts the textural features from the remaining retinal region. The proposed method is much simpler with comparison of the other methods that detect the defective regions first and then extract the required features for classification. The Haralick texture measures calculated are used for classification of DR. The proposed method is evaluated through a classification of DR using both Support Vector Machine (SVM) and Artificial Neural Network (ANN). The results of SVM have a better accuracy (87.5%) over ANN (79%). The performance of the proposed method is presented also in terms of sensitivity and specificity.",Diabetic retinopathy;Texture features;Hard exudates;Hemorrhages;Micro aneurysms;Soft exudates
 Conferences,N. Goel; S. K. Singh,Diabetic Retinopathy Image Analysis Using Deep Learning Techniques,IEEE,2022,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9986469,"In the whole world, one among the leading factors of blindness in the citizens is the diabetic retinopathy (DR). Detection of DR at an early stage can provide crucial assistance in managing with this disease. Deep learning (DL) has excelled in a variety of domains, particularly in the analysis of biomedical images. The diagnosis of DR is made by scanning retinal fundus images. We have done an empirical evaluation for the automatic detection of DR as part of our research. Convolutional Neural Networks (CNN) approach has been used in this research by using two of its architectures i.e. MobileNetV2 and DenseNet-201. For this research work, we have utilized the Indian Diabetic Retinopathy Dataset (IDRID) dataset, which is an online dataset available containing retinal fundus images of size 4288×2848. The outcomes of this research work shows that the DenseNet-201 model detects DR better than MobileNetV2 with the following metrics: accuracy, recall, precision and fl-score of 87.6%, 97.2%, 82.6%, and 88.4%, respectively are the most dependable findings from the DenseNet-201 model's case testing.",Fundus Image;Deep Learning;Diabetic Retinopathy;MobileNetV2;DenseNet201
 Journals,Z. Liu; C. Wang; X. Cai; H. Jiang; J. Wang,Discrimination of Diabetic Retinopathy From Optical Coherence Tomography Angiography Images Using Machine Learning Methods,IEEE,2021,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9344690,"The goal was to discriminate between diabetic retinopathy (DR) and healthy controls (HC) by evaluating Optical coherence tomography angiography (OCTA) images from  $3\times 3$  mm scans with the assistance of different machine learning models. The OCTA angiography dataset of superficial vascular plexus (SVP), deep vascular plexus (DVP), and retinal vascular network (RVN) were acquired from 19 DR (38 eyes) patients and 25 HC (44 eyes). A discrete wavelet transform was applied to extract texture features from each image. Four machine learning models, including logistic regression (LR), logistic regression regularized with the elastic net penalty (LR-EN), support vector machine (SVM), and the gradient boosting tree named XGBoost, were used to classify wavelet features between groups. The area under the receiver operating characteristics curve (AUC), sensitivity, specificity, and diagnostic accuracy of the classifiers were obtained. The OCTA image dataset included 114 and 132 images from DR and HC subjects, respectively. LR-EN and LR using all three images, SVP, DVP, and RVN, provided the highest sensitivity of 0.84 and specificity of 0.80, the best diagnostic accuracy of 0.82, and an AUC of 0.83 and 0.84, respectively, which were slightly lower than that of LR using one image SVP (0.85) or two images DVP and SVP (0.85). The LR-EN and LR classification algorithms had the high sensitivity, specificity, and diagnostic accuracy in identifying DR, which may be promising in facilitating the early diagnosis of DR.",Diabetic retinopathy;machine learning;logistic regression;logistic regression regularized with the elastic net penalty;support vector machine
 Conferences,M. A. Omar; M. A. Tahir; F. Khelifi,Multi-label learning model for improving retinal image classification in diabetic retinopathy,IEEE,2017,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8102591,"Retinal image analysis may disclose severity and causes of many diabetic diseases e.g. for Diabetic Macular Edema inspection. Many techniques have been introduced for automatic classification of exudate lesion to speed up the diagnosis of diabetic disease. In almost all previous work, exudate lesion detection is either modelled as binary or multiclass classification problem. However, along with the classification of normal / abnormal regions, other information needs to be simultaneously classified such as patient's age, ethnicity, race, diabetic's type etc. In this work, we presented a new technique, namely Multi-label learning model to improve the classification of exudate lesions. Features are extracted using multi-scale local binary patterns. Multi label k nearest neighbour (ML-kNN), Multi-label Ranking Support Vector Machine Learning (ML-Rank SVM), Multi-label Learning Neural Network Radial Base Function (MLNN-RBF) and Multi-label Learning Neural Network Back-Propagation (MLNN-BP) are evaluated as the classification models and compared with traditional binary multi-class classifiers. Experiment results show that multi-label framework is very useful for diabetic retinopathy differentiation and can improve retinal image classification.",Diabetic Macular Edema;Multi-Label Learning;Diabetic Retinopathy;kNN classifier
 Conferences,K. Zhou; Z. Gu; W. Liu; W. Luo; J. Cheng; S. Gao; J. Liu,Multi-Cell Multi-Task Convolutional Neural Networks for Diabetic Retinopathy Grading,IEEE,2018,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8512828,"Diabetic Retinopathy (DR) is a non-negligible eye disease among patients with Diabetes Mellitus, and automatic retinal image analysis algorithm for the DR screening is in high demand. Considering the resolution of retinal image is very high, where small pathological tissues can be detected only with large resolution image and large local receptive field are required to identify those late stage disease, but directly training a neural network with very deep architecture and high resolution image is both time computational expensive and difficult because of gradient vanishing/exploding problem, we propose a Multi-Cell architecture which gradually increases the depth of deep neural network and the resolution of input image, which both boosts the training time but also improves the classification accuracy. Further, considering the different stages of DR actually progress gradually, which means the labels of different stages are related. To considering the relationships of images with different stages, we propose a Multi-Task learning strategy which predicts the label with both classification and regression. Experimental results on the Kaggle dataset show that our method achieves a Kappa of 0.841 on test set which is the 4th rank of all state-of-the-arts methods. Further, our Multi-Cell Multi-Task Convolutional Neural Networks (M2CNN) solution is a general framework, which can be readily integrated with many other deep neural network architectures.",Deep Learning;Multi-Cell Architecture;MultiTask Learning;Medical Image;Diabetic Retinopathy.
 Conferences,C. Lyona; J. Menezes; T. Shinde; M. Gavhane; R. M. Rohatgi; S. Chavan,Classification of retinal images in stages of diabetic retinopathy using deep learning,IEEE,2020,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9362913,"Diabetic retinopathy (DR) is an advanced stage of retinal disease with increasing prevalence and the major cause of blindness. In DR, blood vessels get damaged over time at the back of the retina. Large numbers of retinal images are generated as diabetes patients all over the world and it is increasing every year. This increases the workload of ophthalmologists which may result in delayed diagnosis and treatment. In this paper, automatic classification of normal eye and DR eye using convolutional neural network (CNN) is presented. This computerized system also further classifies DR eye in one of the four stages as Microaneurysms, Hemorrhages, Hard Exudates, and Soft Exudates (Cotton Wool Spots). The framework is trained and validated on 413 images and tested on 187 images of IDRiD database with 98.930% average classification accuracy. The system also achieves average 97.316% of sensitivity and 99.338% of specificity. This system will assist ophthalmologists to screen retinal images for abnormality from a large database within reduced time span which may leads to timely treatment to the patient.",Diabetic retinopathy;severity of diabetic retinopathy;classification of retinal images;convolutional neural network
 Conferences,V. K. R. Poranki; B. S. Rao,Performance Evaluation of AI Assisted Automotive Diabetic Retinopathy Classification Systems,IEEE,2022,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10009256,"The reliable diagnosis of diabetic retinopathy (DR) has long been a source of concern for researchers. Due to fluctuating glucose levels, the blood vessels in the retina are more vulnerable to aberrant metabolism. These variances result in lesions or retinal damage, which are then referred to as DR collectively. The signs of DR are often difficult for the current eye healthcare procedures to diagnose. Building an artificial intelligence-assisted automated DR classification (AI-ADRC) system is an excellent way to reduce the pressure of incorrect diagnoses as a result. This article is focused on performance evaluation of DR classification methods, which includes machine learning models, deep learning models, feature extraction, and feature selection methods. The problems presented in state-of-art AI-ADRC systems are addressed, which will help to develop the novel AI-ADRC model. Further, the deep learning-based AI-ADRC models are resulted in superior performance as compared to machine learning based AI-ADRC models using various datasets.",Color eye fundus images;Diabetic retinopathy;Artificial intelligence;IDRiD dataset;Feature extraction;Feature selection
 Conferences,D. A. Hasan; S. R. M. Zeebaree; M. A. M. Sadeeq; H. M. Shukur; R. R. Zebari; A. H. Alkhayyat,Machine Learning-based Diabetic Retinopathy Early Detection and Classification Systems- A Survey,IEEE,2021,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9509920,"Diabetes Mellitus is a chronic disease that spreads quickly worldwide. It results from increasing the blood glucose level and causes complications in the heart, kidney, and eyes. Diabetic Retinopathy (DR) is an eye disease that refers to the bursting of blood vessels in the retina as Diabetes exacerbates. It is considered the main reason for blindness because it appears without showing any symptoms in the primitive stages. Earlier detection and classification of DR cases is a crucial step toward providing the necessary medical treatment. Recently, machine learning plays an efficient role in medical applications and computer-aided diagnosis due to the accelerated development in its algorithms. In this paper, we aim to study the performance of various machine learning algorithms-based DR detection and classification systems. These systems are trained and tested using massive amounts of retina fundus and thermal images from various publicly available datasets. These systems proved their success in tracking down the warning signs and identifying the DR severity level. The reviewed systems' results indicate that ResNet50 deep convolutional neural network was the most effective algorithm for performance metrics. The Resnet50 contains a set of feature extraction kernels that can analyze retina images to extract wealth information. We conclude that machine learning algorithms can support the physician in adopting appropriate diagnoses and treating DR cases.",Diabetic Retinopathy;Machine Learning;Classification;Regression;Clustering;CAD
 Conferences,Z. Tu; S. Gao; K. Zhou; X. Chen; H. Fu; Z. Gu; J. Cheng; Z. Yu; J. Liu,SUNet: A Lesion Regularized Model for Simultaneous Diabetic Retinopathy and Diabetic Macular Edema Grading,IEEE,2020,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9098673,"Diabetic retinopathy (DR), as a leading ocular disease, is often with a complication of diabetic macular edema (DME). However, most existing works only aim at DR grading but ignore the DME diagnosis, but doctors will do both tasks simultaneously. In this paper, motivated by the advantages of multi-task learning for image classification, and to mimic the behavior of clinicians in visual inspection for patients, we propose a feature Separation and Union Network (SUNet) for simultaneous DR and DME grading. Further, to improve the interpretability of the disease grading, a lesion regularizer is also imposed to regularize our network. Specifically, given an image, our SUNet first extracts a common feature for both DR and DME grading and lesion detection. Then a feature blending block is introduced which alternately uses feature separation and feature union for task-specific feature extraction, where feature separation learns task-specific features for lesion detection and DR and DME grading, and feature union aggregates features corresponding to lesion detection, DR and DME grading. In this way, we can distill the irrelevant features and leverage features of different but related tasks to improve the performance of each given task. Then the task-specific features of the same task at different feature separation steps are concatenated for the prediction of each task. Extensive experiments on the very challenging IDRiD dataset demonstrate that our SUNet significantly outperforms existing methods for both DR and DME grading.",Multi-disease diagnosis;Lesion regularization;Feature blending
 Conferences,A. M. Pamadi; A. Ravishankar; P. Anu Nithya; G. Jahnavi; S. Kathavate,Diabetic Retinopathy Detection using MobileNetV2 Architecture,IEEE,2022,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9761289,"The disease Diabetic Retinopathy (DR) is a microvascular diabetic condition that affects the eyes. It is attributed to the impairment of the retinal blood vessels. The later it is detected, the greater the likelihood that the patient will lose sight. This paper proposes two Convolutional Neural Network (CNN) models, one of them a binary classification to detect retinopathy and another multinomial classification model to further classify retinopathy into five distinct and widely used stages - None, Mild, Moderate, Severe and Proliferative DR. Using Gaussian filtered fundus images enhances the recognition of subtle features such as edges or spots used for diagnosis. Transfer learning on a pre-trained MobileNetV2 model further enhances the accuracy to 78% for a multinomial classification and up to 97% for binomial classification.",Convolutional Neural Networks (CNN);Diabetic Retinopathy (DR);Deep Learning;MobileNetV2 Architecture;Gaussian;Dataset
 Conferences,R. S. Latha; G. R. Sreekanth; R. C. Suganthe; B. Bizu; K. Suvalakshmi; K. Venkatachalam,Diagnosis of Diabetic Retinopathy and Glaucoma from Retinal Images Using Deep Convolution Neural Network,IEEE,2022,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9740851,"Diabetic retinopathy and Glaucoma are major retinal diseases that are the primary sources of sightlessness in working-age people all over the universe. The diagnosis of Diabetic Retinopathy (DR) and Glaucoma through color retinal images necessitates trained professionals identifying the existence and importance of numerous small abnormalities, which is a challenging and time-consuming task due to a complex grading scale. Here we suggest a CNN approach for diagnosing Diabetic Retinopathy and Glaucoma and if provided any High - resolution fundus Image of the Retina and appropriately defining its severity, not having the same. Developed a network with Convolutional Neural Network architecture and done data augmenting that can determine the complex aspects that are implicated in the classification, such as micro aneurysms, retinal haemorrhages, and exudates. For DR, the Kaggle dataset is used, and for Glaucoma, the RIGA dataset is used. Kaggle dataset is used as an input for DR which consists of 3658 images that are classified into 5 different classes and RIGA dataset is used as an input for Glaucoma containing 2-class labels of Glaucoma with 1103 images are analyzed. Obtained good predictive accuracy of 98%, the precision of 97.6%, recall of 96%, and an F-measure of 97% an automated system, for instance, can quickly distinguish between healthy and infected retinal images, minimizing the number of clinician reviews.",Diabetic retinopathy classification;Glaucoma classification;Convolutional Neural Network;Retinal images;Deep learning
 Journals,T. Liu; Y. Chen; H. Shen; R. Zhou; M. Zhang; T. Liu; J. Liu,A Novel Diabetic Retinopathy Detection Approach Based on Deep Symmetric Convolutional Neural Network,IEEE,2021,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9628123,"Diabetic Retinopathy (DR) may lead to blindness in diabetic patients, which is one of the most severe eye diseases. Therefore, using automatical technology to detect DR at the early phase has very vital clinical significance. In order to detect the microaneurysms (MAs) and hard exudates (HEs) of DR, a novel detection method based on deep symmetric convolutional neural network is proposed in this paper. The symmetric convolutional structure is used to improve the effectiveness of feature extraction. The proposed method also can overcome the imbalance of positive and negative samples to avoid overfitting by increasing the width and depth of the network. Furthermore, different network structures (convolution, pooling) are used to achieve different feature filtering in the stage of feature extractions. According to the experimental results, the proposed method is superior to the state-of-the-art approach on the public dataset DIARETDB1 (DB1). The detection accuracy of the objects is 92.0%, 93.2%, 93.6%, when using different filtering structures (convolution, max-pooling, ave-pooling) respectively. The detection of microaneurysms is much improved by using ave-pooling layer for feature filtering, and the max-pooling layer can improve the detection of hard exudates.",Diabetic retinopathy;hard exudates;microaneurysms;symmetric convolution neural network
 Conferences,K. V. Spoorthi; B. S. Rekha,Diabetic Retinopathy Prediction using Deep learning,IEEE,2021,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9683553,"Diabetic retinopathy(DR) is a problem in diabetic patients and one of the leading cause of blindness affecting the majority of people around the world. It can cause blindness if not diagnosed early. Due to the diversity and complexity of DR, identifying DR through tedious manual diagnosis is extremely difficult. Therefore, this paper focuses on classifying a certain set of fundus images into 4 stages using deep learning approach as a combination of Deep Convolutional Neural Networks (DCNN) and RNN-LSTM (RNN=Recurrent Neural Network, LSTM = Long Short-Term Memory). This approach automatically detects all the stages of DR. This combination extracts many features of fundus image. In total, approximately 2000 fundus images were used to form the combined model. This study demonstrates that the extraction of those features from fundus images using DCNN and RNN-LSTM has significantly improved the accuracy predicting the DR stages.",DCNN;RNN;DR;LSTM;NPDR;PDR
 Conferences,A. K. Al-Bashir; A. N. A. Obeid,Automatic Discrimination between Normal and Diabetic Retinopathy Fundus Images using Machine Learning Classification Algorithm,IEEE,2022,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9887502,"Diabetic retinopathy (DR) is a retinal disorder of the human eye caused by a complication of diabetes. It causes gradual damage to the eye’s retina, which can eventually lead to loss of vision. Early diagnosis of retinopathy is necessary for timely recovery of eyesight and to prevent complete blindness. In clinical routine, highly qualified specialists analyze the colored fundus images of each diabetic patient for the diagnosis of this disease. However, DR is not easily recognizable, particularly in the early stages, and even experienced experts may find such manual diagnostic procedures challenging, time-consuming, and error-prone. The goal of this study is to develop a robust automated system for classifying a given set of fundus images as normal or with DR symptoms, which would improve the performance of existing approaches. This work comprises three main stages: image preprocessing, feature extraction, and different supervised learning models for classification. A total of 65 features from each fundus image have been extracted and used as neural network (ANN) and support vector machine (SVM) inputs for the classification. Whereas high-level features are extracted from the ‘fully connected’ layer of a Residual Convolutional Neural Network (ResNet50) transfer learning model and utilized as the input feature vector for SVM classification. Based on the obtained findings, it can be indicated that the three approaches have successfully classified the images, but the latter has achieved the best classification accuracy of up to 98.38%. The results showed that these techniques for the classification of retinal fundoscopic images are fairly accurate.",Diabetic retinopathy;retinal fundoscopic image;artificial neural network;SVM;CNN;transfer learning
 Conferences,V. Alvionita; M. Nuh; N. F. Hikmah,Data Balancing Techniques Evaluation on Convolutional Neural Network to Classify The Diabetic Retinopathy of Fundus Image,IEEE,2020,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9297940,"Diabetic retinopathy (DR) is a common complication diabetic patients that causes impaired vision, and may even lead to blindness. Several studies on the DR diagnosis based on Computer-aided Diagnosis (CAD) had been conducted. The method used various feature extraction modules and a particular classifier. However, this method required a long step. In a different circumstance, deep neural networks had been successfully applied in various fields and showing good performance. For this reason, we proposed a classification system for DR based on Convolutional Neural Networks (CNN). In this study, we used retina images dataset from the Asia-Pacific Tele-Ophthalmology Society (APTOS) to train CNN under three different conditions. Sequentially is imbalanced, balanced by undersampling, and balanced by oversampling. The best results were obtained in the third condition, with an accuracy of 73.64%, precision 59.01%, sensitivity 60.69%, and specificity 93.49%. The classification method in the proposed study should be realized in clinical use.",convolutional neural network;diabetic retinopathy;image classification
 Conferences,N. O. Aljehane,An Intelligent Moth Flame Optimization with Inception Network for Diabetic Retinopathy Detection and Grading,IEEE,2022,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9711602,"Diabetic Retinopathy (DR) is a widespread illness among diabetic patients that creates lesions on the retina affecting vision. When the DR is not identified in the earlier stage, the vision can be severely affected. Since the manual detection of DR using fundus images by ophthalmologists is time consuming, expensive, and not accurate, deep learning (DL) models have become a popular tool to detect and classify DR at the beginning stages. With this motivation, this paper designs an intelligent moth flame optimization with Inception network-based DR detection and grading (IMFO-INDR) model. The goal of the IMFO-INDR model is to detect the existence of lesions in the fundus image and assign proper class labels to it. The IMFO-INDR model involves histogram-based segmentation to determine the affected lesion areas in the fundus images. In addition, Inception v4 model is applied as feature extraction and the hyperparameters involved in it are optimally tuned by the use of MFO algorithm. At last, softmax classifier is used for the allocation of class labels to the input fundus images based on the extracted feature vectors. The experimental validation of the IMFO-INDR model takes place using the MESSIDOR database and the results are examined in terms of several aspects. The resultant values demonstrate the promising performance of the IMFO-INDR model over the existing DR diagnosis models.",Diabetic Retinopathy;Computer vision;Image processing;Deep learning;Image classification;MESSIDOR database
 Conferences,Q. Chen; X. Sun; N. Zhang; Y. Cao; B. Liu,Mini Lesions Detection on Diabetic Retinopathy Images via Large Scale CNN Features,IEEE,2019,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8995281,"Diabetic retinopathy (DR) is a diabetes complication that affects eyes. DR is a primary cause of blindness in working-age people and it is estimated that 3 to 4 million people with diabetes are blinded by DR every year worldwide. Early diagnosis have been considered an effective way to mitigate such problem. The ultimate goal of our research is to develop novel machine learning techniques to analyze the DR images generated by the fundus camera for automatically DR diagnosis. In this paper, we focus on identifying small lesions on DR fundus images. The results from our analysis, which include the lesion category and their exact locations in the image, can be used to facilitate the determination of DR severity (indicated by DR stages). Different from traditional object detection for natural images, lesion detection for fundus images have unique challenges. Specifically, the size of a lesion instance is usually very small, compared with the original resolution of the fundus images, making them diffcult to be detected. We analyze the lesion-vs-image scale carefully and propose a large-size feature pyramid network (LFPN) to preserve more image details for mini lesion instance detection. Our method includes an effective region proposal strategy to increase the sensitivity. The experimental results show that our proposed method is superior to the original feature pyramid network (FPN) method and Faster RCNN.",diabetic retinopathy;mini lesion detection;FPN
 Journals,M. M. Farag; M. Fouad; A. T. Abdel-Hamid,Automatic Severity Classification of Diabetic Retinopathy Based on DenseNet and Convolutional Block Attention Module,IEEE,2022,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9750054,"Diabetic Retinopathy (DR) - a complication developed due to heightened blood glucose levels- is deemed one of the most sight-threatening diseases. Unfortunately, DR screening is manually acquired by an ophthalmologist, a process that can be considered erroneous and time-consuming. Accordingly, automated DR diagnostics have become a focus of research in recent years due to the tremendous increase in diabetic patients. Moreover, the recent accomplishments demonstrated by Convolutional Neural Networks (CNN) settle them as state-of-the-art for DR stage identification. This paper proposes a new automatic deep-learning-based approach for severity detection by utilizing a single Color Fundus photograph (CFP). The proposed technique employs DenseNet169’s encoder to construct a visual embedding. Furthermore, Convolutional Block Attention Module (CBAM) is introduced on top of the encoder to reinforce its discriminative power. Finally, the model is trained using cross-entropy loss on the Kaggle Asia Pacific Tele-Ophthalmology Society’s (APTOS) dataset. On the binary classification task, we accomplished (97% accuracy - 97% sensitivity - 98.3% specificity - 0.9455, Quadratic Weighted Kappa score (QWK)) compared to the state-of-the-art. Moreover, Our network showed high competency (82% accuracy - 0.888 (QWK)) for severity grading. The significant contribution of the proposed framework is that it efficiently grades the severity level of diabetic retinopathy while reducing the time and space complexity required, which demonstrates it as a promising candidate for autonomous diagnosis.",Diabetic retinopathy;convolutional neural networks (CNN);attention mechanism;deep learning
 Conferences,Z. Baharlouei; H. Rabbani; G. Plonka,Detection of Retinal Abnormalities in OCT Images Using Wavelet Scattering Network,IEEE,2022,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9871989,"Diagnosis retinal abnormalities in Optical Coherence Tomography (OCT) images assist ophthalmologist in the early detection and treatment of patients. To do this, different Computer Aided Diagnosis (CAD) methods based on machine learning and deep learning algorithms have been proposed. In this paper, wavelet scattering network is used to identify normal retina and four pathologies namely, Central Serous Retinopathy (CSR), Macular Hole (MH), Age-related Macular Degeneration (AMD) and Diabetic Retinopathy (DR). Wavelet scattering network is a particular convolutional network which is formed from cascading wavelet transform with nonlinear modulus and averaging operators. This transform generates sparse, translation invariant and deformation stable representations of signals. Filters in the layers of this network are predefined wavelets and not need to be learned which causes decreasing the processing time and complexity. The extracted features are fed to a Principal Component Analysis (PCA) classifier. The results of this research show the accuracy of 97.4% and 100% in diagnosis abnormal retina and DR from normal ones, respectively. We also achieved the accuracy of 84.2% in classifying OCT images to five classes of normal, CSR, MH, AMD and DR which outperforms other state of the art methods with high computational complexity. Clinical Relevance- Clinically, the manually checking of each OCT B-scan by ophthalmologists is tedious and time consuming and may lead to an erroneous decision specially for multiclass problems. In this study, a low complexity CAD system for retinal OCT image classification based on wavelet scattering network is introduced which can be learned by a small number of data.",Not Found
 Conferences,T. Subha; N. Susila; R. Ranjana; V. Priya; V. Nithyashree,Analysis of Diabetic Retinopathy and Its Causes Using Fuzzy C-Means Model,IEEE,2021,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9711840,"Diabetes Mellitus, commonly known as Diabetes, is a caused due to high range of sugar in the human body. After a period of time diabetes will lead to a deficiency in eye called as Diabetes Retinopathy. The major symptoms of this disorder are bulging of blood vessels, small lesions and other eye related eyes. The idea of our project is to analyze the severity level of the diabetes retinopathy using three different training methods. Deep learning plays a major role in the project. Proposed Model has been trained with three types, back propagation NN, deep neural networks called DNN and convolutional neural network known as CNN. The Deep Learning models created by using the above neural networks are able to measure the features such as micro aneurysms, blood vessels, fluid drip into different class of categories and hemorrhages. Model will find out the value or level of infection in the patient's eye. Fuzzy C- means algorithm are particularly used to calculate severity of the infection caused and the type of infection also. By this paper, severity of the Retinopathy can be found. The entire system has a user-friendly environment which makes the identification easy. Once the test image is uploaded, the interface will have buttons in order to do the necessary transformation on the given image. At the end of the complete interface options, the level of the infection along with the narrowed down area of infection will be seen in the interface.",CNN;DNN;Diabetic Retinopathy;fuzzy c- means;Human body;Infection;Mellitus
 Conferences,N. Z. Abidin; A. Ritahani Ismail,Federated Deep Learning for Automated Detection of Diabetic Retinopathy,IEEE,2022,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10010636,"Diabetic retinopathy (DR) is a primary cause of impaired vision that can lead to permanent blindness if not detected and treated early. Unfortunately, DR frequently has no early warning signs and may not generate any symptoms. According to recent figures, over 382 million people worldwide suffer from DR, with the number expected to climb to 592 million by 2030. Patients with DR may not be treated in time given the apparent large number of DR patients and inadequate medical resources in specific places, resulting in missed treatment possibilities and eventually irreversible vision loss. Color fundus diagnosis requires highly experienced experts to recognize the existence of tiny features and the relevance of DR. Unfortunately, manually diagnosing DR is time-consuming, tedious and error-prone. At the same time, the effect of manual interpretation is highly dependent on the medical expert experiences. Deep learning is a machine learning algorithm with potential for detecting the significance of DR. However, deep learning still suffers from high computational cost, requires tons of training data, over fitting, and non-trivial hyper parameter tuning. Thus, in order to build a model that can compete with medical experts, deep learning algorithms must feed a huge number of instances or pool data from other institutions. Federated learning allows deep learning algorithms to learn from a diverse set of data stored in multiple databases. Federated learning is a novel method for training deep learning models on local DR patient data, with just model parameters exchanged between medical facilities. The objectives of this research is to avoid the requirement sharing DR patient data, since such approaches expedite the development of deep learning models through the use of federated learning. Primarily, we propose a federated learning which decentralizes deep learning by eliminating the need to pool data in a single location. In this research, we present a practical method for the federated learning of deep network based on retinal image of diabetic retinopathy.",federated learning;deep learning;automated detection;diabetic retinopathy
 Journals,S. Huang; J. Li; Y. Xiao; N. Shen; T. Xu,RTNet: Relation Transformer Network for Diabetic Retinopathy Multi-Lesion Segmentation,IEEE,2022,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9684442,"Automatic diabetic retinopathy (DR) lesions segmentation makes great sense of assisting ophthalmologists in diagnosis. Although many researches have been conducted on this task, most prior works paid too much attention to the designs of networks instead of considering the pathological association for lesions. Through investigating the pathogenic causes of DR lesions in advance, we found that certain lesions are closed to specific vessels and present relative patterns to each other. Motivated by the observation, we propose a relation transformer block (RTB) to incorporate attention mechanisms at two main levels: a self-attention transformer exploits global dependencies among lesion features, while a cross-attention transformer allows interactions between lesion and vessel features by integrating valuable vascular information to alleviate ambiguity in lesion detection caused by complex fundus structures. In addition, to capture the small lesion patterns first, we propose a global transformer block (GTB) which preserves detailed information in deep network. By integrating the above blocks of dual-branches, our network segments the four kinds of lesions simultaneously. Comprehensive experiments on IDRiD and DDR datasets well demonstrate the superiority of our approach, which achieves competitive performance compared to state-of-the-arts.",Diabetic retinopathy;fundus image;semantic segmentation;transformer;deep learning
 Conferences,S. Patel; M. Lohakare; S. Prajapati; S. Singh; N. Patel,DiaRet: A Browser-Based Application for the Grading of Diabetic Retinopathy with Integrated Gradients,IEEE,2021,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9507938,"Patients with long-standing diabetes often fall prey to Diabetic Retinopathy (DR) resulting in changes in the retina of the human eye, which may lead to loss of vision in extreme cases. The aim of this study is two-fold: (a) create deep learning models that were trained to grade degraded retinal fundus images and (b) to create a browser-based application that will aid in diagnostic procedures by highlighting the key features of the fundus image. In this research work, we have emulated the images plagued by distortions by degrading the images based on multiple different combinations of Light Transmission Disturbance, Image Blurring and insertion of Retinal Artifacts. InceptionV3, ResNet-50 and InceptionResNetV2 were trained and used to classify retinal fundus images based on their severity level and then further used in the creation of a browser-based application, which implements the Integration Gradient (IG) Attribution Mask on the input image and demonstrates the predictions made by the model and the probability associated with each class.",Diabetic Retinopathy;Deep Learning;Integrated Gradients;Computer-aided Diagnosis;Attention Mechanism;Explainable AI
 Conferences,A. Ghosh; A. B. M. Aowlad Hossain; S. M. Taslim Uddin Raju,Classification of Diabetic Retinopathy Using Few-Shot Transfer Learning from Imbalanced Data,IEEE,2021,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9442024,"Diabetic Retinopathy (DR) has no effective cure if it has reached the proliferative phase and blindness will most probably be cursed on patients ultimately. Good prognosis depends on early detection of DR and Glaucomatous. In this paper, three types of categorical data were fed into AlexNet and VGG16 models. Primarily mild disease was misclassified as the convolutional neural network struggles to distinguish delicate features of disease among normal and mild phase. To mitigate erroneous impact, various image preprocessing techniques such as otsu thresholding, global histogram equalization (GHE), contrast limited adaptive histogram equalization (CLAHE) etc. have been used for the recognition of subtle features lying in fundoscopic images. Pretrained architecture VGG16 model with no freezing of parameters achieved good fitting and accuracy over 3 ary classification of small balanced dataset. The AlexNet achieved better fitting over VGG16 for both 2 ary and 4 ary classification with an optimized learning rate with imbalanced dataset. The deeper VGG16 exploits deeper features from each class thus it faces biased effect from weightier class. Thus, VGG16 performs better over 3 ary dataset through deeper features exploitation. AlexNet model has achieved better results through batch-normalization and batch-wise training methods over a slightly imbalanced dataset.",Diabetic Retinopathy;Glaucomatous;CNN;Otsu Thresholding;CLAHE;GHE;AlexNet;VGG16;Fundo-scopic
 Journals,X. Wang; M. Xu; J. Zhang; L. Jiang; L. Li; M. He; N. Wang; H. Liu; Z. Wang,Joint Learning of Multi-Level Tasks for Diabetic Retinopathy Grading on Low-Resolution Fundus Images,IEEE,2022,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9573274,"Diabetic retinopathy (DR) is a leading cause of permanent blindness among the working-age people. Automatic DR grading can help ophthalmologists make timely treatment for patients. However, the existing grading methods are usually trained with high resolution (HR) fundus images, such that the grading performance decreases a lot given low resolution (LR) images, which are common in clinic. In this paper, we mainly focus on DR grading with LR fundus images. According to our analysis on the DR task, we find that: 1) image super-resolution (ISR) can boost the performance of both DR grading and lesion segmentation; 2) the lesion segmentation regions of fundus images are highly consistent with pathological regions for DR grading. Based on our findings, we propose a convolutional neural network (CNN)-based method for joint learning of multi-level tasks for DR grading, called DeepMT-DR, which can simultaneously handle the low-level task of ISR, the mid-level task of lesion segmentation and the high-level task of disease severity classification on LR fundus images. Moreover, a novel task-aware loss is developed to encourage ISR to focus on the pathological regions for its subsequent tasks: lesion segmentation and DR grading. Extensive experimental results show that our DeepMT-DR method significantly outperforms other state-of-the-art methods for DR grading over three datasets. In addition, our method achieves comparable performance in two auxiliary tasks of ISR and lesion segmentation.",Deep neural networks;diabetic retinopathy;multi-task learning;retinal fundus images
 Journals,B. Yang; T. Li; H. Xie; Y. Liao; Y. -P. P. Chen,Classification of Diabetic Retinopathy Severity Based on GCA Attention Mechanism,IEEE,2022,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9664550,"Diabetic retinopathy (DR) is one of the major complications caused by diabetes and can lead to severe vision loss or even complete blindness if not diagnosed and treated in a timely manner. In this paper, a new feature map global channel attention mechanism (GCA) is proposed to solve the problem of the early detection of DR. In the GCA module, an adaptive one-dimensional convolution kernel size algorithm based on the dimension of the feature map is proposed and a deep convolutional neural network model for DR color medical image severity diagnosis named GCA-EfficientNet (GENet) is designed. The training process uses transfer learning techniques with a cosine annealing learning rate adjustment strategy. The image regions of interest of GENet are visualized using a heat map. The final accuracy, precision, sensitivity and specificity of the DR dataset of the Kaggle competition reached 0.956, 0.956, 0.956, and 0.989, respectively. A large number of experiment results show that GENet based on the GCA attention mechanism can more effectively extract lesion features and classify the severity of DR.",Attention mechanism;convolutional neural network;deep learning;diabetic retinopathy;medical images
 Conferences,N. Ramya; D. Hemavathi,Detection Of Diabetic Retinal Pathogen Using Deep Learning,IEEE,2022,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9915991,"With Numerous changes in the current lifestyle of people, diabetes has become one of the most commonly occurring chronic diseases that lead to many other problems in the body in the long run. Most diabetic patients have the common problem of vision reduction, and joint pain and severe diabetic patients have liver problems, kidney problems, etc. Many pathological and clinical features are required to treat diabetics at a constant interval to maintain the limit and monitor the health of other organs. Diabetic Retinopathy is diabetic retinal pathogen that, if left untreated, might cause lifelong blindness. Diabetic Retinopathy disorder affects 60 % to 70 % of diabetic people with a prolonged diagnosis. Henceforth study of Diabetic Retinopathy and its impacts on diabetic patients is important. On the other hand studies of available methodologies to predict disease in early-stage are considered. The present study focused on a detailed evaluation and analysis of Diabetic Retinopathy with various existing methodologies, treatment procedures, algorithms, and research data available so far and to formulate a prediction model that could help the early prediction of Diabetic Retinopathy.",Diabetic Retinopathy (DR);Segmentation;Generative Adversarial Networks (GAN);Deep Learning(DL);Convolutional Neural Network (CNN);transfer learning
 Conferences,J. Ni; Q. Chen; C. Liu; H. Wang; Y. Cao; B. Liu,An Effective CNN Approach for Diabetic Retinopathy Stage Classification with Dual Inputs and Selective Data Sampling,IEEE,2019,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8999152,"Diabetic retinopathy (DR) is a vision-threatening complication among the diabetic population and a leading cause of blindness for working-age adults. Early detection and timely treatment can reduce the occurrence of blindness due to DR. Computer-aided diagnosis have great potential to significantly improve the accuracy and speed in DR detection over the traditional manual diagnosis process. In this paper, we present a deep convolutional neural network for DR stage classification, trained and evaluated on a large dataset. Our model uses high-resolution retinal fundus images of both the left and right eyes as inputs to take advantage of more detailed retinal lesion information in images and strong correlation between both eyes. Selective data sampling (SeS) is applied in the training process to mitigate the data imbalance problem. Experiments show that our model outperforms the fine-tuned Inception-v3 model by every measure, achieving an accuracy of 87.2% and a Kappa score of 0.806 on the Kaggle dataset.",convolutional neural networks;image classification;deep learning
 Journals,Y. Sun,The Neural Network of One-Dimensional Convolution-An Example of the Diagnosis of Diabetic Retinopathy,IEEE,2019,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8715401,"Diabetes is a serious threat to health development, because diabetes is a disease that caused most other diseases (complications). Diabetic retinopathy is the most important manifestation of diabetic microangiopathy and is also one of the most common complications in people with diabetes. At present, the diagnosis of diabetic retinal complications mainly depends on the pictures for diagnosis. The fundus images are the main ways to diagnose retinal diseases at present, but the diagnosis process is complicated. Based on this, this paper uses the electronic medical record information of 301 hospitalized patients with diabetes from 2009 to 2013, mainly using the diabetes diagnostic data, diabetes glycosylation data and diabetes biochemical test data, the depth of learning methods and medical diabetes combined with the application of convolution Neural Network Method (CNN) to build a diagnostic model, and thus draw the diagnosis. The main contribution of this study is twofold: 1) In this paper, we apply the CNN method to one-dimensional unrelated data sets and solve the problem of how to do one-dimensional irrelevant data convolution. 2) In this paper, the CNN model is combined with the BN layer to prevent the dispersion of the gradient, speed up the training speed and improve the accuracy of the model. In addition, this model incorporates an adaptive learning rate algorithm and optimizes the model. The experiments show that this method can achieve a training accuracy of 99.85% and a testing accuracy of 97.56%, which is more than 2% higher than that of using logistic regression. The model methods involved in this study can not only be used for the diagnosis of diabetic retinopathy, but also for the diagnosis of other diseases, such as chronic kidney disease, cardiovascular, and cerebrovascular diseases.",Diabetic mellitus;retinopathy;convolutional neural network;batch normalization;adaptive learning rate
 Conferences,S. Mohammadian; A. Karsaz; Y. M. Roshan,Comparative Study of Fine-Tuning of Pre-Trained Convolutional Neural Networks for Diabetic Retinopathy Screening,IEEE,2017,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8430269,"Diabetic retinopathy is the leading cause of blindness, engaging people in different ages. Early detection of the disease, although significantly important to control and cure it, is usually being overlooked due to the need for experienced examination. To this end, automatic diabetic retinopathy diagnostic methods are proposed to facilitate the examination process and act as the physician's helper. In this paper, automatic diagnosis of diabetic retinopathy using pre-trained convolutional neural networks is studied. Pre-trained networks are chosen to avoid the time-and resource-consuming training algorithms for designing a convolutional neural network from scratch. Each neural network is fine-tuned with the pre-processed dataset, and the fine-tuning parameters as well as the pre-trained neural networks are compared together. The result of this paper, introduces a fast approach to fine-tune pre-trained networks, by studying different tuning parameters and their effect on the overall system performance due to the specific application of diabetic retinopathy screening.",Diabetic retinopathy;convolutional neural network;deep learning;Inception model
 Journals,Y. Sun; D. Zhang,Diagnosis and Analysis of Diabetic Retinopathy Based on Electronic Health Records,IEEE,2019,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8721113,"Diabetic retinopathy (DR) is an important disease leading to blindness in humans, attracting a lot of research interests. Previous breakthrough research findings rely on deep learning techniques to diagnose diabetic retinopathy in patients with medical imaging. Although the medical imaging achieves reasonable recognition accuracy, the application of mass, easy-to-obtain and free electronic health records (EHR) data in life can make an early diagnosis of the DR more convenient and quick. In this paper, we used a set of five machine learning models to diagnose the DR in patients with the EHR data and formed a set of treatment methods. Our experimental data set is formed by processing the data provided by 301 hospitals. The experimental results show that random forest (RF) in the machine learning model can get 92% accuracy with good performance. Subsequently, the input features were analyzed and their importance graded to find that the predisposing factors triggering the human DR disease were associated with renal and liver function. In addition, disease diagnosis methods based on readily available the EHR data will become an integral part of smart healthcare and mobile healthcare.",Diabetic retinopathy;disease diagnosis;electronic medical records;machine learning;mobile medical
 Conferences,S. B. Nandeeswar; J. AlameluMangai,Comparison of Key Performance Metrics of Ensemble Learning Algorithms for Diagnosis of Diabetic Retinopathy,IEEE,2020,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9210299,"Around the world, Blindness in diabetic patients are seen commonly because of Diabetic Retinopathy (DR). Sadly, the suggested annual testing of the diabetic patients' eye fundus is too complicated or not a regular manner. It is needed to provide information for the doctors about critical patients who would need regular checkup and others who can be considered as low risk and can be screened after considerable time. This paper explores various performance factors from most popular and leading ensemble algorithms that play key role in classifying and grading diabetic retinopathy. Three ensemble algorithms most widely used in Medical-IT industry used for comparison here are Stacking algorithm, AdaBoost algorithm and XGBoost ensemble classifier. The experiment demonstrates how various performance factors used to compare each classifier helps in deciding about the kind of dataset to be used and also for selecting the attributes. This demonstration uses a reduced set of attributes obtained thru correlation based feature extraction (CFS) method in comparison with original dataset with all characteristics that constitute significant risk factors for deciding whether a patients who are at high risk of diabetic retinopathy. Comparison of specificity and sensitivity levels gained are provided for a deeper comprehension of the behaviors of different ensemble algorithms. This research is therefore a first productive step towards developing a customized system helping in making a good decision.",Ensemble algorithm;Retina fundus;eXtreme Gradient Boosting;AdaBoost;Boosting
 Conferences,K. K. Y. Tiong; W. K. Wong; F. H. Juwono; I. M. Chew,Diabetic Retinopathy Detection: Improving Accuracy Using Multiple Transfer Learning Features from Pre-trained Deep Learning Networks,IEEE,2022,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10010468,"Diabetic Retinopathy (DR) is a type of complications caused by diabetes. Patients with DR may experience worsening vision, blindness, and eye pain. To effectively address this disorder, DR must be identified and classified according to its severity. Therefore, automated diagnosis of fundus lesions is of great interest for DR early detection. The development of deep learning technology has provided a strong foundation for effective implementation of the automated detection system. In particular, transfer learning techniques have greatly benefited the research community to reduce computation and reuse trained features. In this paper, the outputs from the ”average pooling” and ”fully connected” layers are used as the features to the Support Vector Machine (SVM) classifier with Error Correction Output Code (ECOC). The proposed method outperforms the fine-tuned pre-trained networks in predicting the severity classes with an accuracy of 80.1%. This means that multiple features extracted from the pre-trained networks contribute to a better recognition process.",Diabetic Retinopathy;Convolution Neural Network;Feature Extraction
 Conferences,X. Xia; K. Zhan; Y. Li; G. Xiao; J. Yan; Z. Huang; G. Huang; Y. Fang,Eye Disease Diagnosis and Fundus Synthesis: A Large-Scale Dataset and Benchmark,IEEE,2022,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9949547,"As one of the most common imaging modalities, retinal fundus imaging offers images of interior surface of eyes for initial examination of disorders. Data-driven machine learning methods, especially deep learning models in recent years, provide automatic ophthalmological disease diagnosis techniques from color fundus images. Data with high quality, diversity and balanced distribution supports deep model-based eye disease diagnosis. However, many existing datasets focus on a specific kind of eye disease, and some suffer from label noise or quality degeneration, which hinders automatic screening algorithms from dealing with multiple eye diseases. To solve this, we propose a high-quality dataset containing 28877 color fundus images for deep learning-based diagnosis. Except for 15000 healthy samples, the dataset consists of 8 eye disorders including diabetic retinopathy, agerelated macular degeneration, glaucoma, pathological myopia, hypertension, retinal vein occlusion, LASIK spot and others. Based on this, we propose a co-attention network for disease diagnosis, establish benchmark on screening and grading tasks, and demonstrate that the proposed dataset supports generative adversarial network-based image synthesis. The dataset will be made publicly available.",dataset;eye disease diagnosis;fundus sythesis
 Conferences,E. AbdelMaksoud; S. Barakat; M. Elmogy,Diabetic Retinopathy Grading Based on a Hybrid Deep Learning Model,IEEE,2020,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9325672,"Diabetic retinopathy (DR) is a dangerous disease that may cause blindness suddenly without any indications. Therefore, it is necessary to continuously screen and audit the disease progress from the early to severe stages. By nature, the color fundus image may facilitate many lesion types that lead to diagnosing different DR grade. In this respect, deep learning achieved great success in medical image analysis, especially in multi-label (ML) classification. In this paper, we present a novel hybrid, deep learning technique for diagnosing different DR grades, which is called the E-DenseNet model. The proposed technique is a hybrid model of the EyeNet and DenseNet using transfer learning. We got benefits from combining the two models as we customized the EyeNet and embedded dense blocks. The proposed computer-aided diagnosis (CAD) system with E-DenseNet can diagnose different DR grades (normal, mild, moderate, severe, and proliferative DR (PDR)) from various ML color fundus images accurately with minimal training time and memory space. The proposed CAD system gives promising results in diagnosing different DR grades from two benchmark datasets. The proposed system achieved an average accuracy (ACC) equals 91.6%, the Dice similarity coefficient (DSC) equals 92.45%, and the Kappa score equals 0.883.",Not Found
 Conferences,C. Santos; M. Aguiar; D. Welfer; B. Belloni,A New Method Based on Deep Learning to Detect Lesions in Retinal Images using YOLOv5,IEEE,2021,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9669581,"Diabetic Retinopathy is one of the leading causes of vision loss and presents in its initial phase retinal lesions, such as microaneurysms, hemorrhages, and hard and soft exudates. Therefore, computational models capable of detecting these lesions can help in the early diagnosis of the disease and prevent the manifestation of more severe forms of lesions, helping define the best form of treatment. This work proposes a method based on deep neural network models that perform one-stage object detection, using state-of-the-art data augmentation and transfer learning techniques to present a model that aids in the medical diagnosis of fundus lesions. The model was trained, adjusted, and evaluated using the DDR Diabetic Retinopathy Dataset, and implemented based on the YOLOv5 architecture and the PyTorch framework, achieving values for mAP of 0.1040 and 0.0283 for IoU threshold of 0.5 and 0.5:0.95 respectively, in the validation set. The results obtained in the experiments demonstrate that the proposed method presented superior results to equivalent works found in the literature.",diabetic retinopathy;fundus image;you only look once;lesion detection
 Conferences,B. Sriman; N. Muangnak; C. Sirawattananon,Automated Clinical Assessment in Diabetic Retinopathy Retinal Images: A Review,IEEE,2022,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9836245,"There are no early symptoms associated with retinal diseases. Diabetic retinopathy (DR) is the leading cause of macular degeneration in people with diabetes in their 40s and 50s. It is a critical step in determining the stage of an ophthalmology preliminary abnormality diagnosis. DR lesions detected on images taken with the hospital's high-quality imaging equipment can now be screened and identified automatically by an image processing system. It is proposed to screen for early symptoms of DR by detecting abnormalities within retinal images using computer-based imaging. The purpose of this study is to conduct a review of existing works in the fields of artificial intelligence and image processing to develop an algorithm for an automatic DR screening system. A review paper on the use of deep learning with DR detection was introduced, as well as a section experimenting with DR in retinal fundus images from publicly available datasets. To enhance DR detection performance, feature extraction techniques would be suggested.",retinal image processing;diabetic retinopathy detection;machine learning;deep learning
 Journals,E. Abdelmaksoud; S. El-Sappagh; S. Barakat; T. Abuhmed; M. Elmogy,Automatic Diabetic Retinopathy Grading System Based on Detecting Multiple Retinal Lesions,IEEE,2021,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9328438,"Multi-label classification (MLC) is considered an essential research subject in the computer vision field, principally in medical image analysis. For this merit, we derive benefits from MLC to diagnose multiple grades of diabetic retinopathy (DR) from various colored fundus images, especially from multi-label (ML) datasets. Therefore, ophthalmologists can detect early signs of DR as well as various grades to initiate appropriate treatment and avoid DR complications. In this paper, we propose a comprehensive ML computer-aided diagnosis (CAD) system based on deep learning technique. The proposed system's main contribution is to detect and analyze various pathological changes accompanying DR development in the retina without injecting the patient with dye or making expensive scans. The proposed ML-CAD system visualizes the different pathological changes and diagnoses the DR grades for the ophthalmologists. First, we eliminate noise, enhance quality, and standardize the sizes of the retinal images. Second, we differentiated between the healthy and DR cases by calculating the gray level run length matrix average in four different directions. The system automatically extracts the four changes: exudates, microaneurysms, hemorrhages, and blood vessels by utilizing a deep learning technique (U-Net). Next, we extract six features, which are the gray level co-occurrence matrix, areas of the four segmenting pathology variations, and the bifurcation points count of the blood vessels. Finally, the resulting features were afforded to an ML support vector machine (SVM) based on a classifier chain to differentiate the various DR grades. We utilized eight benchmark datasets (four of them are considered ML) and six different performance evaluation metrics to evaluate the proposed system's performance. It achieved 95.1%, 91.9%, 86.1%, 86.8%, 84.7%, 86.2% for accuracy, area under the curve, sensitivity, specificity, positive predictive value, and dice similarity coefficient, respectively. The experiments show encouraging results as compared with other systems.",Multi-label computer-aided diagnosis (ML-CAD);multi-label classification (MLC);deep learning (DL);U-Net;diabetic retinopathy (DR)
 Conferences,S. Gupta; A. Panwar; S. Goel; A. Mittal; R. Nijhawan; A. K. Singh,Classification of Lesions in Retinal Fundus Images for Diabetic Retinopathy Using Transfer Learning,IEEE,2019,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9031884,"Diabetic Retinopathy (DR) is an eye disorder that affects the small blood vessels in the retina and is featured by the presence of different types of lesions in the affected area. If an early prognostication of DR is not done, then it may lead to loss of vision. Some of the diagnosing tools for detection of DR are Indirect Ophthalmoscope, Slit Lamp Examination, Color Photograph, and Optical Coherence Tomography (OCT). The DR dataset contains 5 types of lesions ranging from mild to severe. These lesions are hard to distinguish from each other. The manual diagnosis of DR involves the proper classification of these lesions into their appropriate classes that is quite tedious and error-prone process marred with low level of accuracies. Researchers therefore rely on automatic detection and prognosis of DR based on Machine Learning (ML) methods. In this work, we propose a Deep Learning (DL) framework to classify these lesions with high level of accuracy. To accomplish the task, we train a DL model Visual Geometry Group (VGG19) on Indian Diabetic Retinopathy Image Dataset (IDRID) dataset to extract the features from the color fundus eye photography provided in the dataset. The extracted features are then fed into different classifiers such as Logistic Regression (LR), Support Vector Machine (SVM), K-Nearest Neighbors (KNN) etc. to classify the lesions properly. We thus show, that using DL along with Transfer Learning (TL) can classify the affected areas such as Microaneurysms (MA), Soft Exudates (SE), Hard Exudates (EX), and Hemorrhage (HE) of a DR eye with high accuracy.","Deep learning, Inception V3, VGG16, VGG19, SVM, Logistic Regression, KNN, Random Forest"
 Conferences,J. Mathias; S. Gadkari; M. Payapilly; A. Pansare,Categorization of Diabetic Retinopathy and Identification of Characteristics to Assist Effective Diagnosis,IEEE,2021,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9396908,"Diabetic Retinopathy is a condition caused as a result of damage to the blood vessels in the retina due to poor blood sugar control. Diabetes results in a gradual deterioration of the other organs firstly the retina thus causing adverse effects to vision. However, this damage can be prevented or treated if identified in its initial stages which is possible if monitored on a timely basis. The methodology proposed in this paper consists of two components: the classification component and the feature extraction component. The classification component deals with the utilization of transfer learning that includes a CNN model pre-trained on the ImageNet dataset retrained on the retinal dataset to develop a model that most effectively categorizes diabetic retinopathy based on the level of severity. The feature extraction component further extracts characteristics using appropriate image processing libraries. Such an easily accessible system is also capable of most effectively assisting the diagnosis of retinopathy especially in rural areas where instruments to detect such diseases are rarely available.",blood vessels;CNN;diabetes;diabetic retinopathy;exudates;ImageNet;microaneurysms;retina;transfer learning
 Conferences,I. Bidari; S. Chickerur; A. Kulkarni; A. Mahajan; A. Nikkam; A. THM,Deploying Machine Learning Inference on Diabetic Retinopathy in Binary and Multi-class Classification,IEEE,2021,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9726533,"Diabetic Retinopathy is a condition of the person's eye that causes vision loss and blindness in diabetic people. Among adults between 20–74 years, this disease most of the time acts as the cause of blindness. Also, it is the leading reason behind cecity among working-aged adults worldwide. An efficient health care system contributes to an essential part of the country's economy, development, and industrialization. It affects one out of three persons with diabetes. The longer a person has diabetes, the higher their risk of developing some ocular problem. The mobile and web application built adds assistance to the people for endorsing their qualms and knowing about their condition's severity. Since most of the users can be from rural areas, we built applications that work both offline and online. The inference is to select a configuration based on a single input. To decrease the magnitude of the mobile application model, we implemented MobileN et architecture. It is considered a light weightedmodel as it has fewer parameters than others, making it suitable for the application objective. The accuracy of MobileNet is 76 percent. ResNet 50 architecture is used in the web application, which requires an internet facility to predict the output. Because of the increase in the parameters, it provides higher accuracy when compared to the MobileN et model. Kaggle eyepacs dataset is given as input for both models. The dataset is divided into five classes: No Diabetic Retinopathy, mild, moderate, severe, and proliferative. The models classify the images given as input and display one of these class labels as a result. An oversampling technique has been implemented to overcome the problem of data bias. NodeJS and python have been used to build web applications and android studio for mobile applications. The time taken to display the result in both applications is less than 10 seconds. The size of the mobile application has been reduced from 120MB to 25 MB. This application is helpful in rural areas wherever they lack facilities to run tests while obtaining the results on their phones and any web browser by simply up- loading the scanned image of the patient's eye.",MobileNet;ResNet;Diabetic Retinopathy;Deep Learning Inference
 Conferences,P. Qian; Z. Zhao; C. Chen; Z. Zeng; X. Li,Two Eyes Are Better Than One: Exploiting Binocular Correlation for Diabetic Retinopathy Severity Grading,IEEE,2021,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9630812,"Diabetic retinopathy (DR) is one of the most common eye conditions among diabetic patients. However, vision loss occurs primarily in the late stages of DR, and the symptoms of visual impairment, ranging from mild to severe, can vary greatly, adding to the burden of diagnosis and treatment in clinical practice. Deep learning methods based on retinal images have achieved remarkable success in automatic DR grading, but most of them neglect that the presence of diabetes usually affects both eyes, and ophthalmologists usually compare both eyes concurrently for DR diagnosis, leaving correlations between left and right eyes unexploited. In this study, simulating the diagnostic process, we propose a two-stream binocular network to capture the subtle correlations between left and right eyes, in which, paired images of eyes are fed into two identical subnetworks separately during training. We design a contrastive grading loss to learn binocular correlation for five-class DR detection, which maximizes inter-class dissimilarity while minimizing the intra-class difference. Experimental results on the EyePACS dataset show the superiority of the proposed binocular model, outperforming monocular methods by a large margin.Clinical relevance— Compared to conventional DR grading methods based on monocular images, our approach can provide more accurate predictions and extract graphical patterns from retinal images of both eyes for clinical reference.",Not Found
 Conferences,S. S; K. T; S. Bhattacharjee; D. Shahwar; K. S. Sekhar Reddy,Quantum Transfer Learning for Diagnosis of Diabetic Retinopathy,IEEE,2022,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9744184,"India is on track to become the world’s diabetes capital thus demanding accurate diagnosis of Diabetic retinopathy from optical coherence tomography (OCT) retinal images. Accurate and faster diagnosis is difficult as it depends on quality of image, operator handling and also the growing number of patients. In this paper we propose the use of quantum transfer learning model to accomplish diagnosis of Diabetic Retinopathy. Quantum Transfer Learning (QTL), is a hybrid combination of classical transfer learning and quantum computing. Unlike classical computers, quantum computers provide faster computation and better accuracy. The concept of QTL is mainly used where the dataset size is limited. The QTL model, diagnostically significant image features are extracted with Resnet18 Convolutional Neural NEtwork (CNN) model, which is reduced to 4-bit feature vector to be encoded as qubit and is finally classified by utilizing Variational Quantum Circuit (VQC). The proposed model gave a better accuracy than existing state of the art methods in terms of high accuracy despite with a smaller set of images in the training phase.",Quantum Machine Learning;Resnet18;Diabetic Retinopathy;Variational Quantum Circuit;qubit
 Conferences,M. U. Emon; R. Zannat; T. Khatun; M. Rahman; M. S. Keya; Ohidujjaman,Performance Analysis of Diabetic Retinopathy Prediction using Machine Learning Models,IEEE,2021,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9358612,"Diabetic Retinopathy (DR) is a symptom of diabetes that affects the eyes. The blood vessels of the light tissue behind the eyes are damaged (retina). Machine Learning (ML) techniques play a vital role in computer aid diagnosis and discover successful systems for detecting life-threatening diseases. This research aimed to predict diabetic retinopathy and also implement feature extraction to figure out some features. In this research, the data is collected from the UCI machine learning repository. Several Machine Learning (ML) techniques are used for analysis this dataset and find out the best performance and sensitivity, selectivity, true positive (tp) rate, false negative (fn) rate and receiver operating characteristic (roc) curve. In this study, some machine learning algorithms are used such as Naive Bayes, Sequential Minimal Optimization (SMO), logistic regression, Stochastic Gradient Descent (SGD), bagging classifier, J48 classifier, decision tree classifier, and random forest classifier. The overall performance of logistic regression shows the best result.",Diabetic Retinopathy (DR);Feature extraction;Confusion metrics;Machine learning (ML) algorithms
 Journals,Y. Li; Z. Song; S. Kang; S. Jung; W. Kang,Semi-Supervised Auto-Encoder Graph Network for Diabetic Retinopathy Grading,IEEE,2021,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9567704,"Diabetic Retinopathy (DR) causes quite a few blindness worldwide, which can be refrained by the timely diagnosis on retinal images. Recently, researches on deep learning-based retinal image classification have accelerated outstanding improvements in DR grading task. However, existing DR grading works are mostly limited to a supervised manner. They require accurately annotated data labeled by professional experts, and the annotating work is very laborious and time-consuming. We propose a Semi-supervised Auto-encoder Graph Network (SAGN) for the challenging DR diagnosis to relax this constraint. Precisely, SAGN consists of three major modules: auto-encoder feature learning, neighbor correlation mining, and graph representation. Firstly, our model learns to extract representations from retinal images and reconstruct them as close to original inputs as possible. Then neighbor correlations among labeled and unlabeled samples are established by their similarities, calculated by the radial basis function. Finally, we operate Graph Convolutional Neural Network (GCN) to grade retinal samples from extracted features and their correlations. To evaluate the performance of SAGN, we conduct sufficient comparative experiments on APTOS 2019 dataset, trained from EyePACS. Results demonstrate that our SAGN model can achieve comparable performance with limited labeled retinal images with the help of large amounts of unlabeled data.",Diabetic retinopathy grading;semi-supervised learning;auto-encoder;graph convolutional network
 Journals,M. Nahiduzzaman; M. R. Islam; S. M. R. Islam; M. O. F. Goni; M. S. Anower; K. -S. Kwak,Hybrid CNN-SVD Based Prominent Feature Extraction and Selection for Grading Diabetic Retinopathy Using Extreme Learning Machine Algorithm,IEEE,2021,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9605633,"This paper exploits the extreme learning machine (ELM) approach to address diabetic retinopathy (DR), a medical condition in which impairment occurs to the retina caused by diabetes. DR, a leading cause of blindness worldwide, is a sort of swelling leakage due to excessive blood sugar in the retina vessels. An early-stage diagnosis is therefore beneficial to prevent diabetes patients from losing their sight. This study introduced a novel method to detect DR for binary class and multiclass classification based on the APTOS-2019 blindness detection and Messidor-2 datasets. First, DR images have been pre-processed using Ben Graham’s approach. After that, contrast limited adaptive histogram equalization (CLAHE) has been used to get contrast-enhanced images with lower noise and more distinguishing features. Then a novel hybrid convolutional neural network-singular value decomposition model has been developed to reduce input features for classifiers. Finally, the proposed method uses an ELM algorithm as the classifier that minimizes the training time cost. The experiments focus on accuracy, precision, recall, and F1-score and demonstrate the feasibility of adopting the proposed scheme for DR diagnosis. The method outperforms the existing techniques and shows an optimistic accuracy and recall of 99.73% and 100%, respectively, for binary class. For five stages of DR classification, the proposed model achieved an accuracy of 98.09% and 96.26% for APTOS-2019 and Messidor-2 datasets, respectively, which outperformed the existing state-of-art models.",Ben Graham’s pre-processing;contrast limited adaptive histogram equalization (CLAHE);convolutional neural network-singular value decomposition (CNN-SVD);diabetic retinopathy (DR);extreme learning machine (ELM)
 Conferences,R. Bygari; R. Naik; U. K. P,Blindness (Diabetic Retinopathy) Severity Scale Detection,IEEE,2021,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9474600,"Diabetic retinopathy (DR) is a severe complication of diabetes that can cause permanent blindness. Timely diagnosis and treatment of DR are critical to avoid total loss of vision. Manual diagnosis is time consuming and error-prone. In this paper, we propose a novel deep learning based method for automatic screening of retinal fundus images to detect and classify DR based on the severity. The method uses a dual-path configuration of deep neural networks to achieve the objective. In the first step, a modified UNet++ based retinal vessel segmentation is used to create a fundus image that emphasises elements like haemorrhages, cotton wool spots, and exudates that are vital to identify the DR stages. Subsequently, two convolutional neural networks (CNN) classifiers take the original image and the newly created fundus image respectively as inputs and identify the severity of DR on a scale of 0 to 4. These two scores are then passed through a shallow neural network classifier (ANN) to predict the final DR stage. The public datasets STARE, DRIVE, CHASE DB1, and APTOS are used for training and evaluation. Our method achieves an accuracy of 94.80% and Quadratic Weighted Kappa (QWK) score of 0.9254, and outperform many state-of-the-art methods.",Diabetic retinopathy;fundus image;deep learning;convolutional neural network
 Conferences,C. Santos; M. S. De Aguiar; D. Welfer; B. Belloni,Deep Neural Network Model based on One-Stage Detector for Identifying Fundus Lesions,IEEE,2021,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9534354,"Diabetic Retinopathy is a major cause of vision loss caused by retina lesions, including hard and soft exudates, microaneurysms, and hemorrhages. The development of a computational tool capable of detecting these lesions can assist in the early diagnosis of the most severe forms of the lesions and assist in the screening process and definition of the best treatment form. However, the detection of tiny objects of very different sizes and shapes makes the detection process more complicated. This paper proposes a computational model based on pre-trained convolutional neural networks capable of detecting fundus lesions to promote medical diagnosis support. We trained, adjusted, and evaluated the model using the DDR diabetic retinopathy dataset and implemented it based on a YOLOv4 architecture and Darknet framework, achieving an mAP of 7.26% and a mloU of 11.64%. The experimental results show that the proposed model presented results superior to those obtained in related works found in the literature.",diabetic retinopathy;fundus image;deep learning;lesion detection
 Conferences,R. Ramesh; S. Sathiamoorthy,Teaching and Learning based Optimization with Deep learning Model for Diabetic Retinopathy Grading and Classification,IEEE,2022,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9985707,"Diabetic retinopathy (DR) refers to a disease that leads to diabetes complications, causing non-reversible damage to retina blood vessels. DR becomes an important reason for impaired vision if not identified initially. The manual analysis procedure of DR retina fundus image with ophthalmologists consumes more time and is expensive and also has the chance of misdiagnosis different computer-aided diagnosis (CAD) techniques. In recent times, deep learning (DL) turns out to be most common method that has reached superior performance in several regions, particularly in clinical image analysis and classification. This study has presented the fully automatic analysis models which surpass manual approaches for avoiding misdiagnosis, minimizes time, cost, and effort. A novel Teaching and Learning based Optimization with Deep learning for Diabetic Retinopathy Grading and Classification (TLBODL-DRGC) model is introduced. The presented TLBODL-DRGC model inspects the retinal fundus image for the recognition and classification of different DR stages. In the TLBODL-DRGC model, the Gabor filtering (GF) system was applied for preprocessing the retinal image, and Otsu thersholding is employed to segment them. Next, the features are developed in them by the use of EfficientNetB0 method, and TLBO based hyperparameter optimizer is presented to enhance the classifier results. Finally, extra-tree classifier (ETC) model is exploited to properly determine the different stages of DR. The presented TLBODL-DRGC model is evaluated using benchmark retinal image database and the results demonstrate the promising performance over other DL models.",Diabetic retinopathy;Retinal screening;Deep learning;Image processing;Computer vision
 Conferences,A. H. Abu Samah; F. Ahmad; M. K. Osman; M. Idris; N. M. Tahir; N. A. Abd. Aziz,Classification of Pathological Signs for Diabetic Retinopathy Diagnosis using Image Enhancement Technique and Convolution Neural Network,IEEE,2019,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9068538,"Diagnosis of diabetic retinopathy (DR) involves visual examination of retinal images by ophthalmologist to detect pathological signs such as exudate, haemorrhage (HEM) and microaneurysm (MA). This process is conducted manually, therefore it is time-consuming and subjected to human error. This paper develops an automatic and intelligent machine learning algorithm for the detection of diabetic retinopathy (DR) in fundus image. It involves image enhancement and classification of pathological signs using convolution neural network (CNN) for the DR pathological signs classification. In the image enhancement process, high-pass filter and histogram equalization are applied to improve visual quality of fundus images. A five layers CNN architecture is implemented to classify the three pathological signs; exudate, HEM and MA. Two dataset, DIARETDB1 and e-Ophtha are used to evaluate the performance of the system. Simulation results using enhanced DR images show significant improvement in classification accuracy compared to those images without enhancement for both datasets.",Diabetic retinopathy;convolutional neural network;histogram equalization;high pass filter
 Conferences,K. Parthiban; K. Venkatachalapathy,Internet of Things Enabled Intelligent Machine Learning based Diabetic Retinopathy Grading and Classification Model,IEEE,2021,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9489116,"Diabetic retinopathy (DR) is a commonly existing illness among diabetic patients and has become a major reason for blindness. The development of DR can be avoided by the earlier detection of the disease. The detection and severity estimation of DR can be made using retinal inspection. Besides, the machine learning (ML) models and Internet of Things (IoT) technologies help to detect and classify DR with enhanced performance and decreased cost. In this view, this paper presents an intelligent ML based DR grading and classification (IML-DRGC) model using retinal fundus images. The goal of the IML-DRGC model is to automatically diagnose the DR at maximum accuracy. The IML-DRGC model initially enables the IoT devices to capture the retinal fundus image of the patient. Then, the gathered image undergoes preprocessing using Gaussian filtering (GF) technique to get rid of the noise that exists in the fundus image. Followed by, fuzzy c-means enabled segmentation technique is exploited to detect the affected areas in the fundus image. Moreover, the Features from Accelerated Segment Test (FAST) model is utilized as a feature extractor. Finally, support vector machine (SVM) is used as a classification model to allot distinct labels of DR. For investigating the improved diagnostic outcome of the IML-DRGC model, a series of simulations were performed and the results are examined interms of different measures.",Diabetic retinopathy;Intelligent systems;Machine learning;Data classification;Image segmentation;Grading;Image classificaiton;Fundus images;FAST
 Conferences,M. S. Sallam; A. L. Asnawi; R. F. Olanrewaju,Diabetic Retinopathy Grading Using ResNet Convolutional Neural Network,IEEE,2020,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9289822,"Designing and developing automated systems to detect and grade Diabetic Retinopathy (DR) is one of the recent research areas in the world of medical image applications since it is considered one of the main causes of total blindness for people who have diabetes in the mid-age. In this paper, a complete pipeline for retinal fundus images processing and analysis has been described, implemented and evaluated. This pipeline has three main stages: (i) image pre-processing, (ii) features extraction and (iii) classification. In the first stage, the image has been pre-processed using different transformations to standardize the images and to enhance the images quality. It has been proven that Gaussian filtering is quite effective in this context to enhance the images contrast. In the second and third stage, the convolution neural network (CNN), one of the best neural network architecture for image analysis applications, has been used. The concept of transfer learning and fine tuning have been advocated in this paper and applied for ResNet18 using the publicly available Kaggle dataset. The problem of DR diagnosis has been handled as a multi-class classification problem where there are five levels of the disease severity (0 - No DR, 1 - Mild, 2 - Moderate, 3 - Severe, 4 - Proliferative DR). The final model has achieved accuracy of 70 %, recall of 50% and specificity of 88% outperforming other models built from scratch with less training time and proving the efficiency of transfer learning in this context. The training process has considered the problem of imbalanced dataset using two different ways and it has been discovered that using imbalanced dataset sampler is a very efficient solution. The final model developed in this research could be used as the main unit for a computer aided system to be hosted online for DR detection and diagnosis.",Convolutional Neural Networks;Retinal Fundus Images Classification;Transfer Learning;Diabetic Retinopathy
 Conferences,L. Wu; C. Wan; Y. Wu; J. Liu,Generative caption for diabetic retinopathy images,IEEE,2017,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8304332,"For a long time, the detection of diabetic retinopathy has always been a great challenge. People want to find a fast and effective computer-aided treatment to diagnose the disease. In recent years, the rapid development of the deep learning makes it gradually become an effective technique for the analysis of medical images. In this paper, we propose a method to deal with diabetic retinopathy images with generative caption technique of images to generate a simple sequence to explain the abnormal contents in fundus images. The generative technique of images is a generative model based on a deep recurrent architecture that combines convolution neural network (CNN) which is currently state-of-the-art for object recognition and detection with long-short-term-memory (LSTM) which is applied with great success to machine translation and sequence generation, and that can be used to generate natural sentences describing an image. The target of the model in training is to maximize the likelihood of the target description sentence given from the training images. The model built on dataset DIARETDB0, DIARETDB1 and Messidor can achieve good performance and generate fluent sequences. In addition, the experimental results show that the accuracy of diagnosis for individual abnormal discoveries is up to 88.53% and the diagnosis accuracy is more than 90%.",Image Caption;Diabetic Retinopathy;Deep Learning;Retinopathy Lesions
 Conferences,R. Hassan; M. A. Rahman; I. Ullah; A. Hamdan Alenezi; T. H. Rassem,Identifying the Level of Diabetic Retinopathy Using Deep Convolution Neural Network,IEEE,2020,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9350905,"Diabetic Retinopathy is the leading cause of blindness in the last 100 years. The traditional screening process for DR and its stages takes a lot of time, and it is not practical. Using machine learning techniques and image processing, we can automate detecting diabetic retinal disease and disease stage with acceptable performance. In this work, we have used multiple deep convolution neural networks (CNN) with the same architecture of InceptionV3. Each of the pre-trained Inception V3 architecture is retrained with 2200 preprocessed and leveled images. The dataset is preprocessed using multiple high performing and effective image processing techniques. Then the newly trained models are used for identifying the level of DR. In the final stage, we use a voting scheme for classifying the level of DR from the output of each model. We have achieved 90.5% accuracy in binary classification (Normal/DR) and 81.1% accuracy in 5-class classification.",Diabetic Retinopathy;Convolution Neural Network (CNN);InceptionV3;Contrast Limited Adaptive Histogram Equalization (CLAHE)
 Journals,J. Wang; Y. Bai; B. Xia,Feasibility of Diagnosing Both Severity and Features of Diabetic Retinopathy in Fundus Photography,IEEE,2019,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8777173,"Diabetic retinopathy (DR) diagnosis methods in the literature are usually criticized as being limit in diagnosing DR-related features or being lack of interpretability. To deal with these issues, this paper investigates the feasibility of diagnosing both DR severity levels and the presence of DR-related features in a two-step procedure. Specifically, this paper first analyzes the quality of annotations in DR grading by measuring inter-grader variability. Cosine similarity is considered to evaluate the inter-grader variability of the presence of DR-related features, and quadratic weighted Cohen's kappa is employed to assess the inter-grader variability of DR severity levels. Next, different annotation methods as follows are compared to DR severity prediction performance using logistic regression: 1) single annotations by single grader (SASG); 2) single annotations from multiple graders (SAMG); 3) multiple annotations by voting (MAV); and 4) double annotations with adjudication of disagreement (DAAD). Based on the comparison results, the feasibility of diagnosing both DR severity and features is investigated. In the experiments, 1589 fundus images graded by three retinal specialists and four general ophthalmologists are considered. The results demonstrate that retinal specialists are more consistent than general ophthalmologists in grading both the presence of DR-related features and DR severity. The SASG and MAV should be avoided if possible while the DAAD is the good option when prediction performance is the highest priority and the SAMG is especially beneficial when both prediction performance and grading costs are considered. The upper limit performance of DR severity prediction gets accuracy 95.6% and kappa 0.962. When DR-related feature prediction achieves average cosine similarity 0.823, it is potential to get accuracy 91.2% and kappa 0.905 for DR severity prediction in real applications. These results together suggest the potential of diagnosis of both DR severity and the presence of DR-related features in a two-step procedure.",Diabetic retinopathy (DR);DR severity;DR related features;inter-grader variability;data annotation
 Conferences,L. Bai; S. Chen; M. Gao; L. Abdelrahman; M. A. Ghamdi; M. Abdel-Mottaleb,The Influence of Age and Gender Information on the Diagnosis of Diabetic Retinopathy: Based on Neural Networks,IEEE,2021,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9629607,"This paper proposes the importance of age and gender information in the diagnosis of diabetic retinopathy. We utilized Deep Residual Neural Networks (ResNet) and Densely Connected Convolutional Networks (DenseNet), which are proven effective on image classification problems and the diagnosis of diabetic retinopathy using the retinal fundus images. We used the ensemble of several classical networks and decentralized the training so that the network was simple and avoided overfitting. To observe whether the age and gender information could help enhance the performance, we added the information before the dense layer and compared the results with the results that did not add age and gender information. We found that the test accuracy of the network with age and gender information was 2.67% higher than that of the network without age and gender information. Meanwhile, compared with gender information, age information had a better help for the results.Clinical Relevance— The additional information in the dataset (such as age, gender, time of illness, etc.) can improve the accuracy of automatic diagnosis. Therefore, we strongly recommend that researchers add these different kinds of additional information when creating the dataset.",Not Found
 Conferences,F. N. M. Noor; A. P. P. A. Majeed; M. A. M. Razmam; I. M. Khairuddin; W. H. M. Isa,The Diagnosis of Diabetic Retinopathy: A Transfer Learning Approach,IEEE,2021,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9649801,"Diabetic Retinopathy is one of the complications of diabetes mellitus that occurs to the eye. It damages the blood vessels, which cause the leaking of the blood and other fluids due to the elevated blood glucose level. Diabetic Retinopathy is a quiet ailment that patients may not discover until abnormalities in the retina have progressed to the point that medication is difficult or impossible. It can also result in patients losing their sight completely. However, an automated screening machine may help overcome this problem by helping the ophthalmologist diagnose diabetic retinopathy patients as soon as possible. Hence, this research investigates the effectiveness of automatic screening machine by employing the Transfer Learning model such as VGG16 to extract the features and fed them to the Support Vector Machine (SVM), k-Nearest Neighbour (kNN) and Random Forest (RF) for the classification. It was shown that the VGG16-SVM pipeline displayed the most promising performance on the classification of Diabetic Retinopathy.",Diabetic Retinopathy;Transfer Learning;VGG16;SVM;kNN;RF
 Conferences,M. Chetoui; M. A. Akhloufi; M. Kardouchi,Diabetic Retinopathy Detection Using Machine Learning and Texture Features,IEEE,2018,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8447809,"Diabetic retinopathy (DR) is a medical condition due to diabetes mellitus that can damage the patient retina and cause blood leaks. This condition can cause different symptoms from mild vision problems to complete blindness if it is not timely treated. Hemorrhages, hard Exudates, and Micro-aneurysms (HEM) that appear in the retina are the early signs of DR. Early diagnosis of HEM is crucial to prevent blindness. Textures features such as LBP have been widely used in the past as a technique for DR detection. In this work, we introduce the use of different texture features for DR, mainly Local Ternary Pattern (LTP) and Local Energy-based Shape Histogram (LESH). We show that they outperform LBP extracted features. Support Vector Machines (SVM) are used for the classification of the extracted histogram. A histogram binning scheme for features representation is proposed. The experimental results show that LESH is the best performing technique with an obtained accuracy of 0.904 using SVM with a Radial Basis Function kernel (SVM-RBF). Similarly, the analysis of the ROC curve shows that LESH with SVM-RBF gives the best AUC (Area Under Curve) performance with 0.931.",Diabetic retinopathy;LESH;LTP;machine learning;SVM
 Conferences,S. Mohammadian; A. Karsaz; Y. M. Roshan,A comparative analysis of classification algorithms in diabetic retinopathy screening,IEEE,2017,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8167934,"Automated screening of diabetic retinopathy plays an important role in diagnosis of the disease in early stages and preventing blindness in patients with diabetes. Various machine learning approaches have been studied in literature with the purpose of improving the accuracy of the screening methods. Although the performance of the machine learning algorithm depends on the application and the type of data, yet there is no comprehensive analysis of different approaches in the diabetic retinopathy screening to choose the best approach. To this end, in this study a comparative analysis of nine common classification algorithms is performed to select the most applicable approach for the specific problem of screening diabetic retinopathy patients. Individual algorithms are optimized with respect to their tunable parameters, and are compared together in terms of their accuracy, precision, recall, and F1-score. Simulation results demonstrate the difference between the performances of individual classification algorithms and can be used as a deciding factor in method selection for further research.",Diabetic retinopathy;machine learning;classification algorithms
 Conferences,M. Z. Khan; Y. Lee,Ocular Inspection to Prevent Vision Impairment Caused by Diabetic Retinopathy,IEEE,2021,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9476928,"The retina is a unique tissue, considered an extension of the human brain that transforms the incoming light into neural signals. Many significant ocular diseases exhibit themselves in this central hub. Retinal images, therefore, play a vital part in the early detection of these chronic complications. Besides, the advancement of machine learning and biomedical imaging techniques has opened the doors for modern-day researchers to uncover life-threatening problems, such as diabetic retinopathy. This disease is common in middle-aged adults. It weakens the inner surface of retinal vessels, causing vision impairment. The precise diagnosis of diabetic retinopathy needs a computer-guided tool to automate the vessel extraction process. This article applied sequence block with U-Net architecture to segment ocular vasculature. Our approach efficiently used neighboring pixels to predict retinal vessels and generate a segmentation map with a baseline encoder-decoder structure. The vanishing gradient problem is resolved with long-term skip connections. The proposed approach is compared with state-of-the-art work. It is found that the sequence block boosted the U-Net performance on DRIVE and STARE datasets. The underlying method is an effort to limit the human biasness and error in ocular inspection and reduce the vision impairment rate in masses.",deep learning;retinal vessels;image segmentation;diabetic retinopathy;sequence model
 Conferences,H. Chen; X. Zeng; Y. Luo; W. Ye,Detection of Diabetic Retinopathy using Deep Neural Network,IEEE,2018,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8631882,"Diabetic retinopathy (DR) is a common complication of diabetes which is one of the leading causes of blindness worldwide. However, DR is hard to detect in the early stages and the diagnostic procedure can be time-consuming and abundant expertise is needed. Therefore, we proposed a computer-aided diagnosis method based on a deep learning algorithm to automatically diagnose DR and divide color retinal fundus photographs in to five grades. Besides, a novel pre-processing algorithm is adopted to enhance the quality and uniformity of input retinal images and a transfer learning method to achieve better performance. Finally, the system is evaluated based on a test set with 7023 images and an accuracy of 80.0% and a kappa score of 0.64 are achieved.",Not Found
 Journals,D. Wang; L. Wang,On OCT Image Classification via Deep Learning,IEEE,2019,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8794616,"Computer-aided diagnosis of retinopathy is a research hotspot in the field of medical image classification. Diabetic macular edema (DME) and age-related macular degeneration (AMD) are two common ocular diseases that can result in partial or complete loss of vision. Optical coherence tomography imaging (OCT) is widely applied to the diagnosis of ocular diseases including DME and AMD. In this paper, an automatic method based on deep learning is proposed to detect AME and AMD lesions, in which two publicly available OCT datasets of retina were adopted and a network model with effective feature of reuse feature was applied to solve the problem of small datasets and enhance the adaptation to the difference of different datasets of the approach. Several network models with effective feature of reusable feature were compared and the transfer learning on networks with pre-trained models was realized. CliqueNet achieves better, classification results compared with other network models with a more than 0.98 accuracy and 0.99 of area under the curve (AUC) value finally.",Deep learning;optical coherence tomography;diabetic macular edema;age-related macular degeneration automated diagnosis;computer-aided diagnosis
 Conferences,S. Johnson; L. J. J R; G. Karthikeyan; V. M; D. Sasireka,An Ensemble Deep Learning Approach for Diabetic Retinopathy Detection using Fundus Image,IEEE,2022,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10009304,"Detection of diseases, including diabetic retinopathy, may be greatly improved by taking a fundus picture of the back of the eye (DR). Complications in diabetics are the most common cause of vision problems, notably in younger and much more financially secure age groups. The risk of blindness in patients with DR may be reduced if they are diagnosed early enough. An ophthalmologist examined the fundus picture and used DR screening to look for lesions. However, the increase in incidence of DR is not correlated with the number of ophthalmologists who are able to interpret fundus pictures. Delay in prevention and treatment of DR may result as a result of this. Consequently, an automated diagnosis system is required to assist ophthalmologists in increasing the diagnostic process efficiency. The concatenate model is used in this study to differ fundus images into three categories: those without diabetic retinopathy, those with non-proliferative diabetic retinopathy, and those with proliferative diabetic retinopathy. We're using DenseNet121 and Inception-ResNetV2 for our models. Two models' feature extraction findings are integrated using the multilayer perceptron (MLP) classification approach. Compared to a single model, our strategy provides an increase in accuracy, precision, and recall of 91 percent and 90 percent for the F1-score. Deep-learning-based DR categorization utilizing fundus picture data was successfully shown in this experiment.",Diabetes retinopathy;densenet121;inception-resnetv2;concatenation
 Conferences,L. Jain; H. V. S. Murthy; C. Patel; D. Bansal,Retinal Eye Disease Detection Using Deep Learning,IEEE,2018,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9096838,"Retinal fundus images are a valuable source of information for ophthalmologists to diagnose retina problems. Early detection can improve chances of cure and also prevent blindness. Retinal problems like diabetic retinopathy, retinitis pigmentosa can be diagnosed using retinal fundus images by medical experts. In recent times, machine learning research has focused on diagnosing diseases like diabetic retinopathy by extracting features and then classifying the image. In this research our goal is to automatically classify images with retinal problems from those of the healthy ones without performing any explicit segmentation or feature extraction. Rather, we use a deep learning model to automatically classify any retinal fundus image as healthy or diseased. The architecture of the network is both simple and fast. The model has been tested on two datasets, including real patient retinal fundus images obtained from a local hospital. The accuracy of this model has been found to be in the range 96.5 % to 99.7%.",Retinal Diagnosis;CNN;Deep Learning;Machine Learning;Automated Diagnosis
 Conferences,R. Errattahi; S. F. Zahra; A. E. Hannani; A. Abdelhak; H. Ouahmane; S. Mohamed; E. H. Yassin,Investigating generalization in automatic COVID-19 detection using deep learning,IEEE,2022,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9800745,"Computer Vision and Deep Learning have been widely used to automatically detect and analyze many diseases in various fields. Some of these include tumor detection, diabetic retinopathy classification, automatic prostate segmentation, nodules classification, etc. In this work, we are investigating the application of computer vision and deep learning techniques in COVID-19 detection from X-ray images. The general purpose was to offer an aided diagnosis system to assist radiologists in COVID-19 detection or to present a preliminary assessment when a radiologist is not immediately available. To address the problem of dependence on training data, and given the nature of the task, we opted for a double evaluation of the developed models. The proposed system appears promising for the diagnosis of COVID19, showing potential results in two different datasets.",Computer Vision;Deep Learning;X-ray;COVID-19;Transfer Learning
 Conferences,S. Das; D. Das; S. K. Biswas; B. Purkayastha,Deep Diabetic Retinopathy Detection System (DDRDS) using Convolutional Neural Network: A Comparative Study,IEEE,2021,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9498420,"Diabetic Retinopathy (DR) is a medical condition in the retina of human eye, triggered due to diabetes mellitus which causes formation of lesions in the retina and leads to blurred vision and even blindness. The statistical data estimations show 80% of diabetic patients, suffering from protracted diabetes, also suffers from DR. Hence, early DR evaluation and assessment can reduce susceptibility to severe blindness, especially amongst the working generation. The process of physical diagnosis is laborious, inefficient and liable to cause error, and the lack of resources and expert opinions, makes early detection and treatment infeasible. Thus, advanced intelligent systems using innovative Machine Learning (ML) techniques such as Deep Learning (DL) are proposed by researchers. This paper proposes an intelligent system named Deep Diabetic Retinopathy Detection System (DDRDS) which employs four Deep Convolutional Neural Networks (DCNNs), for fundus image classification, for early detection of DR.",DCNN;DR;Generalization;Overfitting;Image Classification
 Journals,E. O. Rodrigues; A. Conci; P. Liatsis,ELEMENT: Multi-Modal Retinal Vessel Segmentation Based on a Coupled Region Growing and Machine Learning Approach,IEEE,2020,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9105089,"Vascular structures in the retina contain important information for the detection and analysis of ocular diseases, including age-related macular degeneration, diabetic retinopathy and glaucoma. Commonly used modalities in diagnosis of these diseases are fundus photography, scanning laser ophthalmoscope (SLO) and fluorescein angiography (FA). Typically, retinal vessel segmentation is carried out either manually or interactively, which makes it time consuming and prone to human errors. In this research, we propose a new multi-modal framework for vessel segmentation called ELEMENT (vEsseL sEgmentation using Machine lEarning and coNnecTivity). This framework consists of feature extraction and pixel-based classification using region growing and machine learning. The proposed features capture complementary evidence based on grey level and vessel connectivity properties. The latter information is seamlessly propagated through the pixels at the classification phase. ELEMENT reduces inconsistencies and speeds up the segmentation throughput. We analyze and compare the performance of the proposed approach against state-of-the-art vessel segmentation algorithms in three major groups of experiments, for each of the ocular modalities. Our method produced higher overall performance, with an overall accuracy of 97.40%, compared to 25 of the 26 state-of-the-art approaches, including six works based on deep learning, evaluated on the widely known DRIVE fundus image dataset. In the case of the STARE, CHASE-DB, VAMPIRE FA, IOSTAR SLO and RC-SLO datasets, the proposed framework outperformed all of the state-of-the-art methods with accuracies of 98.27%, 97.78%, 98.34%, 98.04% and 98.35%, respectively.",Machine learning;pixel-based classi-fication;pixel connectivity;retinal vessel segmentation;region growing
 Conferences,S. R. Arumugam; E. A. Devi; V. Rajeshram; B. R; S. G. Karuppasamy; S. V. Kumar,A Robust Approach based on CNN-LSTM Network for the identification of diabetic retinopathy from Fundus Images,IEEE,2022,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9783570,"Diabetic retinopathy (DR) is a condition that infects the eyes that involve people with diabetes losing their vision. It influences the blood vessels of the eye. Sometimes people complain about eyesight problems, such as difficulties reading or seeing too far away. The retina's blood vessels begin to bleed in the later disease later stages. Highly trained experts typically examine coloured fundus images to detect this fatal condition. This condition's manual diagnosis is time-consuming and error-prone. As a result, many computers vision-based algorithms for automatically detecting DR and its various stages from retina images have been presented. We used the Kaggle retina image dataset for this study, which is openly accessible. We introduced a convolutional neural network (CNN), and long short-term memory (LSTM) based deep learning technique for diagnosing diabetic retinopathy. The system attains better performance than the existing systems.",Diabetic retinopathy;CNN;LSTM;deep learning;Kaggle;fundus images
 Early Access Articles,A. Kukkar; D. Gupta; S. M. Beram; M. Soni; N. K. Singh; A. Sharma; R. Neware; M. Shabaz; A. Rizwan,Optimizing Deep Learning Model Parameters Using Socially Implemented IoMT Systems for Diabetic Retinopathy Classification Problem,IEEE,2022,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9931419,"Diabetic retinopathy (DR) is on the increase nowadays due to the high sugar level in the blood, and it is the reason for blindness that mainly occurs in middle-aged people. Furthermore, the Internet of Medical Things (IoMT) enabled computer-aided diagnostic (CAD) systems record DR-related data online and give patients with reassuring information. The internet allows for the interconnection of a variety of smart devices, enabling remote healthcare systems based on the IoMT to link patients with medical professionals. The proper diagnosis of diabetic patients and detection of DR severity in earlier stages help in preventing blindness. Therefore, the basic aim of this study is to prevent the diabetic patient from losing vision by detecting and classifying the severity of DR fundus images using the IoMT-enabled CAD system. This article designed a novel diabetic retinopathy classification (DRC) system by hybridizing the DL model with optimization algorithms to classify the DR images based on severity. This system begins with preprocessing phase for removing the noise from edges. Next, the proposed K-mean cluster-based growing region segmentation is employed to extract the useful region from the images. Then, pretrained convolutional neural network (CNN) model, i.e., RESnet with the proposed hybrid genetic and ant colony optimization (HGACO) algorithm, is applied to extract the features from the region of interest (ROI) and classify them into four severity levels. Performance indices such as AUC,  $F$ -measure, accuracy, sensitivity, and specificity are analyzed to evaluate the performance on MESSIDOR dataset. The performance of the proposed DRC system is compared with state-of-the-art classification systems. The proposed HGACO algorithm is also compared with Adam and gradient descent (GD) optimizers. The system is also evaluated by employing different parameters of CNN and HGACO. Additionally, for the determination of the classification accuracy of the DRC system, the confidence interval statistical test is implemented considering various parameters and configurations of the neural network. The results revealed that the proposed DR system provides higher classification results by achieving 95.78%, 91.98%, 97.7%, and 94.56% AUC, sensitivity, accuracy, and specificity rate, respectively. CNN alleviates the difficulty of developing image features, whereas the HGACO algorithm-based technique automates CNN hyperparameter design.",Ant colony optimization (ACO);convolutional neural network (CNN);deep learning (DL);diabetic retinopathy classification (DRC);genetic algorithm (GA);MESSIDOR dataset
 Conferences,Q. Wu; A. Cheddad,Segmentation-based Deep Learning Fundus Image Analysis,IEEE,2019,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8936078,"Diabetic retinopathy is the most common cause of new cases of blindness in people of working age. Early diagnosis is the key to slowing the progression of the disease, thus preventing blindness. Retinal fundus images form an important basis for judging these retinal diseases. To the best of our knowledge, no prior studies have scrutinized the predictive power of the different compositions of retinal images using deep learning. This paper is to investigate whether there exists specific region that could assist in better prediction of the retinopathy disease, meaning to find the best region in fundus images that can boost the prediction power of models for retinopathy classification. To this end, with image segmentation techniques, the fundus image is divided into three different segments, namely, the optic disc, the blood vessels, and the other regions (regions other than blood vessels and optic disk). These regions are then contrasted against the performance of original fundus images. The convolutional neural network as well as transfer deep learning with the state-of-the-art pre-trained models (i.e., AlexNet, GoogleNet, Resnet50, VGG19) are deployed. We report the average of ten runs for each model. Different machine learning evaluation metrics are used. The other regions' segment reveals more predictive power than the original fundus image especially when using AlexNet/Resnet50.",Fundus Image;retinopathy;Deep Learning;AlexNet;Image Segmentation
 Journals,Z. Gao; J. Li; J. Guo; Y. Chen; Z. Yi; J. Zhong,Diagnosis of Diabetic Retinopathy Using Deep Neural Networks,IEEE,2019,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8581492,"Diabetic retinopathy (DR) is a common eye disease and a significant cause of blindness in diabetic patients. Regular screening with fundus photography and timely intervention is the most effective way to manage the disease. The large population of diabetic patients and their massive screening requirements have generated interest in a computer-aided and fully automatic diagnosis of DR. Deep neural networks, on the other hand, have brought many breakthroughs in various tasks in the recent years. To automate the diagnosis of DR and provide appropriate suggestions to DR patients, we have built a dataset of DR fundus images that have been labeled by the proper treatment method that is required. Using this dataset, we trained deep convolutional neural network models to grade the severities of DR fundus images. We were able to achieve an accuracy of 88.72% for a four-degree classification task in the experiments. We deployed our models on a cloud computing platform and provided pilot DR diagnostic services for several hospitals; in the clinical evaluation, the system achieved a consistency rate of 91.8% with ophthalmologists, demonstrating the effectiveness of our work.",Diabetic retinopathy;automatic diagnosis;deep neural networks
 Conferences,S. Yu; D. Xiao; Y. Kanagasingam,Exudate detection for diabetic retinopathy with convolutional neural networks,IEEE,2017,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8037180,"Exudate detection is an essential task for computer-aid diagnosis of diabetic retinopathy (DR), so as to monitor the progress of DR. In this paper, deep convolutional neural network (CNN) is adopted to achieve pixel-wise exudate identification. The CNN model is first trained with expert labeled exudates image patches and then saved as off-line classifier. In order to achieve pixel-level accuracy meanwhile reduce computational time, potential exudate candidate points are first extracted with morphological ultimate opening algorithm. Then the local region (64 × 64) surrounding the candidate points are forwarded to the trained CNN model for classification/identification. A pixel-wise accuracy of 91.92%, sensitivity of 88.85% and specificity of 96% is achieved with the proposed CNN architecture on the test database.",Deep Learning;Convolutional Neural Networks;Exudate Detection;Retinal Imaging;Diabetic Retinopathy
 Conferences,G. Kurup; J. A. A. Jothi; A. Kanadath,Diabetic Retinopathy Detection and Classification using Pretrained Inception-v3,IEEE,2021,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9645914,"Diabetes is one of the major health issues faced by the population, with over 400 million people in the world suffering from the same. It is estimated that almost half the percentage out of these people are never diagnosed. Apart from the basic symptoms and effects caused by diabetes; retinopathy, or Diabetic Retinopathy (DR) is a harmful condition that can be a big threat to one’s eyesight. If left undiagnosed or untreated, this condition can cause permanent blindness. This makes it highly crucial to ensure quick consultation and proper treatment. However, it requires appropriate detection measures to be implemented. The need for automated DR diagnosis has been recognized lately due to the difficulty and time-consuming manual techniques used; and several image classification and detection methods are being tested in this field. This work utilizes a pretrained Inception-v3, a Deep Convolutional Neural Network for disease detection and classification. The best trained model is successful in achieving about 82% accuracy and a Cohen’s weighted Kappa score of 0.72.",Diabetic Retinopathy;Deep Learning;Convolutional Neural Networks (CNN);Inception-v3;pretrained model
 Journals,M. D. Alahmadi,Texture Attention Network for Diabetic Retinopathy Classification,IEEE,2022,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9780378,"Diabetic Retinopathy (DR) is a disease caused by a high level of glucose in retina vessels. This malicious disease put millions of people around the world at risk for vision loss each year. Being a life-threatening disease, early diagnosis can be an effective step in the treatment and prevention of vision loss. To automate the early diagnosis process, computer-aided diagnosis methods are not only useful in detecting the diabetic signatures but also provide information regarding the diabetic grade for the optometrist to determine an appropriate treatment. Several deep classification models are proposed in the literature to solve the diabetic retinopathy classification task, however, these methods usually lack incorporate an attention mechanism to better encode the semantic dependency and highlight the most important region for boosting the model performance. To overcome these limitations, we propose to incorporate a style and content recalibration mechanism inside the deep neural network to adaptively scale the informative regions for diabetic retinopathy classification. In our proposed method, the input image passes through the encoder module to encode both high-level and semantic features. Next, by utilizing a content and style separation mechanism, we decompose the representational space into a style (e.g., texture features) and content (e.g., semantic and contextual features) representation. The texture attention module takes the style representation and applies a high-pass filter to highlight the texture information while the spatial normalization module uses a convolutional operation to determine the more informative region inside the retinopathy image to detect diabetic signs. Once the attention modules are applied to the representational features, the fusion module combines both features to form a normalized representation for the decoding path. The decoder module in our model performs both diabetic grading and healthy, non-healthy classification tasks. Our experiment on APTOS Kaggle dataset (accuracy 0.85) demonstrates a significant improvement compared to the literature work. This fact reveals the applicability of our method in a real-world scenario.",Diabetic retinopathy;deep learning;attention;classification
 Conferences,A. Kubde; S. Mohod,Automated Computer Aided Detection of Diabetic Retinopathy Using Machine Learning Hybrid Model,IEEE,2021,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9702608,"Diabetic retinopathy is a potentially fatal condition that affects diabetics worldwide, resulting in blurred vision or total blindness. A technique for identifying diabetic retinopathy using the fundus image obtained from the patient's retina is proposed in this paper. The method entails processing a digital image of the fundus image, which assists the ophthalmologist in examining DR. A neural network was utilized to diagnose a micro-aneurysm, a type of diabetic retinopathy that is the first stage. A comparison was made between the proposed Support Vector Machine and the existing Naive Bayes classifier. For experimental validation, the programed MATLAB/SIMULINK is employed. The preprocess image was used as input data for pattern recognition using a neural network. There has been a significant improvement in terms of sensitivity, specificity, and accuracy when compared to the aforementioned existing techniques.",Diabetic retinopathy (DR);SVM;Neural network
 Conferences,S. Ananda; D. Kitahara; A. Hirabayashi; K. R. Udaya Kumar Reddy,Automatic Fundus Image Segmentation for Diabetic Retinopathy Diagnosis by Multiple Modified U-Nets and SegNets,IEEE,2019,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9023290,"Diabetes mellitus leads to damage of the retina by a high blood sugar level. This disease is called diabetic retinopathy (DR), and it is one major cause of blindness among working-aged people. DR affects about 80% of patients who have had diabetes for twenty years or more. The longer a period of diabetes is, the higher the risk of developing DR is. In order to prevent the blindness caused by DR, accurate DR diagnosis from a retinal fundus image is important. Recently, deep learning techniques play significant role in the field of computer vision. When we apply deep learning to segmentation of abnormal parts in fundus images, two major problems arise. One is that the number of available data is insufficient to train a deep neural network. The other is that the sizes of the abnormal parts are quite different depending on the type of the disease, which leads to low segmentation accuracy of small diseases. These two problems make the fundus image segmentation challenging. In this paper, we propose a segmentation method using multiple deep neural networks. To train the deep neural networks from a small number of data, we use data augmentation as preprocessing and adopt the Dice coefficient with the binary cross entropy as a loss function. Moreover, to improve the segmentation accuracy of small diseases, e.g., microaneurysms, we construct one individual network for each type of the disease. In experiments, the networks are trained from IDRiD dataset and tested for MESSIDOR dataset. We compare and discuss the accuracy of the proposed method with modified U-Nets and SegNets.",Not Found
 Conferences,C. Santos; M. S. de Aguiar; D. Welfer; B. M. Belloni,Detection of Fundus Lesions through a Convolutional Neural Network in Patients with Diabetic Retinopathy,IEEE,2021,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9630075,"Diabetic Retinopathy is a major cause of vision loss caused by retina lesions, including hard and soft exudates, microaneurysms, and hemorrhages. The development of a computational tool capable of detecting these lesions can assist in the early diagnosis of the most severe forms of the lesions and assist in the screening process and definition of the best treatment form. This paper proposes a computational model based on pre-trained convolutional neural networks capable of detecting fundus lesions to promote medical diagnosis support. The model was trained, adjusted, and evaluated using the DDR Diabetic Retinopathy dataset and implemented based on a YOLOv4 architecture and Darknet framework, reaching an mAP of 11.13% and a mIoU of 13.98%. The experimental results show that the proposed model presented results superior to those obtained in related works found in the literature.",Not Found
 Conferences,N. Bibi; N. Nida; A. Irtaza; S. M. Anwar,Automatic Detection of Exudates for Daignosis of Non-proliferative Diabetic Retinopathy using Region-based Convolutional Neural Networks,IEEE,2021,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9701408,"Diabetic Retinopathy (DR) is a severe visual impairment that grows from mild non-proliferative DR to proliferative DR. Exudates are the earliest sign of NPDR and therefore, an earlier detection of exudates would help in the diagnosis of DR. Towards this, a deep region-based convolutional neural network (RCNN) is adopted in this study to achieve pixel-wise exudate detection using MobileNet as feature extractor from fundus images. In particular, preprocessing of the retinal images is performed, including data augmentation and bounding boxes generation. The goal is to achieve pixel-level accuracy and reduce computational time. The region proposal are generated which are potential exudate candidate points within the training fundus images. Further, the local region surrounding the candidate points is forwarded to the deep RCNN for model learning and exudate detection. The proposed model is evaluated using two publicly available datasets including DIARETDB1 and e-Ophtha. Our method achieves sensitivity and specificity values of 0.98 and 0.94, respectively for DIARETDB1 data, while for e-Ophtha sensitivity and specificity is 0.96 and 0.99, respectively.",DCNN;NPDR;RCNN;REGION PROPOSAL;EXUDATE DETECTION
 Conferences,O. Perdomo; S. Otálora; F. A. González; F. Meriaudeau; H. Müller,OCT-NET: A convolutional network for automatic classification of normal and diabetic macular edema using sd-oct volumes,IEEE,2018,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8363839,"Diabetic macular edema (DME) is one of the most common eye complication caused by diabetes mellitus, resulting in partial or total loss of vision. Optical Coherence Tomography (OCT) volumes have been widely used to diagnose different eye diseases, thanks to their sensitivity to represent small amounts of fluid, thickness between layers and swelling. However, the lack of tools for automatic image analysis for supporting disease diagnosis is still a problem. Convolutional neural networks (CNNs) have shown outstanding performance when applied to several medical images analysis tasks. This paper presents a model, OCT-NET, based on a CNN for the automatic classification of OCT volumes. The model was evaluated on a dataset of OCT volumes for DME diagnosis using a leave-one-out cross-validation strategy obtaining an accuracy, sensitivity, and specificity of 93.75%.",Diabetic macular edema;OCT;convolutional neural network;deep learning;eye disease diagnosis
 Conferences,S. S. Prem; A. C. Umesh,Classification of Exudates for Diabetic Retinopathy Prediction using Machine Learning,IEEE,2020,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9250858,"These days diabetes is one of the most common disease that affects the working age group which eventually leads to complication in retina termed as diabetic retinopathy (DR). Initial screening and diagnosis of DR is essential to avoid partial or complete optical damage. Manual inspection by ophthalmologist is time consuming and tedious process. So in order to lower the work load and to reduce the chances of complete blindness an automated screening system is necessary. The paper proposes an algorithm that focuses on DR detection based on exudates using features such as local binary pattern (LBP) and wavelet transform approximation coefficient matrix. Images are distinguished as exudate and non exudate by using machine learning classification algorithms such as support vector machine (SVM), k-nearest neighbour (KNN), decision tree, random forest (RF) and artificial neural network (ANN).",Diabetic retinopathy;Exudate;Machine learning;Local binary pattern
 Conferences,H. Zhao; H. Peng; Z. Gao; S. Zheng,Mask Region-oriented Diabetic Retinopathies Detection in Ophthalmic Medical Images via Non-local Attention,IEEE,2021,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9534118,"Accurate lesions detection on retinopathy images is crucial for the diagnosis of diabetes. However, it is always hampered by various characteristics of lesions such as shape, color, texture, and similarities. Most advanced algorithms still cannot automatically detect common lesions, e.g. exudate, hemorrhage, and cotton-wool spots, being used for comprehensive analysis of disease state. To this end, we present a multi-functional detection model for diabetic retinopathies and further analyze disease mechanisms overall. Specifically, this paper attempts to implement a multi-lesion detector via modified Mask region-oriented CNN, which can be used for the aforementioned retinopathies. Meanwhile, a non-local attention module is introduced to the detector as a spatial attention mechanism for handling the global information missing problem. In addition, to boost the effectiveness of the detector, the dilated operation is implemented for dataset preprocessing. Improvement is achieved both algorithmically and architecturally, via investigating thoroughly the most probable lesion category with a novel ensemble learning framework. Extensive experiments on standard datasets for three different tasks evidence the superior performance of the proposed method over state-of-the-art methods.",Diabetic retinopathy;mask region-oriented CNN;non-local attention;multi-lesion detection
 Journals,A. K. Jaiswal; P. Tiwari; S. Kumar; M. S. Al-Rakhami; M. Alrashoud; A. Ghoneim,Deep Learning-Based Smart IoT Health System for Blindness Detection Using Retina Images,IEEE,2021,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9425499,"Deep Learning-based Smart Healthcare is getting so much attention due to real-time applicability in everyone life's, and It has obtained more attention with the convergence of IoT. Diabetic eye disease is the primary cause of blindness between working aged peoples. The major populated Asian countries such as India and China presently account for millions of people and at the verge of an eruption of diabetic inhabitants. These growing number of diabetic patients posed a major challenge among trained doctors to provide medical screening and diagnosis. Our goal is to leverage the deep learning techniques to automate the detection of blind spot in an eye and identify how severe the stage may be. In this paper, we propose an optimized technique on top of recently released pre-trained EfficientNet models for blindness identification in retinal images along with a comparative analysis among various other neural network models. Our fine-tuned EfficientNet-B5 based model evaluation follows the benchmark dataset of retina images captured using fundus photography during varied imaging stages and outperforms CNN and ResNet50 models.",Diabetic retinopathy;medical diagnosis;CNN;retina images;IoT
 Conferences,R. Chai; D. Chen; X. Ma; S. Liu; Y. Wang; Y. Wang,Diabetic Retinopathy Diagnosis Based on Transfer Learning and Improved Residual Network,IEEE,2022,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9858557,"Diabetic retinopathy (DR) is a common complication of diabetes. Effective DR detection can help diabetic patients seek medical treatment in a timely manner and reduce the risk of blindness. In this study, the attention mechanism SE-block was integrated into the residual network to improve the ability of lesion detection, and combined with the transfer learning method to solve the problem of small sample size. Applies the proposed method to its own proprietary dataset and the IDRiD dataset for referable DR diagnosis. Experimental results show that the method achieves superior classification performance.",Fundus images;Transfer learning;ResNet;SE-block;Classification
 Conferences,D. Nagpal; S. N. Panda; M. Malarvel,Hypertensive Retinopathy Screening through Fundus Images-A Review,IEEE,2021,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9358746,"Automatic segmentation of fundus images is an important task in computer-aided diagnosis (CAD) for analysis of medical images to diagnose diseases such as Hypertensive retinopathy, diabetic Retinopathy (HR). HR occurs due to hypertension for a prolonged period of time. It may lead to vision loss, if not treated at early stages. It can be observed by the changes in retinal vasculature that are caused by arterial hypertension. There are various features observed in fundus images such as arterial narrowing, bifurcation, tortuosity, etc. Computer-aided diagnosis plays a vital role in screening and grading of retinal images. There is still a need for automatic detection and grading of HR. This article presents the state-of-the-art methodologies used by researchers for predicting hypertensive retinopathy. Features that are present in retinal images have also been discussed for early detection of HR. The probable extraction techniques have been explored and evaluated based on layers used by different models. The classification technique discussed by different researchers has also been explored followed by the conclusion. This review will be beneficial for the researchers who want to focus on medical image analysis and enhancing the diagnosis of the system through CAD.",Hypertensive retinopathy;fundus imaging;Deep learning;Survey;Biomedical imaging;Medical Image analysis
 Conferences,S. Praveena; R. Lavanya,Superpixel based Segmentation for Multilesion Detection in Diabetic Retinopathy,IEEE,2019,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8862636,"Diabetic Retinopathy (DR) is a progressive chronic vision-threatening disease of retinal microvasculature associated with prolonged hyperglycaemia, hypertension and other conditions associated with diabetes. Indicators of DR include different kinds of lesions appearing on the retinal surface that are visible in a Digital Fundus Photograph (DFP). Localization of lesions and visual perception is essential to aid physicians in understanding the severity of the condition and to plan an appropriate treatment procedure for the patient. Segmentation inaccuracies due to factors like subtle nature of abnormalities and interference of blood vessels reflect in reduced classification accuracy in case of Feature Based Machine Learning (FML). While Pixel Based Machine Learning (PML) can overcome these issues, they require high computational capabilities and are redundant. Non-segmentation approaches like deep learning have been employed as an alternative for DR diagnosis. However, these techniques directly grade the image through classification and do not allow for visual perception. Thus we have used an intermediate approach called Super-pixel based segmentation that can overcome the problems in FML and PML while retaining the advantages of both. They are consistent with human visual perception and also overcome the data insufficiency problem. In this paper, we have compared the results of multilesion detection associated with DR using super-pixels segmented from three different algorithms namely, Compacted Watershed (CWS), Simple Linear Iterative Clustering (SLIC) & Linear Spectral Clustering (LSC) under a single unified framework. Experimental results show that LSC over-performs both SLIC and CWS quantitatively and qualitatively.",Diabetic Retinopathy;Lesion detection;Super-pixel;Localization
 Conferences,R. Niranjana; K. L. Narayanan; E. F. I. Rani; A. Agalya; C. Chandraleka; K. Indhumathi,Resourceful Retinal Vessel segmentation for Early Exposure of Vision Threatening Diseases,IEEE,2022,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9752931,"Blood Vessels play a major role in our vision process. Likewise, the segmentation of theses vascular structure of blood vessels segmentation projects as a critical part in diagnosis of the various vision threatening diseases including Glaucoma and Diabetic Retinopathy (DR). The accurate way of doing the segmentation of retinal blood vessel is a critical part of analysis of retinal images pertaining to the fundus. Image Processing play a vital role in the medical field. Medical image processing provides very appropriate to diagnoses the various vision threatening diseases like Glaucoma and Diabetic Retinopathy (DR). Nowadays, it is a very growing and challenging field. We proposed a simple supervised approach by using deep learning Convolutional Neural Network. The steps that include in our proposed system are Preprocessing, Segmentation, Feature Extraction, and Classification. Wiener filter is used to de-noise the retinal image. OTSU for segmentation, which separate the foreground and the background and ACO for optimization which enhance the filtered image from Wiener filter. GLCM for feature extraction of the segmented image. For classification, we used a deep learning convolution neural network which provides more iterations. So it will give an appropriate classification for vision threatening diseases. After that a MATLAB software core is implemented.",Diabetic Retinopathy;Otsu;Ant Colony Optimization;Grey Level Occurrence Matrix;MATLAB
 Conferences,R. Song; P. Cao; J. Yang; D. Zhao; O. R. Zaiane,A Domain Adaptation Multi-instance Learning for Diabetic Retinopathy Grading on Retinal Images,IEEE,2020,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9313398,"Diabetic retinopathy (DR) is one of the most concerning, common and serious diseases in the ophthalmology community. Early detection and treatment of DR can significantly reduce the risk of vision loss in patients. Traditional DR automatic classification algorithms rely on the precise detection of microaneurysms (MA) and hemorrhage (H) lesions. Such lesion annotation is an expensive and time-consuming process, hence it is expected to develop automatic grading methods with only image-level annotations. The lack of the position of MA and H hinders the traditional supervised algorithms for the accurate identification. In our work, we formulate the weakly supervised DR grading as a multi-instance learning problem, and propose a domain adaptation multi-instance learning with attention mechanism for DR grading. Specifically, labeled instances are generated by cross-domain to filter irrelevant instances in the target domain. To model the relationship between the suspicious instances and bag label, a multi-instance learning with attention mechanism is developed to acquire the location information of highly suspected lesions and predict the grade of DR. We evaluate our proposed algorithm on the Messidor dataset, and the experimental results demonstrate that it achieves an average accuracy of 0.764 and an AUC value of 0.749 respectively, outperforming state-of-the-art approaches.",Diabetic retinopathy;Severity level grading;Multi-instance learning;Domain adaptation;Attention
 Conferences,M. Elsharkawy; A. Sharafeldeen; A. Soliman; F. Khalifa; M. Ghazal; E. El-Daydamony; A. Atwan; H. S. Sandhu; A. El-Baz,Diabetic Retinopathy Diagnostic CAD System Using 3D-Oct Higher Order Spatial Appearance Model,IEEE,2022,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9761508,"Diagnoses of Diabetic Retinopathy (DR) at an early stage are of extreme importance so that the retina can be preserved and the risk of substantial damage to the retina or loss of vision is reduced. A new Computer-Aided Diagnosis (CAD) method based on Optical Coherence Tomography (OCT) scans of the retina is presented here for the detection of DR at an early stage. Utilizing an adaptive appearance-based approach that uses prior shape information, the system segments the retinal layers from the 3D-OCT scans. From the layers segmented from the B-scans volume of the OCT, novel texture features are extracted for DR diagnosis. In particular, a 2nd-order reflectivity value is calculated for each individual layer using the 2D Markov-Gibbs Random Field (2D-MGRF) model. Then, Cumulative Distribution Function (CDF) descriptors are used to represent the extracted image-derived feature using CDF’s percentiles. A feed-forward neural network is used for layer-by-layer classification of 3D volume using Gibbs energy features extracted from each individual layer. In the final stage, all twelve layers are fused with a global subject diagnosis based on a majority voting method. We evaluated a 3D-OCT system using 180 subjects using a combination of different k-fold validation techniques. The system performance for this CAD system using 4-, 5-, and 10-fold cross validation achieved accuracies of 89.4%, 91.5%, and 95.7%, respectively. In addition, our system’s ability to detect the DR early has been validated by further comparisons with the state-of-the-art deep learning networks.",3-D OCT;DR;CAD;2D-MGRF
 Journals,M. M. Abdelsalam; M. A. Zahran,A Novel Approach of Diabetic Retinopathy Early Detection Based on Multifractal Geometry Analysis for OCTA Macular Images Using Support Vector Machine,IEEE,2021,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9335918,"Diabetic Retinopathy (DR) is a complication of diabetes that affects the eyes. It is caused by blood vessel damage of the light-sensitive tissue at the back of the retina. Neovascularization are emerged and the small blood vessels are blocked. The prevention or delaying vision loss can be obtained by DR early detection. The retinal microvascular network as a biological system has its own multifractal features as generalized dimensions, lacunarity and singularity spectrum. In this study, a novel approach for DR early detection based on the multifractal geometry has been proposed in some details. Analyzing the macular optical coherence tomography angiography (OCTA) images for diagnosing early non-proliferative diabetic retinopathy (NPDR). Using a supervised machine learning method as a Support Vector Machine (SVM) algorithm to automate the diagnosis process and improving the resultant accuracy. The classification technique had achieved 98.5 % accuracy. This approach also can classify easily other diabetic retinopathy stages or other retinal diseases, which affect the vessels or neovascularization distribution.",Diabetic retinopathy;multifractal;optical coherence tomography angiography;support vector machine
 Conferences,A. A. Salam; P. Pal; M. Mahadevappa,Computer-Aided Retinal Haemorrhage Detection and Super-Resolution in Diabetic Retinopathy Digital Fundus Images,IEEE,2021,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9707389,"Retinal diseases such as diabetic retinopathy cause blood vessel ruptures that can lead to vision loss. Automatic retinal haemorrhage detection and labelling support clinicians to facilitate fast screening and initiate immediate treatment. This work proposes a haemorrhage localization technique for the accurate detection of retinal haemorrhages using transfer-learning. The retinal haemorrhages are localized using bounding boxes to obtain their corresponding coordinate locations within the fundus image. An attempt was made to develop a model for the detection of retinal haemorrhages using SSD architecture, for fundus images and the performance of the algorithm was evaluated on Diabetic Retinopathy databases available online. Moreover, a comparison on the haemorrhage detection is assessed by employing a transfer learning-based super-resolution technique on low-resolution images for a scale factor of 4. The proposed model gives a detection accuracy of 91.01%.",Haemorrhage Detection;Box-regression;Super-Resolution
 Conferences,Y. K S; N. M. Mithra; V. KS; K. R,Classification of diabetic retinopathy through identification of diagnostic keywords,IEEE,2021,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9544621,Diabetic retinopathy is a condition caused due to diabetes affecting the blood vessels in the retina. This paper presents a two-phase approach for diagnosing various conditions of the eye and also classify the fundus image as diabetic retinopathy positive or normal. The ODIR dataset containing fundus images of various conditions is used for training and testing purposes. The proposed method consists of an ensemble model. The first phase is a convolutional neural network that takes fundus images for its input and outputs the diagnostic keywords for each eye. The second phase is a machine learning classifier that determines if a person has diabetic retinopathy or not based on the keywords generated from the previous model. The results of the two phases are satisfactory. The diagnosing phase has an accuracy up to 95% and the classifier has an accuracy up to 99%.,Convolutional neural network;Fundus images;Diagnosis;Diabetic retinopathy;Machine learning;Xception;Light gradient boosting machine algorithm
 Conferences,B. Bulut; V. Kalın; B. B. Güneş; R. Khazhin,Deep Learning Approach For Detection Of Retinal Abnormalities Based On Color Fundus Images,IEEE,2020,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9259870,"In cases where people cannot access regular controls, treatment and care, delaying the diagnosis and treatment of eye diseases such as glaucoma, cataracts, diabetic retinopathy or leaving them to deteriorate unconsciously, may make daily life difficult and even cause blindness. Therefore, automatic examination of fundus photographs is important in terms of providing early diagnosis with fast, objective and consistent image evaluation and helping the application of large-scale scanning programs. This research uses Xception model with transfer learning method to classify images obtained from Akdeniz University Hospital Eye Diseases Department. During the analysis, the Xception model containing 50 different parameter combinations was trained by scanning the appropriate hyper-parameter space for the model. Comparisons were made for the top 9 models with the highest performance. The 4th model reached the highest accuracy rate with 91.39% for the training set, and as for the validation set, the 0th model showed 82.5% of accuracy. In addition, in order to test the performance of the model with an independent data set, open access fundus images were used for test analysis and binary classification AUC (Area Under Curve) values were calculated for 21 different diseases.",deep learning;eye disease;fundus images;artificial intelligence;hyper-parameter optimization;transfer learning;Xception;decision support system;convolutional neural network;image classification;computer vision
 Conferences,N. Ameri; N. Shoeibi; M. Abrishami,Segmentation of Hard Exudates in Retina Fundus Images Using BCDU-Net,IEEE,2022,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9960101,"The importance of Diabetic Retinopathy (DR) screening requires attention to the development of computer-aided diagnostic tools. Computer-Aided Diagnosis (CAD) of retinal detachment imaging can reduce mass screening of the diabetic population. For this purpose, the deep learning technique and the developed U-Net canonization network have been used. Using this network, it receives retinal images and shows the segmentation of the hard exudate lesion as a binary image. The result of this research has been evaluated on the IDRID dataset with three important indicators of dice coefficient, sensitivity, and accuracy achieve at 76.81%, 72.24%, and 99.30%, respectively, and the effectiveness of the approach was confirmed.",Fundus image;Diabetic retinopathy;Hard exudate;Deep learning;U-Net extended cannulation network;Lesion segmentation;Hard exudate segmentation
 Conferences,R. Gatti; N. Nataraja; T. Sarala; S. S. Kumar; R. P. Prasad; S. K. N. Kumar,Development of Automated System for Detection of Diabetic Retinopathy,IEEE,2021,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9573723,"The problem of people with diabetes causes a condition known as Diabetic Retinopathy (DR). It is most common in the elderly age peoples. As diabetes progresses, patients' perceptions may begin to deteriorate and cause DR. People lose their sight because of this disease. To deal with DR, early detection is required. Patients will have to be examined by doctors regularly which is a waste of time and energy. In recent time, number of DR cases are increasing exponentially due the modern stress life style. Therefore, it is necessary to automate the detection and diagnosis process of the DR. In this paper, machine learning (ML) techniques are used to diagnose early DR. These are the Probabilistic Neural Network (PNN), Support Vector Machine (SVM), Bayesian Separation and K-Means Clustering. These methods will be tested and compared with choosing the best method. 3000 images being processed for training and testing. Features are extracted from these fundus images using image processing techniques. After research, the results confirm that SVM is the best way to detect DR early with a higher level of accuracy compared to other classifiers.",Diabetic retinopathy;fundus;KNN;optic disk;retina;SVM;PNN;NPDR
 Conferences,M. Z. Khan; Y. Lee,Screening Fundus Images to Extract Multiple Ocular Features: A Unified Modeling Approach,IEEE,2021,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9508593,"The retina is a thin layered tissue located close to the optic nerve, considered an extension of the human brain. It captures the incoming light and transforms it into neural signals. Most ocular and systemic disorders such as diabetic retinopathy, glaucoma, hypertension, and cardiovascular diseases manifest themselves in this central hub. The extraction of useful information from the retina is critical. Different imaging techniques, including fundus photography and optical coherence tomography, helped practitioners find useful details; however, the risk of diagnosis error advanced by human intervention is relatively high. The underlying article has designed a fully automated screening system based on a unified modeling approach of diagnosis. The system can extract multiple ocular features with a novel semantic segmentation network to early detect the symptoms of retinal disease. The proposed method has used a separate, publicly available benchmark dataset for each feature evaluation. It has shown promising results in vessels, optic cup, and optic disc segmentation by achieving the highest accuracy, an area under the roc curve, and dice scores. The method is an effort to reduce vision impairment risks in patients facing diabetic retinopathy and glaucoma by providing an automated screening system that can visualize the changes that appear in retinal features caused by vision-threatening disorders.",deep learning;fundus images;ocular disorder;retinal features;segmentation
 Conferences,K. Parthiban; M. Kamarasan,EfficientNet with Optimal Wavelet Neural Network for DR Detection and Grading,IEEE,2022,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9716528,"Diabetic retinopathy (DR) is an illness caused by diabetes, affecting irreversible injury to the retina blood vessels. Since the traditional diagnosis process is expensive and time consuming, automated DR detection models are necessary to identify the disease at the early stage. The recently developed deep learning (DL) models make it an effective approach for accomplishing interesting solutions for medical image analysis problems. This study introduces an EfficientNet with Chicken Swarm Optimization based Wavelet Neural Network (EN-CSOWNN) model for DR Detection and Grading. The goal of the EN-CSOWNN technique is to classify the different stages of DR using retinal fundus images. In addition, the EN-CSOWNN technique involves the design of U-Net based segmentation approach to determine the infected regions in the fundus image. Besides, EfficientNet model is used for deriving a set of feature vectors and WNN model is employed to allot distinct class labels. Finally, the CSO algorithm is utilized to properly adjust the initial parameters (connection weights, scaling factor, and translation factor) of the WNN model and thereby improves the classification performance significantly. In order to demonstrate the better performance of the EN-CSOWNN technique, a comprehensive set of simulations take place on benchmark MESSIDOR dataset and the results depict the enhanced classification outcome of the EN-CSOWNN technique with the maximum accuracy of 98.60%.",Diabetic retinopathy;Grading;Deep learning;U-Net;Parameter optimization;Fundus images
 Conferences,J. Han; W. Jiang; C. Dai; H. Ma,The Design of Diabetic Retinopathy Classifier Based on Parameter Optimization SVM,IEEE,2018,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8549947,"Diabetic retinopathy is a kind of disease which can seriously damage eyesight. Early diagnosis and regular treatment can effectively reduce visual deterioration. Artificial judgment of fundus images is time-consuming and easy to misdiagnose. Machine learning is an algorithm which automatically analyzes rules from data and uses rules to predict unknown data. Support Vector Machine (SVM) is one of the most important methods of machine learning. SVM is a classifier with learning ability. It is broadly applied to image recognition and image processing. Based on machine learning, a parametric optimized SVM classifier for diabetic retinopathy is proposed. Firstly, the classifier uses PCA and KPCA method to extract the prominent features of the image without artificial recognizing the features of the image, eliminates the specific feature extraction method, reduces the algorithm complexity, increases the generalization ability of the algorithm, and greatly improves the image processing speed. Secondly, grid search and genetic algorithm are used to optimize the parameters, avoid the problem of slow operation speed and low classification accuracy due to the large amount of data or the unsuitable selection of kernel parameters. Finally, a combinatorial optimization algorithm of KPCA and grid search is created. Meanwhile, the designed experiments verify that this combination optimization algorithm can make the classifier achieve the best classification state. The experimental results show that the classification accuracy of this combinatorial optimization algorithm reaches 98.33%, which can realize the automatic classification of diabetic retinopathy more accurately and rapidly.",Support Vector Machine;parameter optimization;Kernel Principal Component Analysis;grid search;Genetic Algorithm;classification accuracy
 Conferences,M. Canche; O. Dalmau; M. García Gadanon,Automatic Detection of Hard Exudates in Retinal Images with Diabetic Retinopathy,IEEE,2017,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8575566,"The Diabetic Retinopathy (DR) is a visual complication of diabetes and one of the principal cause of lost vision not recoverable in industrialized countries. It can be treated, if detected, in its first stages. This is not an easy task because the patients with DR do not perceive any symptoms until the visual loss develops in advanced stages when the treatment is less efficient. Hard exudates are the most common lesions in the early stages. In this work, we developed an automatic method for hard exudates detection in Diabetic Retinopathy images with an acceptable level of confidence that can help specialists in the diagnosis and screening of this disease. We also propose an exhaustive study of feature selection first by individual analysis and then by combining several features. This strategy is efficient, comparable and competitive with results of methods of the state of the art.",Hard exudates detection;blood vessel detection;Adaboost;classification;image processing;diabetic retinopathy
 Conferences,P. A; V. Dhanakoti,Efficient Diabetic Retinopathy Detection using Machine Learning Techniques,IEEE,2022,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9751872,"The medical technology has seen a tremendous growth in this century. Innovative high- end technologies that are created for health care benefits the patients as well as the medical professional in a wider perspective. Diabetes mellitus is a medical complaint among all age groups which occurs due to the increase in the blood sugar level. Diabetic retinopathy is said to be a symptomless diabetic eye illness which affects the retina of human eye and leads to blindness. It affects the retinal blood vessels. There is a growth of abnormal blood vessels in the retinal surface. Diabetic retinopathy can be detected using Ridge based vessel segmentation, Computer Driven Tracing of Vessel Network, Adaptive Local Thresholding it does not have uniform illuminations. Latest technological advancements in image processing provide a more efficient diagnosis of diabetic retinopathy with the help of feature extraction. The retinal scanned image is first pre-processed and feature extraction is done using HAAR wavelet Transform for the quantitative measure of the accuracy of the disease. The image is segmented and classified based on the training sets of data using SVM classifier. This process tends to provides more accuracy and about 98% sensitivity in+ the retinal classification.",Macular oedema;Retinal blood vessels;Red lesion;Ridge based vessel segmentation;Computer Driven Tracing of Vessel Network;Adaptive Local Thresholding;feature extraction;HAAR wavelet Transform;SVM classifier
 Conferences,P. R. B. M. S; A. V; S. B; P. K. Ra; S. D. Dunston; M. A. Rajam V,Analysis of the Effect of Black Box Adversarial Attacks on Medical Image Classification Models,IEEE,2022,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9917603,"In the field of medical science, the reliability of the results produced by deep learning classifiers on disease diagnosis plays a crucial role. The reliability of the classifier substantially reduces by the presence of adversarial examples. The adversarial examples mislead the classifiers to give wrong prediction with equal or more confidence than the actual prediction. The adversarial attacks in the black box type is done by creating a pseudo model that resembles the target model. From the pseudo model, the attack is created and is transferred to the target model. In this work, the Fast Gradient Sign Method and its variants Momentum Iterative Fast Gradient Sign Method, Projected Gradient Descent and Basic Iterative Method are used to create adversarial examples on a target VGG-16 model. The datasets used are Diabetic Retinopathy 2015 Data Colored Resized and SARS-CoV-2 CT Scan Dataset. The experimentation revealed that the transferability of attack is true for the above described attack methods on a VGG-16 model. Also, the Projected Gradient Descent attack provides a higher success in attack in comparison with the other methods experimented in this work.",adversarial attacks;black box attacks;covid;diabetic retinopathy;deep neural networks
 Conferences,Z. Zhao; K. Zhang; X. Hao; J. Tian; M. C. Heng Chua; L. Chen; X. Xu,BiRA-Net: Bilinear Attention Net for Diabetic Retinopathy Grading,IEEE,2019,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8803074,"Diabetic retinopathy (DR) is a common retinal disease that leads to blindness. For diagnosis purposes, DR image grading aims to provide automatic DR grade classification, which is not addressed in conventional research methods of binary DR image classification. Small objects in the eye images, like lesions and microaneurysms, are essential to DR grading in medical imaging, but they could easily be influenced by other objects. To address these challenges, we propose a new deep learning architecture, called BiRA-Net, which combines the attention model for feature extraction and bilinear model for fine-grained classification. Furthermore, in considering the distance between different grades of different DR categories, we propose a new loss function, called grading loss, which leads to improved training convergence of the proposed approach. Experimental results are provided to demonstrate the superior performance of the proposed approach.",Not Found
 Conferences,J. Wu; J. Xin; L. Hong; J. You; N. Zheng,New hierarchical approach for microaneurysms detection with matched filter and machine learning,IEEE,2015,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7319351,"Microaneurysms are regarded as the first signs of diabetic retinopathy (DR), but the microaneurysms are not clear in the color retinal images, and many researches were studied to detect and locate these lesions. In this paper, a new hierarchical computing-aided diagnosis approach is proposed for the microaneurysms detection by using the multi-scale and multi-orientation sum of matched filter (MMMF) and machine learning, where 37 dimensional features are extracted from each candidate. Furthermore, several classifiers such as the k-nearest neighbor (kNN), local linear discrimination analysis (LLDA) and support vector machine (SVM) are modified to distinguish the true microaneurysms from the false ones, which is a typical unbalanced classification problem. The effectiveness of the proposed method is verified through the training set of a publicly available database, and the experiment results show that the proposed method has better detection performance including the receiver operating characteristic (ROC) curve and the free-response receiver operating characteristic (FROC) curve. Moreover, the proposed method with 37 dimensional features outperforms that with other features and has a sensitivity from 1/8 to 8 with the average of all seven points being 0.286 tested on the same database.",Not Found
 Conferences,L. V. S. K. B. K. Varanasi; C. M. Dasari,A Novel Deep Learning Framework for Diabetic Retinopathy Detection,IEEE,2022,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9997826,"Diabetes is one of the most dangerous diseases that is facing by many people in the world. Diabetic Retinopathy (DR) is a retinal disease that is caused by the Diabetes Mellitus (DM). DM causes the lesions on the retinal layer thereby affecting the vision. If it is not detected at the initial stages, it might lead to complete blindness and also DR is an irreversible disease. Hence, early detection of DR is inevitable to avoid the vision loss of the patients. Expeditious detection can decrease the complications of the DR thereby vision of the patient is preserved. It is a laborious task for the ophthalmologists to diagnosis DR manually, since it takes a lot more time and cost-effective. Mis-diagnosis might happen if the ophthalmologists are not skillful and experienced in detecting DR from the fundus images. Over the past two decades, deep learning has shown a significant raise in the bio-medical image processing and its niche areas obtaining the best performance. The state-of-the-art Convolutional Neural Networks (CNN) models achieved notable performance in classifying DR, but the severity levels of DR are not analyzed. To address these challenges, we propose a CNN based model that is used to analyze the fundus oculi retinal images to locate the eyeball structure and observe the presence of DR. The proposed model's hyperparameters are regulated by the transfer learning techniques for mapping the label of the images. The dataset used for training and testing the model is taken from the Kaggle that contains the retinal images and its corresponding severity in a scale. Severity level of the images is classified into five different categories from a normal to DR presented eyeball. The accuracy of the proposed model is 94.92%, proving the confident detection and prediction of the DR from the retinal images.",Deep Learning;Retina;Segmentation;Image processing;Lesion detection
 Conferences,M. Rahimzadeh; M. R. Mohammadi,ROCT-Net: A new ensemble deep convolutional model with improved spatial resolution learning for detecting common diseases from retinal OCT images,IEEE,2021,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9721471,"Optical coherence tomography (OCT) imaging is a well-known technology for visualizing retinal layers and helps ophthalmologists to detect possible diseases. Accurate and early diagnosis of common retinal diseases can prevent the patients from suffering critical damages to their vision. Computer-aided diagnosis (CAD) systems can significantly assist ophthalmologists in improving their examinations. This paper presents a new enhanced deep ensemble convolutional neural network for detecting retinal diseases from OCT images. Our model generates rich and multi-resolution features by employing the learning architectures of two robust convolutional models. Spatial resolution is a critical factor in medical images, especially the OCT images that contain tiny essential points. To empower our model, we apply a new post-architecture model to our ensemble model for enhancing spatial resolution learning without increasing computational costs. The introduced post-architecture model can be deployed to any feature extraction model to improve the utilization of the feature map’s spatial values. We have collected two open-source datasets for our experiments to make our models capable of detecting six crucial retinal diseases: Age-related Macular Degeneration (AMD), Central Serous Retinopathy (CSR), Diabetic Retinopathy (DR), Choroidal Neovascularization (CNV), Diabetic Macular Edema (DME), and Drusen alongside the normal cases. Our experiments on two datasets and comparing our model with some other well-known deep convolutional neural networks have proven that our architecture can increase the classification accuracy up to 5%. We hope that our proposed methods create the next step of CAD systems development and help future researches.",Optical Coherence Tomography;OCT Image Classification;Retinal Disease;CAD System;Convolutional Neural Network;Ensemble Learning;Spatial Resolution Learning;Capsule Network
 Conferences,A. Lahiri; A. G. Roy; D. Sheet; P. K. Biswas,Deep neural ensemble for retinal vessel segmentation in fundus images towards achieving label-free angiography,IEEE,2016,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7590955,"Automated segmentation of retinal blood vessels in label-free fundus images entails a pivotal role in computed aided diagnosis of ophthalmic pathologies, viz., diabetic retinopathy, hypertensive disorders and cardiovascular diseases. The challenge remains active in medical image analysis research due to varied distribution of blood vessels, which manifest variations in their dimensions of physical appearance against a noisy background. In this paper we formulate the segmentation challenge as a classification task. Specifically, we employ unsupervised hierarchical feature learning using ensemble of two level of sparsely trained denoised stacked autoencoder. First level training with bootstrap samples ensures decoupling and second level ensemble formed by different network architectures ensures architectural revision. We show that ensemble training of auto-encoders fosters diversity in learning dictionary of visual kernels for vessel segmentation. SoftMax classifier is used for fine tuning each member autoencoder and multiple strategies are explored for 2-level fusion of ensemble members. On DRIVE dataset, we achieve maximum average accuracy of 95.33% with an impressively low standard deviation of 0.003 and Kappa agreement coefficient of 0.708. Comparison with other major algorithms substantiates the high efficacy of our model.",Not Found
 Conferences,F. Zahra Belharar; N. Zrira,DeepRetino: Ophthalmic Disease Classification from Retinal Images using Deep Learning,IEEE,2022,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9875570,"Eye diseases are one of the main causes of visual impairment. Their causes are various: they may be related to the aging process or originate from another pathology, such as complications of diabetes. Therefore, early diagnosis is highly recommended to prevent and control eye diseases. Previous approaches focused only on the detection of glaucoma, cataract or diabetic retinopathy. The main purpose of this article is to propose DeepRetino, an automatic multi-classification approach for six eye diseases based on advances in Deep Learning, in particular Convolutional Neural Networks (CNNs). In the preprocessing phase, we first focused on the histogram equalization method called Contrast Limited Adaptive Histogram Equalization (CLAHE) to improve the contrast of the fundus images. On the other hand, in the learning phase, we initialize and update the network weights using Xavier Orthogonal and Adam Optimizer. Finally, we evaluate DeepRetino on the Ocular Disease Intelligent Recognition (ODIR) dataset for deployment.",Ophthalmic diseases;Deep Learning;Convolution Neural Networks (CNNs);Contrast Limited Adaptive Histogram Equalization (CLAHE);Ocular Disease Intelligent Recognition (ODIR);DeepRetino
 Journals,G. Zhang; J. Pan; Z. Zhang; H. Zhang; C. Xing; B. Sun; M. Li,Hybrid Graph Convolutional Network for Semi-Supervised Retinal Image Classification,IEEE,2021,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9361692,"Diabetic Retinopathy (DR) causes a significant health threat to the patient's vision with diabetic disease, which may result in blindness in severe situations. Various automatic DR diagnosis models have been proposed along with the development of deep learning, while there always relies on a large scale annotated data to train the network. However, annotating medical fundus images is cost-expensive and requires well-trained professional doctors to identity the DR grades. To overcome this drawback, this paper focuses on utilizing the easily-obtained unlabeled data with the help of limited annotated data to identify DR grades accurately. Hence we proposes a semi-supervised retinal image classification method by a Hybrid Graph Convolutional Network (HGCN). This HGCN network designs a modularity-based graph learning module and integrates Convolutional Neural Network (CNN) features into the graph representation by graph convolutional network. The synthesized hybrid features are optimized by a semi-supervised classification task which is assisted by a similarity-based pseudo label estimator. Through the proposed HGCN method, the retinal image classification model can be trained efficiently by partially labeled samples and the complicated annotating work is not required for the most retinal images. The experimental results on MESSIDOR dataset demonstrate the favorable performance of HGCN on semi-supervised retinal image classification, and the fully labeled data training also achieves an obvious superiority to the state-of-the-art supervised learning methods.",Retinal image classification;semi-supervised;graph convolutional network;modularity-based graph learning
 Conferences,K. R. Lekshmi; A. Ashok,Machine Learning Approach for Automated Recognition of Non-Proliferative Diabetic Retinopathy,IEEE,2022,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9788306,"Diabetic Retinopathy (DR) is one of the most rampant ophthalmic disease found in diabetic patients. The damage of blood venule in the light-sensitive cell at the back of the eye causes DR. Vision impairment and vision loss are the results due to DR. Vision degradation can be prevented if diagnosed early and treated promptly. Normally clinical diagnosis is done by the visual examination of the fundus manually by an ophthalmologist. This technique is time-consuming and costly. Today emerging technologies in health care aims to reduce the cost of treatment and early diagnosis. For solving this problem, a computerized detection method is proposed for the early prediction of DR, i.e., non-proliferative diabetic retinopathy (NPDR). Many studies are being conducted to help in the early detection of DR. Any computer-assisted detection technique include segmentation, extraction of features, and classification. These approaches, on the other hand, are unable to capture the deep complex features and can only classify DR’s prediction with a poor degree of accuracy. In this work, forty-nine features of each candidate object are extracted and classify them as normal verse abnormal using machine learning algorithms. MESSIDOR dataset having 1200 fundus images are used for the classification of DR. The experimental findings reveal that this technique outperforms KNN (K- Nearest Neighbour), SVM (Support Vector Machine), and NB (Naive Bayes) in recognising the existence of DR. In this method SVM performs high accuracy of 98% in prediction of DR.",Diabetic Retinopathy;Fundus image;NPDR;Messidor;KNN;SVM;Naive Bayes
 Journals,K. Aurangzeb; S. Aslam; M. Alhussein; R. A. Naqvi; M. Arsalan; S. I. Haider,Contrast Enhancement of Fundus Images by Employing Modified PSO for Improving the Performance of Deep Learning Models,IEEE,2021,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9385068,"Computer-Aided diagnosis (CAD) is a widely used technique to detect and diagnose diseases like tumors, cancers, edemas, etc. Several critical retinal diseases like diabetic retinopathy (DR), hypertensive retinopathy (HR), Macular degeneration, retinitis pigmentosa (RP) are mainly analyzed based on the observation of fundus images. The raw fundus images are of inferior quality to represent the minor changes directly. To detect and analyze minor changes in retinal vasculature or to apply advanced disease detection algorithms, the fundus image should be enhanced enough to visibly present vessel touristy. The performance of deep learning models for diagnosing these critical diseases is highly dependent on accurate segmentation of images. Specifically, for retinal vessels segmentation, accurate segmentation of fundus images is highly challenging due to low vessel contrast, varying widths, branching, and the crossing of vessels. For contrast enhancement, various retinal-vessel segmentation methods apply image-contrast enhancement as a pre-processing step, which can introduce noise in an image and affect vessel detection. Recently, numerous studies applied Contrast Limited Adaptive Histogram Equalization (CLAHE) for contrast enhancement, but with the default values for the contextual region and clip limit. In this study, our aim is to improve the performance of both supervised and unsupervised machine learning models for retinal-vessel segmentation by applying modified particle swarm optimization (MPSO) for CLAHE parameter tuning, with a specific focus on optimizing the clip limit and contextual regions. We subsequently assessed the capabilities of the optimized version of CLAHE using standard evaluation metrics. We used the contrast enhanced images achieved using MPSO-based CLAHE for demonstrating its real impact on performance of deep learning model for semantic segmentation of retinal images. The achieved results proved positive impact on sensitivity of supervised machine learning models, which is highly important. By applying the proposed approach on the enhanced retinal images of the publicly available databases of {DRIVE and STARE}, we achieved a sensitivity, specificity and accuracy of {0.8315 and 0.8433}, {0.9750 and 0.9760} and {0.9620 and 0.9645}, respectively.",CAD tools;healthcare;contrast enhancement;CLAHE;PSO;modified PSO;semantic segmentation;deep learning
 Journals,M. Tavakoli; A. Mehdizadeh; A. Aghayan; R. P. Shahri; T. Ellis; J. Dehmeshki,Automated Microaneurysms Detection in Retinal Images Using Radon Transform and Supervised Learning: Application to Mass Screening of Diabetic Retinopathy,IEEE,2021,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9409109,"Detection of red lesions in color retinal images is a critical step to prevent the development of vision loss and blindness associated with diabetic retinopathy (DR). Microaneurysms (MAs) are the most frequently observed and are usually the first lesions to appear as a consequence of DR. Therefore, their detection is necessary for mass screening of DR. However, detecting these lesions is a challenging task because of the low image contrast, and the wide variation of imaging conditions. Recently, the emergence of computer-aided diagnosis systems offers promising approaches to detect these lesions for diagnostic purposes. In this paper we focus on developing unsupervised and supervised techniques to cope intelligently with the MAs detection problem. In the first step, the retinal images are preprocessed to remove background variation in order to achieve a high level of accuracy in the detection. In the main processing step, important landmarks such as the optic nerve head and retinal vessels are detected and masked using the Radon transform (RT) and multi-overlapping windows. Finally, the MAs are detected and numbered by using a combination of RT and a supervised support vector machine classifier. The method was tested on three publicly available datasets and a local database comprising a total of 749 images. Detection performance was evaluated using sensitivity, specificity, and FROC analysis. From the image analysis viewpoint, DR was detected with a sensitivity of 100% and a specificity of 93% on average across all of these databases. Moreover, from lesion-based analysis the proposed approach detected the MAs with sensitivity of 95.7% with an average of 7 false positives per image. These results compare favourably with the best of the published results to date.",Diabetic retinopathy;supervised learning;microaneurysms;Radon transform;retinal image
 Conferences,L. Laaksonen; A. Hannuksela; E. Claridge; P. Fält; M. Hauta-Kasari; H. Uusitalo; L. Lensu,Evaluation of feature sensitivity to training data inaccuracy in detection of retinal lesions,IEEE,2016,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7820975,"Computer aided diagnostic and segmentation tools have become increasingly important in reducing the workload of medical experts performing diagnosis, monitoring and documentation of various eye diseases such as age-related macular degeneration (AMD), diabetic retinopathy (DR) and glaucoma. Supervised methods have been developed for the segmentation and detection of lesions, and the reported performance has been good. The supervised methods, however, need representative data to properly train the classifier. Inaccuracies in the ground truth may have a significant impact on the performance of a supervised method as the training data are not representative. In this study, a quantitative evaluation of the sensitivity of different image features, including colour, texture, edge and higher-level features, to inaccuracy in the ground truth on exudates is presented. A mean decrease of approx. 20% in sensitivity and 13% in specificity was observed when using the most inaccurate training data.",Ground truth accuracy;Image features;Computer aided diagnosis;Medical image analysis;Supervised classification
 Conferences,S. Sadhukhan; G. K. Ghorai; S. Maiti; G. Sarkar; A. K. Dhara,Optic Disc Localization in Retinal Fundus Images using Faster R-CNN,IEEE,2018,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8470435,"Now a days lot of people are suffering from Diabetic Retinopathy throughout the world. This is one kind of eye disease which affects people having diabetes for long time. If this is undiagnosed and not treated for long time, it can lead to blindness. Several studies have shown that an early detection and timely treatment is the only way to reduce the sufferings from diabetic retinopathy. The development of an automated screening system is the right approach for screening of diabetic retinopathy. Automated detection of several anatomical regions such as optic disc, retinal vasculature and macula is important to design a tool for the screening purpose. In our work we have presented a novel and fast optic disc detection method using Faster R-CNN. The proposed method is validated on 1200 fundus images from the MESSIDOR database which is widely accepted publicly available dataset for research purpose. We propose a supervised detection technique that uses a deep learning network trained on 6, 992 retinal fundus images augmented using geometrical transformations from MESSIDOR-II database. The proposed method shows satisfactory robustness on both normal and images affected by diabetic retinopathy. It outperforms many previous methods in terms of speed with satisfactory accuracy of optic disc localization.",Convolution neural network;Faster R-CNN;Softmax classifier;Regression;Computer aided diagnosis of diabetic retinopathy;MESSIDOR database.
 Conferences,P. Nijalingappa; B. Sandeep,Machine learning approach for the identification of diabetes retinopathy and its stages,IEEE,2015,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7456965,"The effects of the eye abnormalities are mostly gradual in nature which shows the necessity for an accurate abnormality identification system. Abnormality in retina is one among them. Diabetic Retinopathy (DR) is a disease that causes damage to the retina of human eye, which is caused by complications of diabetes. DR is one of the main causes of vision loss and its prevalence keeps rising. Diabetic Retinopathy, a frequent diabetic retinal disease is caused due to the blood vessels in the retina get changes from its original shape. Diabetic Retinopathy generally affects both the human eyes. Most of the ophthalmologists depend on the visual interpretation for the identification of the types of diseases. But, inaccurate diagnosis will change the course of treatment planning which leads to fatal results. Hence, there is a requirement for a bias free automated system which yields highly accurate results. In this paper, we are classifying the various stages of DR. We first present a summary of diabetic retinopathy and its causes. Then, a literature review of the automatic detection of diabetic retinopathy techniques is presented. Explanation and restrictions of retina databases which are used to test the performance of these detection algorithms are given.",Diabetic Retinopathy;Hemorrhage;Exudates;Retinal Image;Image processing;Medical Imaging
 Conferences,M. Z. Khan; Y. Lee,Retinal Image Analysis to Detect Neovascularization using Deep Segmentation,IEEE,2021,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9476910,"The retina has a significant role in early detection of sight-threatening disease symptoms. Most of the ocular complications manifest themselves in retina. The extraction of useful information from this vital resource is a critical task. The recent advancement in artificial intelligence has opened ways to provide rapid assistance in detecting ocular disorders through retinal images. In this article, we have proposed a vessels segmentation model for the early detection of neovascularization. It is a common symptom for patients facing chronic diabetic retinopathy. In neovascularization, the tiny vessels are produced that gets block over time with an extensive amount of sugar content in human blood. The detection of newly formatted tiny blood vessels needs a precise vessels extraction system. Our model has shown promising results on a publicly available retinal image dataset. It has achieved the highest accuracy of 0.9554 with 0.9780 AUC. The underlying research is an effort to produce automated disease detection system. The core function of the proposed system is to analyze the structural variation in vessels of subjects experiencing ocular disease symptoms and to reduce the risk of blindness through early diagnosis.",image segmentation;neovascularization;deep learning;vessels extraction;diabetic retinopathy
 Conferences,S. S. Mahamood Shazuli; A. Saravanan,Arithmetic Optimization with SE-DenseNet based Image Retrieval and Classification for Diabetic Retinopathy,IEEE,2022,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10010803,"Diabetes is a widespread disease that causes visible microvascular problems like macular edema and diabetic retinopathy (DR) in the human eye retina, the images were utilized for diagnosis and manual disease screening. This labour-intensive task would significantly benefit from automatic detection utilizing the artificial intelligence (AI) method. In addition, Content-based image retrieval (CBIR) models can be used for the retrieval of related images from huge databases and find useful in several application areas, particularly healthcare. This study develops an arithmetic optimization with SE-DenseNet based Image Retrieval and Classification (AOSED-IRC) model for DR. The major intention of the AOSED-IRC model lies in the automated retrieval and classification of fundus images for DR diagnosis. To accomplish this, the presented AOSED-IRC model follows guided image filter (GIF) technique for noise removal. Besides, the AOSED-IRC model uses SE-DenseNet model where the DenseNet with dynamic calibration of feature channels is presented. Moreover, city block similarity measure is used for the retrieval process. For DR classification, AO algorithm with stacked autoencoder (SAE) is utilized in this study in which the hyperparameters of the SAE are tuned by the AO method. The experimental validation of the AOSED-IRC algorithm is tested utilizing benchmark DR dataset and the outcomes demonstrate the significant performance of the AOSED-IRC method over other recent models.",Diabetic retinopathy;Content based image retrieval;Deep learning;Arithmetic optimization algorithm;City block
 Conferences,R. Sun; Y. Li; T. Zhang; Z. Mao; F. Wu; Y. Zhang,Lesion-Aware Transformers for Diabetic Retinopathy Grading,IEEE,2021,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9578017,"Diabetic retinopathy (DR) is the leading cause of permanent blindness in the working-age population. And automatic DR diagnosis can assist ophthalmologists to design tailored treatments for patients, including DR grading and lesion discovery. However, most of existing methods treat DR grading and lesion discovery as two independent tasks, which require lesion annotations as a learning guidance and limits the actual deployment. To alleviate this problem, we propose a novel lesion-aware transformer (LAT) for DR grading and lesion discovery jointly in a unified deep model via an encoder-decoder structure including a pixel relation based encoder and a lesion filter based decoder. The proposed LAT enjoys several merits. First, to the best of our knowledge, this is the first work to formulate lesion discovery as a weakly supervised lesion localization problem via a transformer decoder. Second, to learn lesion filters well with only image-level labels, we design two effective mechanisms including lesion region importance and lesion region diversity for identifying diverse lesion regions. Extensive experimental results on three challenging benchmarks including Messidor-1, Messidor-2 and EyePACS demonstrate that the proposed LAT performs favorably against state-of-the-art DR grading and lesion discovery methods.",Not Found
 Conferences,E. S. Kumar; C. S. Bindu,Segmentation of Retinal Lesions in Fundus Images: A Patch Based Approach Using Encoder-Decoder Neural Network,IEEE,2021,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9441964,"Lesion segmentation is an essential aspect while diagnosing Diabetic Retinopathy (DR) at initial stages. Manual identification becomes exceptionally challenging and time consuming because of the distinction in morphologies and size of lesions. Manual annotation of lesions by professionals is labor intensive and therefore requires the development of automatic segmentation techniques, but still it is also a challenging task because of the low local contrast and small size lesions present in the image. The automatic segmentation of retinal lesions through deep learning approach is of great impact for the initial diagnosis and treatment of DR. This paper proposes a patch based approach using encoder-decoder neural network to perform retinal lesions segmentation in fundus images. The architecture is trained and validated on IDRiD dataset which consists of microaneurysms, hemorrhages and hard exudate segmentations. In this approach for creating image patches a sliding widow technique is used, later the network evaluates the patches of the images and produces a probability map that predicts different types of lesions. An elaborative experiment was accompanied on IDRiD to calculate the performance of the suggested approach. The projected sensitivity, specificity and accuracy are 97.24%, 99.97%, and 99.97% respectively, which validates the effectiveness and dominance of this technique. When compared with other studies on similar tasks, the results obtained by this work indicate substantially improved performance in terms of sensitivity & specificity.",Diabetic Retinopathy;Fundus Images;Patch Generation;Lesion Segmentation;Deep Learning;Convolutional Neural Network;Encoder-Decoder Network
 Journals,J. Xu; X. Zhang; H. Chen; J. Li; J. Zhang; L. Shao; G. Wang,Automatic Analysis of Microaneurysms Turnover to Diagnose the Progression of Diabetic Retinopathy,IEEE,2018,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8295214,"Diabetic retinopathy (DR) is one of the most common microvascular complications and its early detection is critical for the prevention of vision loss. Recent studies have indicated that microaneurysms (MAs) are the hallmark of DR. However, the detection of MAs relies on trained clinicians and relatively expensive software. Moreover, manual errors often lower the accuracy of this detection. Therefore, an automatic analysis technique is highly demanded in the detection of DR progression. In this paper, we present a novel and complete methodology involving two different ways from the view of MAs turnover and pathological risk factors to diagnose the progression of DR. Specifically, one approach follows the traditional image analysis-based roadmap to obtain MAs turnover. The other investigates seven pathological features, related with MAs turnover, to classify the unchanged, new, and resolved MAs by means of statistical analysis and pattern classification techniques. The evaluations on Grampian diabetes database show that the proposed image analysis method could achieve a sensitivity of 94% and a specificity of 93%, while the classification model could achieve 89% sensitivity and 88% specificity, respectively. We also analyzed the potential weight of pathological risk factors leading to the MAs turnover, which could provide an alternative guidance for the progression of DR than traditional detection methods. In conclusion, this study provides a novel and noninvasive detection technique for early diagnosis of diabetic retinopathy with a competitive accuracy.",Mircoaneurysms turnover;lesion coordinates comparison;pathological risk factors
 Conferences,C. Chen; J. H. Chuah; R. Ali,Retinal Vessel Segmentation In Fundus Images Using Convolutional Neural Network,IEEE,2021,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9658459,"The structure of retinal vessel can reflect health status of patients, and a clear representation of retinal vessel map helps ophthalmologist to make diagnosis of some disease, such as diabetic retinopathy (DR) and hypertension. However most automatic methods for the task cannot produce a good performance, they always misclassify pixels in vessel boundaries and thin vessels. In this paper, we propose a deep learning-based model for automatic accurate retinal vessel segmentation. We cascaded two U-net to construct a multi-model network and then obtain a coarse-to-fine segmentation. We introduced residual learning and added sufficient skip connections to reuse feature maps. We adopted dilated convolution and arranged dilation rates carefully to enable the model to capture more context information. Finally, we conducted intensive experiments on DRIVE, STARE, and CHASE_DB1 databases. Our proposed model can produce an accuracy of 0.9552/0.9699/0.9642, an AUC of 0.9787/0.9852/0.9846, a sensitivity of 0.8211/0.8466/0.8395 on DRIVE, STARE and CHASE_DB1 databases, respectively.",retinal vessel segmentation;fundus image;deep learning;convolutional neural network
 Conferences,G. Sivapriya; P. Gowri; V. Praveen; V. Varshini; S. Sanjeevi; B. Tharani,Parallel Network - A Deep Learning Approach for Blood Vessel Segmentation in Retinal fundus Images,IEEE,2022,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9807958,"In this modern era, computerized Retinal Blood Vessel (RVS) segmentation plays major role in diagnosis of various diseases like Diabetic Retinopathy (DR), Neovascularization, Hemorrhage. Early detection of retinal diseases can aid in the preservation of the patient’s vision. Deep learning based a new modified Convolution Neural Network (CNN) architecture is proposed for RVS. The Proposed architecture has two layers in which the layer one is for detecting the blood vessels of size thick and layer two for small vessel detection. Then the output of two layers has been combined to get the desired output. The proposed method is tested on the generally accepted public databases for this research field, DRIVE and STARE. In addition, various pre-processed methods are studied to investigate network performance enhancement. The pre-processing of the raw input image is much needed for better segmented output of blood vessels. In this work CLAHE, normalization and morphological operation of opening are done in the pre-processing stage. The proposed parallel architecture is then used to segment the retinal vessels. Accuracy, specificity, and sensitivity achieved with this proposed network are 98.02, 98.02, 88.04 respectively. Regardless of vessel thickness, the developed system performs better in terms of vessel extraction. The architecture can also be used to identify blood vessels that are frequently obstructed by factors such as lesions and hemorrhages, regardless of vessel thickness.",Parallel architecture;Convolutional Neural Network;Blood vessels;Fundus images;Vessel Segmentation
 Conferences,C. Wang; R. Xu; Y. Zhang; S. Xu; X. Zhang,Retinal Vessel Segmentation Via Context Guide Attention Net With Joint Hard Sample Mining Strategy,IEEE,2021,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9433813,"Retinal vessel segmentation is of great significance for clinical diagnosis of eye-related diseases and diabetic retinopathy. However, due to the imbalance of retinal vessel thickness distribution and the existence of a large number of capillaries, it is difficult to segment the retinal vessels correctly. To better solve this problem, we propose a novel Context Guided Attention Net (CGA-Net) with Joint hard sample mining strategy. Specifically, we propose a Context Guided Attention Module (CGAM) which can utilize both the surrounding context information and spatial attention information to promote the precision of segmentation results. As the CGAM is flexible and lightweight, it can be easily integrated into CNN architecture. To solve the problem of retinal vessel pixel imbalance, we further propose a novel Joint hard sample mining strategy (JHSM) in network training, which combines both the pixel-wise and patch-wise hard mining to largely improve the network's robustness for hard samples. Experiments on publicly DRIVE and CHASE DB1 datasets show that our model outperforms state-of-the-art methods. Our code is available at https://github.com/vignywang/Medical_Seg.",Retinal vessel segmentation;Context guide;Attention mechanism;Hard sample mining
 Journals,W. Zhang; X. Zhao; Y. Chen; J. Zhong; Z. Yi,DeepUWF: An Automated Ultra-Wide-Field Fundus Screening System via Deep Learning,IEEE,2021,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9305690,"The emerging ultra-wide field of view (UWF) fundus color imaging is a powerful tool for fundus screening. However, manual screening is labor-intensive and subjective. Based on 2644 UWF images, a set of early fundus abnormal screening system named DeepUWF is developed. DeepUWF includes an abnormal fundus screening subsystem and a disease diagnosis subsystem for three kinds of fundus diseases (retinal tear & retinal detachment, diabetic retinopathy and pathological myopia). The components in the system are composed of a set of excellent convolutional neural networks and two custom classifiers. However, the contrast of UWF images used in the research is low, which seriously limits the extraction of fine features of UWF images by depth model. Therefore, the high specificity and low sensitivity of prediction results have always been difficult problems in research. In order to solve this problem, six kinds of image preprocessing techniques are adopted, and their effects on the prediction performance of fundus abnormal and three kinds of fundus diseases models are studied. A variety of experimental indicators are used to evaluate the algorithms for validity and reliability. The experimental results show that these preprocessing methods are helpful to improve the learning ability of the networks and achieve good sensitivity and specificity. Without ophthalmologists, DeepUWF has potential application value, which is helpful for fundus health screening and workflow improvement.",Deep learning;fundus screening;image classification;ultra-wide-field
 Journals,A. Aquino; M. E. Gegúndez-Arias; D. Marín,"Detecting the Optic Disc Boundary in Digital Fundus Images Using Morphological, Edge Detection, and Feature Extraction Techniques",IEEE,2010,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5487392,"Optic disc (OD) detection is an important step in developing systems for automated diagnosis of various serious ophthalmic pathologies. This paper presents a new template-based methodology for segmenting the OD from digital retinal images. This methodology uses morphological and edge detection techniques followed by the Circular Hough Transform to obtain a circular OD boundary approximation. It requires a pixel located within the OD as initial information. For this purpose, a location methodology based on a voting-type algorithm is also proposed. The algorithms were evaluated on the 1200 images of the publicly available MESSIDOR database. The location procedure succeeded in 99% of cases, taking an average computational time of 1.67 s. with a standard deviation of 0.14 s. On the other hand, the segmentation algorithm rendered an average common area overlapping between automated segmentations and true OD regions of 86%. The average computational time was 5.69 s with a standard deviation of 0.54 s. Moreover, a discussion on advantages and disadvantages of the models more generally used for OD segmentation is also presented in this paper.",Diabetic retinopathy;glaucoma;optic disc (OD) segmentation;retinal imaging;telemedicine
 Journals,W. Zhou; C. Wu; D. Chen; Y. Yi; W. Du,Automatic Microaneurysm Detection Using the Sparse Principal Component Analysis-Based Unsupervised Classification Method,IEEE,2017,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7859305,"Since microaneurysms (MAs) can be seen as the earliest lesions in diabetic retinopathy, its detection plays a critical role in the diabetic retinopathy diagnosis. In recent years, many machine-learning methods have been developed for MA detection. Generally, MA candidates are first identified and then a set of features for these candidates are extracted. Finally, machine-learning methods are applied for candidate classification. In this paper, we present a novel unsupervised classification method based on sparse posterior cerebral artery (PCA) for MA detection. Since it does not have to consider a non-MA training set, the class imbalance problem can be avoided. Furthermore, effective features can be selected due to the characteristic of sparse PCA, which combines the elastic net penalty with the PCA. Meanwhile, a single T2 statistic is introduced, and the control limit can be determined for distinguishing true MAs from spurious candidates automatically. Experiment results on the retinopathy online challenge competition database show the effectiveness of our proposed method.",Diabetic retinopathy;microaneurysm detection;sparse PCA;unsupervised classification
 Conferences,A. H. Vyas; V. Khanduja,A Survey on Automated Eye Disease Detection using Computer Vision Based Techniques,IEEE,2021,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9686479,"Due to recent advancements in the field of Artificial Intelligence (AI), many recent techniques have been developed to objectively identify diseases using images or videos. Eye-related diseases are one of the commonly occurring diseases in the human body. Many diseases can manifest in the eye such as Diabetic Retinopathy (DR), glaucoma, dry eye, Age Related Macular Degeneration (ARMD), cataract, keratoconus and so on. These diseases can cause severe discomfort in patients eye leading to vision loss, blurred vision or photophobia, highly impacting the quality of life of patients. Various AI and image processing techniques have been developed to assist ophthalmologists to diagnose the disease precisely as well as reducing healthcare cost. This paper reviews techniques utilizing machine learning and deep learning to detect eye diseases namely ARMD, cataract, DR and glaucoma. It is observed that the accuracy of AI based techniques outperforms manual feature extraction and classification techniques in all four disease detection areas.",Eye disease detection;medical image processing;deep learning;computer aided diagnosis;machine learning
 Conferences,M. Z. Khan; Y. Lee,Dynamic Inductive Transfer Learning with Decision Support Feedback to Optimize Retina Analysis,IEEE,2021,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9565725,"The retina is a unique tissue considered an extension of a brain that transforms the incoming light into neural signals. Numerous deep neural networks are developed to segment retinal images precisely for detecting diabetic retinopathy and glaucoma. However, these networks are limited in selecting evaluation metrics and tuning hyperparameters subjectively in the model validation process. Furthermore, the segmentation networks lack a progressive mode of model tuning for active transfer learning. This article proposed a novel technique of dynamic inductive learning with single-point decision criteria, striving to optimize the image segmentation model using multi-criteria decision support feedback. A case study is conducted to reveal the problems related to the conventional approach and establish the significance of a proposed concept with empirical evidence. It is found that dynamic inductive transfer learning reduces the subjectivity of hyperparameter selection in a model validation process. For a given challenge of retinal vessel extraction, stochastic gradient descent is considered an optimal candidate for two variants of dynamic inductive transfer learning with a decision score of 0.9634 and 0.9951, respectively. This effort would serve as a vital step towards an optimal disease diagnosis.",transfer learning;optimization;retinal vessels;segmentation model;decision system
 Conferences,P. Prentašić; S. Lončarić,Voting based automatic exudate detection in color fundus photographs,IEEE,2014,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6952663,"Diabetic retinopathy is one of the leading causes of preventable blindness. Screening programs using color fundus photographs enable early diagnosis of diabetic retinopathy, which enables timely treatment of the disease. Exudate detection algorithms are important for development of automatic screening systems and in this paper we present a method for detection of exudate regions in color fundus photographs. The method combines different preprocessing and candidate extraction algorithms to increase the exudate detection accuracy. First, we form an ensemble of different candidate extraction algorithms, which are used to increase the accuracy. After extracting the potential exudate regions we apply machine learning based classification for detection of exudate regions. For experimental validation we use the DRiDB color fundus image set where the presented method achieves higher accuracy in comparison to other state-of-the art methods.",diabetic retinopathy;exudate detection;machine learning;ensemble;image processing and analysis
 Conferences,J. K. Mathew; S. S. Lakshmi,A Study On Diagnosis Of Diabetes Mellitus Based On Tongue Images With Various Methods,IEEE,2022,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9885616,"Diabetes Mellitus (DM) gotten to be one of the key wellbeing problem in the current world scenario. Non proliferative diabetic retinopathy (NPDR) is an early stage of diabetes mellitus. People getting DM is seems to have tall hazard of many diseases such as heart diseases, kidney problems, stroke, eye problems and even damages in their internal organs. Human tongue contains many important features that helps medical practitioners to diagnose different diseases. The Support Vector Machine (SVM) algorithm is considered as the common algorithm used to classify the diabetic patient's tongue. In SVM, Data preprocessing and parameter optimization plays important role in the results. System trained with tongue images in terms of tongue color, geometry and texture features. If the image belongs to diabetic category, we are about to classify whether that is type -1 or type-2 based upon the complexity of the given image. The main motive to write this paper is to compare different machine learning methods and to give an idea about CNN with the concern of classification and segmentation process.",DM;NPDR;SVM;Pre-processing;CNN
 Conferences,X. Liu; X. Han; Y. Qiao; Y. Ge; S. Li; J. Lu,Unimodal-Uniform Constrained Wasserstein Training for Medical Diagnosis,IEEE,2019,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9022561,"The labels in medical diagnosis task are usually discrete and successively distributed. For example, the Diabetic Retinopathy Diagnosis (DR) involves five health risk levels: no DR (0), mild DR (1), moderate DR (2), severe DR (3) and proliferative DR (4). This labeling system is common for medical disease. Previous methods usually construct a multi-binary-classification task or propose some re-parameter schemes in the output unit. In this paper, we target on this task from the perspective of loss function. More specifically, the Wasserstein distance is utilized as an alternative, explicitly incorporating the inter-class correlations by pre-defining its ground metric. Then, the ground metric which serves as a linear, convex or concave increasing function w.r.t. the Euclidean distance in a line is explored from an optimization perspective. Meanwhile, this paper also proposes of constructing the smoothed target labels that model the inlier and outlier noises by using a unimodal-uniform mixture distribution. Different from the one-hot setting, the smoothed label endues the computation of Wasserstein distance with more challenging features. With either one-hot or smoothed target label, this paper systematically concludes the practical closed-form solution. We evaluate our method on several medical diagnosis tasks (e.g., Diabetic Retinopathy and Ultrasound Breast dataset) and achieve state-of-the-art performance.",Ordinal classification;Medical diagnosis;Wasserstein distance;Optimal Transportation;Earth mover's Distance;Ordinal Regression;Unimodal Uniform distribution;noise data
 Conferences,L. Listyalina; I. Mustiadi; D. A. Dharmawan,Joint Dice and Intersection over Union Losses for Deep Optical Disc Segmentation,IEEE,2020,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9487620,"Optic disc segmentation on retinal images is essential for the diagnosis of various eye-related diseases, such as diabetic retinopathy, glaucoma, and macular edema. However, manual segmentation of optic discs from fundus images by ophthalmologists is time-consuming, tedious, and labor-extensive. In the literature, various optic disc segmentation algorithms have been proposed. In general, the existing methods are evaluated in terms of the Dice coefficient and Area of Overlap. These two metrics indicates the capability of the existing methods in preserving the accurate optic disc contour and size. However, most available segmentation methods do not attempt to reduce the two measures directly. In this paper, we present a new deep optical disc framework that can tackle the drawbacks of the methods in the literature. The proposed framework performs segmentation by taking the advantages of the U-shaped convolutional neural network (U-Net); U-Net could be trained using a limited number of data. Unlike most other methods in the literature, we use a joint dice and intersection over union losses for training the deep network. We train and evaluate the proposed framework on retinal images from the DRIVE and DRISHTI-GS datasets. In the experimental parts, the proposed framework is capable of outperforming competing methods in terms of the Dice coefficient and Area of Overlap. Therefore, our framework is suitable for broad applications of automated retinal diseases diagnosis.",deep learning;dice loss;IoU loss;optical disc;retinal image;segmentation
 Magazines,Y. Wen; L. Chen; L. Qiao; Y. Deng; H. Chen; T. Zhang; C. Zhou,FLeak-Seg: Automated Fundus Fluorescein Leakage Segmentation via Cross-Modal Attention Learning,IEEE,2022,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9681186,"Despite the recent success of deep learning-based models for medical image segmentation and the importance of automated fluorescein leakage segmentation for the diagnosis of advanced diabetic retinopathy, segmentation of fluorescein leakage has been neglected because 1) there are no publicly available databases with sufficient annotations to train segmentation models and 2) supervised models struggle to accurately distinguish between different types of fluorescein leakage and localize leakages at different imaging angles. To tackle these challenges, this work presents FLeak-Seg, a cross-modal dual attention learning method to jointly capture visual and language information, for end-to-end fluorescein leakage segmentation in fundus fluorescein angiography. Specifically, both image and text data are used as input, where visual and linguistic features are captured by a cross-modal attention learning module to compensate for the lack of annotations. A keyword classification module is also employed to identify meaningful expressions related to the type and location of fluorescein leakages to further facilitate the segmentation. Experimental results obtained in an in-house fundus fluorescein angiography database demonstrate the superiority of our method. We show how erroneous segmentation masks can be improved using FLeak-Seg, its advantages in the context of limited samples, and its behavior on segmenting different types of fluorescein leakages.",Deep learning;Fundus fluorescein angiography;Fluorescein leakage segmentation;Cross-modal;Attention learning
 Conferences,K. Wang; X. Zhang; S. Huang; Q. Wang; F. Chen,CTF-Net: Retinal Vessel Segmentation via Deep Coarse-To-Fine Supervision Network,IEEE,2020,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9098742,"Retinal blood vessels structure plays an important role in the early diagnosis of diabetic retinopathy, which is a cause of blindness globally. However, the precise segmentation of retinal vessels is often extremely challenging due to the low contrast and noise of the capillaries. In this paper, we propose a novel model of deep coarse-to-fine supervision network (CTF-Net) to solve this problem. This model consists of two U-shaped architecture(coarse and fine segNet). The coarse segNet, which learns to predict probability retina map from input patchs, while the fine segNet refines the predicted map. To gain more paths to preserve the multi-scale and rich deep features information, we design an end-to-end training network instead of multi-stage learning framework to segment the retina vessel from coarse to fine. Furthermore, in order to improve feature representation and reduce the number of parameters of model, we introduce a novel feature augmentation module (FAM-residual block). Experiment results confirm that our method achieves the state-of-the-art performances on the popular datasets DRIVE, CHASE_DB1 and STARE.",Retinal vessel segmentation;coarse-to-fine segNet;deep learning;computer aided-diagnosis
 Journals,G. Quellec; M. Lamard; L. Bekri; G. Cazuguel; C. Roux; B. Cochener,Medical Case Retrieval From a Committee of Decision Trees,IEEE,2010,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5492200,"A novel content-based information retrieval framework, designed to cover several medical applications, is presented in this paper. The presented framework allows the retrieval of possibly incomplete medical cases consisting of several images together with semantic information. It relies on a committee of decision trees, decision support tools well suited to process this type of information. In our proposed framework, images are characterized by their digital content. It was applied to two heterogeneous medical datasets for computer-aided diagnoses: a diabetic retinopathy follow-up dataset (DRD) and a mammography-screening dataset (DDSM). Measure of precision among the top five retrieved results of 0.788 ± 0.137 and 0.869 ± 0.161 was obtained on DRD and DDSM, respectively. On DRD, for instance, it increases by half the retrieval of single images.",CAD;content-based image retrieval (CBIR);decision trees (DTs);information retrieval;medical databases
 Journals,W. Zhou; C. Wu; Y. Yi; W. Du,Automatic Detection of Exudates in Digital Color Fundus Images Using Superpixel Multi-Feature Classification,IEEE,2017,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8015123,"Exudates can be regarded as one of the most prevalent clinical signs of diabetic retinopathy, and the detection of exudates has important clinical significance in diabetic retinopathy diagnosis. In this paper, a novel approach named superpixel multi-feature classification for the automatic detection of exudates is developed. First, an entire image is segmented into a series of superpixels considered as candidates. Then, a total of 20 features, including 19 multi-channel intensity features and a novel contextual feature, are proposed for characterizing each candidate. A supervised multi-variable classification algorithm is also introduced to distinguish the true exudates from the spurious candidates. Finally, a novel optic disc detection technique is designed to further improve the performance of classification accuracy. Extensive experiments are carried out on two publicly available online databases, DiaretDB1, and e-ophtha EX. Compared with other state-of-the-art approaches, the experimental results show the advantages and effectiveness of the proposed approach.",Computer aided diagnosis;retinal;exudates;superpixel;multi-feature classification
 Conferences,S. Chelaramani; M. Gupta; V. Agarwal; P. Gupta; R. Habash,Multi-Task Knowledge Distillation for Eye Disease Prediction,IEEE,2021,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9423200,"While accurate disease prediction from retinal fundus images is critical, collecting large amounts of high quality labeled training data to build such supervised models is difficult. Deep learning classifiers have led to high accuracy results across a wide variety of medical imaging problems, but they need large amounts of labeled data. Given a fundus image, we aim to evaluate various solutions for learning deep neural classifiers using small labeled data for three tasks related to eye disease prediction: (T1) predicting one of the five broad categories – diabetic retinopathy, age-related macular degeneration, glaucoma, melanoma and normal, (T2) predicting one of the 320 fine-grained disease sub-categories, (T3) generating a textual diagnosis. The problem is challenging because of small data size, need for predictions across multiple tasks, handling image variations, and large number of hyper-parameter choices. Modeling the problem under a multi-task learning (MTL) setup, we investigate the contributions of each of the proposed tasks while dealing with a small amount of labeled data. Further, we suggest a novel MTL-based teacher ensemble method for knowledge distillation. On a dataset of 7212 labeled and 35854 unlabeled images across 3502 patients, our technique obtains ~83% accuracy, ~75% top-5 accuracy and ~48 BLEU for tasks T1, T2 and T3 respectively. Even with 15% training data, our method outperforms baselines by 8.1, 3.2 and 11.2 points for the three tasks respectively.",Not Found
 Conferences,P. Sahu; J. K. Mantri,The Impact of Managerial Approach to Untreated Type -2 Diabetes using AI Techniques,IEEE,2021,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9697120,"Individuals aged 20 years and over are considered. We identified participants as having diabetes if they had a HbA1c level greater than 6.5 %. People with diabetes who say they do not actually obtain care is deemed to be untreated for the purposes of this research. In this research, we used logistic regression to assess which risk factors were correlated with untreated diabetes. The aim of Review Machine learning (ML) is to diagnose, cure, and prevent diabetes. While a number of ML models have been created, they are not relevant to real- world scenarios yet. There has been a significant disconnect between ML architects, health care researchers, physicians, and patients in their technologies. Our aim is to perform an in-depth analysis on ML to recognize the potential and shortcomings of the technology. Recent advances in the development of insulin delivery devices, diabetes retinopathy diagnostic methods, and other medical studies have significantly helped people diagnosed with diabetes. Compared with these, the usage of statistical methods for diabetes treatment is only at an early level. The Food and Drug Administration (FDA) employs several highly creative ideas to get their drugs to the consumer. Description ML offers a fantastic chance to handle diabetes with improved strategies and technology.",Diabetes. Diagnosis AI;ML. Management. Diabetic retinopathy
 Conferences,N. S. Rani; N. B. J. Bipin; C. R. Yadhu,Hemorrhage Segmentation and Detection in Retinal Images using Object Detection Techniques and Machine Learning Perspectives,IEEE,2019,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8978422,"Automated diagnosis of diabetic retinopathy is one of the major goals of hemorrhage detection. Occurrence of hemorrhages in retinal images indicates the early signs of person being suffering from diabetic retinopathy. In this paper, techniques for segmentation and detection of hemorrhages from retinal images are proposed. The objectives of this work primarily focuses of extraction of blood vessel structures and hemorrhages using connected object and Sobel edge detection techniques on green channel extracted from RGB and further classify the local binary pattern features from segmented objects as hemorrhages detected and non-hemorrhage detected images. Pre-processing is performed on retinal images by extraction of green channel images being subject to adaptive histogram equalization, Laplacian filtering followed by morphological bridging operation. Further hemorrhage detection is carried out in both in machine learning and non machine learning approaches. The datasets employed for experimentation is acquired from Indian Diabetic Retinopathy Image Dataset (IDRiD): A Database for Diabetic Retinopathy. A comparative study on the outcomes of both the method is conducted and observed that the results of both methods are in par with each other with promising average accuracy of about 92.31%",Hemorrhage detection;fundus images;machine learning;connected objects
 Early Access Articles,M. Arsalan; T. M. Khan; S. S. Naqvi; M. Nawaz; I. Razzak,Prompt Deep Light-weight Vessel Segmentation Network (PLVS-Net),IEEE,2022,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9910402,"Achieving accurate retinal vessel segmentation is critical in the progression and diagnosis of vision-threatening diseases such as diabetic retinopathy and age-related macular degeneration. Existing vessel segmentation methods are based on encoder-decoder architectures, which frequently fail to take into account the retinal vessel structure's context in their analysis. As a result, such methods have difficulty bridging the semantic gap between encoder and decoder characteristics. This paper proposes a Prompt Deep Light-weight Vessel Segmentation Network (PLVS-Net) to address these issues by using prompt blocks. Each prompt block use combination of asymmetric kernel convolutions, depth-wise separable convolutions, and ordinary convolutions to extract useful features. This novel strategy improves the performance of the segmentation network while simultaneously decreasing the number of trainable parameters. Our method outperformed competing approaches in the literature on three benchmark datasets, including DRIVE, STARE, and CHASE.",Deep Learning;Light-weight Deep Network;Retinal Vessel Segmentation;Convolutional Neural Networks;Diabetic Retinopathy;Medical Image Segmentation
 Conferences,R. Adarsh; G. Amarnageswarao; R. Pandeeswari; S. Deivalakshmi,Dense Residual Convolutional Auto Encoder For Retinal Blood Vessels Segmentation,IEEE,2020,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9074172,"In order to overcome the difficulties in retinal blood vessel segmentation and aid ophthalmologists in diagnosis of diabetic retinopathy and glaucoma, there is a need for effective segmentation techniques. One such efficient technique is to use a model for segmentation using deep learning. In this paper, an auto encoder deep learning network model based on residual path and U-net has been implemented to effectively segment the retinal blood vessels. Our network model has been implemented and tested on DRIVE dataset. This proposed model is reporting an increase in efficiency and Area under ROC compared to previous methods.",Residual Network;U-net;Retinal vessels;medical image segmentation
 Conferences,U. Ozgunalp; R. Fan; A. Serener,Semantic Segmentation of Retinal Vessels Using SegNet,IEEE,2020,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9302055,"Automated retinal vessel segmentation is useful for diagnosis of many pathological diseases such as diabetic retinopathy, hypertensive retinopathy, and glaucoma. In this paper, an algorithm for semantic segmentation of retinal vessels based on semantic pixel-wise segmentation (SegNet) is presented where the network is initialized using the VGG-16 network. The High-Resolution Fundus (HRF) image database has been used for training and testing the network, where in this dataset 15 images from healthy, 15 images from diabetic, and 15 images from eyes with glaucoma are hand labeled for retinal vessels. Because of the limited number of hand-labeled images, first, a data augmentation has been applied where reflection, scaling, translation, and rotation are used for this purpose. Then class weighting is applied to minimize the issues due to the imbalanced dataset. When tested with HRF dataset, sensitivity has been estimated as 73.72%, specificity has been estimated as 94.85%, and accuracy has been estimated as 93.23%.",Deep Learning;Retinal Vessel Segmentation;Seg-Net;Semantic Segmentation;VGG16
 Conferences,A. Rebinth; S. M. Kumar,A Deep Learning Approach To Computer Aided Glaucoma Diagnosis,IEEE,2019,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8994988,"Glaucoma has been listed as a major health deterrent and is one of the top three causes of vision loss which may lead to permanent blindness. Recent global health evaluation on primary health challenges conducted by World Health Organization (WHO) has identified eye related defects as one of the critical few. Survey reports highlight that if not treated, this can become a primary concern by 2020 leading to around 80 million people affected due to eye related defects. Irrespective of geologically being developed or developing country, retinal eye defects have progressing significantly over the earlier part of this century. Progression of eye defects can be reduced by the timely diagnosis of eye defects. Image processing in the recent years has gained traction and growth multiple avenues from facial recognition to computer aided diagnosis of diseases. Cost effective and efficient computer aided diagnosis of fundal abnormalities have been enabled using image processing. This paper discusses the different methodologies adopted for automatic detection and gives insight into the progression of image mining techniques.",Retinal abnormalities;Glaucoma;Diabetic retinopathy;Fundus images;Feature detection;Segmentation;Optic disc;Optic cup;KNN;Naïve-bayes;SVM
 Conferences,W. H. Beluch; T. Genewein; A. Nurnberger; J. M. Kohler,The Power of Ensembles for Active Learning in Image Classification,IEEE,2018,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8579074,"Deep learning methods have become the de-facto standard for challenging image processing tasks such as image classification. One major hurdle of deep learning approaches is that large sets of labeled data are necessary, which can be prohibitively costly to obtain, particularly in medical image diagnosis applications. Active learning techniques can alleviate this labeling effort. In this paper we investigate some recently proposed methods for active learning with high-dimensional data and convolutional neural network classifiers. We compare ensemble-based methods against Monte-Carlo Dropout and geometric approaches. We find that ensembles perform better and lead to more calibrated predictive uncertainties, which are the basis for many active learning algorithms. To investigate why Monte-Carlo Dropout uncertainties perform worse, we explore potential differences in isolation in a series of experiments. We show results for MNIST and CIFAR-10, on which we achieve a test set accuracy of 90% with roughly 12,200 labeled images, and initial results on ImageNet. Additionally, we show results on a large, highly class-imbalanced diabetic retinopathy dataset. We observe that the ensemble-based active learning effectively counteracts this imbalance during acquisition.",Not Found
 Journals,Y. Zong; J. Chen; L. Yang; S. Tao; C. Aoma; J. Zhao; S. Wang,U-net Based Method for Automatic Hard Exudates Segmentation in Fundus Images Using Inception Module and Residual Connection,IEEE,2020,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9194249,"Diabetic retinopathy (DR) is an eye abnormality caused by chronic diabetes that affected patients worldwide. Hard exudate is an important and observable sign of DR and can be used for early diagnosis. In this paper, an automatic hard exudates segmentation method is proposed in order to aid ophthalmologists to diagnose DR in the early stage. We utilized the SLIC superpixel algorithm to generate sample patches, thus overcoming the difficulty of the limited and imbalanced dataset. Furthermore, a U-net based network architecture with inception modules and residual connections is proposed to conduct end-to-end hard exudate segmentation, and focal loss is utilized as the loss function. Extensive experiments have been conducted on the IDRiD dataset to evaluate the performance of the proposed method. The reported sensitivity, specificity, and accuracy achieve 96.38%, 97.14%, and 97.95% respectively, which demonstrates the effectiveness and superiority of our method. The achieved segmentation results prove the potential of the method for clinical diagnosis.",Deep learning;diabetic retinopathy;exudates segmentation;superpixel;U-net
 Conferences,P. Joshi; M. V,An Efficient Transfer Learning Based Approach for Detecting the Abnormal Fundus Images,IEEE,2021,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9672382,"The vision disabilities are seemingly increasing and prevalent across the world. The current diagnosis require a manual expert for diagnosis. The advancement regarding research in AI for healthcare applications has been focused in recent years. The retinal fundus imaging system is used to capture the retinal images. Those retinal fundus images can be used to detect the vision impairments. Prior research has thoroughly investigated regarding detecting the particular type of disease such as diabetic retinopathy, cataract, glaucoma etc. However, only a little research has been conducted to classify a given retinal image into normal and abnormal fundus image. In this paper, a novel transfer learning based method to detect the abnormal fundus image has been proposed. The EfficientNetV2 has been used as classification model, which aids in classifying the normal and abnormal fundus images. To our knowledge, the EfficientNetV2 has not been used as a transfer learning model before. The proposed model has been evaluated against the recent state-of-the-art models including transformers and multi layer perceptron(MLP) based models which have been found to be working well on the image classification task. It has been observed that convolutional neural networks are still performing better than the recent transformer based models and MLP based models for detecting abnormal fundus images. The proposed model has achieved 95 % accuracy on the dataset received from a hospital.",EfficientNetV2;Deep Learning;Transfer Learning;Retinal Fundus Images
 Journals,A. Imran; J. Li; Y. Pei; J. -J. Yang; Q. Wang,Comparative Analysis of Vessel Segmentation Techniques in Retinal Images,IEEE,2019,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8804190,"The blood vessels are the primary anatomical structure that can be visible in retinal images. The segmentation of retinal blood vessels has been accepted worldwide for the diagnosis of both cardiovascular (CVD) and retinal diseases. Thus, it requires an appropriate vessel segmentation method for automatic detection of retinal diseases such as diabetic retinopathy and cataract. The detection of retinal diseases using computer-aided diagnosis (CAD) can help people to avoid the risks of visual impairment and save medical resources. This survey presents a comparative analysis of various machine learning and deep learning-based methods for automated blood vessel segmentation in retinal images. This paper briefly describes fundus photography, publicly available retinal databases, pre-processing and post-processing techniques for retinal vessels segmentation. A comprehensive review of the state of the art supervised and unsupervised blood vessel segmentation methodologies are presented in this paper. The objective of this study is to establish a professional structure to familiarize an individual with up-to-date vessel segmentation techniques. Moreover, we compared these approaches to the dataset, evaluation metrics, pre-processing and post-processing steps, feature extraction, segmentation methods, and induced results.",Vessel segmentation;retinal diseases;image segmentation;retinal fundus images;medical imaging
 Conferences,H. F. Jelinek; A. Rocha; T. Carvalho; S. Goldenstein; J. Wainer,Machine learning and pattern classification in identification of indigenous retinal pathology,IEEE,2011,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6091471,"Diabetic retinopathy (DR) is a complication of diabetes, which if untreated leads to blindness. DR early diagnosis and treatment improve outcomes. Automated assessment of single lesions associated with DR has been investigated for sometime. To improve on classification, especially across different ethnic groups, we present an approach using points-of-interest and visual dictionary that contains important features required to identify retinal pathology. Variation in images of the human retina with respect to differences in pigmentation and presence of diverse lesions can be analyzed without the necessity of preprocessing and utilizing different training sets to account for ethnic differences for instance.",Not Found
 Conferences,Y. Wen; L. Chen; L. Qiao; Y. Deng; H. Chen; T. Zhang; C. Zhou,Let’s Find Fluorescein: Cross-Modal Dual Attention Learning For Fluorescein Leakage Segmentation In Fundus Fluorescein Angiography,IEEE,2021,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9428108,"Automatic segmentation of fluorescein leakage in fundus fluorescein angiography images is important in the clinical diagnosis of advanced diabetic retinopathy. Despite the recent success of deep-learning-based models in improving medical image segmentation, segmentation of fluorescein leakage has been ignored owing to (1) a lack of publicly available data with sufficient annotations for training a segmentation network and (2) incapability of supervised models to accurately localize fluorescein leakage at different imaging angles. To address these issues, we studied the automatic segmentation of fluorescein leakage in fundus fluorescein angiography images and devised a method involving (1) a cross-modal learning framework for fluorescein leakage segmentation using both image and text data, (2) a dual attention learning module for identifying important linguistic and visual features, and (3) fluorescein-related-keyword classification for identifying meaningful textual expressions pertaining to the location and type of fluorescein leakage. We demonstrate the effectiveness of the proposed method for an in-house fundus fluorescein angiography image data set.",Deep learning;Convolutional neural network;Fundus fluorescein angiography;Fluorescein leakage segmentation;Cross-modal;Attention module
 Conferences,Y. Zhou; L. Huang; T. Zhou; L. Shao,CCT-Net: Category-Invariant Cross-Domain Transfer for Medical Single-to-Multiple Disease Diagnosis,IEEE,2021,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9710434,"A medical imaging model is usually explored for the diagnosis of a single disease. However, with the expanding demand for multi-disease diagnosis in clinical applications, multi-function solutions need to be investigated. Previous works proposed to either exploit different disease labels to conduct transfer learning through fine-tuning, or transfer knowledge across different domains with similar diseases. However, these methods still cannot address the real clinical challenge - a multi-disease model is required but annotations for each disease are not always available. In this paper, we introduce the task of transferring knowledge from single-disease diagnosis (source domain) to enhance multi-disease diagnosis (target domain). A category-invariant cross-domain transfer (CCT) method is proposed to address this single-to-multiple extension. First, for domain-specific task learning, we present a confidence weighted pooling (CWP) to obtain coarse heatmaps for different disease categories. Then, conditioned on these heatmaps, category-invariant feature refinement (CIFR) blocks are proposed to better localize discriminative semantic regions related to the corresponding diseases. The category-invariant characteristic enables transferability from the source domain to the target domain. We validate our method in two popular areas: extending diabetic retinopathy to identifying multiple ocular diseases, and extending glioma identification to the diagnosis of other brain tumors.",Transfer/Low-shot/Semi/Unsupervised Learning;Medical;biological;and cell microscopy;Recognition and classification;Representation learning
 Conferences,S. A. Tuncer; T. Selçuk; M. Parlak; A. Alkan,Hybrid approach optic disc segmentation for retinal images,IEEE,2017,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8090289,"Detection of optic disc in retinal images is an important step in disease diagnosis and patient follow-up. Optic disc detection is a Preprocess step for the diagnosis of many diseases, such as glaucoma and DP (Diabetic Retinopathy), which are vital for the eye. In this study, a hybrid approach is proposed for fully automatic segmentation of Optic Disc (OD). The first phase of the study consists of OD localization. The OD localization coordinate obtained in the study was used as an input to the method of region segmentation, which is a semi-automatic segmentation method, used as an initial point for OD segmentation. In this way, fully automatic segmentation is done. The success of the hybrid approach was evaluated according to both localization and segmentation. Performance of the study was evaluated with 30 images according to Dice and Jaccard Similarity. As a result of the evaluation have been obtained respectively % 92 and % 87 success.",Optick disk Segmentation;l1 minimization;Region growing
 Conferences,W. Xu; H. Yang; M. Zhang; X. Pan; W. Liu; S. Yan,DECNet: A Dual-stream Edge Complementary Network for Retinal Vessel Segmentation,IEEE,2021,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9669751,"Retinal vessel segmentation is of great significance for the clinical diagnosis of eye-related diseases and diabetic retinopathy. CNN-based models have led to advancements in the task of retinal vessel segmentation in recent years, but such methods typically miss high-frequency information such as object edges and delicate features, which are critical for vessel segmentation. Therefore, we present a Dual-stream Edge Complementary Network (DECNet) with a novel Edge Complementary Module (ECM) to better tackle these challenges. Specifically, in DECNet, an edge regression stream is added to regress the edges of vessels, and the regression result can be feedback to the original body stream to replenish the missing and coarse edges in the segmentation results. Moreover, the ECM is designed to enhance the interaction between the body stream and the edge stream, and exploit more complementary information. Extensive experiment results on DRIVE and CHASEDB1 not only demonstrate the effectiveness of the proposed DECNet but also indicate that our DECNet outperforms other state-of-the-art approaches.",Retinal vessel segmentation;CNN;Dual-stream;Edge complementary
 Journals,M. Alkhodari; M. Rashid; M. A. Mukit; K. I. Ahmed; R. Mostafa; S. Parveen; A. H. Khandoker,Screening Cardiovascular Autonomic Neuropathy in Diabetic Patients With Microvascular Complications Using Machine Learning: A 24-Hour Heart Rate Variability Study,IEEE,2021,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9521895,"Cardiovascular autonomic neuropathy (CAN) is one of the most overlooked complications associated with diabetes. It is characterized by damage in the autonomic nerves regulating heart rate and vascular compliance. Ewing battery is currently the diagnostic tool of choice but is unable to detect sub-clinical CAN and requires patient cooperation. In addition, appropriate timing (day/night) of CAN diagnostic test was not explored in the past. Therefore, a novel approach is proposed herein to investigate the feasibility of using heart rate variability (HRV) features over 24 hours embedded within machine learning algorithms to provide a complete screening for patients suffering from CAN. 24-hour Holter ECG data were acquired from a Bangladeshi cohort (n = 95 patients [75 Diabetic and 25 healthy]). HRV features were extracted from every 5-minute segment of the HRV signal and used as input to four machine learning algorithms for hourly training and testing. A complete hierarchical step by step diagnosis procedure (4 tests) was developed; namely test 1 to check for being healthy or diabetic; test 2 to check for any microvascular complications (including neuropathy such as CAN, peripheral neuropathy (DPN), nephropathy (NEP), and retinopathy (RET)) or not; test 3 to check for presence of only CAN; test 4 to check for combined or multiple complications along with CAN. The highest levels of performance were achieved with accuracy measures of 85.5% (test 1 - convolutional neural network (CNN)), 98.5% (test 2 - CNN), 98.3% (test 3 - one-class support vector machines (SVM)), and 90.9% (test 4 - random forest). Hours 7:00 AM and 7:00 PM were found to be most significant in the diagnosis of CAN in diabetic patients (test 1, 3, and 4). Early screening of CAN by our proposed models could help primary healthcare centers stratify the risk leading to early treatment in preventing sudden cardiac death due to silent myocardial infarction. The approach is considered to be simple and effective, especially for under-resourced clinical settings.",Diabetes;cardiovascular autonomic neuropathy (CAN);24-hour electrocardiography (ECG);heart rate variability (HRV);machine learning;one-class support vector machine (SVM)
 Conferences,G. Lei; Y. Xia; W. Zhang; D. Chen; D. Wang,Comparative Analysis of Pre-process Pipelines For Automatic Retinal Vessel Segmentation,IEEE,2020,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9189391,"Retinal vessel structure is an unique individual characteristic and important biology marker of many diseases, like Diabetic Retinopathy (DR), cardiovascular ailment, and so on. Automatic retinal vessel segmentation can be used to assist the early diagnosis of above diseases, but suffers from the poor quality and low contrast of fundus images. To eliminate the noise in the fundus images, many pre-process pipelines are designed to normalize and enhance the fundus images. However, the specific operations in pre-process pipelines of the fundus images haven't been distinguished from operations in normalization of natural images. This paper collects a dozen of pre-process pipelines from published retinal vessel segmentation researches, and proposes five general patterns of these pre-process pipelines. Furthermore, we test the flexibility of five classical pre-process pipelines on public retinal vessel datasets with a Dense-UNet model. Experiments demonstrate that the ""Hiera"" pre-process pipeline and the ""DUNet"" pre-process pipeline outperform the rest pipelines in assisting the Dense-UNet to segment the retinal vessels.",Retinal vessel segmentation;deep learning;pre-process pipeline
 Conferences,Q. Wei; X. Li; W. Yu; X. Zhang; Y. Zhang; B. Hu; B. Mo; D. Gong; N. Chen; D. Ding; Y. Chen,Learn to Segment Retinal Lesions and Beyond,IEEE,2021,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9412088,"Towards automated retinal screening, this paper makes an endeavor to simultaneously achieve pixel-level retinal lesion segmentation and image-level disease classification. Such a multi-task approach is crucial for accurate and clinically interpretable disease diagnosis. Prior art is insufficient due to three challenges, i.e., lesions lacking objective boundaries, clinical importance of lesions irrelevant to their size, and the lack of one-to-one correspondence between lesion and disease classes. This paper attacks the three challenges in the context of diabetic retinopathy (DR) grading. We propose Lesion-Net, a new variant of fully convolutional networks, with its expansive path redesigned to tackle the first challenge. A dual Dice loss that leverages both semantic segmentation and image classification losses is introduced to resolve the second challenge. Lastly, we build a multi-task network that employs Lesion-Net as a side-attention branch for both DR grading and result interpretation. A set of 12K fundus images is manually segmented by 45 ophthalmologists for 8 DR-related lesions, resulting in 290K manual segments in total. Extensive experiments on this large-scale dataset show that our proposed approach surpasses the prior art for multiple tasks including lesion segmentation, lesion classification and DR grading.",Not Found
 Conferences,Y. Luo; H. Cheng; L. Yang,Size-Invariant Fully Convolutional Neural Network for vessel segmentation of digital retinal images,IEEE,2016,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7820677,"Vessel segmentation of digital retinal images plays an important role in diagnosis of diseases such as diabetics, hypertension and retinopathy of prematurity due to these diseases impact the retina. In this paper, a novel Size-Invariant Fully Convolutional Neural Network (SIFCN) is proposed to address the automatic retinal vessel segmentation problems. The input data of the network is the patches of images and the corresponding pixel-wise labels. A consecutive convolution layers and pooling layers follow the input data, so that the network can learn the abstract features to segment retinal vessel. Our network is designed to hold the height and width of data of each layer with padding and assign pooling stride so that the spatial information maintain and up-sample is not required. Compared with the pixel-wise retinal vessel segmentation approaches, our patch-wise segmentation is much more efficient since in each cycle it can predict all the pixels of the patch. Our overlapped SIFCN approach achieves accuracy of 0.9471, with the AUC of 0.9682. And our non-overlap SIFCN is the most efficient approach among the deep learning approaches, costing only 3.68 seconds per image, and the overlapped SIFCN costs 31.17 seconds per image.",Not Found
 Conferences,J. Wang; Y. Zhao; L. Qian; X. Yu; Y. Gao,EAR-NET: Error Attention Refining Network For Retinal Vessel Segmentation,IEEE,2021,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9647299,"The precise detection of blood vessels in retinal images is crucial to the early diagnosis of the retinal vascular diseases, e.g., diabetic, hypertensive and solar retinopathies. Existing works often fail in predicting the abnormal areas, e.g, sudden brighter and darker areas and are inclined to predict a pixel to background due to the significant class imbalance, leading to high accuracy and specificity while low sensitivity. To that end, we propose a novel error attention refining network (ERA-Net) that is capable of learning and predicting the potential false predictions in a two-stage manner for effective retinal vessel segmentation. The proposed ERA-Net in the refine stage drives the model to focus on and refine the segmentation errors produced in the initial training stage. To achieve this, unlike most previous attention approaches that run in an unsupervised manner, we introduce a novel error attention mechanism which considers the differences between the ground truth and the initial segmentation masks as the ground truth to supervise the attention map learning. Experimental results demonstrate that our method achieves state-of-the-art performance on two common retinal blood vessel datasets. Code is available at this link.",Not Found
 Conferences,Z. Cai; J. Xin; S. Liu; J. Wu; N. Zheng,Architecture and Factor Design of Fully Convolutional Neural Networks for Retinal Vessel Segmentation,IEEE,2018,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8623701,"The retinal vessel segmentation task plays an important role in clinical diagnosis and treatment, especially in cardiovascular diseases such as diabetic retinopathy and hypertensive retinopathy. Recently, the fully convolutional neural network, as a popular learning-based segmentation method, has been demonstrated to yield highly segmentation performance in vessel wall segmentation tasks. However, the major network factors affecting the performance of segmentation are still not obvious. This paper uses the single-factor control variable method to investigates the effects of network architectures (FCN network and U-Net network) and other network factors (pooling times, patch size, number of skip connection, and network depth) on retinal blood vessel segmentation. Our experiments are performed on two public fundus image database DRIVE and STARE. The results show that U-net is better than FCN and skip connections, proper pooling times, dilated convolution is vital to obtain better performance of retinal vessel segmentation.",Retinal vessel segmentation;FCN;U-Net;Segmentation network factors
 Conferences,X. -n. Fan; J. Gong; Y. Yan,Red lesion detection in fundus images based on convolution neural network,IEEE,2019,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8833280,"Early diagnosis of Diabetic Retinopathy (DR) can effectively control and delay the process of deterioration. The traditional detection method uses the manual design features to classify the lesions after the candidate regions are extracted, and the feature extraction effect is poor. This paper mainly studies the method of lesion detection based on convolutional neural network. We propose a lesion detection method based on improved LeNet convolutional neural network. Three innovations are proposed: (1) The network inherits the size of LeNet's convolution kernel and deepens the depth of the network, and can learn more features; (2) The weighted cross entropy loss, which is used for the sample class imbalance problem; (3) a dynamic learning rate based on the rate of change of loss, which is used to deal with overfitting and underfitting. Finally, the experiments in the DIARETDB1 and E-ophtha databases show that the improved LeNet convolutional neural network has achieved good results in the detection of background retinal image lesions.",Color fundus image;Red lesion detection;convolutional neuron network
 Conferences,A. El Tanboly; M. Ismail; A. Switala; M. Mahmoud; A. Soliman; T. Neyer; A. Palacio; A. Hadayer; M. El-Azab; S. Schaal; A. El-Baz,A novel automatic segmentation of healthy and diseased retinal layers from OCT scans,IEEE,2016,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7532330,"This paper introduces a novel framework for segmenting retinal layers from optical coherence tomography (OCT) images. In order to account for the noise and inhomogeneity of OCT scans, especially for diseased ones, the proposed framework is based on unique joint model that combines shape, intensity, and spatial information, and is able to segment 12 distinct retinal layers. First, the shape prior is built using a subset of co-aligned training OCT images. The alignment process is initialized using an innovative method that employs multi-resolution edge tracking which defines control points on the tracked retinal boundaries. The shape model is then adapted during the segmentation process using visual appearance characteristics that are described using pixel-wise image intensities and their spatial interaction features. In order to more accurately model the empirical grey level distribution of OCT images, a linear combination of discrete Gaussians (LCDG) is used that has positive and negative components. Also, in order to accurately account for noise, the model is integrated with a second-order Markov Gibbs random field (MGRF) spatial interaction model. The proposed approach was tested on 200 normal and diseased OCT scans (e.g. Age macular degeneration (AMD), diabetic retinopathy), having their ground truth delineated by retina specialists, then measured using the Dice similarity coefficient (DSC), agreement coefficient (AC1), and average deviation (AD) metrics. The accuracy achieved by the segmentation approach clearly demonstrates the promise it holds for robust segmentation of retinal layers which would aid in the early diagnosis of different retinal abnormalities.",OCT;shape prior;reflectivity;LCDG;MGRF
 Journals,H. Wei; P. Peng,The Segmentation of Retinal Layer and Fluid in SD-OCT Images Using Mutex Dice Loss Based Fully Convolutional Networks,IEEE,2020,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9049406,"Spectral domain optical coherence tomography (SD-OCT) is a non-invasive imaging modality for assessing retinal diseases, such as diabetic retinopathy (DR), which is one of the most prevalent diseases responsible for visual impairment and blindness in the world. The main manifestations of DR are retinal deformation and fluid masses, termed diabetic macular edema (DME), which is the primary biomarker for assessing and diagnosing diseases. In the clinic, ophthalmologists can manually segment retinal layers and fluids to get quantitative and diagnostic information, which is the basement of the final diagnosis. However, this manual segmentation is time-consuming and labor-intensive. To facilitate and promote it, researchers have proposed many automated methods, where most of them usually ignore the priorities in ophthalmology and just regard this task as a standard semantic segmentation task. In this study, we consider the priority of the mutex relationship among different layers and introduce it into the dice loss function to build a novel one, named mutex dice loss (MDL). Besides, we propose a novel fully convolutional network based on our proposed depth max pooling (DMP) to segment retinal layers and fluids in SD-OCT images. Experimental results of the proposed method on two public datasets demonstrate promising performance, which also shows the potential to help ophthalmologists in the diagnostic process of DR or other related diseases.",Diabetic macular edema (DME);retinal layer segmentation;fully convolutional network;mutex dice loss
 Journals,A. Raj; N. A. Shah; A. K. Tiwari; M. G. Martini,Multivariate Regression-Based Convolutional Neural Network Model for Fundus Image Quality Assessment,IEEE,2020,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9044361,"Objectively assessing the perceptual quality of an ocular fundus image is essential for the reliable diagnosis of various ocular diseases. A fair amount of work has been done in this field to date. However, the generalizability of the current work is limited, as the existing quality models were developed and evaluated with data-sets built with limited subjective inputs. This paper aims at addressing this limitation with the following two contributions. First, a new fundus image quality assessment (FIQuA) data-set is presented, containing 1500 fundus images with three classes of quality: Good, Fair, and Poor. Also, for each image, subjective scores (in the range [0-10]) were collected for six quality parameters, including structural and generic properties of the fundus images. Second, a new multivariate regression based convolutional neural network (CNN) model is proposed to predict the fundus image quality. The proposed model consists of two individually trained blocks. The first block consists of four pre-trained models, trained against the subjective scores for the six quality parameters, and aims at deriving the optimized features for classification. Next, the optimized features from each of the four models are ensembled together and transferred to the second block for final classification. The proposed model achieves a strong correlation with the subjective scores, with the values 0.941, 0.954, 0.853, and 0.401 obtained for SROCC, LCC, KCC, and RMSE respectively. Its classification accuracy is 95.66% over the FIQuA data-set, and 98.96% and 88.43% respectively over the two publicly available data-sets DRIMDB and EyeQ.",Fundus image quality assessment;diabetic retinopathy;multivariate regression;convolutional neural network
 Conferences,X. Liu; L. Hu; X. Li; J. Tang,OCTA Retinal Vessel Segmentation Based on Vessel Thickness Inconsistency Loss,IEEE,2022,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9897486,"Optical coherence tomography angiography (OCTA) technology has been applied to retinal examination for clinical diagnosis. OCTA images reveal important details of eye diseases such as diabetic retinopathy (DR), glaucoma and age-related macular degeneration (AMD). DR and AMD are the leading causes of blindness in these diseases. Quantitative analysis of retinal vessel can help doctors diagnose retinal diseases and track the progression of these diseases. In this paper, we propose a new OCTA vessel segmentation framework based on variable vessel thickness. Specifically, to guide the network to adapt to the scale changes of vessels, we construct a vessel structure attention module. It can better capture the vessel structure by guiding the network to pay attention to the vessel edge information and help the network to establish a good context dependency. By assigning corresponding weights to different pixels, it helps the network to better learn vessels of different thicknesses and segment a more complete vessel structure. Finally, the framework is evaluated on the OCTA500 dataset, and experimental results demonstrate the effectiveness of the proposed segmentation framework.",OCTA;deep learning;vessel structure attention;thickness inconsistency
 Early Access Articles,X. Xu; P. Yang; H. Wang; Z. Xiao; G. Xing; X. Zhang; W. Wang; F. Xu; J. Zhang; J. Lei,AV-casNet: Fully Automatic Arteriole-Venule Segmentation and Differentiation in OCT Angiography,IEEE,2022,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9918059,"Automatic segmentation and differentiation of retinal arteriole and venule (AV), defined as small blood vessels directly before and after the capillary plexus, are of great importance for the diagnosis of various eye diseases and systemic diseases, such as diabetic retinopathy, hypertension, and cardiovascular diseases. Optical coherence tomography angiography (OCTA) is a recent imaging modality that provides capillary-level blood flow information. However, OCTA does not have the colorimetric and geometric differences between AV as the fundus photography does. Various methods have been proposed to differentiate AV in OCTA, which typically needs the guidance of other imaging modalities. In this study, we propose a cascaded neural network to automatically segment and differentiate AV solely based on OCTA. A convolutional neural network (CNN) module is first applied to generate an initial segmentation, followed by a graph neural network (GNN) to improve the connectivity of the initial segmentation. Various CNN and GNN architectures are employed and compared. The proposed method is evaluated on multi-center clinical datasets, including 3×3 mm2 and 6×6 mm2 OCTA. The proposed method holds the potential to enrich OCTA image information for the diagnosis of various diseases.",Vessel segmentation;optical coherence tomography angiography;arteriole-venule differentiation;graph neural network
 Conferences,R. Venkatesan; P. S. Chandakkar; B. Li,Simpler Non-Parametric Methods Provide as Good or Better Results to Multiple-Instance Learning,IEEE,2015,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7410656,"Multiple-instance learning (MIL) is a unique learning problem in which training data labels are available only for collections of objects (called bags) instead of individual objects (called instances). A plethora of approaches have been developed to solve this problem in the past years. Popular methods include the diverse density, MILIS and DD-SVM. While having been widely used, these methods, particularly those in computer vision have attempted fairly sophisticated solutions to solve certain unique and particular configurations of the MIL space. In this paper, we analyze the MIL feature space using modified versions of traditional non-parametric techniques like the Parzen window and k-nearest-neighbour, and develop a learning approach employing distances to k-nearest neighbours of a point in the feature space. We show that these methods work as well, if not better than most recently published methods on benchmark datasets. We compare and contrast our analysis with the well-established diverse-density approach and its variants in recent literature, using benchmark datasets including the Musk, Andrews' and Corel datasets, along with a diabetic retinopathy pathology diagnosis dataset. Experimental results demonstrate that, while enjoying an intuitive interpretation and supporting fast learning, these method have the potential of delivering improved performance even for complex data arising from real-world applications.",Not Found
 Conferences,L. K. Pampana; M. S. Rayudu,A Review: Prediction of Multiple Adverse Health Conditions from Retinal Images,IEEE,2020,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9297936,"During the recent years, lifestyle related diseases and disorders such as stress, hypertension and diabetes are increasing at a rapid rate in the middle aged population also These disorders may have greater likelihood of developing multiple adverse health conditions like cardiovascular strokes, cerebrovascular strokes, kidney failures, depression etc. Preventive diagnosis measures are required to diagnose these adverse health hazards in the middle aged group. These days the health care sector is equipped with sophisticated instruments to diagnose the abnormalities in specific organs using different modalities like Computer Tomography(CT), Magnetic Resonance Imaging(MRI), Positron Emission Tomography(PET), Ultrasonography scans, X-Ray, etc. Retinal vascular imaging has its popularity in diagnosing several ocular diseases viz, Diabetic Retinopathy(DR), Age related Macular Degeneration(AMD), Edema, Glaucoma, etc using the latest advancements in Artificial Intelligence with the aid of modalities like Retinal Fundoscopy, Optical Coherence Tomography(OCT), confocal scanning laser ophthalmoscope (cSLO). As per the clinical based studies, the retina shares similar physiological and anatomical features with vital organs hence it is million worthwhile to say that retinal vascular imaging could predict the multiple adverse health conditions like Cardiovascular(CVD), Cerebrovascular(CVS), Chronicle Kidney Diseases(CKD), Breast Cancer and Pulmonary Diseases. The main objective of this review is to study and present the retinal associations related to these life threat adverse diseases., by considering sources from various clinical based studies. The review is concluded by addressing the potential and candidate retinal biomarkers for each of these diseases.",Retinal Imaging;Biomarkers;Health Risk Factors;Cardiovascular diseases;Cerebrovascular diseases
