Document Type,Authors,Title,Source,Year,Link,Abstract,Keywords
Review,"Li, Sicong; Zhao, Ruiwei; Zou, Haidong",Artificial intelligence for diabetic retinopathy,chinese medical journal,2022,Not found,"Diabetic retinopathy (DR) is an important cause of blindness globally, and its prevalence is increasing. Early detection and intervention can help change the outcomes of the disease. The rapid development of artificial intelligence (AI) in recent years has led to new possibilities for the screening and diagnosis of DR. An AI-based diagnostic system for the detection of DR has significant advantages, such as high efficiency, high accuracy, and lower demand for human resources. At the same time, there are shortcomings, such as the lack of standards for development and evaluation and the limited scope of application. This article demonstrates the current applications of AI in the field of DR, existing problems, and possible future development directions.",artificial intelligence; deep learning; diabetic retinopathy
Review,"Huang, Xuan; Wang, Hui; She, Chongyang; Feng, Jing; Liu, Xuhui; Hu, Xiaofeng; Chen, Li; Tao, Yong",Artificial intelligence promotes the diagnosis and screening of diabetic retinopathy,frontiers in endocrinology,2022,Not found,"Deep learning evolves into a new form of machine learning technology that is classified under artificial intelligence (AI), which has substantial potential for large-scale healthcare screening and may allow the determination of the most appropriate specific treatment for individual patients. Recent developments in diagnostic technologies facilitated studies on retinal conditions and ocular disease in metabolism and endocrinology. Globally, diabetic retinopathy (DR) is regarded as a major cause of vision loss. Deep learning systems are effective and accurate in the detection of DR from digital fundus photographs or optical coherence tomography. Thus, using AI techniques, systems with high accuracy and efficiency can be developed for diagnosing and screening DR at an early stage and without the resources that are only accessible in special clinics. Deep learning enables early diagnosis with high specificity and sensitivity, which makes decisions based on minimally handcrafted features paving the way for personalized DR progression real-time monitoring and in-time ophthalmic or endocrine therapies. This review will discuss cutting-edge AI algorithms, the automated detecting systems of DR stage grading and feature segmentation, the prediction of DR outcomes and therapeutics, and the ophthalmic indications of other systemic diseases revealed by AI.",diabetic retinopathy; artificial intelligence; classification; segmentation; diagnosis; screening; prediction
Review,"Bidwai, Pooja; Gite, Shilpa; Pahuja, Kishore; Kotecha, Ketan",A Systematic Literature Review on Diabetic Retinopathy Using an Artificial Intelligence Approach,big data and cognitive computing,2022,Not found,"Diabetic retinopathy occurs due to long-term diabetes with changing blood glucose levels and has become the most common cause of vision loss worldwide. It has become a severe problem among the working-age group that needs to be solved early to avoid vision loss in the future. Artificial intelligence-based technologies have been utilized to detect and grade diabetic retinopathy at the initial level. Early detection allows for proper treatment and, as a result, eyesight complications can be avoided. The in-depth analysis now details the various methods for diagnosing diabetic retinopathy using blood vessels, microaneurysms, exudates, macula, optic discs, and hemorrhages. In most trials, fundus images of the retina are used, which are taken using a fundus camera. This survey discusses the basics of diabetes, its prevalence, complications, and artificial intelligence approaches to deal with the early detection and classification of diabetic retinopathy. The research also discusses artificial intelligence-based techniques such as machine learning and deep learning. New research fields such as transfer learning using generative adversarial networks, domain adaptation, multitask learning, and explainable artificial intelligence in diabetic retinopathy are also considered. A list of existing datasets, screening systems, performance measurements, biomarkers in diabetic retinopathy, potential issues, and challenges faced in ophthalmology, followed by the future scope conclusion, is discussed. To the author, no other literature has analyzed recent state-of-the-art techniques considering the PRISMA approach and artificial intelligence as the core.",artificial intelligence; diabetic retinopathy; domain adaptation; explainable ai; fundus; optical coherence tomography (oct)
Article,"Quellec, Gwenole; Al Hajj, Hassan; Lamard, Mathieu; Conze, Pierre-Henri; Massin, Pascale; Cochener, Beatrice",ExplAIn: Explanatory artificial intelligence for diabetic retinopathy diagnosis,medical image analysis,2021,Not found,"In recent years, Artificial Intelligence (AI) has proven its relevance for medical decision support. However, the black-box nature of successful AI algorithms still holds back their wide-spread deployment. In this paper, we describe an eXplanatory Artificial Intelligence (XAI) that reaches the same level of performance as black-box AI, for the task of classifying Diabetic Retinopathy (DR) severity using Color Fundus Photography (CFP). This algorithm, called ExplAIn, learns to segment and categorize lesions in images; the final image-level classification directly derives from these multivariate lesion segmentations. The novelty of this explanatory framework is that it is trained from end to end, with image supervision only, just like black-box AI algorithms: the concepts of lesions and lesion categories emerge by themselves. For improved lesion localization, foreground/background separation is trained through self-supervision, in such a way that occluding foreground pixels transforms the input image into a healthy-looking image. The advantage of such an architecture is that automatic diagnoses can be explained simply by an image and/or a few sentences. ExplAIn is evaluated at the image level and at the pixel level on various CFP image datasets. We expect this new framework, which jointly offers high classification performance and explainability, to facilitate AI deployment. (c) 2021 Elsevier B.V. All rights reserved.",explanatory artificial intelligence; self-supervised learning; diabetic retinopathy diagnosis
Proceedings Paper,"Rodriguez-Leon, Ciro; Arevalo, William; Banos, Oresti; Villalonga, Claudia",Deep Learning for Diabetic Retinopathy Prediction,"advances in computational intelligence, iwann 2021, pt i",2021,Not found,"Diabetic retinopathy is a complication of diabetes mellitus. Its early diagnosis can prevent its progression and avoid the development of other major complications such as blindness. Deep learning and transfer learning appear in this context as powerful tools to aid in diagnosing this condition. The present work proposes to experiment with different models of pre-trained convolutional neural networks to determine which one fits best the problem of predicting diabetic retinopathy. The Diabetic Retinopathy Detection dataset supported by the EyePACS competition is used for evaluation. Seven pre-trained CNN models implemented in the Keras library developed in Python and, in this case, executed in the Kaggle platform, are used. Results show that no architecture performs better in all evaluation metrics. From a balanced behaviour perspective, the MobileNetV2 model stands out, with execution times almost half that of the slowest CNNs and without falling into overfitting with 20 learning epochs. InceptionResNetV2 stands out from the perspective of best performance, with a Kappa coefficient of 0.7588.",diabetic retinopathy; deep learning; transfer learning
Article,"Saini, Manisha; Susan, Seba",Diabetic retinopathy screening using deep learning for multi-class imbalanced datasets,computers in biology and medicine,2022,Not found,"Screening and diagnosis of diabetic retinopathy disease is a well known problem in the biomedical domain. The use of medical imagery from a patient's eye for detecting the damage caused to blood vessels is a part of the computer-aided diagnosis that has immensely progressed over the past few years due to the advent and success of deep learning. The challenges related to imbalanced datasets, inconsistent annotations, less number of sample images and inappropriate performance evaluation metrics has caused an adverse impact on the performance of the deep learning models. In order to tackle the effect caused by class imbalance, we have done extensive comparative analysis between various state-of-the-art methods on three benchmark datasets of diabetic retinopathy: -Kaggle DR detection, IDRiD and DDR, for classification, object detection and segmentation tasks. This research could serve as a concrete baseline for future research in this field to find appropriate approaches and deep learning architectures for imbalanced datasets.",diabetic retinopathy; deep learning; image classification; object detection; segmentation; transfer learning
Article,"Atwany, Mohammad Z.; Sahyoun, Abdulwahab H.; Yaqub, Mohammad",Deep Learning Techniques for Diabetic Retinopathy Classification: A Survey,ieee access,2022,Not found,"Diabetic Retinopathy (DR) is a degenerative disease that impacts the eyes and is a consequence of Diabetes mellitus, where high blood glucose levels induce lesions on the eye retina. Diabetic Retinopathy is regarded as the leading cause of blindness for diabetic patients, especially the working-age population in developing nations. Treatment involves sustaining the patient's current grade of vision since the disease is irreversible. Early detection of Diabetic Retinopathy is crucial in order to sustain the patient's vision effectively. The main issue involved with DR detection is that the manual diagnosis process is very time, money, and effort consuming and involves an ophthalmologist's examination of eye retinal fundus images. The latter also proves to be more difficult, particularly in the early stages of the disease when disease features are less prominent in the images. Machine learning-based medical image analysis has proven competency in assessing retinal fundus images, and the utilization of deep learning algorithms has aided the early diagnosis of Diabetic Retinopathy (DR). This paper reviews and analyzes state-of-the-art deep learning methods in supervised, self-supervised, and Vision Transformer setups, proposing retinal fundus image classification and detection. For instance, referable, non-referable, and proliferative classifications of Diabetic Retinopathy are reviewed and summarized. Moreover, the paper discusses the available retinal fundus datasets for Diabetic Retinopathy that are used for tasks such as detection, classification, and segmentation. The paper also assesses research gaps in the area of DR detection/classification and addresses various challenges that need further study and investigation.",diabetes; retina; retinopathy; lesions; deep learning; diseases; biomedical imaging; diabetic retinopathy; diabetes mellitus; diabetic macular edema; lesion; microaneurysms; haemorrhages; exudates; classification; supervised learning; self-supervised learning; transformers
Article,"Hassan, Doaa; Gill, Hunter Mathias; Happe, Michael; Bhatwadekar, Ashay D.; Hajrasouliha, Amir R.; Janga, Sarath Chandra",Combining transfer learning with retinal lesion features for accurate detection of diabetic retinopathy,frontiers in medicine,2022,Not found,"Diabetic retinopathy (DR) is a late microvascular complication of Diabetes Mellitus (DM) that could lead to permanent blindness in patients, without early detection. Although adequate management of DM via regular eye examination can preserve vision in in 98% of the DR cases, DR screening and diagnoses based on clinical lesion features devised by expert clinicians; are costly, time-consuming and not sufficiently accurate. This raises the requirements for Artificial Intelligent (AI) systems which can accurately detect DR automatically and thus preventing DR before affecting vision. Hence, such systems can help clinician experts in certain cases and aid ophthalmologists in rapid diagnoses. To address such requirements, several approaches have been proposed in the literature that use Machine Learning (ML) and Deep Learning (DL) techniques to develop such systems. However, these approaches ignore the highly valuable clinical lesion features that could contribute significantly to the accurate detection of DR. Therefore, in this study we introduce a framework called DR-detector that employs the Extreme Gradient Boosting (XGBoost) ML model trained via the combination of the features extracted by the pretrained convolutional neural networks commonly known as transfer learning (TL) models and the clinical retinal lesion features for accurate detection of DR. The retinal lesion features are extracted via image segmentation technique using the UNET DL model and captures exudates (EXs), microaneurysms (MAs), and hemorrhages (HEMs) that are relevant lesions for DR detection. The feature combination approach implemented in DR-detector has been applied to two common TL models in the literature namely VGG-16 and ResNet-50. We trained the DR-detector model using a training dataset comprising of 1,840 color fundus images collected from e-ophtha, retinal lesions and APTOS 2019 Kaggle datasets of which 920 images are healthy. To validate the DR-detector model, we test the model on external dataset that consists of 81 healthy images collected from High-Resolution Fundus (HRF) dataset and MESSIDOR-2 datasets and 81 images with DR signs collected from Indian Diabetic Retinopathy Image Dataset (IDRID) dataset annotated for DR by expert. The experimental results show that the DR-detector model achieves a testing accuracy of 100% in detecting DR after training it with the combination of ResNet-50 and lesion features and 99.38% accuracy after training it with the combination of VGG-16 and lesion features. More importantly, the results also show a higher contribution of specific lesion features toward the performance of the DR-detector model. For instance, using only the hemorrhages feature to train the model, our model achieves an accuracy of 99.38 in detecting DR, which is higher than the accuracy when training the model with the combination of all lesion features (89%) and equal to the accuracy when training the model with the combination of all lesions and VGG-16 features together. This highlights the possibility of using only the clinical features, such as lesions that are clinically interpretable, to build the next generation of robust artificial intelligence (AI) systems with great clinical interpretability for DR detection. The code of the DR-detector framework is available on GitHub at and can be readily employed for detecting DR from retinal image datasets.",retinal image; diabetic retinopathy; deep learning; transfer learning; lesion features
Review,"Cheung, Carol Y.; Tang, Fangyao; Ting, Daniel Shu Wei; Tan, Gavin Siew Wei; Wong, Tien Yin",Artificial Intelligence in Diabetic Eye Disease Screening,asia-pacific journal of ophthalmology,2019,Not found,"Systematic or national screening programs for diabetic retinopathy (DR) and diabetic macular edema (DME), using digital fundus photography and optical coherence tomography (OCT), are currently implemented at primary care level, aiming to provide timely referral for vision-threatening DR and DME to ophthalmologists for timely treatment and vision loss prevention. However, interpretation of retinal images requires specialized knowledge and expertise in diabetic eye disease. Furthermore, current DR screening programs are capital- and labor-intensive, which makes it difficult to rapidly scale up and expand diabetic eye screening to meet the needs of this growing global epidemic. Deep learning (DL), a new branch of machine learning technology under the broad term of artificial intelligence (AI), has made remarkable breakthrough in medical imaging in particular for pattern recognition and image classification. In ophthalmology, AI and DL technology has been developed from big image datasets in assessment of retinal photographs for detection and screening of DR as well as the segmentation and assessment of OCT images for diagnosis and screening of DME. This review aimed to summarize the current progress and the development of using AI and DL technology for diabetic eye disease screening as well as current challenges in the actual implementation of DL in screening programs, and translating DL research into direct clinical applications of screening in a community setting.",artificial intelligence; deep learning; diabetic retinopathy; optical coherence tomography; screening
Review,"Das, Dolly; Biswas, Saroj Kr; Bandyopadhyay, Sivaji",A critical review on diagnosis of diabetic retinopathy using machine learning and deep learning,multimedia tools and applications,2022,Not found,"Diabetic Retinopathy (DR) is a health condition caused due to Diabetes Mellitus (DM). It causes vision problems and blindness due to disfigurement of human retina. According to statistics, 80% of diabetes patients battling from long diabetic period of 15 to 20 years, suffer from DR. Hence, it has become a dangerous threat to the health and life of people. To overcome DR, manual diagnosis of the disease is feasible but overwhelming and cumbersome at the same time and hence requires a revolutionary method. Thus, such a health condition necessitates primary recognition and diagnosis to prevent DR from developing into severe stages and prevent blindness. Innumerable Machine Learning (ML) models are proposed by researchers across the globe, to achieve this purpose. Various feature extraction techniques are proposed for extraction of DR features for early detection. However, traditional ML models have shown either meagre generalization throughout feature extraction and classification for deploying smaller datasets or consumes more of training time causing inefficiency in prediction while using larger datasets. Hence Deep Learning (DL), a new domain of ML, is introduced. DL models can handle a smaller dataset with help of efficient data processing techniques. However, they generally incorporate larger datasets for their deep architectures to enhance performance in feature extraction and image classification. This paper gives a detailed review on DR, its features, causes, ML models, state-of-the-art DL models, challenges, comparisons and future directions, for early detection of DR.",diabetic retinopathy; image processing; machine learning; retinal lesions; feature extraction; deep learning
Review,"Gensure, Rebekah H.; Chiang, Michael F.; Campbell, John P.",Artificial intelligence for retinopathy of prematurity,current opinion in ophthalmology,2020,Not found,"Purpose of review In this article, we review the current state of artificial intelligence applications in retinopathy of prematurity (ROP) and provide insight on challenges as well as strategies for bringing these algorithms to the bedside. Recent findings In the past few years, there has been a dramatic shift from machine learning approaches based on feature extraction to 'deep' convolutional neural networks for artificial intelligence applications. Several artificial intelligence for ROP approaches have demonstrated adequate proof-of-concept performance in research studies. The next steps are to determine whether these algorithms are robust to variable clinical and technical parameters in practice. Integration of artificial intelligence into ROP screening and treatment is limited by generalizability of the algorithms to maintain performance on unseen data and integration of artificial intelligence technology into new or existing clinical workflows. Real-world implementation of artificial intelligence for ROP diagnosis will require massive efforts targeted at developing standards for data acquisition, true external validation, and demonstration of feasibility. We must now focus on ethical, technical, clinical, regulatory, and financial considerations to bring this technology to the infant bedside to realize the promise offered by this technology to reduce preventable blindness from ROP.",artificial intelligence; deep learning; machine learning; retinopathy of prematurity
Review,"Tsiknakis, Nikos; Theodoropoulos, Dimitris; Manikis, Georgios; Ktistakis, Emmanouil; Boutsora, Ourania; Berto, Alexa; Scarpa, Fabio; Scarpa, Alberto; Fotiadis, Dimitrios, I; Marias, Kostas",Deep learning for diabetic retinopathy detection and classification based on fundus images: A review,computers in biology and medicine,2021,Not found,"Diabetic Retinopathy is a retina disease caused by diabetes mellitus and it is the leading cause of blindness globally. Early detection and treatment are necessary in order to delay or avoid vision deterioration and vision loss. To that end, many artificial-intelligence-powered methods have been proposed by the research community for the detection and classification of diabetic retinopathy on fundus retina images. This review article provides a thorough analysis of the use of deep learning methods at the various steps of the diabetic retinopathy detection pipeline based on fundus images. We discuss several aspects of that pipeline, ranging from the datasets that are widely used by the research community, the preprocessing techniques employed and how these accelerate and improve the models' performance, to the development of such deep learning models for the diagnosis and grading of the disease as well as the localization of the disease's lesions. We also discuss certain models that have been applied in real clinical settings. Finally, we conclude with some important insights and provide future research directions.",artificial intelligence; classification; deep learning; detection; diabetic retinopathy; fundus; retina; review; segmentation
Review,"Sheng, Bin; Chen, Xiaosi; Li, Tingyao; Ma, Tianxing; Yang, Yang; Bi, Lei; Zhang, Xinyuan",An overview of artificial intelligence in diabetic retinopathy and other ocular diseases,frontiers in public health,2022,Not found,"Artificial intelligence (AI), also known as machine intelligence, is a branch of science that empowers machines using human intelligence. AI refers to the technology of rendering human intelligence through computer programs. From healthcare to the precise prevention, diagnosis, and management of diseases, AI is progressing rapidly in various interdisciplinary fields, including ophthalmology. Ophthalmology is at the forefront of AI in medicine because the diagnosis of ocular diseases heavy reliance on imaging. Recently, deep learning-based AI screening and prediction models have been applied to the most common visual impairment and blindness diseases, including glaucoma, cataract, age-related macular degeneration (ARMD), and diabetic retinopathy (DR). The success of AI in medicine is primarily attributed to the development of deep learning algorithms, which are computational models composed of multiple layers of simulated neurons. These models can learn the representations of data at multiple levels of abstraction. The Inception-v3 algorithm and transfer learning concept have been applied in DR and ARMD to reuse fundus image features learned from natural images (non-medical images) to train an AI system with a fraction of the commonly used training data (<1%). The trained AI system achieved performance comparable to that of human experts in classifying ARMD and diabetic macular edema on optical coherence tomography images. In this study, we highlight the fundamental concepts of AI and its application in these four major ocular diseases and further discuss the current challenges, as well as the prospects in ophthalmology.",artificial intelligence; diabetic retinopathy; glaucoma; cataract; age-related macular degeneration
Article,"Wang, Juan; Bai, Yujing; Xia, Bin",Simultaneous Diagnosis of Severity and Features of Diabetic Retinopathy in Fundus Photography Using Deep Learning,ieee journal of biomedical and health informatics,2020,Not found,"Deep learning methods for diabetic retinopathy (DR) diagnosis are usually criticized as being lack of interpretability in the diagnostic result, thus limiting their application in clinic. Simultaneous prediction of DR related features during the DR severity diagnosis is able to resolve this issue by providing supporting evidence (i.e. DR related features) for the diagnostic result (i.e. DR severity). In this study, we propose a hierarchical multi-task deep learning framework for simultaneous diagnosis of DR severity and DR related features in fundus images. A hierarchical structure is introduced to incorporate the casual relationship between DR related features and DR severity levels. In the experiments, the proposed approach was evaluated on two independent testing sets using quadratic weighted Cohen's kappa coefficient, receiver operating characteristic analysis, and precision-recall analysis. A grader study was also conducted to compare the performance of the proposed approach with those of general ophthalmologists with different levels of experience. The results demonstrate that the proposed approach could improve the performance for both DR severity diagnosis and DR related feature detection when comparing with the traditional deep learning-based methods. It achieves performance close to general ophthalmologists with five years of experience when diagnosing DR severity levels, and general ophthalmologists with ten years of experience for referable DR detection.",feature extraction; task analysis; head; machine learning; diabetes; retinopathy; photography; diabetic retinopathy (dr); dr severity; dr related features; deep learning
Article,"Arsalan, Muhammad; Owais, Muhammad; Mahmood, Tahir; Cho, Se Woon; Park, Kang Ryoung",Aiding the Diagnosis of Diabetic and Hypertensive Retinopathy Using Artificial Intelligence-Based Semantic Segmentation,journal of clinical medicine,2019,Not found,"Automatic segmentation of retinal images is an important task in computer-assisted medical image analysis for the diagnosis of diseases such as hypertension, diabetic and hypertensive retinopathy, and arteriosclerosis. Among the diseases, diabetic retinopathy, which is the leading cause of vision detachment, can be diagnosed early through the detection of retinal vessels. The manual detection of these retinal vessels is a time-consuming process that can be automated with the help of artificial intelligence with deep learning. The detection of vessels is difficult due to intensity variation and noise from non-ideal imaging. Although there are deep learning approaches for vessel segmentation, these methods require many trainable parameters, which increase the network complexity. To address these issues, this paper presents a dual-residual-stream-based vessel segmentation network (Vess-Net), which is not as deep as conventional semantic segmentation networks, but provides good segmentation with few trainable parameters and layers. The method takes advantage of artificial intelligence for semantic segmentation to aid the diagnosis of retinopathy. To evaluate the proposed Vess-Net method, experiments were conducted with three publicly available datasets for vessel segmentation: digital retinal images for vessel extraction (DRIVE), the Child Heart Health Study in England (CHASE-DB1), and structured analysis of retina (STARE). Experimental results show that Vess-Net achieved superior performance for all datasets with sensitivity (Se), specificity (Sp), area under the curve (AUC), and accuracy (Acc) of 80.22%, 98.1%, 98.2%, and 96.55% for DRVIE; 82.06%, 98.41%, 98.0%, and 97.26% for CHASE-DB1; and 85.26%, 97.91%, 98.83%, and 96.97% for STARE dataset.",diabetic retinopathy; retinal vessels; vessel segmentation; vess-net
Review,"Lakshminarayanan, Vasudevan; Kheradfallah, Hoda; Sarkar, Arya; Balaji, Janarthanam Jothi",Automated Detection and Diagnosis of Diabetic Retinopathy: A Comprehensive Survey,journal of imaging,2021,Not found,"Diabetic Retinopathy (DR) is a leading cause of vision loss in the world. In the past few years, artificial intelligence (AI) based approaches have been used to detect and grade DR. Early detection enables appropriate treatment and thus prevents vision loss. For this purpose, both fundus and optical coherence tomography (OCT) images are used to image the retina. Next, Deep-learning (DL)-/machine-learning (ML)-based approaches make it possible to extract features from the images and to detect the presence of DR, grade its severity and segment associated lesions. This review covers the literature dealing with AI approaches to DR such as ML and DL in classification and segmentation that have been published in the open literature within six years (2016-2021). In addition, a comprehensive list of available DR datasets is reported. This list was constructed using both the PICO (P-Patient, I-Intervention, C-Control, O-Outcome) and Preferred Reporting Items for Systematic Review and Meta-analysis (PRISMA) 2009 search strategies. We summarize a total of 114 published articles which conformed to the scope of the review. In addition, a list of 43 major datasets is presented.",diabetic retinopathy; artificial intelligence; deep learning; machine-learning; datasets; fundus image; optical coherence tomography; ophthalmology
Review,"Mateen, Muhammad; Wen, Junhao; Hassan, Mehdi; Nasrullah, Nasrullah; Sun, Song; Hayat, Shaukat","Automatic Detection of Diabetic Retinopathy: A Review on Datasets, Methods and Evaluation Metrics",ieee access,2020,Not found,"Diabetic retinopathy (DR) is a fast-spreading disease across the globe, which is caused by diabetes. The DR may lead the diabetic patients to complete vision loss. In this scenario, early identification of DR is more essential to recover the eyesight and provide help for timely treatment. The detection of DR can be manually performed by ophthalmologists and can also be done by an automated system. In the manual system, analysis and explanation of retinal fundus images need ophthalmologists, which is a time-consuming and very expensive task, but in the automated system, artificial intelligence is used to perform an imperative role in the area of ophthalmology and specifically in the early detection of diabetic retinopathy over the traditional detection approaches. Recently, numerous advanced studies related to the identification of DR have been reported. This paper presents a detailed review of the detection of DR with three major aspects; retinal datasets, DR detection methods, and performance evaluation metrics. Furthermore, this study also covers the author's observations and provides future directions in the field of diabetic retinopathy to overcome the research challenges for the research community.",diabetes; retina; retinopathy; feature extraction; lesions; blood vessels; biomedical imaging; artificial intelligence; deep learning; diabetic retinopathy; fundus images; machine learning; ophthalmology
Article,"Shorfuzzaman, Mohammad; Hossain, M. Shamim; El Saddik, Abdulmotaleb",An Explainable Deep Learning Ensemble Model for Robust Diagnosis of Diabetic Retinopathy Grading,acm transactions on multimedia computing communications and applications,2021,Not found,"Diabetic retinopathy (DR) is one of the most common causes of vision loss in people who have diabetes for a prolonged period. Convolutional neural networks (CNNs) have become increasingly popular for computer-aided DR diagnosis using retinal fundus images. While these CNNs are highly reliable, their lack of sufficient explainability prevents them from being widely used in medical practice. In this article, we propose a novel explainable deep learning ensemble model where weights from different models are fused into a single model to extract salient features from various retinal lesions found on fundus images. The extracted features are then fed to a custom classifier for the final diagnosis of DR severity level. The model is trained on an APTOS dataset containing retinal fundus images of various DR grades using a cyclical learning rates strategy with an automatic learning rate finder for decaying the learning rate to improve model accuracy. We develop an explainability approach by leveraging gradient-weighted class activation mapping and shapely adaptive explanations to highlight the areas of fundus images that are most indicative of different DR stages. This allows ophthalmologists to view our model's decision in a way that they can understand. Evaluation results using three different datasets (APTOS, MESSIDOR, IDRiD) show the effectiveness of our model, achieving superior classification rates with a high degree of precision (0.970), sensitivity (0.980), and AUC (0.978). We believe that the proposed model, which jointly offers state-of-the-art diagnosis performance and explainability, will address the black-box nature of deep CNN models in robust detection of DR grading.",explainable deep cnn; diabetic retinopathy diagnosis; ensemble model; transfer learning; retinal fundus images
Proceedings Paper,"Tymchenko, Borys; Marchenko, Philip; Spodarets, Dmitry",Deep Learning Approach to Diabetic Retinopathy Detection,icpram: proceedings of the 9th international conference on pattern recognition applications and methods,2020,Not found,"Diabetic retinopathy is one of the most threatening complications of diabetes that leads to permanent blindness if left untreated. One of the essential challenges is early detection, which is very important for treatment success. Unfortunately, the exact identification of the diabetic retinopathy stage is notoriously tricky and requires expert human interpretation of fundus images. Simplification of the detection step is crucial and can help millions of people. Convolutional neural networks (CNN) have been successfully applied in many adjacent subjects, and for diagnosis of diabetic retinopathy itself. However, the high cost of big labeled datasets, as well as inconsistency between different doctors, impede the performance of these methods. In this paper, we propose an automatic deep-learning-based method for stage detection of diabetic retinopathy by single photography of the human fundus. Additionally, we propose the multistage approach to transfer learning, which makes use of similar datasets with different labeling. The presented method can be used as a screening method for early detection of diabetic retinopathy with sensitivity and specificity of 0.99 and is ranked 54 of 2943 competing methods (quadratic weighted kappa score of 0.925466) on APTOS 2019 Blindness Detection Dataset (13000 images).",deep learning; diabetic retinopathy; deep convolutional neural network; multi-target learning; ordinal regression; classification; shap; kaggle; aptos
Article; Early Access,"Ozbay, Erdal",An active deep learning method for diabetic retinopathy detection in segmented fundus images using artificial bee colony algorithm,artificial intelligence review,0,Not found,"Retinal fundus image analysis (RFIA) is frequently used in diabetic retinopathy (DR) scans to determine the risk of blindness in diabetic patients. Ophthalmologists receive support from various RFIA programs to cope with the detection of visual impairments. In this article, active deep learning (ADL) using new multi-layer architecture for automatic recognition of DR stages is presented. In order to facilitate the detection of retinal lesions in the ADL system preprocessing, the image is segmented using the artificial bee colony (ABC) algorithm with a threshold value determined according to the results of the image histogram. Besides, a tag-efficient convolutional neural networks (CNN) architecture known as ADL-CNN has been developed to automatically extract segmented retinal features. This model has a two-stage process. In the first, images are selected to learn simple or complex retinal features using basic accuracy labels in the training examples. Second, useful masks are provided with key lesion features and segment areas of interest within the retinal image. Performance evaluation of the proposed ADL-CNN model is made by comparing the most advanced methods using the same dataset. The efficiency of the system is made by measuring statistical metrics such as classification accuracy (ACC), sensitivity (SE), specificity (SP), and F-measure. The ADL-CNN model applied to the EyePacs dataset containing 35,122 retinal images yielded 99.66% ACC, 93.76% SE, 96.71% SP, and 94.58% F-measure. In this respect, it can be said that the proposed method shows high performance in detecting DR lesions from various fundus images and determining the severity level.",artificial bee colony; active deep learning; convolutional neural network; diabetic retinopathy; image segmentation
Article,"Canayaz, Murat",Classification of diabetic retinopathy with feature selection over deep features using nature-inspired wrapper methods,applied soft computing,2022,Not found,"Diabetic retinopathy (DR) is the most common cause of blindness in middle-aged people. It shows that an automatic image evaluation system is needed in the diagnosis of this disease due to the low number of scans. It is critical to meet this need that these systems are large-scale, cost-effective, and minimally invasive screening programs. With the use of deep learning techniques, it has become possible to develop these systems faster. In this study, a new approach based on feature selection with wrapper methods used for fundus images is presented that can be used for the classification of diabetic retinopathy. The fundus images used in the approach were improved with image processing techniques, thus eliminating unnecessary dark areas in the image. In this new approach, the most effective features are selected by wrapping methods over 512 deep features obtained from EfficientNet and DenseNet models. Binary Bat Algorithm (BBA), Equilibrium Optimizer (EO), Gravity Search Algorithm (GSA), and Gray Wolf Optimizer (GWO) were chosen as wrappers for the proposed approach. Selected features are classified by support vector machines and random forest machine learning methods. Considering the performance of this new approach, it gives the highest value of 96.32 accuracy and 0.98 kappa. These performance values were obtained with a minimum of 250 selected features. The Asia Pacific Tele-Ophthalmology Society (APTOS) dataset used to obtain these values was taken from a competition organized by Kaggle. The highest kappa value in this competition was reported as 0.93. This parameter clearly demonstrates the success of our approach. (C) 2022 Elsevier B.V. All rights reserved.",diabetic retinopathy; wrapper methods; deep learning models; feature selection
Article,"Roser, Pia; Grohmann, Carsten; Aberle, Jens; Spitzer, Martin S.; Kromer, Robert",Evaluation of the implementation of an approved artificial intelligence system for the detection of diabetic retinopathy,diabetologie und stoffwechsel,2021,Not found,"Introduction The aim of this study was to evaluate the accuracy of an artificial intelligence (AI)-based analysis of fundus photographs compared to ophthalmologists in diabetic retinopathy screening in an internal medicine clinic. In addition, the total examination time as well as the patient and examiner satisfaction were surveyed. Methods In the study, 112 outpatients received fundus photography with automated diagnosis of diabetic retinopathy (DR) via the IDx-DR system (Digital Diagnostics). The images were taken with the Topcon TRC-NW400 camera (Topcon Corp. Japan). Inclusion criterion was a diagnosis of diabetes mellitus type 1, 2, or 3. Patients who could not be imaged with sufficient quality in miosis were imaged in mydriasis. Results Of 112 patients, analysis was possible in 107 patients (95.5 %) by grading by IDx-DR, based on fundus images - vs. 103 patients (91.9 %) by grading by ophthalmologists, based on the same, high-resolution fundus images. In the remaining patients, grading was possible by funduscopy alone. There was a highly significant correlation regarding the assessment of the severity of diabetic retinopathy between the examiner and the IDx-DR system (Correlation coefficient (r) = 0.8738; p < 0.0001). Patient satisfaction was 4.5 +/- 0.6 [1-5], and total examination time in miosis averaged 3:04 +/- 0: 28 [min:sec]. Conclusion Retinopathy screening using IDx-DR enables automated diagnosis based on fundus photographs with a robust, technical and clinical workflow that allows timely and reliable assessment of diabetic retinopathy and is associated with high patient satisfaction.",diabetic retinopathy; artificial intelligence; automated grading
Article,"Seth, Shikhar; Agarwal, Basant",A hybrid deep learning model for detecting diabetic retinopathy,journal of statistics & management systems,2018,Not found,"Diabetes affects large number of people all over the world and is a very common disease in India. People having diabetes are very likely to be affected by diabetic retinopathy which causes blindness. Diagnosis of this disease at an early stage can help in completely eliminating it and hence preserve the person's vision. In this paper, we propose a hybrid deep learning based approach for detection of diabetic retinopathy in fundus photographs. We use convolutional neural network with linear support vector machine to train the network on standard benchmark dataset EyePACS dataset. Experimental results show high sensitivity and specificity achieved in detecting diabetic retinopathy by our proposed model.",diabetic retinopathy (dr); convolutional neural network; deep learning; svm
Article,"Tsai, Ching-Yao; Chen, Chueh-Tan; Chen, Guan-An; Yeh, Chun-Fu; Kuo, Chin-Tzu; Hsiao, Ya-Chuan; Hu, Hsiao-Yun; Tsai, I-Lun; Wang, Ching-Hui; Chen, Jian-Ren; Huang, Su-Chen; Lu, Tzu-Chieh; Woung, Lin-Chung",Necessity of Local Modification for Deep Learning Algorithms to Predict Diabetic Retinopathy,international journal of environmental research and public health,2022,Not found,"Deep learning (DL) algorithms are used to diagnose diabetic retinopathy (DR). However, most of these algorithms have been trained using global data or data from patients of a single region. Using different model architectures (e.g., Inception-v3, ResNet101, and DenseNet121), we assessed the necessity of modifying the algorithms for universal society screening. We used the open-source dataset from the Kaggle Diabetic Retinopathy Detection competition to develop a model for the detection of DR severity. We used a local dataset from Taipei City Hospital to verify the necessity of model localization and validated the three aforementioned models with local datasets. The experimental results revealed that Inception-v3 outperformed ResNet101 and DenseNet121 with a foreign global dataset, whereas DenseNet121 outperformed Inception-v3 and ResNet101 with the local dataset. The quadratic weighted kappa score (kappa) was used to evaluate the model performance. All models had 5-8% higher kappa for the local dataset than for the foreign dataset. Confusion matrix analysis revealed that, compared with the local ophthalmologists' diagnoses, the severity predicted by the three models was overestimated. Thus, DL algorithms using artificial intelligence based on global data must be locally modified to ensure the applicability of a well-trained model to make diagnoses in clinical environments.",diabetic retinopathy; deep learning algorithms; model localised; taiwan; predict
Review,"Hassan, Syed Ale; Akbar, Shahzad; Rehman, Amjad; Saba, Tanzila; Kolivand, Hoshang; Bahaj, Saeed Ali",Recent Developments in Detection of Central Serous Retinopathy Through Imaging and Artificial Intelligence Techniques-A Review,ieee access,2021,Not found,"Central Serous Retinopathy (CSR) or Central Serous Chorioretinopathy (CSC) is a significant disease that causes blindness and vision loss among millions of people worldwide. It transpires as a result of accumulation of watery fluids behind the retina. Therefore, detection of CSR at early stages allows preventive measures to avert any impairment to the human eye. Traditionally, several manual methods for detecting CSR have been developed in the past; however, they have shown to be imprecise and unreliable. Consequently, Artificial Intelligence (AI) services in the medical field, including automated CSR detection, are now possible to detect and cure this disease. This review assessed a variety of innovative technologies and researches that contribute to the automatic detection of CSR. In this review, various CSR disease detection techniques, broadly classified into two categories: a) CSR detection based on classical imaging technologies, and b) CSR detection based on Machine/Deep Learning methods, have been reviewed after an elaborated evaluation of 29 different relevant articles. Additionally, it also goes over the advantages, drawbacks and limitations of a variety of traditional imaging techniques, such as Optical Coherence Tomography Angiography (OCTA), Fundus Imaging and more recent approaches that utilize Artificial Intelligence techniques. Finally, it is concluded that the most recent Deep Learning (DL) classifiers deliver accurate, fast, and reliable CSR detection. However, more research needs to be conducted on publicly available datasets to improve computation complexity for the reliable detection and diagnosis of CSR disease.",retina; imaging; retinopathy; artificial intelligence; visualization; photography; angiography; central serous retinopathy; deep learning; fundus images; machine learning; optical coherence tomography images
Article,"Martinez-Murcia, Francisco J.; Ortiz, Andres; Ramirez, Javier; Gorriz, Juan M.; Cruz, Ricardo",Deep residual transfer learning for automatic diagnosis and grading of diabetic retinopathy,neurocomputing,2021,Not found,"Evaluation and diagnosis of retina pathology is usually made via the analysis of different image modal-ities that allow to explore its structure. The most popular retina image method is retinography, a tech-nique that displays the fundus of the eye, including the retina and other structures. Retinography is the most common imaging method to diagnose retina diseases such as Diabetic Retinopathy (DB) or Macular Edema (ME). However, retinography evaluation to score the image according to the disease grade presents difficulties due to differences in contrast, brightness and the presence of artifacts. Therefore, it is mainly done via manual analysis; a time consuming task that requires a trained clinician to examine and evaluate the images. In this paper, we present a computer aided diagnosis tool that takes advantage of the performance provided by deep learning architectures for image analysis. Our proposal is based on a deep residual convolutional neural network for extracting discriminatory features with no prior complex image transformations to enhance the image quality or to highlight specific structures. Moreover, we used the transfer learning paradigm to reuse layers from deep neural networks previously trained on the ImageNet dataset, under the hypothesis that first layers capture abstract features than can be reused for different problems. Experiments using different convolutional architectures have been car-ried out and their performance has been evaluated on the MESSIDOR database using cross-validation. Best results were found using a ResNet50-based architecture, showing an AUC of 0.93 for grades 0 + 1, AUC of 0.81 for grade 2 and AUC of 0.92 for grade 3 labelling, as well as AUCs higher than 0.97 when con -sidering a binary classification problem (grades 0 vs 3). (c) 2020 Published by Elsevier B.V.",deep learning; residual learning; transfer learning; convolutional neural network; retinography; diabetic retinopathy
Article,"Lahmar, Chaymaa; Idri, Ali",On the value of deep learning for diagnosing diabetic retinopathy,health and technology,2022,Not found,"Diabetic retinopathy (DR) is one of the main causes of vision loss around the world. The early diagnosis of this disease can help in treating it efficiently. Deep learning (DL) is rapidly becoming the state of the art, leading to enhanced performance in various medical applications such as diabetic retinopathy and breast cancer. In this paper, we conduct an empirical evaluation of seven convolutional neural networks (CNN) architectures for an automatic binary classification of the referable diabetic retinopathy; the DL architectures (Inception_ResNet_V2, Inception_V3, ResNet50, VGG16, VGG19, MobileNet_V2 and DenseNet201) were evaluated and compared in terms of accuracy, sensitivity, specificity, precision and F1-score using the Scott Knott test and the Borda count voting method. All the empirical evaluations were over three datasets: APTOS, Kaggle DR and the Messidor-2, using a k-fold cross validation method. Experiments showed the importance of using deep learning in the classification of DR since the seven models gave a high accuracy values. Furthermore, DenseNet201 and mobileNet_V2 were the top two performing techniques respectively. DenseNet201 provided the best performance for the Kaggle and Messidor-2 datasets with an accuracy equal to 84.74% and 85.79% respectively. MobileNet_V2 provided the best performance in the APTOS dataset with an accuracy equal to 93.09%. As for the ResNet50, Inception_V3 and Inception_ResNet_V2, they were the worst performing compared to the other DL techniques. Therefore, we recommend the use of DenseNet201 and MobileNet_V2 for the detection of the referable DR since they provided the best performances on the three datasets.",medical images; diabetic retinopathy; convolutional neural networks; deep learning
Article,"Shankar, K.; Perumal, Eswaran; Elhoseny, Mohamed; Nguyen, Phong Thanh",An IoT-Cloud Based Intelligent Computer-Aided Diagnosis of Diabetic Retinopathy Stage Classification Using Deep Learning Approach,cmc-computers materials & continua,2021,Not found,"Diabetic retinopathy (DR) is a disease with an increasing prevalence and the major reason for blindness among working-age population. The possibility of severe vision loss can be extensively reduced by timely diagnosis and treatment. An automated screening for DR has been identified as an effective method for early DR detection, which can decrease the workload associated to manual grading as well as save diagnosis costs and time. Several studies have been carried out to develop automated detection and classification models for DR. This paper presents a new IoT and cloud-based deep learning for healthcare diagnosis of Diabetic Retinopathy (DR). The proposed model incorporates different processes namely data collection, preprocessing, segmentation, feature extraction and classification. At first, the IoT-based data collection process takes place where the patient wears a head mounted camera to capture the retinal fundus image and send to cloud server. Then, the contrast level of the input DR image gets increased in the preprocessing stage using Contrast Limited Adaptive Histogram Equalization (CLAHE) model. Next, the preprocessed image is segmented using Adaptive Spatial Kernel distance measure-based Fuzzy C-Means clustering (ASKFCM) model. Afterwards, deep Convolution Neural Network (CNN) based Inception v4 model is applied as a feature extractor and the resulting feature vectors undergo classification in line with the Gaussian Naive Bayes (GNB) model. The proposed model was tested using a benchmark DR MESSIDOR image dataset and the obtained results showcased superior performance of the proposed model over other such models compared in the study.",deep learning; classification; gaussian naive bayes; feature extraction; diabetic retinopathy
Proceedings Paper,"Islam, Kh Tohidul; Wijewickrema, Sudanthi; O'Leary, Stephen",Identifying Diabetic Retinopathy from OCT Images using Deep Transfer Learning with Artificial Neural Networks,2019 ieee 32nd international symposium on computer-based medical systems (cbms),2019,Not found,"Diabetic retinopathy occurs when the blood vessels inside the retina are damaged as a result of diabetes. Early diagnosis and treatment of this disease is crucial to avoid blindness. Analysis of retinal images such as funduscopy, ultrasonography, and optical coherence tomography (OCT) is typically used in the diagnosis of diabetic retinopathy. In recent years, various automated techniques including deep learning have been used for this purpose. In this paper, we explore how to use deep transfer learning for the diagnosis of diabetic retinopathy using OCT images. We retrain existing deep learning models for this task and investigate how a retrained model can be optimized. We demonstrate that using an optimized pre-trained model as a feature extractor and training a conventional classifier on these features is an effective way to diagnose diabetic retinopathy using OCT images. We show through experiments that the proposed method outperforms similar existing methods with respect to accuracy and training time.",diabetic retinopathy; oct image; deep learning; transfer learning; feature extraction; artificial neural networks
Review,"Goutam, Balla; Hashmi, Mohammad Farukh; Geem, Zong Woo; Bokde, Neeraj Dhanraj",A Comprehensive Review of Deep Learning Strategies in Retinal Disease Diagnosis Using Fundus Images,ieee access,2022,Not found,"In recent years, there has been an unprecedented growth in computer vision and deep learning implementation owing to the exponential rise of computation infrastructure. The same was also reflected in retinal image analysis and successful artificial intelligence models were developed for various retinal disease diagnoses using a wide variety of visual markers obtained from eye fundus images. This article presents a comprehensive study of different deep learning strategies employed in recent times for the diagnosis of five major eye diseases, i.e., Diabetic retinopathy, Glaucoma, age-related macular degeneration, Cataract, and Retinopathy of prematurity. This article is organized according to the deep learning implementation process pipeline, where commonly used datasets, evaluation metrics, image pre-processing techniques, and deep learning backbone models are first illustrated followed by an extensive review of different strategies for each of the five mentioned retinal diseases is presented. Finally, this article summarizes eight major research directions available in the field of retinal disease diagnosis and outlines key challenges and future scope for the present research community.",retina; medical diagnosis; task analysis; retinopathy; deep learning; measurement; diabetes; computer vision; deep learning; fundus image; retinal disease diagnosis; artificial intelligence; diabetic retinopathy; glaucoma; amd; cataract; rop
Article,"Govindaswamy, Nivedhitha; Ratra, Dhanashree; Dalan, Daleena; Doralli, Subashchandra; Tirumalai, Anirudha A.; Nagarajan, Rajesh; Mochi, Thirumalesh; Shetty, Naren; Roy, Abhijit Sinha",Vascular changes precede tomographic changes in diabetic eyes without retinopathy and improve artificial intelligence diagnostics,journal of biophotonics,2020,Not found,"The purpose of this study was to evaluate early vascular and tomographic changes in the retina of diabetic patients using artificial intelligence (AI). The study included 74 age-matched normal eyes, 171 diabetic eyes without retinopathy (DWR) eyes and 69 mild non-proliferative diabetic retinopathy (NPDR) eyes. All patients underwent optical coherence tomography angiography (OCTA) imaging. Tomographic features (thickness and volume) were derived from the OCTA B-scans. These features were used in AI models. Both OCT and OCTA features showed significant differences between the groups (P< .05). However, the OCTA features indicated early retinal changes in DWR eyes better than OCT (P< .05). In the AI model using both OCT and OCTA features simultaneously, the best area under the curve of 0.91 +/- 0.02 was obtained (P< .05). Thus, the combined use of AI, OCT and OCTA significantly improved the early diagnosis of diabetic changes in the retina.",angiography; artificial intelligence; diabetic retinopathy; optical coherence tomography
Article,"Ayala, Angel; Ortiz Figueroa, Tomas; Fernandes, Bruno; Cruz, Francisco",Diabetic Retinopathy Improved Detection Using Deep Learning,applied sciences-basel,2021,Not found,"Diabetes is a disease that occurs when the body presents an uncontrolled level of glucose that is capable of damaging the retina, leading to permanent damage of the eyes or vision loss. When diabetes affects the eyes, it is known as diabetic retinopathy, which became a global medical problem among elderly people. The fundus oculi technique involves observing the eyeball to diagnose or check the pathology evolution. In this work, we implement a convolutional neural network model to process a fundus oculi image to recognize the eyeball structure and determine the presence of diabetic retinopathy. The model's parameters are optimized using the transfer-learning methodology for mapping an image with the corresponding label. The model training and testing are performed with a dataset of medical fundus oculi images and a pathology severity scale present in the eyeball as labels. The severity scale separates the images into five classes, from a healthy eyeball to a proliferative diabetic retinopathy presence. The latter is probably a blind patient. Our proposal presented an accuracy of 97.78%, allowing for the confident prediction of diabetic retinopathy in fundus oculi images.",diabetic retinopathy; cross-testing benchmark; deep learning
Review,"Nagpal, Dimple; Panda, S. N.; Malarvel, Muthukumaran; Pattanaik, Priyadarshini A.; Khan, Mohammad Zubair","A review of diabetic retinopathy: Datasets, approaches, evaluation metrics and future trends",journal of king saud university-computer and information sciences,2022,Not found,"Diabetic Retinopathy (DR) is the condition caused due to uncontrolled diabetes that can lead to vision impairment. It greatly affects the retinal blood vessels and diminishes the fundus light-sensitive inner coating. Early diagnosis and regular screening of this disease are essential for prompt processing through artificial intelligence techniques. This paper targets assessing the latest techniques for screening and diagnosing DR, including 94 articles based on the Detection and grading of DR. For every analyzed approach, tables are summarized detailing imaging procedure used, datasets, performance metrics used. The research gaps are also highlighted in this paper. Despite the consistent progression and methods actualized in this field, a couple of issues actually should be centered on. The noise and contrast of the image in Image enhancement are still in the infancy stage for high resolution. This study covers a review of existing image techniques, the gold standard and private datasets available, performance measures used for detection and grading of DR. Now the future research focuses on the amalgamation of the dataset as well as techniques to make the generalized technique for detecting the lesion in DR through an auto-mated system. Moreover, various research gaps have also been taken into account for further research. This review is beneficial to the researchers working in the field of medical imaging to screen and diagnose diseases.(c) 2021 The Authors. Published by Elsevier B.V. on behalf of King Saud University. This is an open access article under the CC BY-NC-ND license (http://creativecommons.org/licenses/by-nc-nd/4.0/).",diabetic retinopathy; screening; datasets; diagnosis of dr; evaluation metrics; future trends
Proceedings Paper,"Taspinar, Y. Selim",Diabetic Rethinopathy Phase Identification with Deep Features,2022 11th mediterranean conference on embedded computing (meco),2022,Not found,"One of the most prevalent diabetes symptoms is diabetic retinopathy. Pain is one of the most common causes of vision loss. Years of research have gone into finding a way to diagnose and treat this condition early. In this study (DR) Diabetic Rethinopathy dataset containing 35,126 images was used. The dataset includes 5 classes. Each class represents the diabetic retinopathy stage. For example, 0 was determined as no diagnosis, 4 as the last stage. The pre-trained SqueezeNet model was used to extract image features. 1000 features obtained for each image are given as input to the Logistic Regression (LR) and k-Nearest Neighbor (kNN) machine learning models. As a result of the classifications made with LR and kNN models, 74.4% classification accuracy was obtained from the LR model and 72.2% from the kNN model. The F-1 Score, Precision, and Recall measures were used to assess the models' performance. ROC curve and The learning levels of the models were assessed using AUC values.",diabetic retinopathy; deep features; early detection; transfer learning; classification
Article,"Butt, Muhammad Mohsin; Iskandar, D. N. F. Awang; Abdelhamid, Sherif E.; Latif, Ghazanfar; Alghazo, Runna",Diabetic Retinopathy Detection from Fundus Images of the Eye Using Hybrid Deep Learning Features,diagnostics,2022,Not found,"Diabetic Retinopathy (DR) is a medical condition present in patients suffering from long-term diabetes. If a diagnosis is not carried out at an early stage, it can lead to vision impairment. High blood sugar in diabetic patients is the main source of DR. This affects the blood vessels within the retina. Manual detection of DR is a difficult task since it can affect the retina, causing structural changes such as Microaneurysms (MAs), Exudates (EXs), Hemorrhages (HMs), and extra blood vessel growth. In this work, a hybrid technique for the detection and classification of Diabetic Retinopathy in fundus images of the eye is proposed. Transfer learning (TL) is used on pre-trained Convolutional Neural Network (CNN) models to extract features that are combined to generate a hybrid feature vector. This feature vector is passed on to various classifiers for binary and multiclass classification of fundus images. System performance is measured using various metrics and results are compared with recent approaches for DR detection. The proposed method provides significant performance improvement in DR detection for fundus images. For binary classification, the proposed modified method achieved the highest accuracy of 97.8% and 89.29% for multiclass classification.",hybrid deep learning features; fundus images; diabetic retinopathy; convolutional neural network features
Article,"Alfian, Ganjar; Syafrudin, Muhammad; Fitriyani, Norma Latif; Anshari, Muhammad; Stasa, Pavel; Svub, Jiri; Rhee, Jongtae",Deep Neural Network for Predicting Diabetic Retinopathy from Risk Factors,mathematics,2020,Not found,"Extracting information from individual risk factors provides an effective way to identify diabetes risk and associated complications, such as retinopathy, at an early stage. Deep learning and machine learning algorithms are being utilized to extract information from individual risk factors to improve early-stage diagnosis. This study proposes a deep neural network (DNN) combined with recursive feature elimination (RFE) to provide early prediction of diabetic retinopathy (DR) based on individual risk factors. The proposed model uses RFE to remove irrelevant features and DNN to classify the diseases. A publicly available dataset was utilized to predict DR during initial stages, for the proposed and several current best-practice models. The proposed model achieved 82.033% prediction accuracy, which was a significantly better performance than the current models. Thus, important risk factors for retinopathy can be successfully extracted using RFE. In addition, to evaluate the proposed prediction model robustness and generalization, we compared it with other machine learning models and datasets (nephropathy and hypertension-diabetes). The proposed prediction model will help improve early-stage retinopathy diagnosis based on individual risk factors.",retinopathy; risk factor; machine learning; deep neural network; recursive feature elimination; deep learning
Article,"Wang, Yueye; Shi, Danli; Tan, Zachary; Niu, Yong; Jiang, Yu; Xiong, Ruilin; Peng, Guankai; He, Mingguang",Screening Referable Diabetic Retinopathy Using a Semi-automated Deep Learning Algorithm Assisted Approach,frontiers in medicine,2021,Not found,"Purpose: To assess the accuracy and efficacy of a semi-automated deep learning algorithm (DLA) assisted approach to detect vision-threatening diabetic retinopathy (DR).Methods: We developed a two-step semi-automated DLA-assisted approach to grade fundus photographs for vision-threatening referable DR. Study images were obtained from the Lingtou Cohort Study, and captured at participant enrollment in 2009-2010 (baseline images) and annual follow-up between 2011 and 2017. To begin, a validated DLA automatically graded baseline images for referable DR and classified them as positive, negative, or ungradable. Following, each positive image, all other available images from patients who had a positive image, and a 5% random sample of all negative images were selected and regraded by trained human graders. A reference standard diagnosis was assigned once all graders achieved consistent grading outcomes or with a senior ophthalmologist's final diagnosis. The semi-automated DLA assisted approach combined initial DLA screening and subsequent human grading for images identified as high-risk. This approach was further validated within the follow-up image datasets and its time and economic costs evaluated against fully human grading.Results: For evaluation of baseline images, a total of 33,115 images were included and automatically graded by the DLA. 2,604 images (480 positive results, 624 available other images from participants with a positive result, and 1500 random negative samples) were selected and regraded by graders. The DLA achieved an area under the receiver operating characteristic curve (AUC), sensitivity, specificity, and accuracy of 0.953, 0.970, 0.879, and 88.6%, respectively. In further validation within the follow-up image datasets, a total of 88,363 images were graded using this semi-automated approach and human grading was performed on 8975 selected images. The DLA achieved an AUC, sensitivity, and specificity of 0.914, 0.852, 0.853, respectively. Compared against fully human grading, the semi-automated DLA-assisted approach achieved an estimated 75.6% time and 90.1% economic cost saving.Conclusions: The DLA described in this study was able to achieve high accuracy, sensitivity, and specificity in grading fundus images for referable DR. Validated against long-term follow-up datasets, a semi-automated DLA-assisted approach was able to accurately identify suspect cases, and minimize misdiagnosis whilst balancing safety, time, and economic cost.",diabetic retinopathy; artificial intelligence; screening; cost-saving analysis; deep learning
Article,"Qiao, Lifeng; Zhu, Ying; Zhou, Hui",Diabetic Retinopathy Detection Using Prognosis of Microaneurysm and Early Diagnosis System for Non-Proliferative Diabetic Retinopathy Based on Deep Learning Algorithms,ieee access,2020,Not found,"Predicting the presence of Microaneurysms in the fundus images and the identification of diabetic retinopathy in early-stage has always been a major challenge for decades. Diabetic Retinopathy (DR) is affected by prolonged high blood glucose level which leads to microvascular complications and irreversible vision loss. Microaneurysms formation and macular edema in the retinal is the initial sign of DR and diagnosis at the right time can reduce the risk of non proliferated diabetic retinopathy. The rapid improvement of deep learning makes it gradually become an efficient technique to provide an interesting solution for medical image analysis problems. The proposed system analysis the presence of microaneurysm in fundus image using convolutional neural network algorithms that embeds deep learning as a core component accelerated with GPU(Graphics Processing Unit) which will perform medical image detection and segmentation with high-performance and low-latency inference. The semantic segmentation algorithm is utilized to classify the fundus picture as normal or infected. Semantic segmentation divides the image pixels based on their common semantic to identify the feature of microaneurysm. This provides an automated system that will assist ophthalmologists to grade the fundus images as early NPDR, moderate NPDR, and severe NPDR. The Prognosis of Microaneurysm and early diagnosis system for non - proliferative diabetic retinopathy system has been proposed that is capable to train effectively a deep convolution neural network for semantic segmentation of fundus images which can increase the efficiency and accuracy of NPDR (non proliferated diabetic retinopathy) prediction.",diabetes; retinopathy; retina; lesions; image segmentation; semantics; biomedical imaging; microaneurysm; diabetic retinopathy; deep convolution neural network; semantic segmentation; non proliferated diabetic retinopathy
Article,"Pareja-Rios, Alicia; Ceruso, Sabato; Romero-Aroca, Pedro; Bonaque-Gonzalez, Sergio",A New Deep Learning Algorithm with Activation Mapping for Diabetic Retinopathy: Backtesting after 10 Years of Tele-Ophthalmology,journal of clinical medicine,2022,Not found,"We report the development of a deep learning algorithm (AI) to detect signs of diabetic retinopathy (DR) from fundus images. For this, we use a ResNet-50 neural network with a double resolution, the addition of Squeeze-Excitation blocks, pre-trained in ImageNet, and trained for 50 epochs using the Adam optimizer. The AI-based algorithm not only classifies an image as pathological or not but also detects and highlights those signs that allow DR to be identified. For development, we have used a database of about half a million images classified in a real clinical environment by family doctors (FDs), ophthalmologists, or both. The AI was able to detect more than 95% of cases worse than mild DR and had 70% fewer misclassifications of healthy cases than FDs. In addition, the AI was able to detect DR signs in 1258 patients before they were detected by FDs, representing 7.9% of the total number of DR patients detected by the FDs. These results suggest that AI is at least comparable to the evaluation of FDs. We suggest that it may be useful to use signaling tools such as an aid to diagnosis rather than an AI as a stand-alone tool.",diabetic retinopathy; artificial intelligence; deep learning; tele-ophthalmology
Proceedings Paper,"Das, Dolly; Biswas, Saroj Kumar; Bandyopadhyay, Sivaji; Laskar, Rabul Hussain",Deep Learning Techniques for Early Detection of Diabetic Retinopathy: Recent Developments and Techniques,"proceedings of the 2020 5th international conference on computing, communication and security (icccs-2020)",2020,Not found,"Diabetic Retinopathy (DR) is a health disorder in human retina, caused as a result of Diabetes Mellitus (DM). It leads to loss of vision and in severe cases it results in blindness, as a result of mutilation of the retina. Statistical data estimates that 80% of diabetic patients, suffering from prolonged diabetes, also suffer from DR. Hence, in the present time DR has become an imperative matter and requires primary stage evaluation and assessment such that loss of vision and blindness can be averted. However, the physical diagnosis of the disease is laborious and susceptible to error. Besides, the convenience of availing Ophthalmologist irrespective of place and time, is not possible. Thus, the necessity of an exceedingly enhanced and computerized intelligent system arises, that can be engaged for the initial stage detection of DR. A number of Machine Learning models are proposed by researchers since decades, for the diagnosis of DR. Various feature extraction techniques are also proposed for deriving prominent retinal lesions, for initial stage diagnosis of DR. However, traditional Machine Learning models showcase poor generalization during feature extraction because of smaller datasets. This can be overcome through use of Deep Learning models, larger dataset and high computing processing units for generalization. This paper aims to give an overview about DR, a brief description of the earlier works, and the current automated systems and advancements, for the purpose of early detection of DR. This paper also focuses on the state-of-the-art DR lesions, origin and signs of DR, categories of DR and state-of-the-art Deep Learning models, that are proposed and applied for DR detection, at the preliminary stage.",diabetic retinopathy; diabetic macular edema; image processing; deep learning; retinal lesions
Article,"Zhang, Wen-fei; Li, Dong-hong; Wei, Qi-jie; Ding, Da-yong; Meng, Li-hui; Wang, Yue-lin; Zhao, Xin-yu; Chen, You-xin",The Validation of Deep Learning-Based Grading Model for Diabetic Retinopathy,frontiers in medicine,2022,Not found,"PurposeTo evaluate the performance of a deep learning (DL)-based artificial intelligence (AI) hierarchical diagnosis software, EyeWisdom V1 for diabetic retinopathy (DR). Materials and MethodsThe prospective study was a multicenter, double-blind, and self-controlled clinical trial. Non-dilated posterior pole fundus images were evaluated by ophthalmologists and EyeWisdom V1, respectively. The diagnosis of manual grading was considered as the gold standard. Primary evaluation index (sensitivity and specificity) and secondary evaluation index like positive predictive values (PPV), negative predictive values (NPV), etc., were calculated to evaluate the performance of EyeWisdom V1. ResultsA total of 1,089 fundus images from 630 patients were included, with a mean age of (56.52 +/- 11.13) years. For any DR, the sensitivity, specificity, PPV, and NPV were 98.23% (95% CI 96.93-99.08%), 74.45% (95% CI 69.95-78.60%), 86.38% (95% CI 83.76-88.72%), and 96.23% (95% CI 93.50-98.04%), respectively; For sight-threatening DR (STDR, severe non-proliferative DR or worse), the above indicators were 80.47% (95% CI 75.07-85.14%), 97.96% (95% CI 96.75-98.81%), 92.38% (95% CI 88.07-95.50%), and 94.23% (95% CI 92.46-95.68%); For referral DR (moderate non-proliferative DR or worse), the sensitivity and specificity were 92.96% (95% CI 90.66-94.84%) and 93.32% (95% CI 90.65-95.42%), with the PPV of 94.93% (95% CI 92.89-96.53%) and the NPV of 90.78% (95% CI 87.81-93.22%). The kappa score of EyeWisdom V1 was 0.860 (0.827-0.890) with the AUC of 0.958 for referral DR. ConclusionThe EyeWisdom V1 could provide reliable DR grading and referral recommendation based on the fundus images of diabetics.",diabetic retinopathy; artificial intelligence; validation; eye wisdom v1; sensitivity; specificity
Article,"Patil, Mahesh S.; Chickerur, Satyadhyan; Kumar, Yeshwanth V. S.; Bakale, Vijayalakshmi A.; Giraddi, Shantala; Roodagi, Vivekanand C.; Kulkarni, Yashaswini N.",Deep hyperparameter transfer learning for diabetic retinopathy classification,turkish journal of electrical engineering and computer sciences,2021,Not found,"The detection of diabetic retinopathy (DR) in millions of diabetic patients across the globe is a challenging problem. Diagnosis of retinopathy is a lengthy and tedious process, requiring a medical professional to assess the individual fundus images of a patient's retina. This process can be automated by applying deep learning (DL) technology given a huge dataset. The problems associated with DL are the unavailability of a large dataset and their higher training time. The DL model's best performance is achieved using set of optimal hyperparameters (OHPs) obtained by performing costly iterations of hyperparameter optimization (HPO). These problems can be addressed by using transfer learning (TL) technique in both DL model training and HPO. TL in HP tuning is the focus of this work. The authors study the applicability of EyePACS DR dataset's OHPs to other DR datasets, forming the basis of the research question addressed in this work. The DR classification is performed using a ResNet model trained on the EyePACS (kaggle) and Indian diabetic retinopathy image dataset (IDRiD) datasets. Various HPs tuned in this work are data augmentation configuration, number of layers, optimizers, data samplers, learning rate, and momentum. The authors demonstrate that EyePACS dataset's OHPs are suitable for training with IDRiD dataset without needing to tune HPs for IDRiD dataset from scratch. The OHPs for a task and their reusability is poorly reported in the literature. Therefore, the EyePACS DR dataset's OHPs reported here can be used by other researchers. Moreover, the researchers working on other DR datasets can also apply the same OHPs since they are reusable and no iterations of HPO are required. The OHPs are provided for both EyePAC and IDRiD datasets after being tuned from scratch, which can be used as starting point for HPO by others.",hyperparameter optimization; transfer learning; diabetic retinopathy; augmentation; resnet; bayesian optimization
Review,"Asiri, Norah; Hussain, Muhammad; Al Adel, Fadwa; Alzaidi, Nazih",Deep learning based computer-aided diagnosis systems for diabetic retinopathy: A survey,artificial intelligence in medicine,2019,Not found,"Diabetic retinopathy (DR) results in vision loss if not treated early. A computer-aided diagnosis (CAD) system based on retinal fundus images is an efficient and effective method for early DR diagnosis and assisting experts. A computer-aided diagnosis (CAD) system involves various stages like detection, segmentation and classification of lesions in fundus images. Many traditional machine-learning (ML) techniques based on hand-engineered features have been introduced. The recent emergence of deep learning (DL) and its decisive victory over traditional ML methods for various applications motivated the researchers to employ it for DR diagnosis, and many deep-learning-based methods have been introduced. In this paper, we review these methods, highlighting their pros and cons. In addition, we point out the challenges to be addressed in designing and learning about efficient, effective and robust deep-learning algorithms for various problems in DR diagnosis and draw attention to directions for future research.",diabetic retinopathy; lesion; exudate; macula; diabetic macular edema; optic disc; microaneurysms; hemorrhages; cnn; autoencoder; rnn; dbn
Article,"Dutta, Suvajit; Manideep, Bonthala C. S.; Basha, Syed Muzamil; Caytiles, Ronnie D.; Iyengar, N. Ch. S. N.",Classification of Diabetic Retinopathy Images by Using Deep Learning Models,international journal of grid and distributed computing,2018,Not found,"Diabetes or more precisely Diabetes Mellitus (DM) is a metabolic disorder happens because of high blood sugar level in the body. Over the time, diabetes creates eye deficiency also called as Diabetic Retinopathy (DR) causes major loss of vision. The symptoms can originate in the retinal area are augmented blood vessels, fluid drip, exudates, hemorrhages, and micro aneurysms. In modern medical science, images are the indispensable tool for precise diagnosis of patients. In the meantime evaluation of contemporary medical imageries remains complex. In recent times computer vision with Deep Neural Networks can train a model perfectly and level of accuracy also will be higher than other neural network models. In this study fundus images containing diabetic retinopathy has been taken into consideration. The idea behind this paper is to propose an automated knowledge model to identify the key antecedents of DR. Proposed Model have been trained with three types, back propagation NN, Deep Neural Network (DNN) and Convolutional Neural Network (CNN) after testing models with CPU trained Neural network gives lowest accuracy because of one hidden layers whereas the deep learning models are out performing NN. The Deep Learning models are capable of quantifying the features as blood vessels, fluid drip, exudates, hemorrhages and micro aneurysms into different classes. Model will calculate the weights which gives severity level of the patient's eye. The foremost challenge of this study is the accurate verdict of each feature class thresholds. To identify the target class thresholds weighted Fuzzy C-means algorithm has been used. The model will be helpful to identify the proper class of severity of diabetic retinopathy images.",diabetic retinopathy (dr); retina; classification; threshold; deep learning (dl); deep neural network (dnn); convolutional neural network (cnn)
Article,"Li, Xuechen; Shen, Linlin; Shen, Meixiao; Tan, Fan; Qiu, Connor S.",Deep learning based early stage diabetic retinopathy detection using optical coherence tomography,neurocomputing,2019,Not found,"Diabetic retinopathy (DR) is one of the leading causes of preventable blindness globally. Performing retinal examinations on all diabetic patients is an unmet need, and detection at an early stage can provide better control of the disease. The objective of this study is to provide an optical coherence tomography (OCT) image based diagnostic technology for automated early DR diagnosis, including at both grades 0 and 1. This work can help ophthalmologists with evaluation and treatment, reducing the rate of vision loss, and enabling timely and accurate diagnosis. In this work, we developed and evaluated a novel deep network - OCTD_Net, for early-stage DR detection. While one of the networks extracted features from the original OCT image, the other extracted retinal layer information. The accuracy, sensitivity and specificity was 0.92, 0.90 and 0.95, respectively. Our analysis of retinal layers and the features learned by the proposed network suggests that grade 1 DR patients present with significant changes in the thickness and reflection of certain retinal layers. However, grade 0 DR patients do not have such significant changes. The heatmaps of the trained network also suggest that patients with early DR showed different textures around the myoid and ellipsoid zones, inner nuclear layers, and photoreceptor outer segments, which should all receive dedicated attention for early DR diagnosis. (C) 2019 Elsevier B.V. All rights reserved.",computer-aided diagnosis; diabetic retinopathy; optical coherence tomography; deep learning
Article,"Mansour, Romany F.",Deep-learning-based automatic computer-aided diagnosis system for diabetic retinopathy,biomedical engineering letters,2018,Not found,"The high-pace rise in advanced computing and imaging systems has given rise to a new research dimension called computer-aided diagnosis (CAD) system for various biomedical purposes. CAD-based diabetic retinopathy (DR) can be of paramount significance to enable early disease detection and diagnosis decision. Considering the robustness of deep neural networks (DNNs) to solve highly intricate classification problems, in this paper, AlexNet DNN, which functions on the basis of convolutional neural network (CNN), has been applied to enable an optimal DR CAD solution. The DR model applies a multilevel optimization measure that incorporates pre-processing, adaptive-learning-based Gaussian mixture model (GMM)-based concept region segmentation, connected component-analysis-based region of interest (ROI) localization, AlexNet DNN-based highly dimensional feature extraction, principle component analysis (PCA)-and linear discriminant analysis (LDA)-based feature selection, and support-vector-machine-based classification to ensure optimal five-class DR classification. The simulation results with standard KAGGLE fundus datasets reveal that the proposed AlexNet DNN-based DR exhibits a better performance with LDA feature selection, where it exhibits a DR classification accuracy of 97.93% with FC7 features, whereas with PCA, it shows 95.26% accuracy. Comparative analysis with spatial invariant feature transform (SIFT) technique (accuracy-94.40%) based DR feature extraction also confirms that AlexNet DNN-based DR outperforms SIFT-based DR.",computer-aided diagnosis; diabetic retinopathy; deep neural network; alexnet dnn; convolutional neural network; gaussian mixture model; linear discriminant analysis; svm
Article,"Alyoubi, Wejdan L.; Abulkhair, Maysoon F.; Shalash, Wafaa M.",Diabetic Retinopathy Fundus Image Classification and Lesions Localization System Using Deep Learning,sensors,2021,Not found,"Diabetic retinopathy (DR) is a disease resulting from diabetes complications, causing non-reversible damage to retina blood vessels. DR is a leading cause of blindness if not detected early. The currently available DR treatments are limited to stopping or delaying the deterioration of sight, highlighting the importance of regular scanning using high-efficiency computer-based systems to diagnose cases early. The current work presented fully automatic diagnosis systems that exceed manual techniques to avoid misdiagnosis, reducing time, effort and cost. The proposed system classifies DR images into five stages-no-DR, mild, moderate, severe and proliferative DR-as well as localizing the affected lesions on retain surface. The system comprises two deep learning-based models. The first model (CNN512) used the whole image as an input to the CNN model to classify it into one of the five DR stages. It achieved an accuracy of 88.6% and 84.1% on the DDR and the APTOS Kaggle 2019 public datasets, respectively, compared to the state-of-the-art results. Simultaneously, the second model used an adopted YOLOv3 model to detect and localize the DR lesions, achieving a 0.216 mAP in lesion localization on the DDR dataset, which improves the current state-of-the-art results. Finally, both of the proposed structures, CNN512 and YOLOv3, were fused to classify DR images and localize DR lesions, obtaining an accuracy of 89% with 89% sensitivity, 97.3 specificity and that exceeds the current state-of-the-art results.",computer-aided diagnosis; convolutional neural networks; deep learning; diabetic retinopathy; diabetic retinopathy classification; diabetic retinopathy lesions localization; yolo
Review,"Qummar, Sehrish; Khan, Fiaz Gul; Shah, Sajid; Khan, Ahmad; Din, Ahmad; Gao, Jinfeng",Deep Learning Techniques for Diabetic Retinopathy Detection,current medical imaging,2020,Not found,"Diabetes occurs due to the excess of glucose in the blood that may affect many organs of the body. Elevated blood sugar in the body causes many problems including Diabetic Retinopathy (DR). DR occurs due to the mutilation of the blood vessels in the retina. The manual detection of DR by ophthalmologists is complicated and time-consuming. Therefore, automatic detection is required, and recently different machine and deep learning techniques have been applied to detect and classify DR. In this paper, we conducted a study of the various techniques available in the literature for the identification/classification of DR, the strengths and weaknesses of available datasets for each method, and provides the future directions. Moreover, we also discussed the different steps of detection, that are: segmentation of blood vessels in a retina, detection of lesions, and other abnormalities of DR.",diabetic retinopathy; deep learning; convolutional neural network; diabetes; machine learning; lesions detection
Article,"Kumar, Gaurav; Chatterjee, Shraban; Chattopadhyay, Chiranjoy",DRISTI: a hybrid deep neural network for diabetic retinopathy diagnosis,signal image and video processing,2021,Not found,"Diabetic retinopathy (DR) is a significant reason for the global increase in visual loss. Studies show that timely treatment can significantly bring down such incidents. Hence, it is essential to distinguish the stages and severity of DR to recommend needed medical attention. In this view, this paper presents DRISTI (Diabetic Retinopathy classIfication by analySing reTinal Images), where a hybrid deep learning model composed of VGG16 and capsule network is proposed, which yields statistically significant performance improvement over the state of the art. To validate our claim, we have reported detailed experimental and ablation studies. We have also created an augmented dataset to increase the APTOS dataset's size and check how robust the model is. The five-class training and validation accuracy for the expanded dataset is 99.21% and 75.50%. The two-class training and validation accuracy on augmented APTOS is 99.96% and 97.05%. Extending the two-class model for the mixed dataset, we get a training and validation accuracy of 99.92% and 91.43%, respectively. We have also performed cross-dataset and mixed dataset testing to demonstrate the efficiency of DRISTI.",diabetic retinopathy; deep learning; vgg16; capsule network; image classification
Proceedings Paper,"Lahmar, Chaymaa; Idri, Ali",Classifying Diabetic Retinopathy using CNN and Machine Learning,"proceedings of the 15th international joint conference on biomedical engineering systems and technologies (bioimaging), vol 2",2021,Not found,"Diabetic retinopathy (DR) is one of the main causes of vision loss around the world. A computer-aided diagnosis can help in the early detection of this disease which can be beneficial for a better patient outcome. In this paper, we conduct an empirical evaluation of the performances of twenty-eight deep hybrid architectures for an automatic binary classification of referable DR, and compared them to seven end-to-end deep learning (DL) architectures. The architectures were compared using the Scott Knott test and the Borda count voting method. All the empirical evaluations were over the APTOS dataset, using five-fold cross validation. The results showed the importance of combining DL techniques and classical machine learning techniques for the classification of DR. The hybrid architecture using the SVM classifier and MobileNet_V2 for feature extraction was the top performing and it was classified among the best performing end-to-end deep learning architectures with an accuracy equal to 88.80%: note that none of the hybrid architectures outperformed all the end-to-end architectures.",medical images; diabetic retinopathy; deep learning; hybrid architectures
Review,"Mishra, Anju; Singh, Laxman; Pandey, Mrinal; Lakra, Sachin",Image based early detection of diabetic retinopathy: A systematic review on Artificial Intelligence (AI) based recent trends and approaches,journal of intelligent & fuzzy systems,2022,Not found,"Diabetic Retinopathy (DR) is a disease that damages the retina of the human eye due to diabetic complications, resulting in a loss of vision. Blindness may be avoided If the DR disease is detected at an early stage. Unfortunately, DR is irreversible process, however, early detection and treatment of DR can significantly reduce the risk of vision loss. The manual diagnosis done by ophthalmologists on DR retina fundus images is time consuming, and error prone process. Nowadays, machine learning and deep learning have become one of the most effective approaches, which have even surpassed the human performance as well as performance of traditional image processing-based algorithms and other computer aided diagnosis systems in the analysis and classification of medical images. This paper addressed and evaluated the various recent state-of-the-art methodologies that have been used for detection and classification of Diabetic Retinopathy disease using machine learning and deep learning approaches in the past decade. Furthermore, this study also provides the authors observation and performance evaluation of available research using several parameters, such as accuracy, disease status, and sensitivity. Finally, we conclude with limitations, remedies, and future directions in DR detection. In addition, various challenging issues that need further study are also discussed.",retinal fundus images; machine learning; deep learning; classification; diabetic retinopathy
Article,"Zhang, Qiu-Ming; Luo, Jing; Cengiz, Korhan",An Optimized Deep Learning Based Technique for Grading and Extraction of Diabetic Retinopathy Severities,informatica-an international journal of computing and informatics,2021,Not found,"The prognosis of Diabetic Retinopathy (DR) requires regular eye examinations, as ophthalmologists depends on fundus segmentation to treat DR pathologies. Automated approaches for detection, segmentation and classification have developed as an imperative area of research for the effective diagnosis of DR for the treatment of serious eye conditions that prevent visual impairment. Diagnosis of various DR lesions, as well as different severities, helping the ophthalmologists to analyze variations in fundus images and take the necessary measures before the disease progresses. Deep learning techniques have evolved as a recent advent to combat the issues of conventional machine leaning based methods. An optimized deep learning framework is proposed in this article for grading and extraction of diabetic retinopathy severities. This involves various steps like background segmentation, feature set extraction, feature optimization using Cuckoo search and Convolutional Neural Network (CNN) severity grade classification. The method was validated on two standard datasets MESSIDOR and IDRiD. The proposed method yields an accuracy value of 97.55%, cross entropy loss of 0.367 and time intricacy of 20 mins and 15 secs for MESSIDOR and 98.02% cross entropy loss of 0.345 and time intricacy of 22 mins and 21 secs for IDRiD dataset; respectively. The state-of-the-art comparison depicts that the proposed CNN based method provides a maximum accuracy improvement of 10.46% comparative to the existing methodology. The proposed framework yields better accuracy by procurement of the investigative outcomes acquired exhibits proficient DR determination.",diabetic retinopathy; machine learning; deep learning; convolution neural network; severity grading
Article; Early Access,"Lahmar, Chaymaa; Idri, Ali",Deep hybrid architectures for diabetic retinopathy classification,computer methods in biomechanics and biomedical engineering-imaging and visualization,0,Not found,"Diabetic retinopathy (DR) is the most severe ocular complication of diabetes. It leads to serious eye complications such as vision impairment and blindness. A computer-aided diagnosis may help in the early detection of this disease, which increases the chances of treating it efficiently. This paper carried out an empirical evaluation of the performances of 28 deep hybrid architectures for an automatic binary classification of the referable diabetic retinopathy, and compared them to seven end-to-end deep learning (DL) architectures. For the hybrid architectures, we combined seven DL techniques for feature extraction (DenseNet201, VGG16, VGG19, MobileNet_V2, Inception_V3, Inception_ResNet_V2 and ResNet50) and four classifiers (SVM, MLP, DT and KNN). For the end-to-end DL architectures, we used the same techniques used for the feature extraction in the hybrid architectures. The architectures were compared in terms of accuracy, sensitivity, precision and F1-score using the Scott Knott test and the Borda count voting method. All the empirical evaluations were over three datasets: APTOS, Kaggle DR and Messidor-2, using a k-fold cross validation method. The results showed the potential of combining deep learning techniques for feature extraction and classical machine learning techniques to classify referable diabetic retinopathy. The hybrid architecture using the SVM classifier and MobileNet_V2 for feature extraction was the top performing architecture and it was classified with the best performing end-to-end architectures in the best clusters of APTOS, Kaggle DR and Messidor-2 datasets with an accuracy equal to 88.80%, 84.01% and 84.05% respectively. Note that the two end-to-end architectures DenseNet201 and MobileNet_V2 outperformed all the hybrid architectures over the three datasets. However, we recommend the use of the hybrid architecture designed with SVM and MobileNet_V2 since it is promising and less time consuming, and requires less parameter tuning compared to the end-to-end techniques.",medical images; diabetic retinopathy; hybrid architecture
Article,"El-Ateif, Sara; Idri, Ali",Single-modality and joint fusion deep learning for diabetic retinopathy diagnosis,scientific african,2022,Not found,"The current study evaluated and compared single-modality and joint fusion deep learn-ing approaches for automatic binary classification of diabetic retinopathy (DR) using seven convolutional neural network models (VGG19, ResNet50V2, DenseNet121, InceptionV3, In-ceptionResNetV2, Xception, and MobileNetV2) over two datasets: APTOS 2019 blindness detection and Messidor-2. The empirical evaluations used (1) six performance metrics (ac-curacy, sensitivity, specificity, precision, F1-score, and area under the curve), (2) the Scott -Knott Effect Size difference (SK ESD) statistical test to rank and cluster the models based on accuracy, and (3) the Borda count voting method to rank the best models figuring in the first SK ESD cluster, based on sensitivity, specificity, precision, F1-score, and area un-der the curve. Results showed that the single-modality DenseNet121 and InceptionV3 were the top-performing and less sensitive approaches, with an accuracy of 90.63% and 75.25%, respectively. The joint fusion strategy outperformed single-modality techniques across the two datasets, regardless of the modality used, because of the additional information pro-vided by the preprocessed modality to the Fundus. The Fundus modality was the most favorable modality for DR diagnosis using the seven models. Furthermore, the joint fu-sion VGG19 model performed best with an accuracy of 97.49% and 91.20% over APTOS19 and Messidor-2, respectively; as the VGG19 model was fine-tuned in comparison to the remaining six models. In comparison with state-of-the-art models, Attention Fusion, and Cascaded Framework, joint fusion VGG19 ranks below the Attention Fusion network and outperforms the Cascaded Framework on the Messidor dataset by 5.6% and 8%, respec-tively.(c) 2022 The Authors. Published by Elsevier B.V. on behalf of African Institute of Mathematical Sciences / Next Einstein Initiative. This is an open access article under the CC BY-NC-ND license ( http://creativecommons.org/licenses/by-nc-nd/4.0/ )",joint fusion; multimodality; deep convolutional neural networks; diabetic retinopathy
Review,"Padhy, Srikanta Kumar; Takkar, Brijesh; Chawla, Rohan; Kumar, Atul",Artificial intelligence in diabetic retinopathy: A natural step to the future,indian journal of ophthalmology,2019,Not found,Use of artificial intelligence in medicine in an evolving technology which holds promise for mass screening and perhaps may even help in establishing an accurate diagnosis. The ability of complex computing is to perform pattern recognition by creating complex relationships based on input data and then comparing it with performance standards is a big step. Diabetic retinopathy is an ever-increasing problem. Early screening and timely treatment of the same can reduce the burden of sight threatening retinopathy. Any tool which can aid in quick screening of this disorder and minimize requirement of trained human resource for the same would probably be a boon for patients and ophthalmologists. In this review we discuss the current status of use of artificial intelligence in diabetic retinopathy and few other common retinal disorders.,artificial intelligence; idx-dr; fundus image; screening
Article,"Dong, Xiuqing; Du, Shaolin; Zheng, Wenkai; Cai, Chusheng; Liu, Huaxiu; Zou, Jiangfeng",Evaluation of an Artificial Intelligence System for the Detection of Diabetic Retinopathy in Chinese Community Healthcare Centers,frontiers in medicine,2022,Not found,"ObjectiveTo evaluate the sensitivity and specificity of a Comprehensive Artificial Intelligence Retinal Expert (CARE) system for detecting diabetic retinopathy (DR) in a Chinese community population. MethodsThis was a cross-sectional, diagnostic study. Participants with a previous diagnosis of diabetes from three Chinese community healthcare centers were enrolled in the study. Single-field color fundus photography was obtained and analyzed by the AI system and two ophthalmologists. Primary outcome measures included the sensitivity, specificity, positive predictive value, and negative predictive value with their 95% confidence intervals (CIs) of the AI system in detecting DR and diabetic macular edema (DME). ResultsIn this study, 443 subjects (848 eyes) were enrolled, and 283 (63.88%) were men. The mean age was 52.09 (11.51) years (range 18-82 years); 266 eyes were diagnosed with any DR, 233 with more-than-mild diabetic retinopathy (mtmDR), 112 with vision-threatening diabetic retinopathy (vtDR), and 57 with DME. The image ability of the AI system was as high as 99.06%, whereas its sensitivity and specificity varied significantly in detecting DR with different severities. The sensitivity/specificity to detect any DR was 75.19% (95%CI 69.47-80.17)/93.99% (95%CI 91.65-95.71), mtmDR 78.97% (95%CI 73.06-83.90)/92.52% (95%CI 90.07-94.41), vtDR 33.93% (95%CI 25.41-43.56)/97.69% (95%CI 96.25-98.61), and DME 47.37% (95%CI 34.18-60.91)/93.99% (95%CI 91.65-95.71). ConclusionsThis multicenter cross-sectional diagnostic study noted the safety and reliability of the CARE system for DR (especially mtmDR) detection in Chinese community healthcare centers. The system may effectively solve the dilemma faced by Chinese community healthcare centers: due to the lack of ophthalmic expertise of primary physicians, DR diagnosis and referral are not timely.",artificial intelligence; diabetic retinopathy; community healthcare; color fundus photography; sensitivity; specificity
Article,"Geetha, S.; Parashar, Mansi; Abhishek, J. S.; Turaga, Raj Vishal; Lawal, Isah A.; Kadry, Seifedine",Diabetic Retinopathy Grading with Deep Visual Attention Network,international journal of online and biomedical engineering,2022,Not found,"Diabetic Retinopathy is a serious complication arising in diabetes afflicted patients. Its effective treatment depends on early detection, and the course of action varies decisively with the intensity of the affliction. Computer-aided diagnosis helps to detect not only the presence or absence of the disease, but also the severity, making it easier for ophthalmologists to construct a treatment plan. Diabetic retinopathy grading is the task of classifying images of the eye's fundus of diabetic patients into 5 different grades ranging from 0-4 based on the severity of the disease. In this work, we propose a deep neural network architecture to address the grading problem. The method utilizes additional attention layer in the neural network model to capture the spatial relationship between the region of interests in the images during the training process to better discriminate between the different severity stage of the disease. Also, we analyze the impact of different image processing techniques on the classification results. We assessed the performance of our proposed method using a dataset of eye fundus images and obtained classification accuracy of 89.20% on average. This performance surpass that reported for other state-of-the-art methods on the same dataset. The effectiveness of the proposed method will facilitate the procedural workflow of identifying severe cases of diabetic retinopathy.",diabetic retinopathy; diabetic retinopathy grading; deep learning; attention net; clare; gaussian blur
Article,"Serener, Ali; Serte, Sertan",Geographic variation and ethnicity in diabetic retinopathy detection via deep learning,turkish journal of electrical engineering and computer sciences,2020,Not found,"The prevalence of diabetes is on the rise steadily around the globe. Diabetic retinopathy (DR) is a result of damage to the blood vessels in the retina due to diabetes and its fast treatment is crucial for preventing possible blindness. The diagnosis of DR is done mostly using a comprehensive eye exam, where the eye is dilated for better inspection. Analysis by an ophthalmologist is prone to human error and thus automatic and highly accurate detection of DR is preferred for an earlier and better diagnosis. It is important, however, that automatic detection be accurate for all data collected from patients of different geographic and ethnic backgrounds. In this paper, the automatic detection of DR with a deep learning algorithm is analyzed when geographic and ethnic information of the patients is also integrated into the architecture. It is shown that robust and generalizable DR detection performance is linearly related to the correlation of geographic and ethnic patient information between the training and the testing datasets. The deep learning model created eliminates geographic variation in the detection and works for patients of all ethnicities.",deep learning; diabetic retinopathy; ethnicity; fundus images; geographic variation
Proceedings Paper,"Islam, Md Robiul; Hasan, Md Al Mehedi; Abu Sayeed",Transfer Learning based Diabetic Retinopathy Detection with a Novel Preprocessed Layer,2020 ieee region 10 symposium (tensymp) - technology for impactful sustainable development,2020,Not found,"one of the major reasons for impaired vision in the world nowadays is diabetic retinopathy (DR). Many people could be saved from permanent blindness with early detection. The manual diagnosis is erroneous and tedious. Hence, numerous computerized vision methods for the automatic detection of diabetic retinopathy and its distinctive stages from retinal images were proposed. Various image processing techniques have been developed besides deep learning methods. In image processing techniques, complex features are manually identified. Most of the earlier works used very small dataset which has a great chance to be over-fitting and worked with grayscale image after transforming color fundus images. In our paper, we developed a deep learning model with transfer learning from VGG16 model followed by a novel color version preprocessing technique. It reduced the training time and provided an average accuracy of 0.9132683 implemented to new Kaggle dataset  APTOS 2019 Blindness Detection. Moreover, to avoid the over-fitting problem for long run we used Stratified K-fold cross validation.",diabetic retinopathy; transfer learning; deep learning; convolution neural network
Article,"Qummar, Sehrish; Khan, Fiaz Gul; Shah, Sajid; Khan, Ahmad; Shamshirband, Shahaboddin; Rehman, Zia Ur; Khan, Iftikhar Ahmed; Jadoon, Waqas",A Deep Learning Ensemble Approach for Diabetic Retinopathy Detection,ieee access,2019,Not found,"Diabetic Retinopathy (DR) is an ophthalmic disease that damages retinal blood vessels. DR causes impaired vision and may even lead to blindness if it is not diagnosed in early stages. DR has five stages or classes, namely normal, mild, moderate, severe and PDR (Proliferative Diabetic Retinopathy). Normally, highly trained experts examine the colored fundus images to diagnose this fatal disease. This manual diagnosis of this condition (by clinicians) is tedious and error-prone. Therefore, various computer vision-based techniques have been proposed to automatically detect DR and its different stages from retina images. However, these methods are unable to encode the underlying complicated features and can only classify DRs different stages with very low accuracy particularly, for the early stages. In this research, we used the publicly available Kaggle dataset of retina images to train an ensemble of five deep Convolution Neural Network (CNN) models (Resnet50, Inceptionv3, Xception, Dense121, Dense169) to encode the rich features and improve the classification for different stages of DR. The experimental results show that the proposed model detects all the stages of DR unlike the current methods and performs better compared to state-of-the-art methods on the same Kaggle dataset.",diabetes; retinopathy; training; predictive models; retina; biomedical imaging; cnn; diabetic retinopathy; deep learning; ensemble model; fundus images; medical image analysis
Review,"Kandel, Ibrahem; Castelli, Mauro",Transfer Learning with Convolutional Neural Networks for Diabetic Retinopathy Image Classification. A Review,applied sciences-basel,2020,Not found,"Diabetic retinopathy (DR) is a dangerous eye condition that affects diabetic patients. Without early detection, it can affect the retina and may eventually cause permanent blindness. The early diagnosis of DR is crucial for its treatment. However, the diagnosis of DR is a very difficult process that requires an experienced ophthalmologist. A breakthrough in the field of artificial intelligence called deep learning can help in giving the ophthalmologist a second opinion regarding the classification of the DR by using an autonomous classifier. To accurately train a deep learning model to classify DR, an enormous number of images is required, and this is an important limitation in the DR domain. Transfer learning is a technique that can help in overcoming the scarcity of images. The main idea that is exploited by transfer learning is that a deep learning architecture, previously trained on non-medical images, can be fine-tuned to suit the DR dataset. This paper reviews research papers that focus on DR classification by using transfer learning to present the best existing methods to address this problem. This review can help future researchers to find out existing transfer learning methods to address the DR classification task and to show their differences in terms of performance.",diabetic retinopathy; deep learning; convolutional neural networks; transfer learning
Article,"Jabbar, Muhammad Kashif; Yan, Jianzhuo; Xu, Hongxia; Ur Rehman, Zaka; Jabbar, Ayesha",Transfer Learning-Based Model for Diabetic Retinopathy Diagnosis Using Retinal Images,brain sciences,2022,Not found,"Diabetic retinopathy (DR) is a visual obstacle caused by diabetic disease, which forms because of long-standing diabetes mellitus, which damages the retinal blood vessels. This disease is considered one of the principal causes of sightlessness and accounts for more than 158 million cases all over the world. Since early detection and classification could diminish the visual impairment, it is significant to develop an automated DR diagnosis method. Although deep learning models provide automatic feature extraction and classification, training such models from scratch requires a larger annotated dataset. The availability of annotated training datasets is considered a core issue for implementing deep learning in the classification of medical images. The models based on transfer learning are widely adopted by the researchers to overcome annotated data insufficiency problems and computational overhead. In the proposed study, features are extracted from fundus images using the pre-trained network VGGNet and combined with the concept of transfer learning to improve classification performance. To deal with data insufficiency and unbalancing problems, we employed various data augmentation operations differently on each grade of DR. The results of the experiment indicate that the proposed framework (which is evaluated on the benchmark dataset) outperformed advanced methods in terms of accurateness. Our technique, in combination with handcrafted features, could be used to improve classification accuracy.",diabetic retinopathy; annotated data insufficiency; transfer learning; fundus images; computer-aided diagnosis; convolutional neural network
Article,"Hemanth, D. Jude; Deperlioglu, Omer; Kose, Utku",An enhanced diabetic retinopathy detection and classification approach using deep convolutional neural network,neural computing & applications,2020,Not found,"The objective of this study is to propose an alternative, hybrid solution method for diagnosing diabetic retinopathy from retinal fundus images. In detail, the hybrid method is based on using both image processing and deep learning for improved results. In medical image processing, reliable diabetic retinopathy detection from digital fundus images is known as an open problem and needs alternative solutions to be developed. In this context, manual interpretation of retinal fundus images requires the magnitude of work, expertise, and over-processing time. So, doctors need support from imaging and computer vision systems and the next step is widely associated with use of intelligent diagnosis systems. The solution method proposed in this study includes employment of image processing with histogram equalization, and the contrast limited adaptive histogram equalization techniques. Next, the diagnosis is performed by the classification of a convolutional neural network. The method was validated using 400 retinal fundus images within the MESSIDOR database, and average values for different performance evaluation parameters were obtained as accuracy 97%, sensitivity (recall) 94%, specificity 98%, precision 94%, FScore 94%, and GMean 95%. In addition to those results, a general comparison of with some previously carried out studies has also shown that the introduced method is efficient and successful enough at diagnosing diabetic retinopathy from retinal fundus images. By employing the related image processing techniques and deep learning for diagnosing diabetic retinopathy, the proposed method and the research results are valuable contributions to the associated literature.",diabetic retinopathy; image processing; deep learning; convolutional neural network
Article,"Qian, Xu; Han, Jingying; Xian, Song; Zhao, Yuqing; Wu, Lili; Chu, Baorui; Wei, Guo; Zheng, Yefeng; Qiang, Zhang; Chu, Chunyan; Cheng, Bian; Kai, Ma; Yi, Qu",The effectiveness of artificial intelligence-based automated grading and training system in education of manual detection of diabetic retinopathy,frontiers in public health,2022,Not found,"BackgroundThe purpose of this study is to develop an artificial intelligence (AI)-based automated diabetic retinopathy (DR) grading and training system from a real-world diabetic dataset of China, and in particular, to investigate its effectiveness as a learning tool of DR manual grading for medical students. MethodsWe developed an automated DR grading and training system equipped with an AI-driven diagnosis algorithm to highlight highly prognostic related regions in the input image. Less experienced prospective physicians received pre- and post-training tests by the AI diagnosis platform. Then, changes in the diagnostic accuracy of the participants were evaluated. ResultsWe randomly selected 8,063 cases diagnosed with DR and 7,925 with non-DR fundus images from type 2 diabetes patients. The automated DR grading system we developed achieved accuracy, sensitivity/specificity, and AUC values of 0.965, 0.965/0.966, and 0.980 for moderate or worse DR (95 percent CI: 0.976-0.984). When the graders received assistance from the output of the AI system, the metrics were enhanced in varying degrees. The automated DR grading system helped to improve the accuracy of human graders, i.e., junior residents and medical students, from 0.947 and 0.915 to 0.978 and 0.954, respectively. ConclusionThe AI-based systemdemonstrated high diagnostic accuracy for the detection of DR on fundus images from real-world diabetics, and could be utilized as a training aid system for trainees lacking formal instruction on DR management.",medical image education; artificial intelligence; diabetic retinopathy; medical students; diagnosis
Article,"Tariq, Hassan; Rashid, Muhammad; Javed, Asfa; Zafar, Eeman; Alotaibi, Saud S.; Zia, Muhammad Yousuf Irfan",Performance Analysis of Deep-Neural-Network-Based Automatic Diagnosis of Diabetic Retinopathy,sensors,2022,Not found,"Diabetic retinopathy (DR) is a human eye disease that affects people who are suffering from diabetes. It causes damage to their eyes, including vision loss. It is treatable; however, it takes a long time to diagnose and may require many eye exams. Early detection of DR may prevent or delay the vision loss. Therefore, a robust, automatic and computer-based diagnosis of DR is essential. Currently, deep neural networks are being utilized in numerous medical areas to diagnose various diseases. Consequently, deep transfer learning is utilized in this article. We employ five convolutional-neural-network-based designs (AlexNet, GoogleNet, Inception V4, Inception ResNet V2 and ResNeXt-50). A collection of DR pictures is created. Subsequently, the created collections are labeled with an appropriate treatment approach. This automates the diagnosis and assists patients through subsequent therapies. Furthermore, in order to identify the severity of DR retina pictures, we use our own dataset to train deep convolutional neural networks (CNNs). Experimental results reveal that the pre-trained model Se-ResNeXt-50 obtains the best classification accuracy of 97.53% for our dataset out of all pre-trained models. Moreover, we perform five different experiments on each CNN architecture. As a result, a minimum accuracy of 84.01% is achieved for a five-degree classification.",deep learning; diabetic retinopathy; deep transfer learning; convolutional neural network; automatic detection
Article,"Mohan, N. Jagan; Murugan, R.; Goel, Tripti; Mirjalili, Seyedali; Roy, Parthapratim",A novel four-step feature selection technique for diabetic retinopathy grading,physical and engineering sciences in medicine,2021,Not found,"Diabetic retinopathy is a microvascular complication of diabetes mellitus that develops over time. Diabetic retinopathy is one of the retinal disorders. Early detection of diabetic retinopathy reduces the chances of permanent vision loss. However, the identification and regular diagnosis of diabetic retinopathy is a time-consuming task and requires expert ophthalmologists and radiologists. In addition, an automatic diabetic retinopathy detection technique is necessary for real-time applications to facilitate and minimize potential human errors. Therefore, we propose an ensemble deep neural network and a novel four-step feature selection technique in this paper. In the first step, the preprocessed entropy images improve the quality of the retinal features. Second, the features are extracted using a deep ensemble model include InceptionV3, ResNet101, and Vgg19 from the retinal fundus images. Then, these features are combined to create an ample feature space. To reduce the feature space, we propose four-step feature selection techniques: minimum redundancy, maximum relevance, Chi-Square, ReliefF, and F test for selecting efficient features. Further, appropriate features are chosen from the majority voting techniques to reduce the computational complexity. Finally, the standard machine learning classifier, support vector machines, is used in diabetic retinopathy classification. The proposed method is tested on Kaggle, MESSIDOR-2, and IDRiD databases, available publicly. The proposed algorithm provided an accuracy of 97.78%, a sensitivity of 97.6%, and a specificity of 99.3%, using top 300 features, which are better than other state-of-the-art methods.",retina; fundus images; diabetic retinopathy; deep networks; feature extraction; feature selection; support vector machine
Review; Early Access,"Vij, Richa; Arora, Sakshi",A Systematic Review on Diabetic Retinopathy Detection Using Deep Learning Techniques,archives of computational methods in engineering,0,Not found,"Segmentation is an essential requirement to accurately access diabetic retinopathy (DR) and it becomes extremely time-consuming and challenging to detect manually. As a result, an automatic retinal fundus image segmentation (RFIS) system is required to precisely define the region of interest and help ophthalmologists in the rapid diagnosis of DR. This systematic review provides a comprehensive overview of the development of deep learning (DL) based approach for RFIS to diagnose DR at an early stage. This review is fivefold: (1) retinal datasets, (2) pre-processing approaches, (3) DR segmentation and detection methods, (4) performance evaluation measures, and (5) proposed methodology. Articles on RFIS for DR detection were identified using the query Deep Learning Techniques , Diabetic Retinopathy , and RFIS , alone and in combination using PubMed, Google Scholar, IEEE Xplore, and Research Gate databases until 2021 using PRISMA principle. Approximately 340 publications were searched and 115 relevant studies focused on the DL approaches for RFIS for DR diagnosis were chosen for study. According to the survey, 66% of researchers employed DL approaches for Blood vessel (BV) segmentation, 36% of researchers used DL approaches for lesion detection, and 15% of researchers used DL approaches for optic disc and optic cup (OD & OC) segmentation for DR Diagnosis. This systematic review provides detailed literature of the state-of-the-art relevant articles for RFIS of BV, Lesions, OD & OC for non-proliferative DR diagnosis and discusses future directions to improve the performance of DR and overcome research challenges. Finally, this article highlights the outline of the proposed work to improve the accuracy of existing models.",diabetic retinopathy; retinal fundus image segmentation; deep learning; blood vessels; retinal lesions; optic disc; optic cup
Article,"Phong Thanh Nguyen; Vy Dang Bich Huynh; Khoa Dang Vo; Phuong Thanh Phan; Yang, Eunmok; Joshi, Gyanendra Prasad",An Optimal Deep Learning Based Computer-Aided Diagnosis System for Diabetic Retinopathy,cmc-computers materials & continua,2021,Not found,"Diabetic Retinopathy (DR) is a significant blinding disease that poses serious threat to human vision rapidly. Classification and severity grading of DR are difficult processes to accomplish. Traditionally, it depends on ophthalmoscopically-visible symptoms of growing severity, which is then ranked in a stepwise scale from no retinopathy to various levels of DR severity. This paper presents an ensemble of Orthogonal Learning Particle Swarm Optimization (OPSO) algorithm-based Convolutional Neural Network (CNN) Model EOPSO-CNN in order to perform DR detection and grading. The proposed EOPSO-CNN model involves three main processes such as preprocessing, feature extraction, and classification. The proposed model initially involves preprocessing stage which removes the presence of noise in the input image. Then, the watershed algorithm is applied to segment the preprocessed images. Followed by, feature extraction takes place by leveraging EOPSO-CNN model. Finally, the extracted feature vectors are provided to a Decision Tree (DT) classifier to classify the DR images. The study experiments were carried out using Messidor DR Dataset and the results showed an extraordinary performance by the proposed method over compared methods in a considerable way. The simulation outcome offered the maximum classification with accuracy, sensitivity, and specificity values being 98.47%, 96.43%, and 99.02% respectively.",diabetic retinopathy; convolutional neural network; classification; image processing; computer-aided diagnosis
Review; Early Access,"Gargi, M.; Namburu, Anupama",Severity Detection of Diabetic Retinopathy - A Review,international journal of image and graphics,0,Not found,"Diabetic Retinopathy (DR) refers to a micro-vascular complication causing vision problems in diabetic patients. It is a serious global public health issue that damages the retinal blood vessels and leaves a large number of patients with loss of vision. Micro-aneurysms, hemorrhages, macular edema, and exudates are some of the lesions used to diagnose it. When detected early, Diabetic Retinopathy can be treated well with precise identification of lesions. Computer-aided diagnosis refers to the approaches used to extract specific features associated with the disease by using image processing filters. Some Machine Learning tools, especially the ones well-suited to data analysis applications are particularly useful. This paper primarily focuses on a comparative performance evaluation of many machine learning and deep learning-based techniques applied for the diagnosis of this vision ailment in diabetic patients.",diabetic retinopathy; machine learning; deep learning; computer aided diagnosis; lesion detection
Review,"Raman, Rajiv; Dasgupta, Debarati; Ramasamy, Kim; George, Ronnie; Mohan, Viswanathan; Ting, Daniel",Using artificial intelligence for diabetic retinopathy screening: Policy implications,indian journal of ophthalmology,2021,Not found,"Artificial intelligence (AI) has evolved over the last few years; its use in DR screening has been demonstrated in multiple evidences across the globe. However, there are concerns right from the data acquisition, bias in data, difficulty in comparing between different algorithm, challenges in machine learning, its application in different group of population, and human barrier to AI adoption in health care. There are also legal and ethical concerns related to AI. The tension between risks and concerns on one hand versus potential and opportunity on the other have driven a need for authorities to implement policies for AI in DR screening to address these issues. The policy makers should support and facilitate research and development of AI in healthcare, but at the same time, it has to be ensured that the use of AI in healthcare aligns with recognized standards of safety, efficacy, and equity. It is essential to ensure that algorithms, datasets, and decisions are auditable and when applied to medical care (such as screening, diagnosis, or treatment) are clinically validated and explainable. Policy frameworks should require design of AI systems in health care that are informed by real-world workflow and human-centric design. Lastly, it should be ensured that healthcare AI solutions align with all relevant ethical obligations, from design to development to use and to be delivered properly in the real world.",artificial intelligence; diabetic retinopathy; machine learning; policy implications
Article,"Farooq, Muhammad Shoaib; Arooj, Ansif; Alroobaea, Roobaea; Baqasah, Abdullah M.; Jabarulla, Mohamed Yaseen; Singh, Dilbag; Sardar, Ruhama",Untangling Computer-Aided Diagnostic System for Screening Diabetic Retinopathy Based on Deep Learning Techniques,sensors,2022,Not found,"Diabetic Retinopathy (DR) is a predominant cause of visual impairment and loss. Approximately 285 million worldwide population is affected with diabetes, and one-third of these patients have symptoms of DR. Specifically, it tends to affect the patients with 20 years or more with diabetes, but it can be reduced by early detection and proper treatment. Diagnosis of DR by using manual methods is a time-consuming and expensive task which involves trained ophthalmologists to observe and evaluate DR using digital fundus images of the retina. This study aims to systematically find and analyze high-quality research work for the diagnosis of DR using deep learning approaches. This research comprehends the DR grading, staging protocols and also presents the DR taxonomy. Furthermore, identifies, compares, and investigates the deep learning-based algorithms, techniques, and, methods for classifying DR stages. Various publicly available dataset used for deep learning have also been analyzed and dispensed for descriptive and empirical understanding for real-time DR applications. Our in-depth study shows that in the last few years there has been an increasing inclination towards deep learning approaches. 35% of the studies have used Convolutional Neural Networks (CNNs), 26% implemented the Ensemble CNN (ECNN) and, 13% Deep Neural Networks (DNN) are amongst the most used algorithms for the DR classification. Thus using the deep learning algorithms for DR diagnostics have future research potential for DR early detection and prevention based solution.",diabetic retinopathy; deep learning; deep neural network; automated detection
Article,"Chetoui, Mohamed; Akhloufi, Moulay A.",Explainable end-to-end deep learning for diabetic retinopathy detection across multiple datasets,journal of medical imaging,2020,Not found,"Purpose: Diabetic retinopathy (DR) is characterized by retinal lesions affecting people having diabetes for several years. It is one of the leading causes of visual impairment worldwide. To diagnose this disease, ophthalmologists need to manually analyze retinal fundus images. Computer-aided diagnosis systems can help alleviate this burden by automatically detecting DR on retinal images, thus saving physicians' precious time and reducing costs. The objective of this study is to develop a deep learning algorithm capable of detecting DR on retinal fundus images. Nine public datasets and more than 90,000 images are used to assess the efficiency of the proposed technique. In addition, an explainability algorithm is developed to visually show the DR signs detected by the deep model. Approach: The proposed deep learning algorithm fine-tunes a pretrained deep convolutional neural network for DR detection. The model is trained on a subset of EyePACS dataset using a cosine annealing strategy for decaying the learning rate with warm up, thus improving the training accuracy. Tests are conducted on the nine datasets. An explainability algorithm based on gradient-weighted class activation mapping is developed to visually show the signs selected by the model to classify the retina images as DR. Result: The proposed network leads to higher classification rates with an area under curve (AUC) of 0.986, sensitivity = 0.958, and specificity = 0.971 for EyePACS. For MESSIDOR, MESSIDOR-2, DIARETDB0, DIARETDB1, STARE, IDRID, E-ophtha, and UoA-DR, the AUC is 0.963, 0.979, 0.986, 0.988, 0.964, 0.957, 0.984, and 0.990, respectively. Conclusions: The obtained results achieve state-of-the-art performance and outperform past published works relying on training using only publicly available datasets. The proposed approach can robustly classify fundus images and detect DR. An explainability model was developed and showed that our model was able to efficiently identify different signs of DR and detect this health issue. (C) 2020 Society of Photo Optical Instrumentation Engineers (SPIE)",diabetic retinopathy; convolutional neural networks; residual networks; inception; microaneurysms; exudates and hemorrhage
Proceedings Paper,"Sivapriya, G.; Keerthika, P.",Computer aided diagnosis systems using deep learning for retinal diseases: A survey,materials today-proceedings,2022,Not found,"Classification and segmentation of blood vessels, lesions, exudates in the retina play a great role in the detection and classification of different ocular diseases like diabetic retinopathy, glaucoma and Familial Exudative Vitreoretinopathy (FEVR). To monitor and analyze microvascular and systematic diseases, classification and segmentation of blood vessels and optic disk are primary tasks. Many research works are being carried out from past one decade concentrating on various classification and segmentation algorithm which helps the ophthalmologists in the quicker diagnosis of retinal diseases. Image processing-based segmentation algorithms were used in the early days. After the evolution of Machine Learning (ML) and Deep Learning (DL) algorithms, many researchers started focusing on applying it in various fields. Here the review focuses on medical image analysis of the retina. In this review, a detailed survey is done on deep learning methods applied for retinal diseases in fundus images with high-quality papers published from 2012 to 2021. It typically focuses on appropriate preprocessing methods, classification, and segmentation models designed with deep learning algorithms. A glimpse of available and mostly preferred datasets for various retinal diseases, costs, and benefits of each model are given and highlighted in terms of the results produced. An attempt is made to assess the deep learning architectures with the help of accuracy, sensitivity, specificity produced by each model. The impact of this study helps in future research directions in medical image analysis and the segmentation of retinal diseases. Copyright (c) 2022 Elsevier Ltd. All rights reserved. Selection and peer-review under responsibility of the scientific committee of the International Conference on Artificial Intelligence & Energy Systems.",diabetic retinopathy; glaucoma; vessel segmentation; hemorrhages; medical imaging; deep learning; diabetic retinopathy; glaucoma; vessel segmentation; hemorrhages; medical imaging; deep learning
Proceedings Paper,"Levenkova, Anastasia; Sowmya, Arcot; Kalloniatis, Michael; Ly, Angelica; Ho, Arthur",Lesion detection in ultra-wide field retinal images for diabetic retinopathy diagnosis,medical imaging 2018: computer-aided diagnosis,2018,Not found,"Diabetic retinopathy (DR) leads to irreversible vision loss. Diagnosis and staging of DR is usually based on the presence, number, location and type of retinal lesions. Ultra-wide field (UWF) digital scanning laser technology provides an opportunity for computer-aided DR lesion detection. High-resolution UWF images (3078x2702 pixels) may allow detection of more clinically relevant retinopathy in comparison with conventional retinal images as UWF imaging covers a 200 degrees retinal area, versus 45 degrees by conventional cameras. Current approaches to DR diagnosis that analyze 7-field Early Treatment Diabetic Retinopathy Study (ETDRS) retinal images provide similar results to UWF imaging. However, in 40% of cases, more retinopathy was found outside the 7-field ETDRS fields by UWF and in 10% of cases, retinopathy was reclassified as more severe. The reason is that UWF images examine both the central retina and more peripheral regions. We propose an algorithm for automatic detection and classification of DR lesions such as cotton wool spots, exudates, microaneurysms and haemorrhages in UWF images. The algorithm uses convolutional neural network (CNN) as a feature extractor and classifies the feature vectors extracted from colour-composite UWF images using a support vector machine (SVM). The main contribution includes detection of four types of DR lesions in the peripheral retina for diagnostic purposes. The evaluation dataset contains 146 UWF images. The proposed method for detection of DR lesion subtypes in UWF images using two scenarios for transfer learning achieved AUC approximate to 80%. Data was split at the patient level to validate the proposed algorithm.",computer-aided diagnosis; diabetic retinopathy; ultra-wide field retinal imaging; deep learning; convolutional neural network
Article,"Heisler, Morgan; Karst, Sonja; Lo, Julian; Mammo, Zaid; Yu, Timothy; Warner, Simon; Maberley, David; Beg, Mirza Faisal; Navajas, Eduardo, V; Sarunic, Marinko, V",Ensemble Deep Learning for Diabetic Retinopathy Detection Using Optical Coherence Tomography Angiography,translational vision science & technology,2020,Not found,"Purpose: To evaluate the role of ensemble learning techniques with deep learning in classifying diabetic retinopathy (DR) in optical coherence tomography angiography (OCTA) images and their corresponding co-registered structural images. Methods: A total of 463 volumes from 380 eyes were acquired using the 3 x 3-mm OCTA protocol on the Zeiss Plex Elite system. Enface images of the superficial and deep capillary plexus were exported from both the optical coherence tomography and OCTA data. Component neural networks were constructed using single data-types and fine-tuned using VGG19, ResNet50, and DenseNet architectures pretrained on ImageNet weights. These networks were then ensembled using majority soft voting and stacking techniques. Results were compared with a classifier using manually engineered features. Class activation maps (CAMs) were created using the original CAM algorithm and Grad-CAM. Results: The networks trained with the VGG19 architecture outperformed the networks trained on deeper architectures. Ensemble networks constructed using the four fine-tuned VGG19 architectures achieved accuracies of 0.92 and 0.90 for the majority soft voting and stacking methods respectively. Both ensemble methods outperformed the highest single data-type network and the network trained on hand-crafted features. Grad-CAM was shown to more accurately highlight areas of disease. Conclusions: Ensemble learning increases the predictive accuracy of CNNs for classifying referable DR on OCTA datasets. Translational Relevance: Because the diagnostic accuracy of OCTA images is shown to be greater than the manually extracted features currently used in the literature, the proposed methods may be beneficial toward developing clinically valuable solutions for DR diagnoses.",machine learning; diabetic retinopathy; deep learning; optical coherence tomography; optical coherence tomography angiography
Article,"Nneji, Grace Ugochi; Cai, Jingye; Deng, Jianhua; Monday, Happy Nkanta; Hossin, Md Altab; Nahar, Saifun",Identification of Diabetic Retinopathy Using Weighted Fusion Deep Learning Based on Dual-Channel Fundus Scans,diagnostics,2022,Not found,"It is a well-known fact that diabetic retinopathy (DR) is one of the most common causes of visual impairment between the ages of 25 and 74 around the globe. Diabetes is caused by persistently high blood glucose levels, which leads to blood vessel aggravations and vision loss. Early diagnosis can minimise the risk of proliferated diabetic retinopathy, which is the advanced level of this disease, and having higher risk of severe impairment. Therefore, it becomes important to classify DR stages. To this effect, this paper presents a weighted fusion deep learning network (WFDLN) to automatically extract features and classify DR stages from fundus scans. The proposed framework aims to treat the issue of low quality and identify retinopathy symptoms in fundus images. Two channels of fundus images, namely, the contrast-limited adaptive histogram equalization (CLAHE) fundus images and the contrast-enhanced canny edge detection (CECED) fundus images are processed by WFDLN. Fundus-related features of CLAHE images are extracted by fine-tuned Inception V3, whereas the features of CECED fundus images are extracted using fine-tuned VGG-16. Both channels' outputs are merged in a weighted approach, and softmax classification is used to determine the final recognition result. Experimental results show that the proposed network can identify the DR stages with high accuracy. The proposed method tested on the Messidor dataset reports an accuracy level of 98.5%, sensitivity of 98.9%, and specificity of 98.0%, whereas on the Kaggle dataset, the proposed model reports an accuracy level of 98.0%, sensitivity of 98.7%, and specificity of 97.8%. Compared with other models, our proposed network achieves comparable performance.",clahe; ceced; deep learning; fundus scan; diabetic retinopathy; image identification
Article,"Nanda, Pranamita; Duraipandian, N.",A Novel Optimizer in Deep Neural Network for Diabetic Retinopathy Classification,computer systems science and engineering,2022,Not found,"In severe cases, diabetic retinopathy can lead to blindness. For decades, automatic classification of diabetic retinopathy images has been a challenge. Medical image processing has benefited from advances in deep learning systems. To enhance the accuracy of image classification driven by Convolutional Neural Network (CNN), balanced dataset is generated by data augmentation method followed by an optimized algorithm. Deep neural networks (DNN) are frequently optimized using gradient (GD) based techniques. Vanishing gradient is the main drawback of GD algorithms. In this paper, we suggest an innovative algorithm, to solve the above problem, Hypergradient Descent learning rate based Quasi hyperbolic (HDQH) gradient descent to optimize the weights and biases. The algorithms only use first order gradients, which reduces computation time and storage space requirements. The algorithms do not require more tuning of the learning rates as the learning rate tunes itself by means of gradients. We present empirical evaluation of our algorithm on two public retinal image datasets such as Messidor and DDR by using Resnet18 and Inception V3 architectures. The findings of the experiment show that the efficiency and accuracy of our algorithm outperforms the other cutting-edge algorithms. HDQHAdam shows the highest accuracy of 97.5 on Resnet18 and 95.7 on Inception V3 models respectively.",cnn; diabetic retinopathy; data augmentation; gradient descent; deep learning; optimization
Article,"Ragab, Mahmoud; Aljedaibi, Wajdi H.; Nahhas, Alaa F.; Alzahrani, Ibrahim R.",Computer aided diagnosis of diabetic retinopathy grading using spiking neural network,computers & electrical engineering,2022,Not found,"The recently developed deep learning models can be employed to design computer aided diagnosis (CAD) models for diabetic retinopathy (DR). Though several DR classification approaches are available in the survey, but still there is need to improve the overall DR detection performance. With this motivation, this paper design a novel metaheuristic with deep learning enabled computer aided diagnosis model for DR (MDL-CADDR) detection and grading. The proposed MDL-CADDR technique involves pre-processing stage to boost the quality of fundus images. In addition, Archimedes Optimization Algorithm (AOA) with Kapur's Entropy (AOA-KE) based image segmentation technique is applied. Moreover, Chimp Optimization Algorithm with DenseNet (COA-DN) based Feature Extraction and Spiking Neural Network (SNN) based classification processes are performed to classify distinct stages of DR. The performance validation of the MDLCADDR technique on benchmark MESSIDOR data set pointed out the supremacy of the MDLCADDR technique with maximum accuracy of 99.73%.",computer aided diagnosis; deep learning; densenet; diabetic retinopathy; metaheuristics; deep transfer learning; spiking neural network
Proceedings Paper,"Nugroho, Hanung Adi; Frannita, Eka Legya",Intelligent Diabetic Retinopathy Detection using Deep Learning,2021 4th international seminar on research of information technology and intelligent systems (isriti 2021),2020,Not found,"Diabetic retinopathy (DR) is the most common illness related to diabetes caused by the increasing of glucose in human blood and has been dramatically increased in the last decade. Practically, DR is examined by conducting manual analysis on retina images resulted from fundus camera modality in which can lead to some problems such as time-consuming, need more thoroughness and properly skill and experience. Due to the insufficient number of ophthalmologists, especially in rural areas, an alternative solution in supporting diagnosis properly is needed. Regarding to those issues, some research communities have proposed intelligent system for detecting DR. Despite some previous intelligent DR detection have been developed, there still remained problem that quality of image was extremely affect the performance. Hence, in this study we proposed an intelligent DR detection completed with image enhancement process for maintaining the model performance. Our proposed solution was performed in 200 retina images consisting of two classes (normal and abnormal or DR). Our proposed solution successfully increased the performance with the highest accuracy, sensitivity, specificity, positive predictive value, and negative predictive value of 0.92, 0.95, 0.81, 0.95, 0.81, respectively. This result has increased by around of 40%in most of evaluation metrics of the model's performance without an image enhancement process. It indicates that conducting image enhancement process before training the model was important to increase the model performance and to prevent the miss-detection.",diabetes; diabetic retinopathy; deep learning; image enhancement
Review,"Keskinbora, Kadircan; Guven, Fatih",Artificial Intelligence and Ophthalmology,turk oftalmoloji dergisi-turkish journal of ophthalmology,2020,Not found,"Artificial intelligence is advancing rapidly and making its way into all areas of our lives. This review discusses developments and potential practices regarding the use of artificial intelligence in the field of ophthalmology, and the related topic of medical ethics. Various artificial intelligence applications related to the diagnosis of eye diseases were researched in books, journals, search engines, print and social media. Resources were cross-checked to verify the information. Artificial intelligence algorithms, some of which were approved by the US Food and Drug Administration, have been adopted in the field of ophthalmology, especially in diagnostic studies. Studies are being conducted that prove that artificial intelligence algorithms can be used in the field of ophthalmology, especially in diabetic retinopathy, age-related macular degeneration, and retinopathy of prematurity. Some of these algorithms have come to the approval stage. The current point in artificial intelligence studies shows that this technology has advanced considerably and shows promise for future work. It is believed that artificial intelligence applications will be effective in identifying patients with preventable vision loss and directing them to physicians, especially in developing countries where there are fewer trained professionals and physicians are difficult to reach. When we consider the possibility that some future artificial intelligence systems may be candidates for moral/ethical status, certain ethical issues arise. Questions about moral/ethical status are important in some areas of applied ethics. Although it is accepted that current intelligence systems do not have moral/ethical status, is has yet to be determined what the exact the characteristics that confer moral/ethical status are or will be.",artificial intelligence; machine learning; deep learning; ophthalmology; medical ethics
Article; Early Access,"Kalyani, G.; Janakiramaiah, B.; Karuna, A.; Prasad, L. V. Narasimha",Diabetic retinopathy detection and classification using capsule networks,complex & intelligent systems,0,Not found,"Nowadays, diabetic retinopathy is a prominent reason for blindness among the people who suffer from diabetes. Early and timely detection of this problem is critical for a good prognosis. An automated system for this purpose contains several phases like identification and classification of lesions in fundus images. Machine learning techniques based on manual extraction of features and automatic extraction of features with convolution neural network have been presented for diabetic retinopathy detection. The recent developments like capsule networks in deep learning and their significant success over traditional machine learning methods for a variety of applications inspired the researchers to apply them for diabetic retinopathy diagnosis. In this paper, a reformed capsule network is developed for the detection and classification of diabetic retinopathy. Using the convolution and primary capsule layer, the features are extracted from the fundus images and then using the class capsule layer and softmax layer the probability that the image belongs to a specific class is estimated. The efficiency of the proposed reformed network is validated concerning four performance measures by considering the Messidor dataset. The constructed capsule network attains an accuracy of 97.98%, 97.65%, 97.65%, and 98.64% on the healthy retina, stage 1, stage 2, and stage 3 fundus images.",diabetic retinopathy; deep learning; capsule networks; classification
Article,"Bhardwaj, Charu; Jain, Shruti; Sood, Meenakshi",Deep Learning-Based Diabetic Retinopathy Severity Grading System Employing Quadrant Ensemble Model,journal of digital imaging,2021,Not found,"The diabetic retinopathy accounts in the deterioration of retinal blood vessels leading to a serious compilation affecting the eyes. The automated DR diagnosis frameworks are critically important for the early identification and detection of these eye-related problems, helping the ophthalmic experts in providing the second opinion for effectual treatment. The deep learning techniques have evolved as an improvement over the conventional approaches, which are dependent on the handcrafted feature extraction. To address the issue of proficient DR discrimination, the authors have proposed a quadrant ensemble automated DR grading approach by implementing InceptionResnet-V2 deep neural network framework. The presented model incorporates histogram equalization, optical disc localization, and quadrant cropping along with the data augmentation step for improving the network performance. A superior accuracy performance of 93.33% is observed for the proposed framework, and a significant reduction of 0.325 is noticed in the cross-entropy loss function for MESSIDOR benchmark dataset; however, its validation utilizing the latest IDRiD dataset establishes its generalization ability. The accuracy improvement of 13.58% is observed when the proposed QEIRV-2 model is compared with the classical Inception-V3 CNN model. To justify the viability of the proposed framework, its performance is compared with the existing state-of-the-art approaches and 25.23% of accuracy improvement is observed.",diabetic retinopathy; deep neural network; convolution neural network; hand-crafted features; inceptionresnet-v2; data augmentation
Article,"Majumder, Sharmin; Kehtarnavaz, Nasser",Multitasking Deep Learning Model for Detection of Five Stages of Diabetic Retinopathy,ieee access,2021,Not found,"Early diagnosis and treatment of diabetic retinopathy (DR) can reduce the risk of vision loss. There are five stages of DR consisting of no DR, mild DR, moderate DR, severe DR, and proliferate DR. This paper presents a multitask deep learning model to detect all the five stages of DR more accurately than existing methods. The developed multitask model consists of one classification model and one regression model, each with its own loss function. After training the regression model and the classification model separately, the features extracted by these two models are concatenated and inputted to a multilayer perceptron network to classify the five stages of DR. A modified Squeeze Excitation Densely Connected deep neural network is also developed as part of this multitasking approach. The developed multitask model is applied to the two large Kaggle datasets of APTOS and EyePACS. The results obtained indicate that the developed multitask model achieved a weighted Kappa score of 0.90 and 0.88 for the APTOS and EyePACS datasets, respectively. In addition, the micro and macro average area under the receiver operating characteristic (ROC) curve was found to be 0.96, and 0.93, respectively, which are higher than existing methods for detecting the five stages of DR.",deep learning; multitasking; diabetes; task analysis; retina; lesions; convolutional neural networks; diabetic retinopathy (dr); eye fundus images; five stages of diabetic retinopathy; multitasking deep neural network; squeeze excitation densely connected network
Article,"Alahmadi, Mohammad D.",Texture Attention Network for Diabetic Retinopathy Classification,ieee access,2022,Not found,"Diabetic Retinopathy (DR) is a disease caused by a high level of glucose in retina vessels. This malicious disease put millions of people around the world at risk for vision loss each year. Being a life-threatening disease, early diagnosis can be an effective step in the treatment and prevention of vision loss. To automate the early diagnosis process, computer-aided diagnosis methods are not only useful in detecting the diabetic signatures but also provide information regarding the diabetic grade for the optometrist to determine an appropriate treatment. Several deep classification models are proposed in the literature to solve the diabetic retinopathy classification task, however, these methods usually lack incorporate an attention mechanism to better encode the semantic dependency and highlight the most important region for boosting the model performance. To overcome these limitations, we propose to incorporate a style and content recalibration mechanism inside the deep neural network to adaptively scale the informative regions for diabetic retinopathy classification. In our proposed method, the input image passes through the encoder module to encode both high-level and semantic features. Next, by utilizing a content and style separation mechanism, we decompose the representational space into a style (e.g., texture features) and content (e.g., semantic and contextual features) representation. The texture attention module takes the style representation and applies a high-pass filter to highlight the texture information while the spatial normalization module uses a convolutional operation to determine the more informative region inside the retinopathy image to detect diabetic signs. Once the attention modules are applied to the representational features, the fusion module combines both features to form a normalized representation for the decoding path. The decoder module in our model performs both diabetic grading and healthy, non-healthy classification tasks. Our experiment on APTOS Kaggle dataset (accuracy 0.85) demonstrates a significant improvement compared to the literature work. This fact reveals the applicability of our method in a real-world scenario.",diabetes; retinopathy; retina; feature extraction; biomedical imaging; deep learning; blood; diabetic retinopathy; deep learning; attention; classification
Article,"Kaushik, Harshit; Singh, Dilbag; Kaur, Manjit; Alshazly, Hammam; Zaguia, Atef; Hamam, Habib",Diabetic Retinopathy Diagnosis From Fundus Images Using Stacked Generalization of Deep Models,ieee access,2021,Not found,"Diabetic retinopathy (DR) is a diabetes complication that affects the eye and can cause damage from mild vision problems to complete blindness. It has been observed that the eye fundus images show various kinds of color aberrations and irrelevant illuminations, which degrade the diagnostic analysis and may hinder the results. In this research, we present a methodology to eliminate these unnecessary reflectance properties of the images using a novel image processing schema and a stacked deep learning technique for the diagnosis. For the luminosity normalization of the image, the gray world color constancy algorithm is implemented which does image desaturation and improves the overall image quality. The effectiveness of the proposed image enhancement technique is evaluated based on the peak signal to noise ratio (PSNR) and mean squared error (MSE) of the normalized image. To develop a deep learning based computer-aided diagnostic system, we present a novel methodology of stacked generalization of convolution neural networks (CNN). Three custom CNN model weights are fed on the top of a single meta-learner classifier, which combines the most optimum weights of the three sub-neural networks to obtain superior metrics of evaluation and robust prediction results. The proposed stacked model reports an overall test accuracy of 97.92% (binary classification) and 87.45% (multi-class classification). Extensive experimental results in terms of accuracy, F-measure, sensitivity, specificity, recall and precision reveal that the proposed methodology of illumination normalization greatly facilitated the deep learning model and yields better results than various state-of-art techniques.",image color analysis; retina; lighting; feature extraction; image processing; diabetes; deep learning; convolutional neural networks; diabetic retinopathy; early diagnosis; fundus images; gray world algorithm; ensemble learning
Article,"Abbas, Qaisar",DME-Deep: A Computerize Tool for Detection of Diabetic Macular Edema Grading Based on Multilayer Deep Learning and Transfer Learning,international journal of medical research & health sciences,2020,Not found,"Diabetic macular edema (DME) is a common disease of diabetic retinopathy (DR). Due to the infection of DME disease, many patients 'vision is lost. To cure DME eye disease, early detection and treatment are very important and vital steps. To automatically diagnosis DEM disease, several studies were developed by detection of the macula center which is dependent on optic disc (OD) location. In this paper, a novel features pre-training based model was proposed based on dense convolutional neural network (DCNN) to diagnose DME related disease. As a result, a computerize tool DME-Deep for detection of DME-based grading system was implemented through a new dense deep learning model and feature 's transfer learning approaches. This DCNN model was developed by adding new five convolutional and one dropout layers to the network. The DME-Deep system was tested on three different datasets, which obtained from online sources. To train the DCNN model for features learning, the 1650 retinal fundus images were utilized from the Hamilton HEI-MED, ISBI 2018 IDRiD and MESSIDOR datasets. On datasets, the DME-Deep achieved 91.2% of accuracy, 87.5% of sensitivity and 94.4% of specificity. Compare to obtain hand-crafted features, the automatic feature' learning it provided favorable results. Hence, the experimental results also indicate that this DME-Deep system can automatically assist ophthalmologists in finding DEM eye-related disease.",diabetic retinopathy; retinal fundus image; diabetic macular edema; deep learning; convolutional neural network; transfer learning
Article,"Yang, Wei-Hua; Zheng, Bo; Wu, Mao-Nian; Zhu, Shao-Jun; Fei, Fang-Qin; Weng, Ming; Zhang, Xian; Lu, Pei-Rong",An Evaluation System of Fundus Photograph-Based Intelligent Diagnostic Technology for Diabetic Retinopathy and Applicability for Research,diabetes therapy,2019,Not found,"Introduction In April 2018, the US Food and Drug Administration (FDA) approved the world's first artificial intelligence (AI) medical device for detecting diabetic retinopathy (DR), the IDx-DR. However, there is a lack of evaluation systems for DR intelligent diagnostic technology. Methods Five hundred color fundus photographs of diabetic patients were selected. DR severity varied from grade 0 to 4, with 100 photographs for each grade. Following that, these were diagnosed by both ophthalmologists and the intelligent technology, the results of which were compared by applying the evaluation system. The system includes primary, intermediate, and advanced evaluations, of which the intermediate evaluation incorporated two methods. Main evaluation indicators were sensitivity, specificity, and kappa value. Results The AI technology diagnosed 93 photographs with no DR, 107 with mild non-proliferative DR (NPDR), 107 with moderate NPDR, 108 with severe NPDR, and 85 with proliferative DR (PDR). The sensitivity, specificity, and kappa value of the AI diagnoses in the primary evaluation were 98.8%, 88.0%, and 0.89, respectively. According to method 1 of the intermediate evaluation, the sensitivity of AI diagnosis was 98.0%, specificity 97.0%, and the kappa value 0.95. In method 2 of the intermediate evaluation, the sensitivity of AI diagnosis was 95.5%, the specificity 99.3%, and kappa value 0.95. In the advanced evaluation, the kappa value of the intelligent diagnosis was 0.86. Conclusions This article proposes an evaluation system for color fundus photograph-based intelligent diagnostic technology of DR and demonstrates an application of this system in a clinical setting. The results from this evaluation system serve as the basis for the selection of scenarios in which DR intelligent diagnostic technology can be applied.",deep learning; diabetic retinopathy; evaluation studies; ophthalmological diagnostic techniques
Article,"Ming, Shuai; Xie, Kunpeng; Lei, Xiang; Yang, Yingrui; Zhao, Zhaoxia; Li, Shuyin; Jin, Xuemin; Lei, Bo",Evaluation of a novel artificial intelligence-based screening system for diabetic retinopathy in community of China: a real-world study,international ophthalmology,2021,Not found,"Purpose To evaluate the performance of an AI-based diabetic retinopathy (DR) grading model in real-world community clinical setting. Methods Participants with diabetes on record in the chosen community were recruited by health care staffs in a primary clinic of Zhengzhou city, China. Retinal images were prospectively collected during December 2018 and April 2019 based on intent-to-screen principle. A pre-validated AI system based on deep learning algorithm was deployed to screen DR graded according to the International Clinical Diabetic Retinopathy scale. Kappa value of DR severity, the sensitivity, specificity of detecting referable DR (RDR) and any DR were generated based on the standard of the majority manual grading decision of a retina specialist panel. Results Of the 193 eligible participants, 173 (89.6%) were readable with at least one eye image. Mean [SD] age was 69.3 (9.0) years old. Total of 321 eyes (83.2%) were graded both by AI and the specialist panel. The kappa value in eye image grading was 0.715. The sensitivity, specificity and area under curve for detection of RDR were 84.6% (95% CI: 54.6- 98.1%), 98.0% (95% CI: 94.3-99.6%) and 0.913 (95% CI: 0.797-1.000), respectively. For detection of any DR, the upper indicators were 90.0% (95% CI: 68.3-98.8), 96.6% (95% CI: 92.1-98.9) and 0.933 (95% CI: 0.933-1.000), respectively. Conclusion The AI system showed relatively good consistency with ophthalmologist diagnosis in DR grading, high specificity and acceptable sensitivity for identifying RDR and any DR. Translational relevance It is feasible to apply AI-based DR screening in community. Precis Deployed in community real-world clinic setting, AI-based DR screening system showed high specificity and acceptable sensitivity in identifying RDR and any DR. Good DR diagnostic consistency was found between AI and manual grading. These prospective evidences were essential for regulatory approval.",artificial intelligence; diabetic retinopathy; deep neural network; fundus photography; rreal-world study
Article,"Alam, Minhaj; Le, David; Lim, Jennifer, I; Chan, Robison V. P.; Yao, Xincheng",Supervised Machine Learning Based Multi-Task Artificial Intelligence Classification of Retinopathies,journal of clinical medicine,2019,Not found,"Artificial intelligence (AI) classification holds promise as a novel and affordable screening tool for clinical management of ocular diseases. Rural and underserved areas, which suffer from lack of access to experienced ophthalmologists may particularly benefit from this technology. Quantitative optical coherence tomography angiography (OCTA) imaging provides excellent capability to identify subtle vascular distortions, which are useful for classifying retinovascular diseases. However, application of AI for differentiation and classification of multiple eye diseases is not yet established. In this study, we demonstrate supervised machine learning based multi-task OCTA classification. We sought (1) to differentiate normal from diseased ocular conditions, (2) to differentiate different ocular disease conditions from each other, and (3) to stage the severity of each ocular condition. Quantitative OCTA features, including blood vessel tortuosity (BVT), blood vascular caliber (BVC), vessel perimeter index (VPI), blood vessel density (BVD), foveal avascular zone (FAZ) area (FAZ-A), and FAZ contour irregularity (FAZ-CI) were fully automatically extracted from the OCTA images. A stepwise backward elimination approach was employed to identify sensitive OCTA features and optimal-feature-combinations for the multi-task classification. For proof-of-concept demonstration, diabetic retinopathy (DR) and sickle cell retinopathy (SCR) were used to validate the supervised machine leaning classifier. The presented AI classification methodology is applicable and can be readily extended to other ocular diseases, holding promise to enable a mass-screening platform for clinical deployment and telemedicine.",ophthalmology; diabetic retinopathy; sickle cell retinopathy; quantitative analysis; computer aided diagnosis; artificial intelligence; support vector machine; optical coherence tomography angiography
Article,"Porwal, Prasanna; Pachade, Samiksha; Kokare, Manesh; Deshmukh, Girish; Son, Jaemin; Bae, Woong; Liu, Lihong; Wang, Jianzong; Liu, Xinhui; Gao, Liangxin; Wu, TianBo; Xiao, Jing; Wang, Fengyan; Yin, Baocai; Wang, Yunzhi; Danala, Gopichandh; He, Linsheng; Choi, Yoon Ho; Lee, Yeong Chan; Jung, Sang-Hyuk; Li, Zhongyu; Sui, Xiaodan; Wu, Junyan; Li, Xiaolong; Zhou, Ting; Toth, Janos; Bara, Agnes; Kori, Avinash; Chennamsetty, Sai Saketh; Safwan, Mohammed; Alex, Varghese; Lyu, Xingzheng; Cheng, Li; Chu, Qinhao; Li, Pengcheng; Ji, Xin; Zhang, Sanyuan; Shen, Yaxin; Dai, Ling; Saha, Oindrila; Sathish, Rachana; Melo, Tania; Araujo, Teresa; Harangi, Balazs; Sheng, Bin; Fang, Ruogu; Sheet, Debdoot; Hajdu, Andras; Zheng, Yuanjie; Mendonca, Ana Maria; Zhang, Shaoting; Campilho, Aurelio; Zheng, Bin; Shen, Dinggang; Giancardo, Luca; Quellec, Gwenole; Meriaudeau, Fabrice",IDRiD: Diabetic Retinopathy - Segmentation and Grading Challenge,medical image analysis,2020,Not found,"Diabetic Retinopathy (DR) is the most common cause of avoidable vision loss, predominantly affecting the working-age population across the globe. Screening for DR, coupled with timely consultation and treatment, is a globally trusted policy to avoid vision loss. However, implementation of DR screening programs is challenging due to the scarcity of medical professionals able to screen a growing global diabetic population at risk for DR. Computer-aided disease diagnosis in retinal image analysis could provide a sustainable approach for such large-scale screening effort. The recent scientific advances in computing capacity and machine learning approaches provide an avenue for biomedical scientists to reach this goal. Aiming to advance the state-of-the-art in automatic DR diagnosis, a grand challenge on Diabetic Retinopathy - Segmentation and Grading was organized in conjunction with the IEEE International Symposium on Biomedical Imaging (ISBI-2018). In this paper, we report the set-up and results of this challenge that is primarily based on Indian Diabetic Retinopathy Image Dataset (IDRiD). There were three principal subchallenges: lesion segmentation, disease severity grading, and localization of retinal landmarks and segmentation. These multiple tasks in this challenge allow to test the generalizability of algorithms, and this is what makes it different from existing ones. It received a positive response from the scientific community with 148 submissions from 495 registrations effectively entered in this challenge. This paper outlines the challenge, its organization, the dataset used, evaluation methods and results of top-performing participating solutions. The top-performing approaches utilized a blend of clinical information, data augmentation, and an ensemble of models. These findings have the potential to enable new developments in retinal image analysis and image-based DR screening in particular. (C) 2019 Elsevier B.V. All rights reserved.",diabetic retinopathy; retinal image analysis; deep learning; challenge
Article,"Bilal, Anas; Zhu, Liucun; Deng, Anan; Lu, Huihui; Wu, Ning",AI-Based Automatic Detection and Classification of Diabetic Retinopathy Using U-Net and Deep Learning,symmetry-basel,2022,Not found,"Artificial intelligence is widely applied to automate Diabetic retinopathy diagnosis. Diabetes-related retinal vascular disease is one of the world's most common leading causes of blindness and vision impairment. Therefore, automated DR detection systems would greatly benefit the early screening and treatment of DR and prevent vision loss caused by it. Researchers have proposed several systems to detect abnormalities in retinal images in the past few years. However, Diabetic Retinopathy automatic detection methods have traditionally been based on hand-crafted feature extraction from the retinal images and using a classifier to obtain the final classification. DNN (Deep neural networks) have made several changes in the previous few years to assist overcome the problem mentioned above. We suggested a two-stage novel approach for automated DR classification in this research. Due to the low fraction of positive instances in the asymmetric Optic Disk (OD) and blood vessels (BV) detection system, preprocessing and data augmentation techniques are used to enhance the image quality and quantity. The first step uses two independent U-Net models for OD (optic disc) and BV (blood vessel) segmentation. In the second stage, the symmetric hybrid CNN-SVD model was created after preprocessing to extract and choose the most discriminant features following OD and BV extraction using Inception-V3 based on transfer learning, and detects DR by recognizing retinal biomarkers such as MA (microaneurysms), HM (hemorrhages), and exudates (EX). On EyePACS-1, Messidor-2, and DIARETDB0, the proposed methodology demonstrated state-of-the-art performance, with an average accuracy of 97.92%, 94.59%, and 93.52%, respectively. Extensive testing and comparisons with baseline approaches indicate the efficacy of the suggested methodology.",diabetic retinopathy (dr); dr detection and classification; automatic diagnosis; feature extraction; multi-class segmentation and classification; fundus images (fis); transfer learning
Article,"Araujo, Teresa; Aresta, Guilherme; Mendonca, Luis; Penas, Susana; Maia, Carolina; Carneiro, Angela; Maria Mendonca, Ana; Campilho, Aurelio",DR vertical bar GRADUATE: Uncertainty-aware deep learning-based diabetic retinopathy grading in eye fundus images,medical image analysis,2020,Not found,"Diabetic retinopathy (DR) grading is crucial in determining the adequate treatment and follow up of patient, but the screening process can be tiresome and prone to errors. Deep learning approaches have shown promising performance as computer-aided diagnosis (CAD) systems, but their black-box behaviour hinders clinical application. We propose DR vertical bar GRADUATE, a novel deep learning-based DR grading CAD system that supports its decision by providing a medically interpretable explanation and an estimation of how uncertain that prediction is, allowing the ophthalmologist to measure how much that decision should be trusted. We designed DR vertical bar GRADUATE taking into account the ordinal nature of the DR grading problem. A novel Gaussian-sampling approach built upon a Multiple Instance Learning framework allow DR vertical bar GRADUATE to infer an image grade associated with an explanation map and a prediction uncertainty while being trained only with image-wise labels. DR vertical bar GRADUATE was trained on the Kaggle DR detection training set and evaluated across multiple datasets. In DR grading, a quadratic-weighted Cohen's kappa (kappa) between 0.71 and 0.84 was achieved in five different datasets. We show that high kappa values occur for images with low prediction uncertainty, thus indicating that this uncertainty is a valid measure of the predictions' quality. Further, bad quality images are generally associated with higher uncertainties, showing that images not suitable for diagnosis indeed lead to less trustworthy predictions. Additionally, tests on unfamiliar medical image data types suggest that DR vertical bar GRADUATE allows outlier detection. The attention maps generally highlight regions of interest for diagnosis. These results show the great potential of DR vertical bar GRADUATE as a second-opinion system in DR severity grading. (C) 2020 Elsevier B.V. All rights reserved.",diabetic retinopathy grading; deep learning; uncertainty; explainability
Proceedings Paper,"Di Giammarco, Marcello; Iadarola, Giacomo; Martinelli, Fabio; Mercaldo, Francesco; Santone, Antonella",Explainable Retinopathy Diagnosis and Localisation by means of Class Activation Mapping,2022 international joint conference on neural networks (ijcnn),2022,Not found,"Diabetic retinopathy is a disease afflicting the retina and currently is manually diagnosed by specialists through eye tomography inspection. In order to assist the clinician in this time-consuming task, in this paper, we propose a method aimed to automatically diagnose the (proliferative and non-proliferative) diabetic retinopathy by exploiting deep learning. Furthermore, we investigate the possibility to automatically localise the areas related to the disease by exploiting class activation maps. We evaluate different deep learning models from a quantitative point of view (i.e, using metrics like accuracy, precision and recall) and a qualitative point of view (by exploiting class activation maps and image similarity metrics) with the aim to understand the quality of predictions performed by a model in retinopathy diagnosis, reducing the amount of knowledge required to assess the model performance. From the experimental analysis is emerging that deep learning shows an interesting diagnostic potential in the retinopathy disease localisation and can effectively help the clinician in retinopathy diagnosis. Moreover, the adoption of the class activation maps and its comparison evaluation can help the developers to debug the training step of the model without medical expertise.",retinopathy; deep learning; transfer learning; classification; diagnosis
Article,"Vidal-Alaball, Josep; Royo Fibla, Didac; Zapata, Miguel A.; Marin-Gomez, Francesc X.; Solans Fernandez, Oscar",Artificial Intelligence for the Detection of Diabetic Retinopathy in Primary Care: Protocol for Algorithm Development,jmir research protocols,2019,Not found,"Background: Diabetic retinopathy (DR) is one of the most important causes of blindness worldwide, especially in developed countries. In diabetic patients, periodic examination of the back of the eye using a nonmydriatic camera has been widely demonstrated to be an effective system to control and prevent the onset of DR. Convolutional neural networks have been used to detect DR, achieving very high sensitivities and specificities. Objective: The objective of this is paper was to develop an artificial intelligence (AI) algorithm for the detection of signs of DR in diabetic patients and to scientifically validate the algorithm to be used as a screening tool in primary care. Methods: Under this project, 2 studies will be conducted in a concomitant way: (1) Development of an algorithm with AI to detect signs of DR in patients with diabetes and (2) A prospective study comparing the diagnostic capacity of the AI algorithm with respect to the actual system of family physicians evaluating the images. The standard reference to compare with will be a blinded double reading conducted by retina specialists. For the development of the AI algorithm, different iterations and workouts will be performed on the same set of data. Before starting each new workout, the strategy of dividing the set date into 2 groups will be used randomly. A group with 80% of the images will be used during the training (training dataset), and the remaining 20% images will be used to validate the results (validation dataset) of each cycle (epoch). During the prospective study, true-positive, true-negative, false-positive, and false-negative values will be calculated again. From here, we will obtain the resulting confusion matrix and other indicators to measure the performance of the algorithm. Results: Cession of the images began at the end of 2018. The development of the AI algorithm is calculated to last about 3 to 4 months. Inclusion of patients in the cohort will start in early 2019 and is expected to last 3 to 4 months. Preliminary results are expected to be published by the end of 2019. Conclusions: The study will allow the development of an algorithm based on AI that can demonstrate an equal or superior performance, and that constitutes a complement or an alternative, to the current screening of DR in diabetic patients.",diabetes mellitus; diabetic retinopathy; fundus oculi; artificial intelligence; computer assisted diagnosis; neural network computer
Review,"Schmidt-Erfurth, Ursula; Sadeghipour, Amir; Gerendas, Bianca S.; Waldstein, Sebastian M.; Bogunovic, Hrvoje",Artificial intelligence in retina,progress in retinal and eye research,2018,Not found,"Major advances in diagnostic technologies are offering unprecedented insight into the condition of the retina and beyond ocular disease. Digital images providing millions of morphological datasets can fast and non-invasively be analyzed in a comprehensive manner using artificial intelligence (AI). Methods based on machine learning (ML) and particularly deep learning (DL) are able to identify, localize and quantify pathological features in almost every macular and retinal disease. Convolutional neural networks thereby mimic the path of the human brain for object recognition through learning of pathological features from training sets, supervised ML, or even extrapolation from patterns recognized independently, unsupervised ML. The methods of AI-based retinal analyses are diverse and differ widely in their applicability, interpretability and reliability in different datasets and diseases. Fully automated AI-based systems have recently been approved for screening of diabetic retinopathy (DR). The overall potential of ML/DL includes screening, diagnostic grading as well as guidance of therapy with automated detection of disease activity, recurrences, quantification of therapeutic effects and identification of relevant targets for novel therapeutic approaches. Prediction and prognostic conclusions further expand the potential benefit of AI in retina which will enable personalized health care as well as large scale management and will empower the ophthalmologist to provide high quality diagnosis/therapy and successfully deal with the complexity of 21st century ophthalmology.",artificial intelligence (ai); machine learning (ml); deep learning (dl); automated screening; prognosis and prediction; personalized healthcare (phc)
Article,"Haggag, Sayed; Elnakib, Ahmed; Sharafeldeen, Ahmed; Elsharkawy, Mohamed; Khalifa, Fahmi; Farag, Rania Kamel; Mohamed, Mohamed A.; Sandhu, Harpal Singh; Mansoor, Wathiq; Sewelam, Ashraf; El-Baz, Ayman",A Computer-Aided Diagnostic System for Diabetic Retinopathy Based on Local and Global Extracted Features,applied sciences-basel,2022,Not found,"Featured Application This paper presents a novel deep learning system for the detection and diagnosis of diabetic retinopathy using optical coherence tomography images. Diabetic retinopathy (DR) is a major public health problem and the leading cause of vision loss in the working age population. This paper presents a novel deep learning system for the detection and diagnosis of DR using optical coherence tomography (OCT) images. The input for this system is three-channel local and global information from OCT images. The local high-level information is represented by the thickness channel and the reflectivity channel. The global low-level information is represented by the grey-level OCT original image. The deep learning system processes the three-channel input to produce the final DR diagnoses. Experimental results on 200 OCT images, augmented to 800 images, which are collected by the University of Louisville, show high system performance related to other competing methods. Moreover, 10-fold and leave-one-subject-out (LOSO) experiments are performed to confirm how significant using the fused images is in improving the performance of the diagnoses, by investigating four different CNN architectures. All of the four architectures achieve acceptable performance and confirm a significant performance improvement using the fused images. Using LOSO, the best network performance has improved from 90.1 +/- 2% using only the grey level dataset to 97.7 +/- 0.5% using the proposed fused dataset. These results confirm the promise of using the proposed system for the detection of DR using OCT images.",diabetic retinopathy; deep learning; low level information; high level information
Article,"Ogunyemi, Omolola, I; Gandhi, Meghal; Lee, Martin; Teklehaimanot, Senait; Daskivich, Lauren Patty; Hindman, David; Lopez, Kevin; Taira, Ricky K.","Detecting diabetic retinopathy through machine learning on electronic health record data from an urban, safety net healthcare system",jamia open,2021,Not found,"Objective Clinical guidelines recommend annual eye examinations to detect diabetic retinopathy (DR) in patients with diabetes. However, timely DR detection remains a problem in medically underserved and under-resourced settings in the United States. Machine learning that identifies patients with latent/undiagnosed DR could help to address this problem. Materials and Methods Using electronic health record data from 40 631 unique diabetic patients seen at Los Angeles County Department of Health Services healthcare facilities between January 1, 2015 and December 31, 2017, we compared ten machine learning environments, including five classifier models, for assessing the presence or absence of DR. We also used data from a distinct set of 9300 diabetic patients seen between January 1, 2018 and December 31, 2018 as an external validation set. Results Following feature subset selection, the classifier with the best AUC on the external validation set was a deep neural network using majority class undersampling, with an AUC of 0.8, the sensitivity of 72.17%, and specificity of 74.2%. Discussion A deep neural network produced the best AUCs and sensitivity results on the test set and external validation set. Models are intended to be used to screen guideline noncompliant diabetic patients in an urban safety-net setting. Conclusion Machine learning on diabetic patients' routinely collected clinical data could help clinicians in safety-net settings to identify and target unscreened diabetic patients who potentially have undiagnosed DR.",diabetic retinopathy; machine learning; artificial intelligence; safety net providers; diabetic retinopathy diagnosis
Proceedings Paper,"Zaylaa, Amira J.; Wehbe, Ghiwa, I; Ouahabi, AbdulJalil M.",Bringing AI to Automatic Diagnosis of Diabetic Retinopathy from Optical Coherence Tomography Angiography,2021 sixth international conference on advances in biomedical engineering (icabme),2021,Not found,"Artificial Intelligence (AI) is significantly gaining interest in the field of Diagnostic and Functional Optical Imaging. As cutting-edge algorithms for decision-making are vast and medical imaging machines are diverse, the choice of the ultimate algorithm remains challenging. As a breakthrough in the field, our aim is to explore the adequate machine and deep learning algorithms that improve the classification of Optical Coherence Tomography Angiography (OCTA) Images, between normal and Diabetic Retinopathy (DR) images. The target was to provide an automatic paradigm for the medical staff to detect the presence of DR Lesions from OCTA images for diagnostic and monitoring purposes. Data were collected prospectively over a year from a comprehensive medical center in Lebanon. The mixed Convolution Neural Network (CNN)-Support Vector Machine Network (CNN, SVM) algorithm was utilized in the new paradigm and compared to the feed forward backpropagation NN, to the SVM and to the modified SVM. Results were evaluated independently for the presence or absence of DR using statistical metrics. Experimental results showcased promising association of deep learning to the early diagnosis of DR. Results manifested the high performance of the new paradigm, where the mixed algorithm applied to the functional OCTA surpassed the performance of the feed forward backpropagation NN. The sensitivity of the mixed (CNN, SVM) algorithm was 22.22% higher than that obtained by the feed forward backpropagation NN. Moreover, the specificity of classification of DR from OCTA images using mixed (CNN, SVM) algorithm was 24.44% higher than that obtained by the feed forward backpropagation NN. The precision was 25.47% higher in the new paradigm than that obtained by the feed forward backpropagation network, and the accuracy was 2335% higher in the mixed (CNN, SVM) than that obtained by the feed forward backpropagation NN. This high performance plays a massive role in improving the diagnosis of DR, and thus Healthcare system and processing of information. As a future prospect, we aim to consider more algorithms and variables in the diagnosis of DR from OCTA images.",artificial intelligence; machine and deep learning; functional medical imaging; optical coherence tomography angiography; diabetic retinopathy; statistical evaluation
Article; Early Access,"Parthiban, K.; Kamarasan, M.",Diabetic retinopathy detection and grading of retinal fundus images using coyote optimization algorithm with deep learning,multimedia tools and applications,0,Not found,"Diabetic retinopathy (DR) is a major reason of preventable blindness for diabetic patients. Regular retinal screening is recommended for diabetic persons to detect DR at the earlier stages. Manual retinal screening of DR is a difficult and laborious process, computer aided diagnosis models become essential. Recently deep learning (DL) methods enable effectual detection and classification of medical images, particularly retinal fundus images. With this motivation, this work presents an intelligent coyote optimization algorithm with DL based DR detection and grading (ICOA-DLDRD) model on retinal fundus images. The purpose of the ICOA-DLDRD approach is to identify the presence of DR on retinal fundus images. Primarily, the ICOA-DLDRD algorithm comprises Gabor filtering (GF) based noise removal and optimal region growing segmentation technique. Further, the primary seed points and thresholds of the region growing segmentation technique are optimally created utilizing the glowworm swarm optimization (GSO) algorithm. In addition, SqueezeNet with class attention learning (CAL) layer is derived for the extraction of feature vectors. Lastly, COA with a deep extreme learning machine (DELM) classifier is applied for the detection and grading of DR, in which the penalty parameter C and kernel parameter gamma gamma of the DELM model are optimally adjusted by the use of COA. The performance validation of the ICOA-DLDRD method occurs utilizing the benchmark MESSIDOR dataset and the outcomes reported the betterment of the ICOA-DLDRD approach on the recent methods with maximum accuracy of 99.65%.",retinal fundus image; diabetic retinopathy; image segmentation; optimal parameter tuning; decision making; deep learning
Proceedings Paper,"Kassani, Sara Hosseinzadeh; Kassani, Peyman Hosseinzadeh; Khazaeinezhad, Reza; Wesolowski, Michal J.; Schneider, Kevin A.; Deters, Ralph",Diabetic Retinopathy Classification Using a Modified Xception Architecture,2019 ieee 19th international symposium on signal processing and information technology (isspit 2019),2019,Not found,"Diabetic retinopathy (DR) is one of the major causes of blindness worldwide. With proper treatment, early diagnosis of DR can prevent the progression of the disease. In this paper, we present a new feature extraction method using a modified Xception architecture for the diagnosis of DR disease. The proposed method is based on deep layer aggregation that combines multilevel features from different convolutional layers of Xception architecture. The extracted features are subsequently fed into a multi-layer perceptron (MLP) to be trained for DR severity classification. The performance of the proposed approach was assessed with four deep feature extractors, including InceptionV3, MobileNet, and ResNet50 and original Xception architecture. Compared with typical Xception architecture, the aggregation of deep CNN layers can effectively fuse deep features and improve the learning process. Additionally, a transfer learning strategy and hyper-parameter tuning are adopted to further improve the overall classification performance. The performance of the proposed model was validated on the Kaggle APTOS 2019 contest dataset. Experiments demonstrate that the modified Xception deep feature extractor improves DR classification with a classification accuracy of 83.09% versus 79.59%, sensitivity of 88.24% versus 82.35% and specificity of 87.00% versus 86.32% when compared with the original Xception architecture.",computer-aided diagnosis; convolutional neural network; deep learning; diabetic retinopathy; transfer learning
Article,"Ogunyemi, Omolola, I; Gandhi, Meghal; Lee, Martin; Teklehaimanot, Senait; Daskivich, Lauren Patty; Hindman, David; Lopez, Kevin; Taira, Ricky K.","Detecting diabetic retinopathy through machine learning on electronic health record data from an urban, safety net healthcare system",jamia open,2021,Not found,"Objective: Clinical guidelines recommend annual eye examinations to detect diabetic retinopathy (DR) in patients with diabetes. However, timely DR detection remains a problem in medically underserved and under-resourced settings in the United States. Machine learning that identifies patients with latent/undiagnosed DR could help to address this problem. Materials and Methods: Using electronic health record data from 40 631 unique diabetic patients seen at Los Angeles County Department of Health Services healthcare facilities between January 1, 2015 and December 31, 2017, we compared ten machine learning environments, including five classifier models, for assessing the presence or absence of DR. We also used data from a distinct set of 9300 diabetic patients seen between January 1, 2018 and December 31, 2018 as an external validation set. Results: Following feature subset selection, the classifier with the best AUC on the external validation set was a deep neural network using majority class undersampling, with an AUC of 0.8, the sensitivity of 72.17%, and specificity of 74.2%. Discussion: A deep neural network produced the best AUCs and sensitivity results on the test set and external validation set. Models are intended to be used to screen guideline noncompliant diabetic patients in an urban safety-net setting. Conclusion: Machine learning on diabetic patients' routinely collected clinical data could help clinicians in safety-net settings to identify and target unscreened diabetic patients who potentially have undiagnosed DR.",diabetic retinopathy; machine learning; artificial intelligence; safety net providers; diabetic retinopathy diagnosis
Article,"Riaz, Hamza; Park, Jisu; Choi, Hojong; Kim, Hyunchul; Kim, Jungsuk",Deep and Densely Connected Networks for Classification of Diabetic Retinopathy,diagnostics,2020,Not found,"Diabetes has recently emerged as a worldwide problem, and diabetic retinopathy is an abnormal state associated with the human retina. Due to the increase in daily screen-related activities of modern human beings, diabetic retinopathy is more prevalent among adults, leading to minor and major blindness. Doctors and clinicians are unable to perform early diagnoses due to the large number of patients. To solve this problem, this study introduces a classification model for retinal images that distinguishes between the various stages of diabetic retinopathy. This work involves deploying deep and densely connected networks for retinal image analysis with training from scratch. Dense connections between the convolutional layers of the network are an essential factor to enhance accuracy owing to the deeper supervision between layers. Another factor is the growth rate that further assists our model in learning more sophisticated feature maps regarding retinal images from every stage of the network. We compute the area under the curve, sensitivity, and specificity, particularly for messidor-2 and EyePACS. Compared to existing approaches, our method achieved better results, with an approximate rise rate of 0.01, 0.03, and 0.01, respectively. Therefore, computer-aided programs can help in diagnostic centers as automated detection systems.",deep learning; densely connected networks; healthcare diagnosis; diabetic retinopathy; convolutional neural networks; fundus image analysis
Article,"Lin, Po-Kang; Chiu, Yu-Hsien; Huang, Chiu-Jung; Wang, Chien-Yao; Pan, Mei-Lien; Wang, Da-Wei; Liao, Hong-Yuan Mark; Chen, Yong-Sheng; Kuan, Chieh-Hsiung; Lin, Shih-Yen; Chen, Li-Fen",PADAr: physician-oriented artificial intelligence-facilitating diagnosis aid for retinal diseases,journal of medical imaging,2022,Not found,"Purpose: Retinopathy screening via digital imaging is promising for early detection and timely treatment, and tracking retinopathic abnormality over time can help to reveal the risk of disease progression. We developed an innovative physician-oriented artificial intelligence-facilitating diagnosis aid system for retinal diseases for screening multiple retinopathies and monitoring the regions of potential abnormality over time. Approach: Our dataset contains 4908 fundus images from 304 eyes with image-level annotations, including diabetic retinopathy, age-related macular degeneration, cellophane maculopathy, pathological myopia, and healthy control (HC). The screening model utilized a VGG-based feature extractor and multiple-binary convolutional neural network-based classifiers. Images in time series were aligned via affine transforms estimated through speeded-up robust features. Heatmaps of retinopathy were generated from the feature extractor using gradient-weighted class activation mapping++, and individual candidate retinopathy sites were identified from the heatmaps using clustering algorithm. Nested cross-validation with a train-to-test split of 80% to 20% was used to evaluate the performance of the screening model. Results: Our screening model achieved 99% accuracy, 93% sensitivity, and 97% specificity in discriminating between patients with retinopathy and HCs. For discriminating between types of retinopathy, our model achieved an averaged performance of 80% accuracy, 78% sensitivity, 94% specificity, 79% F1-score, and Cohen's kappa coefficient of 0.70. Moreover, visualization results were also shown to provide reasonable candidate sites of retinopathy. Conclusions: Our results demonstrated the capability of the proposed model for extracting diagnostic information of the abnormality and lesion locations, which allows clinicians to focus on patient-centered treatment and untangles the pathological plausibility hidden in deep learning models. (C) The Authors. Published by SPIE under a Creative Commons Attribution 4.0 International License.",computer-aided diagnosis; multi-retinopathy classification; lesion-sites visualization
Article,"Li, Feng; Liu, Zheng; Chen, Hua; Jiang, Minshan; Zhang, Xuedian; Wu, Zhizheng",Automatic Detection of Diabetic Retinopathy in Retinal Fundus Photographs Based on Deep Learning Algorithm,translational vision science & technology,2019,Not found,"Purpose: To achieve automatic diabetic retinopathy (DR) detection in retinal fundus photographs through the use of a deep transfer learning approach using the Inception-v3 network. Methods: A total of 19,233 eye fundus color numerical images were retrospectively obtained from 5278 adult patients presenting for DR screening. The 8816 images passed image-quality review and were graded as no apparent DR (1374 images), mild nonproliferative DR (NPDR) (2152 images), moderate NPDR (2370 images), severe NPDR (1984 images), and proliferative DR (PDR) (936 images) by eight retinal experts according to the International Clinical Diabetic Retinopathy severity scale. After image preprocessing, 7935 DR images were selected from the above categories as a training dataset, while the rest of the images were used as validation dataset. We introduced a 10-fold cross-validation strategy to assess and optimize our model. We also selected the publicly independent Messidor-2 dataset to test the performance of our model. For discrimination between no referral (no apparent DR and mild NPDR) and referral (moderate NPDR, severe NPDR, and PDR), we also computed prediction accuracy, sensitivity, specificity, area under the receiver operating characteristic curve (AUC), and kappa value. Results: The proposed approach achieved a high classification accuracy of 93.49% (95% confidence interval [CI], 93.13%-93.85%), with a 96.93% sensitivity (95% CI, 96.35%-97.51%) and a 93.45% specificity (95% CI, 93.12%-93.79%), while the AUC was up to 0.9905 (95% CI, 0.9887-0.9923) on the independent test dataset. The j value of our best model was 0.919, while the three experts had j values of 0.906, 0.931, and 0.914, independently. Conclusions: This approach could automatically detect DR with excellent sensitivity, accuracy, and specificity and could aid in making a referral recommendation for further evaluation and treatment with high reliability. Translational Relevance: This approach has great value in early DR screening using retinal fundus photographs.",diabetic retinopathy; retinal fundus photographs; deep transfer learning; inception-v3 network
Article,"Dayana, A. Mary; Emmanuel, W. R. Sam",Deep learning enabled optimized feature selection and classification for grading diabetic retinopathy severity in the fundus image,neural computing & applications,2022,Not found,"Diabetic Retinopathy (DR), one of the most progressive sight-threatening diseases caused by the long-term diabetic condition, can lead to vision impairment and blindness later. Early diagnosis and timely treatment help control and avert DR from its progression. However, manual grading is exceptionally challenging and arduous due to the complex anatomical features in the retina. Therefore, developing an automated diagnostic method for screening DR is obligatory. This paper proposes a deep learning-enabled optimized feature selection approach to classify the stage of DR severity in the fundus image. At first, a pre-processing phase eradicates the noise and improves the contrast in the retinal fundus image. Then, blood vessel segmentation is performed using the Coherence Enhancing Energy Based Regularized Level Set Evolution method in the green channel fundus image. Subsequently, the optic disk is segmented with Canny Anisotropic Diffusion filter and morphological transformations. Next, the candidate lesion region is detected using an Attention-based Fusion Network (AFU-Net). Then, shape and texture features are extracted, and then, the optimal subset of features is selected using the Improved Harris Hawk Optimization algorithm. Finally, a deep Convolutional Neural Network classifies the DR stages, and the model weight is updated using the same algorithm. The proposed method achieved superior performance in two benchmark public datasets compared with the existing state-of-the-art methods using F1-score, accuracy, sensitivity, and specificity measures.",diabetic retinopathy; anisotropic diffusion filter; fusion network; harris hawk optimization; convolutional neural network
Proceedings Paper,"Memari, Nogol; Abdollahi, Saranaz; Ganzagh, Mahdi Maghrouni; Moghbel, Mehrdad",Computer-assisted diagnosis (CAD) system for Diabetic Retinopathy screening using color fundus images using Deep learning,2020 18th ieee student conference on research and development (scored),2020,Not found,"Diabetes is a serious medical condition and regular screening for diabetes is of great importance as treatment options are most effective in the early stages of diabetes. Digital imaging of retina is considered as a low-cost method for screening and could be used in conjunction with computer-based image processing techniques to automatically detect early signs of diabetes utilizing diabetes-related pathologies visible in retinal fundus images. This research proposes a novel computer-assisted diagnosis (CAD) system for assisting with the screening of the population as up to 50% of the affected population are not aware of having diabetes. Moreover, these screenings are often carried out by an optometrist who receives some training with the patients being referred to an ophthalmologist if they show symptoms. Having a computer-assisted diagnosis system assisting the optometrist during the screening can greatly increase the detection rate for patients with diabetes by providing a second opinion and highlighting any suspicious pathologies. For achieving the highest detection rate possible, a hybrid machine learning approach is proposed in this research by combining Deep Learning with the AdaBoost classifier. The proposed computer-assisted diagnosis system starts with the segmentation of the blood vessels. Then, microaneurysms and exudates are segmentation from the image. Statistical and regional features are then extracted utilizing first, second, and higher-order image features. A Deep Learning framework will be utilized for extracting additional statistical image descriptors as a Deep Learning has superior contextual analysis capabilities compared to other machine learning techniques. Finally, the most informative features are selected by a minimal-redundancy maximal-relevance feature selection approach with an AdaBoost classifier analyzing all the features and informing the operator regarding the patient's condition. Ethereum Swarm blockchain-based decentralized cloud file storage provides the proposed CAD users with a secure storage olution to access the patient information and related images. The sensitivity, specificity, and accuracy of the classification will be measured under clinical conditions. Healthcare, government, and public users would receive the most benefit from this project.",retinal vessel segmentation; machine learning; deep learning; diabetic retinopathy
Article,"Rajkumar, R. S.; Selvarani, A. Grace",Diabetic Retinopathy Diagnosis Using ResNet with Fuzzy Rough C-Means Clustering,computer systems science and engineering,2022,Not found,"Diabetic Retinopathy (DR) is a vision disease due to the long-term prevalence of Diabetes Mellitus. It affects the retina of the eye and causes severe damage to the vision. If not treated on time it may lead to permanent vision loss in diabetic patients. Today's development in science has no medication to cure Diabetic Retinopathy. However, if diagnosed at an early stage it can be controlled and permanent vision loss can be avoided. Compared to the diabetic population, experts to diagnose Diabetic Retinopathy are very less in particular to local areas. Hence an automatic computer-aided diagnosis for DR detection is necessary. In this paper, we propose an unsupervised clustering technique to automatically cluster the DR into one of its five development stages. The deep learning based unsupervised clustering is made to improve itself with the help of fuzzy rough c-means clustering where cluster centers are updated by fuzzy rough c-means clustering algorithm during the forward pass and the deep learning model representations are updated by Stochastic Gradient Descent during the backward pass of training. The proposed method was implemented using python and the results were taken on DGX server with Tesla V100 GPU cards. An experimental result on the publically available Kaggle dataset shows an overall accuracy of 88.7%. The proposed model improves the accuracy of DR diagnosis compared to the existing unsupervised algorithms like k-means, FCM, auto-encoder, and FRCM with alexnet.",diabetic retinopathy detection; diabetic retinopathy diagnosis; fuzzy rough c-means clustering; unsupervised cnn; clustering
Proceedings Paper,"Goncalves, Joao; Conceicao, Teresa; Soares, Filipe",Inter-observer Reliability in Computer-aided Diagnosis of Diabetic Retinopathy,healthinf: proceedings of the 12th international joint conference on biomedical engineering systems and technologies - vol 5: healthinf,2019,Not found,"The rapid growth of digital data in healthcare demands medical image analysis to be faster, precise and, at the same time, decentralized. Deep Learning (DL) fits well in this scenario, as there is an enormous data to sift through. Diabetic Retinopathy (DR) is one of the leading causes of blindness that can be avoided if detected in early stages. In this paper, we aim to compare the agreement of different machine learning models against the performance of highly trained ophthalmologists (human graders). Overall results show that transfer learning in the renowned CNNs has a strong agreement even in different datasets. This work also presents an objective comparison between classical feature-based approaches and DL for DR classification, specifically, the interpretability of these approaches. The results show that Inception-V3 CNN was indeed the best-tested model across all the performance metrics in distinct datasets, but with lack of interpretability. In particular, this model reaches the accuracy of 89% on the EyePACS dataset.",convolution neural networks; feature-based machine learning; inter-observer reliability; diabetic retinopathy
Article; Early Access,"Gour, Neha; Tanveer, M.; Khanna, Pritee",Challenges for ocular disease identification in the era of artificial intelligence,neural computing & applications,0,Not found,"Retinal image analysis is an integral and fundamental step towards the identification and classification of ocular diseases like glaucoma, diabetic retinopathy, macular edema, and cardiovascular diseases through computer-aided diagnosis systems. Various abnormalities are observed through retinal image modalities like fundus, fluorescein angiography, and optical coherence tomography by ophthalmologists, and computer science professionals. Retinal image analysis has gained a lot of importance in recent years due to advances in computational, storage, and image acquisition technologies. Better computational capabilities lead to a rise in the implementation of deep learning-based methods for ocular disease detection. Although deep learning promises better performance in this field, some issues like lack of well-labeled datasets, unavailability of large enough datasets, class imbalance, and model generalizability are yet to be addressed. Also, the real-time implementation of detection methods on new devices or existing hardware is an untouched area. This article highlights the development of retinal image analysis and related issues due to the introduction of AI-based methods. The methods are analyzed in terms of standard performance metrics on various publicly and privately available datasets.",ocular diseases; artificial intelligence; retinal datasets; deep learning
Review,"Li, Zhixi; Keel, Stuart; Liu, Chi; He, Mingguang","Can Artificial Intelligence Make Screening Faster, More Accurate, and More Accessible?",asia-pacific journal of ophthalmology,2018,Not found,"Diabetic retinopathy, glaucoma, and age-related macular degeneration are leading causes of vision loss and blindness worldwide. They tend to be asymptomatic in the early phase of disease and therefore require active screening programs to identify the patients requiring referral and treatment. Deep learning-based artificial intelligence technology has recently become a major topic in the field of ophthalmology. This paper aimed to provide a general view of the major findings on the application of deep learning for the classification of eye diseases from common imaging modalities. In the future, it is expected that these technologies will be applied in real-world screening programs to improve their efficiency and affordability.",artificial intelligence; deep learning; screening
Article,"Das, Sraddha; Kharbanda, Krity; Suchetha, M.; Raman, Rajiv; Dhas, Edwin D.",Deep learning architecture based on segmented fundus image features for classification of diabetic retinopathy,biomedical signal processing and control,2021,Not found,"Diabetic retinopathy is ophthalmological distress, diabetic patients suffer due to clots, lesions, or haemorrhage formation in the light-sensitive region of the retina. Blocking of vessels leads, due to the increase of blood sugar leads to the formation of new vessel growth, which gives rise to mesh-like structures. Assessing the branching retinal vasculature is an important aspect for ophthalmologists for efficient diagnosis. The fundus scans of the eye are first subjected to pre-processing, followed by segmentation. To extract the branching blood vessels, the technique of maximal principal curvature has been applied, which utilizes the maximum Eigenvalues of the Hessian matrix. Adaptive histogram equalization and the morphological opening, are performed post to that, to enhance and eliminate falsely segmented regions. The proliferation of optical nerves was observed much greater in diabetic or affected patients than in healthy ones. We have used a convolution neural network (CNN) to train the classifier for performing classification. The CNN, constructed for classification, comprises a combination of squeeze and excitation and bottleneck layers, one for each class, and a convolution and pooling layer architecture for classification between the two classes. For the performance evaluation of the proposed algorithm, we use the dataset DIARETDB1 (standard Diabetic Retinopathy Dataset) and the dataset provided by a medical institution, comprised of fundus scans of both affected and normal retinas. Experimental results show that the proposed algorithm provides improved results, when compared to traditional schemes. The model yielded an accuracy of 98.7 % and a precision of 97.2 % while evaluated on the DIARETDB1 dataset.",diabetic retinopathy; maximum principal curvature; hessian matrix; squeeze-excitation; bottleneck; convolutional neural network
Article,"Bhardwaj, Charu; Jain, Shruti; Sood, Meenakshi",Transfer learning based robust automatic detection system for diabetic retinopathy grading,neural computing & applications,2021,Not found,"Diabetic retinopathy (DR) can be categorized on the basis of prolonged complication in the retinal blood vessels which may lead to severe blindness. Early stage prediction and diagnosis of DR requires regular eye examination to reduce the complications causing vision loss. Indicative significance of DR forecast and evaluation to help the ophthalmologists in standard screening has prompted the improvement of computerized DR recognition frameworks. This work focuses on automatic DR disease identification and its grading by the means of transfer learning approach using dynamic investigation. Our proposed approach utilizes deep neural network for feature extraction from fundus images and these features are further ensembled with supervised machine learning technique for DR grading. An optimized classification is achieved by applying an ensemble of convolution neural networks (CNNs) with statistical feature selection module and SVM classifier. The learning of classifier is achieved by the feature information transferred from CNN model to the SVM classifier, which results in remarkable performance of the learned models. Statistically optimized feature set utilized for transfer learning technique yields in the classification accuracy of 90.51% with proposed Prominent Feature-based Transfer Learning (PFTL) method employing Inception V3 model. The cost analysis of the proposed model provides a minimum cross-entropy loss of 0.295 consuming the time of 38 min 53 s, thus, maintaining a trade-off. The generalization ability of the proposed model is established by the performance assessment using latest IDRiD dataset that yields accuracy of 90.01% for Inception V3 network providing uniform outcomes for all the evaluation parameters. The diagnosis ability of the proposed transfer learning-based model is justified by comparing the proposed methods with the state-of-the-art methods. The optimized PFTL model (CNN + Statistical Analysis + SVM) outperforms other classification algorithms and provides the maximum accuracy improvement of 16.01% over the state-of-the-art techniques.",diabetic retinopathy; supervised machine learning; deep neural network; convolution neural network; statistical analysis
Review,"Lalithadevi, Balakrishnan; Krishnaveni, Sivamohan",Detection of diabetic retinopathy and related retinal disorders using fundus images based on deep learning and image processing techniques: A comprehensive review,concurrency and computation-practice & experience,2022,Not found,"Diabetes mellitus is a chronic disorder disease in which a person's body fails to adhere insulin produced by their pancreas or unable to segregate enough insulin due to harmonic imbalance. Diabetic people are suffering from eye disorders like diabetic retinopathy (DR), glaucoma and various diseases such as neuropathy, nephropathy, cardiomyopathy over long intervals. One of the most prevalent diabetic consequence is DR. Detecting the morphological variations in retina is difficult and requires an effective automated detection system. DR can be predicted in earlier stage using tremendous development of deep learning models and image processing techniques. Recently, many research articles have been published in DR diagnosis system. This article shows a comprehensive review of automated diagnostic methods for DR detection and other related eye disorders from several points: Causes for DR, publicly available datasets, image preprocessing, segmentation of various DR lesions, feature optimization, various deep learning models, and open research challenges. The study offers a thorough overview of DR detection techniques, which delivers valuable information for researchers, medical professionals, and DR affected patients.",deep learning; diabetes; diabetic retinopathy; fundus images; image processing; lesions
Article,"Alghamdi, Hanan Saleh",Towards Explainable Deep Neural Networks for the Automatic Detection of Diabetic Retinopathy,applied sciences-basel,2022,Not found,"Featured Application The proposed approach can be applied to any of the Convolutional Neural Networks-based architecture to explain, evaluate and validate the model's decisions. Diabetic Retinopathy (DR) is a common complication associated with diabetes, causing irreversible vision loss. Early detection of DR can be very helpful for clinical treatment. Ophthalmologists' manual approach to DR diagnoses is expensive and time-consuming; thus, automatic detection of DR is becoming vital, especially with the increasing number of diabetes patients worldwide. Deep learning methods for analyzing medical images have recently become prevalent, achieving state-of-the-art results. Consequently, the need for interpretable deep learning has increased. Although it was demonstrated that the representation depth is beneficial for classification accuracy for DR diagnoses, model explainability is rarely analyzed. In this paper, we evaluated three state-of-the-art deep learning models to accelerate DR detection using the fundus images dataset. We have also proposed a novel explainability metric to leverage domain-based knowledge and validate the reasoning of a deep learning model's decisions. We conducted two experiments to classify fundus images into normal and abnormal cases and to categorize the images according to the DR severity. The results show the superiority of the VGG-16 model in terms of accuracy, precision, and recall for both binary and DR five-stage classification. Although the achieved accuracy of all evaluated models demonstrates their capability to capture some lesion patterns in the relevant DR cases, the evaluation of the models in terms of their explainability using the Grad-CAM-based color visualization approach shows that the models are not necessarily able to detect DR related lesions to make the classification decision. Thus, more investigations are needed to improve the deep learning model's explainability for medical diagnosis.",explainable deep networks; diabetic retinopathy; deep learning; grad-cam; convolutional neural networks; resnet; densenet
Article,"Krishnamoorthy, Sujatha; Shanthini, A.; Manogaran, Gunasekaran; Saravanan, Vijayalakshmi; Manickam, Adhiyaman; Samuel, R. Dinesh Jackson",Regression Model-based Feature Filtering for Improving Hemorrhage Detection Accuracy in Diabetic Retinopathy Treatment,international journal of uncertainty fuzziness and knowledge-based systems,2021,Not found,"Diabetic retinopathy (DR) is an optical syndrome infecting the eyes' vision by impairing the retinal blood vessels. Early misdetection of impairment results in hemorrhage, a state in which retinal bleeding occurs. Therefore, initial detection of such bleeding in the retina is identified using intelligent computing and clinical analysis. This analysis helps to improve the precision of detection and requires complex-less time and processing instances. In this article, the regression model for retina feature filtering (RM-FF) is introduced to improve the accuracy of detecting hemorrhages. In this filtering, the complex image is simplified into smaller blocks for classification and conditional verification. Based on conditional verification, the training set is updated recursively to improve the specificity and sensitivity detection process. Using a differential dataset, the proposed detection method assessed using the metrics true positive rate, accuracy, sensitivity, and specificity.",diabetic retinopathy; feature extraction; hemorrhage syndrome; optic disk; regression learning
Article,"Qureshi, Imran; Ma, Jun; Abbas, Qaisar",Diabetic retinopathy detection and stage classification in eye fundus images using active deep learning,multimedia tools and applications,2021,Not found,"Retinal fundus image analysis (RFIA) for diabetic retinopathy (DR) screening can be used to reduce the risk of blindness among diabetic patients. The RFIA screening programs help the ophthalmologists to cope with this paramount visual impairment problem. In this article, an automatic recognition of the DR stage is proposed based on a new multi-layer architecture of active deep learning (ADL). To develop the ADL system, we used the convolutional neural networks (CNN) model to automatically extract features compare to handcrafted-based features. However, the training of CNN procedure requires an immense size of labeled data that makes it almost difficult in the classification phase. As a result, a label-efficient CNN architecture is presented known as ADL-CNN by using one of the active learning methods known as an expected gradient length (EGL). This ADL-CNN model can be seen as a two-stage process. At first, the proposed ADL-CNN system selects both the most informative patches and images by using some ground truth labels of training samples to learn the simple to complex retinal features. Next, it provides useful masks for prognostication to assist clinical specialists for the important eye sample annotation and segment regions-of-interest within the retinograph image to grade five severity-levels of diabetic retinopathy. To test and evaluate the performance of ADL-CNN model, the EyePACS benchmark is utilized and compared with state-of-the-art methods. The statistical metrics are used such as sensitivity (SE), specificity (SP), F-measure and classification accuracy (ACC) to measure the effectiveness of ADL-CNN system. On 54,000 retinograph images, the ADL-CNN model achieved an average SE of 92.20%, SP of 95.10%, F-measure of 93% and ACC of 98%. Hence, the new ADL-CNN architecture is outperformed for detecting DR-related lesions and recognizing the five levels of severity of DR on a wide range of fundus images.",diabetic retinopathy; severity-level; active deep learning; convolutional neural network; diabetic retinopathy; expected gradient length; image processing
Review,"Nadeem, Muhammad Waqas; Goh, Hock Guan; Hussain, Muzammil; Liew, Soung-Yue; Andonovic, Ivan; Khan, Muhammad Adnan","Deep Learning for Diabetic Retinopathy Analysis: A Review, Research Challenges, and Future Directions",sensors,2022,Not found,"Deep learning (DL) enables the creation of computational models comprising multiple processing layers that learn data representations at multiple levels of abstraction. In the recent past, the use of deep learning has been proliferating, yielding promising results in applications across a growing number of fields, most notably in image processing, medical image analysis, data analysis, and bioinformatics. DL algorithms have also had a significant positive impact through yielding improvements in screening, recognition, segmentation, prediction, and classification applications across different domains of healthcare, such as those concerning the abdomen, cardiac, pathology, and retina. Given the extensive body of recent scientific contributions in this discipline, a comprehensive review of deep learning developments in the domain of diabetic retinopathy (DR) analysis, viz., screening, segmentation, prediction, classification, and validation, is presented here. A critical analysis of the relevant reported techniques is carried out, and the associated advantages and limitations highlighted, culminating in the identification of research gaps and future challenges that help to inform the research community to develop more efficient, robust, and accurate DL models for the various challenges in the monitoring and diagnosis of DR.",deep learning; machine learning; diabetic retinopathy; medical imaging; color fundus images; image processing; image recognition; computer vision; segmentation; classification
Article,"Yi, San-Li; Yang, Xue-Lian; Wang, Tian-Wei; She, Fu-Rong; Xiong, Xin; He, Jian-Feng",Diabetic Retinopathy Diagnosis Based on RA-EfficientNet,applied sciences-basel,2021,Not found,"The early detection and grade diagnosis of diabetic retinopathy (DR) are very important for the avoidance of blindness, and using deep learning methods to automatically diagnose DR has attracted great attention. However, the small amount of DR data limits its application. To automatically learn the disease's features and detect DR more accurately, we constructed a DR grade diagnostic model. To realize the model, the authors performed the following steps: firstly, we preprocess the DR images to solve the existing problems in an APTOS 2019 dataset, such as size difference, information redundancy and the data imbalance. Secondly, to extract more valid image features, a new network named RA-EfficientNet is proposed, in which a residual attention (RA) block is added to EfficientNet to extract more features and to solve the problem of small differences between lesions. EfficientNet has been previously trained on the ImageNet dataset, based on transfer learning technology, to overcome the small sample size problem of DR. Lastly, based on the extracted features, two classifiers are designed, one is a 2-grade classifier and the other a 5-grade classifier. The 2-grade classifier can diagnose DR, and the 5-grade classifier provides 5 grades of diagnosis for DR, as follows: 0 for No DR, 1 for mild DR, 2 for moderate, 3 for severe and 4 for proliferative DR. Experiments show that our proposed RA-EfficientNet can achieve better performance, with an accuracy value of 98.36% and a kappa score of 96.72% in a 2-grade classification and an accuracy value of 93.55% and a kappa score of 91.93% in a 5-grade classification. The results indicate that the proposed model effectively improves DR detection efficiency and resolves the existing limitation of manual feature extraction.",efficientnet; transfer learning; residual attention block; retinal image; diabetic retinopathy
Article,"Zhou, Lei; Zhao, Yu; Yang, Jie; Yu, Qi; Xu, Xun",Deep multiple instance learning for automatic detection of diabetic retinopathy in retinal images,iet image processing,2018,Not found,"As a weakly supervised learning technique, multiple instance learning (MIL) has shown an advantage over supervised learning methods for automatic detection of diabetic retinopathy (DR): only the image-level annotation is needed to achieve both detection of DR images and DR lesions, making more graded and de-identified retinal images available for learning. However, the performance of existing studies on this technique is limited by the use of handcrafted features. The authors propose a deep MIL method for DR detection, which jointly learns features and classifiers from data and achieves a significant improvement on detecting DR images and their inside lesions. Specifically, a pre-trained convolutional neural network is adapted to achieve the patch-level DR estimation, and then global aggregation is used to make the classification of DR images. Further, the authors propose an end-to-end multi-scale scheme to better deal with the irregular DR lesions. For detection of DR images, they achieve an area under the ROC curve of 0.925 on a subset of a Kaggle dataset, and 0.960 on Messidor. For detection of DR lesions, they achieve an F1-score of 0.924 with sensitivity 0.995 and precision 0.863 on DIARETDB1 using the connected component-level validation.",learning (artificial intelligence); medical image processing; neural nets; image classification; deep multiple instance learning; automatic detection; diabetic retinopathy; retinal images; weakly supervised learning technique; dr lesions; dr image classification; image-level annotation; pre-trained convolutional neural network; patch-level dr estimation; global aggregation; end-to-end multi-scale scheme; kaggle dataset
Article,"Cao, Kai; Xu, Jie; Zhao, Wei-Qi",Artificial intelligence on diabetic retinopathy diagnosis: an automatic classification method based on grey level co-occurrence matrix and naive Bayesian model,international journal of ophthalmology,2019,Not found,"AIM: To develop an automatic tool on screening diabetic retinopathy (DR) from diabetic patients. METHODS: We extracted textures from eye fundus images of each diabetes subject using grey level co-occurrence matrix method and trained a Bayesian model based on these textures. The receiver operating characteristic (ROC) curve was used to estimate the sensitivity and specificity of the Bayesian model. RESULTS: A total of 1000 eyes fundus images from diabetic patients in which 298 eyes were diagnosed as DR by two ophthalmologists. The Bayesian model was trained using four extracted textures including contrast, entropy, angular second moment and correlation using a training dataset. The Bayesian model achieved a sensitivity of 0.949 and a specificity of 0.928 in the validation dataset. The area under the ROC curve was 0.938, and the 10-fold cross validation method showed that the average accuracy rate is 93.5%. CONCLUSION: Textures extracted by grey level co-occurrence can be useful information for DR diagnosis, and a trained Bayesian model based on these textures can be an effective tool for DR screening among diabetic patients.",grey level co-occurrence matrix; bayesian; textures; artificial intelligence; receiver operating characteristic curve; diabetic retinopathy
Article,"Arsalan, Muhammad; Haider, Adnan; Lee, Young Won; Park, Kang Ryoung",Detecting retinal vasculature as a key biomarker for deep Learning-based intelligent screening and analysis of diabetic and hypertensive retinopathy,expert systems with applications,2022,Not found,"Retinal vessels are considered important biomarkers for the detection of retinal diseases, like diabetic retinopathy (caused by diabetes) and hypertensive retinopathy (caused by hypertension). The manual finding from this retinal vasculature is time-consuming and costly. The image quality of the fundus image directly affects the accurate segmentation of these vessels in the automatic methods. With such inferior quality images, deep learning-based methods are better for dealing with segmentation. Conventional deep-learning-based vessel segmentation methods deal the segmentation task with deeper convolutional neural networks and many trainable parameters. Minor changes in the retinal vasculature, such as those that result from the creation of new smaller vessels, is crucial for the keen analysis of diseases (e.g., diabetic retinopathy). The small vessels are crucial to segment, owing to continuous max-pooling operations and deeper networks. We herein present a pool less residual segmentation network that is capable of segmenting even smaller vessels using a shallower network with a low number of trainable parameters. Our proposed pool-less residual segmentation network (PLRS-Net) is a vessel segmentation network that provides the pooling effect with strided convolution for better segmentation sensitivity. The final PLRS-Net is an advanced form of a pool-less segmentation network (PLS-Net) wherein semantic segmentation was performed with a few layers, and the residual connection fulfilled the feature enhancement strategy to construct PLRS-Net. PLS-Net and PLRS-Net are two separate networks that can perform vessel segmentation without prior preprocessing and postprocessing.To evaluate our proposed method, the experiments include three publicly available datasets: Digital retinal images for vessel extraction (DRIVE), child heart health study in England database (CHASE-DB1), and structured analysis of retina (STARE). The results demonstrate that our proposed method provides a high segmentation performance, achieving an average sensitivity (Sen) of 82.69, specificity (Spe) of 98.17, accuracy (Acc) 96.82, and area under the curve (AUC) of 98.35 for the DRIVE dataset, Sen of 83.01, Spe of 98.39, Acc of 97.31, and AUC of 98.63 for the CHASE-DB1 dataset, and a Sen of 86.35, Spe of 98.03, Acc of 97.15, and AUC of 98.99 for the STARE dataset. These accuracies show exceptional segmentation performance of the proposed method compared to state-of-the-art approaches for automatic vessel detection for diagnosis purposes.",retinal vessels; diabetic and hypertensive retinopathy; deep learning; plrs-net; pls-net
Article,"Zhang, Guanghua; Sun, Bin; Chen, Zhixian; Gao, Yuxi; Zhang, Zhaoxia; Li, Keran; Yang, Weihua",Diabetic Retinopathy Grading by Deep Graph Correlation Network on Retinal Images Without Manual Annotations,frontiers in medicine,2022,Not found,"BackgroundDiabetic retinopathy, as a severe public health problem associated with vision loss, should be diagnosed early using an accurate screening tool. While many previous deep learning models have been proposed for this disease, they need sufficient professional annotation data to train the model, requiring more expensive and time-consuming screening skills. MethodThis study aims to economize manual power and proposes a deep graph correlation network (DGCN) to develop automated diabetic retinopathy grading without any professional annotations. DGCN involves the novel deep learning algorithm of a graph convolutional network to exploit inherent correlations from independent retinal image features learned by a convolutional neural network. Three designed loss functions of graph-center, pseudo-contrastive, and transformation-invariant constrain the optimisation and application of the DGCN model in an automated diabetic retinopathy grading task. ResultsTo evaluate the DGCN model, this study employed EyePACS-1 and Messidor-2 sets to perform grading results. It achieved an accuracy of 89.9% (91.8%), sensitivity of 88.2% (90.2%), and specificity of 91.3% (93.0%) on EyePACS-1 (Messidor-2) data set with a confidence index of 95% and commendable effectiveness on receiver operating characteristic (ROC) curve and t-SNE plots. ConclusionThe grading capability of this study is close to that of retina specialists, but superior to that of trained graders, which demonstrates that the proposed DGCN provides an innovative route for automated diabetic retinopathy grading and other computer-aided diagnostic systems.",diabetic retinopathy; retinal image classification; graph correlation network; unsupervised learning; automated diagnosis
Article,"Sun, Yunlei; Zhang, Dalin",Diagnosis and Analysis of Diabetic Retinopathy Based on Electronic Health Records,ieee access,2019,Not found,"Diabetic retinopathy (DR) is an important disease leading to blindness in humans, attracting a lot of research interests. Previous breakthrough research findings rely on deep learning techniques to diagnose diabetic retinopathy in patients with medical imaging. Although the medical imaging achieves reasonable recognition accuracy, the application of mass, easy-to-obtain and free electronic health records (EHR) data in life can make an early diagnosis of the DR more convenient and quick. In this paper, we used a set of five machine learning models to diagnose the DR in patients with the EHR data and formed a set of treatment methods. Our experimental data set is formed by processing the data provided by 301 hospitals. The experimental results show that random forest (RF) in the machine learning model can get 92% accuracy with good performance. Subsequently, the input features were analyzed and their importance graded to find that the predisposing factors triggering the human DR disease were associated with renal and liver function. In addition, disease diagnosis methods based on readily available the EHR data will become an integral part of smart healthcare and mobile healthcare.",diabetic retinopathy; disease diagnosis; electronic medical records; machine learning; mobile medical
Article,"Rego, Silvia; Dutra-Medeiros, Marco; Soares, Filipe; Monteiro-Soares, Matilde",Screening for Diabetic Retinopathy Using an Automated Diagnostic System Based on Deep Learning: Diagnostic Accuracy Assessment,ophthalmologica,2021,Not found,"Purpose: To evaluate the diagnostic accuracy of a diagnostic system software for the automated screening of diabetic retinopathy (DR) on digital colour fundus photographs, the 2019 Convolutional Neural Network (CNN) model with Inception-V3. Methods: In this cross-sectional study, 295 fundus images were analysed by the CNN model and compared to a panel of ophthalmologists. Images were obtained from a dataset acquired within a screening programme. Diagnostic accuracy measures and respective 95% CI were calculated. Results: The sensitivity and specificity of the CNN model in diagnosing referable DR was 81% (95% CI 66-90%) and 97% (95% CI 95-99%), respectively. Positive predictive value was 86% (95% CI 72-94%) and negative predictive value 96% (95% CI 93-98%). The positive likelihood ratio was 33 (95% CI 15-75) and the negative was 0.20 (95% CI 0.11-0.35). Its clinical impact is demonstrated by the change observed in the pre-test probability of referable DR (assuming a prevalence of 16%) to a post-test probability for a positive test result of 86% and for a negative test result of 4%. Conclusion: A CNN model negative test result safely excludes DR, and its use may significantly reduce the burden of ophthalmologists at reading centres.",diabetic retinopathy; screening; artificial intelligence; automated diagnosis
Article,"Bustamam, Alhadi; Sarwinda, Devvi; Paradisa, Radifa H.; Victor, Andi Arus; Yudantha, Anggun Rama; Siswantining, Titin",EVALUATION OF CONVOLUTIONAL NEURAL NETWORK VARIANTS FOR DIAGNOSIS OF DIABETIC RETINOPATHY,communications in mathematical biology and neuroscience,2021,Not found,"Diabetic Retinopathy (DR) is a long-term complication of Diabetes Mellitus (DM) that impairs vision. This stage occurs in visual impairment and blindness if treated late. DR identified through scanning fundus images. A technique on classifying DR in fundus images is the deep learning approach, one of the methods of implementing machine learning. In this study, the Convolutional Neural Networks (CNN) method applied with the ResNet-50 and DenseNet-121 architectures. The data adopted in this analysis was generated from DIARETDB1, an online database containing fundus images. Then, the pre-processing stage is carried out on the fundus image to improve model performance, such as selected the green channel from the images and inverted it, converted the images into grayscale images, and applied Contrast Limited Adaptive Histogram Equalization (CLAHE) for uniform contrast in the images. The outcome of this research indicates that the ResNet-50 model is better than DenseNet-121 in detecting DR. The most reliable results from the ResNet-50 model's case testing are accuracy, precision, and recall of 95%, 98%, and 96% respectively.",diabetic retinopathy; fundus image; deep learning; resnet; densenet
Proceedings Paper,"Suedumrong, Chaichana; Leksakul, Komgrit; Wattana, Pranprach; Chaopaisarn, Poti",Application of Deep Convolutional Neural Networks VGG-16 and GoogLeNet for Level Diabetic Retinopathy Detection,"proceedings of the future technologies conference (ftc) 2021, vol 2",2022,Not found,"Diabetic retinopathy (DR) is a diabetes complication that damages the retina. This type of medical condition affects up to 80% of patients with diabetes for 10 or more years. The expertise and equipment required are often lacking in areas where diabetic retinopathy detection is most needed. Most of the work in the field of diabetic retinopathy has been based on disease detection or manual extraction of features. Thus, this research aims at automatic diagnosis of the disease in its different stages using deep learning neural network approach. This paper presents the design and implementation of Graphic Processing Unit (hereby GPU) accelerated deep convolutional neural networks to automatically diagnose and thereby classify high-resolution retinal images into five stages of the disease based on its severity. The accuracy of the single model convolutional neural networks presented in this paper is 71.65% from VGG-16.",diabetic retinopathy; deep learning; convolutional neural networks; vgg-16; googlenet
Proceedings Paper,"Tian, Li; Ma, Liyan; Wen, Zhijie; Xie, Shaorong; Xu, Yupeng",Learning Discriminative Representations for Fine-Grained Diabetic Retinopathy Grading,2021 international joint conference on neural networks (ijcnn),2021,Not found,"Diabetic retinopathy is one of the leading causes of blindness. However, no specific symptoms of early DR lead to a delayed diagnosis, which results in disease progression in patients. To determine the disease severity levels, ophthalmologists need to focus on the discriminative parts of the retinal images. In recent years, deep learning has achieved great success in medical image analysis. However, most works directly employ algorithms based on convolutional neural networks (CNNs), which ignore the fact that the difference among classes is subtle and gradual. Hence, we consider automatic image grading of DR as a fine-grained classification task, and construct a bilinear model to identify the pathologically discriminative areas. In order to leverage the ordinal information among classes, we put the soft labels with ordinal information among classes into the loss function rather than the most commonly used one-hot labels for the diabetic retinopathy classification. In addition, other than only using a categorical loss to train our network, we also introduce the metric loss to learn a more discriminative feature space which is beneficial to locate the finer discriminative lesion parts. Experimental results demonstrate the superior performance of the proposed method on publicly available IDRiD, DeepDRiD and FGADR datasets.",diabetic retinopathy; fine-grained classification; ordinal regression; metric learning
Review,"Sengupta, Sourya; Singh, Amitojdeep; Leopold, Henry A.; Gulati, Tanmay; Lakshminarayanan, Vasudevan",Ophthalmic diagnosis using deep learning with fundus images - A critical review,artificial intelligence in medicine,2020,Not found,"An overview of the applications of deep learning for ophthalmic diagnosis using retinal fundus images is presented. We describe various retinal image datasets that can be used for deep learning purposes. Applications of deep learning for segmentation of optic disk, optic cup, blood vessels as well as detection of lesions are reviewed. Recent deep learning models for classification of diseases such as age-related macular degeneration, glaucoma, and diabetic retinopathy are also discussed. Important critical insights and future research directions are given.",fundus photos; deep learning; ophthalmology; image segmentation; classification; fundus image datasets; retina
Proceedings Paper,"Amanda, Isca; Zakaria, Hasballah",Development of Diabetic Retinopathy Early Detection and Its Implementation in Android Application,"4th biomedical engineering's recent progress in biomaterials, drugs development, health, and medical devices: proceedings of the international symposium of biomedical engineering (isbe) 2019",2019,Not found,"Diabetic retinopathy (DR) is a diabetes complication causing blindness in which symptoms are not perceived in earlier stage or non-proliferative diabetic retinopathy (NPDR). It is difficult for manual diagnosis methods to keep pace with the growing number of DR. In this study, an algorithm to detect NPDR was developed and implemented in the Android application. In contrary to feature engineering, this study explored a different classification approach by having used a deep neural networks and transfer learning methods on fundus images to train the classifier models. Model development utilized Messidor (4 class) dataset and Messidor-2 (2 class) dataset, image pre-processing, Inception V3 network and MobileNetV1 network, the configuration of test set-train set split, optimizer, and learning rate. Test accuracy of 86% was acquired with InceptionV3 and Messidor-2 which then implemented in Android application. Its yielded accuracy, sensitivity, and specificity are 88%, 80%, and 76% respectively.",android; deep neural network; diabetic retinopathy; transfer learning
Article,"Skouta, Ayoub; Elmoufidi, Abdelali; Jai-Andaloussi, Said; Ouchetto, Ouail",Hemorrhage semantic segmentation in fundus images for the diagnosis of diabetic retinopathy by using a convolutional neural network,journal of big data,2022,Not found,"Because retinal hemorrhage is one of the earliest symptoms of diabetic retinopathy, its accurate identification is essential for early diagnosis. One of the major obstacles ophthalmologists face in making a quick and effective diagnosis is viewing too many images to manually identify lesions of different shapes and sizes. To this end, researchers are working to develop an automated method for screening for diabetic retinopathy. This paper presents a modified CNN UNet architecture for identifying retinal hemorrhages in fundus images. Using the graphics processing unit (GPU) and the IDRiD dataset, the proposed UNet was trained to segment and detect potential areas that may harbor retinal hemorrhages. The experiment was also tested using the IDRiD and DIARETDB1 datasets, both freely available on the Internet. We applied preprocessing to improve the image quality and increase the data, which play an important role in defining the complex features involved in the segmentation task. A significant improvement was then observed in the learning neural network that was able to effectively segment the bleeding and achieve sensitivity, specificity and accuracy of 80.49%, 99.68%, and 98.68%, respectively. The experimental results also yielded an IoU of 76.61% and a Dice value of 86.51%, showing that the predictions obtained by the network are effective and can significantly reduce the efforts of ophthalmologists. The results revealed a significant increase in the diagnostic performance of one of the most important retinal disorders caused by diabetes.",diabetic retinopathy; fundus images; segmentation; detection; deep learning; convolutional neural networks; artificial intelligence; cad system
Article,"Dai, Ling; Wu, Liang; Li, Huating; Cai, Chun; Wu, Qiang; Kong, Hongyu; Liu, Ruhan; Wang, Xiangning; Hou, Xuhong; Liu, Yuexing; Long, Xiaoxue; Wen, Yang; Lu, Lina; Shen, Yaxin; Chen, Yan; Shen, Dinggang; Yang, Xiaokang; Zou, Haidong; Sheng, Bin; Jia, Weiping",A deep learning system for detecting diabetic retinopathy across the disease spectrum,nature communications,2021,Not found,"Retinal screening contributes to early detection of diabetic retinopathy and timely treatment. To facilitate the screening process, we develop a deep learning system, named DeepDR, that can detect early-to-late stages of diabetic retinopathy. DeepDR is trained for real-time image quality assessment, lesion detection and grading using 466,247 fundus images from 121,342 patients with diabetes. Evaluation is performed on a local dataset with 200,136 fundus images from 52,004 patients and three external datasets with a total of 209,322 images. The area under the receiver operating characteristic curves for detecting microaneurysms, cotton-wool spots, hard exudates and hemorrhages are 0.901, 0.941, 0.954 and 0.967, respectively. The grading of diabetic retinopathy as mild, moderate, severe and proliferative achieves area under the curves of 0.943, 0.955, 0.960 and 0.972, respectively. In external validations, the area under the curves for grading range from 0.916 to 0.970, which further supports the system is efficient for diabetic retinopathy grading. As the leading cause of vision loss in working-age adults, diabetic retinopathy requires routinely retinal screening. Here the authors develop a deep learning system that can facilitate the screening by providing real-time image quality assessment, lesions detection, and grades across the disease spectrum.",risk-factors; glycemic control; macular edema; prevalence; progression
Article,"Stolte, Skylar; Fang, Ruogu",A survey on medical image analysis in diabetic retinopathy,medical image analysis,2020,Not found,"Diabetic Retinopathy (DR) represents a highly-prevalent complication of diabetes in which individuals suffer from damage to the blood vessels in the retina. The disease manifests itself through lesion presence, starting with microaneurysms, at the nonproliferative stage before being characterized by neovascularization in the proliferative stage. Retinal specialists strive to detect DR early so that the disease can be treated before substantial, irreversible vision loss occurs. The level of DR severity indicates the extent of treatment necessary - vision loss may be preventable by effective diabetes management in mild (early) stages, rather than subjecting the patient to invasive laser surgery. Using artificial intelligence (AI), highly accurate and efficient systems can be developed to help assist medical professionals in screening and diagnosing DR earlier and without the full resources that are available in specialty clinics. In particular, deep learning facilitates diagnosis earlier and with higher sensitivity and specificity. Such systems make decisions based on minimally handcrafted features and pave the way for personalized therapies. Thus, this survey provides a comprehensive description of the current technology used in each step of DR diagnosis. First, it begins with an introduction to the disease and the current technologies and resources available in this space. It proceeds to discuss the frameworks that different teams have used to detect and classify DR. Ultimately, we conclude that deep learning systems offer revolutionary potential to DR identification and prevention of vision loss. (C) 2020 Elsevier B.V. All rights reserved.",diabetic retinopathy; deep learning; image mining; lesion detection
Article; Early Access,"Sambyal, Nitigya; Saini, Poonam; Syal, Rupali; Gupta, Varun",Modified residual networks for severity stage classification of diabetic retinopathy,evolving systems,0,Not found,"Diabetic Retinopathy is a common microvascular complication associated with diabetes and also one of the main reason for blindness globally. Manual diagnosis of diabetic retinopathy (DR) by ophthalmologists is time consuming and tedious task. This paper proposes modified deep residual networks for binary and multistage classification of DR. The proposed models have been evaluated on publicly available MESSIDOR dataset. For binary classification, the modified ResNet18, ResNet34 and ResNet50 models show an accuracy of 99.47%, 99.47% and 99.87% respectively. The Multistage classification accuracy obtained using modified ResNet18 is 99.37%, modified Resnet34 is 99.16% and modified ResNet50 is 99.37%. Further, a comparison of the proposed model with the models in literature shows an overall accuracy improvement by at least 0.83% and more than 5% for binary and multistage classification respectively. It has been observed that the proposed DR classification models outperform the existing methods on the benchmark dataset.",diabetic retinopathy; computer-aided diagnosis; cnn; deep learning; residual networks
Proceedings Paper,"Attota, Dinesh; Tadikonda, Durga Nagarjuna; Pethe, Shruthi; Khan, Md Abdullah Al Hafiz",An Ensembled Method For Diabetic Retinopathy Classification using Transfer Learning,"2022 ieee 46th annual computers, software, and applications conference (compsac 2022)",2022,Not found,"Diabetes affects 40-45% of Diabetic Retinopathy (DR) patients in the US. Early detection of DR may prevent or postpone vision deterioration, but it is difficult since the disorder often manifests with few symptoms until it is too late to treat. Clinically, DR is routinely treated using fundus images, with an estimated 200 million cases worldwide and over 400,000 deaths each year. A great deal of progress has been made by applying machine learning algorithms to the fundus images. As a result, image classification and detection have become reliable techniques for detecting the severity of diabetic retinopathy. Convolutional Neural Networks (CNNs) play a crucial role in the image classification and detection process by capturing various images' details, enabling a fast and efficient method for detecting diabetic retinopathy. CNN pre-trained models such as ResNet50, InceptionV3, and EfficientNetB7 have substantially improved their performance in the ImageNet Large-Scale Visual Recognition Competition. In addition, these pre-trained models are more precise and inexpensive to train because of the shorter connections between their input and output layers. This work proposes an approach for image classification that ensembles three pre-trained models, namely: EfficientNetB7, ResNet50V2, and InceptionV3, to perform the classification of the diabetic retinopathy subtypes. Our proposed method achieves 97.43% accuracy by adjusting the weights of the pre-trained models in detecting DR using the EyePacs Dataset.",convolutional neural network (cnn); deep transfer learning; diabetic retinopathy (dr)
Article,"Saeed, Fahman; Hussain, Muhammad; Aboalsamh, Hatim A.",Automatic Diabetic Retinopathy Diagnosis Using Adaptive Fine-Tuned Convolutional Neural Network,ieee access,2021,Not found,"Diabetic retinopathy (DR) is a complication of diabetes that leads to blindness. The manual screening of color fundus images to detect DR at early stages is expensive and time consuming. Deep learning (DL) techniques have been employed for automatic DR screening on fundus images due to their outstanding performance in many applications. However, training a DL model needs a huge amount of data, which are usually unavailable in the case of DR, and overfitting is unavoidable. Employing a two-stage transfer learning method, we developed herein an intelligent computer-aided system using a pre-trained convolutional neural network (CNN) for automatic DR screening on fundus images. A CNN model learns the domain-specific hierarchy of low- to high-level features. Given this, using the regions of interest (ROIs) of lesions extracted from the annotated fundus images, the first layer of a pre-trained CNN model is re-initialized. The model is then fine-tuned, such that the low-level layers learn the local structures of the lesion and normal regions. As the fully connected layer (FC) layers encode high-level features, which are global in nature and domain specific, we replace them with a new FC layer based on the principal component analysis PCA and use it in an unsupervised manner to extract discriminate features from the fundus images. This step reduces the model complexity, significantly avoiding the overfitting problem. This step also lets the model adopt the fundus image structures, making it suitable for DR feature detection. Finally, we add a gradient boosting-based classification layer. The evaluation of the proposed system using a 10-fold cross-validation on two challenging datasets (i.e., EyePACS and Messidor) indicates that it outperforms state-of-the-art methods. It will be useful for the initial screening of DR patients and will help graders in deciding quickly as regards patient referral to an ophthalmologist for further diagnosis and treatment.",retina; lesions; feature extraction; diabetes; transfer learning; retinopathy; training; fundus images; diabetic retinopathy; classification; cnn
Review,"Sorrentino, Francesco Saverio; Jurman, Giuseppe; De Nadai, Katia; Campa, Claudio; Furlanello, Cesare; Parmeggiani, Francesco",Application of Artificial Intelligence in Targeting Retinal Diseases,current drug targets,2020,Not found,"Retinal diseases affect an increasing number of patients worldwide because of the aging population. Request for diagnostic imaging in ophthalmology is ramping up, while the number of specialists keeps shrinking Cutting-edge technology embedding artificial intelligence (AI) algorithms are thus advocated to help ophthalmologists perform their clinical tasks as well as to provide a source for the advancement of novel biomarkers. In particular, optical coherence tomography (OCT) evaluation of the retina can be augmented by algorithms based on machine learning and deep learning to early detect, qualitatively localize and quantitatively measure epilintra/subretinal abnormalities or pathological features of macular or neural diseases. In this paper, we discuss the use of Al to facilitate efficacy and accuracy of retinal imaging in those diseases increasingly treated by intravitreal vascular endothelial growth factor (VEGF) inhibitors (i.e. anti-VEGF drugs), also including integration and interpretation features in the process. We review recent advances by Al in diabetic retinopathy, age -related macular degeneration, and retinopathy of prematurity that envision a potentially key role of highly automated systems in screening, early diagnosis, grading and individualized therapy. We discuss benefits and critical aspects of automating the evaluation of disease activity, recurrences, the timing of re treatment and therapeutically potential novel targets in ophthalmology. The impact of massive employment of AI to optimize clinical assistance and encourage tailored therapies for distinct patterns of retinal diseases is also discussed.","retinal diseases; macular complications; anti-vegf drugs; retinal imaging; optical coherence tomography; artificial intelligence; machine learning, deep learning"
Article,"Gu, Yunchao; Wang, Xinliang; Pan, Junjun; Yong, Zhifan; Guo, Shihui; Pan, Tianze; Jiao, Yonghong; Zhou, Zhong",Effective methods of diabetic retinopathy detection based on deep convolutional neural networks,international journal of computer assisted radiology and surgery,2021,Not found,"Purpose Diabetic retinopathy (DR) has become the leading cause of blindness worldwide. In clinical practice, the detection of DR often takes a lot of time and effort for ophthalmologist. It is necessary to develop an automatic assistant diagnosis method based on medical image analysis techniques. Methods Firstly, we design a feature enhanced attention module to capture focus lesions and regions. Secondly, we propose a stage sampling strategy to solve the problem of data imbalance on datasets and avoid the CNN ignoring the focus features of samples that account for small parts. Finally, we treat DR detection as a regression task to keep the gradual change characteristics of lesions and output the final classification results through the optimization method on the validation set. Results Extensive experiments are conducted on open-source datasets. Our methods achieve 0.851 quadratic weighted kappa which outperforms first place in the Kaggle DR detection competition based on the EyePACS dataset and get the accuracy of 0.914 in the referable/non-referable task and 0.913 in the normal/abnormal task based on the Messidor dataset. Conclusion In this paper, we propose three novel automatic DR detection methods based on deep convolutional neural networks. The results illustrate that our methods can obtain comparable performance compared with previous methods and generate visualization pictures with potential lesions for doctors and patients.",diabetic retinopathy; fundus image analysis; deep learning; convolutional neural networks
Article,"Thomas, G. Arun Sampaul; Robinson, Y. Harold; Julie, E. Golden; Shanmuganathan, Vimal; Rho, Seungmin; Nam, Yunyoung",Intelligent Prediction Approach for Diabetic Retinopathy Using Deep Learning Based Convolutional Neural Networks Algorithm by Means of Retina Photographs,cmc-computers materials & continua,2021,Not found,"Retinopathy is a human eye disease that causes changes in retinal blood vessels that leads to bleed, leak fluid and vision impairment. Symptoms of retinopathy are blurred vision, changes in color perception, red spots, and eye pain and it cannot be detected with a naked eye. In this paper, a new methodology based on Convolutional Neural Networks (CNN) is developed and proposed to intelligent retinopathy prediction and give a decision about the presence of retinopathy with automatic diabetic retinopathy screening with accurate diagnoses. The CNN model is trained by different images of eyes that have retinopathy and those which do not have retinopathy. The fully connected layers perform the classification process of the images from the dataset with the pooling layers minimize the coherence among the adjacent layers. The feature loss factor increases the label value to identify the patterns with the kernel-based matching. The performance of the proposed model is compared with the related methods of DREAM, KNN, GD-CNN and SVM. Experimental results show that the proposed CNN performs better.",convolutional neural networks; dental diagnosis; image recognition; diabetic retinopathy detection
Article,"Zhang, Xiao; Li, Fan; Li, Donghong; Wei, Qijie; Han, Xiaoxu; Zhang, Bilei; Chen, Huan; Zhang, Yongpeng; Mo, Bin; Hu, Bojie; Ding, Dayong; Li, Xirong; Yu, Weihong; Chen, Youxin",Automated detection of severe diabetic retinopathy using deep learning method,graefes archive for clinical and experimental ophthalmology,2022,Not found,"Purpose The purpose of this study is to develop and validate the intelligent diagnosis of severe DR with lesion recognition based on color fundus photography. Methods The Kaggle public dataset for DR grading is used in the project, including 53,576 fundus photos in the test set, 28,101 in the training set, and 7,025 in the validation set. We randomly select 4,192 images for lesion annotation. Inception V3 structure is adopted as the classification algorithm. Both 299 x 299 pixel images and 896 x 896 pixel images are used as the input size. ROC curve, AUC, sensitivity, specificity, and their harmonic mean are used to evaluate the performance of the models. Results The harmonic mean and AUC of the model of 896 x 896 input are higher than those of the 299 x 299 input model. The sensitivity, specificity, harmonic mean, and AUC of the method with 896 x 896 resolution images as input for severe DR are 0.925, 0.907, 0.916, and 0.968, respectively. The prediction error mainly occurs in moderate NPDR, and cases with more hard exudates and cotton wool spots are easily predicted as severe cases. Cases with preretinal hemorrhage and vitreous hemorrhage are easily identified as severe cases, and IRMA is the most difficult lesion to recognize. Conclusions We have studied the intelligent diagnosis of severe DR based on color fundus photography. This artificial intelligence-based technology offers a possibility to increase the accessibility and efficiency of severe DR screening.",severe diabetic retinopathy; color fundus photography; deep learning; intraretinal microvascular abnormality
Article,"Tang, Michael Chi Seng; Teoh, Soo Siang; Ibrahim, Haidi; Embong, Zunaina",Neovascularization Detection and Localization in Fundus Images Using Deep Learning,sensors,2021,Not found,"Proliferative Diabetic Retinopathy (PDR) is a severe retinal disease that threatens diabetic patients. It is characterized by neovascularization in the retina and the optic disk. PDR clinical features contain highly intense retinal neovascularization and fibrous spreads, leading to visual distortion if not controlled. Different image processing techniques have been proposed to detect and diagnose neovascularization from fundus images. Recently, deep learning methods are getting popular in neovascularization detection due to artificial intelligence advancement in biomedical image processing. This paper presents a semantic segmentation convolutional neural network architecture for neovascularization detection. First, image pre-processing steps were applied to enhance the fundus images. Then, the images were divided into small patches, forming a training set, a validation set, and a testing set. A semantic segmentation convolutional neural network was designed and trained to detect the neovascularization regions on the images. Finally, the network was tested using the testing set for performance evaluation. The proposed model is entirely automated in detecting and localizing neovascularization lesions, which is not possible with previously published methods. Evaluation results showed that the model could achieve accuracy, sensitivity, specificity, precision, Jaccard similarity, and Dice similarity of 0.9948, 0.8772, 0.9976, 0.8696, 0.7643, and 0.8466, respectively. We demonstrated that this model could outperform other convolutional neural network models in neovascularization detection.",diabetic retinopathy; neovascularization detection; convolutional neural network; deep learning; computer-aided diagnosis
Review,"Mathews, Mili Rosline; Anzar, S. M.",A comprehensive review on automated systems for severity grading of diabetic retinopathy and macular edema,international journal of imaging systems and technology,2021,Not found,"Diabetes mellitus is a major medical concern worldwide. Long-term diabetes can affect the retina of the eye and lead to diabetic retinopathy (DR) and diabetic macular edema (DME). Proper screening and consultation with an ophthalmologist are necessary to prevent avoidable vision loss. As DR and DME have become more prevalent, automated screening is essential to provide cost-effective and rapid solutions with reduced human resources requirements. This paper aims to provide a comprehensive review of the literature on computer-aided diagnosis of DR and DME. We identified the studies on automated five-class grading of DR according to International Clinical Diabetic Retinopathy severity scale and three class grading of diabetic maculopathy, using fundus images. A systematic search on research repositories was conducted, and relevant studies were scrutinized and included in the review. The studies were reported in nearly 100 different journals. We have reviewed the studies in all aspects including datasets, preprocessing, non-deep learning, and deep learning-based algorithms, and evaluation metrics. Significant contributions in developing automated tools for DR/DME grading are highlighted. We have identified and discussed research gaps and challenges. This will help researchers to get an updated summary of work done in the area. Deep learning-based algorithms have outperformed the traditional algorithms in the domain. Despite their promising performance, these algorithms reveal the potential for significant improvements to become a reliable tool in clinical settings.",computer aided diagnosis; convolutional neural networks; deep learning; diabetic macular edema; diabetic retinopathy; image processing; retinal fundus imaging
Article,"Wang, Shuqiang; Wang, Xiangyu; Hu, Yong; Shen, Yanyan; Yang, Zhile; Gan, Min; Lei, Baiying",Diabetic Retinopathy Diagnosis Using Multichannel Generative Adversarial Network With Semisupervision,ieee transactions on automation science and engineering,2021,Not found,"Diabetic retinopathy (DR) is one of the major causes of blindness. It is of great significance to apply deep-learning techniques for DR recognition. However, deep-learning algorithms often depend on large amounts of labeled data, which is expensive and time-consuming to obtain in the medical imaging area. In addition, the DR features are inconspicuous and spread out over high-resolution fundus images. Therefore, it is a big challenge to learn the distribution of such DR features. This article proposes a multichannel-based generative adversarial network (MGAN) with semisupervision to grade DR. The multichannel generative model is developed to generate a series of subfundus images corresponding to the scattering DR features. By minimizing the dependence on labeled data, the proposed semisupervised MGAN can identify the inconspicuous lesion features by using high-resolution fundus images without compression. Experimental results on the public Messidor data set show that the proposed model can grade DR effectively. Note to Practitioners-This article is motivated by the challenging problem due to the inadequacy of labeled data in medical image analysis and the dispersion of efficient features in high-resolution medical images. As for the inadequacy of labeled data in medical image analysis, the reasons mainly include the followings: 1) the high-quality annotation of medical imaging sample depends heavily on scarce medical expertise which is very expensive and 2) comparing with natural issues, it is more difficult to collect medical images because of privacy issues. It is of great significance to apply deep-learning techniques for diabetic retinopathy (DR) recognition. In this article, the multichannel generative adversarial network (GAN) with semisupervision is developed for DR-aided diagnosis. The proposed model can deal with DR classification problem with inadequacy of labeled data in the following ways: 1) the multichannel generative scheme is proposed to generate a series of subfundus images corresponding to the scattering DR features and 2) the proposed multichannel-based GAN (MGAN) model with semisupervision can make full use of both labeled data and unlabeled data. The experimental results demonstrate that the proposed model outperforms the other representative models in terms of accuracy, area under ROC curve (AUC), sensitivity, and specificity.",computer-aided diagnosis (cad); diabetic retinopathy (dr); generative adversarial network (gan); multichannel; semisupervised learning
Article,"Al-Moosawi, Noor M.; Khudeyer, Raidah S.",ResNet-34/DR: A Residual Convolutional Neural Network for the Diagnosis of Diabetic Retinopathy,informatica-an international journal of computing and informatics,2021,Not found,"Diabetic retinopathy (DR) is an eye complication associated with diabetes, resulting in blurred vision or blindness. The early diagnosis and treatment of DR can decrease the risk of vision loss dramatically. However, such diagnosis is a tedious and complicated task due to the variability of retinal changes across the stages of the diseases, and due to the high number of undiagnosed and untreated DR cases. In this paper, we develop a computationally efficient and scalable deep learning model using convolutional neural networks (CNN), for diagnosing DR automatically. Various preprocessing algorithms are utilized to improve accuracy, and a transfer learning strategy is adopted to speed up the process. Our experiment used the fundus image set available on online Kaggle datasets. As an ultimate conclusion of applicable performance metrics, our computational simulation achieved a relatively-high F1 score of 93.2% for stage-based DR classification.",convolutional neural networks (cnn); deep learning (dl); diabetic retinopathy (dr); resnet-34; transfer learning (tl)
Article,"Rahman, K. K. Mujeeb; Nasor, Mohamed; Imran, Ahmed",Automatic Screening of Diabetic Retinopathy Using Fundus Images and Machine Learning Algorithms,diagnostics,2022,Not found,"Diabetic Retinopathy is a vision impairment caused by blood vessel degeneration in the retina. It is becoming more widespread as it is linked to diabetes. Diabetic retinopathy can lead to blindness. Early detection of diabetic retinopathy by an ophthalmologist can help avoid vision loss and other complications. Diabetic retinopathy is currently diagnosed by visually recognizing irregularities on fundus pictures. This procedure, however, necessitates the use of ophthalmic imaging technologies to acquire fundus images as well as a detailed visual analysis of the stored photos, resulting in a costly and time-consuming diagnosis. The fundamental goal of this project is to create an easy-to-use machine learning model tool that can accurately predict diabetic retinopathy using pre-recorded digital fundus images. To create the suggested classifier model, we gathered annotated fundus images from publicly accessible data repositories and used two machine learning methods, support vector machine (SVM) and deep neural network (DNN). On test data, the proposed SVM model had a mean area under the receiver operating characteristic curve (AUC) of 97.11%, whereas the DNN model had a mean AUC of 99.15%.",diabetic retinopathy; machine learning; glcm feature; fundus image; image segmentation; matlab; svm; dnn
Article,"AbdelMaksoud, Eman; Barakat, Sherif; Elmogy, Mohammed",A computer-aided diagnosis system for detecting various diabetic retinopathy grades based on a hybrid deep learning technique,medical & biological engineering & computing,2022,Not found,"Diabetic retinopathy (DR) is a serious disease that may cause vision loss unawares without any alarm. Therefore, it is essential to scan and audit the DR progress continuously. In this respect, deep learning techniques achieved great success in medical image analysis. Deep convolution neural network (CNN) architectures are widely used in multi-label (ML) classification. It helps in diagnosing normal and various DR grades: mild, moderate, and severe non-proliferative DR (NPDR) and proliferative DR (PDR). DR grades are formulated by appearing multiple DR lesions simultaneously on the color retinal fundus images. Many lesion types have various features that are difficult to segment and distinguished by utilizing conventional and hand-crafted methods. Therefore, the practical solution is to utilize an effective CNN model. In this paper, we present a novel hybrid, deep learning technique, which is called E-DenseNet. We integrated EyeNet and DenseNet models based on transfer learning. We customized the traditional EyeNet by inserting the dense blocks and optimized the resulting hybrid E-DensNet model's hyperparameters. The proposed system based on the E-DenseNet model can accurately diagnose healthy and different DR grades from various small and large ML color fundus images. We trained and tested our model on four different datasets that were published from 2006 to 2019. The proposed system achieved an average accuracy (ACC), sensitivity (SEN), specificity (SPE), Dice similarity coefficient (DSC), the quadratic Kappa score (QKS), and the calculation time (T) in minutes (m) equal 91.2%, 96%, 69%, 92.45%, 0.883, and 3.5m respectively. The experiments show promising results as compared with other systems.",diabetic retinopathy (dr); convolution neural network (cnn); transfer learning; eyenet; densenet; e-densenet
Review; Early Access,"Dubey, Shradha; Dixit, Manish",Recent developments on computer aided systems for diagnosis of diabetic retinopathy: a review,multimedia tools and applications,0,Not found,"Diabetes is a long-term condition in which the pancreas quits producing insulin or the body's insulin isn't utilised properly. One of the signs of diabetes is Diabetic Retinopathy. Diabetic retinopathy is the most prevalent type of diabetes, if remains unaddressed, diabetic retinopathy can affect all diabetics and become very serious, raising the chances of blindness. It is a chronic systemic condition that affects up to 80% of patients for more than ten years. Many researchers believe that if diabetes individuals are diagnosed early enough, they can be rescued from the condition in 90% of cases. Diabetes damages the capillaries, which are microscopic blood vessels in the retina. On images, blood vessel damage is usually noticeable. Therefore, in this study, several traditional, as well as deep learning-based approaches, are reviewed for the classification and detection of this particular diabetic-based eye disease known as diabetic retinopathy, and also the advantage of one approach over the other is also described. Along with the approaches, the dataset and the evaluation metrics useful for DR detection and classification are also discussed. The main finding of this study is to aware researchers about the different challenges occurs while detecting diabetic retinopathy using computer vision, deep learning techniques. Therefore, a purpose of this review paper is to sum up all the major aspects while detecting DR like lesion identification, classification and segmentation, security attacks on the deep learning models, proper categorization of datasets and evaluation metrics. As deep learning models are quite expensive and more prone to security attacks thus, in future it is advisable to develop a refined, reliable and robust model which overcomes all these aspects which are commonly found while designing deep learning models.",diabetic retinopathy; microaneurysms; hemorrhages; exudate; retinal blood vessel; optic disc; cup
Review,"Shetty, Dasharathraj K.; Talasila, Abhiroop; Shanbhag, Swapna; Patil, Vathsala; Hameed, Zeehan; Naik, Nithesh; Raju, Adithya",Current state of artificial intelligence applications in ophthalmology and their potential to influence clinical practice,cogent engineering,2021,Not found,"Artificial intelligence (AI) has emerged as a major frontier in healthcare and finds broad range of applications. It has the potential to revolutionize current procedures of disease diagnosis and treatment, thus influencing the clinical practice. Artificial intelligence (AI) in ophthalmology, primarily concentrates on diagnostic and treatment pathways for eye conditions such as cataract, glaucoma, age-related macular degeneration (MDA) and diabetic retinopathy (DR). The purpose of this article is to systematically review the existing state of literature on the various AI techniques and its applications in the diagnosis and treatment of eye diseases and conduct an in-depth enquiry to identify the challenges in accurate detection, pre-processing of data, monitoring and assessment through various AI algorithms. The results suggest that all AI models proposed reduce the detection time considerably. The potential limitations and challenges in the development and application play a significant role in clinical practice. There is a need for the development of AI-assisted technologies that shall consider the clinical implications based on experience and guided by patient-centred healthcare principles. The diagnostic models should assist ophthalmologists on making quick and accurate decisions in determining the progression of various ocular diseases.",artificial intelligence; machine learning; neural networks; ophthalmology; deep learning; diabetic retinopathy; age-related macular degeneration; diagnosis; diagnostic imaging; image interpretation
Article,"Abbood, Saif Hameed; Hamed, Haza Nuzly Abdull; Rahim, Mohd Shafry Mohd; Rehman, Amjad; Saba, Tanzila; Bahaj, Saeed Ali",Hybrid Retinal Image Enhancement Algorithm for Diabetic Retinopathy Diagnostic Using Deep Learning Model,ieee access,2022,Not found,"Diabetic Retinopathy (DR) is a prevalent acute stage of diabetes mellitus that causes vision-effecting abnormalities on the retina. This will cause blindness if not identified early. Because DR not an irreversible procedure, and only vision is preserved via care. Consequently, Early diagnosis and care with DR will significantly minimize the chance of vision loss. In modern ophthalmology, retinal image analysis has become a popular approach to disease diagnosis. The ophthalmologists and computerized systems extensively employ fundus angiography to detect DR-based clinical signs for early detection of DR. fundus photographs are commonly prone to low contrast, noise, and irregular illumination issues due to the complexity of imaging environments such as imaging variety of angles and light conditions. This research presents an Algorithm for improving the quality of images to strengthen the standard of color fundus images by reducing the noise and improving the contrast. The approach includes two main stages: cropping the images to remove insignificant content, then applying the shape crop and gaussian blurring for noise reduction and contrast improvement. The experimental results are evaluated using two standard datasets EyePACS and MESSIDOR. It's clearly shown that the outcomes of feature extraction and classification of enhanced images is outperform the results without applying the enhancement approach. The improved algorithm is also tested in smart hospitals as an IoMT application.",retina; image enhancement; feature extraction; image color analysis; histograms; diabetes; image segmentation; image enhancement; deep learning; diabetic retinopathy; retina; fundus image; healthcare; health risks
Article; Early Access,"Das, Dolly; Biswas, Saroj Kumar; Bandyopadhyay, Sivaji",Detection of Diabetic Retinopathy using Convolutional Neural Networks for Feature Extraction and Classification (DRFEC),multimedia tools and applications,0,Not found,"Diabetic Retinopathy (DR) is caused as a result of Diabetes Mellitus which causes development of various retinal abrasions in the human retina. These lesions cause hindrance in vision and in severe cases, DR can lead to blindness. DR is observed amongst 80% of patients who have been diagnosed from prolonged diabetes for a period of 10-15 years. The manual process of periodic DR diagnosis and detection for necessary treatment, is time consuming and unreliable due to unavailability of resources and expert opinion. Therefore, computerized diagnostic systems which use Deep Learning (DL) Convolutional Neural Network (CNN) architectures, are proposed to learn DR patterns from fundus images and identify the severity of the disease. This paper proposes a comprehensive model using 26 state-of-the-art DL networks to assess and evaluate their performance, and which contribute for deep feature extraction and image classification of DR fundus images. In the proposed model, ResNet50 has shown highest overfitting in comparison to Inception V3, which has shown lowest overfitting when trained using the Kaggle's EyePACS fundus image dataset. EfficientNetB4 is the most optimal, efficient and reliable DL algorithm in detection of DR, followed by InceptionResNetV2, NasNetLarge and DenseNet169. EfficientNetB4 has achieved a training accuracy of 99.37% and the highest validation accuracy of 79.11%. DenseNet201 has achieved the highest training accuracy of 99.58% and a validation accuracy of 76.80% which is less than the top-4 best performing models.",diabetic retinopathy; fundus image; convolutional neural network; deep learning; image classification
Proceedings Paper,"Wu, Cong; Xia, Dong; Jin, Jicheng; Yang, Zhi",Classification of diabetic retinopathy based on DSIRNet,14th international conference on computer science and education (iccse 2019),2019,Not found,"The rapid development of deep learning in recent years has achieved great success in the fields of speech recognition, image recognition and natural language processing. At present, the automatic diagnosis of medical images is the focus of attention from all walks of life, and deep learning technology has shown good application prospects in this respect. In response to the screening of diabetic retinopathy, this paper proposes a deep supervision of the Inception-Residual network(DSIRNet) to classify DR images end-to-end. The network combines the advantages of Inception module and residual module, which can not only learn multi-scale features, but also ensure the transmission of feature information between network layers. At the same time, this paper also uses deep monitoring method to assist the training network, which can improve thermal classification effect of the network to a certain extent. In terms of data sets, data noise and sample distribution imbalances are also addressed. The effectiveness of the proposed model and method is verified by comparative experiments.",deep learning; convolutional neural network; image processing; diabetic retinopathy
Article,"Priya, Raju Pugal; Sivarani, Thankanmony Saradadevi; Saravanan, Athimoolam Gnana",Deep long and short term memory based Red Fox optimization algorithm for diabetic retinopathy detection and classification,international journal for numerical methods in biomedical engineering,2022,Not found,"Because of retina abnormalities of diabetic patients, the most common vision-threatening disease is diabetic retinopathy (DR). The DR diagnosis and prevention are challenging tasks as they may lead to vision loss. According to the literature analysis, the shortcomings in existing studies, such as failed to reduce the feature dimension, higher execution time, and higher computational cost, unable to tune the hyper-parameters, such as a number of hidden layers and learning rate, more computational complexities, higher cost, and so forth, during DR classification. To tackle these problems, we proposed a deep long- and short-term memory (LSTM) in a neural network with Red Fox optimization (deep LSTM-RFO) algorithm for DR classification. The four major components involved in the proposed methods are image preprocessing, segmentation, feature extraction, and classification. At first, an adaptive histogram equalization and histogram equalization model performs the fundus image preprocessing, thereby neglecting the noise and improving the contrast level of an image. Next, an adaptive watershed segmentation model effectively segments the lesion region based on the optic disc color and size of hemorrhages. At the third stage, we have extracted statistical, intensity, color, and shape features. Finally, the single normal class with three abnormal classes such as mild non-proliferative diabetic retinopathy, moderate NPDR, and severe NPDR are accurately classified using the deep LSTM-RFO algorithm. Experimentally, the MESSIDOR, STARE, and DRIVE datasets are used for both training and validation. MATLAB software performs the implementation process with respect to various evaluation criteria used. However, the proposed method accomplished superior performance, such as 98.45% specificity, 96.78% sensitivity, 97.92% precision, 96.89% recall, and 97.93% F-score results in terms of DR classification than previous methods.",deep lstm in neural network; diabetic retinopathy; feature extraction; red fox optimization algorithm; watershed segmentation model
Article,"Bodapati, Jyostna Devi; Shaik, Nagur Shareef; Naralasetti, Veeranjaneyulu",Composite deep neural network with gated-attention mechanism for diabetic retinopathy severity classification,journal of ambient intelligence and humanized computing,2021,Not found,"Diabetic Retinopathy (DR) is a micro vascular complication caused by long-term diabetes mellitus. Unidentified diabetic retinopathy leads to permanent blindness. Early identification of this disease requires frequent complex diagnostic procedure which is expensive and time consuming. In this article, we propose a composite deep neural network architecture with gated-attention mechanism for automated diagnosis of diabetic retinopathy. The feature descriptors obtained from multiple pre-trained deep Convolutional Neural Networks (CNNs) are used to represent color fundus retinal images. Spatial pooling methods are introduced to get the reduced versions of these representations without loosing much information. The proposed composite DNN learns independently from each of these reduced representations through different channels and contributes to improving the model generalization. In addition, model also includes gated attention blocks which allows the model to emphasize more on lesion portions of the retinal images while reduced attention to the non-lesion regions. Our experiments on APTOS-2019 Kaggle blindness detection challenge reveal that, the proposed approach leads to improved performance when compared to the existing best models. Our empirical studies also reveal that, the proposed approach leads to more generalised predictions with multi-modal representations when compared to those of uni-modal representations. The proposed composite deep neural network model recorded an accuracy of 82.54% (up arrow 2%), and a Kappa score of 79 (up arrow 9points) for diabetic retinopathy severity level prediction.",diabetic retinopathy (dr); pre-trained convolutional neural network; retinal fundus images; spatial pooling; composite deep neural network; multi-modal features; gated-attention; transfer learning
Article,"Hu, Jingbo; Wang, Huan; Wang, Le; Lu, Ye",Graph Adversarial Transfer Learning for Diabetic Retinopathy Classification,ieee access,2022,Not found,"Diabetic retinopathy (DR) is an essential factor that has caused vision loss and even blindness in middle-aged and older adults. A system that can automatically perform DR diagnosis can help ophthalmologists save a lot of tedious work, such as DR grading or lesion detection. At the same time, patients can find their diseases earlier and perform the correct treatment. However, most of the existing methods require many DR annotations to train the model, and the DR data will vary to different degrees due to various shooting tools. The above problems lead to the inefficient use of existing data in the experiment, limiting actual deployment. To alleviate this problem, we propose a novel Graph Adversarial Transfer Learning (GATL) for DR diagnosis in a deep model through transfer learning, including intra-domain alignment and inter-domain alignment. The proposed GATL enjoys several merits. First, our GATL adopts the self-supervised training to save the annotating cost in the target domain thus this domain adaptation method can significantly reduce annotation cost compared to the supervised approaches. Second, we introduce the graph neural network to extract potential features between unknown samples. Third, to enhance the robustness of the model, we use adversarial training to perform both inter-domain and intra-domain alignment to further improve the model's classification accuracy. GATL achieved 94.3%, 97.5%, and 91.1% in accuracy, sensitivity, and specificity in the APTOS dataset and 92.7%, 95.7%, and 89.7% in the EyePACS dataset, respectively. Extensive experimental results on two challenging benchmarks, including APTOS 2019 and EyePACS, demonstrate that the proposed GATL performs favorably against baseline DR classification methods.",diabetic retinopathy classification; graph adversarial network; transfer learning; intradomain; inter-domain
Article,"Mirabedini, Shirin; Kangavari, Mohammadreza; Mohammadzadeh, Javad",Diabetic retinopathy classification via Generative Adversarial Networks,bioscience research,2020,Not found,"Diabetic retinopathy is a disease that affects many people around the world. So an optimal way to diagnose the degree of diabetes on retinal images is essential in the prevention of acute illness and vision loss. But the dataset is imbalanced, then we introduce a new solution for facing to imbalanced data challenge. This study is a new method in medical image classification applying the Kaggle dataset of a hospital in England. This dataset consists of 5 classes that a major class (normal eyes) accounting for about 73% of the total data, and minor classes in a low percentage of the total data. To solve imbalanced data problems, first the number of minor classes is increased via training of designed Generative Adversarial Network (GAN), then classification is done in both proliferative and non - proliferative classes by using the designed deep model. Three general methods have been reviewed, then the problem of degree diagnosis is solved with 89% accuracy via deep model training that improvements have been made about 7% compared to the top Kaggle Challenge participants. Then GANs are distributed in several processors, it results in Run time decreasing about 60%. In the last two decades, three methods of screening for diabetic retinopathy, retinal imaging, and deep models have been used, and deep learning techniques have been more efficient than other methods. The proposed model is optimized by solving the problem of imbalanced data by generating new images via the designed deep generative model.",diabetic retinopathy; medical image classification; deep learning; model distributing; generative adversarial network
Proceedings Paper,"Li, Yihao; Daho, Mostafa El Habib; Conze, Pierre-Henri; Al Hajj, Hassan; Bonnin, Sophie; Ren, Hugang; Manivannan, Niranchana; Magazzeni, Stephanie; Tadayoni, Ramin; Cochener, Beatrice; Lamard, Mathieu; Quellec, Gwenole",Multimodal Information Fusion for Glaucoma and Diabetic Retinopathy Classification,"ophthalmic medical image analysis, omia 2022",2022,Not found,"Multimodal information is frequently available in medical tasks. By combining information from multiple sources, clinicians are able to make more accurate judgments. In recent years, multiple imaging techniques have been used in clinical practice for retinal analysis: 2D fundus photographs, 3D optical coherence tomography (OCT) and 3D OCT angiography, etc. Our paper investigates three multimodal information fusion strategies based on deep learning to solve retinal analysis tasks: early fusion, intermediate fusion, and hierarchical fusion. The commonly used early and intermediate fusion are simple but do not fully exploit the complementary information between modalities. We developed a hierarchical fusion approach that focuses on combining features across multiple dimensions of the network, as well as exploring the correlation between modalities. These approaches were applied to glaucoma and diabetic retinopathy classification, using the public GAMMA dataset (fundus photographs and OCT) and a private dataset of PLEX (R) Elite 9000 (Carl Zeis Meditec Inc.) OCT angiography acquisitions, respectively. Our hierarchical fusion method performed the best in both cases and paved the way for better clinical diagnosis.",glaucoma classification; diabetic retinopathy classification; multimodal information fusion; deep learning; computer-aided diagnosis
Review,"Behera, Ashish",Use of artificial intelligence for management and identification of complications in diabetes,clinical diabetology,2021,Not found,"Artificial intelligence (AI) can play an important role is in early diagnosis of complications, adherence to a healthy lifestyle and medication, real-time monitoring for optimal glycemic status and predictive prognostic model for the diabetic status of a patient. The early recognition and management of the complications (acute as well as chronic) in diabetes predict the quality of life (QoL) of a patient. The promising results of AI in the early diagnosis of diabetic retinopathy have opened the frontiers for management of other complications as well. Although flash glucose monitoring (FGMs) and continuous glucose monitoring(CGMs) are yet to be used in routine clinical practice but these modalities do hold promise in future for management of diabetes. Automated diagnosis of diabetic retinopathy (DR) and cardiovascular risk factor monitoring are now possible based on the large retinal fundus imaging datasets with improved sensitivity and specificity. Smart-phones and smart devices do have the potential to bring the monitoring and early diagnosis of complications of diabetes into the patient's domain with the use of applications on their smart devices which will make future management of diabetes as an e-disease management. AI applications offer greater accuracy, efficiency, ease of use and satisfaction and can complement the management and early identification of complication of diabetes in long run.",artificial intelligence; fuzzy logic; diabetic retinopathy; diabetes monitoring devices; machine learning
Article,"Zhou, Yi; Wang, Boyang; Huang, Lei; Cui, Shanshan; Shao, Ling","A Benchmark for Studying Diabetic Retinopathy: Segmentation, Grading, and Transferability",ieee transactions on medical imaging,2021,Not found,"People with diabetes are at risk of developing an eye disease called diabetic retinopathy (DR). This disease occurs when high blood glucose levels cause damage to blood vessels in the retina. Computer-aided DR diagnosis has become a promising tool for the early detection and severity grading of DR, due to the great success of deep learning. However, most current DR diagnosis systems do not achieve satisfactory performance or interpretability for ophthalmologists, due to the lack of training data with consistent and fine-grained annotations. To address this problem, we construct a large fine-grained annotated DR dataset containing 2,842 images (FGADR). Specifically, this dataset has 1,842 images with pixel-level DR-related lesion annotations, and 1,000 images with image-level labels graded by six board-certified ophthalmologists with intra-rater consistency. The proposed dataset will enable extensive studies on DR diagnosis. Further, we establish three benchmark tasks for evaluation: 1. DR lesion segmentation; 2. DR grading by joint classification and segmentation; 3. Transfer learning for ocular multi-disease identification. Moreover, a novel inductive transfer learning method is introduced for the third task. Extensive experiments using different state-of-the-art methods are conducted on our FGADR dataset, which can serve as baselines for future research. Our dataset will be released in https://csyizhou.github.io/FGADR/.",image segmentation; retinopathy; transfer learning; benchmark testing; diabetes; lesions; task analysis; diabetic retinopathy; lesion segmentation; grading; transfer learning
Article,"Hervella, Alvaro S.; Rouco, Jose; Novo, Jorge; Ortega, Marcos",Multimodal image encoding pre-training for diabetic retinopathy grading,computers in biology and medicine,2022,Not found,"Diabetic retinopathy is an increasingly prevalent eye disorder that can lead to severe vision impairment. The severity grading of the disease using retinal images is key to provide an adequate treatment. However, in order to learn the diverse patterns and complex relations that are required for the grading, deep neural networks require very large annotated datasets that are not always available. This has been typically addressed by reusing networks that were pre-trained for natural image classification, hence relying on additional annotated data from a different domain. In contrast, we propose a novel pre-training approach that takes advantage of unlabeled multimodal visual data commonly available in ophthalmology.The use of multimodal visual data for pre-training purposes has been previously explored by training a network in the prediction of one image modality from another. However, that approach does not ensure a broad understanding of the retinal images, given that the network may exclusively focus on the similarities between modalities while ignoring the differences. Thus, we propose a novel self-supervised pre-training that explicitly teaches the networks to learn the common characteristics between modalities as well as the characteristics that are exclusive to the input modality. This provides a complete comprehension of the input domain and facilitates the training of downstream tasks that require a broad understanding of the retinal images, such as the grading of diabetic retinopathy.To validate and analyze the proposed approach, we performed an exhaustive experimentation on different public datasets. The transfer learning performance for the grading of diabetic retinopathy is evaluated under different settings while also comparing against previous state-of-the-art pre-training approaches. Additionally, a comparison against relevant state-of-the-art works for the detection and grading of diabetic retinopathy is also provided. The results show a satisfactory performance of the proposed approach, which outperforms previous pre-training alternatives in the grading of diabetic retinopathy.",diabetic retinopathy; computer-aided diagnosis; medical imaging; self-supervised learning; deep learning; eye fundus
Article,"Abbas, Qaisar; Ibrahim, Mostafa E. A.; Baig, Abdul Rauf",Transfer Learning-based Computer-aided Diagnosis System for Predicting Grades of Diabetic Retinopathy,cmc-computers materials & continua,2022,Not found,"Diabetic retinopathy (DR) diagnosis through digital fundus images requires clinical experts to recognize the presence and importance of many intricate features. This task is very difficult for ophthalmologists and time-consuming. Therefore, many computer-aided diagnosis (CAD) systems were developed to automate this screening process ofDR. In this paper, aCAD-DR system is proposed based on preprocessing and a pre-train transfer learning-based convolutional neural network (PCNN) to recognize the five stages of DR through retinal fundus images. To develop this CAD-DR system, a preprocessing step is performed in a perceptual-oriented color space to enhance the DR-related lesions and then a standard pre-train PCNN model is improved to get high classification results. The architecture of the PCNN model is based on three main phases. Firstly, the training process of the proposed PCNN is accomplished by using the expected gradient length (EGL) to decrease the image labeling efforts during the training of the CNN model. Secondly, themost informative patches and images were automatically selected using a few pieces of training labeled samples. Thirdly, the PCNN method generated useful masks for prognostication and identified regions of interest. Fourthly, the DR-related lesions involved in the classification task such as micro-aneurysms, hemorrhages, and exudates were detected and then used for recognition of DR. The PCNN model is pre-trained using a high-end graphical processor unit (GPU) on the publicly available Kaggle benchmark. The obtained results demonstrate that the CAD-DR system outperforms compared to other state-of-the-art in terms of sensitivity (SE), specificity (SP), and accuracy (ACC). On the test set of 30,000 images, the CAD-DR system achieved an average SE of 93.20%, SP of 96.10%, and ACC of 98%. This result indicates that the proposed CAD-DR system is appropriate for the screening of the severity-level of DR.",diabetic retinopathy; retinal fundus images; computer-aided diagnosis system; deep learning; transfer learning; convolutional neural network
Article,"Ashraf, Muhammad Nadeem; Hussain, Muhammad; Habib, Zulfiqar",Deep Red Lesion Classification for Early Screening of Diabetic Retinopathy,mathematics,2022,Not found,"Diabetic retinopathy (DR) is an asymptotic and vision-threatening complication among working-age adults. To prevent blindness, a deep convolutional neural network (CNN) based diagnosis can help to classify less-discriminative and small-sized red lesions in early screening of DR patients. However, training deep models with minimal data is a challenging task. Fine-tuning through transfer learning is a useful alternative, but performance degradation, overfitting, and domain adaptation issues further demand architectural amendments to effectively train deep models. Various pre-trained CNNs are fine-tuned on an augmented set of image patches. The best-performing ResNet50 model is modified by introducing reinforced skip connections, a global max-pooling layer, and the sum-of-squared-error loss function. The performance of the modified model (DR-ResNet50) on five public datasets is found to be better than state-of-the-art methods in terms of well-known metrics. The highest scores (0.9851, 0.991, 0.991, 0.991, 0.991, 0.9939, 0.0029, 0.9879, and 0.9879) for sensitivity, specificity, AUC, accuracy, precision, F1-score, false-positive rate, Matthews's correlation coefficient, and kappa coefficient are obtained within a 95% confidence interval for unseen test instances from e-Ophtha_MA. This high sensitivity and low false-positive rate demonstrate the worth of a proposed framework. It is suitable for early screening due to its performance, simplicity, and robustness.",computer-aided diagnosis; diabetic retinopathy; red lesions; convolutional neural networks; deep residual networks; skip connections
Article,"Abdelmaksoud, Eman; El-Sappagh, Shaker; Barakat, Sherif; Abuhmed, Tamer; Elmogy, Mohammed",Automatic Diabetic Retinopathy Grading System Based on Detecting Multiple Retinal Lesions,ieee access,2021,Not found,"Multi-label classification (MLC) is considered an essential research subject in the computer vision field, principally in medical image analysis. For this merit, we derive benefits from MLC to diagnose multiple grades of diabetic retinopathy (DR) from various colored fundus images, especially from multi-label (ML) datasets. Therefore, ophthalmologists can detect early signs of DR as well as various grades to initiate appropriate treatment and avoid DR complications. In this paper, we propose a comprehensive ML computer-aided diagnosis (CAD) system based on deep learning technique. The proposed system's main contribution is to detect and analyze various pathological changes accompanying DR development in the retina without injecting the patient with dye or making expensive scans. The proposed ML-CAD system visualizes the different pathological changes and diagnoses the DR grades for the ophthalmologists. First, we eliminate noise, enhance quality, and standardize the sizes of the retinal images. Second, we differentiated between the healthy and DR cases by calculating the gray level run length matrix average in four different directions. The system automatically extracts the four changes: exudates, microaneurysms, hemorrhages, and blood vessels by utilizing a deep learning technique (U-Net). Next, we extract six features, which are the gray level co-occurrence matrix, areas of the four segmenting pathology variations, and the bifurcation points count of the blood vessels. Finally, the resulting features were afforded to an ML support vector machine (SVM) based on a classifier chain to differentiate the various DR grades. We utilized eight benchmark datasets (four of them are considered ML) and six different performance evaluation metrics to evaluate the proposed system's performance. It achieved 95.1%, 91.9%, 86.1%, 86.8%, 84.7%, 86.2% for accuracy, area under the curve, sensitivity, specificity, positive predictive value, and dice similarity coefficient, respectively. The experiments show encouraging results as compared with other systems.",multi-label computer-aided diagnosis (ml-cad); multi-label classification (mlc); deep learning (dl); u-net; diabetic retinopathy (dr)
Proceedings Paper,"Kheradfallah, Hoda; Balaji, Janarthanam Jothi; Jayakumar, Varadharajan; Rasheed, Mohammed Abdul; Lakshminarayanan, Vasudevan",Annotation and Segmentation of Diabetic Retinopathy Lesions: An Explainable AI Application,medical imaging 2022: computer-aided diagnosis,2022,Not found,"One of the leading causes of irreversible vision loss is Diabetic Retinopathy (DR). The International Clinical Diabetic Retinopathy scale (ICDRS) provides grading criteria for DR. Deep Convolutional Neural Networks (DCNNs) have high performance in DR grading in terms of classification evaluation metrics; however, these metrics are not sufficient for evaluation. The eXplainable Artificial Intelligence (XAI) methodology provides insight into the decisions made by networks by producing sparce, generic heat maps highlighting the most critical DR features. XAI also could not satisfy clinical criteria due to the lack of explanation on the number and types of lesions. Hence, we propose a computational tool box that provides lesion-based explanation according to grading system criteria for determining severity levels. According to ICDRS, DR has 10 major lesions and 4 severity levels. Experienced clinicians annotated 143 DR fundus images and we developed a toolbox containing 9 lesion-specified segmentation networks. Networks should detect lesions with high annotation resolution and then compute DR severity grade according to ICDRS. The network that was employed in this study is the optimized version of Holistically Nested Edge Detection Network (HEDNet). Using this model, the lesions such as hard exudates (Ex), cotton wool spots (CWS), microaneurysms (MA), intraretinal haemorrhages (IHE) and vitreous preretinal haemorrhages (VPHE) were properly detected but the prediction of lesions such as venous beading (VB), neovascularization (NV), intraretinal microvascular abnormalities (IRMA) and fibrous proliferation (FP) had low specificity. Consequently, this will affect the value of grading which uses the segmented masks of all contributing lesions.",diabetic retinopathy; explainable artificial intelligence; icdrs; fundus images; dcnns; retina; ophthalmology
Proceedings Paper,"Zeghlache, Rachid; Conze, Pierre-Henri; Daho, Mostafa El Habib; Tadayoni, Ramin; Massin, Pascal; Cochener, Beatrice; Quellec, Gwenole; Lamard, Mathieu",Detection of Diabetic Retinopathy Using Longitudinal,"ophthalmic medical image analysis, omia 2022",2022,Not found,"Longitudinal imaging is able to capture both static anatomical structures and dynamic changes in disease progression towards earlier and better patient-specific pathology management. However, conventional approaches for detecting diabetic retinopathy (DR) rarely take advantage of longitudinal information to improve DR analysis. In this work, we investigate the benefit of exploiting self-supervised learning with a longitudinal nature for DR diagnosis purposes. We compare different longitudinal self-supervised learning (LSSL) methods to model the disease progression from longitudinal retinal color fundus photographs (CFP) to detect early DR severity changes using a pair of consecutive exams. The experiments were conducted on a longitudinal DR screening dataset with or without those trained encoders (LSSL) acting as a longitudinal pretext task. Results achieve an AUC of 0.875 for the baseline (model trained from scratch) and an AUC of 0.96 (95% CI: 0.9593 0.9655 DeLong test) with a p-value <2.2e-16 on early fusion using a simple ResNet alike architecture with frozen LSSL weights, suggesting that the LSSL latent space enables to encode the dynamic of DR progression.",diabetic retinopathy; deep learning; self-supervised learning; longitudinal analysis; computer-aided diagnosis
Proceedings Paper,"Ahmad, Maroof; Kasukurthi, Nikhil; Pande, Harshit",DEEP LEARNING FOR WEAK SUPERVISION OF DIABETIC RETINOPATHY ABNORMALITIES,2019 ieee 16th international symposium on biomedical imaging (isbi 2019),2019,Not found,"Deep learning-based grading of the fundus images of the retina is an active area of research. Various existing studies use different deep learning architectures on different datasets. Results of some of the studies could not be replicated in other studies. Thus a benchmarking study across multiple architectures spanning both classification and localization is needed. We present a comparative study of different state-of-the-art architectures trained on a proprietary dataset and tested on the publicly available Messidor-2 dataset. Although evidence is of utmost importance in AI-based medical diagnosis, most studies limit themselves to the classification performance and do not report the quantification of the performance of the abnormalities localization. To alleviate this, using class activation maps, we also report a comparison of localization scores for different architectures. For classification, we found that as the number of parameters increase, the models perform better, with NASNet yielding highest accuracy and average precision, recall, and F1-scores of around 95%. For localization, VGG19 outperformed all the models with a mean Intersection over Minimum of 0.45. We also found that there is a trade-off between classification performance and localization performance. As the models get deeper, their receptive field increases, causing them to perform well on classification but under-perform on the localization of fine-grained abnormalities.",diabetic retinopathy; messidor-2; abnormality localization; class activation maps
Article,"Zhang, Guanghua; Sun, Bin; Zhang, Zhaoxia; Pan, Jing; Yang, Weihua; Liu, Yunfang",Multi-Model Domain Adaptation for Diabetic Retinopathy Classification,frontiers in physiology,2022,Not found,"Diabetic retinopathy (DR) is one of the most threatening complications in diabetic patients, leading to permanent blindness without timely treatment. However, DR screening is not only a time-consuming task that requires experienced ophthalmologists but also easy to produce misdiagnosis. In recent years, deep learning techniques based on convolutional neural networks have attracted increasing research attention in medical image analysis, especially for DR diagnosis. However, dataset labeling is expensive work and it is necessary for existing deep-learning-based DR detection models. For this study, a novel domain adaptation method (multi-model domain adaptation) is developed for unsupervised DR classification in unlabeled retinal images. At the same time, it only exploits discriminative information from multiple source models without access to any data. In detail, we integrate a weight mechanism into the multi-model-based domain adaptation by measuring the importance of each source domain in a novel way, and a weighted pseudo-labeling strategy is attached to the source feature extractors for training the target DR classification model. Extensive experiments are performed on four source datasets (DDR, IDRiD, Messidor, and Messidor-2) to a target domain APTOS 2019, showing that MMDA produces competitive performance for present state-of-the-art methods for DR classification. As a novel DR detection approach, this article presents a new domain adaptation solution for medical image analysis when the source data is unavailable.",diabetic retinopathy classification; multi-model; domain adaptation; convolutional neural network; deep learning
Article; Proceedings Paper,"Chen, Ping-Nan; Lee, Chia-Chiang; Liang, Chang-Min; Pao, Shu-, I; Huang, Ke-Hao; Lin, Ke-Feng",General deep learning model for detecting diabetic retinopathy,bmc bioinformatics,2021,Not found,"Background Doctors can detect symptoms of diabetic retinopathy (DR) early by using retinal ophthalmoscopy, and they can improve diagnostic efficiency with the assistance of deep learning to select treatments and support personnel workflow. Conventionally, most deep learning methods for DR diagnosis categorize retinal ophthalmoscopy images into training and validation data sets according to the 80/20 rule, and they use the synthetic minority oversampling technique (SMOTE) in data processing (e.g., rotating, scaling, and translating training images) to increase the number of training samples. Oversampling training may lead to overfitting of the training model. Therefore, untrained or unverified images can yield erroneous predictions. Although the accuracy of prediction results is 90%-99%, this overfitting of training data may distort training module variables. Results This study uses a 2-stage training method to solve the overfitting problem. In the training phase, to build the model, the Learning module 1 used to identify the DR and no-DR. The Learning module 2 on SMOTE synthetic datasets to identify the mild-NPDR, moderate NPDR, severe NPDR and proliferative DR classification. These two modules also used early stopping and data dividing methods to reduce overfitting by oversampling. In the test phase, we use the DIARETDB0, DIARETDB1, eOphtha, MESSIDOR, and DRIVE datasets to evaluate the performance of the training network. The prediction accuracy achieved to 85.38%, 84.27%, 85.75%, 86.73%, and 92.5%. Conclusions Based on the experiment, a general deep learning model for detecting DR was developed, and it could be used with all DR databases. We provided a simple method of addressing the imbalance of DR databases, and this method can be used with other medical images.",smote; overfitting; decision tree; nasnet-large; transfer learning
Article,"Ravala, Lavanya; Rajini, G. K.",Automatic Diagnosis of Diabetic Retinopathy from Retinal Abnormalities: Improved Jaya-Based Feature Selection and Recurrent Neural Network,computer journal,2022,Not found,"Accurate diagnosis of lesions bears the highest significance in the early detection of diabetic retinopathy (DR). In this paper, the combination of intelligent methods is developed for segmenting the abnormalities like 'hard exudates, hemorrhages, microaneurysm and soft exudates' to detect the DR. The proposed model involves seven main steps: (a) image pre-processing, (b) optic disk removal (c) blood vessel removal, (d) segmentation of abnormalities, (e) feature extraction, (f) optimal feature selection and (f) classification. The pre-processing of the input retinal fundus image is performed by two operations like contrast enhancement by histogram equalization and filtering by average filtering. For the segmentation of abnormalities, the same Circular Hough Transform followed by Top-hat filtering and Gabor filtering is used. Next, the entropy-scale-invariant feature transform (SIFT), grey level co-occurrence matrices and color morphological features are extracted in feature extraction. The optimally selected features are subjected to the classification part, which uses a modified deep learning algorithm called optimized recurrent neural network (RNN). As the main novelty, the optimal feature selection and optimized RNN depends on an improved meta-heuristic algorithm called fitness oriented improved Jaya algorithm. Hence, the beneficial part of the optimization algorithm improves the feature selection and classification.",diagnosis of diabetic retinopathy; novel blood vessel segmentation algorithm; feature extraction; optimal feature selection; recurrent neural network; fitness oriented improved jaya algorithm
Article,"Sandhu, Harpal Singh; Eltanboly, Ahmed; Shalaby, Ahmed; Keynton, Robert S.; Schaal, Schlomit; El-Baz, Ayman",Automated Diagnosis and Grading of Diabetic Retinopathy Using Optical Coherence Tomography,investigative ophthalmology & visual science,2018,Not found,"PURPOSE. We determine the feasibility and accuracy of a computer-assisted diagnostic (CAD) system to diagnose and grade nonproliferative diabetic retinopathy (NPDR) from optical coherence tomography (OCT) images. METHODS. A cross-sectional, single-center study was done of type II diabetics who presented for routine screening and/or monitoring exams. Inclusion criteria were age 18 or older, diagnosis of diabetes mellitus type II, and clear media allowing for OCT imaging. Exclusion criteria were inability to image the macula, posterior staphylomas, proliferative diabetic retinopathy, and concurrent retinovascular disease. All patients underwent a full dilated eye exam and spectral-domain OCT of a 6 3 6 mm area of the macula in both eyes. These images then were analyzed by a novel CAD system that segments the retina into 12 layers; quantifies the reflectivity, curvature, and thickness of each layer; and ultimately uses this information to train a neural network that classifies images as either normal or having NPDR, and then further grades the level of retinopathy. A first dataset was tested by `` leave-one-subject-out'' (LOSO) methods and by 2-and 4-fold cross-validation. The system then was tested on a second, independent dataset. RESULTS. Using LOSO experiments on a dataset of images from 80 patients, the proposed CAD system distinguished normal from NPDR subjects with 93.8% accuracy (sensitivity = 92.5%, specificity = 95%) and achieved 97.4% correct classification between subclinical and mild/ moderate DR. When tested on an independent dataset of 40 patients, the proposed system distinguished between normal and NPDR subjects with 92.5% accuracy and between subclinical and mild/moderate NPDR with 95% accuracy. CONCLUSIONS. A CAD system for automated diagnosis of NPDR based on macular OCT images from type II diabetics is feasible, reliable, and accurate.",diabetic retinopathy; machine learning; oct; deep fusion classification networks; neural networks; npdr; dfcn; sncae
Proceedings Paper,"Alcala-Rmz, Vanessa; Maeda-Gutierrez, Valeria; Zanella-Calzada, Laura A.; Valladares-Salgado, Adan; Celaya-Padilla, Jose M.; Galvan-Tejada, Carlos E.",Convolutional Neural Network for Classification of Diabetic Retinopathy Grade,"advances in soft computing, micai 2020, pt i",2020,Not found,"Diabetic Retinopathy (DR) represents an important group of lesions found in the retina of patients who suffer from diabetes mellitus, affecting around one out of three patients and presenting a global prevalence of approximately 34.6%. Besides, DR is characterized as being the leading cause of vision loss in adults. Its diagnosis consists on a series of screening tests to obtain digital photographs of the retina, to find the grade of the evolution of the disease, which can be classified into four grades. The early detection and diagnosis of DR are fundamental to prevent its evolution. In this paper it is proposed the implementation of the Convolutional Neural Network (CNN), VGGNet-like, which is a model focused in the classification of images based on object recognition and detection. The main objective is the classification of a set of images containing the four different grades in the evolution of DR. The datasets used are the Indian Diabetic Retinopathy Image Dataset and the Diabetic Retinopathy Detection. The performance of the CNN proposed is evaluated through a statistical analysis based on accuracy, the loss function and area under the curve (AUC). The results present statistically significant values, obtaining 0.81 of accuracy, 0.49 of loss function and, 0.71 of micro-average and 0.72 of macro-average in the AUC. According to the results, it is possible to conclude that the CNN implemented can classify DR into its different grades in patients with presence of diabetes mellitus, obtaining a preliminary Computer-Aided Diagnosis tool that could be supportive for the diagnosis of the evolution of DR.",diabetic retinopathy; computer-aided diagnosis; vggnet-like
Proceedings Paper,"Mohamed, Eman; Abd Elmohsen, Mai; Basha, Tamer",Improved Automatic Grading of Diabetic Retinopathy Using Deep Learning and Principal Component Analysis,2021 43rd annual international conference of the ieee engineering in medicine & biology society (embc),2021,Not found,"Diabetic retinopathy (DR) is one of the most common chronic diseases around the world. Early screening and diagnosis of DR patients through retinal fundus is always preferred. However, image screening and diagnosis is a highly time-consuming task for clinicians. So, there is a high need for automatic diagnosis. The objective of our study is to develop and validate a new automated deep learning-based approach for diabetic retinopathy multi-class detection and classification. In this study we evaluate the contribution of the DR features in each color channel then we pick the most significant channels and calculate their principal components (PCA) which are then fed to the deep learning model, and the grading decision is decided based on a majority voting scheme applied to the out of the deep learning model. The developed models were trained on a publicly available dataset with around 80K color fundus images and were tested on our local dataset with around 100 images. Our results show a significant improvement in DR multi-class classification with 85% accuracy, 89% sensitivity, and 96% specificity.",not found
Article,"Alqudah, Ali Mohammad; Alquran, Hiam; Abu-Qasmieh, Isam; Al-Badarneh, Alaa",Employing Image Processing Techniques and Artificial Intelligence for Automated Eye Diagnosis Using Digital Eye Fundus Images,journal of biomimetics biomaterials and biomedical engineering,2018,Not found,"Blindness usually comes from two main causes, glaucoma and diabetes. Robust mass screening is performed for diagnosing, such as screening that requires a cost-effective method for glaucoma and diabetic retinopathy and integrates well with digital medical imaging, image processing, and administrative processes. For addressing all these issues, we propose a novel low-cost automated glaucoma and diabetic retinopathy diagnosis system, based on features extraction from digital eye fundus images. This paper proposes a diagnosis system for automated identification of healthy, glaucoma, and diabetic retinopathy. Using a combination of local binary pattern features, Gabor filter features, statistical features, and color features which are then fed to an artificial neural network and support vector machine classifiers. In this work, the classifier identifies healthy, glaucoma, and diabetic retinopathy images with an accuracy of 91.1%,92.9%, 92.9%, and 92.3% and sensitivity of 91.06%, 92.6%, 92.66%, and 91.73% and specificity of 89.83%, 91.26%, 91.96%, and 89.16% for ANN, and an accuracy of 90.0%,92.94%, 95.43%, and 97.92% and sensitivity of 89.34%, 93.26%, 95.72%, and 97.93% and specificity of 95.13%, 96.68%, 97.88%, and 99.05% for SVM, based on 5, 10, 15, and 31 number of selected features. The proposed system can detect glaucoma, diabetic retinopathy and normal cases with high accuracy and sensitivity using selected features, the performance of the system is high due to using of a huge fundus database.",eye fundus; diagnosis; glaucoma; diabetic retinopathy; classification
Article,"Mohammedhasan, Mali; Uguz, Harun",A New Early Stage Diabetic Retinopathy Diagnosis Model Using Deep Convolutional Neural Networks and Principal Component Analysis,traitement du signal,2020,Not found,"Diabetic retinopathy (DR) is a disease of the retina, which leads over time to vision problems such retinal detachment, vitreous hemorrhage, glaucoma, and in worse cases leads to blindness, which can initially be controlled by periodic DR-screening. Early diagnosis will lead to greater control of the disease, whereas performing retinal examinations on all diabetic patients is an unattainable need, as diabetes is a chronic disease and its global prevalence has been steadily increasing over the past few decades. According to recent World Health Organization statistics, about 422 million people worldwide have diabetes, the majority living in low-and middle-income countries. This paper proposes a new strategy that brings the strength of convolutional neural networks (CNNs) to the diagnosis of DR. Coupled with using principal component analysis (PCA) that performs dimension reduction to improve the diagnostic accuracy, the proposed model exploiting edge-preserving guided image filtering (E-GIF) that performs as a contrast enhancement mechanism, and in addition to smoothing low gradient areas, it also accentuates strong edges. Diabetic retinopathy causes progressive damage to the blood vessels in the retina to the extent that it leaves traces and lesions in the tissues of the retina. These lesions appear in the form of edges and when processing retinal images, we seek to accentuate these edges to enable better diagnosis of diabetic retinopathy symptoms. A new CNN architecture with residual connections is used, which performs very well in diagnosing DR. The proposed model is named with RUnet-PCA: Residual U-net Deep CNN with Principal Component Analysis. The well-known AlexNet, VggNet-s, VggNet-16, VggNet-19, GoogleNet, and ResNet models were adopted for comparison with the proposed model. Publicly available Kaggle dataset was employed for training exploring the DR diagnosis accuracy. Experimental results show that the proposed RUnet-PCA model achieved a diagnosis accuracy of 98.44% and it was extremely robust and promising in comparison to other diagnosis methods.",diabetic retinopathy; deep learning; convolutional neural network; principal component analysis; edge preserving guided image filtering; u-network; data augmentation
Article,"Toledo-Cortes, Santiago; Useche, Diego H.; Muller, Henning; Gonzalez, Fabio A.",Grading diabetic retinopathy and prostate cancer diagnostic images with deep quantum ordinal regression,computers in biology and medicine,2022,Not found,"Although for many diseases there is a progressive diagnosis scale, automatic analysis of grade-based medical images is quite often addressed as a binary classification problem, missing the finer distinction and intrinsic relation between the different possible stages or grades. Ordinal regression (or classification) considers the order of the values of the categorical labels and thus takes into account the order of grading scales used to assess the severity of different medical conditions. This paper presents a quantum-inspired deep probabilistic learning ordinal regression model for medical image diagnosis that takes advantage of the representational power of deep learning and the intrinsic ordinal information of disease stages. The method is evaluated on two different medical image analysis tasks: prostate cancer diagnosis and diabetic retinopathy grade estimation on eye fundus images. The experimental results show that the proposed method not only improves the diagnosis performance on the two tasks but also the interpretability of the results by quantifying the uncertainty of the predictions in comparison to conventional deep classification and regression architectures. The code and datasets are available at https://github.com/stoledoc/DQOR.",deep probabilistic learning; density matrices; diabetic retinopathy; eye fundus images; histopathology images; ordinal regression; prostate cancer; quantum measurement; uncertainty quantification
Article,"Ursin, Frank; Timmermann, Cristian; Orzechowski, Marcin; Steger, Florian",Diagnosing Diabetic Retinopathy With Artificial Intelligence: What Information Should Be Included to Ensure Ethical Informed Consent?,frontiers in medicine,2021,Not found,"Purpose: The method of diagnosing diabetic retinopathy (DR) through artificial intelligence (AI)-based systems has been commercially available since 2018. This introduces new ethical challenges with regard to obtaining informed consent from patients. The purpose of this work is to develop a checklist of items to be disclosed when diagnosing DR with AI systems in a primary care setting. Methods: Two systematic literature searches were conducted in PubMed and Web of Science databases: a narrow search focusing on DR and a broad search on general issues of AI-based diagnosis. An ethics content analysis was conducted inductively to extract two features of included publications: (1) novel information content for AI-aided diagnosis and (2) the ethical justification for its disclosure. Results: The narrow search yielded n = 537 records of which n = 4 met the inclusion criteria. The information process was scarcely addressed for primary care setting. The broad search yielded n = 60 records of which n = 11 were included. In total, eight novel elements were identified to be included in the information process for ethical reasons, all of which stem from the technical specifics of medical AI. Conclusions: Implications for the general practitioner are two-fold: First, doctors need to be better informed about the ethical implications of novel technologies and must understand them to properly inform patients. Second, patient's overconfidence or fears can be countered by communicating the risks, limitations, and potential benefits of diagnostic AI systems. If patients accept and are aware of the limitations of AI-aided diagnosis, they increase their chances of being diagnosed and treated in time.",informed consent; information process; machine learning; diabetic retinopathy; ethics
Article,"Li, Yu; Zhu, Meilong; Sun, Guangmin; Chen, Jiayang; Zhu, Xiaorong; Yang, Jinkui",Weakly supervised training for eye fundus lesion segmentation in patients with diabetic retinopathy,mathematical biosciences and engineering,2022,Not found,"Objective: Diabetic retinopathy is the leading cause of vision loss in working-age adults. Early screening and diagnosis can help to facilitate subsequent treatment and prevent vision loss. Deep learning has been applied in various fields of medical identification. However, current deep learning-based lesion segmentation techniques rely on a large amount of pixel-level labeled ground truth data, which limits their performance and application. In this work, we present a weakly supervised deep learning framework for eye fundus lesion segmentation in patients with diabetic retinopathy. Methods: First, an efficient segmentation algorithm based on grayscale and morphological features is proposed for rapid coarse segmentation of lesions. Then, a deep learning model named Residual-Attention Unet (RAUNet) is proposed for eye fundus lesion segmentation. Finally, a data sample of fundus images with labeled lesions and unlabeled images with coarse segmentation results is jointly used to train RAUNet to broaden the diversity of lesion samples and increase the robustness of the segmentation model. Results: A dataset containing 582 fundus images with labels verified by doctors, including hemorrhage (HE), microaneurysm (MA), hard exudate (EX) and soft exudate (SE), and 903 images without labels was used to evaluate the model. In ablation test, the proposed RAUNet achieved the highest intersection over union (IOU) on the labeled dataset, and the proposed attention and residual modules both improved the IOU of the UNet benchmark. Using both the images labeled by doctors and the proposed coarse segmentation method, the weakly supervised framework based on RAUNet architecture significantly improved the mean segmentation accuracy by over 7% on the lesions. Significance: This study demonstrates that combining unlabeled medical images with coarse segmentation results can effectively improve the robustness of the lesion segmentation model and proposes a practical framework for improving the performance of medical image segmentation given limited labeled data samples.",diabetic retinopathy; deep learning; fundus image; lesion segmentation; weak supervision
Article,"Zhang, Wei; Zhong, Jie; Yang, Shijun; Gao, Zhentao; Hu, Junjie; Chen, Yuanyuan; Yi, Zhang",Automated identification and grading system of diabetic retinopathy using deep neural networks,knowledge-based systems,2019,Not found,"Diabetic retinopathy (DR) is a major cause of human vision loss worldwide. Slowing down the progress of the disease requires early screening. However, the clinical diagnosis of DR presents a considerable challenge in low-resource settings where few ophthalmologists are available to care for all patients with diabetes. In this study, an automated DR identification and grading system called DeepDR is proposed. DeepDR directly detects the presence and severity of DR from fundus images via transfer learning and ensemble learning. It comprises a set of state-of-the-art neural networks based on combinations of popular convolutional neural networks and customised standard deep neural networks. The DeepDR system is developed by constructing a high-quality dataset of DR medical images and then labelled by clinical ophthalmologists. We further explore the relationship between the number of ideal component classifiers and the number of class labels, as well as the effects of different combinations of component classifiers on the best integration performance to construct an optimal model. We evaluate the models on the basis of validity and reliability using nine metrics. Results show that the identification model performs best with a sensitivity of 97.5%, a specificity of 97.7% and an area under the curve of 97.7%. Meanwhile, the grading model achieves a sensitivity of 98.1% and a specificity of 98.9%. On the basis of the methods above, DeepDR can detect DR satisfactorily. Experiment results indicate the importance and effectiveness of the ideal number and combinations of component classifiers in relation to model performance. DeepDR provides reproducible and consistent detection results with high sensitivity and specificity instantaneously. Hence, this work provides ophthalmologists with insights into the diagnostic process. (C) 2019 Elsevier B.V. All rights reserved.",deep learning; diabetic retinopathy; ensemble learning; fundus images; image classification; transfer learning
Article,"Jadhav, Ambaji S.; Patil, Pushpa B.; Biradar, Sunil",Optimal feature selection-based diabetic retinopathy detection using improved rider optimization algorithm enabled with deep learning,evolutionary intelligence,2021,Not found,"This proposal tempts to develop automated DR detection by analyzing the retinal abnormalities like hard exudates, haemorrhages, Microaneurysm, and soft exudates. The main processing phases of the developed DR detection model is Pre-processing, Optic Disk removal, Blood vessel removal, Segmentation of abnormalities, Feature extraction, Optimal feature selection, and Classification. At first, the pre-processing of the input retinal image is done by Contrast Limited Adaptive Histogram Equalization. The next phase performs the optic disc removal, which is carried out by open-close watershed transformation. Further, the Grey Level thresholding is done for segmenting the blood vessels and its removal. Once the optic disk and blood vessels are removed, segmentation of abnormalities is done by Top hat transformation and Gabor filtering. Further, the feature extraction phase is started, which tends to extract four sets of features like Local Binary Pattern, Texture Energy Measurement, Shanon's and Kapur's entropy. Since the length of the feature vector seems to be long, the feature selection process is done, which selects the unique features with less correlation. Moreover, the Deep Belief Network (DBN)-based classification algorithm performs the categorization of images into four classes normal, earlier, moderate, or severe stages. The optimal feature selection is done by the improved meta-heuristic algorithm called Modified Gear and Steering-based Rider Optimization Algorithm (MGS-ROA), and the same algorithm updates the weight in DBN. Finally, the effectual performance and comparative analysis prove the stable and reliable performance of the proposed model over existing models. The performance of the proposed model is compared with the existing classifiers, such as, NN, KNN, SVM, DBN and the conventional Heuristic-Based DBNs, such as PSO-DBN, GWO-DBN, WOA-DBN, and ROA-DBN for the evaluation metrics, accuracy, sensitivity, specificity, precision, FPR, FNR, NPV, FDR, F1 score, and MC. From the results, it is exposed that the accuracy of the proposed MGS-ROA-DBN is 30.1% higher than NN, 32.2% higher than KNN, and 17.1% higher than SVM and DBN. Similarly, the accuracy of the developed MGS-ROA-DBN is 13.8% superior to PSO, 5.1% superior to GWO, 10.8% superior to WOA, and 2.5% superior to ROA.",diabetic retinopathy diagnosis; retinal abnormalities; optimal feature selection; deep belief network; modified gear and steering-based rider optimization algorithm
Article,"Erciyas, Abdussamed; Barisci, Necaattin",An Effective Method for Detecting and Classifying Diabetic Retinopathy Lesions Based on Deep Learning,computational and mathematical methods in medicine,2021,Not found,"Diabetic retinopathy occurs as a result of the harmful effects of diabetes on the eyes. Diabetic retinopathy is also a disease that should be diagnosed early. If not treated early, vision loss may occur. It is estimated that one third of more than half a million diabetic patients will have diabetic retinopathy by the 22nd century. Many effective methods have been proposed for disease detection with deep learning. In this study, unlike other studies, a deep learning-based method has been proposed in which diabetic retinopathy lesions are detected automatically and independently of datasets, and the detected lesions are classified. In the first stage of the proposed method, a data pool is created by collecting diabetic retinopathy data from different datasets. With Faster RCNN, lesions are detected, and the region of interests are marked. The images obtained in the second stage are classified using the transfer learning and attention mechanism. The method tested in Kaggle and MESSIDOR datasets reached 99.1% and 100% ACC and 99.9% and 100% AUC, respectively. When the obtained results are compared with other results in the literature, it is seen that more successful results are obtained.",computer-aided diagnosis; retinal images; optic disk; classification; segmentation; algorithms; networks; dataset
Review,"Salamat, Nadeem; Missen, Malik M. Saad; Rashid, Aqsa",Diabetic retinopathy techniques in retinal images: A review,artificial intelligence in medicine,2019,Not found,"The diabetic retinopathy is the main reason of vision loss in people. Medical experts recognize some clinical, geometrical and haemodynamic features of diabetic retinopathy. These features include the blood vessel area, exudates, microaneurysm, hemorrhages and neovascularization, etc. In Computer Aided Diagnosis (CAD) systems, these features are detected in fundus images using computer vision techniques. In this paper, we review the methods of low, middle and high level vision for automatic detection and classification of diabetic retinopathy. We give a detailed review of 79 algorithms for detecting different features of diabetic retinopathy during the last eight years.",computer aided diagnosis; optic disc; blood vessels; exudates; diabetic retinopathy screening
Article,"Tehrani, Amirali Amini; Nickfarjam, Ali Mohammad; Ebrahimpour-komleh, Hossein; Aghadoost, Dawood",Multi-input 2-dimensional deep belief network: diabetic retinopathy grading as case study,multimedia tools and applications,2021,Not found,"The most important action in treating diabetic retinopathy is early diagnosis and its progression degree. This paper presents a two-dimensional Deep Belief Network based on Mixed-restricted Boltzmann Machine capable of receiving multiple two-dimensional inputs. Using multiple inputs provides more appropriate prior information for learning. In this proposed method, the image is transferred to the HSV color space and then the 3D color image is converted to a 2D matrix using a weighted mean. This weighted mean is calculated based on the entropy criterion. The resulting two-dimensional matrix is not in pixel and is merely a raw description of the image. The local, regional and global descriptions are extracted from this matrix and provided for the network. The proposed deep network automatically extracts the appropriate features to determine the progression degree of diabetic retinopathy by the network. Window by window image processing can overcome one of the basic problems of image classification, i.e. the small number of labeled data. Experiments showed that the proposed method is superior when compared to other methods.",diabetic retinopathy; mixed-restricted boltzmann machine; retinal image; deep networks; multi-input 2-dimensional deep belief network
Review,"Hormel, Tristan T.; Hwang, Thomas S.; Bailey, Steven T.; Wilson, David J.; Huang, David; Jia, Yali",Artificial intelligence in OCT angiography,progress in retinal and eye research,2021,Not found,"Optical coherence tomographic angiography (OCTA) is a non-invasive imaging modality that provides threedimensional, information-rich vascular images. With numerous studies demonstrating unique capabilities in biomarker quantification, diagnosis, and monitoring, OCTA technology has seen rapid adoption in research and clinical settings. The value of OCTA imaging is significantly enhanced by image analysis tools that provide rapid and accurate quantification of vascular features and pathology. Today, the most powerful image analysis methods are based on artificial intelligence (AI). While AI encompasses a large variety of techniques, machinelearning-based, and especially deep-learning-based, image analysis provides accurate measurements in a variety of contexts, including different diseases and regions of the eye. Here, we discuss the principles of both OCTA and AI that make their combination capable of answering new questions. We also review contemporary applications of AI in OCTA, which include accurate detection of pathologies such as choroidal neovascularization, precise quantification of retinal perfusion, and reliable disease diagnosis.",oct angiography; artificial intelligence; deep learning; image analysis
Review,"Lee, Eric Boya; Wang, Sophia Ying; Chang, Robert T.",Interpreting Deep Learning Studies in Glaucoma: Unresolved Challenges,asia-pacific journal of ophthalmology,2021,Not found,"Deep learning algorithms as tools for automated image classification have recently experienced rapid growth in imaging-dependent medical specialties, including ophthalmology. However, only a few algorithms tailored to specific health conditions have been able to achieve regulatory approval for autonomous diagnosis. There is now an international effort to establish optimized thresholds for algorithm performance benchmarking in a rapidly evolving artificial intelligence field. This review examines the largest deep learning studies in glaucoma, with special focus on identifying recurrent challenges and limitations within these studies which preclude widespread clinical deployment. We focus on the 3 most common input modalities when diagnosing glaucoma, namely, fundus photographs, spectral domain optical coherence tomography scans, and standard automated perimetry data. We then analyze 3 major challenges present in all studies: defining the algorithm output of glaucoma, determining reliable ground truth datasets, and compiling representative training datasets.",artificial intelligence; deep learning; primary open angle glaucoma
Review,"Kuwahara, Takamichi; Hara, Kazuo; Mizuno, Nobumasa; Haba, Shin; Okuno, Nozomi; Koda, Hiroki; Miyano, Akira; Fumihara, Daiki",Current status of artificial intelligence analysis for endoscopic ultrasonography,digestive endoscopy,2021,Not found,"Endoscopic ultrasonography (EUS) is an essential diagnostic tool for various types of pancreatic diseases such as pancreatic tumors and chronic pancreatitis; however, EUS imaging has low specificity for the diagnosis of pancreatic diseases. Artificial intelligence (AI) is a mathematical prediction technique that automates learning and recognizes patterns in data. This review describes the details and principles of AI and deep learning algorithms. The term AI does not have any definite definition; almost all AI systems fall under narrow AI, which can handle single or limited tasks. Deep learning is based on neural networks, which is a machine learning technique that is widely used in the medical field. Deep learning involves three phases: data collection and annotation, building the deep learning architecture, and training and ability validation. For medical image diagnosis, image classification, object detection, and semantic segmentation are performed. In EUS, AI is used for detecting anatomical features, differential pancreatic tumors, and cysts. For this, conventional machine learning architectures are used, and deep learning architecture has been used in only two reports. Although the diagnostic abilities in these reports were about 85-95%, these were exploratory research and very few reports have included substantial evidence. AI is increasingly being used for medical image diagnosis due to its high performance and will soon become an essential technique for medical diagnosis.",artificial intelligence; deep learning; endoscopic ultrasonography; intraductal papillary mucinous neoplasms; pancreas
Article,"Liu, Zhiping; Wang, Chen; Cai, Xiaodong; Jiang, Hong; Wang, Jianhua",Discrimination of Diabetic Retinopathy From Optical Coherence Tomography Angiography Images Using Machine Learning Methods,ieee access,2021,Not found,"The goal was to discriminate between diabetic retinopathy (DR) and healthy controls (HC) by evaluating Optical coherence tomography angiography (OCTA) images from 3 x 3 mm scans with the assistance of different machine learning models. The OCTA angiography dataset of superficial vascular plexus (SVP), deep vascular plexus (DVP), and retinal vascular network (RVN) were acquired from 19 DR (38 eyes) patients and 25 HC (44 eyes). A discrete wavelet transform was applied to extract texture features from each image. Four machine learning models, including logistic regression (LR), logistic regression regularized with the elastic net penalty (LR-EN), support vector machine (SVM), and the gradient boosting tree named XGBoost, were used to classify wavelet features between groups. The area under the receiver operating characteristics curve (AUC), sensitivity, specificity, and diagnostic accuracy of the classifiers were obtained. The OCTA image dataset included 114 and 132 images from DR and HC subjects, respectively. LR-EN and LR using all three images, SVP, DVP, and RVN, provided the highest sensitivity of 0.84 and specificity of 0.80, the best diagnostic accuracy of 0.82, and an AUC of 0.83 and 0.84, respectively, which were slightly lower than that of LR using one image SVP (0.85) or two images DVP and SVP (0.85). The LR-EN and LR classification algorithms had the high sensitivity, specificity, and diagnostic accuracy in identifying DR, which may be promising in facilitating the early diagnosis of DR.",diabetic retinopathy; machine learning; logistic regression; logistic regression regularized with the elastic net penalty; support vector machine
Article,"Wu, Dongxuan; Xiang, Yifan; Wu, Xiaohang; Yu, Tongyong; Huang, Xiucheng; Zou, Yuxian; Liu, Zhenzhen; Lin, Haotian",Artificial intelligence-tutoring problem-based learning in ophthalmology clerkship,annals of translational medicine,2020,Not found,"Background: Artificial intelligence (AI) is an increasingly popular tool in medical investigations. However, AI's potential of aiding medical teaching has not been explored. This study aimed to evaluate the effectiveness of AI-tutoring problem-based-learning (PBL) in ophthalmology clerkship and to assess the student evaluations of this module. Methods: Thirty-eight Grade-two students in ophthalmology clerkship at Sun Yat-Sen University were randomly assigned to two groups. In Group A, students learned congenital cataracts through an AI-tutoring PBL module by exploring and operating an AI diagnosis platform. In Group B, students learned congenital cataracts through traditional lecture given with the same faculty. The improvement in student performance was evaluated by comparing the pre- and post-lecture scores of a specific designed test using paired-T tests. Student evaluations of AI-tutoring PBL were measured by a 17-item questionnaire. Results: The post-lecture scores were significantly higher than the pre-lecture scores in both groups (Group A: P<0.0001, Group B: P<0.0001). The improvement of group A in the part of sign and diagnosis test (Part I) was more significant than that of group B (P=0.016). However, there was no difference in the improvement in the part of treatment plan test (Part II) between two groups (P=0.556). Overall, all respondents were satisfied and agreed that AI-tutoring PBL was helpful, effective, motive and beneficial to help develop critical and creative thinking. Conclusions: The application of AI-tutoring PBL into ophthalmology clerkship improved students' performance and satisfaction. AI-tutoring PBL teaching showed advantage in promoting students' understanding of signs of diseases. The instructors play an indispensable role in AI-tutoring PBL curriculum.",artificial-intelligence; problem-based learning; ophthalmology clerkship
Review,"Tajudin, Nurul Mirza Afiqah; Kipli, Kuryati; Mahmood, Muhammad Hamdi; Lim, Lik Thai; Mat, Dayang Azra Awang; Sapawi, Rohana; Sahari, Siti Kudnie; Lias, Kasumawati; Jali, Suriati Khartini; Hoque, Mohammed Enamul",Deep learning in the grading of diabetic retinopathy: A review,iet computer vision,2022,Not found,"Diabetic Retinopathy (DR) grading into different stages of severity continues to remain a challenging issue due to the complexities of the disease. Diabetic Retinopathy grading classifies retinal images to five levels of severity ranging from 0 to 5, which represents No DR, Mild non-proliferative diabetic retinopathy (NPDR), Moderate NPDR, Severe NPDR, and proliferative diabetic retinopathy. With the advancement of Deep Learning, studies on the application of the Convolutional Neural Network (CNN) in DR grading have been on the rise. High accuracy and sensitivity are the desired outcome of these studies. This paper reviewed recently published studies that employed CNN for DR grading to 5 levels of severity. Various approaches are applied in classifying retinal images which are, (i) by training CNN models to learn the features for each grade and (ii) by detecting and segmenting lesions using information about their location such as microaneurysms, exudates, and haemorrhages. Public and private datasets have been utilised by researchers in classifying retinal images for DR. The performance of the CNN models was measured by accuracy, specificity, sensitivity, and area under the curve. The CNN models and their performance varies for every study. More research into the CNN model is necessary for future work to improve model performance in DR grading. The Inception model can be used as a starting point for subsequent research. It will also be necessary to investigate the attributes that the model uses for grading.",algorithm; diagnosis; images
Article,"Malerbi, Fernando Korn; Melo, Gustavo Barreto","Feasibility of screening for diabetic retinopathy using artificial intelligence, Brazil",bulletin of the world health organization,2022,Not found,"Problem There is currently no national strategy or standardized approach to diabetic retinopathy screening in the Brazilian public health system, and multiple socioeconomic barriers prevent access to eye examination in Brazil's poorest regions. Approach From September 2021 to March 2022 we carried out a pilot project with an artificial intelligence system for diabetic retinopathy screening, embedded in a portable retinal camera. Patients with a diagnosis of diabetes according to the municipality registry were invited to attend nearby clinics for screening on designated days. Trained health-care technicians acquired images which were automatically evaluated by the system, with instant remote evaluation by retinal specialists in selected cases. Local setting Our study was based in Sergipe State, located at a region with high illiteracy rates and no local availability of specialized retina care.The average number of laser treatments performed annually in the last 5 years is 126, for a total State population of 2.3 million. Relevant changes Even though screening was performed free of charge in a convenient location for patients, from a total 2052 eligible individuals, only 1083 attended for screening. Lessons learnt Efforts to raise awareness on the condition screened and to provide health education for patients and local health-care personnel are fundamental for increased attendance. Tailoring screening systems to the local setting, such as determining the trade-off between sensitivity and specificity, is challenging in regions with no current benchmarks. Standards for retinopathy screening based on the strategies adopted by high-income countries may not be realistic in low- and middle-income countries.",not found
Article,"Maqsood, Sarmad; Damasevicius, Robertas; Maskeliunas, Rytis",Hemorrhage Detection Based on 3D CNN Deep Learning Framework and Feature Fusion for Evaluating Retinal Abnormality in Diabetic Patients,sensors,2021,Not found,"Diabetic retinopathy (DR) is the main cause of blindness in diabetic patients. Early and accurate diagnosis can improve the analysis and prognosis of the disease. One of the earliest symptoms of DR are the hemorrhages in the retina. Therefore, we propose a new method for accurate hemorrhage detection from the retinal fundus images. First, the proposed method uses the modified contrast enhancement method to improve the edge details from the input retinal fundus images. In the second stage, a new convolutional neural network (CNN) architecture is proposed to detect hemorrhages. A modified pre-trained CNN model is used to extract features from the detected hemorrhages. In the third stage, all extracted feature vectors are fused using the convolutional sparse image decomposition method, and finally, the best features are selected by using the multi-logistic regression controlled entropy variance approach. The proposed method is evaluated on 1509 images from HRF, DRIVE, STARE, MESSIDOR, DIARETDB0, and DIARETDB1 databases and achieves the average accuracy of 97.71%, which is superior to the previous works. Moreover, the proposed hemorrhage detection system attains better performance, in terms of visual quality and quantitative analysis with high accuracy, in comparison with the state-of-the-art methods.",medical image processing; hemorrhage detection; retinal fundus image; diabetic retinopathy; feature fusion; deep learning
Proceedings Paper,"Kim, DaEl; Hacisoftaoglu, Recep Emre; Karakaya, Mahmut",Optic Disc Localization in Retinal Images using Deep Learning Frameworks,disruptive technologies in information sciences iv,2020,Not found,"Diabetic Retinopathy (DR) is one of the most common eye diseases related to diabetics. If the diagnosis and treatment are conducted too late, it may result in various degrees of vision loss, even blindness. Therefore, individuals with diabetes should have a regular annual eye exam. Studies showed that early detection can prevent vision loss in earlier stages. However, in places such as undeveloped or developing countries, and even sometimes rural areas in developed countries, may not have enough resources for DR screening. Furthermore, even though these places may have adequate equipment, the diagnosis may take a few days to obtain results for the analysis of the ophthalmologists. Developing an automated detection algorithm is an emerging research area to diagnose DR remotely using a retina image. Localizing the optic disc and fovea is an essential task in these DR detection algorithms. After locating the optic disc, finding other components of the retina is easier. Technological developments in recent years enable the acceleration of diagnosis of such diseases including DR. Deep learning techniques are becoming an essential part of the medical field. In the last years, there have been many attempts to automatize the analysis of medical disorders such as breast cancer, glaucoma, diabetic macular edema, and diabetic retinopathy. In this paper, we presented the utilization of a pre-trained deep learning framework to localize the optic disc in the retina images. Using the transfer learning approach for AlexNet with a linear regression output, we localized the optic disc center. Retina images with labeled ground truth values of optic disc center were used to retrain the AlexNet. We tested our proposed deep learning-based optic disc localization approach with three different publicly available datasets including EyePACS, Messidor, and IDRID. Based on the results, the deep learning-based optic disc localization method shows high detection accuracy. The best results for optic disc detection were observed with cross dataset images as the accuracy of 88.35%, while a 97.66% testing accuracy was observed for the merged dataset using transfer learning approach for the pretrained AlexNet.",retinal imaging; diabetic retinopathy; optic disc; localization; deep learning; convolutional neural networks; regression; classification; eyepacs; messidor; idrid; transfer learning; alexnet
Article,"Sahlsten, Jaakko; Jaskari, Joel; Kivinen, Jyri; Turunen, Lauri; Jaanio, Esa; Hietala, Kustaa; Kaski, Kimmo",Deep Learning Fundus Image Analysis for Diabetic Retinopathy and Macular Edema Grading,scientific reports,2019,Not found,"Diabetes is a globally prevalent disease that can cause visible microvascular complications such as diabetic retinopathy and macular edema in the human eye retina, the images of which are today used for manual disease screening and diagnosis. This labor-intensive task could greatly benefit from automatic detection using deep learning technique. Here we present a deep learning system that identifies referable diabetic retinopathy comparably or better than presented in the previous studies, although we use only a small fraction of images (<1/4) in training but are aided with higher image resolutions. We also provide novel results for five different screening and clinical grading systems for diabetic retinopathy and macular edema classification, including state-of-the-art results for accurately classifying images according to clinical five-grade diabetic retinopathy and for the first time for the four-grade diabetic macular edema scales. These results suggest, that a deep learning system could increase the cost-effectiveness of screening and diagnosis, while attaining higher than recommended performance, and that the system could be applied in clinical examinations requiring finer grading.",validation
Article,"Leeza, Mona; Farooq, Humera",Detection of severity level of diabetic retinopathy using Bag of features model,iet computer vision,2019,Not found,"Diabetic retinopathy is a vascular disease caused by uncontrolled diabetes. Its early detection can save diabetic patients from blindness. However, the detection of its severity level is a challenge for ophthalmologists since last few decades. Several efforts have been made for the identification of its limited stages by using pre- and post-processing methods, which require extensive domain knowledge. This study proposes an improved automated system for severity detection of diabetic retinopathy which is a dictionary-based approach and does not include pre- and post-processing steps. This approach integrates pathological explicit image representation into a learning outline. To create the dictionary of visual features, points of interest are detected to compute the descriptive features from retinal images through speed up robust features algorithm and histogram of oriented gradients. These features are clustered to generate a dictionary, then coding and pooling are applied for compact representation of features. Radial basis kernel support vector machine and neural network are used to classify the images into five classes namely normal, mild, moderate, severe non-proliferative diabetic retinopathy, and proliferative diabetic retinopathy. The proposed system exhibits improved results of 95.92% sensitivity and 98.90% specificity in relation to the reported state of the art methods.",eye; patient diagnosis; image representation; medical image processing; feature extraction; image segmentation; support vector machines; image classification; biomedical optical imaging; learning (artificial intelligence); diseases; features model; uncontrolled diabetes; early detection; diabetic patients; severity level; post-processing methods; severity detection; dictionary-based approach; post-processing steps; pathological explicit image representation; visual features; descriptive features; robust features algorithm; histogram; nonproliferative diabetic retinopathy; proliferative diabetic retinopathy
Proceedings Paper,"Pedrosa, Micael; Silva, Jorge Miguel; Matos, Sergio; Costa, Carlos",SCREEN-DR Software rchitecture for the Diabetic Retinopathy Screening,building continents of knowledge in oceans of data: the future of co-created ehealth,2018,Not found,"Diabetic Retinopathy (DR) is a common complication of diabetes that may lead to blindness if not treated. However, since DR evolves without any symptoms in the initial stages, early detection and treatment can only be achieved through routine checks. This article presents the collaborative platform of the SCREEN-DR project that promotes partnership between physicians and researchers in the scope of a regional DR screening program. The role of researchers is to create classification algorithms to evaluate image quality, discard non-pathological cases, locate possible lesions and grade DR severity. Physicians are responsible for annotating datasets, including the visual delineation of lesions. The collaborative platform collects the studies, indexes the images metadata, and manages the creation of datasets and the respective annotation process. An advanced searching mechanism supports multimodal queries over annotated datasets and exporting of results for feeding artificial intelligence algorithms.",diabetic retinopathy; computer-aided diagnosis; image annotation
Article,"Shivsharan, Nitin; Ganorkar, Sanjay",Diabetic Retinopathy Detection Using Optimization Assisted Deep Learning Model: Outlook on Improved Grey Wolf Algorithm,international journal of image and graphics,2021,Not found,"In recent days, study on retinal image remains a significant area for analysis. Several retinal diseases are identified by examining the differences occurring in the retina. Anyhow, the major shortcoming between these analyses was that the identification accuracy is not satisfactory. The adopted framework includes two phases namely; (i) feature extraction and (ii) classification. Initially, the input fundus image is subjected to the feature extraction process, where the features like Local Binary Pattern (LBP), Local Vector Pattern (LVP) and Local Tetra Patterns (LTrP) are extracted. These extracted features are subjected to the classification process, where the Deep Belief Network (DBN) is used as the classifier. In addition, to improve the accuracy, the activation function and hidden neurons of DBN are optimally tuned by means of the Self Improved Grey Wolf Optimization (SI-GWO). Finally, the performance of implemented work is compared and proved over the conventional models.",diabetic retinopathy; feature extraction; deep learning; optimization; grey wolf optimizer
Proceedings Paper,"Furtado, Pedro",Segmentation of Diabetic Retinopathy Lesions by Deep Learning: Achievements and Limitations,"proceedings of the 13th international joint conference on biomedical engineering systems and technologies, vol 2: bioimaging",2020,Not found,"Analysis of Eye Fundus Images (EFI) allows early diagnosis and grading of Diabetic Retinopathy (DR), detecting micro-aneurisms, exudates, haemorrhages, neo-vascularizations and other signs. Automated detection of individual lesions helps visualizing, characterizing and determining degree of DR. Today modified deep convolution neural networks (DCNNs) are state-of-the-art in most segmentation tasks. But the task of segmenting lesions in EFI is challenging due to sizes, varying shapes, similarity and lack of contrast with other parts of the EFI, so that the results are ambiguous. In this paper we test two DCNNs to do a preliminary evaluation of the strengths and limitations using publicly available data. We already conclude that the accuracies are good but the segmentations still have relevant deficiencies. Based on this, we identify the need for further assessment and suggest future work to improve segmentation approaches.",medical imaging; deep learning; segmentation; efi
Article,"Yang, Binhua; Li, Tongyan; Xie, Haidi; Liao, Yulin; Chen, Yi-Ping Phoebe",Classification of Diabetic Retinopathy Severity Based on GCA Attention Mechanism,ieee access,2022,Not found,"Diabetic retinopathy (DR) is one of the major complications caused by diabetes and can lead to severe vision loss or even complete blindness if not diagnosed and treated in a timely manner. In this paper, a new feature map global channel attention mechanism (GCA) is proposed to solve the problem of the early detection of DR. In the GCA module, an adaptive one-dimensional convolution kernel size algorithm based on the dimension of the feature map is proposed and a deep convolutional neural network model for DR color medical image severity diagnosis named GCA-EfficientNet (GENet) is designed. The training process uses transfer learning techniques with a cosine annealing learning rate adjustment strategy. The image regions of interest of GENet are visualized using a heat map. The final accuracy, precision, sensitivity and specificity of the DR dataset of the Kaggle competition reached 0.956, 0.956, 0.956, and 0.989, respectively. A large number of experiment results show that GENet based on the GCA attention mechanism can more effectively extract lesion features and classify the severity of DR.",feature extraction; lesions; support vector machines; adaptation models; diabetes; kernel; image color analysis; attention mechanism; convolutional neural network; deep learning; diabetic retinopathy; medical images
Article,"Asia, Al-Omaisi; Zhu, Cheng-Zhang; Althubiti, Sara A.; Al-Alimi, Dalal; Xiao, Ya-Long; Ouyang, Ping-Bo; Al-Qaness, Mohammed A. A.",Detection of Diabetic Retinopathy in Retinal Fundus Images Using CNN Classification Models,electronics,2022,Not found,"Diabetes is a widespread disease in the world and can lead to diabetic retinopathy, macular edema, and other obvious microvascular complications in the retina of the human eye. This study attempts to detect diabetic retinopathy (DR), which has been the main reason behind the blindness of people in the last decade. Timely or early treatment is necessary to prevent some DR complications and control blood glucose. DR is very difficult to detect in time-consuming manual diagnosis because of its diversity and complexity. This work utilizes a deep learning application, a convolutional neural network (CNN), in fundus photography to distinguish the stages of DR. The images dataset in this study is obtained from Xiangya No. 2 Hospital Ophthalmology (XHO), Changsha, China, which is very large, little and the labels are unbalanced. Thus, this study first solves the problem of the existing dataset by proposing a method that uses preprocessing, regularization, and augmentation steps to increase and prepare the image dataset of XHO for training and improve performance. Then, it takes the advantages of the power of CNN with different residual neural network (ResNet) structures, namely, ResNet-101, ResNet-50, and VggNet-16, to detect DR on XHO datasets. ResNet-101 achieved the maximum level of accuracy, 0.9888, with a training loss of 0.3499 and a testing loss of 0.9882. ResNet-101 is then assessed on 1787 photos from the HRF, STARE, DIARETDB0, and XHO databases, achieving an average accuracy of 0.97, which is greater than prior efforts. Results prove that the CNN model (ResNet-101) has better accuracy than ResNet-50 and VggNet-16 in DR image classification.",classification; diabetic retinopathy; deep learning; cnn; resnet; vggnet
Proceedings Paper,"Wu, Qian; Cheddad, Abbas",Segmentation-based Deep Learning Fundus Image Analysis,"2019 ninth international conference on image processing theory, tools and applications (ipta)",2019,Not found,"Diabetic retinopathy is the most common cause of new cases of blindness in people of working age. Early diagnosis is the key to slowing the progression of the disease, thus preventing blindness. Retinal fundus images form an important basis for judging these retinal diseases. To the best of our knowledge, no prior studies have scrutinized the predictive power of the different compositions of retinal images using deep learning. This paper is to investigate whether there exists specific region that could assist in better prediction of the retinopathy disease, meaning to find the best region in fundus images that can boost the prediction power of models for retinopathy classification. To this end, with image segmentation techniques, the fundus image is divided into three different segments, namely, the optic disc, the blood vessels, and the other regions (regions other than blood vessels and optic disk). These regions are then contrasted against the performance of original fundus images. The convolutional neural network as well as transfer deep learning with the state-of-the-art pre-trained models (i.e., AlexNet, GoogleNet, Resnet50, VGG19) are deployed. We report the average of ten runs for each model. Different machine learning evaluation metrics are used. The other regions' segment reveals more predictive power than the original fundus image especially when using AlexNet/Resnet50.",fundus image; retinopathy; deep learning; alexnet; image segmentation
Review,"Kang, Linda; Ballouz, Dena; Woodward, Maria A.",Artificial intelligence and corneal diseases,current opinion in ophthalmology,2022,Not found,"Purpose of review Artificial intelligence has advanced rapidly in recent years and has provided powerful tools to aid with the diagnosis, management, and treatment of ophthalmic diseases. This article aims to review the most current clinical artificial intelligence applications in anterior segment diseases, with an emphasis on microbial keratitis, keratoconus, dry eye syndrome, and Fuchs endothelial dystrophy. Recent findings Most current artificial intelligence approaches have focused on developing deep learning algorithms based on various imaging modalities. Algorithms have been developed to detect and differentiate microbial keratitis classes and quantify microbial keratitis features. Summary Artificial intelligence may aid with early detection and staging of keratoconus. Many advances have been made to detect, segment, and quantify features of dry eye syndrome and Fuchs. There is significant variability in the reporting of methodology, patient population, and outcome metrics. Artificial intelligence shows great promise in detecting, diagnosing, grading, and measuring diseases. There is a need for standardization of reporting to improve the transparency, validity, and comparability of algorithms.",artificial intelligence; dry eye syndrome; fuchs endothelial dystrophy; keratoconus; microbial keratitis
Article,"Wang, Depeng; Wang, Liejun",On OCT Image Classification via Deep Learning,ieee photonics journal,2019,Not found,"Computer-aided diagnosis of retinopathy is a research hotspot in the field of medical image classification. Diabetic macular edema (DME) and age-related macular degeneration (AMD) are two common ocular diseases that can result in partial or complete loss of vision. Optical coherence tomography imaging (OCT) is widely applied to the diagnosis of ocular diseases including DME and AMD. In this paper, an automatic method based on deep learning is proposed to detect AME and AMD lesions, in which two publicly available OCT datasets of retina were adopted and a network model with effective feature of reuse feature was applied to solve the problem of small datasets and enhance the adaptation to the difference of different datasets of the approach. Several network models with effective feature of reusable feature were compared and the transfer learning on networks with pre-trained models was realized. CliqueNet achieves better, classification results compared with other network models with a more than 0.98 accuracy and 0.99 of area under the curve (AUC) value finally.",deep learning; optical coherence tomography; diabetic macular edema; age-related macular degeneration automated diagnosis; computer-aided diagnosis
Article,"Tseng, Vincent S.; Chen, Ching-Long; Liang, Chang-Min; Tai, Ming-Cheng; Liu, Jung-Tzu; Wu, Po-Yi; Deng, Ming-Shan; Lee, Ya-Wen; Huang, Teng-Yi; Chen, Yi-Hao",Leveraging Multimodal Deep Learning Architecture with Retina Lesion Information to Detect Diabetic Retinopathy,translational vision science & technology,2020,Not found,"Purpose: To improve disease severity classification from fundus images using a hybrid architecture with symptom awareness for diabetic retinopathy (DR). Methods: We used 26,699 fundus images of 17,834 diabetic patients from three Taiwanese hospitals collected in 2007 to 2018 for DR severity classification. Thirty-seven ophthalmologists verified the images using lesion annotation and severity classification as the ground truth. Two deep learning fusion architectures were proposed: late fusion, which combines lesion and severity classification models in parallel using a postprocessing procedure, and two-stage early fusion, which combines lesion detection and classification models sequentially and mimics the decision-making process of ophthalmologists. Messidor-2 was used with 1748 images to evaluate and benchmark the performance of the architecture. The primary evaluation metrics were classification accuracy, weighted kappa statistic, and area under the receiver operating characteristic curve (AUC). Results: For hospital data, a hybrid architecture achieved a good detection rate, with accuracy and weighted kappa of 84.29% and 84.01%, respectively, for five-class DR grading. It also classified the images of early stage DR more accurately than conventional algorithms. The Messidor-2 model achieved an AUC of 97.09% in referral DR detection compared to AUC of 85% to 99% for state-of-the-art algorithms that learned from a larger database. Conclusions: Our hybrid architectures strengthened and extracted characteristics from DR images, while improving the performance of DR grading, thereby increasing the robustness and confidence of the architectures for general use. Translational Relevance: The proposed fusion architectures can enable faster and more accurate diagnosis of various DR pathologies than that obtained in current manual clinical practice.",diabetic retinopathy; fusion architecture; convolutional neural network; object detection; fundus image
Proceedings Paper,"delaPava, Melissa; Rios, Hernan; Rodriguez, Francisco J.; Perdomo, Oscar J.; Gonzalez, Fabio A.",A deep learning model for classification of diabetic retinopathy in eye fundus images based on retinal lesion detection,17th international symposium on medical information processing and analysis,2021,Not found,"Diabetic retinopathy (DR) is the result of a complication of diabetes affecting the retina. It can cause blindness, if left undiagnosed and untreated. An ophthalmologist performs the diagnosis by screening each patient and analyzing the retinal lesions via ocular imaging. In practice, such analysis is time-consuming and cumbersome to perform. This paper presents a model for automatic DR classification on eye fundus images. The approach identifies the main ocular lesions related to DR and subsequently diagnoses the illness. The proposed method follows the same workflow as the clinicians, providing information that can be interpreted clinically to support the prediction. A subset of the kaggle EyePACS and the Messidor-2 datasets, labeled with ocular lesions, is made publicly available. The kaggle EyePACS subset is used as training set and the Messidor-2 as a test set for lesions and DR classification models. For DR diagnosis, our model has an area-under-the-curve, sensitivity, and specificity of 0.948, 0.886, and 0.875, respectively, which competes with state-of-the-art approaches.",retinal lesions; ocular screening; diabetic retinopathy; machine learning
Article; Early Access,"Shanthini, A.; Manogaran, Gunasekaran; Vadivu, G.; Kottilingam, K.; Nithyakani, P.; Fancy, C.",Threshold segmentation based multi-layer analysis for detecting diabetic retinopathy using convolution neural network,journal of ambient intelligence and humanized computing,0,Not found,"Diabetic retinopathy (DR) syndrome affects the vision of the eyes by damaging the blood vessels. Fore-hand detection and prevention of this syndrome are most significant as it results in vision blindness. Diagnosis and procedural analysis of this syndrome with modern healthcare science and technology are aided through artificial intelligence and processing units. In this article, a threshold segmentation based DR detection method is introduced. This method is keen is classifying the foreground and background of the input retinal image and processing through pixel-based segmentation. The process of assessing the layers is augmented using a two-layer convolutional neural network (CNN) that mitigates the false positives during classification. This process is sequential in determining the precise detection of the infected region of the retina. Besides, the segment-based CNN (S-CNN) handles the flaw in diagnosis through two-hidden layers for differentiating the threshold and normalized conditions based on classification. The proposed method is reliable in achieving better accuracy of detection, sensitivity, and true positives.",cnn; diabetic retinopathy; feature map; multi-layer processing; threshold segmentation
Article,"Gunasekaran, K.; Pitchai, R.; Chaitanya, Gogineni Krishna; Selvaraj, D.; Annie Sheryl, S.; Almoallim, Hesham S.; Alharbi, Sulaiman Ali; Raghavan, S. S.; Tesemma, Belachew Girma",A Deep Learning Framework for Earlier Prediction of Diabetic Retinopathy from Fundus Photographs,biomed research international,2022,Not found,"Diabetic patients can also be identified immediately utilizing retinopathy photos, but it is a challenging task. The blood veins visible in fundus photographs are used in several disease diagnosis approaches. We sought to replicate the findings published in implementation and verification of a deep learning approach for diabetic retinopathy identification in retinal fundus pictures. To address this issue, the suggested investigative study uses recurrent neural networks (RNN) to retrieve characteristics from deep networks. As a result, using computational approaches to identify certain disorders automatically might be a fantastic solution. We developed and tested several iterations of a deep learning framework to forecast the progression of diabetic retinopathy in diabetic individuals who have undergone teleretinal diabetic retinopathy assessment in a basic healthcare environment. A collection of one-field or three-field colour fundus pictures served as the input for both iterations. Utilizing the proposed DRNN methodology, advanced identification of the diabetic state was performed utilizing HE detected in an eye's blood vessel. This research demonstrates the difficulties in duplicating deep learning approach findings, as well as the necessity for more reproduction and replication research to verify deep learning techniques, particularly in the field of healthcare picture processing. This development investigates the utilization of several other Deep Neural Network Frameworks on photographs from the dataset after they have been treated to suitable image computation methods such as local average colour subtraction to assist in highlighting the germane characteristics from a fundoscopy, thus, also enhancing the identification and assessment procedure of diabetic retinopathy and serving as a skilled guidelines framework for practitioners all over the globe.",images; disease; sites
Proceedings Paper,"Bajwa, Muhammad Naseer; Taniguchi, Yoshinobu; Malik, Muhammad Imran; Neumeier, Wolfgang; Dengel, Andreas; Ahmed, Sheraz",Combining Fine- and Coarse-Grained Classifiers for Diabetic Retinopathy Detection,"medical image understanding and analysis, miua 2019",2020,Not found,"Visual artefacts of early diabetic retinopathy in retinal fundus images are usually small in size, inconspicuous, and scattered all over retina. Detecting diabetic retinopathy requires physicians to look at the whole image and fixate on some specific regions to locate potential biomarkers of the disease. Therefore, getting inspiration from ophthalmologist, we propose to combine coarse-grained classifiers that detect discriminating features from the whole images, with a recent breed of fine-grained classifiers that discover and pay particular attention to pathologically significant regions. To evaluate the performance of this proposed ensemble, we used publicly available EyePACS and Messidor datasets. Extensive experimentation for binary, ternary and quaternary classification shows that this ensemble largely outperforms individual image classifiers as well as most of the published works in most training setups for diabetic retinopathy detection. Furthermore, the performance of finegrained classifiers is found notably superior than coarse-grained image classifiers encouraging the development of task-oriented fine-grained classifiers modelled after specialist ophthalmologists.",computer-aided diagnosis; medical image analysis; automated diabetic retinopathy detection; convolutional neural network; deep learning in ophthalmology
Article,"Garifullin, Azat; Lensu, Lasse; Uusitalo, Hannu",Deep Bayesian baseline for segmenting diabetic retinopathy lesions: Advances and challenges,computers in biology and medicine,2021,Not found,"Early diagnosis of retinopathy is essential for preventing retinal complications and visual impairment due to diabetes. For the detection of retinopathy lesions from retinal images, several automatic approaches based on deep neural networks have been developed in the recent years. Most of the proposed methods produce point estimates of pixels belonging to the lesion areas and give no or little information on the uncertainty of method predictions. However, the latter can be essential in the examination of the medical condition of the patient when the goal is early detection of abnormalities. This work extends the recent research with a Bayesian framework by considering the parameters of a convolutional neural network as random variables and utilizing stochastic variational dropout based approximation for uncertainty quantification. The framework includes an extended validation procedure and it allows analyzing lesion segmentation distributions, model calibration and prediction uncertainties. Also the challenges related to the deep probabilistic model and uncertainty quantification are presented. The proposed method achieves area under precision-recall curve of 0.84 for hard exudates, 0.641 for soft exudates, 0.593 for haemorrhages, and 0.484 for microaneurysms on IDRiD dataset.",bayesian deep learning; diabetic retinopathy; lesion segmentation; microaneurysm; hard exudate; soft exudate; haemorrhage
Article,"Prahs, Philipp; Radeck, Viola; Mayer, Christian; Cvetkov, Yordan; Cvetkova, Nadezhda; Helbig, Horst; Maerker, David",OCT-based deep learning algorithm for the evaluation of treatment indication with anti-vascular endothelial growth factor medications,graefes archive for clinical and experimental ophthalmology,2018,Not found,"Intravitreal injections with anti-vascular endothelial growth factor (anti-VEGF) medications have become the standard of care for their respective indications. Optical coherence tomography (OCT) scans of the central retina provide detailed anatomical data and are widely used by clinicians in the decision-making process of anti-VEGF indication. In recent years, significant progress has been made in artificial intelligence and computer vision research. We trained a deep convolutional artificial neural network to predict treatment indication based on central retinal OCT scans without human intervention. A total of 183,402 retinal OCT B-scans acquired between 2008 and 2016 were exported from the institutional image archive of a university hospital. OCT images were cross-referenced with the electronic institutional intravitreal injection records. OCT images with a following intravitreal injection during the first 21 days after image acquisition were assigned into the 'injection' group, while the same amount of random OCT images without intravitreal injections was labeled as 'no injection'. After image preprocessing, OCT images were split in a 9:1 ratio to training and test datasets. We trained a GoogLeNet inception deep convolutional neural network and assessed its performance on the validation dataset. We calculated prediction accuracy, sensitivity, specificity, and receiver operating characteristics. The deep convolutional neural network was successfully trained on the extracted clinical data. The trained neural network classifier reached a prediction accuracy of 95.5% on the images in the validation dataset. For single retinal B-scans in the validation dataset, a sensitivity of 90.1% and a specificity of 96.2% were achieved. The area under the receiver operating characteristic curve was 0.968 on a per B-scan image basis, and 0.988 by averaging over six B-scans per examination on the validation dataset. Deep artificial neural networks show impressive performance on classification of retinal OCT scans. After training on historical clinical data, machine learning methods can offer the clinician support in the decision-making process. Care should be taken not to mistake neural network output as treatment recommendation and to ensure a final thorough evaluation by the treating physician.",deep learning; optical coherence tomography; age-related macular degeneration; diabetic retinopathy; artificial intelligence; computer vision; computer-aided diagnosis
Proceedings Paper,"Dekhil, Omar; Naglah, Ahmed; Shaban, Mohamed; Ghazal, Mohammed; Taher, Fatma; Elbaz, Ayman",Deep Learning Based Method for Computer Aided Diagnosis of Diabetic Retinopathy,2019 ieee international conference on imaging systems & techniques (ist 2019),2019,Not found,"Diabetic retinopathy (DR) is a retinal disease caused by the high blood sugar levels that may damage and block the blood vessels feeding the retina. In the early stages of DR, the disease is asymptomatic; however, as the disease advances, a possible sudden loss of vision and blindness may occur. Therefore, an early diagnosis and staging of the disease is required to possibly slow down the progression of the disease and improve control of the symptoms. In response to the previous challenge, we introduce a computer aided diagnosis tool based on convolutional neural networks (CNN) to classify fundus images into one of the five stages of DR. The proposed CNN consists of a preprocessing stage, five stage convolutional, rectified linear and pooling layers followed by three fully connected layers. Transfer learning was adopted to minimize overfitting by training the model on a larger dataset of 3.2 million images (i.e. ImageNet) prior to the use of the model on the APTOS 2019 Kaggle DR dataset. The proposed approach has achieved a testing accuracy of 77% and a quadratic weighted kappa score of 78%, offering a promising solution for a successful early diagnose and staging of DR in an automated fashion.",convolutional neural network; image classification; ophthalmoscopy
Proceedings Paper,"Ye, Lei; Zhu, Weifang; Feng, Shuanglang; Chen, Xinjian",GANet: Group Attention Network for Diabetic Retinopathy Image Segmentation,medical imaging 2020: image processing,2021,Not found,"The assistance of deep learning techniques for clinic doctors in disease analysis, diagnosis and treatment is becoming popular and popular. In this paper, we propose a U-shape architecture based Group Attention network (named as GANet) for symptom segmentation in fundus images with diabetic retinopathy, in which Channel Group Attention(CGA) module and Spatial Group Attention Upsampling (SGAU) module are designed. The CGA module can adaptively allocate resources based on the importance of the feature channels, which can enhance the flexibility of the network to handle different types of information. The original U-Net directly merges the high-level features and low-level features in decoder stage for semantic segmentation, and achieves good results. To increase the nonlinearity of the U-shape network and pay more attention to the lesion area, we propose a Spatial Group Attention Upsampling (SGAU) module. In summary, our main contributions include two aspects: (1) Based on the U-shape network, the CGA module and SGAU module are designed and applied, which can adaptively allocate the weight of channels and pay more attention to the lesion area, respectively. (2) Compared with the original U-Net, the Dice coefficients of the proposed network improves by nearly 2.96% for hard exudates segmentation and 2.89% for hemorrhage segmentation, respectively.",deep learning; diabetic retinopathy; segmentation; group attention network
Proceedings Paper,"Sarki, Rubina; Ahmed, Khandakar; Wang, Hua; Michalska, Sandra; Zhang, Yanchun",Early Detection of Diabetic Eye Disease from Fundus Images with Deep Learning,"databases theory and applications, adc 2020",2020,Not found,"Diabetes is a life-threatening disease that affects various human body organs, including eye retina. Advanced Diabetic Eye disease (DED) leads to permanent vision loss, thus an early detection of DED symptoms is essential to prevent disease escalation and timely treatment. Up till now, research challenges in early DED detection can be summarised as follows: Firstly, changes in the eye anatomy during its early stage are frequently untraceable by human eye due to subtle nature of the features, and Secondly, large volume of fundus images puts a significant strain on limited specialist resources, rendering manual analysis practically infeasible. Thus, Deep Learning-based methods have been practiced to facilitate early DED detection and address the issues currently faced. Despite promising, highly accurate detection of early anatomical changes in the eye using Deep Learning remains a challenge in wide scale practical application. Consequently, in this research we aim to address the main three research gaps and propose the framework for early automated DED detection system on fundus images through Deep Learning.",diabetic disease; diabetic retinopathy; deep learning; glaucoma; image processing; macular edema; transfer learning
Article,"May, Anna; Gesell-May, Stefan; Mueller, Tobias; Ertel, Wolfgang",Artificial intelligence as a tool to aid in the differentiation of equine ophthalmic diseases with an emphasis on equine uveitis,equine veterinary journal,2022,Not found,"Background Due to recent developments in artificial intelligence, deep learning, and smart-device-technology, diagnostic software may be developed which can be executed offline as an app on smartphones using their high-resolution cameras and increasing processing power to directly analyse photos taken on the device. Objectives A software tool was developed to aid in the diagnosis of equine ophthalmic diseases, especially uveitis. Study design Prospective comparison of software and clinical diagnoses. Methods A deep learning approach for image classification was used to train software by analysing photographs of equine eyes to make a statement on whether the horse was displaying signs of uveitis or other ophthalmic diseases. Four basis networks of different sizes (MobileNetV2, InceptionV3, VGG16, VGG19) with modified top-layers were evaluated. Convolutional Neural Networks (CNN) were trained on 2346 pictures of equine eyes, which were augmented to 9384 images. 261 separate unmodified images were used to evaluate the performance of the trained network. Results Cross validation showed accuracy of 99.82% on training data and 96.66% on validation data when distinguishing between three categories (uveitis, other ophthalmic diseases, healthy). Main limitations One source of selection bias for the artificial intelligence presumably was the increased pupil size, which was mainly present in horses with ophthalmic diseases due to the use of mydriatics, and was not homogeneously dispersed in all categories of the dataset. Conclusions Our system for detection of equine uveitis is unique and novel and can differentiate between uveitis and other equine ophthalmic diseases. Its development also serves as a proof-of-concept for image-based detection of ophthalmic diseases in general and as a basis for its further use and expansion.",artificial intelligence; blindness; equine uveitis; horse; machine; deep learning; ophthalmology
Article,"Somasundaram, Krishnamoorthy; Sivakumar, Paulraj; Suresh, Durairaj",Classification of Diabetic Retinopathy Disease with Transfer Learning using Deep Convolutional Neural Networks,advances in electrical and computer engineering,2021,Not found,"Diabetic Retinopathy (DR) stays a main source of vision deterioration around world and it is getting exacerbated day by day. Almost no warning signs for detecting DR which will be greater challenge with us today. So, it is extremely preferred that DR has to be discovered on time. Adversely, the existing result involves an ophthalmologist to manually check and identify DR by positioning the exudates related with vascular irregularity due to diabetes from fundus image. In this work, we are able to classify images based on different severity levels through an automatic DR classification system. To extract specific features of image without any loss in spatial information, a Convolutional Neural Network (CNN) models which possesses an image with a distinct weight matrix is used. In the beginning, we estimate various CNN models to conclude the best performing CNN for DR classification with an objective to obtain much better accuracy. In the classification of DR disease with transfer learning using deep CNN models, 97.72% of accuracy is provided by the propOsed CNN model for Kaggle dataset. The proposed CNN model provides a classification accuracy of 97.58% for MESSIDOR dataset. The proposed technique provides better results than other state-of-art methods.",computer aided diagnosis; image classification; learning; neural networks; retimmathy
Article,"Sarki, Rubina; Ahmed, Khandakar; Wang, Hua; Zhang, Yanchun",Automatic Detection of Diabetic Eye Disease Through Deep Learning Using Fundus Images: A Survey,ieee access,2020,Not found,"Diabetes Mellitus, or Diabetes, is a disease in which a person's body fails to respond to insulin released by their pancreas, or it does not produce sufficient insulin. People suffering from diabetes are at high risk of developing various eye diseases over time. As a result of advances in machine learning techniques, early detection of diabetic eye disease using an automated system brings substantial benefits over manual detection. A variety of advanced studies relating to the detection of diabetic eye disease have recently been published. This article presents a systematic survey of automated approaches to diabetic eye disease detection from several aspects, namely: i) available datasets, ii) image preprocessing techniques, iii) deep learning models and iv) performance evaluation metrics. The survey provides a comprehensive synopsis of diabetic eye disease detection approaches, including state of the art field approaches, which aim to provide valuable insight into research communities, healthcare professionals and patients with diabetes.",diabetes; retina; machine learning; biomedical imaging; retinopathy; blood vessels; diabetic eye disease; diabetic retinopathy; deep leaning; glaucoma; image processing; macular edema; transfer learning
Article,"Huang, Chenxi; Zong, Yongshuo; Ding, Yimin; Luo, Xin; Clawson, Kathy; Peng, Yonghong",A new deep learning approach for the retinal hard exudates detection based on superpixel multi-feature extraction and patch-based CNN,neurocomputing,2021,Not found,"Diabetic Retinopathy (DR) is a severe complication of chronic diabetes causing significant visual deterioration and may lead to blindness with delay of being treated. Exudative diabetic maculopathy, a form of macular edema where hard exudates (HE) develop, is a frequent cause of visual deterioration in DR. The detection of HE comprises a significant role in the DR diagnosis. In this paper, an automatic exudates detection method based on superpixel multi-feature extraction and patch-based deep convolutional neural network is proposed. Firstly, superpixels, regarded as candidates, are generated on each resized image using the superpixel segmentation algorithm called Simple Linear Iterative Clustering (SLIC). Then, 25 features extracted from resized images and patches are generated on each feature. Patches are subsequently used to train a deep convolutional neural network, which distinguishes the hard exudates from the background. Experiments conducted on three publicly available datasets (DiaretDB1, e-ophtha EX and IDRiD) demonstrate that our proposed methodology achieved superior HE detection when compared with current state-of-art algorithms. (C) 2020 Elsevier B.V. All rights reserved.",retinal hard exudates; superpixel; feature extraction; deep learning; automatic diagnosis
Article,"Bhardwaj, Charu; Jain, Shruti; Sood, Meenakshi",Diabetic retinopathy severity grading employing quadrant-basedInception-V3convolution neural network architecture,international journal of imaging systems and technology,2021,Not found,Diabetic retinopathy (DR) accounts in eye-related disorders due to accumulated damage to small retinal blood vessels. Automated diagnostic systems are effective in early detection and diagnosis of severe eye complications by assisting the ophthalmologists. Deep learning-based techniques have emerged as an advancement over conventional techniques based on hand-crafted features. The authors have proposed a Quadrant-based automated DR grading system in this work using Inception-V3 deep neural network to extract small lesions present in retinal fundus images. The grading efficiency of the proposed architecture is improved utilizing image enhancement and optical disc removal pipeline along with data augmentation stage. The proposed system yields accuracy of 93.33% with minimized cross-entropy loss of 0.291. Capability of proposed system is demonstrated experimentally to provide efficient DR diagnosis. The diagnosis ability of the proposed architecture is demonstrated by state-of-the-art comparison with other mainstream convolution neural network models and a maximum improvement of 14.33% is observed.,convolution neural network; data augmentation; deep neural network; diabetic retinopathy; hand-crafted features
Article,"Hemamalini, Selvamani; Kumar, Visvam Devadoss Ambeth",Outlier Based Skimpy Regularization Fuzzy Clustering Algorithm for Diabetic Retinopathy Image Segmentation,symmetry-basel,2022,Not found,"Blood vessels are harmed in diabetic retinopathy (DR), a condition that impairs vision. Using modern healthcare research and technology, artificial intelligence and processing units are used to aid in the diagnosis of this syndrome and the study of diagnostic procedures. The correct assessment of DR severity requires the segmentation of lesions from fundus pictures. The manual grading method becomes highly difficult and time-consuming due to the wide range of the morphologies, number, and sizes of lesions. For image segmentation, traditional fuzzy clustering techniques have two major drawbacks. First, fuzzy memberships based clustering are more susceptible to outliers. Second, because of the lack of local spatial information, these techniques often result in oversegmentation of images. In order to address these issues, this research study proposes an outlier-based skimpy regularization fuzzy clustering technique (OSR-FCA) for image segmentation. Clustering methods that use fuzzy membership with sparseness can be improved by incorporating a Gaussian metric regularisation into the objective function. The proposed study used the symmetry information contained in the image data to conduct the image segmentation using the fuzzy clustering technique while avoiding over segmenting relevant data. This resulted in a reduced proportion of noisy data and better clustering results. The classification was carried out by a deep learning technique called convolutional neural network (CNN). Two publicly available datasets were used for the validation process by using different metrics. The experimental results showed that the proposed segmentation technique achieved 97.16% and classification technique achieved 97.26% of accuracy on the MESSIDOR dataset.",diabetic retinopathy; outliers; oversegmentation; spatial information; skimpy regularization; fuzzy clustering algorithm; deep learning technique
Proceedings Paper,"Chen, Qilei; Sun, Xinzi; Zhang, Ning; Cao, Yu; Liu, Benyuan",Mini Lesions Detection on Diabetic Retinopathy Images via Large Scale CNN Features,2019 ieee 31st international conference on tools with artificial intelligence (ictai 2019),2019,Not found,"Diabetic retinopathy (DR) is a diabetes complication that affects eyes. DR is a primary cause of blindness in working-age people and it is estimated that 3 to 4 million people with diabetes are blinded by DR every year worldwide. Early diagnosis have been considered an effective way to mitigate such problem. The ultimate goal of our research is to develop novel machine learning techniques to analyze the DR images generated by the fundus camera for automatically DR diagnosis. In this paper, we focus on identifying small lesions on DR fundus images. The results from our analysis, which include the lesion category and their exact locations in the image, can be used to facilitate the determination of DR severity (indicated by DR stages). Different from traditional object detection for natural images, lesion detection for fundus images have unique challenges. Specifically, the size of a lesion instance is usually very small, compared with the original resolution of the fundus images, making them diffcult to be detected. We analyze the lesion-vs-image scale carefully and propose a large-size feature pyramid network (LFPN) to preserve more image details for mini lesion instance detection. Our method includes an effective region proposal strategy to increase the sensitivity. The experimental results show that our proposed method is superior to the original feature pyramid network (FPN) method and Faster RCNN.",diabetic retinopathy; mini lesion detection; fpn
Proceedings Paper,"Bai, Yanmiao; Hao, Jinkui; Fu, Huazhu; Hu, Yan; Ge, Xinting; Liu, Jiang; Zhao, Yitian; Zhang, Jiong",Unsupervised Lesion-Aware Transfer Learning for Diabetic Retinopathy Grading in Ultra-Wide-Field Fundus Photography,"medical image computing and computer assisted intervention, miccai 2022, pt ii",2022,Not found,"Ultra-wide-field (UWF) fundus photography is a new imaging technique with providing a broader field of view images, and it has become a popular and effective tool for the screening and diagnosis for many eye diseases, such as diabetic retinopathy (DR). However, it is practically challenging to train a robust deep learning model for DR grading in UWF images, due to the limited scale of data and manual annotations. By contrast, we may find large-scale high-quality regular color fundus photography datasets in the research community, with either image-level or pixel-level annotation. In consequence, we propose an Unsupervised Lesion-aware TRAnsfer learning framework (ULTRA) for DR grading in UWF images, by leveraging a large amount of publicly well-annotated regular color fundus images. Inspired by the clinical identification of DR severity, i.e., the decision making process of ophthalmologists based on the type and number of associated lesions, we design an adversarial lesion map generator to provide the auxiliary lesion information for DR grading. A Lesion External Attention Module (LEAM) is introduced to integrate the lesion feature into the model, allowing a relative explainable DR grading. Extensive experimental results show the proposed method is superior to the state-of-the-art methods.",unsupervised; uwf imaging; diabetic retinopathy
Article,"Arcadu, Filippo; Benmansour, Fethallah; Maunz, Andreas; Willis, Jeff; Haskova, Zdenka; Prunotto, Marco",Deep learning algorithm predicts diabetic retinopathy progression in individual patients,npj digital medicine,2019,Not found,"The global burden of diabetic retinopathy (DR) continues to worsen and DR remains a leading cause of vision loss worldwide. Here, we describe an algorithm to predict DR progression by means of deep learning (DL), using as input color fundus photographs (CFPs) acquired at a single visit from a patient with DR. The proposed DL models were designed to predict future DR progression, defined as 2-step worsening on the Early Treatment Diabetic Retinopathy Diabetic Retinopathy Severity Scale, and were trained against DR severity scores assessed after 6, 12, and 24 months from the baseline visit by masked, well-trained, human reading center graders. The performance of one of these models (prediction at month 12) resulted in an area under the curve equal to 0.79. Interestingly, our results highlight the importance of the predictive signal located in the peripheral retinal fields, not routinely collected for DR assessments, and the importance of microvascular abnormalities. Our findings show the feasibility of predicting future DR progression by leveraging CFPs of a patient acquired at a single visit. Upon further development on larger and more diverse datasets, such an algorithm could enable early diagnosis and referral to a retina specialist for more frequent monitoring and even consideration of early intervention. Moreover, it could also improve patient recruitment for clinical trials targeting DR.",neural-network; severity; classification; validation; images; system
Article,"Prakruthi, M. K.; Komarasamy, G.",Novel Framework for Enhanced Learning-based Classification of Lesion in Diabetic Retinopathy,international journal of advanced computer science and applications,2022,Not found,"Diabetic retinopathy is an adverse medical condition resulting from a high level of blood sugar potentially affecting the retina and leading to permanent vision loss in its advanced stage of progression. A literature review is conducted to assess the effectiveness of existing approaches to find that Convolution Neural Network (CNN) has been frequently adopted for analyzing the fundus retinal image for detection and classification. However, existing scientific methods are mainly inclined towards achieving accuracy in their learning techniques without much deeper investigation of possibilities to improve the methodology of type using CNN. Therefore, the proposed scheme introduces a computational framework where a simplified feature enhancement operation is carried out, resulting in artifact-free images with better features. The enhanced image is then subjected to CNN to perform multiclass categorization of potential stages of diabetic retinopathy to see if it outperforms existing schemes.",diabetic retinopathy; convolution neural network; classification; fundus retinal image; multi-class categorization
Proceedings Paper,"Xia, Xue; Zhan, Kun; Li, Ying; Xiao, Guobei; Yan, Jinhua; Huang, Zhuxiang; Huang, Guofu; Fang, Yuming",Eye Disease Diagnosis and Fundus Synthesis: A Large-Scale Dataset and Benchmark,2022 ieee 24th international workshop on multimedia signal processing (mmsp),2022,Not found,"As one of the most common imaging modalities, retinal fundus imaging offers images of interior surface of eyes for initial examination of disorders. Data-driven machine learning methods, especially deep learning models in recent years, provide automatic ophthalmological disease diagnosis techniques from color fundus images. Data with high quality, diversity and balanced distribution supports deep model-based eye disease diagnosis. However, many existing datasets focus on a specific kind of eye disease, and some suffer from label noise or quality degeneration, which hinders automatic screening algorithms from dealing with multiple eye diseases. To solve this, we propose a high-quality dataset containing 28877 color fundus images for deep learning-based diagnosis. Except for 15000 healthy samples, the dataset consists of 8 eye disorders including diabetic retinopathy, age-related macular degeneration, glaucoma, pathological myopia, hypertension, retinal vein occlusion, LASIK spot and others. Based on this, we propose a co-attention network for disease diagnosis, establish benchmark on screening and grading tasks, and demonstrate that the proposed dataset supports generative adversarial network-based image synthesis. The dataset will be made publicly available.",dataset; eye disease diagnosis; fundus sythesis
Article,"Deepa, V.; Kumar, C. Sathish; Cherian, Thomas",Ensemble of multi-stage deep convolutional neural networks for automated grading of diabetic retinopathy using image patches,journal of king saud university-computer and information sciences,2022,Not found,"Diabetic retinopathy (DR) is one of the most common retinal diseases that cause preventable blindness in diabetic patients. The timely screening and grading of retinal images minimize the possibility of vision loss. However, manual screening of retinal images, for detecting micro lesions in the early stages of DR, is time-consuming. This paper proposes an ensemble of deep convolutional neural network (CNN) models for accurate detection and grading of DR using fundus images. Each input image is divided into four patches at the first stage and passed on to pre-trained CNN models (InceptionV3, Xception) for train-ing. The relevant features in the shallow-dense layers of CNN models are utilized as prior knowledge. The integration of shallow and dense layer features helps the model learn the significant information of DR images. At the second stage, a classifier based on artificial neural network is trained using the fused prob-ability vectors of four patches. The results of individual CNN models are combined to generate the final decision in the third stage. This ensemble approach of multi-stage deep learning model improves the overall classification accuracy of diabetic retinopathy grading. Among the five different classification schemes presented in this paper, multistage patch-based deep CNN (MPDCNN), in which local patch -based and holistic details of fundus image are concatenated, provides the best classification accuracy. This ensemble classifier exhibits 96.2 % classification accuracy with fivefold cross-validation. (c) 2021 The Authors. Published by Elsevier B.V. on behalf of King Saud University. This is an open access article under the CC BY-NC-ND license (http://creativecommons.org/licenses/by-nc-nd/4.0/).",diabetic retinopathy; image patches; ensemble; shallow and dense layer features; pre-trained cnn models
Article; Early Access,"Chandrasekaran, Raja; Loganathan, Balaji",Retinopathy grading with deep learning and wavelet hyper-analytic activations,visual computer,0,Not found,"Recent developments reveal the prominence of Diabetic Retinopathy (DR) grading. In the past few decades, Wavelet-based DR classification has shown successful impacts and the Deep Learning models, like Convolutional Neural Networks (CNN's), have evolved in offering the highest prediction accuracy. In this work, the features of the input image are enhanced with the integration of Multi-Resolution Analysis (MRA) and a CNN framework without costing more convolution filters. The bottleneck with conventional activation functions, used in CNN's, is the nullification of the feature maps that are negative in value. In this work, a novel Hyper-analytic Wavelet (HW) phase activation function is formulated with unique characteristics for the wavelet sub-bands. Instead of dismissal, the function transforms these negative coefficients that correspond to significant edge feature maps. The hyper-analytic wavelet phase forms the imaginary part of the complex activation. And the hyper-parameter of the activation function is selected such that the corresponding magnitude spectrum produces monotonic and effective activations. The performance of 3 CNN models (1 custom, shallow CNN, ResNet with Soft attention, Alex Net for DR) with spatial-Wavelet quilts is better. With the spatial-Wavelet quilts, the Alex Net for DR has an improvement with an 11% of accuracy level (from 87 to 98%). The highest accuracy level of 98% and the highest Sensitivity of 99% are attained through Modified Alex Net for DR. The proposal also illustrates the visualization of the negative edge preservation with assumed image patches. From this study, the researcher infers that models with spatial-Wavelet quilts, with the hyper-analytic activations, have better generalization ability. And the visualization of heat maps provides evidence of better learning of the feature maps from the wavelet sub-bands.",diabetic retinopathy; cnn; wavelets; spatial-wavelet inputs; complex activations
Review,"Zhu, Taiyu; Li, Kezhi; Herrero, Pau; Georgiou, Pantelis",Deep Learning for Diabetes: A Systematic Review,ieee journal of biomedical and health informatics,2021,Not found,"Diabetes is a chronic metabolic disorder that affects an estimated 463 million people worldwide. Aiming to improve the treatment of people with diabetes, digital health has been widely adopted in recent years and generated a huge amount of data that could be used for further management of this chronic disease. Taking advantage of this, approaches that use artificial intelligence and specifically deep learning, an emerging type of machine learning, have been widely adopted with promising results. In this paper, we present a comprehensive review of the applications of deep learning within the field of diabetes. We conducted a systematic literature search and identified three main areas that use this approach: diagnosis of diabetes, glucose management, and diagnosis of diabetes-related complications. The search resulted in the selection of 40 original research articles, of which we have summarized the key information about the employed learning models, development process, main outcomes, and baseline methods for performance evaluation. Among the analyzed literature, it is to be noted that various deep learning techniques and frameworks have achieved state-of-the-art performance in many diabetes-related tasks by outperforming conventional machine learning approaches. Meanwhile, we identify some limitations in the current literature, such as a lack of data availability and model interpretability. The rapid developments in deep learning and the increase in available data offer the possibility to meet these challenges in the near future and allow the widespread deployment of this technology in clinical settings.",diabetes; deep learning; insulin; glucose; task analysis; training; machine learning; artificial intelligence; deep learning; deep neural networks; diabetes; diabetic complications; glucose management
Article,"Yadav, Nirmal",A deep data-driven approach for enhanced segmentation of blood vessel for diabetic retinopathy,international journal of imaging systems and technology,2022,Not found,"The segmentation step of retinal blood vessel helps to diagnosis the diseases including diabetic retinopathy, glaucoma, etc. The automatic image segmentation process helps experts to speed up the diagnosis of DR, since analytic methods are time consuming and error prone. The neural network (NN) based methods like U-Net uses leap bonding that extract fine information from the training dataset. However automatic segmentation of image using neural network is a challenging process because of uneven and irregular geometry of organ. In this article, we proposed a U-Net based approach for segmentation of retinal vessels. Before applying segmentation step, the affected area of image is enhanced with some preprocessing techniques. Then a dual tree discrete Ridgelet transform (DT-DRT) is apply on the dataset to extract the features from the region of interest. The features accumulation with DT-DRT ensures better feature representation of vessel for segmentation task. The proposed segmentation is implemented on different publicly available dataset and achieve accuracy of 96.01% in CHASE DB1, 97.65% in DRIVE and 98.61% in STARE dataset. The performance of this algorithm is also compared with some other deep learning models, and results demonstrate that this proposed algorithm performed better than them.",deep learning model; neural networks; radon transform; wavelet transform
Article,"He, Mingguang; Li, Zhixi; Liu, Chi; Shi, Danli; Tan, Zachary",Deployment of Artificial Intelligence in Real-World Practice: Opportunity and Challenge,asia-pacific journal of ophthalmology,2020,Not found,"Artificial intelligence has rapidly evolved from the experimental phase to the implementation phase in many image-driven clinical disciplines, including ophthalmology. A combination of the increasing availability of large datasets and computing power with revolutionary progress in deep learning has created unprecedented opportunities for major breakthrough improvements in the performance and accuracy of automated diagnoses that primarily focus on image recognition and feature detection. Such an automated disease classification would significantly improve the accessibility, efficiency, and cost-effectiveness of eye care systems where it is less dependent on human input, potentially enabling diagnosis to be cheaper, quicker, and more consistent. Although this technology will have a profound impact on clinical flow and practice patterns sooner or later, translating such a technology into clinical practice is challenging and requires similar levels of accountability and effectiveness as any new medication or medical device due to the potential problems of bias, and ethical, medical, and legal issues that might arise. The objective of this review is to summarize the opportunities and challenges of this transition and to facilitate the integration of artificial intelligence (AI) into routine clinical practice based on our best understanding and experience in this area.",artificial intelligence; deployment; real-world
Article,"Yang, Jingyuan; Zhang, Chenxi; Wang, Erqian; Chen, Youxin; Yu, Weihong",Utility of a public-available artificial intelligence in diagnosis of polypoidal choroidal vasculopathy,graefes archive for clinical and experimental ophthalmology,2020,Not found,"Purpose To investigate the feasibility of training an artificial intelligence (AI) on a public-available AI platform to diagnose polypoidal choroidal vasculopathy (PCV) using indocyanine green angiography (ICGA). Methods Two methods using AI models were trained by a data set including 430 ICGA images of normal, neovascular age-related macular degeneration (nvAMD), and PCV eyes on a public-available AI platform. The one-step method distinguished normal, nvAMD, and PCV images simultaneously. The two-step method identifies normal and abnormal ICGA images at the first step and diagnoses PCV from the abnormal ICGA images at the second step. The method with higher performance was used to compare with retinal specialists and ophthalmologic residents on the performance of diagnosing PCV. Results The two-step method had better performance, in which the precision was 0.911 and the recall was 0.911 at the first step, and the precision was 0.783, and the recall was 0.783 at the second step. For the test data set, the two-step method distinguished normal and abnormal images with an accuracy of 1 and diagnosed PCV with an accuracy of 0.83, which was comparable to retinal specialists and superior to ophthalmologic residents. Conclusion In this evaluation of ICGA images from normal, nvAMD, and PCV eyes, the models trained on a public-available AI platform had comparable performance to retinal specialists for diagnosing PCV. The utility of public-available AI platform might help everyone including ophthalmologists who had no AI-related resources, especially those in less developed areas, for future studies.",artificial intelligence; deep learning; diagnosis; indocyanine green angiography; machine learning; polypoidal choroidal vasculopathy
Article,"Ibrahim, Mohamed Ramzy; Fathalla, Karma M.; Youssef, Sherin M.",HyCAD-OCT: A Hybrid Computer-Aided Diagnosis of Retinopathy by Optical Coherence Tomography Integrating Machine Learning and Feature Maps Localization,applied sciences-basel,2020,Not found,"Optical Coherence Tomography (OCT) imaging has major advantages in effectively identifying the presence of various ocular pathologies and detecting a wide range of macular diseases. OCT examinations can aid in the detection of many retina disorders in early stages that could not be detected in traditional retina images. In this paper, a new hybrid computer-aided OCT diagnostic system (HyCAD) is proposed for classification of Diabetic Macular Edema (DME), Choroidal Neovascularization (CNV) and drusen disorders, while separating them from Normal OCT images. The proposed HyCAD hybrid learning system integrates the segmentation of Region of Interest (RoI), based on central serious chorioretinopathy (CSC) in Spectral Domain Optical Coherence Tomography (SD-OCT) images, with deep learning architectures for effective diagnosis of retinal disorders. The proposed system assimilates a range of techniques including RoI localization and feature extraction, followed by classification and diagnosis. An efficient feature fusion phase has been introduced for combining the OCT image features, extracted by Deep Convolutional Neural Network (CNN), with the features extracted from the RoI segmentation phase. This fused feature set is used to predict multiclass OCT retina disorders. The proposed segmentation phase of retinal RoI regions adds substantial contribution as it draws attention to the most significant areas that are candidate for diagnosis. A new modified deep learning architecture (Norm-VGG16) is introduced integrating a kernel regularizer. Norm-VGG16 is trained from scratch on a large benchmark dataset and used in RoI localization and segmentation. Various experiments have been carried out to illustrate the performance of the proposed system. Large Dataset of Labeled Optical Coherence Tomography (OCT) v3 benchmark is used to validate the efficiency of the model compared with others in literature. The experimental results show that the proposed model achieves relatively high-performance in terms of accuracy, sensitivity and specificity. An average accuracy, sensitivity and specificity of 98.8%, 99.4% and 98.2% is achieved, respectively. The remarkable performance achieved reflects that the fusion phase can effectively improve the identification ratio of the urgent patients' diagnostic images and clinical data. In addition, an outstanding performance is achieved compared to others in literature.",deep learning; cnn; feature generation; feature fusion; roi segmentation; oct; retina disorders
Article,"Santos, Carlos; Aguiar, Marilton; Welfer, Daniel; Belloni, Bruno",A New Approach for Detecting Fundus Lesions Using Image Processing and Deep Neural Network Architecture Based on YOLO Model,sensors,2022,Not found,"Diabetic Retinopathy is one of the main causes of vision loss, and in its initial stages, it presents with fundus lesions, such as microaneurysms, hard exudates, hemorrhages, and soft exudates. Computational models capable of detecting these lesions can help in the early diagnosis of the disease and prevent the manifestation of more severe forms of lesions, helping in screening and defining the best form of treatment. However, the detection of these lesions through computerized systems is a challenge due to numerous factors, such as the characteristics of size and shape of the lesions, noise and the contrast of images available in the public datasets of Diabetic Retinopathy, the number of labeled examples of these lesions available in the datasets and the difficulty of deep learning algorithms in detecting very small objects in digital images. Thus, to overcome these problems, this work proposes a new approach based on image processing techniques, data augmentation, transfer learning, and deep neural networks to assist in the medical diagnosis of fundus lesions. The proposed approach was trained, adjusted, and tested using the public DDR and IDRiD Diabetic Retinopathy datasets and implemented in the PyTorch framework based on the YOLOv5 model. The proposed approach reached in the DDR dataset an mAP of 0.2630 for the IoU limit of 0.5 and F1-score of 0.3485 in the validation stage, and an mAP of 0.1540 for the IoU limit of 0.5 and F1-score of 0.2521, in the test stage. The results obtained in the experiments demonstrate that the proposed approach presented superior results to works with the same purpose found in the literature.",diabetic retinopathy; fundus images; lesions detection; deep learning; yolo
Article,"Chen, Jimmy S.; Coyner, Aaron S.; Ostmo, Susan; Sonmez, Kemal; Bajimaya, Sanyam; Pradhan, Eli; Valikodath, Nita; Cole, Emily D.; Al-Khaled, Tala; Chan, R. V. Paul; Singh, Praveer; Kalpathy-Cramer, Jayashree; Chiang, Michael F.; Campbell, J. Peter",Deep Learning for the Diagnosis of Stage in Retinopathy of Prematurity Accuracy and Generalizability across Populations and Cameras,ophthalmology retina,2021,Not found,"Purpose: Stage is an important feature to identify in retinal images of infants at risk of retinopathy of prematurity (ROP). The purpose of this study was to implement a convolutional neural network (CNN) for binary detection of stages 1, 2, and 3 in ROP and to evaluate its generalizability across different populations and camera systems. Design: Diagnostic validation study of CNN for stage detection. Participants: Retinal fundus images obtained from preterm infants during routine ROP screenings. Methods: Two datasets were used: 5943 fundus images obtained by RetCam camera (Natus Medical, Pleasanton, CA) from 9 North American institutions and 5049 images obtained by 3nethra camera (Forus Health Incorporated, Bengaluru, India) from 4 hospitals in Nepal. Images were labeled based on the presence of stage by 1 to 3 expert graders. Three CNN models were trained using 5-fold cross-validation on datasets from North America alone, Nepal alone, and a combined dataset and were evaluated on 2 held-out test sets consisting of 708 and 247 images from the Nepali and North American datasets, respectively. Main Outcome Measures: Convolutional neural network performance was evaluated using area under the receiver operating characteristic curve (AUROC), area under the precision-recall curve (AUPRC), sensitivity, and specificity. Results: Both the North American- and Nepali-trained models demonstrated high performance on a test set from the same population: AUROC, 0.99; AUPRC, 0.98; sensitivity, 94%; and AUROC, 0.97; AUPRC, 0.91; and sensitivity, 73%; respectively. However, the performance of each model decreased to AUROC of 0.96 and AUPRC of 0.88 (sensitivity, 52%) and AUROC of 0.62 and AUPRC of 0.36 (sensitivity, 44%) when evaluated on a test set from the other population. Compared with the models trained on individual datasets, the model trained on a combined dataset achieved improved performance on each respective test set: sensitivity improved from 94% to 98% on the North American test set and from 73% to 82% on the Nepali test set. Conclusions: A CNN can identify accurately the presence of ROP stage in retinal images, but performance depends on the similarity between training and testing populations. We demonstrated that internal and external performance can be improved by increasing the heterogeneity of the training dataset features of the training dataset, in this case by combining images from different populations and cameras. (C) 2020 by the American Academy of Ophthalmology",artificial intelligence; generalizability; neural networks; retinopathy of prematurity; stage
Article,"Pedrosa, Micael; Silva, Jorge Miguel; Silva, Joao Figueira; Matos, Sergio; Costa, Carlos",SCREEN-DR: Collaborative platform for diabetic retinopathy,international journal of medical informatics,2018,Not found,"Background and objective: Diabetic retinopathy (DR) is the most prevalent microvascular complication of diabetes mellitus and can lead to irreversible visual loss. Screening programs, based on retinal imaging techniques, are fundamental to detect the disease since the initial stages are asymptomatic. Most of these examinations reflect negative cases and many have poor image quality, representing an important inefficiency factor. The SCREEN-DR project aims to tackle this limitation, by researching and developing computer-aided methods for diabetic retinopathy detection. This article presents a multidisciplinary collaborative platform that was created to meet the needs of physicians and researchers, aiming at the creation of machine learning algorithms to facilitate the screening process. Methods: Our proposal is a collaborative platform for textual and visual annotation of image datasets. The architecture and layout were optimized for annotating DR images by gathering feedback from several physicians during the design and conceptualization of the platform. It allows the aggregation and indexing of imagiology studies from diverse sources, and supports the creation and annotation of phenotype-specific datasets to feed artificial intelligence algorithms. The platform makes use of an anonymization pipeline and role-based access control for securing personal data. Results: The SCREEN-DR platform has been deployed in the production environment of the SCREEN-DR project at http://demo.dicoogle.com/screen-dr, and the source code of the project is publicly available. We provide a description of the platform's interface and use cases it supports. At the time of publication, four physicians have created a total of 1826 annotations for 701 distinct images, and the annotated data has been used for training classification models.",diabetic retinopathy screening; collaborative pacs; telemedicine; computer-aided diagnosis; image annotation
Proceedings Paper,"Khan, Muhammad Zubair; Lee, Yugyung",Ocular Inspection to Prevent Vision Impairment Caused by Diabetic Retinopathy,2021 4th international conference on information and computer technologies (icict 2021),2021,Not found,"The retina is a unique tissue, considered an extension of the human brain that transforms the incoming light into neural signals. Many significant ocular diseases exhibit themselves in this central hub. Retinal images, therefore, play a vital part in the early detection of these chronic complications. Besides, the advancement of machine learning and biomedical imaging techniques has opened the doors for modern-day researchers to uncover life-threatening problems, such as diabetic retinopathy. This disease is common in middle-aged adults. It weakens the inner surface of retinal vessels, causing vision impairment. The precise diagnosis of diabetic retinopathy needs a computer-guided tool to automate the vessel extraction process. This article applied sequence block with U-Net architecture to segment ocular vasculature. Our approach efficiently used neighboring pixels to predict retinal vessels and generate a segmentation map with a baseline encoder-decoder structure. The vanishing gradient problem is resolved with long-term skip connections. The proposed approach is compared with state-of-the-art work. It is found that the sequence block boosted the U-Net performance on DRIVE and STARE datasets. The underlying method is an effort to limit the human biasness and error in ocular inspection and reduce the vision impairment rate in masses.",deep learning; retinal vessels; image segmentation; diabetic retinopathy; sequence model
Article,"Sanchez-Morla, Eva M.; Fuentes, Juan L.; Miguel-Jimenez, Juan M.; Boquete, Luciano; Ortiz, Miguel; Orduna, Elvira; Satue, Maria; Garcia-Martin, Elena",Automatic Diagnosis of Bipolar Disorder Using Optical Coherence Tomography Data and Artificial Intelligence,journal of personalized medicine,2021,Not found,"Background: The aim of this study is to explore an objective approach that aids the diagnosis of bipolar disorder (BD), based on optical coherence tomography (OCT) data which are analyzed using artificial intelligence. Methods: Structural analyses of nine layers of the retina were analyzed in 17 type I BD patients and 42 controls, according to the areas defined by the Early Treatment Diabetic Retinopathy Study (ETDRS) chart. The most discriminating variables made up the feature vector of several automatic classifiers: Gaussian Naive Bayes, K-nearest neighbors and support vector machines. Results: BD patients presented retinal thinning affecting most layers, compared to controls. The retinal thickness of the parafoveolar area showed a high capacity to discriminate BD subjects from healthy individuals, specifically for the ganglion cell (area under the curve (AUC) = 0.82) and internal plexiform (AUC = 0.83) layers. The best classifier showed an accuracy of 0.95 for classifying BD versus controls, using as variables of the feature vector the IPL (inner nasal region) and the INL (outer nasal and inner inferior regions) thickness. Conclusions: Our patients with BD present structural alterations in the retina, and artificial intelligence seem to be a useful tool in BD diagnosis, but larger studies are needed to confirm our findings.",bipolar disorder; optical coherence tomography; neuroprogression; artificial intelligence
Article,"Li, Xiang; Jiang, Yuchen; Zhang, Jiusi; Li, Minglei; Luo, Hao; Yin, Shen",Lesion-attention pyramid network for diabetic retinopathy grading,artificial intelligence in medicine,2022,Not found,"As one of the most common diabetic complications, diabetic retinopathy (DR) can cause retinal damage, vision loss and even blindness. Automated DR grading technology has important clinical significance, which can help ophthalmologists achieve rapid and early diagnosis. With the popularity of deep learning, DR grading based on the convolutional neural networks (CNNs) has become the mainstream method. Unfortunately, although the CNN-based method can achieve satisfactory diagnostic accuracy, it lacks significant clinical information. In this paper, a lesion-attention pyramid network (LAPN) is presented. The pyramid network integrates the subnetworks with different resolutions to get multi-scale features. In order to take the lesion regions in the high-resolution image as the diagnostic evidence, the low-resolution network calculates the lesion activation map (using the weakly-supervised localization method) and guides the high-resolution network to concentrate on the lesion regions. Furthermore, a lesion attention module (LAM) is designed to capture the complementary relationship between the high-resolution features and the low-resolution features, and to fuse the lesion activation map. Experiment results show that the proposed scheme outperforms other existing approaches, and the proposed method can provide lesion activation map with lesion consistency as an additional evidence for clinical diagnosis.",diabetic retinopathy; pyramid network; attention mechanism; convolutional neural network
Proceedings Paper,"Jain, Lorick; Murthy, H. V. Srinivasa; Patel, Chirayush; Bansal, Devansh",Retinal Eye Disease Detection Using Deep Learning,2018 fourteenth international conference on information processing (icinpro) - 2018,2018,Not found,"Retinal fundus images are a valuable source of information for ophthalmologists to diagnose retina problems. Early detection can improve chances of cure and also prevent blindness. Retinal problems like diabetic retinopathy, retinitis pigmentosa can be diagnosed using retinal fundus images by medical experts. In recent times, machine learning research has focused on diagnosing diseases like diabetic retinopathy by extracting features and then classifying the image. In this research our goal is to automatically classify images with retinal problems from those of the healthy ones without performing any explicit segmentation or feature extraction. Rather, we use a deep learning model to automatically classify any retinal fundus image as healthy or diseased. The architecture of the network is both simple and fast. The model has been tested on two datasets, including real patient retinal fundus images obtained from a local hospital. The accuracy of this model has been found to be in the range 96.5 % to 99.7%.",retinal diagnosis; cnn; deep learning; machine learning; automated diagnosis
Article,"Al-Timemy, Ali H.; Mosa, Zahraa M.; Alyasseri, Zaid; Lavric, Alexandru; Lui, Marcelo M.; Hazarbassanov, Rossen M.; Yousefi, Siamak",A Hybrid Deep Learning Construct for Detecting Keratoconus From Corneal Maps,translational vision science & technology,2021,Not found,"Purpose: To develop and assess the accuracy of a hybrid deep learning construct for detecting keratoconus (KCN) based on corneal topographic maps. Methods: We collected 3794 corneal images from 542 eyes of 280 subjects and devel-oped seven deep learning models based on anterior and posterior eccentricity, anterior and posterior elevation, anterior and posterior sagittal curvature, and corneal thick-ness maps to extract deep corneal features. An independent subset with 1050 images collected from 150 eyes of 85 subjects from a separate center was used to validate models. We developed a hybrid deep learning model to detect KCN. We visualized deep features of corneal parameters to assess the quality of learning subjectively and computed area under the receiver operating characteristic curve (AUC), confusion matri-ces, accuracy, and F1 score to evaluate models objectively. Results: In the development dataset, 204 eyes were normal, 123 eyes were suspected KCN, and 215 eyes had KCN. In the independent validation dataset, 50 eyes were normal, 50 eyes were suspected KCN, and 50 eyes were KCN. Images were annotated by three corneal specialists. The AUC of the models for the two-class and three-class problems based on the development set were 0.99 and 0.93, respectively. Conclusions: The hybrid deep learning model achieved high accuracy in identifying KCN based on corneal maps and provided a time-efficient framework with low compu-tational complexity. Translational Relevance: Deep learning can detect KCN from non-invasive corneal images with high accuracy, suggesting potential application in research and clinical practice to identify KCN.",artificial intelligence; deep learning; corneal imaging; keratoconus; automated diagnosis
Article,"Farag, Mohamed M.; Fouad, Mariam; Abdel-Hamid, Amr T.",Automatic Severity Classification of Diabetic Retinopathy Based on DenseNet and Convolutional Block Attention Module,ieee access,2022,Not found,"Diabetic Retinopathy (DR) - a complication developed due to heightened blood glucose levels- is deemed one of the most sight-threatening diseases. Unfortunately, DR screening is manually acquired by an ophthalmologist, a process that can be considered erroneous and time-consuming. Accordingly, automated DR diagnostics have become a focus of research in recent years due to the tremendous increase in diabetic patients. Moreover, the recent accomplishments demonstrated by Convolutional Neural Networks (CNN) settle them as state-of-the-art for DR stage identification. This paper proposes a new automatic deep-learning-based approach for severity detection by utilizing a single Color Fundus photograph (CFP). The proposed technique employs DenseNet169's encoder to construct a visual embedding. Furthermore, Convolutional Block Attention Module (CBAM) is introduced on top of the encoder to reinforce its discriminative power. Finally, the model is trained using cross-entropy loss on the Kaggle Asia Pacific Tele-Ophthalmology Society's (APTOS) dataset. On the binary classification task, we accomplished (97% accuracy - 97% sensitivity - 98.3% specificity - 0.9455, Quadratic Weighted Kappa score (QWK)) compared to the state-of-the-art. Moreover, Our network showed high competency (82% accuracy - 0.888 (QWK)) for severity grading. The significant contribution of the proposed framework is that it efficiently grades the severity level of diabetic retinopathy while reducing the time and space complexity required, which demonstrates it as a promising candidate for autonomous diagnosis.",diabetes; retinopathy; task analysis; convolutional neural networks; computer architecture; feature extraction; retina; diabetic retinopathy; convolutional neural networks (cnn); attention mechanism; deep learning
Proceedings Paper,"Karki, Sagar Suresh; Kulkarni, Pradnya",Diabetic Retinopathy Classification using a Combination of EfficientNets,2021 international conference on emerging smart computing and informatics (esci),2021,Not found,"Diabetic Retinopathy (DR) is a diabetes complication that affects vision. It is caused by damage to the blood vessels of retina. Early and accurate detection of DR is crucial to reduce likelihood of progression to proliferative retinopathy and blindness. This paper proposes a method for classifying the severity of DR using deep learning. Experiments were conducted by blending the members of EfficientNet for classification of the diabetic retinopathy image as no DR, mild, moderate, severe, or proliferative DR. The models have been trained using different datasets and best model achieved a quadratic kappa score of 0.924377 on the APTOS test dataset. The results are promising and warrant further investigation. The presented model has the potential aid in fast diagnosis for better early detection of DR.",cnn; retinopathy; aptos; efficientnet; bce loss
Article,"Huang, Shiqi; Li, Jianan; Xiao, Yuze; Shen, Ning; Xu, Tingfa",RTNet: Relation Transformer Network for Diabetic Retinopathy Multi-Lesion Segmentation,ieee transactions on medical imaging,2022,Not found,"Automatic diabetic retinopathy (DR) lesions segmentation makes great sense of assisting ophthalmologists in diagnosis. Although many researches have been conducted on this task, most prior works paid too much attention to the designs of networks instead of considering the pathological association for lesions. Through investigating the pathogenic causes of DR lesions in advance, we found that certain lesions are closed to specific vessels and present relative patterns to each other. Motivated by the observation, we propose a relation transformer block (RTB) to incorporate attention mechanisms at two main levels: a self-attention transformer exploits global dependencies among lesion features, while a cross-attention transformer allows interactions between lesion and vessel features by integrating valuable vascular information to alleviate ambiguity in lesion detection caused by complex fundus structures. In addition, to capture the small lesion patterns first, we propose a global transformer block (GTB) which preserves detailed information in deep network. By integrating the above blocks of dual-branches, our network segments the four kinds of lesions simultaneously. Comprehensive experiments on IDRiD and DDR datasets well demonstrate the superiority of our approach, which achieves competitive performance compared to state-of-the-arts.",lesions; transformers; image segmentation; pathology; task analysis; head; feature extraction; diabetic retinopathy; fundus image; semantic segmentation; transformer; deep learning
Article,"Bodapati, Jyostna Devi",Stacked convolutional auto-encoder representations with spatial attention for efficient diabetic retinopathy diagnosis,multimedia tools and applications,2022,Not found,"Recently, the attention mechanism has been effectively implemented in convolutional neural networks to boost performance of several computer vision tasks. Recognizing the potential of the attention mechanism in medical imaging, we present an end-to-end-trainable spatial Attention based convolutional neural network architecture for recognizing diabetic retinopathy severity level. Initially spatial representations of the fundus images are projected to reduced space using a stacked convolutional Auto-Encoder. In order to enhance discrimination in reduced space, the auto-encoder is jointly trained with the classifier in an end-to-end manner. Attention mechanism introduced in the classification module ensures high emphasis on lesion regions compared to the non-lesion regions. The proposed model is evaluated on two benchmark datasets, and the experimental outcomes indicate that joint training favors stability and complements the learned representations when used along with attention. The proposed approach outperforms several existing models by achieving an accuracy of 84.17%, 63.24% respectively on Kaggle APTOS19 and IDRiD datasets. In addition, ablation studies validate our contributions and the behavior of the proposed model on both the datasets.",diabetic retinopathy; convolutional neural networks; spatial attention; convolutional auto-encoder; neural induced support vector machine; attention; deep features
Review,"Vaz-Pereira, Sara; Morais-Sarmento, Tiago; Engelbert, Michael",Update on Optical Coherence Tomography and Optical Coherence Tomography Angiography Imaging in Proliferative Diabetic Retinopathy,diagnostics,2021,Not found,"Proliferative diabetic retinopathy (PDR) is a major cause of blindness in diabetic individuals. Optical coherence tomography (OCT) and OCT-angiography (OCTA) are noninvasive imaging techniques useful for the diagnosis and assessment of PDR. We aim to review several recent developments using OCT and discuss their present and potential future applications in the clinical setting. An electronic database search was performed so as to include all studies assessing OCT and/or OCTA findings in PDR patients published from 1 January 2020 to 31 May 2021. Thirty studies were included, and the most recently published data essentially focused on the higher detection rate of neovascularization obtained with widefield-OCT and/or OCTA (WF-OCT/OCTA) and on the increasing quality of retinal imaging with quality levels non-inferior to widefield-fluorescein angiography (WF-FA). There were also significant developments in the study of retinal nonperfusion areas (NPAs) using these techniques and research on the impact of PDR treatment on NPAs and on vascular density. It is becoming increasingly clear that it is critical to use adequate imaging protocols focused on optimized segmentation and maximized imaged retinal area, with ongoing technological development through artificial intelligence and deep learning. These latest findings emphasize the growing applicability and role of noninvasive imaging in managing PDR with the added benefit of avoiding the repetition of invasive conventional FA.</p>",diabetic retinopathy; proliferative diabetic retinopathy; retinal neovascularization; optical coherence tomography; optical coherence tomography angiography
Article,"Li, Yujie; Song, Zhang; Kang, Sunkyoung; Jung, Sungtae; Kang, Wenpei",Semi-Supervised Auto-Encoder Graph Network for Diabetic Retinopathy Grading,ieee access,2021,Not found,"Diabetic Retinopathy (DR) causes quite a few blindness worldwide, which can be refrained by the timely diagnosis on retinal images. Recently, researches on deep learning-based retinal image classification have accelerated outstanding improvements in DR grading task. However, existing DR grading works are mostly limited to a supervised manner. They require accurately annotated data labeled by professional experts, and the annotating work is very laborious and time-consuming. We propose a Semi-supervised Auto-encoder Graph Network (SAGN) for the challenging DR diagnosis to relax this constraint. Precisely, SAGN consists of three major modules: auto-encoder feature learning, neighbor correlation mining, and graph representation. Firstly, our model learns to extract representations from retinal images and reconstruct them as close to original inputs as possible. Then neighbor correlations among labeled and unlabeled samples are established by their similarities, calculated by the radial basis function. Finally, we operate Graph Convolutional Neural Network (GCN) to grade retinal samples from extracted features and their correlations. To evaluate the performance of SAGN, we conduct sufficient comparative experiments on APTOS 2019 dataset, trained from EyePACS. Results demonstrate that our SAGN model can achieve comparable performance with limited labeled retinal images with the help of large amounts of unlabeled data.",retina; feature extraction; correlation; training; task analysis; annotations; convolutional neural networks; diabetic retinopathy grading; semi-supervised learning; auto-encoder; graph convolutional network
Article,"Zheng, Liwen; Wang, Haolin; Mei, Li; Chen, Qiuman; Zhang, Yuxin; Zhang, Hongmei",Artificial intelligence in digital cariology: a new tool for the diagnosis of deep caries and pulpitis using convolutional neural networks,annals of translational medicine,2021,Not found,"Background: An accurate diagnosis of deep caries and pulpitis on periapical radiographs is a clinical challenge. Methods: A total of 844 radiographs were included in this study. Of the 844, 717 (85%) were used for training and 127 (15%) were used for testing the three convolutional neural networks (CNNs) (VGG19, Inception V3, and ResNet18). The performance [accuracy, precision, sensitivity, specificity, and the area under the receiver operating characteristic curve (AUC)] of the CNNs were evaluated and compared. The CNN model with the best performance was further integrated with clinical parameters to see whether multimodal CNN could provide an enhanced performance. The Gradient-weighted Class Activation Mapping (Grad-CAM) technique illustrates what image feature was the most important for the CNNs. Results: The CNN of ResNet18 demonstrated the best performance [accuracy =0.82, 95% confidence interval (CI): 0.80-0.84; precision =0.81, 95% CI: 0.73-0.89; sensitivity =0.85, 95% CI: 0.79-0.91; specificity =0.82, 95% CI: 0.76-0.88; and AUC =0.89, 95% CI: 0.86-0.92], compared with VGG19 and Inception V3 as well as the comparator dentists. Therefore, ResNet18 was chosen to integrate with clinical parameters to produce the multi-modal CNN of ResNet18 + C, which showed a significantly enhanced performance (accuracy =0.86, 95% CI: 0.84-0.88; precision =0.85, 95% CI: 0.76-0.94; sensitivity =0.89, 95% CI: 0.83-0.95; specificity =0.86, 95% CI: 0.79-0.93; and AUC =0.94, 95% CI: 0.91-0.97). Conclusions: The CNN of ResNet18 showed good performance (accuracy, precision, sensitivity, specificity, and AUC) for the diagnosis of deep caries and pulpitis. The multi-modal CNN of ResNet18 + C (ResNet18 integrated with clinical parameters) demonstrated a significantly enhanced performance, with Background: An accurate diagnosis of deep caries and pulpitis on periapical radiographs is a clinical challenge. Methods: A total of 844 radiographs were included in this study. Of the 844, 717 (85%) were used for training and 127 (15%) were used for testing the three convolutional neural networks (CNNs) (VGG19, Inception V3, and ResNet18). The performance [accuracy, precision, sensitivity, specificity, and the area under the receiver operating characteristic curve (AUC)] of the CNNs were evaluated and compared. The CNN model with the best performance was further integrated with clinical parameters to see whether multi modal CNN could provide an enhanced performance. The Gradient-weighted Class Activation Mapping (Grad-CAM) technique illustrates what image feature was the most important for the CNNs. Results: The CNN of ResNet18 demonstrated the best performance [accuracy =0.82, 95% confidence interval (CI): 0.80-0.84; precision =0.81, 95% CI: 0.73-0.89; sensitivity =0.85, 95% CI: 0.79-0.91; specificity =0.82, 95% CI: 0.76-0.88; and AUC =0.89, 95% CI: 0.86-0.92], compared with VGG19 and Inception V3 as well as the comparator dentists. Therefore, ResNet18 was chosen to integrate with clinical parameters to produce the multi-modal CNN of ResNet18 + C, which showed a significantly enhanced performance (accuracy =0.86, 95% CI: 0.84-0.88; precision =0.85, 95% CI: 0.76-0.94; sensitivity =0.89, 95% CI: 0.83-0.95; specificity =0.86, 95% CI: 0.79-0.93; and AUC =0.94, 95% CI: 0.91-0.97). Conclusions: The CNN of ResNet18 showed good performance (accuracy, precision, sensitivity, specificity, and AUC) for the diagnosis of deep caries and pulpitis. The multi-modal CNN of ResNet18 + C (ResNet18 integrated with clinical parameters) demonstrated a significantly enhanced performance, with promising potential for the diagnosis of deep caries and pulpitis.",artificial intelligence (ai); deep learning; convolutional neural network (cnns); caries; pulpitis; carious lesions
Article,"Abbood, Saif Hameed; Hamed, Haza Nuzly Abdull; Rahim, Mohd Shafry Mohd; Alaidi, Abdul Hadi M.; ALRikabi, Haider Th Salim",DR-LL Gan: Diabetic Retinopathy Lesions Synthesis using Generative Adversarial Network,international journal of online and biomedical engineering,2022,Not found,"Diabetic Retinopathy (DR) is a serious consequence of diabetes that seriously impact on the eyes and is a leading cause of blindness. If the lesions in DR arise in the central portion of the fundus, they may result in significant vision loss, which we refer to as Diabetic Macular Edema (DME). Deep learning (DL) techniques are commonly used utilized in ophthalmology for discriminative tasks such as diabetic retinopathy or age-related macular degeneration (AMD) diagnosis. Deep learning techniques typically need huge picture data sets for deep convolutional neural networks (DCNNs) training, it should be graded by human specialists. According to international protocol, it is classified into five severity categories. However, improving a grading model for high generality needs a significant quantity of balanced training data, which is challenging to obtain, especially at high levels of severity. Typical techniques for data augmentation, in many applications of deep learning in the retinal image processing domain, the difficulty of access to huge annotated datasets and legal concerns about patient privacy are limiting issues. As a result, the concept of creating synthetic retinal pictures that are indistinguishable from actual data has garnered more attention. GANs have been certain to be an effective framework for creating synthetic databases of anatomically accurate retinal fundus pictures. GANs, in particular, have garnered increasing attention in ophthalmology. in this article, we present a lossless generative adversarial network (DR-LL GAN) to generate good resolution fundus pictures that May be adjusted to include random grading and information about the lesion. As a result, large-scale generated data may be used to train a DR grading and lesion segmentation model with more appropriate augmentation. Our model experiments evaluated on IDRID and MESSIDOR datasets, it's obtained a discrimination loss of 0.69374 and a generation loss of 1.10438, as well as a segmentation accuracy of 0.9840 in our tests. This might support in the optimization techniques of the neural network design and in computer-aided screening of medical picture, thus increasing diagnostic reliability for clinical assessment in the future of sophisticated technological healthcare.",diabetic retinopathy; diabetic macular edema; gan; dcnn; dl
Article,"Orlando, Jose Ignacio; Prokofyeva, Elena; del Fresno, Mariana; Blaschko, Matthew B.",An ensemble deep learning based approach for red lesion detection in fundus images,computer methods and programs in biomedicine,2018,Not found,"Background and objectives: Diabetic retinopathy (DR) is one of the leading causes of preventable blindness in the world. Its earliest sign are red lesions, a general term that groups both microaneurysms (MAs) and hemorrhages (HEs). In daily clinical practice, these lesions are manually detected by physicians using fundus photographs. However, this task is tedious and time consuming, and requires an intensive effort due to the small size of the lesions and their lack of contrast. Computer-assisted diagnosis of DR based on red lesion detection is being actively explored due to its improvement effects both in clinicians consistency and accuracy. Moreover, it provides comprehensive feedback that is easy to assess by the physicians. Several methods for detecting red lesions have been proposed in the literature, most of them based on characterizing lesion candidates using hand crafted features, and classifying them into true or false positive detections. Deep learning based approaches, by contrast, are scarce in this domain due to the high expense of annotating the lesions manually. Methods: In this paper we propose a novel method for red lesion detection based on combining both deep learned and domain knowledge. Features learned by a convolutional neural network (CNN) are augmented by incorporating hand crafted features. Such ensemble vector of descriptors is used afterwards to identify true lesion candidates using a Random Forest classifier. Results: We empirically observed that combining both sources of information significantly improve results with respect to using each approach separately. Furthermore, our method reported the highest performance on a per-lesion basis on DIARETDB1 and e-ophtha, and for screening and need for referral on MESSIDOR compared to a second human expert. Conclusions: Results highlight the fact that integrating manually engineered approaches with deep learned features is relevant to improve results when the networks are trained from lesion-level annotated data. An open source implementation of our system is publicly available at https://github.com/ignaciorlando/red-lesion-detection. (C) 2017 Elsevier B.V. All rights reserved.",fundus images; diabetic retinopathy; red lesion detection; deep learning
Article,"Yu, Moye; Wang, Yi",Intelligent detection and applied research on diabetic retinopathy based on the residual attention network,international journal of imaging systems and technology,2022,Not found,"This study proposes a high-accuracy (ACC) algorithm to automatically detect diabetic retinopathy (DR) and diabetic macular edema (DME) in retinal fundus images. Three DR datasets were obtained for use in this study: EyePACS, Messidor, and IDRid. In the EyePACS dataset, two DR classifications and five classifications experiments were conducted. The Messidor and IDRid dataset were graded DR and DME. After preprocessing, enhancement, and normalizing, common convolutional neural networks (CNN) were used to obtain the classification results. Afterward, an optimization method residual attention network (RAN) was introduced that was based on the residual attention module, and incorporated dilated convolution, so as to optimize the experimental results. The focal loss was then added to solve the imbalance problem. Next, a five-fold cross-validation strategy was introduced so as to assess and optimize the proposed model, after which the prediction ACC, sensitivity, specificity, area under receiver operating curve, and Kappa score were assessed. The proposed method RAN was shown to achieve 89.2% ACC (95% confidence interval [CI], 0.8782-0.9123) for two DR classifications (normal and abnormal) on the EyePACS dataset, 89.8% ACC (95% CI, 0.8751-0.9275) for two DR classifications on the Messidor dataset. The IDRid dataset achieved an ACC of 71.5% (95% CI, 0.6941-0.7423) for the two DR classifications. RAN mainly improves the results of commonly used CNN methods on the same dataset. Therefore, the classification and diagnosis of DR may be improved by adopting the proposed method.",artificial intelligence; attention mechanism; cnn; diabetic retinopathy; dilated convolution; fundus image
Article,"Atteia, Ghada; Abdel Samee, Nagwan; Zohair Hassan, Hassan",DFTSA-Net: Deep Feature Transfer-Based Stacked Autoencoder Network for DME Diagnosis,entropy,2021,Not found,"Diabetic macular edema (DME) is the most common cause of irreversible vision loss in diabetes patients. Early diagnosis of DME is necessary for effective treatment of the disease. Visual detection of DME in retinal screening images by ophthalmologists is a time-consuming process. Recently, many computer-aided diagnosis systems have been developed to assist doctors by detecting DME automatically. In this paper, a new deep feature transfer-based stacked autoencoder neural network system is proposed for the automatic diagnosis of DME in fundus images. The proposed system integrates the power of pretrained convolutional neural networks as automatic feature extractors with the power of stacked autoencoders in feature selection and classification. Moreover, the system enables extracting a large set of features from a small input dataset using four standard pretrained deep networks: ResNet-50, SqueezeNet, Inception-v3, and GoogLeNet. The most informative features are then selected by a stacked autoencoder neural network. The stacked network is trained in a semi-supervised manner and is used for the classification of DME. It is found that the introduced system achieves a maximum classification accuracy of 96.8%, sensitivity of 97.5%, and specificity of 95.5%. The proposed system shows a superior performance over the original pretrained network classifiers and state-of-the-art findings.",diabetic macular edema; retinal fundus image; deep learning; pretrained convolutional neural network; autoencoder; transfer learning
Article,"Kobat, Sabiha Gungor; Baygin, Nursena; Yusufoglu, Elif; Baygin, Mehmet; Barua, Prabal Datta; Dogan, Sengul; Yaman, Orhan; Celiker, Ulku; Yildirim, Hakan; Tan, Ru-San; Tuncer, Turker; Islam, Nazrul; Acharya, U. Rajendra",Automated Diabetic Retinopathy Detection Using Horizontal and Vertical Patch Division-Based Pre-Trained DenseNET with Digital Fundus Images,diagnostics,2022,Not found,"Diabetic retinopathy (DR) is a common complication of diabetes that can lead to progressive vision loss. Regular surveillance with fundal photography, early diagnosis, and prompt intervention are paramount to reducing the incidence of DR-induced vision loss. However, manual interpretation of fundal photographs is subject to human error. In this study, a new method based on horizontal and vertical patch division was proposed for the automated classification of DR images on fundal photographs. The novel sides of this study are given as follows. We proposed a new non-fixed-size patch division model to obtain high classification results and collected a new fundus image dataset. Moreover, two datasets are used to test the model: a newly collected three-class (normal, non-proliferative DR, and proliferative DR) dataset comprising 2355 DR images and the established open-access five-class Asia Pacific Tele-Ophthalmology Society (APTOS) 2019 dataset comprising 3662 images. Two analysis scenarios, Case 1 and Case 2, with three (normal, non-proliferative DR, and proliferative DR) and five classes (normal, mild DR, moderate DR, severe DR, and proliferative DR), respectively, were derived from the APTOS 2019 dataset. These datasets and these cases have been used to demonstrate the general classification performance of our proposal. By applying transfer learning, the last fully connected and global average pooling layers of the DenseNet201 architecture were used to extract deep features from input DR images and each of the eight subdivided horizontal and vertical patches. The most discriminative features are then selected using neighborhood component analysis. These were fed as input to a standard shallow cubic support vector machine for classification. Our new DR dataset obtained 94.06% and 91.55% accuracy values for three-class classification with 80:20 hold-out validation and 10-fold cross-validation, respectively. As can be seen from steps of the proposed model, a new patch-based deep-feature engineering model has been proposed. The proposed deep-feature engineering model is a cognitive model, since it uses efficient methods in each phase. Similar excellent results were seen for three-class classification with the Case 1 dataset. In addition, the model attained 87.43% and 84.90% five-class classification accuracy rates using 80:20 hold-out validation and 10-fold cross-validation, respectively, on the Case 2 dataset, which outperformed prior DR classification studies based on the five-class APTOS 2019 dataset. Our model attained about >2% classification results compared to others. These findings demonstrate the accuracy and robustness of the proposed model for classification of DR images.",diabetic retinopathy; patch division; deep feature extraction; transfer learning; neighborhood component analysis; support vector machine
Article,"Vasireddi, Hemanth Kumar; Devi, Suganya K.; Reddy, Raja G. N., V",Deep feed forward neural network-based screening system for diabetic retinopathy severity classification using the lion optimization algorithm,graefes archive for clinical and experimental ophthalmology,2022,Not found,"Diabetic Retinopathy (DR) has become a major cause of blindness in recent years. Diabetic patients should be screened on a regular basis for early detection, which can help them avoid blindness. Furthermore, the number of diabetic patients undergoing these screening procedures is rapidly increasing, resulting in increased workload for ophthalmologists. An efficient screening system that assists ophthalmologists in DR diagnosis saves ophthalmologists a lot of time and effort. To address this issue, an automatic DR detection screening system is required to improve diagnosis speed and detection accuracy. Appropriate treatment can be provided to patients to prevent vision loss if the severity levels of DR are accurately diagnosed in the early stages. A growing number of screening systems for DR diagnosis have been developed in recent years using various deep learning models, and the majority of the published work did not include any optimization algorithm in the neural network for severity classification. The use of an optimization algorithm with the necessary hyper parameter tuning will improve the model's performance. Considering this as motivation, we proposed a five-phase DFNN-LOA model. The DFNN-LOA algorithm presented here has five phases: (i) pre-processing, (ii) optic disc detection, (iii) segmentation, (iv) feature extraction, and (v) severity classification. The proposed model's experimental analysis is carried out on the MESSIDOR dataset. The experimental results show that the proposed DFNN-LOA model has superior characteristics, with maximum accuracy, sensitivity, specificity, F1-score, PPV, and NPV of 97.6%, 98.4%, 90.7%, 96.5%, 94.6%, and 97.1%, respectively.",diabetic retinopathy; deep feed forward neural network (dfnn); lion optimization algorithm (loa); optic disc (od) detection; classification; optimization
Article,"Shaik, Nagur Shareef; Cherukuri, Teja Krishna",Hinge attention network: A joint model for diabetic retinopathy severity grading,applied intelligence,2022,Not found,"Diabetic Retinopathy is one of the prominent reasons for permanent blindness in working age, long term diabetic patients. With the prevalence in raise of diabetics, majority of the people are endangered to permanent vision loss. The advancements in medical imaging techniques enabled the research community to focus on developing automated and computerized systems for diagnosing retinopathy in early stages. But, it is a very complex challenge due to the presence of high intra-class variations and imbalanced data distribution for higher grades of severity. In recent years, various deep learning based models have been designed for automating the process of retinopathy severity classification. In this research work, we present a fascinating deep learning model with multiple attention stages called Hinge Attention Network (HA-Net). Proposed model consists of a pre-trained VGG16 base to extract initial spatial representation from retinal scan images, spatial attention autoencoder to learn lesion specific latent representations in spatial dimensions and a channel attention based hinge neural network to grab category based discriminative features in channel dimension and classify the severity grade of retinopathy. In addition to spatial and channel attention mechanism, we use Convolutional LSTM layer to prioritize highly important spatial maps before passing to hinge neural network. All these components of HA-Net, enabled it to make generalised and accurate predictions on unseen data. The effectiveness and acceptability of proposed model is proved by validating it using two benchmark datasets, Kaggle APTOS 2019 and ISBI IDRiD. Extensive experimental studies on these datasets reveal that, proposed HA-Net outstrip several existing models by achieving an accuracy of 85.54% on Kaggle APTOS, and an accuracy of 66.41% on IDRiD datasets.",diabetic retinopathy (dr); transfer learning; pre-trained models; visual geometry group net (vgg16); attention autoencoder; spatial attention; channel attention; spatial sequence attention; convolutional lstm; hinge neural network
Article,"Pin, Kuntha; Chang, Jee Ho; Nam, Yunyoung",Comparative Study of Transfer Learning Models for Retinal Disease Diagnosis from Fundus Images,cmc-computers materials & continua,2022,Not found,"While the usage of digital ocular fundus image has been widespread in ophthalmology practice, the interpretation of the image has been still on the hands of the ophthalmologists which are quite costly. We explored a robust deep learning system that detects three major ocular diseases: diabetic retinopathy (DR), glaucoma (GLC), and age-related macular degeneration (AMD). The proposed method is composed of two steps. First, an initial quality evaluation in the classification system is proposed to filter out poorquality images to enhance its performance, a technique that has not been explored previously. Second, the transfer learning technique is used with various convolutional neural networks (CNN) models that automatically learn a thousand features in the digital retinal image, and are based on those features for diagnosing eye diseases. Comparison performance of many models is conducted to find the optimal model which fits with fundus classification. Among the different CNN models, DenseNet-201 outperforms others with an area under the receiver operating characteristic curve of 0.99. Furthermore, the corresponding specificities for healthy, DR, GLC, and AMD patients are found to be 89.52%, 96.69%, 89.58%, and 100%, respectively. These results demonstrate that the proposed method can reduce the time-consumption by automatically diagnosing multiple eye diseases using computer-aided assistance tools.",multiclass classification; deep neural networks; glaucoma; age-related macular degeneration; diabetic retinopathy; transfer learning; qual-ity evaluation
Article,"Karsaz, Ali",A modified convolutional neural network architecture for diabetic retinopathy screening using SVDD,applied soft computing,2022,Not found,"Automatic diabetic retinopathy diagnostic methods are proposed to facilitate the examination process and act as the physician's helper. Most of the traditional convolution neural network (CNN) algorithms use only spatial features for image category recognition. This approach may not be optimal for the screening diabetic retinopathy because the retinal images have generally the same feature maps with minor differences in spatial domain. We propose a new high level image understanding using a modified CNN architecture mixed with modified support vector domain description (SVDD) as a classifier. This new innovative architecture uses two pathways extracting features of the retinal images in both spatial and spectral domains. The standard pre-trained AlexNet is chosen for modification to avoid the time complexity of the training algorithms. In spite the advantages of the modified AlexNet with two pathways configuration and standard SVDD classification, the different SVDD kernel functions affect the performance of the proposed algorithm. By using the appropriate transformed data into two or three dimensional feature spaces, the proposed SVDD can obtain more flexible and more accurate image descriptions. Also, we compared the performance of our approach with that of the commonly used as classification methods such as K-Means, subtractive and FCM clustering. Our proposed architecture achieves more than 98% precision and sensitivity for two class classification. (c) 2022 Elsevier B.V. All rights reserved.",diabetic retinopathy; convolutional neural network; deep learning; support vector domain description (svdd)
Article,"Sugeno, Ayaka; Ishikawa, Yasuyuki; Ohshima, Toshio; Muramatsu, Rieko",Simple methods for the lesion detection and severity grading of diabetic retinopathy by image processing and transfer learning,computers in biology and medicine,2021,Not found,"Diabetic retinopathy (DR) has become one of the major causes of blindness. Due to the increased prevalence of diabetes worldwide, diabetic patients exhibit high probabilities of developing DR. There is a need to develop a labor-less computer-aided diagnosis system to support the clinical diagnosis. Here, we attempted to develop simple methods for severity grading and lesion detection from retinal fundus images. We developed a severity grading system for DR by transfer learning with a recent convolutional neural network called EfficientNet-B3 and the publicly available Kaggle Asia Pacific Tele-Ophthalmology Society (APTOS) 2019 training dataset, which includes artificial noise. After removing the blurred and duplicated images from the dataset using a numerical threshold, the trained model achieved specificity and sensitivity values greater than or similar to 0.98 in the identification of DR retinas. For severity grading, the classification accuracy values of 0.84, 0.95, and 0.98 were recorded for the 1st, 2nd, and 3rd predicted labels, respectively. The utility of EfficientNets-B3 for the severity grading of DR as well as the detailed retinal areas referred were confirmed via visual explanation methods of convolutional neural networks. Lesion extraction was performed by applying an empirically defined threshold value to the enhanced retinal images. Although the extraction of blood vessels and detection of red lesions occurred simultaneously, the red and white lesions, including both soft and hard exudates, were clearly extracted. The detected lesion areas were further confirmed with ground truth using the DIARETDB1 database images with general accuracy. The simple and easily applicable methods proposed in this study will aid in the detection and severity grading of DR, which might help in the selection of appropriate treatment strategies for DR.",computer-aided diagnosis; diabetic retinopathy (dr); lesion detection; severity grading; image processing; convolutional neural network (cnn); deep learning
Article,"Shaik, Nagur Shareef; Cherukuri, Teja Krishna",Lesion-aware attention with neural support vector machine for retinopathy diagnosis,machine vision and applications,2021,Not found,"Diabetic retinopathy (DR) is a severe eye disease which can lead to permanent blindness. Identifying DR in early stages by using computer-aided diagnosis (CAD) systems can help the ophthalmologists to give proper treatment rationally, there by preventing many people from going blind. Due to intra-class variations and imbalanced data distribution, it is highly difficult to design a CAD system for DR severity diagnosis with greater generalizability. In this article, we propose a multi-stage deep learning pipeline, lesion-aware attention with neural support vector machine, for diabetic retinopathy diagnosis. Proposed pipeline consists of a pre-trained convolution base for learning retinal image spatial representations, lesion-aware attention for weighting lesion specific features, convolution autoencoder for learning latent attention representations and a neural support vector machine for discrimination. Convolutional autoencoder and neural support vector machine are jointly trained in end-to-end fashion to obtain category based lesion specific latent attention features by complementing each other in re-constructor and discriminator paths. Proposed approach is validated using two benchmark retinal scan image datasets, Kaggle APTOS 2019 and ISBI 2018 IDRiD, for DR type and severity grade classification tasks. Our experimental studies expose that using lesion-aware attention along with the joint training of autoencoder and neural support vector machine boosted the performance of models used for DR diagnosis, thereby outperforming existing works presented in the literature for DR severity grading. Proposed model achieved the highest accuracy of 90.45%, 84.31% on APTOS dataset and an accuracy of 79.85%, 63.24% on IDRiD dataset for DR type and severity grade classification tasks, respectively.",diabetic retinopathy (dr); transfer learning; pre-trained convolution neural networks (cnns); extreme inception (xception); lesion-aware attention; convolutional autoencoder; neural support vector machine
Article,"Chawla, Shubhaa; Chawla, Aastha; Chawla, Rajeev; Jaggi, Shalini; Singh, Deependra; Trehan, Siddhant",Trained nurse-operated teleophthalmology screening approach as a cost-effective tool for diabetic retinopathy,international journal of diabetes in developing countries,2022,Not found,"Introduction Teleophthalmology for diabetic retinopathy seems to be a cost-effective, accurate, and reliable method for screening for diabetic retinopathy. Aims To study the cost-effectiveness of a novel telemedicine-based digital retinal imaging teleophthalmology performed by a locally trained nurse compared to conventional ophthalmologic fundus examination of diabetic patients for early diagnosis of diabetic retinopathy. Materials and methods We compared the cost of evaluation of diabetic retinopathy in a total of 3090 patients. These were grouped based on the conventional approach of evaluation (n = 1500) and compared with the teleophthalmology (n = 1590) approach. The diabetic patients were examined through teleophthalmology by a trained nurse using the Forbes 3nethra fundal camera, and these fundal images were transferred by iCloud to a specialized retina center. Results In total, 18.2% (n = 562) patients were diagnosed with diabetic retinopathy (DR). Of these, 8.7% had mild non-proliferative diabetic retinopathy (NPDR), 4.8% had moderate NPDR, 3.8% had severe NPDR, and 0.9% had PDR. The total cost of conventional telemedicine-based digital retinal imaging was approximately INR 550 which in contrast was less than half to the total cost of conventional dilated fundus examination by an ophthalmologist (INR 1400). Conclusion Our cost analysis indicates that telemedicine-based diabetic retinopathy screening is economical (INR 550 as compared to INR 1400) than conventional retinal examination.",teleophthalmology; diabetic retinopathy; microvascular complication; cost-effective tool
Article; Early Access,"Sundar, Sumod; Sumathy, Subramanian",An effective deep learning model for grading abnormalities in retinal fundus images using variational auto-encoders,international journal of imaging systems and technology,0,Not found,"Diabetic retinopathy (DR) and Diabetic Macular Edema (DME) are severe diseases that affect the eyes due to damage in blood vessels. Computer-aided automated grading will help clinicians conduct disease diagnoses at ease. Experiments of automated image processing with deep learning techniques using CNN produce promising results, especially in the medical imaging domain. However, the disease grading tasks in retinal images using CNN struggle to retain high-quality information at the output. A novel deep learning model based on variational auto-encoder to grade DR and DME abnormalities in retinal images is proposed. The objective of the proposed model is to extract the most relevant retinal image features efficiently. It focuses on addressing less relevant candidate region generation and translational invariance present in images. The experiments are conducted in IDRID dataset and evaluated using accuracy, U-kappa, sensitivity, specificity and precision metrics. The results outperform compared with other state-of-art techniques.",diabetic macular edema; diabetic retinopathy; region proposal network; retinal image grading; softmax classifier; variational auto-encoder
Article,"Duwairi, Rehab M.; Al-Zboon, Saad A.; Al-Dwairi, Rami A.; Obaidi, Ahmad",A Deep Learning Model and a Dataset for Diagnosing Ophthalmology Diseases,journal of information & knowledge management,2021,Not found,"The rapid development of artificial neural network techniques, especially convolutional neural networks, encouraged the researchers to adapt such techniques in the medical domain. Specifically, to provide assist tools to help the professionals in patients' diagnosis. The main problem faced by the researchers in the medical domain is the lack of available annotated datasets which can be used to train and evaluate large and complex deep neural networks. In this paper, to assist researchers who are interested in applying deep learning techniques to aid the ophthalmologists in diagnosing eye-related diseases, we provide an optical coherence tomography dataset with collaboration with ophthalmologists from the King Abdullah University Hospital, Irbid, Jordan. This dataset consists of 21,991 OCT images distributed over seven eye diseases in addition to normal images (no disease), namely, Choroidal Neovascularisation, Full Macular Hole (Full Thickness), Partial Macular Hole, Central Serous Retinopathy, Geographic atrophy, Macular Retinal Oedema, and Vitreomacular Traction. To the best of our knowledge, this dataset is the largest of its kind, where images belong to actual patients from Jordan and the annotation was carried out by ophthalmologists. Two classification tasks were applied to this dataset; a binary classification to distinguish between images which belong to healthy eyes (normal) and images which belong to diseased eyes (abnormal). The second classification task is a multi-class classification, where the deep neural network is trained to distinguish between the seven diseases listed above in addition to the normal case. In both classification tasks, the U-Net neural network was modified and subsequently utilised. This modification adds an additional block of layers to the original U-Net model to become capable of handling classification as the original network is used for image segmentation. The results of the binary classification were equal to 84.90% and 69.50% as accuracy and quadratic weighted kappa, respectively. The results of the multi-class classification, by contrast, were equal to 63.68% and 66.06% as accuracy and quadratic weighted kappa, respectively.",image classification; deep learning; machine learning; medical image processing; optical coherence tomography
Article,"Dai, Ling; Fang, Ruogu; Li, Huating; Hou, Xuhong; Sheng, Bin; Wu, Qiang; Jia, Weiping",Clinical Report Guided Retinal Microaneurysm Detection With Multi-Sieving Deep Learning,ieee transactions on medical imaging,2018,Not found,"Timely detection and treatment of microaneurysms is a critical step to prevent the development of vision-threatening eye diseases such as diabetic retinopathy. However, detecting microaneurysms in fundus images is a highly challenging task due to the low image contrast, misleading cues of other red lesions, and the large variation of imaging conditions. Existing methods tend to fail in face of the large intra-class variation and small inter-class variations for microaneurysm detection in fundus images. Recently, hybrid text/image mining computer-aided diagnosis systems have emerged to offer a promise of bridging the semantic gap between images and diagnostic information. In this paper, we focus on developing an interleaved deep mining technique to cope intelligently with the unbalanced microaneurysm detection problem. Specifically, we present a clinical report guided multi-sieving convolutional neural network, which leverages a small amount of supervised information in clinical reports to identify the potential microaneurysm regions via the image-to-text mapping in the feature space. These potential microaneurysm regions are then interleaved with fundus image information for multi-sieving deep mining in a highly unbalanced classification problem. Critically, the clinical reports are employed to bridge the semantic gap between low-level image features and high-level diagnostic information. We build an efficient microaneurysm detection framework based on the hybrid text/image interleaving and validate its performance on challenging clinical data sets acquired from diabetic retinopathy patients. Extensive evaluations are carried out in terms of fundus detection and classification. Experimental results show that our framework achieves 99.7% precision and 87.8% recall, comparing favorably with the state-of-the-art algorithms. Integration of expert domain knowledge and image information demonstrates the feasibility of reducing the difficulty of training classifiers under extremely unbalanced data distributions.",diabetic retinopathy; fundus image analysis; multi-sieving cnn; microaneurysm detection; clinical reports; deep learning
Review,"Rajalakshmi, Ramachandran; Prathiba, Vijayaraghavan; Rani, Padmaja Kumari; Mohan, Viswanathan",Various models for diabetic retinopathy screening that can be applied to India,indian journal of ophthalmology,2021,Not found,"The increased burden of diabetes in India has resulted in an increase in the complications of diabetes including sight-threatening diabetic retinopathy (DR). Visual impairment and blindness due to DR can be prevented by early detection and management of sight-threatening DR. Life-long evaluation by repetitive retinal screening of people with diabetes is an essential strategy as DR has an asymptomatic presentation. Fundus examination by trained ophthalmologists and fundus photography are established modes of screening. Various modes of opportunistic screening have been followed in India. Hospital-based screening (diabetes care/eye care) and community-based screening are the common modes. Tele-ophthalmology programs based on retinal imaging, remote interpretation, and grading of DR by trained graders/ophthalmologists have facilitated greater coverage of DR screening and enabled timely referral of those with sight-threatening DR. DR screening programs use nonmydriatic or mydriatic fundus cameras for retinal photography. Hand-held/smartphone-based fundus cameras that are portable, less expensive, and easy to use in remote places are gaining popularity. Good retinal image quality and accurate diagnosis play an important role in reducing unnecessary referrals. Recent advances like nonmydriatic ultrawide field fundus photography can be used for DR screening, though likely to be more expensive. The advent of artificial intelligence and deep learning has raised the possibility of automated detection of DR. Efforts to increase the awareness regarding DR is essential to ensure compliance to regular follow-up. Cost-effective sustainable models will ensure systematic nation-wide DR screening in the country.",diabetic retinopathy; screening models; tele-ophthalmology
Article,"Sudha, V; Ganeshbabu, T. R.",A Convolutional Neural Network Classifier VGG-19 Architecture for Lesion Detection and Grading in Diabetic Retinopathy Based on Deep Learning,cmc-computers materials & continua,2021,Not found,"Diabetic Retinopathy (DR) is a type of disease in eyes as a result of a diabetic condition that ends up damaging the retina, leading to blindness or loss of vision. Morphological and physiological retinal variations involving slowdown of blood flow in the retina, elevation of leukocyte cohesion, basement membrane dystrophy, and decline of pericyte cells, develop. As DR in its initial stage has no symptoms, early detection and automated diagnosis can prevent further visual damage. In this research, using a Deep Neural Network (DNN), segmentation methods are proposed to detect the retinal defects such as exudates, hemorrhages, microaneurysms from digital fundus images and then the conditions are classified accurately to identify the grades as mild, moderate, severe, no PDR, PDR in DR. Initially, saliency detection is applied on color images to detect maximum salient foreground objects from the background. Next, structure tensor is applied powerfully to enhance the local patterns of edge elements and intensity changes that occur on edges of the object. Finally, active contours approximation is performed using gradient descent to segment the lesions from the images. Afterwards, the output images from the proposed segmentation process are subjected to evaluate the ratio between the total contour area and the total true contour arc length to label the classes as mild, moderate, severe, No PDR and PDR. Based on the computed ratio obtained from segmented images, the severity levels were identified. Meanwhile, statistical parameters like the mean and the standard deviation of pixel intensities, mean of hue, saturation and deviation clustering, are estimated through K-means, which are computed as features from the output images of the proposed segmentation process. Using these derived feature sets as input to the classifier, the classification of DR was performed. Finally, a VGG-19 deep neural network was trained and tested using the derived feature sets from the KAGGLE fundus image dataset containing 35,126 images in total. The VGG-19 is trained with features extracted from 20,000 images and tested with features extracted from 5,000 images to achieve a sensitivity of 82% and an accuracy of 96%. The proposed system was able to label and classify DR grades automatically.",diabetic retinopathy; saliency map; structure tensor; gradient descent method; exudates; haemorrhages; microaneurysms; vgg-19
Article,"Gurcan, Omer Faruk; Beyca, Omer Faruk; Dogan, Onur",A Comprehensive Study of Machine Learning Methods on Diabetic Retinopathy Classification,international journal of computational intelligence systems,2021,Not found,"Diabetes is one of the emerging threats to public health all over the world. According to projections by the World Health Organization, diabetes will be the seventh foremost cause of death in 2030 (WHO, Diabetes, 2020. https://www.afro.who.int/healthtopics/diabetes). Diabetic retinopathy (DR) results from long-lasting diabetes and is the fifth leading cause of visual impairment, worldwide. Early diagnosis and treatment processes are critical to overcoming this disease. The diagnostic procedure is challenging, especially in low-resource settings, or time-consuming, depending on the ophthalmologist's experience. Recently, automated systems now address DR classification tasks. This study proposes an automated DR classification system based on preprocessing, feature extraction, and classification steps using deep convolutional neural network (CNN) and machine learning methods. Features are extracted from a pretrained model by the transfer learning approach. DR images are classified by several machine learning methods. XGBoost outperforms other methods. Dimensionality reduction algorithms are applied to obtain a lower-dimensional representation of extracted features. The proposed model is trained and evaluated on a publicly available dataset. Grid search and calibration are used in the analysis. This study provides researchers with performance comparisons of different machine learning methods. The proposed model offers a robust solution for detecting DR with a small number of images. We used a transfer learning approach, which differs from other studies in the literature, during the feature extraction. It provides a data-driven, cost-effective solution, which includes comprehensive preprocessing and fine-tuning processes. (C) 2021 The Authors. Published by Atlantis Press B.V.",machine learning; ensemble learning; transfer learning; xgboost; pca; svd
Review,"Penso, Marco; Solbiati, Sarah; Moccia, Sara; Caiani, Enrico G.",Decision Support Systems in HF based on Deep Learning Technologies,current heart failure reports,2022,Not found,"Purpose of Review Application of deep learning (DL) is growing in the last years, especially in the healthcare domain. This review presents the current state of DL techniques applied to electronic health record structured data, physiological signals, and imaging modalities for the management of heart failure (HF), focusing in particular on diagnosis, prognosis, and re-hospitalization risk, to explore the level of maturity of DL in this field. Recent Findings DL allows a better integration of different data sources to distillate more accurate outcomes in HF patients, thus resulting in better performance when compared to conventional evaluation methods. While applications in image and signal processing for HF diagnosis have reached very high performance, the application of DL to electronic health records and its multisource data for prediction could still be improved, despite the already promising results. Embracing the current big data era, DL can improve performance compared to conventional techniques and machine learning approaches. DL algorithms have potential to provide more efficient care and improve outcomes of HF patients, although further investigations are needed to overcome current limitations, including results generalizability and transparency and explicability of the evidences supporting the process.",deep learning; heart failure; artificial intelligence; prognosis; diagnosis; readmission
Review,"Yin, Jiamin; Ngiam, Kee Yuan; Teo, Hock Hai",Role of Artificial Intelligence Applications in Real-Life Clinical Practice: Systematic Review,journal of medical internet research,2021,Not found,"Background: Artificial intelligence (AI) applications are growing at an unprecedented pace in health care, including disease diagnosis, triage or screening, risk analysis, surgical operations, and so forth. Despite a great deal of research in the development and validation of health care AI, only few applications have been actually implemented at the frontlines of clinical practice. Objective: The objective of this study was to systematically review AI applications that have been implemented in real-life clinical practice. Methods: We conducted a literature search in PubMed, Embase, Cochrane Central, and CINAHL to identify relevant articles published between January 2010 and May 2020. We also hand searched premier computer science journals and conferences as well as registered clinical trials. Studies were included if they reported AI applications that had been implemented in real-world clinical settings. Results: We identified 51 relevant studies that reported the implementation and evaluation of AI applications in clinical practice, of which 13 adopted a randomized controlled trial design and eight adopted an experimental design. The AI applications targeted various clinical tasks, such as screening or triage (n=16), disease diagnosis (n=16), risk analysis (n=14), and treatment (n=7). The most commonly addressed diseases and conditions were sepsis (n=6), breast cancer (n=5), diabetic retinopathy (n=4), and polyp and adenoma (n=4). Regarding the evaluation outcomes, we found that 26 studies examined the performance of AI applications in clinical settings, 33 studies examined the effect of AI applications on clinician outcomes, 14 studies examined the effect on patient outcomes, and one study examined the economic impact associated with AI implementation. Conclusions: This review indicates that research on the clinical implementation of AI applications is still at an early stage despite the great potential. More research needs to assess the benefits and challenges associated with clinical AI applications through a more rigorous methodology.",artificial intelligence; machine learning; deep learning; system implementation; clinical practice; review
Article; Early Access,"Gao, Zhiyuan; Pan, Xiangji; Shao, Ji; Jiang, Xiaoyu; Su, Zhaoan; Jin, Kai; Ye, Juan",Automatic interpretation and clinical evaluation for fundus fluorescein angiography images of diabetic retinopathy patients by deep learning,british journal of ophthalmology,0,Not found,"Background/aims Fundus fluorescein angiography (FFA) is an important technique to evaluate diabetic retinopathy (DR) and other retinal diseases. The interpretation of FFA images is complex and time-consuming, and the ability of diagnosis is uneven among different ophthalmologists. The aim of the study is to develop a clinically usable multilevel classification deep learning model for FFA images, including prediagnosis assessment and lesion classification. Methods A total of 15 599 FFA images of 1558 eyes from 845 patients diagnosed with DR were collected and annotated. Three convolutional neural network (CNN) models were trained to generate the label of image quality, location, laterality of eye, phase and five lesions. Performance of the models was evaluated by accuracy, F-1 score, the area under the curve and human-machine comparison. The images with false positive and false negative results were analysed in detail. Results Compared with LeNet-5 and VGG16, ResNet18 got the best result, achieving an accuracy of 80.79%-93.34% for prediagnosis assessment and an accuracy of 63.67%-88.88% for lesion detection. The human-machine comparison showed that the CNN had similar accuracy with junior ophthalmologists. The false positive and false negative analysis indicated a direction of improvement. Conclusion This is the first study to do automated standardised labelling on FFA images. Our model is able to be applied in clinical practice, and will make great contributions to the development of intelligent diagnosis of FFA images.",imaging; telemedicine; retina
Article,"Salam, Amritha Abdul; Mahadevappa, Manjunatha; Das, Asha; Nair, Madhu S.",DRG-NET: A graph neural network for computer-aided grading of diabetic retinopathy,signal image and video processing,2022,Not found,"Diabetic retinopathy is emerging as a very serious vision disorder in the recent decades, due to escalation of diabetes world-over. This condition can be minimized to a great extend with timely prognosis. Computer-aided detection techniques are very useful for assisting ophthalmologists, for faster diagnosis and intervention. With the advent of digital fundus cameras and the digitization of retinal images, there is a huge availability of digital fundus images with expert-annotated labels. For addressing the challenge of digital image grading, an attempt was made to model the features in digital fundus images, utilizing the non-Euclidean geometry. Here, a Graph Neural Network with supervised learning is suitably adapted for diabetic retinopathy image grading. The images are represented as 3D graphs, to encapsulate discriminate information, as nodes in network. The features extracted from the diabetic retinopathy images, using Scale Invariant Feature Transform technique, is used for graph construction and training. The Diabetic Retinopathy Graph Neural Network namely, DRG-NET model is trained and validated on two publicly available datasets namely Aptos 2019 and Messidor. Ten different types of performance indicators, including accuracy and Cohen's kappa values, were estimated and used for the comparison of models. For the Aptos and Messidor dataset, the model achieved an accuracy of 0.9954/0.9984, F1-score of 0.9774/0.9968 and kappa score of 0.9930/0.9980, respectively. It is evident from the results that the proposed DRG-NET model shows state-of-the-art performance for retinal image grading.",retinopathy; k-dimensional graph neural network; non-euclidean geometry; feature descriptor
Proceedings Paper,"Nandeeswar, S. B.; AlameluMangai, J.",Comparison of Key Performance Metrics of Finsemble Learning Algorithms for Diagnosis of Diabetic Retinopathy,"proceedings of the 2020 fourth world conference on smart trends in systems, security and sustainability (worlds4 2020)",2020,Not found,"Around the world, Blindness in diabetic patients are seen commonly because of Diabetic Retinopathy (DR). Sadly, the suggested annual testing of the diabetic patients' eye fundus is too complicated or not a regular manner. It is needed to provide information for the doctors about critical patients who would need regular checkup and others who can be considered as low risk and can be screened after considerable time. This paper explores various performance factors from most popular and leading ensemble algorithms that play key role in classifying and grading diabetic retinopathy. Three ensemble algorithms most widely used in Medical-IT industry used for comparison here are Stacking algorithm, AdaBoost algorithm and XGBoost ensemble classifier. The experiment demonstrates how various performance factors used to compare each classifier helps in deciding about the kind of dataset to be used and also for selecting the attributes. This demonstration uses a reduced set of attributes obtained thru correlation based feature extraction (CFS) method in comparison with original dataset with all characteristics that constitute significant risk factors for deciding whether a patients who are at high risk of diabetic retinopathy. Comparison of specificity and sensitivity levels gained are provided for a deeper comprehension of the behaviors of different ensemble algorithms. This research is therefore a first productive step towards developing a customized system helping in making a good decision.",ensemble algorithm; retina fundus; extreme gradient boosting; a daboost; boosting
Article,"Paradisa, Radifa Hilya; Bustamam, Alhadi; Mangunwardoyo, Wibowo; Victor, Andi Arus; Yudantha, Anggun Rama; Anki, Prasnurzaki",Deep Feature Vectors Concatenation for Eye Disease Detection Using Fundus Image,electronics,2022,Not found,"Fundus image is an image that captures the back of the eye (retina), which plays an important role in the detection of a disease, including diabetic retinopathy (DR). It is the most common complication in diabetics that remains an important cause of visual impairment, especially in the young and economically active age group. In patients with DR, early diagnosis can effectively help prevent the risk of vision loss. DR screening was performed by an ophthalmologist by analysing the lesions on the fundus image. However, the increasing prevalence of DR is not proportional to the availability of ophthalmologists who can read fundus images. It can lead to delayed prevention and management of DR. Therefore, there is a need for an automated diagnostic system as it can help ophthalmologists increase the efficiency of the diagnostic process. This paper provides a deep learning approach with the concatenate model for fundus image classification with three classes: no DR, non-proliferative diabetic retinopathy (NPDR), and proliferative diabetic retinopathy (PDR). The model architecture used is DenseNet121 and Inception-ResNetV2. The feature extraction results from the two models are combined and classified using the multilayer perceptron (MLP) method. The method that we propose gives an improvement compared to a single model with the results of accuracy, and average precision and recall of 91% and 90% for the F1-score, respectively. This experiment demonstrates that our proposed deep-learning approach is effective for the automatic DR classification using fundus photo data.",diabetic retinopathy; densenet121; inception-resnetv2; concatenate
Article,"Arsalan, Muhammad; Haider, Adnan; Choi, Jiho; Park, Kang Ryoung",Diabetic and Hypertensive Retinopathy Screening in Fundus Images Using Artificially Intelligent Shallow Architectures,journal of personalized medicine,2022,Not found,"Retinal blood vessels are considered valuable biomarkers for the detection of diabetic retinopathy, hypertensive retinopathy, and other retinal disorders. Ophthalmologists analyze retinal vasculature by manual segmentation, which is a tedious task. Numerous studies have focused on automatic retinal vasculature segmentation using different methods for ophthalmic disease analysis. However, most of these methods are computationally expensive and lack robustness. This paper proposes two new shallow deep learning architectures: dual-stream fusion network (DSF-Net) and dual-stream aggregation network (DSA-Net) to accurately detect retinal vasculature. The proposed method uses semantic segmentation in raw color fundus images for the screening of diabetic and hypertensive retinopathies. The proposed method's performance is assessed using three publicly available fundus image datasets: Digital Retinal Images for Vessel Extraction (DRIVE), Structured Analysis of Retina (STARE), and Children Heart Health Study in England Database (CHASE-DB1). The experimental results revealed that the proposed method provided superior segmentation performance with accuracy (Acc), sensitivity (SE), specificity (SP), and area under the curve (AUC) of 96.93%, 82.68%, 98.30%, and 98.42% for DRIVE, 97.25%, 82.22%, 98.38%, and 98.15% for CHASE-DB1, and 97.00%, 86.07%, 98.00%, and 98.65% for STARE datasets, respectively. The experimental results also show that the proposed DSA-Net provides higher SE compared to the existing approaches. It means that the proposed method detected the minor vessels and provided the least false negatives, which is extremely important for diagnosis. The proposed method provides an automatic and accurate segmentation mask that can be used to highlight the vessel pixels. This detected vasculature can be utilized to compute the ratio between the vessel and the non-vessel pixels and distinguish between diabetic and hypertensive retinopathies, and morphology can be analyzed for related retinal disorders.",fundus images; diabetic retinopathy; hypertensive retinopathy; retinal disease screening; retinal vasculature; ophthalmic diseases
Article,"Redd, Travis K.; Campbell, John Peter; Brown, James M.; Kim, Sang Jin; Ostmo, Susan; Chan, Robison Vernon Paul; Dy, Jennifer; Erdogmus, Deniz; Ioannidis, Stratis; Kalpathy-Cramer, Jayashree; Chiang, Michael F.",Evaluation of a deep learning image assessment system for detecting severe retinopathy of prematurity,british journal of ophthalmology,2019,Not found,"Background Prior work has demonstrated the near-perfect accuracy of a deep learning retinal image analysis system for diagnosing plus disease in retinopathy of prematurity (ROP). Here we assess the screening potential of this scoring system by determining its ability to detect all components of ROP diagnosis. Methods Clinical examination and fundus photography were performed at seven participating centres. A deep learning system was trained to detect plus disease, generating a quantitative assessment of retinal vascular abnormality (the i-ROP plus score) on a 1-9 scale. Overall ROP disease category was established using a consensus reference standard diagnosis combining clinical and image-based diagnosis. Experts then ranked ordered a second data set of 100 posterior images according to overall ROP severity. Results 4861 examinations from 870 infants were analysed. 155 examinations (3%) had a reference standard diagnosis of type 1 ROP. The i-ROP deep learning (DL) vascular severity score had an area under the receiver operating curve of 0.960 for detecting type 1 ROP. Establishing a threshold i-ROP DL score of 3 conferred 94% sensitivity, 79% specificity, 13% positive predictive value and 99.7% negative predictive value for type 1 ROP. There was strong correlation between expert rank ordering of overall ROP severity and the i-ROP DL vascular severity score (Spearman correlation coefficient= 0.93; p< 0.0001). Conclusion The i-ROP DL system accurately identifies diagnostic categories and overall disease severity in an automated fashion, after being trained only on posterior pole vascular morphology. These data provide proof of concept that a deep learning screening platform could improve objectivity of ROP diagnosis and accessibility of screening.",plus disease diagnosis; diabetic-retinopathy; validation
Article; Proceedings Paper,"Yu, Zehao; Yang, Xi; Sweeting, Gianna L.; Ma, Yinghan; Stolte, Skylar E.; Fang, Ruogu; Wu, Yonghui",Identify diabetic retinopathy-related clinical concepts and their attributes using transformer-based natural language processing methods,bmc medical informatics and decision making,2022,Not found,"Background Diabetic retinopathy (DR) is a leading cause of blindness in American adults. If detected, DR can be treated to prevent further damage causing blindness. There is an increasing interest in developing artificial intelligence (AI) technologies to help detect DR using electronic health records. The lesion-related information documented in fundus image reports is a valuable resource that could help diagnoses of DR in clinical decision support systems. However, most studies for AI-based DR diagnoses are mainly based on medical images; there is limited studies to explore the lesion-related information captured in the free text image reports. Methods In this study, we examined two state-of-the-art transformer-based natural language processing (NLP) models, including BERT and RoBERTa, compared them with a recurrent neural network implemented using Long short-term memory (LSTM) to extract DR-related concepts from clinical narratives. We identified four different categories of DR-related clinical concepts including lesions, eye parts, laterality, and severity, developed annotation guidelines, annotated a DR-corpus of 536 image reports, and developed transformer-based NLP models for clinical concept extraction and relation extraction. We also examined the relation extraction under two settings including 'gold-standard' setting-where gold-standard concepts were used-and end-to-end setting. Results For concept extraction, the BERT model pretrained with the MIMIC III dataset achieve the best performance (0.9503 and 0.9645 for strict/lenient evaluation). For relation extraction, BERT model pretrained using general English text achieved the best strict/lenient F1-score of 0.9316. The end-to-end system, BERT_general_e2e, achieved the best strict/lenient F1-score of 0.8578 and 0.8881, respectively. Another end-to-end system based on the RoBERTa architecture, RoBERTa_general_e2e, also achieved the same performance as BERT_general_e2e in strict scores. Conclusions This study demonstrated the efficiency of transformer-based NLP models for clinical concept extraction and relation extraction. Our results show that it's necessary to pretrain transformer models using clinical text to optimize the performance for clinical concept extraction. Whereas, for relation extraction, transformers pretrained using general English text perform better.",diabetic retinopathy; natural language processing; named entity recognition; deep learning; relation extraction
Article,"Ali, Redha; Hardie, Russell C.; Narayanan, Barath Narayanan; Kebede, Temesguen M.",IMNets: Deep Learning Using an Incremental Modular Network Synthesis Approach for Medical Imaging Applications,applied sciences-basel,2022,Not found,"Deep learning approaches play a crucial role in computer-aided diagnosis systems to support clinical decision-making. However, developing such automated solutions is challenging due to the limited availability of annotated medical data. In this study, we proposed a novel and computationally efficient deep learning approach to leverage small data for learning generalizable and domain invariant representations in different medical imaging applications such as malaria, diabetic retinopathy, and tuberculosis. We refer to our approach as Incremental Modular Network Synthesis (IMNS), and the resulting CNNs as Incremental Modular Networks (IMNets). Our IMNS approach is to use small network modules that we call SubNets which are capable of generating salient features for a particular problem. Then, we build up ever larger and more powerful networks by combining these SubNets in different configurations. At each stage, only one new SubNet module undergoes learning updates. This reduces the computational resource requirements for training and aids in network optimization. We compare IMNets against classic and state-of-the-art deep learning architectures such as AlexNet, ResNet-50, Inception v3, DenseNet-201, and NasNet for the various experiments conducted in this study. Our proposed IMNS design leads to high average classification accuracies of 97.0%, 97.9%, and 88.6% for malaria, diabetic retinopathy, and tuberculosis, respectively. Our modular design for deep learning achieves the state-of-the-art performance in the scenarios tested. The IMNets produced here have a relatively low computational complexity compared to traditional deep learning architectures. The largest IMNet tested here has 0.95 M of the learnable parameters and 0.08 G of the floating-point multiply-add (MAdd) operations. The simpler IMNets train faster, have lower memory requirements, and process images faster than the benchmark methods tested.",medical imaging; deep learning; malaria detection; diabetic retinopathy; tuberculosis detection; modular networks
Article,"Liang, Nan; Yuan, Liming; Wen, Xianbin; Xu, Haixia; Wang, Jingyi",End-To-End Retina Image Synthesis Based on CGAN Using Class Feature Loss and Improved Retinal Detail Loss,ieee access,2022,Not found,"Retinal images are the most direct and effective basis for Diabetic Retinopathy (DR) diagnosis. With the rapid development of deep learning, the technology of retinal image-assisted diagnosis based on deep learning is widely used in the field of DR intelligent diagnosis. However, the training of deep neural network usually requires a large number of annotated samples, but retinal images annotated by professional doctors are cost-expensive and difficult to obtain, which limits the application of deep learning technology in DR intelligent diagnosis. In order to alleviate the scarcity of labelled retinal images, we propose an end-to-end conditional generative adversarial network with class feature loss and improved retinal detail loss. The network combines the above two losses with the adversarial loss, and jointly constrains the generator to generate high-quality retinal images. The proposed retinal detail loss is summed over physiological detail loss which is meant to preserve high-level semantic features of the physiological details contained in the fundus images and pixel loss which ensures the low-level features in synthesized image will not deviate from the real image. In addition, the class feature loss constrains the synthesized images to be consistent with the real images in class features representation, which further makes the synthesized images have pathological features of the corresponding grade. The generated images by the proposed network are evaluated from three objective metrics including the subjective effect and the FID, SWD, which are used to evaluate the quality and diversity of generated images, and the effect of retinal vessel segmentation, respectively. Experimental results demonstrate that our synthesized images have superior performance on both the quality and quantity.",retina; generative adversarial networks; feature extraction; deep learning; image synthesis; physiology; diabetes; diabetic retinopathy; retinal image synthesis; conditional generative adversarial network; deep learning; dr~grading
Proceedings Paper,"Zhao, Ziyuan; Zhang, Kerui; Hao, Xuejie; Tian, Jing; Chua, Matthew Chin Heng; Chen, Li; Xu, Xin",BIRA-NET: BILINEAR ATTENTION NET FOR DIABETIC RETINOPATHY GRADING,2019 ieee international conference on image processing (icip),2019,Not found,"Diabetic retinopathy (DR) is a common retinal disease that leads to blindness. For diagnosis purposes, DR image grading aims to provide automatic DR grade classification, which is not addressed in conventional research methods of binary DR image classification. Small objects in the eye images, like lesions and microaneurysms, are essential to DR grading in medical imaging, but they could easily be influenced by other objects. To address these challenges, we propose a new deep learning architecture, called BiRA-Net, which combines the attention model for feature extraction and bilinear model for fine-grained classification. Furthermore, in considering the distance between different grades of different DR categories, we propose a new loss function, called grading loss, which leads to improved training convergence of the proposed approach. Experimental results are provided to demonstrate the superior performance of the proposed approach.",diabetic retinopathy grading; attention mechanism; bilinear model; convolutional neural network
Article,"Luo, Ling; Xue, Dingyu; Feng, Xinglong",Automatic Diabetic Retinopathy Grading via Self-Knowledge Distillation,electronics,2020,Not found,"Diabetic retinopathy (DR) is a common fundus disease that leads to irreversible blindness, which plagues the working-age population. Automatic medical imaging diagnosis provides a non-invasive method to assist ophthalmologists in timely screening of suspected DR cases, which prevents its further deterioration. However, the state-of-the-art deep-learning-based methods generally have a large amount of model parameters, which makes large-scale clinical deployment a time-consuming task. Moreover, the severity of DR is associated with lesions, and it is difficult for the model to focus on these regions. In this paper, we propose a novel deep-learning technique for grading DR with only image-level supervision. Specifically, we first customize the model with the help of self-knowledge distillation to achieve a trade-off between model performance and time complexity. Secondly, CAM-Attention is used to allow the network to focus on discriminative zone,e.g., microaneurysms, soft/hard exudates, etc.. Considering that directly attaching a classifier after the Side branch will disrupt the hierarchical nature of convolutional neural networks, a Mimicking Module is employed that allows the Side branch to actively mimic the main branch structure. Extensive experiments are conducted on two benchmark datasets, with an AUC of 0.965 and an accuracy of 92.9% for the Messidor dataset and 67.96% accuracy achieved for the challenging IDRID dataset, which demonstrates the superior performance of our proposed method.",image classification; convolutional neural network (cnn); diabetic retinopathy (dr); self-knowledge distillation (skd); attention mechanism
Article,"Jaiswal, Amit Kumar; Tiwari, Prayag; Kumar, Sachin; Al-Rakhami, Mabrook S.; Alrashoud, Mubarak; Ghoneim, Ahmed",Deep Learning-Based Smart IoT Health System for Blindness Detection Using Retina Images,ieee access,2021,Not found,"Deep Learning-based Smart Healthcare is getting so much attention due to real-time applicability in everyone life's, and It has obtained more attention with the convergence of IoT. Diabetic eye disease is the primary cause of blindness between working aged peoples. The major populated Asian countries such as India and China presently account for millions of people and at the verge of an eruption of diabetic inhabitants. These growing number of diabetic patients posed a major challenge among trained doctors to provide medical screening and diagnosis. Our goal is to leverage the deep learning techniques to automate the detection of blind spot in an eye and identify how severe the stage may be. In this paper, we propose an optimized technique on top of recently released pre-trained EfficientNet models for blindness identification in retinal images along with a comparative analysis among various other neural network models. Our fine-tuned EfficientNet-B5 based model evaluation follows the benchmark dataset of retina images captured using fundus photography during varied imaging stages and outperforms CNN and ResNet50 models.",diabetes; retina; retinopathy; medical services; blindness; image resolution; data models; diabetic retinopathy; medical diagnosis; cnn; retina images; iot
Proceedings Paper,"Araujo Alves, Shara Shami; Matos, Alexis Galeno; Almeida, Jefferson Silva; Benevides, Cilis Aragao; Henrique Cunha, Caio Cesar; Crescencio Santiago, Rhuan Victor; Pereira, Renato Francisco; Reboucas Filho, Pedro Pedrosa",A New Strategy for the Detection of Diabetic Retinopathy using a Smartphone App and Machine Learning Methods Embedded on Cloud Computer,2020 ieee 33rd international symposium on computer-based medical systems(cbms 2020),2020,Not found,"Diabetes is a major cause of blindness, kidney failure, heart attacks, stroke and lower limb amputation. According to World Health Organization (WHO), about 422 million people worldwide have diabetes, particularly in low-and middle-income countries, and 1.6 million deaths are directly attributed to diabetes each year. In Brazil, according to the Ministry of Health, the disease affects 7.6% of the population. Our challenge here is to design a deep learning neural network able to fully detect such lesions in digital retinal fundus image to help building robust and scaled solutions to tackle this urgent diabetes scenario. Using Diavision model good performance was obtained with Gray Level Co-occurrence Matrix (GLCM), Local Binary Pattern (LBP) and Support Vector Machine (SVM), presenting 100% for Accuracy and F1-score. Using Messidor model were obtained better performance with VGG16 and SVM, archiving 100% for all metrics. In terms of feature extraction time, the GLCM and VGG16 presented acceptable times, respectively, 17.63ms and 37.87ms.",diabetic; retinopathy; deep features; machine learning; computer aided diagnosis; color fundus photographs
Proceedings Paper,"Zabihollahy, F.; Ukwatta, E.",Fully automated segmentation of optic disk from retinal images using deep learning techniques,medical imaging 2019: computer-aided diagnosis,2019,Not found,"Segmentation of optic disk (OD) from retinal images is a crucial task for early detection of many eye diseases, including glaucoma and diabetic retinopathy. The main goal of this research is to facilitate early diagnosis of certain pathologies via fully automated segmentation of the OD from retinal images. We propose a deep learning-based technique to delineate the boundary of OD from retinal images of patients with diabetic retinopathy and diabetic macular edema. In our method, we first localized OD within a region of interest (ROI) using random forest (RF). The RF is an ensemble algorithm, which trains and combines multiple decision trees to produce a highly accurate classifier. We then used a convolutional neural network (CNN) based model to segment OD from chosen ROIs in the retinal images. The developed algorithm has been validated on 480,249 image patches extracted from 49 images of public Indian diabetic retinopathy image dataset (IDRiD). This dataset includes images with large variability in terms of the spatial location of OD and presence of other eye lesions that resemble the contrast of OD. Validation metrics including average of Dice and Jaccard indexes (DI and JI), Hausdorff distance (HD), and absolute surface difference (ASD) were reported as 82.62 +/- 11.07%, 71.78 +/- 14.87%, 13.19 +/- 10.90 mm, and 22.74 +/- 19.78%, respectively. As compared to other alternative methods, such as K-nearest neighbors (KNN), deformable models, graph-cuts, and image thresholding, our method yielded higher accuracy for OD segmentation in comparison to manual expert delineation. The algorithm-generated results demonstrate the usefulness of our proposed method for automated segmentation of OD from retinal images.",optic disk; glaucoma; diabetic retinopathy; random forest; convolutional neural network
Article,"Lo, Jui-En; Kang, Eugene Yu-Chuan; Chen, Yun-Nung; Hsieh, Yi-Ting; Wang, Nan-Kai; Chen, Ta-Ching; Chen, Kuan-Jen; Wu, Wei-Chi; Hwang, Yih-Shiou; Lo, Fu-Sung; Lai, Chi-Chun",Data Homogeneity Effect in Deep Learning-Based Prediction of Type 1 Diabetic Retinopathy,journal of diabetes research,2021,Not found,"This study is aimed at evaluating a deep transfer learning-based model for identifying diabetic retinopathy (DR) that was trained using a dataset with high variability and predominant type 2 diabetes (T2D) and comparing model performance with that in patients with type 1 diabetes (T1D). The Kaggle dataset, which is a publicly available dataset, was divided into training and testing Kaggle datasets. In the comparison dataset, we collected retinal fundus images of T1D patients at Chang Gung Memorial Hospital in Taiwan from 2013 to 2020, and the images were divided into training and testing T1D datasets. The model was developed using 4 different convolutional neural networks (Inception-V3, DenseNet-121, VGG1, and Xception). The model performance in predicting DR was evaluated using testing images from each dataset, and area under the curve (AUC), sensitivity, and specificity were calculated. The model trained using the Kaggle dataset had an average (range) AUC of 0.74 (0.03) and 0.87 (0.01) in the testing Kaggle and T1D datasets, respectively. The model trained using the T1D dataset had an AUC of 0.88 (0.03), which decreased to 0.57 (0.02) in the testing Kaggle dataset. Heatmaps showed that the model focused on retinal hemorrhage, vessels, and exudation to predict DR. In wrong prediction images, artifacts and low-image quality affected model performance. The model developed with the high variability and T2D predominant dataset could be applied to T1D patients. Dataset homogeneity could affect the performance, trainability, and generalization of the model.",risk-factors; prevalence; validation; mellitus; complications; surveillance; diagnosis; taiwan
Article; Early Access,"Salluri, Deva Kumar; Sistla, Venkatramaphanikumar; Kolli, Venkata Krishna Kishore",HRUNET: Hybrid Residual U - Net for automatic severity prediction of Diabetic Retinopathy,computer methods in biomechanics and biomedical engineering-imaging and visualization,0,Not found,"Diabetic Retinopathy (DR) is a vision-threatening illness that affects diabetics and is the common cause of vision loss among working-age people. Many technologies have been developed to classify DR reliably at an early stage. In this paper, a new hybrid deep-learning algorithm for automatic severity detection in DR is proposed. The proposed Hybrid Residual U-Net (HRUNET) is applied for the contraction and extensive paths from the down-sample to the up-sample to resolve the limitation of plain skip connections in the segmentation of DR. Further, every convolution layer is replaced by a residue module with varying sizes of kernels, and the residual connection is employed in each module to make the network broader without gradient disappearing. These residual modules are linked amid the network to increase the depth of the network. To avoid gradient vanishing, a batch normalization layer follows all convolutional blocks except the bottleneck layers. HRUNet achieves an accuracy of 94% and 91% on the Asia Pacific Tele-Ophthalmology Society (APTOS) and KAGGLE Datasets, respectively. The proposed HRUNET model has a total of 6,315,732 trainable parameters, which are comparatively lower than state-of-art methods such as VGG16, VGG19, and ResNet50 and have higher accuracy on both the datasets.",diabetic retinopathy; vgg16; vgg19; resnet; u-net; hrunet
Proceedings Paper,"Tu, Zhi; Gao, Shenghua; Zhou, Kang; Chen, Xianing; Fu, Huazhu; Gu, Zaiwang; Cheng, Jun; Yu, Zehao; Liu, Jiang",SUNET: A LESION REGULARIZED MODEL FOR SIMULTANEOUS DIABETIC RETINOPATHY AND DIABETIC MACULAR EDEMA GRADING,2020 ieee 17th international symposium on biomedical imaging (isbi 2020),2020,Not found,"Diabetic retinopathy (DR), as a leading ocular disease, is often with a complication of diabetic macular edema (DME). However, most existing works only aim at DR grading but ignore the DME diagnosis, but doctors will do both tasks simultaneously. In this paper, motivated by the advantages of multi-task learning for image classification, and to mimic the behavior of clinicians in visual inspection for patients, we propose a feature Separation and Union Network (SUNet) for simultaneous DR and DME grading. Further, to improve the interpretability of the disease grading, a lesion regularizer is also imposed to regularize our network. Specifically, given an image, our SUNet first extracts a common feature for both DR and DME grading and lesion detection. Then a feature blending block is introduced which alternately uses feature separation and feature union for task-specific feature extraction, where feature separation learns task-specific features for lesion detection and DR and DME grading, and feature union aggregates features corresponding to lesion detection, DR and DME grading. In this way, we can distill the irrelevant features and leverage features of different but related tasks to improve the performance of each given task. Then the task-specific features of the same task at different feature separation steps are concatenated for the prediction of each task. Extensive experiments on the very challenging IDRiD dataset demonstrate that our SUNet significantly outperforms existing methods for both DR and DME grading.",multi-disease diagnosis; lesion regularization; feature blending
Proceedings Paper,"Maryada, Sai Kiran Reddy; Booker, William Lee; Danala, Gopichandh; Ha, Catherine An; Mudduluru, Sanjana; Hougen, Dean F.; Zheng, Bin",Applying a novel two-stage deep-learning model to improve accuracy in detecting retinal fundus images,medical imaging 2022: computer-aided diagnosis,2022,Not found,"Applications of artificial intelligence (AI) in medical imaging informatics have attracted broad research interest. In ophthalmology, for example, automated analysis of retinal fundus photography helps diagnose and monitor illnesses like glaucoma, diabetic retinopathy, hypertensive retinopathy, and cancer. However, building a robust AI model requires a large and diverse dataset for training and validation. While large number of fundus photos are available online, collecting them to create a clean, well-structured dataset is a difficult and manually intensive process. In this work, we propose a two-stage deep-learning system to automatically identify clean retinal fundus images and delete images with severe artifacts. In two stages, two transfer-learning models based the ResNet-50 architecture pre-trained using ImageNet data are built with Increased threshold values on SoftMax to reduce false positives. The first stage classifier identifies easy images, and the remaining difficult (or undetermined) images are further identified by the second stage classifier. Using the Google Search Engine, we initially retrieve 1,227 retinal fundus images. Using this two-stage deep-learning model yields a positive predictive value (PPV) of 98.56% for the target class compared to a single-stage model with a PPV of 95.74%. The two-stage model helps reduce by two-thirds the false positives for the retinal fundus image class. The PPV over all classes increases from 91.9% to 96.6% without compromising the number of images classified by the model. The superior performance of this two-stage model indicates that the building of an optimal training dataset can play an important role in increasing performance of deep-learning models.",deep learning; retinal fundus; transfer learning; multi-stage classification; retinal photography; positive predictive value; k-fold cross validation
Review,"Thompson, Atalie C.; Jammal, Alessandro A.; Medeiros, Felipe A.","A Review of Deep Learning for Screening, Diagnosis, and Detection of Glaucoma Progression",translational vision science & technology,2020,Not found,"Because of recent advances in computing technology and the availability of large datasets, deep learning has risen to the forefront of artificial intelligence, with performances that often equal, or sometimes even exceed, those of human subjects on a variety of tasks, especially those related to image classification and pattern recognition. As one of the medical fields that is highly dependent on ancillary imaging tests, ophthalmology has been in a prime position to witness the application of deep learning algorithms that can help analyze the vast amount of data coming from those tests. In particular, glaucoma stands as one of the conditions where application of deep learning algorithms could potentially lead to better use of the vast amount of information coming from structural and functional tests evaluating the optic nerve and macula. The purpose of this article is to critically review recent applications of deep learning models in glaucoma, discussing their advantages but also focusing on the challenges inherent to the development of such models for screening, diagnosis and detection of progression. After a brief general overview of deep learning and how it compares to traditional machine learning classifiers, we discuss issues related to the training and validation of deep learning models and how they specifically apply to glaucoma. We then discuss specific scenarios where deep learning has been proposed for use in glaucoma, such as screening with fundus photography, and diagnosis and detection of glaucoma progression with optical coherence tomography and standard automated perimetry. Translational Relevance: Deep learning algorithms have the potential to significantly improve diagnostic capabilities in glaucoma, but their application in clinical practice requires careful validation, with consideration of the target population, the reference standards used to build the models, and potential sources of bias.",glaucoma; deep learning; optical coherence tomography; visual fields
Article,"Hoque, Mohammed Enamul; Kipli, Kuryati; Zulcaffle, Tengku Mohd Afendi; Al-Hababi, Abdulrazak Yahya Saleh; Mat, Dayang Azra Awang; Sapawi, Rohana; Joseph, Annie Anak",A Deep Learning Approach for Retinal Image Feature Extraction,pertanika journal of science and technology,2021,Not found,"Retinal image analysis is crucially important to detect the different kinds of life-threatening cardiovascular and ophthalmic diseases as human retinal microvasculature exhibits remarkable abnormalities responding to these disorders. The high dimensionality and random accumulation of retinal images enlarge the data size, that creating complexity in managing and understating the retinal image data. Deep Learning (DL) has been introduced to deal with this big data challenge by developing intelligent tools. Convolutional Neural Network (CNN), a DL approach, has been designed to extract hierarchical image features with more abstraction. To assist the ophthalmologist in eye screening and ophthalmic disease diagnosis, CNN is being explored to create automatic systems for microvascular pattern analysis, feature extraction, and quantification of retinal images. Extraction of the true vessel of retinal microvasculature is significant for further analysis, such as vessel diameter and bifurcation angle quantification. This study proposes a retinal image feature, true vessel segments extraction approach exploiting the Faster RCNN. The fundamental Image Processing principles have been employed for pre-processing the retinal image data. A combined database assembling image data from different publicly available databases have been used to train, test, and evaluate this proposed method. This proposed method has obtained 92.81% sensitivity and 63.34 positive predictive value in extracting true vessel segments from the top first tier of colour retinal images. It is expected to integrate this method into ophthalmic diagnostic tools with further evaluation and validation by analysing the performance.",cardiovascular disease; convolutional neural network; deep learning; feature extraction; retinal imaging
Proceedings Paper,"Filippini, Chiara; Chiarelli, Antonio Maria; Cardone, Daniela; Perpetuini, David; Brescia, Lorenza; Agnifili, Luca; Mastropasqua, Leonardo; Merla, Arcangelo",Age-related ocular surface modifications assessment combining thermal infrared and deep learning approach.,"infrared sensors, devices, and applications xi",2021,Not found,"Age-related diseases such as glaucoma, diabetic retinopathy, and macular degeneration remain the leading causes of low, vision in developed countries. Early detection of such diseases can prevent the risk of progression to blindness. To this end, regular check-ups are encouraged to favor timely eye disease diagnosis. Yet, conducting routine large-scale eye screening can be difficult and time-consuming. In this study, a novel, fast and automatic approach for age-related ocular surface modifications (AR-OSM) assessment is proposed. Indeed, accurate AR-OSM detection in the healthy population may allow to establish age-matched normal ranges, valuable for the preliminary identification of age-related diseases. The task was performed combining thermal infrared (IR) imaging of the eye with artificial intelligence techniques. Thermal IR imaging enables non-invasive real-time imaging of the ocular surface temperature (OST). OST is influenced by ocular factors like the tear film, blood flow perfusion, heat conduction, and convection of the aqueous humor, thus providing significant information on eye health. Ninety-two healthy subjects participated in the experiment (age: 20-90 years-old). A Deep convolutional neural network (DCNN) model was implemented to predict the subjects' age based on their eye IR-image. The DCNN was able to predict the participants' age with a good level of accuracy, reporting a correlation between real and predicted age of r=0.82 and RMSE=9.9years. In conclusion, this method allows an accurate AR-OSM evaluation usable for early recognition of eyes at risk for age-related disease.",eye aging; ir imaging; deep learning; artificial intelligence
Article,"Bi, Shaowei; Chen, Rongxin; Zhang, Kai; Xiang, Yifan; Wang, Ruixin; Lin, Haotian; Yang, Huasheng",Differentiate cavernous hemangioma from schwannoma with artificial intelligence (AI),annals of translational medicine,2020,Not found,"Background: Cavernous hemangioma and schwannoma are tumors that both occur in the orbit. Because the treatment strategies of these two tumors are different, it is necessary to distinguish them at treatment initiation. Magnetic resonance imaging (MRI) is typically used to differentiate these two tumor types; however, they present similar features in MRI images which increases the difficulty of differential diagnosis. This study aims to devise and develop an artificial intelligence framework to improve the accuracy of clinicians' diagnoses and enable more effective treatment decisions by automatically distinguishing cavernous hemangioma from schwannoma. Methods: Material: As the study materials, we chose MRI images as the study materials that represented patients from diverse areas in China who had been referred to our center from more than 45 different hospitals. All images were initially acquired on films, which we scanned into digital versions and recut. Finally, 11,489 images of cavernous hemangioma (from 33 different hospitals) and 3,478 images of schwannoma (from 16 different hospitals) were collected. Labeling: All images were labeled using standard anatomical knowledge and pathological diagnosis. Training: Three types of models were trained in sequence (a total of 96 models), with each model including a specific improvement. The first two model groups were eye- and tumor-positioning models designed to reduce the identification scope, while the third model group consisted of classification models trained to make the final diagnosis. Results: First, internal four-fold cross-validation processes were conducted for all the models. During the validation of the first group, the 32 eye-positioning models were able to localize the position of the eyes with an average precision of 100%. In the second group, the 28 tumor-positioning models were able to reach an average precision above 90%. Subsequently, using the third group, the accuracy of all 32 tumor classification models reached nearly 90%. Next, external validation processes of 32 tumor classification models were conducted. The results showed that the accuracy of the transverse T1-weighted contrast-enhanced sequence reached 91.13%; the accuracy of the remaining models was significantly lower compared with the ground truth. Conclusions: The findings of this retrospective study show that an artificial intelligence framework can achieve high accuracy, sensitivity, and specificity in automated differential diagnosis between cavernous hemangioma and schwannoma in a real-world setting, which can help doctors determine appropriate treatments.",artificial intelligence (ai); differential diagnosis; multicenter
Article,"Li, Qianjin; Fan, Shanshan; Chen, Changsheng",An Intelligent Segmentation and Diagnosis Method for Diabetic Retinopathy Based on Improved U-NET Network,journal of medical systems,2019,Not found,"Due to insufficient samples, the generalization performance of deep network is insufficient. In order to solve this problem, an improved U-net based image automatic segmentation and diagnosis algorithm was proposed, in which the max-pooling operation in original U-net model was replaced by the convolution operation to keep more feature information. Firstly, the regions of 128x128 were extracted from all slices of the patients as data samples. Secondly, the patient samples were divided into training sample set and testing sample set, and data augmentation was performed on the training samples. Finally, all the training samples were adopted to train the model. Compared with Fully Convolutional Network (FCN) model and max-pooling based U-net model, DSC and CR coefficients of the proposed method achieve the best results, while PM coefficient is 2.55 percentage lower than the maximum value in the two comparison models, and Average Symmetric Surface Distance is slightly higher than the minimum value of the two comparison models by 0.004. The experimental results show that the proposed model can achieve good segmentation and diagnosis results.",generalization performance; deep learning; diabetic retinopathy; u-net model; fully convolutional network; intelligent diagnosis
Proceedings Paper,"Kamble, Vaibhav V.; Kokate, Rajendra D.","Automatic Identification and Classification of Microaneurysms, Exudates and Blood Vessel for Early Diabetic Retinopathy Recognition",computational intelligence in data mining,2019,Not found,"Diabetic retinopathy (DR) is vital concern that leads to blindness in adults around the world. In this paper, we proposed a system for early identification and classification of retinal fundus images as DR or non-DR. The ophthalmic features like blood vessels, microaneurysms and exudates are extracted and calculated by applying morphological of 2D median filter, multilevel histogram analysis and intensity transformation, respectively. The proposed system is executed on DIARETDBO 130 and DIARETDB1 89 fundus images dataset using artificial neural networks (ANNs). Result analysis is completed by calculating mean, variance, standard deviation, and correlation. We trained the proposed system model by multilayer perceptron with back-propagation, and system achieved sensitivity 0.83 and specificity 0.045 for DIARETDBO and sensitivity 0.95 and specificity 0.2 for DIARETDB1.",diabetic retinopathy; blood vessels; microaneurysms; exudates; tortuosity; ann; fundus images
Proceedings Paper,"Yu, Zehao; Yang, Xi; Sweeting, Gianna L.; Ma, Yinghan; Stolte, Skylar E.; Fang, Ruogu; Wu, Yonghui",Identify Diabetic Retinopathy-related Clinical Concepts Using Transformer-based Natural Language Processing Methods,2021 ieee 9th international conference on healthcare informatics (ichi 2021),2021,Not found,"Diabetic retinopathy (DR) is a leading cause of blindness in American adults. If detected early, DR can be treated to preventing further damage causing blindness, therefore, early detection is very important for the treatment of DR. There is an increasing interest in developing Al technologies to help early detection of DR using electronic health records (EHR). The detailed diagnoses information documented in image reports is a valuable resource that could help detect lesions from the medical image, thus helping early detection of DR. In this study, we examined two state-of-the-art transformer-based natural language processing models, including BERT and RoBERTa, to extract DR-related concepts from clinical narratives. We identified four different categories of DR-related clinical concepts including lesions, eye parts, laterality, and severity, developed annotation guidelines, annotated a DR-corpus of 536 image reports, and trained four transformer-based NLP models for clinical concept extraction. The experimental results show that the BERT model pretrained with the MIMIC III dataset achieved the best strict/lenient F1-score of 0.9503 and 0.9645, respectively.",diabetic retinopathy; natural language processing; named entity recognition; deep learning
Review,"Bhambra, Nishaant; Antaki, Fares; El Malt, Farida; Xu, AnQi; Duval, Renaud",Deep learning for ultra-widefield imaging: a scoping review,graefes archive for clinical and experimental ophthalmology,2022,Not found,"Purpose This article is a scoping review of published and peer-reviewed articles using deep-learning (DL) applied to ultra-widefield (UWF) imaging. This study provides an overview of the published uses of DL and UWF imaging for the detection of ophthalmic and systemic diseases, generative image synthesis, quality assessment of images, and segmentation and localization of ophthalmic image features. Methods A literature search was performed up to August 31st, 2021 using PubMed, Embase, Cochrane Library, and Google Scholar. The inclusion criteria were as follows: (1) deep learning, (2) ultra-widefield imaging. The exclusion criteria were as follows: (1) articles published in any language other than English, (2) articles not peer-reviewed (usually preprints), (3) no full-text availability, (4) articles using machine learning algorithms other than deep learning. No study design was excluded from consideration. Results A total of 36 studies were included. Twenty-three studies discussed ophthalmic disease detection and classification, 5 discussed segmentation and localization of ultra-widefield images (UWFIs), 3 discussed generative image synthesis, 3 discussed ophthalmic image quality assessment, and 2 discussed detecting systemic diseases via UWF imaging. Conclusion The application of DL to UWF imaging has demonstrated significant effectiveness in the diagnosis and detection of ophthalmic diseases including diabetic retinopathy, retinal detachment, and glaucoma. DL has also been applied in the generation of synthetic ophthalmic images. This scoping review highlights and discusses the current uses of DL with UWF imaging, and the future of DL applications in this field.",deep learning; ultra-widefield imaging; artificial intelligence; scoping review; machine learning; quality assessment
Article,"Lee, JoonHo; Lee, Joonseok; Cho, Sooah; Song, JiEun; Lee, Minyoung; Kim, Sung Ho; Lee, Jin Young; Shin, Dae Hwan; Kim, Joon Mo; Bae, Jung Hun; Song, Su Jeong; Sagong, Min; Park, Donggeun",Development of Decision Support Software for Deep Learning-Based Automated Retinal Disease Screening Using Relatively Limited Fundus Photograph Data,electronics,2021,Not found,"Purpose-This study was conducted to develop an automated detection algorithm for screening fundus abnormalities, including age-related macular degeneration (AMD), diabetic retinopathy (DR), epiretinal membrane (ERM), retinal vascular occlusion (RVO), and suspected glaucoma among health screening program participants. Methods-The development dataset consisted of 43,221 retinal fundus photographs (from 25,564 participants, mean age 53.38 +/- 10.97 years, female 39.0%) from a health screening program and patients of the Kangbuk Samsung Hospital Ophthalmology Department from 2006 to 2017. We evaluated our screening algorithm on independent validation datasets. Five separate one-versus-rest (OVR) classification algorithms based on deep convolutional neural networks (CNNs) were trained to detect AMD, ERM, DR, RVO, and suspected glaucoma. The ground truth for both development and validation datasets was graded at least two times by three ophthalmologists. The area under the receiver operating characteristic curve (AUC), sensitivity, and specificity were calculated for each disease, as well as their macro-averages. Results-For the internal validation dataset, the average sensitivity was 0.9098 (95% confidence interval (CI), 0.8660-0.9536), the average specificity was 0.9079 (95% CI, 0.8576-0.9582), and the overall accuracy was 0.9092 (95% CI, 0.8769-0.9415). For the external validation dataset consisting of 1698 images, the average of the AUCs was 0.9025 (95% CI, 0.8671-0.9379). Conclusions-Our algorithm had high sensitivity and specificity for detecting major fundus abnormalities. Our study will facilitate expansion of the applications of deep learning-based computer-aided diagnostic decision support tools in actual clinical settings. Further research is needed to improved generalization for this algorithm.",deep learning; diagnosis; fundus
Article,"Wang, Chengjin; Zhang, Yuwei; Xu, Shuai; Liu, Yuyan; Xie, Lindan; Wu, Changlong; Yang, Qianhui; Chu, Yanhua; Ye, Qing",Research on Assistant Diagnosis of Fundus Optic Neuropathy Based on Deep Learning,current eye research,2023,Not found,"Purpose The purpose of this study was to use the neural network to distinguish optic edema (ODE), and optic atrophy from normal fundus images and try to use visualization to explain the artificial intelligence methods. Methods Three hundred and sixty-seven images of ODE, 206 images of optic atrophy, and 231 images of normal fundus were used, which were provided by two hospitals. A set of image preprocessing and data enhancement methods were created and a variety of different neural network models, such as VGG16, VGG19, Inception V3, and 50-layer Deep Residual Learning (ResNet50) were used. The accuracy, recall, F1-score, and ROC curve under different networks were analyzed to evaluate the performance of models. Besides, CAM (class activation mapping) was utilized to find the focus of neural network and visualization of neural network with feature fusion. Results Our image preprocessing and data enhancement method significantly improved the accuracy of model performance by about 10%. Among the networks, VGG16 had the best effect, as the accuracy of ODE, optic atrophy and normal fundus were 98, 90, and 95%, respectively. The macro-average and micro-average of VGG16 both reached 0.98. From CAM we can clearly find out that the focus area of the network is near the optic cup. From feature fusion images, we can find out the difference between the three types fundus images. Conclusion Through image preprocessing, data enhancement, and neural network training, we applied artificial intelligence to identify ophthalmic diseases, acquired the focus area through CAM, and identified the difference between the three ophthalmic diseases through neural network middle layers visualization. With the help of assistant diagnosis, ophthalmologists can evaluate cases more precisely and more clearly.",deep learning; convolutional neural network; visualization; cam; funds photos
Proceedings Paper,"Santos, Carlos; De Aguiar, Marilton Sanchotene; Welfer, Daniel; Belloni, Bruno",Deep Neural Network Model based on One-Stage Detector for Identifying Fundus Lesions,2021 international joint conference on neural networks (ijcnn),2021,Not found,"Diabetic Retinopathy is a major cause of vision loss caused by retina lesions, including hard and soft exudates, microaneurysms, and hemorrhages. The development of a computational tool capable of detecting these lesions can assist in the early diagnosis of the most severe forms of the lesions and assist in the screening process and definition of the best treatment form. However, the detection of tiny objects of very different sizes and shapes makes the detection process more complicated. This paper proposes a computational model based on pre-trained convolutional neural networks capable of detecting fundus lesions to promote medical diagnosis support. We trained, adjusted, and evaluated the model using the DDR diabetic retinopathy dataset and implemented it based on a YOLOv4 architecture and Darknet framework, achieving an mAP of 7.26% and a mIoU of 11.64%. The experimental results show that the proposed model presented results superior to those obtained in related works found in the literature.",diabetic retinopathy; fundus image; deep learning; lesion detection
Article,"Escorcia-Gutierrez, Jose; Torrents-Barrena, Jordina; Gamarra, Margarita; Madera, Natasha; Romero-Aroca, Pedro; Valls, Aida; Puig, Domenec",A Feature Selection Strategy to Optimize Retinal Vasculature Segmentation,cmc-computers materials & continua,2022,Not found,"Diabetic retinopathy (DR) is a complication of diabetes mellitus that appears in the retina. Clinitians use retina images to detect DR pathological signs related to the occlusion of tiny blood vessels. Such occlusion brings a degenerative cycle between the breaking off and the new generation of thinner and weaker blood vessels. This research aims to develop a suitable retinal vasculature segmentation method for improving retinal screening procedures by means of computer-aided diagnosis systems. The blood vessel segmenta-tion methodology relies on an effective feature selection based on Sequential Forward Selection, using the error rate of a decision tree classifier in the evaluation function. Subsequently, the classification process is performed by three alternative approaches: artificial neural networks, decision trees and support vector machines. The proposed methodology is validated on three publicly accessible datasets and a private one provided by Hospital Sant Joan of Reus. In all cases we obtain an average accuracy above 96% with a sensitivity of 72% in the blood vessel segmentation process. Compared with the state-of -the-art, our approach achieves the same performance as other methods that need more computational power. Our method significantly reduces the number of features used in the segmentation process from 20 to 5 dimensions. The implementation of the three classifiers confirmed that the five selected features have a good effectiveness, independently of the classification algorithm.",diabetic retinopathy; artificial neural networks; decision trees; support vector machines; feature selection; retinal vasculature segmentation
Proceedings Paper,"Abbasi-Sureshjani, Samaneh; Dashtbozorg, Behdad; Romeny, Bart M. ter Haar; Fleuret, Francois",Exploratory Study on Direct Prediction of Diabetes Using Deep Residual Networks,vipimage 2017,2018,Not found,"Diabetes is threatening the health of many people in the world. People may be diagnosed with diabetes only when symptoms or complications such as diabetic retinopathy start to appear. Retinal images reflect the health of the circulatory system and they are considered as a cheap and patient-friendly source of information for diagnosis purposes. Convolutional neural networks have enhanced the performance of conventional image processing techniques significantly by neglecting inconsistent feature extraction pipelines and learning informative features automatically from data. In this work we explore the possibility of using the deep residual networks as one of the state-of-the-art convolutional networks to diagnose diabetes directly from retinal images, without using any blood glucose information. The results indicate that convolutional networks are able to capture informative differences between healthy and diabetic patients and it is possible to differentiate between these two groups using only the retinal images. The performance of the proposed method is significantly higher than human experts.",retinal images; diabetes; diabetic retinopathy; deep learning; resnet
Article,"Bhattacharya, Sweta; Maddikunta, Praveen Kumar Reddy; Pham, Quoc-Viet; Gadekallu, Thippa Reddy; Krishnan, S. Siva Rama; Chowdhary, Chiranji Lal; Alazab, Mamoun; Piran, Md. Jalil",Deep learning and medical image processing for coronavirus (COVID-19) pandemic: A survey,sustainable cities and society,2021,Not found,"Since December 2019, the coronavirus disease (COVID-19) outbreak has caused many death cases and affected all sectors of human life. With gradual progression of time, COVID-19 was declared by the world health organization (WHO) as an outbreak, which has imposed a heavy burden on almost all countries, especially ones with weaker health systems and ones with slow responses. In the field of healthcare, deep learning has been implemented in many applications, e.g., diabetic retinopathy detection, lung nodule classification, fetal localization, and thyroid diagnosis. Numerous sources of medical images (e.g., X-ray, CT, and MRI) make deep learning a great technique to combat the COVID-19 outbreak. Motivated by this fact, a large number of research works have been proposed and developed for the initial months of 2020. In this paper, we first focus on summarizing the state-of-the-art research works related to deep learning applications for COVID-19 medical image processing. Then, we provide an overview of deep learning and its applications to healthcare found in the last decade. Next, three use cases in China, Korea, and Canada are also presented to show deep learning applications for COVID-19 medical image processing. Finally, we discuss several challenges and issues related to deep learning implementations for COVID-19 medical image processing, which are expected to drive further studies in controlling the outbreak and controlling the crisis, which results in smart healthy cities.",artificial intelligence (ai); big data; coronavirus pandemic; covid-19; epidemic outbreak; deep learning; medical image processing
Article,"Nazir, Tahira; Irtaza, Aun; Javed, Ali; Malik, Hafiz; Hussain, Dildar; Naqvi, Rizwan Ali",Retinal Image Analysis for Diabetes-Based Eye Disease Detection Using Deep Learning,applied sciences-basel,2020,Not found,"Diabetic patients are at the risk of developing different eye diseases i.e., diabetic retinopathy (DR), diabetic macular edema (DME) and glaucoma. DR is an eye disease that harms the retina and DME is developed by the accumulation of fluid in the macula, while glaucoma damages the optic disk and causes vision loss in advanced stages. However, due to slow progression, the disease shows few signs in early stages, hence making disease detection a difficult task. Therefore, a fully automated system is required to support the detection and screening process at early stages. In this paper, an automated disease localization and segmentation approach based on Fast Region-based Convolutional Neural Network (FRCNN) algorithm with fuzzy k-means (FKM) clustering is presented. The FRCNN is an object detection approach that requires the bounding-box annotations to work; however, datasets do not provide them, therefore, we have generated these annotations through ground-truths. Afterward, FRCNN is trained over the annotated images for localization that are then segmented-out through FKM clustering. The segmented regions are then compared against the ground-truths through intersection-over-union operations. For performance evaluation, we used the Diaretdb1, MESSIDOR, ORIGA, DR-HAGIS, and HRF datasets. A rigorous comparison against the latest methods confirms the efficacy of the approach in terms of both disease detection and segmentation.",glaucoma; deep learning; diabetic retinopathy; fuzzy k-means clustering; medical imaging
Review,"Buisson, Mathieu; Navel, Valentin; Labbe, Antoine; Watson, Stephanie L.; Baker, Julien S.; Murtagh, Patrick; Chiambaretta, Frederic; Dutheil, Frederic",Deep learning versus ophthalmologists for screening for glaucoma on fundus examination: A systematic review and meta-analysis,clinical and experimental ophthalmology,2021,Not found,"Background In this systematic review and meta-analysis, we aimed to compare deep learning versus ophthalmologists in glaucoma diagnosis on fundus examinations. Method PubMed, Cochrane, Embase, and ScienceDirect databases were searched for studies reporting a comparison between the glaucoma diagnosis performance of deep learning and ophthalmologists on fundus examinations on the same datasets, until 10 December 2020. Studies had to report an area under the receiver operating characteristics (AUC) with SD or enough data to generate one. Results We included six studies in our meta-analysis. There was no difference in AUC between ophthalmologists (AUC = 82.0, 95% confidence intervals [CI] 65.4-98.6) and deep learning (97.0, 89.4-104.5). There was also no difference using several pessimistic and optimistic variants of our meta-analysis: the best (82.2, 60.0-104.3) or worst (77.7, 53.1-102.3) ophthalmologists versus the best (97.1, 89.5-104.7) or worst (97.1, 88.5-105.6) deep learning of each study. We did not retrieve any factors influencing those results. Conclusion Deep learning had similar performance compared to ophthalmologists in glaucoma diagnosis from fundus examinations. Further studies should evaluate deep learning in clinical situations.",artificial intelligence; deep learning; glaucoma; machine learning; screening
Article,"Asif, Sohaib; Amjad, Kamran; Qurrat-ul-Ain",Deep Residual Network for Diagnosis of Retinal Diseases Using Optical Coherence Tomography Images,interdisciplinary sciences-computational life sciences,2022,Not found,"Diabetic retinopathy occurs due to damage to the blood vessels in the retina, and it is a major health problem in recent years that progresses slowly without recognizable symptoms. Optical coherence tomography (OCT) is a popular and widely used noninvasive imaging modality for the diagnosis of diabetic retinopathy. Accurate and early diagnosis of this disease using OCT images is crucial for the prevention of blindness. In recent years, several deep learning methods have been very successful in automating the process of detecting retinal diseases from OCT images. However, most methods face reliability and interpretability issues. In this study, we propose a deep residual network for the classification of four classes of retinal diseases, namely diabetic macular edema (DME), choroidal neovascularization (CNV), DRUSEN and NORMAL in OCT images. The proposed model is based on the popular architecture called ResNet50, which eliminates the vanishing gradient problem and is pre-trained on large dataset such as ImageNet and trained end-to-end on the publicly available OCT image dataset. We removed the fully connected layer of ResNet50 and placed our new fully connected block on top to improve the classification accuracy and avoid overfitting in the proposed model. The proposed model was trained and evaluated using different performance metrics, including receiver operating characteristic (ROC) curve on a dataset of 84,452 OCT images with expert disease grading as DRUSEN, CNV, DME and NORMAL. The proposed model provides an improved overall classification accuracy of 99.48% with only 5 misclassifications out of 968 test samples and outperforms existing methods on the same dataset. The results show that the proposed model is well suited for the diagnosis of retinal diseases in ophthalmology clinics. [GRAPHICS] .",optical coherence tomography; computer-aided detection and diagnosis; residual network; deep learning; transfer learning
Proceedings Paper,"Shah, Abhay; Lynch, Stephanie; Niemeijer, Meindert; Amelon, Ryan; Clarida, Warren; Folk, James; Russell, Stephen; Wu, Xiaodong; Abramoff, Michael D.",SUSCEPTIBILITY TO MISDIAGNOSIS OF ADVERSARIAL IMAGES BY DEEP LEARNING BASED RETINAL IMAGE ANALYSIS ALGORITHMS,2018 ieee 15th international symposium on biomedical imaging (isbi 2018),2018,Not found,"Deep learning algorithms, typically implemented as Convolutional Neural Networks (CNNs), in recent years have gained traction in medical image analysis. The majority of CNNs employed in retinal image diagnosis applications are image-based; wherein input is the retinal image and output is the classification/diagnosis, resulting in a black-box like algorithm. In contrast, hybrid lesion-based algorithms employ multiple CNN-based detectors to categorically detect various lesions in the image, and final diagnosis is computed from combination of detector outputs. Such algorithms are more physiologically plausible and provides explainability of the final prediction through intermediate detector outputs. Both classes of algorithms have reported equal diagnostic performance and outperform clinical experts in detecting referable diabetic retinopathy (rDR). However, CNNs are sensitive to adversarial images where a limited number of pixels are modified by a fraction of intensity while preserving global image context; leading to CNN misclassification. We compared diagnostic accuracy of the two classes of algorithms on adversarial images generated from rDR retinal images and results show that image-based CNNs are significantly more susceptible to adversarial images than hybrid lesion-based algorithms.",image adversarial; diabetic retinopathy; convolutional neural network
Article,"Elmoufidi, Abdelali; Skouta, Ayoub; Jai-andaloussi, Said; Ouchetto, Ouail",Deep multiple instance learning for automatic glaucoma prevention and auto-annotation using color fundus photography,progress in artificial intelligence,2022,Not found,"In the area of ophthalmology, glaucoma affects an increasing number of people. It is a major cause of blindness. Early detection prevents severe ocular complications such as glaucoma, cystoid macular edema, or diabetic proliferative retinopathy. Intelligent systems are proven to be beneficial for the assessment of glaucoma. In this paper, we describe an approach to automate the diagnosis of glaucoma disease, based on color funds photography using deep learning. The setup of the proposed framework is ordered as follows: The bidimensional empirical mode decomposition (BEMD) algorithm is applied to decompose the ROI to components (BIMFs + residue). CNN architecture VGG19 is implemented to extract features from decomposed BEMD components. The features obtained are the input parameters of the implemented classifier based on full connect layers and softmax. To train the built model, we have used the public dataset RIM-ONE DL. To test our models, we have used a part of RIM-ONE DL and REFUGE. The average obtained sensitivity, specificity, accuracy and AUC rates are, respectively, 99.14%, 99.19%, 99.13%, 99.09% and 99.17%, 99.24%, 99.20%, 99.18% in RIM-ONE DL and REFUGE dataset. The experimental results obtained from different datasets demonstrate the efficiency and robustness of the proposed approach. A comparison with some recent previous work in the literature has shown a significant advancement in our proposal.",computer-aided diagnosis; convolutional neural networks (cnns); deep learning; glaucoma; medical imaging; machine learning; ophthalmology
Article,"Murugan, R.; Roy, Parthapratim; Singh, Utkarsh",An abnormality detection of retinal fundus images by deep convolutional neural networks,multimedia tools and applications,2020,Not found,"Identification of retinal diseases is a test for the ophthalmologists as the anomalies are just unmistakable at the beginning period. Early detection of these diseases can avoid lasting vision misfortune. Dealing with a lot of retinal images and location of variations from the norm because of these infections is difficult just as tedious. In this work, the deep learning algorithm has proposed to check the abnormality condition of retina with the help of retinal fundus images. In deep leaning a training set is produced with features of variations from the norm present in the retinal images and the infection the retina is experiencing. The deep Convolutional Neural Network (CNN) classifier predicts the infection for every retinal images in the wake of social event the learning from training the set. The rightness of desire is resolved to evaluate the viability of the classifier. The proposed technique was executed in MATLAB and assessed both normal and abnormal diabetic retinopathy retinal images of IDRID, ROC, and local datasets. The proposed technique has gotten better execution measurements, for example, sensitivity of 98.2%, Specificity of 98.45%, accuracy of 98.56% and average area under receiver operating characteristics of 0.9 when contrasted with different conditions of the workmanship strategies.",retina; diabetic retinopathy; machine leaning; deep learning; convolutional neural network
Proceedings Paper,"Li, Qi; Peng, Chenglei; Ma, Yazhen; Du, Sidan; Guo, Bin; Li, Yang",Pixel-level Diabetic Retinopathy Lesion Detection Using Multi-scale Convolutional Neural Network,2021 ieee 3rd global conference on life sciences and technologies (ieee lifetech 2021),2021,Not found,"Diabetic retinopathy (DR) is one of the leading causes of preventable blindness. It's urgent to develop reliable methods for auto DR screening, the key of which is the detection of lesions. This paper presents an innovative method to detect DR lesions in pixel-level. We design a multi-scale Convolution Neural Network (CNN) that make the full use of multiple different scales with complementary image information. Experiments are carried out on both private and public datasets. Results show that multi-scale CNN model outperforms single-scale CNN model and other state-of-the-art approaches.",medical image processing; diabetic retinopathy; lesion detection; multi-scale cnn; computer-aided diagnosis
Review,"Heidari, Arash; Navimipour, Nima Jafari; Unal, Mehmet; Toumaj, Shiva",The COVID-19 epidemic analysis and diagnosis using deep learning: A systematic literature review and future directions,computers in biology and medicine,2022,Not found,"Since December 2019, the COVID-19 outbreak has resulted in countless deaths and has harmed all facets of human existence. COVID-19 has been designated an epidemic by the World Health Organization (WHO), which has placed a tremendous burden on nearly all countries, especially those with weak health systems. However, Deep Learning (DL) has been applied in several applications and many types of detection applications in the medical field, including thyroid diagnosis, lung nodule recognition, fetal localization, and detection of diabetic retinopathy. Furthermore, various clinical imaging sources, like Magnetic Resonance Imaging (MRI), X-ray, and Computed Tomography (CT), make DL a perfect technique to tackle the epidemic of COVID-19. Inspired by this fact, a considerable amount of research has been done. A Systematic Literature Review (SLR) has been used in this study to discover, assess, and integrate findings from relevant studies. DL techniques used in COVID-19 have also been categorized into seven main distinct categories as Long Short Term Memory Networks (LSTM), Self-Organizing Maps (SOMs), Conventional Neural Networks (CNNs), Generative Adversarial Networks (GANs), Recurrent Neural Networks (RNNs), Autoencoders, and hybrid approaches. Then, the state-of-the-art studies connected to DL techniques and applications for health problems with COVID-19 have been highlighted. Moreover, many issues and problems associated with DL implementation for COVID-19 have been addressed, which are anticipated to stimulate more investigations to control the prevalence and disaster control in the future. According to the findings, most papers are assessed using characteristics such as accuracy, delay, robustness, and scalability. Meanwhile, other features are underutilized, such as security and convergence time. Python is also the most commonly used language in papers, accounting for 75% of the time. According to the investigation, 37.83% of applications have identified chest CT/chest X-ray images for patients.",artificial intelligence; covid-19; deep learning; neural networks; pandemic
Article,"Sayres, Rory; Taly, Ankur; Rahimy, Ehsan; Blumer, Katy; Coz, David; Hammel, Naama; Krause, Jonathan; Narayanaswamy, Arunachalam; Rastegar, Zahra; Wu, Derek; Xu, Shawn; Barb, Scott; Joseph, Anthony; Shumski, Michael; Smith, Jesse; Sood, Arjun B.; Corrado, Greg S.; Peng, Lily; Webster, Dale R.",Using a Deep Learning Algorithm and Integrated Gradients Explanation to Assist Grading for Diabetic Retinopathy,ophthalmology,2019,Not found,"Purpose: To understand the impact of deep learning diabetic retinopathy (DR) algorithms on physician readers in computer-assisted settings. Design: Evaluation of diagnostic technology. Participants: One thousand seven hundred ninety-six retinal fundus images from 1612 diabetic patients. Methods: Ten ophthalmologists (5 general ophthalmologists, 4 retina specialists, 1 retina fellow) read images for DR severity based on the International Clinical Diabetic Retinopathy disease severity scale in each of 3 conditions: unassisted, grades only, or grades plus heatmap. Grades-only assistance comprised a histogram of DR predictions (grades) from a trained deep-learning model. For grades plus heatmap, we additionally showed explanatory heatmaps. Main Outcome Measures: For each experiment arm, we computed sensitivity and specificity of each reader and the algorithm for different levels of DR severity against an adjudicated reference standard. We also measured accuracy (exact 5-class level agreement and Cohen's quadratically weighted k), reader-reported confidence (5-point Likert scale), and grading time. Results: Readers graded more accurately with model assistance than without for the grades-only condition (P < 0.001). Grades plus heatmaps improved accuracy for patients with DR (P < 0.001), but reduced accuracy for patients without DR (P = 0.006). Both forms of assistance increased readers' sensitivity moderate-or-worse DR: unassisted: mean, 79.4% [95% confidence interval (CI), 72.3% -86.5%]; grades only: mean, 87.5% [95% CI, 85.1%-89.9%]; grades plus heatmap: mean, 88.7% [95% CI, 84.9%-92.5%] without a corresponding drop in specificity (unassisted: mean, 96.6% [95% CI, 95.9%-97.4%]; grades only: mean, 96.1% [95% CI, 95.5%-96.7%]; grades plus heatmap: mean, 95.5% [95% CI, 94.8%-96.1%]). Algorithmic assistance increased the accuracy of retina specialists above that of the unassisted reader or model alone; and increased grading confidence and grading time across all readers. For most cases, grades plus heatmap was only as effective as grades only. Over the course of the experiment, grading time decreased across all conditions, although most sharply for grades plus heatmap. Conclusions: Deep learning algorithms can improve the accuracy of, and confidence in, DR diagnosis in an assisted read setting. They also may increase grading time, although these effects may be ameliorated with experience. (C) 2018 by the American Academy of Ophthalmology.",major risk-factors; global prevalence; retinal images; validation; ophthalmoscopy; photography; specificity; sensitivity
Article; Proceedings Paper,"Fourcade, A.; Khonsari, R. H.",Deep learning in medical image analysis: A third eye for doctors,journal of stomatology oral and maxillofacial surgery,2019,Not found,"Aim and scope: Artificial intelligence (AI) in medicine is a fast-growing field. The rise of deep learning algorithms, such as convolutional neural networks (CNNs), offers fascinating perspectives for the automation of medical image analysis. In this systematic review article, we screened the current literature and investigated the following question: Can deep learning algorithms for image recognition improve visual diagnosis in medicine?'' Materials and methods: We provide a systematic review of the articles using CNNs for medical image analysis, published in the medical literature before May 2019. Articles were screened based on the following items: type of image analysis approach (detection or classification), algorithm architecture, dataset used, training phase, test, comparison method (with specialists or other), results (accuracy, sensibility and specificity) and conclusion. Results: We identified 352 articles in the PubMed database and excluded 327 items for which performance was not assessed (review articles) or for which tasks other than detection or classification, such as segmentation, were assessed. The 25 included papers were published from 2013 to 2019 and were related to a vast array of medical specialties. Authors were mostly from North America and Asia. Large amounts of qualitative medical images were necessary to train the CNNs, often resulting from international collaboration. The most common CNNs such as AlexNet and GoogleNet, designed for the analysis of natural images, proved their applicability to medical images. Conclusion: CNNs are not replacement solutions for medical doctors, but will contribute to optimize routine tasks and thus have a potential positive impact on our practice. Specialties with a strong visual component such as radiology and pathology will be deeply transformed. Medical practitioners, including surgeons, have a key role to play in the development and implementation of such devices. (C) 2019 Published by Elsevier Masson SAS.",deep learning; artificial intelligence; neural network; image analysis; systematic review; computer vision
Article,"Li, Yu-Hsuan; Sheu, Wayne Huey-Herng; Chou, Chien-Chih; Lin, Chun-Hsien; Cheng, Yuan-Shao; Wang, Chun-Yuan; Wu, Chieh Liang; Lee, I. -Te",The Clinical Influence after Implementation of Convolutional Neural Network-Based Software for Diabetic Retinopathy Detection in the Primary Care Setting,life-basel,2021,Not found,"Deep learning-based software is developed to assist physicians in terms of diagnosis; however, its clinical application is still under investigation. We integrated deep-learning-based software for diabetic retinopathy (DR) grading into the clinical workflow of an endocrinology department where endocrinologists grade for retinal images and evaluated the influence of its implementation. A total of 1432 images from 716 patients and 1400 images from 700 patients were collected before and after implementation, respectively. Using the grading by ophthalmologists as the reference standard, the sensitivity, specificity, and area under the receiver operating characteristic curve (AUC) to detect referable DR (RDR) were 0.91 (0.87-0.96), 0.90 (0.87-0.92), and 0.90 (0.87-0.93) at the image level; and 0.91 (0.81-0.97), 0.84 (0.80-0.87), and 0.87 (0.83-0.91) at the patient level. The monthly RDR rate dropped from 55.1% to 43.0% after implementation. The monthly percentage of finishing grading within the allotted time increased from 66.8% to 77.6%. There was a wide range of agreement values between the software and endocrinologists after implementation (kappa values of 0.17-0.65). In conclusion, we observed the clinical influence of deep-learning-based software on graders without the retinal subspecialty. However, the validation using images from local datasets is recommended before clinical implementation.",area under the curve; diabetes; deep learning; image; retinopathy
Article,"Yoo, Tae Keun; Choi, Joon Yul; Kim, Hong Kyu",Feasibility study to improve deep learning in OCT diagnosis of rare retinal diseases with few-shot classification,medical & biological engineering & computing,2021,Not found,"Deep learning (DL) has been successfully applied to the diagnosis of ophthalmic diseases. However, rare diseases are commonly neglected due to insufficient data. Here, we demonstrate that few-shot learning (FSL) using a generative adversarial network (GAN) can improve the applicability of DL in the optical coherence tomography (OCT) diagnosis of rare diseases. Four major classes with a large number of datasets and five rare disease classes with a few-shot dataset are included in this study. Before training the classifier, we constructed GAN models to generate pathological OCT images of each rare disease from normal OCT images. The Inception-v3 architecture was trained using an augmented training dataset, and the final model was validated using an independent test dataset. The synthetic images helped in the extraction of the characteristic features of each rare disease. The proposed DL model demonstrated a significant improvement in the accuracy of the OCT diagnosis of rare retinal diseases and outperformed the traditional DL models, Siamese network, and prototypical network. By increasing the accuracy of diagnosing rare retinal diseases through FSL, clinicians can avoid neglecting rare diseases with DL assistance, thereby reducing diagnosis delay and patient burden.",rare diseases; optical coherence tomography; few-shot learning; deep learning; generative adversarial network
Article,"Srinivasan, Vignesh; Strodthoff, Nils; Ma, Jackie; Binder, Alexander; Mueller, Klaus-Robert; Samek, Wojciech",To pretrain or not? A systematic analysis of the benefits of pretraining in diabetic retinopathy,plos one,2022,Not found,"There is an increasing number of medical use cases where classification algorithms based on deep neural networks reach performance levels that are competitive with human medical experts. To alleviate the challenges of small dataset sizes, these systems often rely on pretraining. In this work, we aim to assess the broader implications of these approaches in order to better understand what type of pretraining works reliably (with respect to performance, robustness, learned representation etc.) in practice and what type of pretraining dataset is best suited to achieve good performance in small target dataset size scenarios. Considering diabetic retinopathy grading as an exemplary use case, we compare the impact of different training procedures including recently established self-supervised pretraining methods based on contrastive learning. To this end, we investigate different aspects such as quantitative performance, statistics of the learned feature representations, interpretability and robustness to image distortions. Our results indicate that models initialized from ImageNet pretraining report a significant increase in performance, generalization and robustness to image distortions. In particular, self-supervised models show further benefits to supervised models. Self-supervised models with initialization from ImageNet pretraining not only report higher performance, they also reduce overfitting to large lesions along with improvements in taking into account minute lesions indicative of the progression of the disease. Understanding the effects of pretraining in a broader sense that goes beyond simple performance comparisons is of crucial importance for the broader medical imaging community beyond the use case considered in this work.",convolutional neural-networks; deep; prediction; diagnosis
Article,"Li, Yung-Hui; Yeh, Nai-Ning; Chen, Shih-Jen; Chung, Yu-Chien",Computer-Assisted Diagnosis for Diabetic Retinopathy Based on Fundus Images Using Deep Convolutional Neural Network,mobile information systems,2019,Not found,"Diabetic retinopathy (DR) is a complication of long-standing diabetes, which is hard to detect in its early stage because it only shows a few symptoms. Nowadays, the diagnosis of DR usually requires taking digital fundus images, as well as images using optical coherence tomography (OCT). Since OCT equipment is very expensive, it will benefit both the patients and the ophthalmologists if an accurate diagnosis can be made, based solely on reading digital fundus images. In the paper, we present a novel algorithm based on deep convolutional neural network (DCNN). Unlike the traditional DCNN approach, we replace the commonly used max-pooling layers with fractional max-pooling. Two of these DCNNs with a different number of layers are trained to derive more discriminative features for classification. After combining features from metadata of the image and DCNNs, we train a support vector machine (SVM) classifier to learn the underlying boundary of distributions of each class. For the experiments, we used the publicly available DR detection database provided by Kaggle. We used 34,124 training images and 1,000 validation images to build our model and tested with 53,572 testing images. The proposed DR classifier classifies the stages of DR into five categories, labeled with an integer ranging between zero and four. The experimental results show that the proposed method can achieve a recognition rate up to 86.17%, which is higher than previously reported in the literature. In addition to designing a machine learning algorithm, we also develop an app called Deep Retina. Equipped with a handheld ophthalmoscope, the average person can take fundus images by themselves and obtain an immediate result, calculated by our algorithm. It is beneficial for home care, remote medical care, and self-examination.",blood-vessel segmentation; retinal images; assessment software; tracking; level; set
Article,"Sikder, Niloy; Masud, Mehedi; Bairagi, Anupam Kumar; Arif, Abu Shamim Mohammad; Nahid, Abdullah-Al; Alhumyani, Hesham A.",Severity Classification of Diabetic Retinopathy Using an Ensemble Learning Algorithm through Analyzing Retinal Images,symmetry-basel,2021,Not found,"Diabetic Retinopathy (DR) refers to the damages endured by the retina as an effect of diabetes. DR has become a severe health concern worldwide, as the number of diabetes patients is soaring uncountably. Periodic eye examination allows doctors to detect DR in patients at an early stage to initiate proper treatments. Advancements in artificial intelligence and camera technology have allowed us to automate the diagnosis of DR, which can benefit millions of patients indeed. This paper inscribes a novel method for DR diagnosis based on the gray-level intensity and texture features extracted from fundus images using a decision tree-based ensemble learning technique. This study primarily works with the Asia Pacific Tele-Ophthalmology Society 2019 Blindness Detection (APTOS 2019 BD) dataset. We undertook several steps to curate its contents to make them more suitable for machine learning applications. Our approach incorporates several image processing techniques, two feature extraction techniques, and one feature selection technique, which results in a classification accuracy of 94.20% (margin of error: +/- 0.32%) and an F-measure of 93.51% (margin of error: +/- 0.5%). Several other parameters regarding the proposed method's performance have been presented to manifest its robustness and reliability. Details on each employed technique have been included to make the provided results reproducible. This method can be a valuable tool for mass retinal screening to detect DR, thus drastically reducing the rate of vision loss attributed to it.",diabetic retinopathy detection; medical image analysis; image histogram; gray-level co-occurrence matrix; genetic algorithm; ensemble learning
Article,"de Figueiredo, Laura Alves; Pacheco Dias, Joao Victor; Polati, Mariza; Carricondo, Pedro Carlos; Debert, Iara",Strabismus and Artificial Intelligence App: Optimizing Diagnostic and Accuracy,translational vision science & technology,2021,Not found,"Purpose: Clinical evaluation of eye versions plays an important role in the diagnosis of special strabismus. Despite the importance of versions, they are not standardized in clinical practice because they are subjective. Assuming that objectivity confers accuracy, this research aims to create an artificial intelligence app that can classify the eye versions into nine positions of gaze. Methods: We analyzed photos of 110 strabismus patients from an outpatient clinic of a tertiary hospital at nine gazes. For each photo, the gaze was identified, and the corresponding version was rated by the same examiner during patient evaluation. Results: The images were standardized by using the OpenCV library in Python language, so that the patient's eyes were located and sent to a multilabel model through the Keras framework regardless of the photo orientation. Then, the model was trained for each combination of the following groupings: eyes (left, right), gaze (1 to 9), and version (-4 to 4). Resnet50 was used as the neural network architecture, and the Data Augmentation technique was applied. For quick inference via web browser, the SteamLit app framework was employed. For use in Mobiles, the finished model was exported for use in through the Tensorflow Lite converter. Conclusions: The results showed that the mobile app might be applied to complement evaluation of ocular motility based on objective classification of ocular versions. However, further exploratory research and validations are required. Translational Relevance: Apart from the traditional clinical practice method, professionals will be able to envisage an easy-to-apply support app, to increase diagnostic accuracy.",strabismus; artificial intelligence; smartphone app; eye version
Article,"Lahmiri, Salim",Hybrid deep learning convolutional neural networks and optimal nonlinear support vector machine to detect presence of hemorrhage in retina,biomedical signal processing and control,2020,Not found,"Diabetic retinopathy is a disorder that occurs in retina and it is caused by diabetes mellitus. Millions of people with diabetic retinopathy are expected to experience a loss of vision across the globe. Therefore, accurate automated-diagnosis systems are highly needed to help physicians in clinical milieu. Though many factors are effective in the diagnosis of diabetic retinopathy, presence of hemorrhage in retina remains one of the most significant factors. We present a three-stage hybrid system for classification of normal and abnormal digital retina images with hemorrhage. First, deep learning convolutional neural networks (CNN) is used for automatic features extraction. Second, the Student t-test is applied to the high dimensional features set extracted by CNN to select the best ten features. Third, the selected CNN-based features are fed to a nonlinear support vector machine (SVM) tuned by Bayes optimization to perform classification task. Three additional popular classifiers are also trained with features extracted by CNN and their performances are compared to that of the optimal nonlinear SVM including linear discriminant analysis (LDA), naive Bayes (NB), and k nearest neighbor (kNN). Each automated-diagnosis system is validated on a database composed of healthy and unhealthy digital retina images affected with various grades of hemorrhage. Experimental results from ten-fold cross-validation methodology show that CNN-SVM outperforms all other three reference systems; namely, CNN-LDA, CNN-NB, and CNN-kNN. Indeed, CNN-SVM system achieved 99.11%+/- 0.0101 accuracy, 99.14%+/- 0.0143 sensitivity, 99.08%+/- 0.0083 specificity, and 0.97.31%+/- 0.0381 area under curve (AUC) of the receiver operating characteristic. The proposed system is fast and accurate. (C) 2020 Elsevier Ltd. All rights reserved.",retina hemorrhage; diabetic retinopathy; deep learning convolutional neural networks; nonlinear support vector machine; bayes optimization; classification
Article; Early Access,"Mohanalakshmi, S.; Morarji, C. K.; Soban, S.",Locust based genetic classifier for the diagnosis of diabetic retinopathy,journal of ambient intelligence and humanized computing,0,Not found,"Due to the ongoing advancement in detection of critical diseases, there is a need in revamping the accurate diagnosis of diabetic retinopathy (DR). In this current study, locust based genetic classifier plays a crucial role in early screening of DR and to determine the exact location of the affected region of retina. Initially, preprocessing is performed to remove the obnoxious information such as noise present in the image and helps to transform the RGB format to gray scale image. It is done by applying wiener filter technique. After removing the obnoxious information, exudate segmentation is performed. After splitting out the image into samples, feature extraction is applied by Gabor based region covariance matrix. It helps to reduce the feature in the DIARETDB1 dataset by obtaining a new feature. After obtaining the feature, whale optimization is performed to pick out the best features such as mean, exudate area, optic distance and standard deviation and finally locust based genetic classifier is used to analogize between trained and test set data and it provides infallible information to the ophthalmologist to provide timely treatments. Comparative analysis is performed. It reveals the significant performance of the current approach over other existing SVM and CNN classifier. The results obtained from the current study shows a promising future and it achieves an accuracy of 98.9%.",wiener filter; locust based genetic classifier; artificial neural network (ann); convolutional neural network (cnn); support vector machine (svm)
Proceedings Paper,"Wang, Lei; Huang, Ying; Lin, Bing; Wu, Wencan; Chen, Hao; Pu, Jiantao",Automatic Classification of Exudates in Color Fundus Images Using an Augmented Deep Learning Procedure,third international symposium on image computing and digital medicine (isicdm 2019),2019,Not found,"Automatic classification of hard and soft exudates in color fundus images is very helpful for computer-aided diagnosis of retina related diseases, such as diabetic retinopathy (DR). In this study, we developed a novel method for this purpose based on the emerging deep learning technology known as convolutional neural networks (CNNs) by leveraging its strength of explicitly extracting the underlying image textures. We specifically investigate whether the emphasis of the image characteristic within an exudate spot could improve the classification performance. To verify this, we collected a database of fundus image that contains soft and hard exudates. The exudate regions were cropped from fundus images. There are a total of 550 cropped image patches (275 hard and 275 soft) with a fixed dimension of 128x128 pixels. These patches were further thresholded to exclude image background, resulting in another version of image patches merely containing exudate regions. Each version of image patches was randomly divided into 440 for training and 110 for testing, and then fed into the developed deep learning network in a separate or combinatorial way. Experimental results showed that the classification accuracy of this method was 93.41% when the thresholded version of the dataset was used as an augmented learning procedure, as compared to 90.80% and 87.41% when the original and background excluded datasets were used for training, respectively. This suggests that the augmented CNN can provide more accurate classification performance when the region-of-interest (ROI) and the original images were integrated.",exudate classification; diabetic retinopathy; convolutional neural networks; color fundus images
Article,"Balasubramanian, Kishore; Ananthamoorthy, N. P.; Ramya, K.",AN END-END DEEP LEARNING FRAMEWORK FOR LUNG INFECTION RECOGNITION USING ATTENTION-BASED FEATURES AND CROSS AVERAGE POOLING,international journal for multiscale computational engineering,2022,Not found,"Automated detection of lung infections from medical imaging combined with computer vision has a great deal of promise for improving healthcare towards COVID-19 and its consequences due to restricted healthcare emergencies. Finding the affected tissues, segmenting them from lung images is difficult due to comparable neighboring tissues, hazy boundaries, and unpredictable infections. To overcome these issues, we propose a novel deep learning framework that employs attention-based feature vectors and cross average pooling to detect the lung infection from the images. Multimodal images, after enhancement are processed independently through a pretrained DenseNet where the feature extraction is performed from fully connected and average pooled layers. Instead of assigning equal weight to each feature value in the feature vectors, an attention weight is assigned to each feature to highlight how much attention should be paid to it. The attention-based features are then fused using cross average pooling to produce a discriminatory feature set leading to improved diagnosis. The fused features are passed through a deep learning (DL) modified neural network classifier to diagnose the infection. Experiments are performed on the standard Kaggle and Mendeley datasets containing 24,697 X-ray images and 8055 computed topography (CT) images. The results indicated an average accuracy of 99.2%, appreciable Kappa index of 98.11%, and F1 Score of 0.99. A one class accuracy of 99.5% is achieved for COVID-19. The proposed model is robust to noise when tested on degraded images. The results of our DL method for categorizing respiratory tract infections are compared to that of various existing DL models, demonstrating its effectiveness.",covid-19; attention-based features; cross pooling; deep learning; weight aggregation
Review,"Tong, Yan; Lu, Wei; Yu, Yue; Shen, Yin",Application of machine learning in ophthalmic imaging modalities,eye and vision,2020,Not found,"In clinical ophthalmology, a variety of image-related diagnostic techniques have begun to offer unprecedented insights into eye diseases based on morphological datasets with millions of data points. Artificial intelligence (AI), inspired by the human multilayered neuronal system, has shown astonishing success within some visual and auditory recognition tasks. In these tasks, AI can analyze digital data in a comprehensive, rapid and non-invasive manner. Bioinformatics has become a focus particularly in the field of medical imaging, where it is driven by enhanced computing power and cloud storage, as well as utilization of novel algorithms and generation of data in massive quantities. Machine learning (ML) is an important branch in the field of AI. The overall potential of ML to automatically pinpoint, identify and grade pathological features in ocular diseases will empower ophthalmologists to provide high-quality diagnosis and facilitate personalized health care in the near future. This review offers perspectives on the origin, development, and applications of ML technology, particularly regarding its applications in ophthalmic imaging modalities.",artificial intelligence; deep learning; ophthalmic imaging modalities; machine learning
Proceedings Paper,"Niu, Yuhao; Gu, Lin; Lu, Feng; Lv, Feifan; Wang, Zongji; Sato, Imari; Zhang, Zijian; Xiao, Yangyan; Dai, Xunzhang; Cheng, Tingting",Pathological Evidence Exploration in Deep Retinal Image Diagnosis,thirty-third aaai conference on artificial intelligence / thirty-first innovative applications of artificial intelligence conference / ninth aaai symposium on educational advances in artificial intelligence,2019,Not found,"Though deep learning has shown successful performance in classifying the label and severity stage of certain disease, most of them give few evidence on how to make prediction. Here, we propose to exploit the interpretability of deep learning application in medical diagnosis. Inspired by Koch's Postulates, a well-known strategy in medical research to identify the property of pathogen, we define a pathological descriptor that can be extracted from the activated neurons of a diabetic retinopathy detector. To visualize the symptom and feature encoded in this descriptor, we propose a GAN based method to synthesize pathological retinal image given the descriptor and a binary vessel segmentation. Besides, with this descriptor, we can arbitrarily manipulate the position and quantity of lesions. As verified by a panel of 5 licensed ophthalmologists, our synthesized images carry the symptoms that are directly related to diabetic retinopathy diagnosis. The panel survey also shows that our generated images is both qualitatively and quantitatively superior to existing methods.",generation
Article,"Khojasteh, Parham; Passos Junior, Leandro Aparecido; Carvalho, Tiago; Rezende, Edmar; Aliahmad, Behzad; Papa, Joao Paulo; Kumar, Dinesh Kant",Exudate detection in fundus images using deeply-learnable features,computers in biology and medicine,2019,Not found,"Presence of exudates on a retina is an early sign of diabetic retinopathy, and automatic detection of these can improve the diagnosis of the disease. Convolutional Neural Networks (CNNs) have been used for automatic exudate detection, but with poor performance. This study has investigated different deep learning techniques to maximize the sensitivity and specificity. We have compared multiple deep learning methods, and both supervised and unsupervised classifiers for improving the performance of automatic exudate detection, i.e., CNNs, pre-trained Residual Networks (ResNet-50) and Discriminative Restricted Boltzmann Machines. The experiments were conducted on two publicly available databases: (i) DIARETDB1 and (ii) e-Ophtha. The results show that ResNet-50 with Support Vector Machines outperformed other networks with an accuracy and sensitivity of 98% and 0.99, respectively. This shows that ResNet-50 can be used for the analysis of the fundus images to detect exudates.",exudate detection; deep learning; convolutional neural networks; deep residual networks; discriminative restricted boltzmann machines; diabetic retinopathy
Article; Data Paper,"Karsaz, Ali",Diabetic retinopathy screening using improved support vector domain description: a clinical study,soft computing,2022,Not found,"Diabetic retinopathy (DR) is the major cause of visual impairment among diabetic patients. Significant works have been done to hybrid a modified CNN architecture such as AlexNet with some of classifiers such as support vector machines (SVMs) or fuzzy C-Means (FCM) to improve the DR screening. This new hybrid innovative structure uses more efficient extracting features of a retinal images in both spatial and spectral domains. In spite the advantages of this innovative architecture, the different kernel functions affect the performance of the proposed algorithm. Using the appropriate transformed data into two- or three-dimensional feature maps and using an improved support vector domain description (ISVDD) can obtain more flexible and more accurate image description. To this end, the optimal degree values of different kernel functions can be extracted by using a particle swarm optimization (PSO) algorithm. Also, we compared the performance of our approach (modified-AlexNet-ISVDD) with the results obtained by hybrid modified AlexNet and some of classifiers such as K-Nearest Neighbors (KNN) and FCM clustering. We achieve the proposed CNN architecture using ISVDD on the DIARETDB1 and MESSIDOR datasets, with more than 99% sensitivity.",diabetic retinopathy screening; deep learning; optimal kernel functions; improved support vector domain description (isvdd); particle swarm optimization (pso); clinical study
Review,"Badar, Maryam; Haris, Muhammad; Fatima, Anam",Application of deep learning for retinal image analysis: A review,computer science review,2020,Not found,"Retinal image analysis holds an imperative position for the identification and classification of retinal diseases such as Diabetic Retinopathy (DR), Age Related Macular Degeneration (AMD), Macular Bunker, Retinoblastoma, Retinal Detachment, and Retinitis Pigmentosa. Automated identification of retinal diseases is a big step towards early diagnosis and prevention of exacerbation of the disease. A number of state-of-the-art methods have been developed in the past that helped in the automatic segmentation and identification of retinal landmarks and pathologies. However, the current unprecedented advancements in deep learning and modern imaging modalities in ophthalmology have opened a whole new arena for researchers. This paper is a review of deep learning techniques applied to 2-D fundus and 3-D Optical Coherence Tomography (OCT) retinal images for automated classification of retinal landmarks, pathology, and disease classification. The methodologies are analyzed in terms of sensitivity, specificity, Area under ROC curve, accuracy, and F score on publicly available datasets which includes DRIVE, STARE, CHASE_DB1, DRiDB, NIH AREDS, ARIA, MESSIDOR-2, E-OPTHA, EyePACS-1 DIARETDB and OCT image datasets. (C) 2019 Elsevier Inc. All rights reserved.",deep learning; deep neural network; convolutional neural network; auto-encoder; sparse stacked auto-encoder; de-noised sparse auto-encoder; softmax; random forest; rectified linear unit; hidden layers
Article,"Wewetzer, Larisa; Held, Linda A.; Steinhaeuser, Jost",Diagnostic performance of deep-learning-based screening methods for diabetic retinopathy in primary care-A meta-analysis,plos one,2021,Not found,"Background Diabetic retinopathy (DR) affects 10-24% of patients with diabetes mellitus type 1 or 2 in the primary care (PC) sector. As early detection is crucial for treatment, deep learning screening methods in PC setting could potentially aid in an accurate and timely diagnosis. Purpose The purpose of this meta-analysis was to determine the current state of knowledge regarding deep learning (DL) screening methods for DR in PC. Data sources A systematic literature search was conducted using Medline, Web of Science, and Scopus to identify suitable studies. Study selection Suitable studies were selected by two researchers independently. Studies assessing DL methods and the suitability of these screening systems (diagnostic parameters such as sensitivity and specificity, information on datasets and setting) in PC were selected. Excluded were studies focusing on lesions, applying conventional diagnostic imaging tools, conducted in secondary or tertiary care, and all publication types other than original research studies on human subjects. Data extraction The following data was extracted from included studies: authors, title, year of publication, objectives, participants, setting, type of intervention/method, reference standard, grading scale, outcome measures, dataset, risk of bias, and performance measures. Data synthesis and conclusion The summed sensitivity of all included studies was 87% and specificity was 90%. Given a prevalence of DR of 10% in patients with DM Type 2 in PC, the negative predictive value is 98% while the positive predictive value is 49%. Limitations Selected studies showed a high variation in sample size and quality and quantity of available data.",macular edema; prevalence; validation; algorithm; accuracy
Proceedings Paper,"Khan, Muhammad Zubair; Lee, Yugyung",Retinal Image Analysis to Detect Neovascularization using Deep Segmentation,2021 4th international conference on information and computer technologies (icict 2021),2021,Not found,"The retina has a significant role in early detection of sight-threatening disease symptoms. Most of the ocular complications manifest themselves in retina. The extraction of useful information from this vital resource is a critical task. The recent advancement in artificial intelligence has opened ways to provide rapid assistance in detecting ocular disorders through retinal images. In this article, we have proposed a vessels segmentation model for the early detection of neovascularization. It is a common symptom for patients facing chronic diabetic retinopathy. In neovascularization, the tiny vessels are produced that gets block over time with an extensive amount of sugar content in human blood. The detection of newly formatted tiny blood vessels needs a precise vessels extraction system. Our model has shown promising results on a publicly available retinal image dataset. It has achieved the highest accuracy of 0.9554 with 0.9780 AUC. The underlying research is an effort to produce automated disease detection system. The core function of the proposed system is to analyze the structural variation in vessels of subjects experiencing ocular disease symptoms and to reduce the risk of blindness through early diagnosis.",image segmentation; neovascularization; deep learning; vessels extraction; diabetic retinopathy
Article,"Jeong, Yeonwoo; Hong, Yu-Jin; Han, Jae-Ho",Review of Machine Learning Applications Using Retinal Fundus Images,diagnostics,2022,Not found,"Automating screening and diagnosis in the medical field saves time and reduces the chances of misdiagnosis while saving on labor and cost for physicians. With the feasibility and development of deep learning methods, machines are now able to interpret complex features in medical data, which leads to rapid advancements in automation. Such efforts have been made in ophthalmology to analyze retinal images and build frameworks based on analysis for the identification of retinopathy and the assessment of its severity. This paper reviews recent state-of-the-art works utilizing the color fundus image taken from one of the imaging modalities used in ophthalmology. Specifically, the deep learning methods of automated screening and diagnosis for diabetic retinopathy (DR), age-related macular degeneration (AMD), and glaucoma are investigated. In addition, the machine learning techniques applied to the retinal vasculature extraction from the fundus image are covered. The challenges in developing these systems are also discussed.",deep learning; fundus image; machine learning; retinal image
Article,"Arsalan, Muhammad; Baek, Na Rae; Owais, Muhammad; Mahmood, Tahir; Park, Kang Ryoung",Deep Learning-Based Detection of Pigment Signs for Analysis and Diagnosis of Retinitis Pigmentosa,sensors,2020,Not found,"Ophthalmological analysis plays a vital role in the diagnosis of various eye diseases, such as glaucoma, retinitis pigmentosa (RP), and diabetic and hypertensive retinopathy. RP is a genetic retinal disorder that leads to progressive vision degeneration and initially causes night blindness. Currently, the most commonly applied method for diagnosing retinal diseases is optical coherence tomography (OCT)-based disease analysis. In contrast, fundus imaging-based disease diagnosis is considered a low-cost diagnostic solution for retinal diseases. This study focuses on the detection of RP from the fundus image, which is a crucial task because of the low quality of fundus images and non-cooperative image acquisition conditions. Automatic detection of pigment signs in fundus images can help ophthalmologists and medical practitioners in diagnosing and analyzing RP disorders. To accurately segment pigment signs for diagnostic purposes, we present an automatic RP segmentation network (RPS-Net), which is a specifically designed deep learning-based semantic segmentation network to accurately detect and segment the pigment signs with fewer trainable parameters. Compared with the conventional deep learning methods, the proposed method applies a feature enhancement policy through multiple dense connections between the convolutional layers, which enables the network to discriminate between normal and diseased eyes, and accurately segment the diseased area from the background. Because pigment spots can be very small and consist of very few pixels, the RPS-Net provides fine segmentation, even in the case of degraded images, by importing high-frequency information from the preceding layers through concatenation inside and outside the encoder-decoder. To evaluate the proposed RPS-Net, experiments were performed based on 4-fold cross-validation using the publicly available Retinal Images for Pigment Signs (RIPS) dataset for detection and segmentation of retinal pigments. Experimental results show that RPS-Net achieved superior segmentation performance for RP diagnosis, compared with the state-of-the-art methods.",deep learning; retinal disease; retinitis pigmentosa; semantic segmentation; rps-net
Article,"Togacar, Mesut",Detection of retinopathy disease using morphological gradient and segmentation approaches in fundus images,computer methods and programs in biomedicine,2022,Not found,"Background and objective: Diabetes-related cases can cause glaucoma, cataracts, optic neuritis, paralysis of the eye muscles, or various retinal damages over time. Diabetic retinopathy is the most common form of blindness that occurs with diabetes. Diabetic retinopathy is a disease that occurs when the blood vessels in the retina of the eye become damaged, leading to loss of vision in advanced stages. This disease can occur in any diabetic patient, and the most important factor in treating the disease is early diagnosis. Nowadays, deep learning models and machine learning methods, which are open to technological developments, are already used in early diagnosis systems. In this study, two publicly available datasets were used. The datasets consist of five types according to the severity of diabetic retinopathy. The objectives of the proposed approach in diabetic retinopathy detection are to positively contribute to the performance of CNN models by processing fundus images through preprocessing steps (morphological gradient and segmentation approaches). The other goal is to detect efficient sets from type-based activation sets obtained from CNN models using Atom Search Optimization method and increase the classification success. Methods: The proposed approach consists of three steps. In the first step, the Morphological Gradient method is used to prevent parasitism in each image, and the ocular vessels in fundus images are extracted using the segmentation method. In the second step, the datasets are trained with transfer learning models and the activations for each class type in the last fully connected layers of these models are extracted. In the last step, the Atom Search optimization method is used, and the most dominant activation class is selected from the extracted activations on a class basis. Results: When classified by the severity of diabetic retinopathy, an overall accuracy of 99.59% was achieved for dataset #1 and 99.81% for dataset #2. Conclusions: In this study, it was found that the overall accuracy achieved with the proposed approach increased. To achieve this increase, the application of preprocessing steps and the selection of the dominant activation sets from the deep learning models were implemented using the Atom Search optimization method. (C) 2021 Elsevier B.V. All rights reserved.",diabetic retinopathy; morphological gradient and segmentation; atom search optimization; selection of dominant activations
Proceedings Paper,"Auccahuasi, Wilver; Flores, Edward; Sernaque, Fernando; Cueva, Juanita; Diaz, Monica; Ore, Elizabeth",Recognition of hard exudates using Deep Learning,international conference on computational intelligence and data science,2020,Not found,"Diabetes Mellitus is a metabolic disease characterized by the presence of elevated blood glucose levels. Diabetes itself causes other chronic complications, including an eye disease known as diabetic retinopathy. Nowadays, diabetic retinopathy is the most frequent cause of blindness among the active population of developed countries. The principles that produce this disease are not completely known and can not yet be prevented. However, there are effective treatments that delay their evolution as long as it is diagnosed with sufficient anticipation. The problem of diabetic retinopathy is that it is an asymptomatic disease and only defects appear in the vision at an advanced stage of the disease. So in the early stages of diabetic retinopathy is usually imperceptible, diabetic patients do not realize that they have the disease and do not undergo an eye examination. Sometimes the patient is examined when it is too late for proper treatment, due to the presence of severe damage to the retina, occurring only the diagnosis of Diabetes. Currently, technology is becoming more important in the field of health, due to this, a series of systems have been designed to help decision making that helps in the early detection of diabetic retinopathy through the images of Eye, in the present work we present a methodology to be able to recognize the hard exudates that is the first manifestation of diabetic retinopathy, by presenting coloration similar to the other anatomical forms of the eye, its automatic recognition is complicated, the methodology that is presented consists of the use of a database of fundus images with positive and negative symptoms of diabetic retinopathy, from this database a set of images is created that correspond to the hard exudates and images that do not correspond to the hard exudates, with this set of images creates a convolutional network, in order to improve the recognition, obtaining sultados that can satisfy in the clinical practice.",diabetes mellitus; processing; retinography; images; segmentation; features
Article,"Zhang, Yinsheng; Wang, Li; Wu, Zhenquan; Zeng, Jian; Chen, Yi; Tian, Ruyin; Zhao, Jinfeng; Zhang, Guoming",Development of an Automated Screening System for Retinopathy of Prematurity Using a Deep Neural Network for Wide-Angle Retinal Images,ieee access,2019,Not found,"Retinopathy of prematurity (ROP) is one of the main causes of childhood blindness. However, insufficient ophthalmologists are qualified for ROP screening. The objective of this paper is to evaluate the performance of a deep neural network (DNN) for the automated screening of ROP. The training and test sets came from 420 365 wide-angle retina images from ROP screening. A transfer learning scheme was designed to train the DNN classifier. First, a pre-processing classifier separated unqualified images. Then, pediatric ophthalmologists labeled each image as either ROP or negative. The labeled training set (8090 positive images and 9711 negative ones) was used to fine-tune three candidate DNN classifiers (AlexNet, VGG-16, and GoogLeNet) with the transfer learning approach. The resultant classifiers were evaluated on a test dataset of 1742 samples and compared with five independent pediatric retinal ophthalmologists. The receiver operating characteristic (ROC) curve, ROC area under the curve, and precision-recall (P-R) curve on the test dataset were analyzed. Accuracy, precision, sensitivity (recall), specificity, F1 score, the Youden index, and the Matthews correlation coefficient were evaluated at different sensitivity cutoffs. The data from the five pediatric ophthalmologists were plotted in the ROC and P-R curves to visualize their performances. VGG-16 achieved the best performance. At the cutoff point that maximized F1 score in the P-R curve, the final DNN model achieved 98.8% accuracy, 94.1% sensitivity, 99.3% specificity, and 93.0% precision. This was comparable to the pediatric ophthalmologists (98.8% accuracy, 93.5% sensitivity, 99.5% specificity, and 96.7% precision). In the screening of ROP using the evaluation of wide-angle retinal images, DNNs had high accuracy, sensitivity, specificity, and precision, comparable to that of pediatric ophthalmologists.",retinopathy of prematurity; deep neural network; transfer learning; wide-angle retinal image; image classification; computer-aided diagnosis
Review,"Teikari, Petteri; Najjar, Raymond P.; Schmetterer, Leopold; Milea, Dan",Embedded deep learning in ophthalmology: making ophthalmic imaging smarter,therapeutic advances in ophthalmology,2019,Not found,"Deep learning has recently gained high interest in ophthalmology due to its ability to detect clinically significant features for diagnosis and prognosis. Despite these significant advances, little is known about the ability of various deep learning systems to be embedded within ophthalmic imaging devices, allowing automated image acquisition. In this work, we will review the existing and future directions for 'active acquisition'-embedded deep learning, leading to as high-quality images with little intervention by the human operator. In clinical practice, the improved image quality should translate into more robust deep learning-based clinical diagnostics. Embedded deep learning will be enabled by the constantly improving hardware performance with low cost. We will briefly review possible computation methods in larger clinical systems. Briefly, they can be included in a three-layer framework composed of edge, fog, and cloud layers, the former being performed at a device level. Improved egde-layer performance via 'active acquisition' serves as an automatic data curation operator translating to better quality data in electronic health records, as well as on the cloud layer, for improved deep learning-based clinical data mining.",artificial intelligence; deep learning; embedded devices; medical devices; ophthalmic devices; ophthalmology
Article,"Chea, Nakhim; Nam, Yunyoung",Classification of Fundus Images Based on Deep Learning for Detecting Eye Diseases,cmc-computers materials & continua,2021,Not found,"Various techniques to diagnose eye diseases such as diabetic retinopathy (DR), glaucoma (GLC), and age-related macular degeneration (AMD), are possible through deep learning algorithms. A few recent studies have examined a couple of major diseases and compared them with data from healthy subjects. However, multiple major eye diseases, such as DR, GLC, and AMD, could not be detected simultaneously by computer-aided systems to date. There were just high-performance-outcome researches on a pair of healthy and eye-diseased group, besides of four categories of fundus image classification. To have a better knowledge of multi-categorical classification of fundus photographs, we used optimal residual deep neural networks and effective image preprocessing techniques, such as shrinking the region of interest, iso-luminance plane contrast-limited adaptive histogram equalization, and data augmentation. Applying these to the classification of three eye diseases from currently available public datasets, we achieved peak and average accuracies of 91.16% and 85.79%, respectively. The specificities for images from the eyes of healthy, GLC, AMD, and DR patients were 90.06%, 99.63%, 99.82%, and 91.90%, respectively. The better specificity performances may alert patient in an early stage of eye diseases to prevent vision loss. This study presents a possible occurrence of a multi-categorical deep neural network technique that can be deemed as a successful pilot study of classification for the three most-common eye diseases and can be used for future assistive devices in computer-aided clinical applications.",multi-categorical classification; deep neural networks; glaucoma; age-related macular degeneration; diabetic retinopathy
Article,"Wu, Zhan; Shi, Gonglei; Chen, Yang; Shi, Fei; Chen, Xinjian; Coatrieux, Gouenou; Yang, Jian; Luo, Limin; Li, Shuo",Coarse-to-fine classification for diabetic retinopathy grading using convolutional neural network,artificial intelligence in medicine,2020,Not found,"Diabetic retinopathy (DR) is the most common eye complication of diabetes and one of the leading causes of blindness and vision impairment. Automated and accurate DR grading is of great significance for the timely and effective treatment of fundus diseases. Current clinical methods remain subject to potential time-consumption and high-risk. In this paper, a hierarchically Coarse-to-fine network (CF-DRNet) is proposed as an automatic clinical tool to classify five stages of DR severity grades using convolutional neural networks (CNNs). The CF-DRNet conforms to the hierarchical characteristic of DR grading and effectively improves the classification performance of five-class DR grading, which consists of the following: (1) The Coarse Network performs two-class classification including No DR and DR, where the attention gate module highlights the salient lesion features and suppresses irrelevant background information. (2) The Fine Network is proposed to classify four stages of DR severity grades of the grade DR from the Coarse Network including mild, moderate, severe non-proliferative DR (NPDR) and proliferative DR (PDR). Experimental results show that proposed CF-DRNet out-performs some state-of-art methods in the publicly available IDRiD and Kaggle fundus image datasets. These results indicate our method enables an efficient and reliable DR grading diagnosis in clinic.",diabetic retinopathy grading; coarse-to-fine classification; convolutional neural networks; fundus images
Article,"Liu, Ruhan; Wang, Xiangning; Wu, Qiang; Dai, Ling; Fang, Xi; Yan, Tao; Son, Jaemin; Tang, Shiqi; Li, Jiang; Gao, Zijian; Galdran, Adrian; Poorneshwaran, J. M.; Liu, Hao; Wang, Jie; Chen, Yerui; Porwal, Prasanna; Tan, Gavin Siew Wei; Yang, Xiaokang; Dai, Chao; Song, Haitao; Chen, Mingang; Li, Huating; Jia, Weiping; Shen, Dinggang; Sheng, Bin; Zhang, Ping",DeepDRiD: Diabetic Retinopathy-Grading and Image Quality Estimation Challenge,patterns,2022,Not found,"We described a challenge named Diabetic Retinopathy (DR)-Grading and Image Quality Estimation Challenge in conjunction with ISBI 2020 to hold three sub-challenges and develop deep learning models for DR image assessment and grading. The scientific community responded positively to the challenge, with 34 submissions from 574 registrations. In the challenge, we provided the DeepDRiD dataset containing 2,000 regular DR images (500 patients) and 256 ultra-widefield images (128 patients), both having DR quality and grading annotations. We discussed details of the top 3 algorithms in each sub-challenges. The weighted kappa for DR grading ranged from 0.93 to 0.82, and the accuracy for image quality evaluation ranged from 0.70 to 0.65. The results showed that image quality assessment can be used as a further target for exploration. We also have released the DeepDRiD dataset on GitHub to help develop automatic systems and improve human judgment in DR screening and diagnosis.",prevalence; validation
Proceedings Paper,"Muddamsetty, Satya M.; Moeslund, Thomas B.",Multi-level Quality Assessment of Retinal Fundus Images using Deep Convolution Neural Networks,"visapp: proceedings of the 16th international joint conference on computer vision, imaging and computer graphics theory and applications - vol. 4: visapp",2021,Not found,"Retinal fundus image quality assessment is one of the major steps in screening for retinal diseases, since the poor-quality retinal images do not allow an accurate medical diagnosis. In this paper, we first introduce a large multi-level Retinal Fundus Image Quality Assessment (RFIQA) dataset. It has six levels of quality grades, which are based on important regions to consider for diagnosing diabetic retinopathy (DR), Aged Macular Degeneration (AMD) and Glaucoma by ophthalmologists. Second, we propose a Convolution Neural Network (CNN) model to assess the quality of the retinal images with much fewer parameters than existing deep CNN models and finally we propose to combine deep and generic texture features, and using Random Forest classifier. Experiments show that combing both deep and generic features outperforms using any of the two feature types in isolation. This is confirmed on our new dataset as well as on other public datasets.",retinal fundus image; deep-learning; quality assessment; generic features; cnn; multi-level grading
Review,"Yang, Jie; Fong, Simon; Wang, Han; Hu, Quanyi; Lin, Chen; Huang, Shigao; Shi, Jian; Lan, Kun; Tang, Rui; Wu, Yaoyang; Zhao, Qi",Artificial intelligence in ophthalmopathy and ultra-wide field image: A survey,expert systems with applications,2021,Not found,"Fundus digital photography and optical coherence tomography (OCT) are currently the primary imaging approaches for early diagnosis and treatment of eye diseases. In recent years, the significant development in artificial intelligence (AI), particularly in machine learning (ML) and deep learning (DL) are new and vital technical-driven motivations impacting on the traditional diagnosis and treatment methods. At the same time, the ultra-wide field (UWF) imaging technology is getting widely accepted and prevalent by its obvious advantageous features of non-dilate pupils, express-track result and the vast pool of fundus viewing angles. As a result, numerous research have been done to explore AI in ultra-wide field fundus imaging ophthalmology for joint diagnosis and treatment. However, the current review of this method is still in least ink. We first outlines the application and impact of AI technology in ophthalmic diseases in the past ten years. With the following part exclusively summarizing the technical integration of ultra-wide field fundus images and AI technology in the past four years, which has brought innovations to clinical treatment methods for the diagnosis and treatment of ophthalmic diseases; finally, we analyzed the application and implementation of the novel technology as well as the potential limitations and challenges, to predict the possibility of the technology's further principles role and values in clinical ophthalmology.",ophthalmopathy; ultra-wide field (uwf) imaging; deep learning; machine learning
Article,"Khojasteh, Parham; Aliahmad, Behzad; Kumar, Dinesh K.","Fundus images analysis using deep features for detection of exudates, hemorrhages and microaneurysms",bmc ophthalmology,2018,Not found,"BackgroundConvolution neural networks have been considered for automatic analysis of fundus images to detect signs of diabetic retinopathy but suffer from low sensitivity.MethodsThis study has proposed an alternate method using probabilistic output from Convolution neural network to automatically and simultaneously detect exudates, hemorrhages and microaneurysms. The method was evaluated using two approaches: patch and image-based analysis of the fundus images on two public databases: DIARETDB1 and e-Ophtha. The novelty of the proposed method is that the images were analyzed using probability maps generated by score values of the softmax layer instead of the use of the binary output.ResultsThe sensitivity of the proposed approach was 0.96, 0.84 and 0.85 for detection of exudates, hemorrhages and microaneurysms, respectively when considering patch-based analysis. The results show overall accuracy for DIARETDB1 was 97.3% and 86.6% for e-Ophtha. The error rate for image-based analysis was also significantly reduced when compared with other works.ConclusionThe proposed method provides the framework for convolution neural network-based analysis of fundus images to identify exudates, hemorrhages, and microaneurysms. It obtained accuracy and sensitivity which were significantly better than the reported studies and makes it suitable for automatic diabetic retinopathy signs detection.",fundus image analysis; diabetic retinopathy; deep learning; convolutional neural networks; image processing
Proceedings Paper,"Siebert, M.; Rostalski, P.",Performance evaluation of lightweight convolutional neural networks on retinal lesion segmentation,medical imaging 2022: computer-aided diagnosis,2022,Not found,"In addition to the recent development of deep learning-based, automatic detection systems for diabetic retinopathy (DR), efforts are being made to integrate those systems into mobile detection devices running on the edge requiring lightweight algorithms. Moreover, to enable clinical deployment it is important to enhance the transparency of the deep learning systems usually being black-box models and hence giving no insights into its reasoning. By providing precise segmentation masks for lesions being related to the severity of DR, a good intuition about the decision making of the diagnosing system can be given. Hence, to enable transparent mobile DR detection devices simultaneously segmenting disease-related lesions and running on the edge, lightweight models capable to produce fine-grained segmentation masks are required contradicting the generally high complexity of fully convolutional architectures used for image segmentation. In this paper, we evaluate both the runtime and segmentation performance of several lightweight fully convolutional networks for DR related lesion segmentation and assess its potential to extend mobile DR-grading systems for improved transparency. To this end, the U-2-Net is downscaled to reduce the computational load by reducing feature size and applying depthwise separable convolutions and evaluated using deep model ensembling as well as single- and multi-task inference to improve performance and further reduce memory cost. Experimental results using the U-2-Net-S+ ensemble show good segmentation performance while maintaining a small memory footprint as well as reasonable inference speed and thus indicate a promising first step towards a holistic mobile diagnostic system providing both precise lesion segmentation and DR-grading.",mobile segmentation; diabetic retinopathy; deep learning; multi-lesion segmentation; u-net; fundus; image
Proceedings Paper,"Akil, M.; Elloumi, Y.; Kachouri, R.",Computational aspects of deep learning models for detection of eye retina abnormalities,real-time image processing and deep learning 2020,2020,Not found,"Glaucoma, Cataract, Age-related macular degeneration, (AMD) Diabetic retinopathy (DR) are among the leading retinal diseases. Thus, there is an active effort to create and develop methods to automate screening of retinal diseases. Many CAD (Computer Aided Diagnosis) systems have been expanded and are widely used for ocular diseases. Recently, Deep Neural Networks (DNNs) have been adopted in ophthalmology and applied to fundus images, achieving detection of retinal abnormalities using retinal images. There are essentially two approaches, the first one is based on hybrid method that employs image processing for preprocessing, features extraction and post processing and Deep Neural Network (DNN) is only used for classification. The second is the fully method where DNN is used for both feature extraction and classification. Several DNN models and their variants have been proposed such as AlexNet, VGG, GoogleNet, Inception, U-Net, Residual Net (ResNet), DenseNet for detection of eye retina abnormalities. The aim of this work is to provide the background and the methodology to conduct a benchmarking analysis including the computational aspects and analysis of the representative DNNs proposed in the state of the art for detection DR diseases. For each DNN different characteristics and some performance indices (i.e. model complexity, computation complexity, inference time, memory use) and detection disease performance (i.e. accuracy rate), must be taking into account to find the more accurate model. The public domain datasets used for training and testing the DNN models such as Kaggle, MESSIDOR, and EyePACS are outlined and analyzed in particular in DR detection.",deep neural networks; automated screening and detection of dr disease; computation complexity; performance analysis; fundus images
Article,"Miao, Yue; Tang, Siyuan",Classification of Diabetic Retinopathy Based on Multiscale Hybrid Attention Mechanism and Residual Algorithm,wireless communications & mobile computing,2022,Not found,"The key of classification diagnosis of diabetic retinopathy lies in the recognition of the features of small lesions, and it is difficult to extract the features of too small lesions by general extraction methods. In order to solve the problem that it is difficult to extract small focus, a hybrid attention mechanism combined with residual convolutional neural network model algorithm is proposed to improve the classification accuracy of diabetic retinopathy. Firstly, a multiscale deep learning network model with hybrid attention is designed, and then, the high-level features of images are extracted by using the network model; finally, after balancing different types of samples by sampling algorithm, the spatial attention and channel attention of the extracted features are enhanced; small-step learning strategy, loss function, and initial parameters are used to optimize the performance of the network model. The classifier based on multiscale hybrid attention network is used to judge the five classifications. Experimental results show that the proposed algorithm can learn more features of small targets and can effectively improve the classification performance of diabetic retina. An experimental test was performed on Kaggle's publicly available dataset of diabetic retinas, and the classification accuracy was 93.8%, compared to some existing classification models; the method proposed in this paper can achieve better classification results for diabetic retinopathy.",images
Article,"Keel, Stuart; Wu, Jinrong; Lee, Pei Ying; Scheetz, Jane; He, Mingguang",Visualizing Deep Learning Models for the Detection of Referable Diabetic Retinopathy and Glaucoma,jama ophthalmology,2019,Not found,"IMPORTANCE Convolutional neural networks have recently been applied to ophthalmic diseases; however, the rationale for the outputs generated by these systems is inscrutable to clinicians. A visualization tool is needed that would enable clinicians to understand important exposure variables in real time. OBJECTIVE To systematically visualize the convolutional neural networks of 2 validated deep learning models for the detection of referable diabetic retinopathy (DR) and glaucomatous optic neuropathy (GON). DESIGN, SETTING, AND PARTICIPANTS The GON and referable DR algorithms were previously developed and validated (holdout method) using 48116 and 66 790 retinal photographs, respectively, derived from a third-party database (LabelMe) of deidentified photographs from various clinical settings in China. In the present cross-sectional study, a random sample of 100 true-positive photographs and all false-positive cases from each of the GON and DR validation data sets were selected. All data were collected from March to June 2017. The original color fundus images were processed using an adaptive kernel visualization technique. The images were preprocessed by applying a sliding window with a size of 28 x 28 pixels and a stride of 3 pixels to crop images into smaller subimages to produce a feature map. Threshold scales were adjusted to optimal levels for each model to generate heat maps highlighting localized landmarks on the input image. A single optometrist allocated each image to predefined categories based on the generated heat map. MAIN OUTCOMES AND MEASURES Visualization regions of the fundus. RESULTS In the GON data set, 90 of 100 true-positive cases (90%; 95% CI, 82%-95%) and 15 of 22 false-positive cases (68%; 95% CI, 45%-86%) displayed heat map visualization within regions of the optic nerve head only. Lesions typically seen in cases of referable DR (exudate, hemorrhage, or vessel abnormality) were identified as the most important prognostic regions in 96 of 100 true-positive DR cases (96%; 95% CI, 90%-99%). In 39 of 46 false-positive DR cases (85%; 95% CI, 71%-94%), the heat map displayed visualization of nontraditional fundus regions with or without retinal venules. CONCLUSIONS AND RELEVANCE These findings suggest that this visualization method can highlight traditional regions in disease diagnosis, substantiating the validity of the deep learning models investigated. This visualization technique may promote the clinical adoption of these models.",validation
Article,"Kim, Kyoung Min; Heo, Tae-Young; Kim, Aesul; Kim, Joohee; Han, Kyu Jin; Yun, Jaesuk; Min, Jung Kee",Development of a Fundus Image-Based Deep Learning Diagnostic Tool for Various Retinal Diseases,journal of personalized medicine,2021,Not found,"Artificial intelligence (AI)-based diagnostic tools have been accepted in ophthalmology. The use of retinal images, such as fundus photographs, is a promising approach for the development of AI-based diagnostic platforms. Retinal pathologies usually occur in a broad spectrum of eye diseases, including neovascular or dry age-related macular degeneration, epiretinal membrane, rhegmatogenous retinal detachment, retinitis pigmentosa, macular hole, retinal vein occlusions, and diabetic retinopathy. Here, we report a fundus image-based AI model for differential diagnosis of retinal diseases. We classified retinal images with three convolutional neural network models: ResNet50, VGG19, and Inception v3. Furthermore, the performance of several dense (fully connected) layers was compared. The prediction accuracy for diagnosis of nine classes of eight retinal diseases and normal control was 87.42% in the ResNet50 model, which added a dense layer with 128 nodes. Furthermore, our AI tool augments ophthalmologist's performance in the diagnosis of retinal disease. These results suggested that the fundus image-based AI tool is applicable for the medical diagnosis process of retinal diseases.",artificial intelligence; class activation map; convolutional neural network; fundus photograph; retinal diseases
Article,"Xu, Yesheng; Kong, Ming; Xie, Wenjia; Duan, Runping; Fang, Zhengqing; Lin, Yuxiao; Zhu, Qiang; Tang, Siliang; Wu, Fei; Yao, Yu-Feng",Deep Sequential Feature Learning in Clinical Image Classification of Infectious Keratitis,engineering,2021,Not found,"Infectious keratitis is the most common condition of corneal diseases in which a pathogen grows in the cornea leading to inflammation and destruction of the corneal tissues. Infectious keratitis is a medical emergency for which a rapid and accurate diagnosis is needed to ensure prompt and precise treatment to halt the disease progression and to limit the extent of corneal damage; otherwise, it may develop a sight-threatening and even eye-globe-threatening condition. In this paper, we propose a sequential level deep model to effectively discriminate infectious corneal disease via the classification of clinical images. In this approach, we devise an appropriate mechanism to preserve the spatial structures of clinical images and disentangle the informative features for clinical image classification of infectious keratitis. In a comparison, the performance of the proposed sequential-level deep model achieved 80% diagnostic accuracy, far better than the 49.27% +/- 11.5% diagnostic accuracy achieved by 421 ophthalmologists over 120 test images. (C) 2021 THE AUTHORS. Published by Elsevier LTD on behalf of Chinese Academy of Engineering and Higher Education Press Limited Company.",deep learning; corneal disease; sequential features; machine learning; long short-term memory
Review,"Lee, Sang Min; Seo, Joon Beom; Yun, Jihye; Cho, Young-Hoon; Vogel-Claussen, Jens; Schiebler, Mark L.; Gefter, Warren B.; van Beek, Edwin J. R.; Goo, Jin Mo; Lee, Kyung Soo; Hatabu, Hiroto; Gee, James; Kim, Namkug",Deep Learning Applications in Chest Radiography and Computed Tomography Current State of the Art,journal of thoracic imaging,2019,Not found,"Deep learning is a genre of machine learning that allows computational models to learn representations of data with multiple levels of abstraction using numerous processing layers. A distinctive feature of deep learning, compared with conventional machine learning methods, is that it can generate appropriate models for tasks directly from the raw data, removing the need for human-led feature extraction. Medical images are particularly suited for deep learning applications. Deep learning techniques have already demonstrated high performance in the detection of diabetic retinopathy on fundoscopic images and metastatic breast cancer cells on pathologic images. In radiology, deep learning has the opportunity to provide improved accuracy of image interpretation and diagnosis. Many groups are exploring the possibility of using deep learning-based applications to solve unmet clinical needs. In chest imaging, there has been a large effort to develop and apply computer-aided detection systems for the detection of lung nodules on chest radiographs and chest computed tomography. The essential limitation to computer-aided detection is an inability to learn from new information. To overcome these deficiencies, many groups have turned to deep learning approaches with promising results. In addition to nodule detection, interstitial lung disease recognition, lesion segmentation, diagnosis and patient outcomes have been addressed by deep learning approaches. The purpose of this review article was to cover the current state of the art for deep learning approaches and its limitations, and some of the potential impact on the field of radiology, with specific reference to chest imaging.",chest imaging; machine learning; deep learning; radiography; computed tomography; magnetic resonance imaging
Article,"Tan, Tien-En; Anees, Ayesha; Chen, Cheng; Li, Shaohua; Xu, Xinxing; Li, Zengxiang; Xiao, Zhe; Yang, Yechao; Lei, Xiaofeng; Ang, Marcus; Chia, Audrey; Lee, Shu Yen; Wong, Edmund Yick Mun; Yeo, Ian Yew San; Wong, Yee Ling; Hoang, Quan, V; Wang, Ya Xing; Bikbov, Mukharram M.; Nangia, Vinay; Jonas, Jost B.; Chen, Yen-Po; Wu, Wei-Chi; Ohno-Matsui, Kyoko; Rim, Tyler Hyungtaek; Tham, Yih-Chung; Goh, Rick Siow Mong; Lin, Haotian; Liu, Hanruo; Wang, Ningli; Yu, Weihong; Tan, Donald Tiang Hwee; Schmetterer, Leopold; Cheng, Ching-Yu; Chen, Youxin; Wong, Chee Wai; Cheung, Gemmy Chui Ming; Saw, Seang-Mei; Wong, Tien Yin; Liu, Yong; Ting, Daniel Shu Wei",Retinal photograph-based deep learning algorithms for myopia and a blockchain platform to facilitate artificial intelligence medical research: a retrospective multicohort study,lancet digital health,2021,Not found,"Background By 2050, almost 5 billion people globally are projected to have myopia, of whom 20% are likely to have high myopia with clinically significant risk of sight-threatening complications such as myopic macular degeneration. These are diagnoses that typically require specialist assessment or measurement with multiple unconnected pieces of equipment. Artificial intelligence (AI) approaches might be effective for risk stratification and to identify individuals at highest risk of visual loss. However, unresolved challenges for AI medical studies remain, including paucity of transparency, auditability, and traceability. Methods In this retrospective multicohort study, we developed and tested retinal photograph-based deep learning algorithms for detection of myopic macular degeneration and high myopia, using a total of 226 686 retinal images. First we trained and internally validated the algorithms on datasets from Singapore, and then externally tested them on datasets from China, Taiwan, India, Russia, and the UK. We also compared the performance of the deep learning algorithms against six human experts in the grading of a randomly selected dataset of 400 images from the external datasets. As proof of concept, we used a blockchain-based AI platform to demonstrate the real-world application of secure data transfer, model transfer, and model testing across three sites in Singapore and China. Findings The deep learning algorithms showed robust diagnostic performance with areas under the receiver operating characteristic curves [AUC] of 0.969 (95% CI 0.959-0.977) or higher for myopic macular degeneration and 0.913 (0.906-0.920) or higher for high myopia across the external testing datasets with available data. In the randomly selected dataset, the deep learning algorithms outperformed all six expert graders in detection of each condition (AUC of 0.978 [0.957-0.994] for myopic macular degeneration and 0.973 [0.941-0.995] for high myopia). We also successfully used blockchain technology for data transfer, model transfer, and model testing between sites and across two countries. Interpretation Deep learning algorithms can be effective tools for risk stratification and screening of myopic macular degeneration and high myopia among the large global population with myopia. The blockchain platform developed here could potentially serve as a trusted platform for performance testing of future AI models in medicine. Copyright (C) 2021 The Author(s). Published by Elsevier Ltd. This is an Open Access article under the CC BY-NC-ND 4.0 license.",choroidal neovascularization; visual impairment; eye diseases; diabetic-retinopathy; classification; epidemiology; methodology; prevalence; validation; blindness
Article,"Li, Mei; Wan, Chao",The use of deep learning technology for the detection of optic neuropathy,quantitative imaging in medicine and surgery,2022,Not found,"The emergence of computer graphics processing units (GPUs), improvements in mathematical models, and the availability of big data, has allowed artificial intelligence (AI) to use machine learning and deep learning (DL) technology to achieve robust performance in various fields of medicine. The DL system provides improved capabilities, especially in image recognition and image processing. Recent progress in the sorting of AI data sets has stimulated great interest in the development of DL algorithms. Compared with subjective evaluation and other traditional methods, DL algorithms can identify diseases faster and more accurately in diagnostic tests. Medical imaging is of great significance in the clinical diagnosis and individualized treatment of ophthalmic diseases. Based on the morphological data sets of millions of data points, various image-related diagnostic techniques can now impart high-resolution information on anatomical and functional changes, thereby providing unprecedented insights in ophthalmic clinical practice. As ophthalmology relies heavily on imaging examinations, it is one of the first medical fields to apply DL algorithms in clinical practice. Such algorithms can assist in the analysis of large amounts of data acquired from the examination of auxiliary images. In recent years, rapid advancements in imaging technology have facilitated the application of DL in the automatic identification and classification of pathologies that are characteristic of ophthalmic diseases, thereby providing high quality diagnostic information. This paper reviews the origins, development, and application of DL technology. The technical and clinical problems associated with building DL systems to meet clinical needs and the potential challenges of clinical application are discussed, especially in relation to the field of optic nerve diseases.",deep learning (dl); optic nerve; artificial intelligence (ai); fundus image; optical coherence tomography (oct)
Article,"Maji, Debasis; Sekh, Arif Ahmed",Automatic Grading of Retinal Blood Vessel in Deep Retinal Image Diagnosis,journal of medical systems,2020,Not found,"Automatic grading of retinal blood vessels from fundus image can be a useful tool for diagnosis, planning and treatment of eye. Automatic diagnosis of retinal images for early detection of glaucoma, stroke, and blindness is emerging in intelligent health care system. The method primarily depends on various abnormal signs, such as area of hard exudates, area of blood vessels, bifurcation points, texture, and entropies. The development of an automated screening system based on vessel width, tortuosity, and vessel branching are also used for grading. However, the automated method that directly can come to a decision by taking the fundus images got less attention. Detecting eye problems based on the tortuosity of the vessel from fundus images is a complicated task for opthalmologists. So automated grading algorithm using deep learning can be most valuable for grading retinal health. The aim of this work is to develop an automatic computer aided diagnosis system to solve the problem. This work approaches to achieve an automatic grading method that is opted using Convolutional Neural Network (CNN) model. In this work we have studied the state-of-the-art machine learning algorithms and proposed an attention network which can grade retinal images. The proposed method is validated on a public dataset EIARG1, which is only publicly available dataset for such task as per our knowledge.",diabetic retinopathy (dr); retinopathy of prematurity (rop); tortuosity-based grading
Review,"Ting, Daniel S. W.; Peng, Lily; Varadarajan, Avinash V.; Keane, Pearse A.; Burlina, Philippe M.; Chiang, Michael F.; Schmetterer, Leopold; Pasquale, Louis R.; Bressler, Neil M.; Webster, Dale R.; Abramoff, Michael; Wong, Tien Y.",Deep learning in ophthalmology: The technical and clinical considerations,progress in retinal and eye research,2019,Not found,"The advent of computer graphic processing units, improvement in mathematical models and availability of big data has allowed artificial intelligence (AI) using machine learning (ML) and deep learning (DL) techniques to achieve robust performance for broad applications in social-media, the intemet of things, the automotive industry and healthcare. DL systems in particular provide improved capability in image, speech and motion recognition as well as in natural language processing. In medicine, significant progress of AI and DL systems has been demonstrated in image-centric specialties such as radiology, dermatology, pathology and ophthalmology. New studies, including pre-registered prospective clinical trials, have shown DL systems are accurate and effective in detecting diabetic retinopathy (DR), glaucoma, age-related macular degeneration (AMD), retinopathy of prematurity, refractive error and in identifying cardiovascular risk factors and diseases, from digital fundus photographs. There is also increasing attention on the use of AI and DL systems in identifying disease features, progression and treatment response for retinal diseases such as neovascular AMD and diabetic macular edema using optical coherence tomography (OCT). Additionally, the application of ML to visual fields may be useful in detecting glaucoma progression. There are limited studies that incorporate clinical data including electronic health records, in AL and DL algorithms, and no prospective studies to demonstrate that AI and DL algorithms can predict the development of clinical eye disease. This article describes global eye disease burden, unmet needs and common conditions of public health importance for which AI and DL systems may be applicable. Technical and clinical aspects to build a DL system to address those needs, and the potential challenges for clinical adoption are discussed. AI, ML and DL will likely play a crucial role in clinical ophthalmology practice, with implications for screening, diagnosis and follow up of the major causes of vision impairment in the setting of ageing populations globally.",optical coherence tomography; plus disease diagnosis; macular degeneration; diabetic-retinopathy; cardiovascular risk; global prevalence; heart-disease; automated detection; vision impairment; image-analysis
Review,"Xiao, Di; Bhuiyan, Alauddin; Frost, Shaun; Vignarajan, Janardhan; Tay-Kearney, Mei-Ling; Kanagasingam, Yogesan",Major automatic diabetic retinopathy screening systems and related core algorithms: a review,machine vision and applications,2019,Not found,"Diabetic retinopathy (DR), one of the major and long-term microvascular complications of diabetes, is the most common cause of vision loss and blindness in the working population of the world. Even with the management of diabetes, most patients will develop some forms of DR after approximately 20 years. However, DR is a treatable disease throughout the disease progression. To provide appropriate DR management, the USA and European countries have successfully implemented systematic early DR screening programs. At the same time, some computer-aided DR screening systems, which combine advanced DR detection algorithms and telemedicine technology, have also been developed for early-stage DR detection. Some of them have been tested in the DR screening programs. In this paper, we focus on a review of the major automatic DR screening systems which have performed large-scale evaluation rather than give an extensive review of all published DR grading algorithms. We first present the structures of the automatic systems and their supporting algorithms developed by the research groups, as well as the practices of the systems in their screening programs. We further present a more detailed review of the DR lesion detection algorithms in each system and reveal how the DR screening systems successfully practiced in clinical trials or large-scale screening programs. We also review recently new research areas as well as deep learning-based DR screening systems and compare them with the traditional lesion detection-based DR screening systems. The performances of the systems in the trials are summarized by considering the specificity and sensitivity with respect to the scale of testing datasets. At last, we will discuss future challenges.",diabetic retinopathy; automatic dr screening system; dr grading algorithm; dr screening program
Article,"Murugappan, M.; Prakash, N. B.; Jeya, R.; Mohanarathinam, A.; Hemalakshmi, G. R.; Mahmud, Mufti",A novel few-shot classification framework for diabetic retinopathy detection and grading,measurement,2022,Not found,"Diabetes Retinopathy (DR) is a major microvascular complication of diabetes. Computer-Aided Diagnosis (CAD) tools for DR management are primarily developed using Artificial Intelligence (AI) methods, such as machine and deep learning algorithms. DR diagnostic tools have been developed in recent years using deep learning models. Thus, these models require large amounts of data for training. Consequently, these huge amounts of data are not balanced due to fewer cases in the dataset. To solve the problems associated with training models with small datasets, such as overfitting and poor approximation, this paper proposes a paradigm called Few-Shot Learning (FSL) which uses a relatively small amount of training data to train the models effectively. This paper proposes a novel prototype network, a type of FSL classification network capable of grading and detecting DR based on attention. The DRNet framework uses episodic learning to train its model on few-shot classification tasks. We developed a DRNet based on the APTOS2019 dataset for diabetic detection and grading. In the proposed network, aggregated transformations and gradient activations of classes are leveraged to design the attention mechanism to capture image representations. As a result, the system achieves 99.73 % accuracy, 99.82 % sensitivity, 99.63 % specificity in DR detection, 98.18 % accuracy, 97.41% sensitivity, and 99.55% specificity in DR grading. An analysis of objective performance metrics and model interpretation shows that the proposed model can detect DR more efficiently and grade the severity more accurately when using unseen fundus images than existing state-of-the-art methods. Therefore, this tool could help provide a second opinion to an ophthal-mologist about the severity level of DR.",diabeticretinopathy; detection; grading; aggregatedtransformations; classactivation
Proceedings Paper,"Martinez-Villasenor, Lourdes; Ponce, Hiram; Martinez-Velasco, Antonieta; Miralles-Pechuan, Luis",An Explainable Tool to Support Age-related Macular Degeneration Diagnosis,2022 international joint conference on neural networks (ijcnn),2022,Not found,"Artificial intelligence and deep learning, in particular, have gained large attention in the ophthalmology community due to the possibility of processing large amounts of data and digitized ocular images. Intelligent systems are developed to support the diagnosis and treatment of a number of ophthalmic diseases such as age-related macular degeneration (AMD), glaucoma and retinopathy of prematurity. Hence, explainability is necessary to gain trust and therefore the adoption of these critical decision support systems. Visual explanations have been proposed for AMD diagnosis only when optical coherence tomography (OCT) images are used, but interpretability using other inputs (i.e. data point-based features) for AMD diagnosis is rather limited. In this paper, we propose a practical tool to support AMD diagnosis based on Artificial Hydrocarbon Networks (AHN) with different kinds of input data such as demographic characteristics, features known as risk factors for AMD, and genetic variants obtained from DNA genotyping. The proposed explainer, namely eXplainable Artificial Hydrocarbon Networks (XAHN) is able to get global and local interpretations of the AHN model. An explainability assessment of the XAHN explainer was applied to clinicians for getting feedback from the tool. We consider the XAHN explainer tool will be beneficial to support expert clinicians in AMD diagnosis, especially where input data are not visual.",explainability; age-related macular degeneration; artificial hydrocarbon networks; explainable ai
Article; Early Access,"Bansode, Balbhim Narhari; Bakwad, K. M.; Dildar, Ajij Sayyad; Sable, G. S.",Deen CNN-based feature extraction with optimised LSTM for enhanced diabetic retinopathy detection,computer methods in biomechanics and biomedical engineering-imaging and visualization,0,Not found,"The early detection and treatment of DR have helped the ophthalmologist to treat the affected patients and to reduce vision loss. Computer-aided screening for automatic DR detection in the medical system has consistent detection of lesions in retinal fundus image. To overcome these challenges and to offer timely treatment, this paper aims to develop a novel deep learning-based DR detection. Here, the integration of 'Optimized Iterative Thresholding (O-IT)' is adopted for the accurate segmentation of blood vessels. The first novelty of this work is that the thresholding approach is improved by tuning the parameters in the proposed model by developing a hybrid meta-heuristic Shark Smell-Jaya Optimisation (SS-JO) algorithm to enhance the performance of both blood vessel segmentation and classification. CNN is replaced by a deep learning framework termed as optimised 'Long Short-Term Memory (LSTM)'. The second novelty of this work is that the optimised LSTM is designed in the proposed model by optimising the parameters in LSTM using the implemented SS-JO to reduce the complexity of the network. The accuracy analysis of the implemented SS-JO-CN-LSTM is secured 44%, 29%, 19%, 6%, 4% and 15% improved than SVM, NN, CNN, LSTM, CN-LSTM and FR-CSA-NN+CNN.",diabetic retinopathy diagnosis; shark smell-jaya optimization; blood vessel segmentation optimised iterative thresholding; optimised long short-term memory
Article,"Elsharkawy, Mohamed; Sharafeldeen, Ahmed; Soliman, Ahmed; Khalifa, Fahmi; Ghazal, Mohammed; El-Daydamony, Eman; Atwan, Ahmed; Sandhu, Harpal Singh; El-Baz, Ayman",A Novel Computer-Aided Diagnostic System for Early Detection of Diabetic Retinopathy Using 3D-OCT Higher-Order Spatial Appearance Model,diagnostics,2022,Not found,"Early diagnosis of diabetic retinopathy (DR) is of critical importance to suppress severe damage to the retina and/or vision loss. In this study, an optical coherence tomography (OCT)-based computer-aided diagnosis (CAD) method is proposed to detect DR early using structural 3D retinal scans. This system uses prior shape knowledge to automatically segment all retinal layers of the 3D-OCT scans using an adaptive, appearance-based method. After the segmentation step, novel texture features are extracted from the segmented layers of the OCT B-scans volume for DR diagnosis. For every layer, Markov-Gibbs random field (MGRF) model is used to extract the 2nd-order reflectivity. In order to represent the extracted image-derived features, we employ cumulative distribution function (CDF) descriptors. For layer-wise classification in 3D volume, using the extracted Gibbs energy feature, an artificial neural network (ANN) is fed the extracted feature for every layer. Finally, the classification outputs for all twelve layers are fused using a majority voting schema for global subject diagnosis. A cohort of 188 3D-OCT subjects are used for system evaluation using different k-fold validation techniques and different validation metrics. Accuracy of 90.56%, 93.11%, and 96.88% are achieved using 4-, 5-, and 10-fold cross-validation, respectively. Additional comparison with deep learning networks, which represent the state-of-the-art, documented the promise of our system's ability to diagnose the DR early.",3-d optical coherence tomography (3-d oct); diabetic retinopathy (dr); neural network (nn); majority voting; computer-aided diagnosis (cad); markov-gibbs random field model (mgrf)
Article; Early Access,"Elmoufidi, Abdelali; Skouta, Ayoub; Jai-Andaloussi, Said; Ouchetto, Ouail",CNN with Multiple Inputs for Automatic Glaucoma Assessment Using Fundus Images,international journal of image and graphics,0,Not found,"In the area of ophthalmology, glaucoma affects an increasing number of people. It is a major cause of blindness. Early detection avoids severe ocular complications such as glaucoma, cystoid macular edema, or diabetic proliferative retinopathy. Intelligent artificial intelligence has been confirmed beneficial for glaucoma assessment. In this paper, we describe an approach to automate glaucoma diagnosis using funds images. The setup of the proposed framework is in order: The Bi-dimensional Empirical Mode Decomposition (BEMD) algorithm is applied to decompose the Regions of Interest (ROI) to components (BIMFs+residue). CNN architecture VGG19 is implemented to extract features from decomposed BEMD components. Then, we fuse the features of the same ROI in a bag of features. These last very long; therefore, Principal Component Analysis (PCA) are used to reduce features dimensions. The bags of features obtained are the input parameters of the implemented classifier based on the Support Vector Machine (SVM). To train the built models, we have used two public datasets, which are ACRIMA and REFUGE. For testing our models, we have used a part of ACRIMA and REFUGE plus four other public datasets, which are RIM-ONE, ORIGA-light, Drishti-GS1, and sjchoi86-HRF. The overall precision of 98.31%, 98.61%, 96.43%, 96.67%, 95.24%, and 98.60% is obtained on ACRIMA, REFUGE, RIM-ONE, ORIGA-light, Drishti-GS1, and sjchoi86-HRF datasets, respectively, by using the model trained on REFUGE. Again an accuracy of 98.92%, 99.06%, 98.27%, 97.10%, 96.97%, and 96.36% is obtained in the ACRIMA, REFUGE, RIM-ONE, ORIGA-light, Drishti-GS1, and sjchoi86-HRF datasets, respectively, using the model training on ACRIMA. The experimental results obtained from different datasets demonstrate the efficiency and robustness of the proposed approach. A comparison with some recent previous work in the literature has shown a significant advancement in our proposal.",artificial intelligence; ophthalmology; glaucoma; deep learning; bag of features; image classification; computer aided diagnosis
Article,"Macsik, Peter; Pavlovicova, Jarmila; Goga, Jozef; Kajan, Slavomir",Local Binary CNN for Diabetic Retinopathy Classification on Fundus Images,acta polytechnica hungarica,2022,Not found,"Diabetic retinopathy (DR), is currently one of the major causes of preventable blindness, worldwide. With an early diagnosis and proper treatment of this eye disease, we can prevent the spread of diabetic retinopathy. In this paper, we propose a new alternative of local binary convolutional neural network (LBCNN) deterministic filter generation which can approximate the performance of the standard convolutional neural network (CNN) with less learnable parameters and also with less memory use, which can be helpful in systems with low-memory or low computational capacity, like smart-phones. We compare our scheme with standard CNN and LBCNN that uses stochastic filter generation strategy on retinal fundus image datasets in case of binary classification into healthy and damaged classes. These experiments are also evaluated according to the standard criteria used in medical applications, such as, overall accuracy, specificity, sensitivity and predictive values. On the small dataset (Aptos), one of our proposed LBCNN architectures outperformed all of the other deep learning models examined.",cad (computer-aided diagnostics); binary classification; memory reduction; learnable parameters
Article,"Park, Seong Ho; Park, Chang Min; Choi, Joon-Il",Health insurance coverage for artificial intelligence-based medical technologies: focus on radiology,journal of the korean medical association,2021,Not found,"Background: Interest in health insurance coverage for artificial intelligence (AI)-based medical technologies is growing. This article provides a review of the current developments in the sphere and provides future perspectives, focusing on AI application in radiology. Current Concepts: In December 2019, the Health Insurance Review and Assessment Service under the Korean Ministry of Health and Welfare released its first guidelines for determining the National Health Insurance coverage for AI-based medical technologies. Additionally, in 2020, the largest US health insurance provider, the Centers for Medicare and Medicaid Services, approved payment for AI technologies using two different systems. First, in September 2020, it granted New Technology Add-on Payments for AI algorithms that facilitate the diagnosis and treatment of large vessel occlusion strokes. Second, in December 2020, the Centers for Medicare and Medicaid Services finalized the provision of reimbursements for IDx-DR through a Current Procedural Terminology code. The AI system screens for more than mild diabetic retinopathy, which requires further evaluation by an ophthalmologist. Discussion and Conclusion: An in-depth look at the three events suggests the importance of demonstrating the added clinical value of AI technologies through improved patient outcomes in enabling insurance coverage. Therefore, it is critical to create clinically meaningful collaboration between healthcare professionals and AI by understanding and combining their unique strengths, thus actualizing new forms of patient care instead of having AI merely copy the professionals. Furthermore, if National Health Insurance coverage is granted for AI technologies in radiology, add-on payments would be the most appropriate method.",health insurance; insurance coverage; artificial intelligence; radiology
Article,"Jiang, Jiewei; Lei, Shutao; Zhu, Mingmin; Li, Ruiyang; Yue, Jiayun; Chen, Jingjing; Li, Zhongwen; Gong, Jiamin; Lin, Duoru; Wu, Xiaohang; Lin, Zhuoling; Lin, Haotian",Improving the Generalizability of Infantile Cataracts Detection via Deep Learning-Based Lens Partition Strategy and Multicenter Datasets,frontiers in medicine,2021,Not found,"Infantile cataract is the main cause of infant blindness worldwide. Although previous studies developed artificial intelligence (AI) diagnostic systems for detecting infantile cataracts in a single center, its generalizability is not ideal because of the complicated noises and heterogeneity of multicenter slit-lamp images, which impedes the application of these AI systems in real-world clinics. In this study, we developed two lens partition strategies (LPSs) based on deep learning Faster R-CNN and Hough transform for improving the generalizability of infantile cataracts detection. A total of 1,643 multicenter slit-lamp images collected from five ophthalmic clinics were used to evaluate the performance of LPSs. The generalizability of Faster R-CNN for screening and grading was explored by sequentially adding multicenter images to the training dataset. For the normal and abnormal lenses partition, the Faster R-CNN achieved the average intersection over union of 0.9419 and 0.9107, respectively, and their average precisions are both > 95%. Compared with the Hough transform, the accuracy, specificity, and sensitivity of Faster R-CNN for opacity area grading were improved by 5.31, 8.09, and 3.29%, respectively. Similar improvements were presented on the other grading of opacity density and location. The minimal training sample size required by Faster R-CNN is determined on multicenter slit-lamp images. Furthermore, the Faster R-CNN achieved real-time lens partition with only 0.25 s for a single image, whereas the Hough transform needs 34.46 s. Finally, using Grad-Cam and t-SNE techniques, the most relevant lesion regions were highlighted in heatmaps, and the high-level features were discriminated. This study provides an effective LPS for improving the generalizability of infantile cataracts detection. This system has the potential to be applied to multicenter slit-lamp images.",lens partition strategy; infantile cataracts; automatic diagnosis; faster r-cnn; multicenter slit-lamp images
Article,"Wang, Chi-Chih; Chiu, Yu-Ching; Chen, Wei-Liang; Yang, Tzu-Wei; Tsai, Ming-Chang; Tseng, Ming-Hseng",A Deep Learning Model for Classification of Endoscopic Gastroesophageal Reflux Disease,international journal of environmental research and public health,2021,Not found,"Gastroesophageal reflux disease (GERD) is a common disease with high prevalence, and its endoscopic severity can be evaluated using the Los Angeles classification (LA grade). This paper proposes a deep learning model (i.e., GERD-VGGNet) that employs convolutional neural networks for automatic classification and interpretation of routine GERD LA grade. The proposed model employs a data augmentation technique, a two-stage no-freezing fine-tuning policy, and an early stopping criterion. As a result, the proposed model exhibits high generalizability. A dataset of images from 464 patients was used for model training and validation. An additional 32 patients served as a test set to evaluate the accuracy of both the model and our trainees. Experimental results demonstrate that the best model for the development set exhibited an overall accuracy of 99.2% (grade A-B), 100% (grade C-D), and 100% (normal group) using narrow-band image (NBI) endoscopy. On the test set, the proposed model resulted in an accuracy of 87.9%, which was significantly higher than the results of the trainees (75.0% and 65.6%). The proposed GERD-VGGNet model can assist automatic classification of GERD in conventional and NBI environments and thereby increase the accuracy of interpretation of the results by inexperienced endoscopists.",gastroesophageal reflux disease classification; artificial intelligence; deep learning; conventional endoscopy; narrow-band image
Review,"Dong, Li; Yang, Qiong; Zhang, Rui Heng; Wei, Wen Bin",Artificial intelligence for the detection of age-related macular degeneration in color fundus photographs: A systematic review and meta-analysis,eclinicalmedicine,2021,Not found,"Background: Age-related macular degeneration (AMD) is one of the leading causes of vision loss in the elderly population. The application of artificial intelligence (AI) provides convenience for the diagnosis of AMD. This systematic review and meta-analysis aimed to quantify the performance of AI in detecting AMD in fundus photographs. Methods: We searched PubMed, Embase, Web of Science and the Cochrane Library before December 31st, 2020 for studies reporting the application of AI in detecting AMD in color fundus photographs. Then, we pooled the data for analysis. PROSPERO registration number: CRD42020197532. Findings: 19 studies were finally selected for systematic review and 13 of them were included in the quantitative synthesis. All studies adopted human graders as reference standard. The pooled area under the receiver operating characteristic curve (AUROC) was 0.983 (95% confidence interval (CI):0.979-0.987). The pooled sensitivity, specificity, and diagnostic odds ratio (DOR) were 0.88 (95% CI:0.88-0.88), 0.90 (95% CI:0.90-0.91), and 275.27 (95% CI:158.43-478.27), respectively. Threshold analysis was performed and a potential threshold effect was detected among the studies (Spearman correlation coefficient: -0.600, P = 0.030), which was the main cause for the heterogeneity. For studies applying convolutional neural networks in the Age-Related Eye Disease Study database, the pooled AUROC, sensitivity, specificity, and DOR were 0.983 (95% CI:0.978-0.988), 0.88 (95% CI:0.88-0.88), 0.91 (95% CI:0.91-0.91), and 273.14 (95% CI:130.79-570.43), respectively. Interpretation: Our data indicated that AI was able to detect AMD in color fundus photographs. The application of AI-based automatic tools is beneficial for the diagnosis of AMD. (C) 2021 The Author(s). Published by Elsevier Ltd.",artificial intelligence; deep learning; convolutional neural networks; algorithm; agerelated macular degeneration
Proceedings Paper,"Ananda, Swathi; Kitahara, Daichi; Hirabayashi, Akira; Reddy, K. R. Udaya Kumar",Automatic Fundus Image Segmentation for Diabetic Retinopathy Diagnosis by Multiple Modified U-Nets and SegNets,2019 asia-pacific signal and information processing association annual summit and conference (apsipa asc),2019,Not found,"Diabetes mellitus leads to damage of the retina by a high blood sugar level. This disease is called diabetic retinopathy (DR), and it is one major cause of blindness among working-aged people. DR affects about 80% of patients who have had diabetes for twenty years or more. The longer a period of diabetes is, the higher the risk of developing DR is. In order to prevent the blindness caused by DR, accurate DR diagnosis from a retinal fundus image is important. Recently, deep learning techniques play a significant role in the field of computer vision. When we apply deep learning to segmentation of abnormal parts in fundus images, two major problems arise. One is that the number of available data is insufficient to train a deep neural network. The other is that the sizes of the abnormal parts are quite different depending on the type of the disease, which leads to low segmentation accuracy of small diseases. These two problems make the fundus image segmentation challenging. In this paper, we propose a segmentation method using multiple deep neural networks. To train the deep neural networks from a small number of data, we use data augmentation as preprocessing and adopt the Dice coefficient with the binary cross entropy as a loss function. Moreover, to improve the segmentation accuracy of small diseases, e.g., microaneurysms, we construct one individual network for each type of the disease. In experiments, the networks are trained from IDRiD dataset and tested for MESSIDOR dataset. We compare and discuss the accuracy of the proposed method with modified U-Nets and SegNets.",exudate detection; retinal images
Review,"Li, Tao; Bo, Wang; Hu, Chunyu; Kang, Hong; Liu, Hanruo; Wang, Kai; Fu, Huazhu",Applications of deep learning in fundus images: A review,medical image analysis,2021,Not found,"The use of fundus images for the early screening of eye diseases is of great clinical importance. Due to its powerful performance, deep learning is becoming more and more popular in related applications, such as lesion segmentation, biomarkers segmentation, disease diagnosis and image synthesis. Therefore, it is very necessary to summarize the recent developments in deep learning for fundus images with a review paper. In this review, we introduce 143 application papers with a carefully designed hierarchy. Moreover, 33 publicly available datasets are presented. Summaries and analyses are provided for each task. Finally, limitations common to all tasks are revealed and possible solutions are given. We will also release and regularly update the state-of-the-art results and newly-released datasets at https://github.com/nkicsl/Fundus_Review to adapt to the rapid development of this field. ? 2021 Elsevier B.V. All rights reserved.",fundus images; deep learning; eye diseases
Article,"Li, Wangting; Yang, Yahan; Zhang, Kai; Long, Erping; He, Lin; Zhang, Lei; Zhu, Yi; Chen, Chuan; Liu, Zhenzhen; Wu, Xiaohang; Yun, Dongyuan; Lv, Jian; Liu, Yizhi; Liu, Xiyang; Lin, Haotian",Dense anatomical annotation of slit-lamp images improves the performance of deep learning for the diagnosis of ophthalmic disorders,nature biomedical engineering,2020,Not found,"The development of artificial intelligence algorithms typically demands abundant high-quality data. In medicine, the datasets that are required to train the algorithms are often collected for a single task, such as image-level classification. Here, we report a workflow for the segmentation of anatomical structures and the annotation of pathological features in slit-lamp images, and the use of the workflow to improve the performance of a deep-learning algorithm for diagnosing ophthalmic disorders. We used the workflow to generate 1,772 general classification labels, 13,404 segmented anatomical structures and 8,329 pathological features from 1,772 slit-lamp images. The algorithm that was trained with the image-level classification labels and the anatomical and pathological labels showed better diagnostic performance than the algorithm that was trained with only the image-level classification labels, performed similar to three ophthalmologists across four clinically relevant retrospective scenarios and correctly diagnosed most of the consensus outcomes of 615 clinical reports in prospective datasets for the same four scenarios. The dense anatomical annotation of medical images may improve their use for automated classification and detection tasks. A workflow that segments anatomical structures in slit-lamp images and that annotates pathological features in each image improves the performance of a deep-learning algorithm for the diagnosis of ophthalmic disorders.",diabetic-retinopathy; united-states; validation
Article,"Pao, Shu-, I; Lin, Hong-Zin; Chien, Ke-Hung; Tai, Ming-Cheng; Chen, Jiann-Torng; Lin, Gen-Min",Detection of Diabetic Retinopathy Using Bichannel Convolutional Neural Network,journal of ophthalmology,2020,Not found,"Deep learning of fundus photograph has emerged as a practical and cost-effective technique for automatic screening and diagnosis of severer diabetic retinopathy (DR). The entropy image of luminance of fundus photograph has been demonstrated to increase the detection performance for referable DR using a convolutional neural network- (CNN-) based system. In this paper, the entropy image computed by using the green component of fundus photograph is proposed. In addition, image enhancement by unsharp masking (UM) is utilized for preprocessing before calculating the entropy images. The bichannel CNN incorporating the features of both the entropy images of the gray level and the green component preprocessed by UM is also proposed to improve the detection performance of referable DR by deep learning.",major risk-factors; unsharp masking; global prevalence; validation; system
Article,"Narhari, Bansode Balbhim; Murlidhar, Bakwad Kamlakar; Sayyad, Ajij Dildar; Sable, Ganesh Shahubha",Automated diagnosis of diabetic retinopathy enabled by optimized thresholding-based blood vessel segmentation and hybrid classifier,bio-algorithms and med-systems,2021,Not found,"Objectives: The focus of this paper is to introduce an automated early Diabetic Retinopathy (DR) detection scheme from colour fundus images through enhanced segmentation and classification strategies by analyzing blood vessels. Methods: The occurrence of DR is increasing from the past years, impacting the eyes due to a sudden rise in the glucose level of blood. All over the world, half of the people who are under age 70 are severely suffered from diabetes. The patients who are affected by DR will lose their vision during the absence of early recognition of DR and appropriate treatment. To decrease the growth and occurrence of loss of vision, the early detection and timely treatment of DR are desirable. At present, deep learning models have presented better performance using retinal images for DR detection. In this work, the input retinal fundus images are initially subjected to pre-processing that undergoes contrast enhancement by Contrast Limited Adaptive Histogram Equalization (CLAHE) and average filtering. Further, the optimized binary thresholding-based segmentation is done for blood vessel segmentation. For the segmented image, Tri-level Discrete Level Decomposition (Tri-DWT) is performed to decompose it. In the feature extraction phase, Local Binary Pattern (LBP), and Gray-Level Co-occurrence Matrices (GLCMs) are extracted. Next, the classification of images is done through the combination of two algorithms, one is Neural Network (NN), and the other Convolutional Neural Network (CNN). The extracted features are subjected to NN, and the triDWT-based segmented image is subjected to CNN. Both the segmentation and classification phases are enhanced by the improved meta-heuristic algorithm called Fitness Rate-based Crow Search Algorithm (FR-CSA), in which few parameters are optimized for attaining maximum detection accuracy. Results: The proposed DR detection model was implemented in MATLAB 2018a, and the analysis was done using three datasets, HRF, Messidor, and DIARETDB. Conclusions: The developed FR-CSA algorithm has the best detection accuracy in diagnosing DR.",average filtering; contrast limited adaptive histogram equalization; convolutional neural network; diabetic retinopathy; fitness rate-based crow search algorithm; gray-level co-occurrence matrices; neural network; optimized binary thresholding; tri-level discrete level decomposition
Proceedings Paper,"Fu, Huazhu; Wang, Boyang; Shen, Jianbing; Cui, Shanshan; Xu, Yanwu; Liu, Jiang; Shao, Ling",Evaluation of Retinal Image Quality Assessment Networks in Different Color-Spaces,"medical image computing and computer assisted intervention - miccai 2019, pt i",2019,Not found,"Retinal image quality assessment (RIQA) is essential for controlling the quality of retinal imaging and guaranteeing the reliability of diagnoses by ophthalmologists or automated analysis systems. Existing RIQA methods focus on the RGB color-space and are developed based on small datasets with binary quality labels (i.e., 'Accept' and 'Reject'). In this paper, we first re-annotate an Eye-Quality (EyeQ) dataset with 28,792 retinal images from the EyePACS dataset, based on a three-level quality grading system (i.e., 'Good', 'Usable' and 'Reject') for evaluating RIQA methods. Our RIQA dataset is characterized by its large-scale size, multi-level grading, and multi-modality. Then, we analyze the influences on RIQA of different color-spaces, and propose a simple yet efficient deep network, named Multiple Color-space Fusion Network (MCF-Net), which integrates the different color-space representations at both a feature-level and prediction-level to predict image quality grades. Experiments on our EyeQ dataset show that our MCF-Net obtains a state-of-the-art performance, outperforming the other deep learning methods. Furthermore, we also evaluate diabetic retinopathy (DR) detection methods on images of different quality, and demonstrate that the performances of automated diagnostic systems are highly dependent on image quality.",retinal image; quality assessment; deep learning
Article,"Zago, Gabriel Tozatto; Andreao, Rodrigo Varejao; Dorizzi, Bernadette; Teatini Salles, Evandro Ottoni",Retinal image quality assessment using deep learning,computers in biology and medicine,2018,Not found,"Poor-quality retinal images do not allow an accurate medical diagnosis, and it is inconvenient for a patient to return to a medical center to repeat the fundus photography exam. In this paper, a robust automatic system is proposed to assess the quality of retinal images at the moment of the acquisition, aiming at assisting health care professionals during a fundus photography exam. We propose a convolutional neural network (CNN) pretrained on non-medical images for extracting general image features. The weights of the CNN are further adjusted via a fine-tuning procedure, resulting in a performant classifier obtained only with a small quantity of labeled images. The CNN performance was evaluated on two publicly available databases (i.e., DRIMDB and ELSA-Brasil) using two different procedures: intra-database and inter-database cross-validation. The CNN achieved an area under the curve (AUC) of 99.98% on DRIMDB and an AUC of 98.56% on ELSA-Brasil in the inter-database experiment, where training and testing were not performed on the same database. These results show the robustness of the proposed model to various image acquisitions without requiring special adaptation, thus making it a good candidate for use in operational clinical scenarios.",retinal images; image quality; deep learning; diabetic retinopathy; convolutional neural networks
Proceedings Paper,"Wang, Kun; Zhang, Xiaohong; Huang, Sheng; Wang, Qiuli; Chen, Feiyu",CTF-NET:RETINAL VESSEL SEGMENTATION VIA DEEP COARSE-TO-FINE SUPERVISION NETWORK,2020 ieee 17th international symposium on biomedical imaging (isbi 2020),2020,Not found,"Retinal blood vessels structure plays an important role in the early diagnosis of diabetic retinopathy, which is a cause of blindness globally. However, the precise segmentation of retinal vessels is often extremely challenging due to the low contrast and noise of the capillaries. In this paper, we propose a novel model of deep coarse-to-fine supervision network (CTF-Net) to solve this problem. This model consists of two U-shaped architecture(coarse and fine segNet). The coarse segNet, which learns to predict probability retina map from input patchs, while the fine segNet refines the predicted map. To gain more paths to preserve the multi-scale and rich deep features information, we design an end-to-end training network instead of multi-stage learning framework to segment the retina vessel from coarse to fine. Furthermore, in order to improve feature representation and reduce the number of parameters of model, we introduce a novel feature augmentation module (FAM-residual block). Experiment results confirm that our method achieves the state-of-the-art performances on the popular datasets DRIVE, CHASE DB1 and STARE.",retinal vessel segmentation; coarse-tofine segnet; deep learning; computer aided-diagnosis
Article,"Lin, Duoru; Xiong, Jianhao; Liu, Congxin; Zhao, Lanqin; Li, Zhongwen; Yu, Shanshan; Wu, Xiaohang; Ge, Zongyuan; Hu, Xinyue; Wang, Bin; Fu, Meng; Zhao, Xin; Wang, Xin; Zhu, Yi; Chen, Chuan; Li, Tao; Li, Yonghao; Wei, Wenbin; Zhao, Mingwei; Li, Jianqiao; Xu, Fan; Ding, Lin; Tan, Gang; Xiang, Yi; Hu, Yongcheng; Zhang, Ping; Han, Yu; Li, Ji-Peng Olivia; Wei, Lai; Zhu, Pengzhi; Liu, Yizhi; Chen, Weirong; Ting, Daniel S. W.; Wong, Tien Y.; Chen, Yuzhong; Lin, Haotian",Application of Comprehensive Artificial intelligence Retinal Expert (CARE) system: a national real-world evidence study,lancet digital health,2021,Not found,"Background Medical artificial intelligence (AI) has entered the clinical implementation phase, although real-world performance of deep-learning systems (DLSs) for screening fundus disease remains unsatisfactory. Our study aimed to train a clinically applicable DLS for fundus diseases using data derived from the real world, and externally test the model using fundus photographs collected prospectively from the settings in which the model would most likely be adopted. Methods In this national real-world evidence study, we trained a DLS, the Comprehensive AI Retinal Expert (CARE) system, to identify the 14 most common retinal abnormalities using 207228 colour fundus photographs derived from 16 clinical settings with different disease distributions. CARE was internally validated using 21867 photographs and externally tested using 18136 photographs prospectively collected from 35 real-world settings across China where CARE might be adopted, including eight tertiary hospitals, six community hospitals, and 21 physical examination centres. The performance of CARE was further compared with that of 16 ophthalmologists and tested using datasets with non-Chinese ethnicities and previously unused camera types. This study was registered with ClinicalTrials.gov, NCT04213430, and is currently closed. Findings The area under the receiver operating characteristic curve (AUC) in the internal validation set was 0.955 (SD 0.046). AUC values in the external test set were 0.965 (0.035) in tertiary hospitals, 0.983 (0.031) in community hospitals, and 0.953 (0.042) in physical examination centres. The performance of CARE was similar to that of ophthalmologists. Large variations in sensitivity were observed among the ophthalmologists in different regions and with varying experience. The system retained strong identification performance when tested using the non-Chinese dataset (AUC 0.960, 95% CI 0.957-0.964 in referable diabetic retinopathy). Interpretation Our DLS (CARE) showed satisfactory performance for screening multiple retinal abnormalities in real-world settings using prospectively collected fundus photographs, and so could allow the system to be implemented and adopted for clinical care. Copyright (C) 2021 The Author(s). Published by Elsevier ltd.",deep learning-system; diabetic-retinopathy; validation
Article,"Zhang, Quan; Liu, Zhiang; Li, Jiaxu; Liu, Guohua",Identifying Diabetic Macular Edema and Other Retinal Diseases by Optical Coherence Tomography Image and Multiscale Deep Learning,diabetes metabolic syndrome and obesity-targets and therapy,2020,Not found,"Purpose: Diabetic Macular Edema has been one of the research hotspots all over the world. But as the global population continues to grow, the number of OCT images requiring manual analysis is becoming increasingly unaffordable. Medical images are often fuzzy due to the inherent physical processes of acquiring them. It is difficult for traditional algorithms to use low-quality data. And traditional algorithms usually only provide diagnostic results, which makes the reliability and interpretability of the model face challenges. To solve problem above, we proposed a more intuitive and robust diagnosis model with self-enhancement ability and clinical triage patients' ability. Methods: We used 38,057 OCT images (Drusen, DME, CNV and Normal) to establish and evaluate the model. All data are OCT images of fundus retina. There were 37,457 samples in the training dataset and 600 samples in the validation dataset. In order to diagnose these images accurately, we propose a multiscale transfer learning algorithm. Firstly, the sample is sent to the automatic self-enhancement module for edge detection and enhancement. Then, the processed data are sent to the image diagnosis module to determine the disease type. This process makes more data more effective and can be accurately classified. Finally, we calculated the accuracy, precision, sensitivity and specificity of the model, and verified the performance of the model from the perspective of clinical application. Results: The model proposed in this paper can provide the diagnosis results and display the detection targets more intuitively. The model reached 94.5% accuracy, 97.2% precision, 97.7% sensitivity and 97% specificity in the independent testing dataset. Conclusion: Comparing the performance of relevant work and ablation test, our model achieved relatively good performance. It is proved that the model proposed in this paper has a stronger ability to recognize diseases even in the face of low-quality images. Experiment results also demonstrate its clinical referral capability. It can reduce the workload of medical staff and save the precious time of patients.",optical coherence tomography; clinical triage; self-reinforcing; assisted diagnostics; deep learning; diabetic macular edema; retina diseases
Article,"Guo, Menglin; Zhao, Mei; Cheong, Allen M. Y.; Dai, Houjiao; Lam, Andrew K. C.; Zhou, Yongjin",Automatic quantification of superficial foveal avascular zone in optical coherence tomography angiography implemented with deep learning,visual computing for industry biomedicine and art,2019,Not found,"An accurate segmentation and quantification of the superficial foveal avascular zone (sFAZ) is important to facilitate the diagnosis and treatment of many retinal diseases, such as diabetic retinopathy and retinal vein occlusion. We proposed a method based on deep learning for the automatic segmentation and quantification of the sFAZ in optical coherence tomography angiography (OCTA) images with robustness to brightness and contrast (B/C) variations. A dataset of 405 OCTA images from 45 participants was acquired with Zeiss Cirrus HD-OCT 5000 and the ground truth (GT) was manually segmented subsequently. A deep learning network with an encoder-decoder architecture was created to classify each pixel into an sFAZ or non-sFAZ class. Subsequently, we applied largest-connected-region extraction and hole-filling to fine-tune the automatic segmentation results. A maximum mean dice similarity coefficient (DSC) of 0.976 +/- 0.011 was obtained when the automatic segmentation results were compared against the GT. The correlation coefficient between the area calculated from the automatic segmentation results and that calculated from the GT was 0.997. In all nine parameter groups with various brightness/contrast, all the DSCs of the proposed method were higher than 0.96. The proposed method achieved better performance in the sFAZ segmentation and quantification compared to two previously reported methods. In conclusion, we proposed and successfully verified an automatic sFAZ segmentation and quantification method based on deep learning with robustness to B/C variations. For clinical applications, this is an important progress in creating an automated segmentation and quantification applicable to clinical analysis.",optical coherence tomography angiography; deep learning; foveal avascular zone; automatic segmentation and quantification
Review,"Boned-Murillo, Ana; Albertos-Arranz, Henar; Diaz-Barreda, Maria Dolores; Orduna-Hospital, Elvira; Sanchez-Cano, Ana; Ferreras, Antonio; Cuenca, Nicolas; Pinilla, Isabel",Optical Coherence Tomography Angiography in Diabetic Patients: A Systematic Review,biomedicines,2022,Not found,"Background: Diabetic retinopathy (DR) is the leading cause of legal blindness in the working population in developed countries. Optical coherence tomography (OCT) angiography (OCTA) has risen as an essential tool in the diagnosis and control of diabetic patients, with and without DR, allowing visualisation of the retinal and choroidal microvasculature, their qualitative and quantitative changes, the progression of vascular disease, quantification of ischaemic areas, and the detection of preclinical changes. The aim of this article is to analyse the current applications of OCTA and provide an updated overview of them in the evaluation of DR. Methods: A systematic literature search was performed in PubMed and Embase, including the keywords OCTA OR OCT angiography OR optical coherence tomography angiography AND diabetes OR diabetes mellitus OR diabetic retinopathy OR diabetic maculopathy OR diabetic macular oedema OR diabetic macular ischaemia. Of the 1456 studies initially identified, 107 studies were screened after duplication, and those articles that did not meet the selection criteria were removed. Finally, after looking for missing data, we included 135 studies in this review. Results: We present the common and distinctive findings in the analysed papers after the literature search including the diagnostic use of OCTA in diabetes mellitus (DM) patients. We describe previous findings in retinal vascularization, including microaneurysms, foveal avascular zone (FAZ) changes in both size and morphology, changes in vascular perfusion, the appearance of retinal microvascular abnormalities or new vessels, and diabetic macular oedema (DME) and the use of deep learning technology applied to this disease. Conclusion: OCTA findings enable the diagnosis and follow-up of DM patients, including those with no detectable lesions with other devices. The evaluation of retinal and choroidal plexuses using OCTA is a fundamental tool for the diagnosis and prognosis of DR.",diabetes mellitus; diabetic retinopathy; foveal avascular zone; faz; optical coherence tomography angiography; octa; diabetic macular oedema
Article,"Son, Jaemin; Shin, Joo Young; Kim, Hoon Dong; Jung, Kyu-Hwan; Park, Kyu Hyung; Park, Sang Jun",Development and Validation of Deep Learning Models for Screening Multiple Abnormal Findings in Retinal Fundus Images,ophthalmology,2020,Not found,"Purpose: To develop and evaluate deep learning models that screen multiple abnormal findings in retinal fundus images. Design: Cross-sectional study. Participants: For the development and testing of deep learning models, 309 786 readings from 103 262 images were used. Two additional external datasets (the Indian Diabetic Retinopathy Image Dataset and e-ophtha) were used for testing. A third external dataset (Messidor) was used for comparison of the models with human experts. Methods: Macula-centered retinal fundus images from the Seoul National University Bundang Hospital Retina Image Archive, obtained at the health screening center and ophthalmology outpatient clinic at Seoul National University Bundang Hospital, were assessed for 12 major findings (hemorrhage, hard exudate, cottonwool patch, drusen, membrane, macular hole, myelinated nerve fiber, chorioretinal atrophy or scar, any vascular abnormality, retinal nerve fiber layer defect, glaucomatous disc change, and nonglaucomatous disc change) with their regional information using deep learning algorithms. Main Outcome Measures: Area under the receiver operating characteristic curve and sensitivity and specificity of the deep learning algorithms at the highest harmonic mean were evaluated and compared with the performance of retina specialists, and visualization of the lesions was qualitatively analyzed. Results: Areas under the receiver operating characteristic curves for all findings were high at 96.2% to 99.9% when tested in the in-house dataset. Lesion heatmaps highlight salient regions effectively in various findings. Areas under the receiver operating characteristic curves for diabetic retinopathy-related findings tested in the Indian Diabetic Retinopathy Image Dataset and e-ophtha dataset were 94.7% to 98.0%. The model demonstrated a performance that rivaled that of human experts, especially in the detection of hemorrhage, hard exudate, membrane, macular hole, myelinated nerve fiber, and glaucomatous disc change. Conclusions: Our deep learning algorithms with region guidance showed reliable performance for detection of multiple findings in macula-centered retinal fundus images. These interpretable, as well as reliable, classification outputs open the possibility for clinical use as an automated screening system for retinal fundus images. (C) 2019 by the American Academy of Ophthalmology.",diabetic-retinopathy; interobserver agreement; diagnosis; glaucoma; segmentation
Article,"Babenko, Boris; Mitani, Akinori; Traynis, Ilana; Kitade, Naho; Singh, Preeti; Maa, April Y.; Cuadros, Jorge; Corrado, Greg S.; Peng, Lily; Webster, Dale R.; Varadarajan, Avinash; Hammel, Naama; Liu, Yun",Detection of signs of disease in external photographs of the eyes via deep learning,nature biomedical engineering,2022,Not found,"Retinal fundus photographs can be used to detect a range of retinal conditions. Here we show that deep-learning models trained instead on external photographs of the eyes can be used to detect diabetic retinopathy (DR), diabetic macular oedema and poor blood glucose control. We developed the models using eye photographs from 145,832 patients with diabetes from 301 DR screening sites and evaluated the models on four tasks and four validation datasets with a total of 48,644 patients from 198 additional screening sites. For all four tasks, the predictive performance of the deep-learning models was significantly higher than the performance of logistic regression models using self-reported demographic and medical history data, and the predictions generalized to patients with dilated pupils, to patients from a different DR screening programme and to a general eye care programme that included diabetics and non-diabetics. We also explored the use of the deep-learning models for the detection of elevated lipid levels. The utility of external eye photographs for the diagnosis and management of diseases should be further validated with images from different cameras and patient populations. Deep-learning models trained on external eye photographs can detect diabetic retinopathy, diabetic macular oedema and poor blood glucose control more accurately than models relying on demographic and medical history data.",white corneal diameter; diabetic-retinopathy; fundus photography; risk-factors; care; conjunctival; validation; calcification; morphometry; prediction
Article,"Zhang, Guanghua; Li, Keran; Chen, Zhixian; Sun, Li; Zhang, Jianwei; Pan, Xueping",Augmentation-Consistent Clustering Network for Diabetic Retinopathy Grading with Fewer Annotations,journal of healthcare engineering,2022,Not found,"Diabetic retinopathy (DR) is currently one of the severe complications leading to blindness, and computer-aided, diagnosis technology-assisted DR grading has become a popular research trend especially for the development of deep learning methods. However, most deep learning-based DR grading models require a large number of annotations to provide data guidance, and it is laborious for experts to find subtle lesion areas from fundus images, making accurate annotation more expensive than other vision tasks. In contrast, large-scale unlabeled data are easily accessible, becoming a potential solution to reduce the annotating workload in DR grading. Thus, this paper explores the internal correlations from unknown fundus images assisted by limited labeled fundus images to solve the semisupervised DR grading problem and proposes an augmentation-consistent clustering network (ACCN) to address the above-mentioned challenges. Specifically, the augmentation provides an efficient cue for the similarity information of unlabeled fundus images, assisting the supervision from the labeled data. By mining the consistent correlations from augmentation and raw images, the ACCN can discover subtle lesion features by clustering with fewer annotations. Experiments on Messidor and APTOS 2019 datasets show that the ACCN surpasses many state-of-the-art methods in a semisupervised manner.",not found
Proceedings Paper,"Nagpal, Dimple; Panda, Surya Narayan; Malarvel, Muthukumaran",Hypertensive Retinopathy Screening through Fundus Images-A Review,proceedings of the 6th international conference on inventive computation technologies (icict 2021),2021,Not found,"Automatic segmentation of fundus images is an important task in computer-aided diagnosis (CAD) for analysis of medical images to diagnose diseases such as Hypertensive retinopathy, diabetic Retinopathy (HR). HR occurs due to hypertension for a prolonged period of time. It may lead to vision loss, if not treated at early stages. It can be observed by the changes in retinal vasculature that are caused by arterial hypertension. There are various features observed in fundus images such as arterial narrowing, bifurcation, tortuosity, etc. Computer-aided diagnosis plays a vital role in screening and grading of retinal images. There is still a need for automatic detection and grading of HR This article presents the state-of-the-art methodologies used by researchers for predicting hypertensive retinopathy. Features that are present in retinal images have also been discussed for early detection of HR. The probable extraction techniques have been explored and evaluated based on layers used by different models. The classification technique discussed by different researchers has also been explored followed by the conclusion. This review will be beneficial for the researchers who want to focus on medical image analysis and enhancing the diagnosis of the system through CAD.",hypertensive retinopathy; fundus imaging; deep learning; survey; biomedical imaging; medical image analysis
Article,"Pappu, Geetha Pavani; Krishna, Talabhakthula; Biswal, Birendra; Karn, Prakash Kumar; Biswal, Pradyut Kumar; Hasan, Shazia; Nayak, Debasish",A deeply supervised maximum response texton based SegNet for simultaneous multi retinal lesion segmentation,international journal of imaging systems and technology,2022,Not found,"Diabetic Retinopathy (DR) is a diabetic mellitus complication that causes vision impairment and may lead to permanent blindness. The early signs of DR that appear on the retinal surface are microaneurysms, hemorrhages, hard exudates, and soft exudates. Hence the automatic detection of these retinal lesions assists in the early diagnosis of DR. This paper presents a novel deep learning model, MRT-SegNet (Maximum Response Texton - Segmentation Network) for the automatic segmentation of different retinal lesions simultaneously along with the optic disc. In the proposed MRT-SegNet, each encoder block consists of an MRT filter bank that extracts the textural feature maps of the retinal images and then fuses them with the local feature maps that are extracted from the traditional encoder block of the network. This fusion enables the network to segment the minute lesions from the retinal surface. The proposed model is evaluated on the IDRiD dataset and achieves a mean Area Under the Precision & Recall Curve (mAUC_PR) of 0.698 and AUC_PR scores of 0.495, 0.706, 0.823, 0.769 for microaneurysms, hemorrhages, hard exudates, and soft exudates respectively. The experimental results demonstrate that the MRT-SegNet outperformed other multi retinal lesion segmentation models by achieving superior performance.",diabetic retinopathy; idrid dataset; maximum response texton filter bank; multi retinal lesion segmentation
Article,"Liao, Yinhan; Xia, Haiying; Song, Shuxiang; Li, Haisheng",Microaneurysm detection in fundus images based on a novel end-to-end convolutional neural network,biocybernetics and biomedical engineering,2021,Not found,"Microaneurysms are the earliest symptom of diabetic retinopathy and play an important role in the screening of diabetic retinopathy. However, because of the complex background, automatic detection microaneurysm in fundus images is a challenging task. Firstly, moti-vated by the characteristics of microaneurysm, a novel deep convolutional encoder-decoder network for microaneurysm detection is designed to locate the MAs by the differ-ences between the skip connection in the network. Then, a weighted dice loss, termed the smooth dice loss, is presented to put more focus on misclassified microaneurysms. Finally, an activation function with a long tail is used to produce an accurate probability map for MA detection. Plenty of experiments, conducted on the Retinopathy Online Challenge data-set and the e-ophtha-MA dataset, demonstrate that the proposed model achieves the com-parable performance to the existing state-of-the-art methods on microaneurysm detection with only one-hundredth the running time compared with its counterparts. The proposed method is simple and effective, guarantees the performance while shortening the test time. It indicates the potential application in the auxiliary diagnosis of diabetic retinopathy screening. (c) 2021 Nalecz Institute of Biocybernetics and Biomedical Engineering of the Polish Academy of Sciences. Published by Elsevier B.V. All rights reserved.",deep learning; computer-aided diagnosis; diabetic retinopathy screening; microaneurysm detection; encoder-decoder
Proceedings Paper,"Paul, Dipam; Tewari, Alankrita; Ghosh, Sourodip; Santosh, K. C.",OCTx: Ensembled Deep Learning Model to Detect Retinal Disorders,2020 ieee 33rd international symposium on computer-based medical systems(cbms 2020),2020,Not found,"In this paper, we deconstruct and demonstrate a detection framework to classify Retinal Optical Coherence Tomography (OCT) images across three classes namely, Diabetic Macular Edema (DME), Choroidal Neovascularization (CNV), and the DRUSEN from normal Retina. In this research, we developed on a Deep Ensemble Network by the virtue of which we were able to obtain a state-of-the-art accuracy of 98.53% on our test image dataset that was deliberately increased to 12% of the total images. Further, we also took advantage and insight from a feature map obtained from our convolutional layers to build our final model, which we call Optical Coherence Tomography Extended (OCTx). In our experiments, we found that OCTx was more accurate and diverse as compared to previously reported works that were validated on the exact same dataset.",retinal oct images; deep neural networks; ensemble learning; octx
Article,"Maji, Debasis; Maiti, Souvik; Dhara, Ashis Kumar; Sarkar, Gautam",Automatic grading of retinal blood vessel tortuosity using Modified CNN in deep retinal image diagnosis,biomedical signal processing and control,2022,Not found,"Background: The World Health Organization states that the number of patients suffering from diabetes has shot up by nearly four times from 108 millions in 1980 to 422 millions in 2014. Diabetic Retinopathy (DR) is the longterm effect of diabetes, which if not clinically treated effectively on time might lead to irreversible loss of vision. By examining the retinal fundus images the disease might be diagnosed well by examining the retinal fundus images. However, the fact that these images contain noise and variation due to certain environmental conditions such as light makes it difficult even for experts in the field to access the right grade of the disease. In this paper, we aim to present a robust Convolution Neural Network (CNN) architecture, which can grade the disease irrespective of noise and variation. We have used the publicly available dataset on Kaggle to train our model and we have validated on another publicly available data set, EIARG2. We also provide a comparative study of our model against standard architectures like ResNet50, VGG16 and several others of the domain and thus conclude by virtue of promising results that our architecture is superior for grading diabetic retinopathy than the present-day standard architectures. A CNN network has been proposed which can grade retinal images using the state-of-theart machine learning algorithms. The method found 0.96 Performance (SCC) accurate for grading the tortuositybased eye health.",diabetic retinopathy (dr); convolutional neural network (cnn); fundus image; retinal blood vessel
Article,"Allyn, Jerome; Allou, Nicolas; Vidal, Charles; Renou, Amelie; Ferdynus, Cyril",Adversarial attack on deep learning-based dermatoscopic image recognition systems Risk of misdiagnosis due to undetectable image perturbations,medicine,2020,Not found,"Deep learning algorithms have shown excellent performances in the field of medical image recognition, and practical applications have been made in several medical domains. Little is known about the feasibility and impact of an undetectable adversarial attacks, which can disrupt an algorithm by modifying a single pixel of the image to be interpreted. The aim of the study was to test the feasibility and impact of an adversarial attack on the accuracy of a deep learning-based dermatoscopic image recognition system. First, the pre-trained convolutional neural network DenseNet-201 was trained to classify images from the training set into 7 categories. Second, an adversarial neural network was trained to generate undetectable perturbations on images from the test set, to classifying all perturbed images as melanocytic nevi. The perturbed images were classified using the model generated in the first step. This study used the HAM-10000 dataset, an open source image database containing 10,015 dermatoscopic images, which was split into a training set and a test set. The accuracy of the generated classification model was evaluated using images from the test set. The accuracy of the model with and without perturbed images was compared. The ability of 2 observers to detect image perturbations was evaluated, and the inter observer agreement was calculated. The overall accuracy of the classification model dropped from 84% (confidence interval (CI) 95%: 82-86) for unperturbed images to 67% (CI 95%: 65-69) for perturbed images (Mc Nemar test, P < .0001). The fooling ratio reached 100% for all categories of skin lesions. Sensitivity and specificity of the combined observers calculated on a random sample of 50 images were 58.3% (CI 95%: 45.9-70.8) and 42.5% (CI 95%: 27.2-57.8), respectively. The kappa agreement coefficient between the 2 observers was negative at -0.22 (CI 95%: -0.49--0.04). Adversarial attacks on medical image databases can distort interpretation by image recognition algorithms, are easy to make and undetectable by humans. It seems essential to improve our understanding of deep learning-based image recognition systems and to upgrade their security before putting them to practical and daily use.",adversarial attack; artificial intelligence; deep learning; dermatoscopic lesions; image recognition systems
Article,"Lin, Haotian; Li, Ruiyang; Liu, Zhenzhen; Chen, Jingjing; Yang, Yahan; Chen, Hui; Lin, Zhuoling; Lai, Weiyi; Long, Erping; Wu, Xiaohang; Lin, Duoru; Zhu, Yi; Chen, Chuan; Wu, Dongxuan; Yu, Tongyong; Cao, Qianzhong; Li, Xiaoyan; Li, Jing; Li, Wangting; Wang, Jinghui; Yang, Mingmin; Hu, Huiling; Zhang, Li; Yu, Yang; Chen, Xuelan; Hu, Jianmin; Zhu, Ke; Jiang, Shuhong; Huang, Yalin; Tan, Gang; Huang, Jialing; Lin, Xiaoming; Zhang, Xinyu; Luo, Lixia; Liu, Yuhua; Liu, Xialin; Cheng, Bing; Zheng, Danying; Wu, Mingxing; Chen, Weirong; Liu, Yizhi",Diagnostic Efficacy and Therapeutic Decision-making Capacity of an Artificial Intelligence Platform for Childhood Cataracts in Eye Clinics: A Multicentre Randomized Controlled Trial,eclinicalmedicine,2019,Not found,"Background: CC-Cruiser is an artificial intelligence (AI) platform developed for diagnosing childhood cataracts and providing risk stratification and treatment recommendations. The high accuracy of CC-Cruiser was previously validated using specific datasets. The objective of this study was to compare the diagnostic efficacy and treatment decision-making capacity between CC-Cruiser and ophthalmologists in real-world clinical settings. Methods: This multicentre randomized controlled trial was performed in five ophthalmic clinics in different areas across China. Pediatric patients (aged <= 14 years) without a definitive diagnosis of cataracts or history of previous eye surgery were randomized (1:1) to receive a diagnosis and treatment recommendation from either CC-Cruiser or senior consultants (with over 5 years of clinical experience in pediatric ophthalmology). The experts who provided a gold standard diagnosis, and the investigators who performed slit-lamp photography and data analysis were blinded to the group assignments. The primary outcome was the diagnostic performance for childhood cataracts with reference to cataract experts' standards. The secondary outcomes included the evaluation of disease severity and treatment determination, the time required for the diagnosis, and patient satisfaction, which was determined by the mean rating. This trial is registered with ClinicalTrials.gov (NCT03240848). Findings: Between August 9, 2017 and May 25, 2018, 350 participants (700 eyes) were randomly assigned for diagnosis by CC-Cruiser (350 eyes) or senior consultants (350 eyes). The accuracies of cataract diagnosis and treatment determination were 87.4% and 70.8%, respectively, for CC-Cruiser, which were significantly lower than 99.1% and 96.7%, respectively, for senior consultants (p < 0.001, OR = 0.06 [95% CI 0.02 to 0.19]; and p < 0.001, OR = 0.08 [95% CI 0.03 to 0.25], respectively). The mean time for receiving a diagnosis from CC-Cruiser was 2.79 min, which was significantly less than 8.53 min for senior consultants (p < 0.001, mean difference 5.74 [95% CI 5.43 to 6.05]). The patients were satisfied with the overall medical service quality provided by CC-Cruiser, typically with its time-saving feature in cataract diagnosis. Interpretation: CC-Cruiser exhibited less accurate performance comparing to senior consultants in diagnosing childhood cataracts and making treatment decisions. However, the medical service provided by CC-Cruiser was less time-consuming and achieved a high level of patient satisfaction. CC-Cruiser has the capacity to assist human doctors in clinical practice in its current state. (C) 2019 Published by Elsevier Ltd.",artificial intelligence; childhood cataracts; multicentre randomized controlled trial; ophthalmology
Review,"Devalla, Sripad Krishna; Liang, Zhang; Tan Hung Pham; Boote, Craig; Strouthidis, Nicholas G.; Thiery, Alexandre H.; Girard, Michael J. A.",Glaucoma management in the era of artificial intelligence,british journal of ophthalmology,2020,Not found,"Glaucoma is a result of irreversible damage to the retinal ganglion cells. While an early intervention could minimise the risk of vision loss in glaucoma, its asymptomatic nature makes it difficult to diagnose until a late stage. The diagnosis of glaucoma is a complicated and expensive effort that is heavily dependent on the experience and expertise of a clinician. The application of artificial intelligence (AI) algorithms in ophthalmology has improved our understanding of many retinal, macular, choroidal and corneal pathologies. With the advent of deep learning, a number of tools for the classification, segmentation and enhancement of ocular images have been developed. Over the years, several AI techniques have been proposed to help detect glaucoma by analysis of functional and/or structural evaluations of the eye. Moreover, the use of AI has also been explored to improve the reliability of ascribing disease prognosis. This review summarises the role of AI in the diagnosis and prognosis of glaucoma, discusses the advantages and challenges of using AI systems in clinics and predicts likely areas of future progress.",optical coherence tomography; machine learning classifiers; scanning laser ophthalmoscopy; relevance vector machine; open-angle glaucoma; visual-field progression; retinal blood-vessels; neural-network; automated segmentation; diabetic-retinopathy
Article,"Suguna, G.; Lavanya, R.",Performance Assessment of EyeNet Model in Glaucoma Diagnosis,pattern recognition and image analysis,2021,Not found,"Deep learning (DL) has recently gained increasing attention in biomedical data analytics, demonstrating robust performance and promising results. A deep network requires massive amount of data to learn meaningful patterns useful in solving complex problems. Data scarcity in medical field is a bottleneck for applying deep learning in this area. This has led to the popularity of pre-trained models, trained on huge source data to achieve reasonable accuracy in medical diagnosis even with less data in target domain. A wise choice of models trained with data similar to target data would ensure that relevant features are captured. In this work, the significance of choosing appropriate pre-trained models is demonstrated. The EyeNet model, originally trained for diagnosis of diabetic retinopathy (DR) using fundus image dataset, is used as a pre-trained model for building a convolutional neural network (CNN) - based DL architecture for glaucoma diagnosis using images from the same modality. The results are compared with glaucoma diagnosis using different pre-trained models that are less relevant to the problem considered. Different experiments including fine-tuning and transfer learning were performed. Results were validated using the benchmark Rim-one dataset. The EyeNet model outperformed all other models, achieving a maximum accuracy of 89% with transfer learning using support vector machines (SVM) combined with principal component analysis (PCA) for dimensionality reduction.",convolutional neural network; pre-trained models; deep-learning; glaucoma; transfer leaning
Proceedings Paper,"Singh, Amitojdeep; Sengupta, Sourya; Rasheeda, Mohammed Abdul; Jayakumara, Varadharajan; Lakshminarayanana, Vasudevan",Uncertainty aware and explainable diagnosis of retinal disease,"medical imaging 2021: imaging informatics for healthcare, research, and applications",2021,Not found,"Deep learning methods for ophthalmic diagnosis have shown considerable success in tasks like segmentation and classification. However, their widespread application is limited due to the models being opaque and vulnerable to making a wrong decision in complicated cases. Explainability methods show the features that a system used to make prediction while uncertainty awareness is the ability of a system to highlight when it is not sure about the decision. This is one of the first studies using uncertainty and explanations for informed clinical decision making. We perform uncertainty analysis of a deep learning model for diagnosis of four retinal diseases - age-related macular degeneration (AMD), central serous retinopathy (CSR), diabetic retinopathy (DR), and macular hole (MH) using images from a publicly available (OCTID) dataset. Monte Carlo (MC) dropout is used at the test time to generate a distribution of parameters and the predictions approximate the predictive posterior of a Bayesian model. A threshold is computed using the distribution and uncertain cases can be referred to the ophthalmologist thus avoiding an erroneous diagnosis. The features learned by the model are visualized using a proven attribution method from a previous study. The effects of uncertainty on model performance and the relationship between uncertainty and explainability are discussed in terms of clinical significance. The uncertainty information along with the heatmaps make the system more trustworthy for use in clinical settings.",uncertainty; explainability; deep learning; retinal imaging; bayesian; attributions; retina; retinal disease
Article,"Atteia, Ghada; Samee, Nagwan Abdel; El-Kenawy, El-Sayed M.; Ibrahim, Abdelhameed",CNN-Hyperparameter Optimization for Diabetic Maculopathy Diagnosis in Optical Coherence Tomography and Fundus Retinography,mathematics,2022,Not found,"Diabetic Maculopathy (DM) is considered the most common cause of permanent visual impairment in diabetic patients. The absence of clear pathological symptoms of DM hinders the timely diagnosis and treatment of such a critical condition. Early diagnosis of DM is feasible through eye screening technologies. However, manual inspection of retinography images by eye specialists is a time-consuming routine. Therefore, many deep learning-based computer-aided diagnosis systems have been recently developed for the automatic prognosis of DM in retinal images. Manual tuning of deep learning network's hyperparameters is a common practice in the literature. However, hyperparameter optimization has shown to be promising in improving the performance of deep learning networks in classifying several diseases. This study investigates the impact of using the Bayesian optimization (BO) algorithm on the classification performance of deep learning networks in detecting DM in retinal images. In this research, we propose two new custom Convolutional Neural Network (CNN) models to detect DM in two distinct types of retinal photography; Optical Coherence Tomography (OCT) and fundus retinography datasets. The Bayesian optimization approach is utilized to determine the optimal architectures of the proposed CNNs and optimize their hyperparameters. The findings of this study reveal the effectiveness of using the Bayesian optimization for fine-tuning the model hyperparameters in improving the performance of the proposed CNNs for the classification of diabetic maculopathy in fundus and OCT images. The pre-trained CNN models of AlexNet, VGG16Net, VGG 19Net, GoogleNet, and ResNet-50 are employed to be compared with the proposed CNN-based models. Statistical analyses, based on a one-way analysis of variance (ANOVA) test, receiver operating characteristic (ROC) curve, and histogram, are performed to confirm the performance of the proposed models.",diabetic maculopathy; convolutional neural network; bayesian optimization; hyperparameters; optical coherence tomography; fundus images
Proceedings Paper,"Zabihollahy, F.; Lochbihler, A.; Ukwatta, E.",Deep Learning Based Approach for Fully Automated Detection and Segmentation of Hard Exudate from Retinal Images,"medical imaging 2019: biomedical applications in molecular, structural, and functional imaging",2019,Not found,"Diabetic retinopathy (DR), which is a major cause of blindness in the world is characterized by hard exudate lesions in the eyes as these lesions are one of the most prevalent and earliest symptoms of DR. In this paper, a fully automated method for hard exudate delineation is described that could assist ophthalmologists for timely diagnosis of DR before disease progress to a level beyond treatment. We used a dataset consist of 107 images to develop a U-Net-based method for hard exudate detection and segmentation. This network consists of shrinking and expansive streams in which shrinking path has the same structure as conventional convolutional networks. In expansive path, obtained features are merged with those from shrinking path with the proper resolution to generate multi-scale features and accomplish distinction between hard exudate and normal tissue in retinal images. The training images were augmented artificially to increase the number of samples in the dataset and avoid overfitting issues. Experimental results showed that our proposed method reported sensitivity, specificity, accuracy, and Dice similarity coefficient of 96.15%, 80.77%, 88.46%, and 67.23 +/- 13.60% on 52 test images, respectively.",diabetic retinopathy; hard exudate; u-net convolutional neural network (cnn)-based
Article; Early Access,"Li, He-Yan; Dong, Li; Zhou, Wen-Da; Wu, Hao-Tian; Zhang, Rui-Heng; Li, Yi-Tong; Yu, Chu-Yao; Wei, Wen-Bin",Development and validation of medical record-based logistic regression and machine learning models to diagnose diabetic retinopathy,graefes archive for clinical and experimental ophthalmology,0,Not found,"Purposes Many factors were reported to be associated with diabetic retinopathy (DR); however, their contributions remained unclear. We aimed to evaluate the prognostic and diagnostic accuracy of logistic regression and three machine learning models based on various medical records. Methods This was a cross-sectional study. We investigated the prevalence and associations of DR among 757 participants aged 40 years or older in the 2005-2006 National Health and Nutrition Examination Survey (NHANES). We trained the models to predict if the participants had DR with 15 predictor variables. Area under the receiver operating characteristic (AUROC) and mean squared error (MSE) of each algorithm were compared in the external validation dataset using a replicate cohort from NHANES 2007-2008. Results Among the 757 participants, 53 (7.00%) subjects had DR, the mean (standard deviation, SD) age was 57.7 (13.04), and 78.0% were male (n = 42). Logistic regression revealed that female gender (OR = 4.130, 95% CI: 1.820-9.380; P < 0.05), HbA1c (OR = 1.665, 95% CI: 1.197-2.317; P < 0.05), serum creatine level (OR = 2.952, 95% CI: 1.274-6.851; P < 0.05), and eGFR level (OR = 1.009, 95% CI: 1.000-1.014, P < 0.05) increased the risk of DR. The average performance obtained from internal validation was similar in all models (AUROC >= 0.945), and k-nearest neighbors (KNN) had the highest value with an AUROC of 0.984. In external validation, they remained robust or with modest reductions in discrimination with AUROC still >= 0.902, and KNN also performed the best with an AUROC of 0.982. Both logistic regression and machine learning models had good performance in the clinical diagnosis of DR. Conclusions This study highlights the utility of comparing traditional logistic regression to machine learning models. We found that logistic regression performed as well as optimized machine learning methods when classifying DR patients.",diabetic retinopathy; machine learning; logistic regression; model selection; national health and nutrition examination survey (nhanes)
Article,"Shaban, Mohamed; Ogur, Zeliha; Mahmoud, Ali; Switala, Andrew; Shalaby, Ahmed; Abu Khalifeh, Hadil; Ghazal, Mohammed; Fraiwan, Luay; Giridharan, Guruprasad; Sandhu, Harpal; El-Baz, Ayman S.",A convolutional neural network for the screening and staging of diabetic retinopathy,plos one,2020,Not found,"Diabetic retinopathy (DR) is a serious retinal disease and is considered as a leading cause of blindness in the world. Ophthalmologists use optical coherence tomography (OCT) and fundus photography for the purpose of assessing the retinal thickness, and structure, in addition to detecting edema, hemorrhage, and scars. Deep learning models are mainly used to analyze OCT or fundus images, extract unique features for each stage of DR and therefore classify images and stage the disease. Throughout this paper, a deep Convolutional Neural Network (CNN) with 18 convolutional layers and 3 fully connected layers is proposed to analyze fundus images and automatically distinguish between controls (i.e. no DR), moderate DR (i.e. a combination of mild and moderate Non Proliferative DR (NPDR)) and severe DR (i.e. a group of severe NPDR, and Proliferative DR (PDR)) with a validation accuracy of 88%-89%, a sensitivity of 87%-89%, a specificity of 94%-95%, and a Quadratic Weighted Kappa Score of 0.91-0.92 when both 5-fold, and 10-fold cross validation methods were used respectively. A prior pre-processing stage was deployed where image resizing and a class-specific data augmentation were used. The proposed approach is considerably accurate in objectively diagnosing and grading diabetic retinopathy, which obviates the need for a retina specialist and expands access to retinal care. This technology enables both early diagnosis and objective tracking of disease progression which may help optimize medical therapy to minimize vision loss.",diagnosis
Proceedings Paper,"Qian, Peisheng; Zhao, Ziyuan; Chen, Cong; Zeng, Zeng; Li, Xiaoli",Two Eyes Are Better Than One: Exploiting Binocular Correlation for Diabetic Retinopathy Severity Grading,2021 43rd annual international conference of the ieee engineering in medicine & biology society (embc),2021,Not found,"Diabetic retinopathy (DR) is one of the most common eye conditions among diabetic patients. However, vision loss occurs primarily in the late stages of DR, and the symptoms of visual impairment, ranging from mild to severe, can vary greatly, adding to the burden of diagnosis and treatment in clinical practice. Deep learning methods based on retinal images have achieved remarkable success in automatic DR grading, but most of them neglect that the presence of diabetes usually affects both eyes, and ophthalmologists usually compare both eyes concurrently for DR diagnosis, leaving correlations between left and right eyes unexploited. In this study, simulating the diagnostic process, we propose a two-stream binocular network to capture the subtle correlations between left and right eyes, in which, paired images of eyes are fed into two identical subnetworks separately during training. We design a contrastive grading loss to learn binocular correlation for five-class DR detection, which maximizes inter-class dissimilarity while minimizing the intra-class difference. Experimental results on the EyePACS dataset show the superiority of the proposed binocular model, outperforming monocular methods by a large margin.",not found
Article,"Bhardwaj, Pranjal; Gupta, Prajjwal; Guhan, Thejineaswar; Srinivasan, Kathiravan",Early Diagnosis of Retinal Blood Vessel Damage via Deep Learning-Powered Collective Intelligence Models,computational and mathematical methods in medicine,2022,Not found,"Early diagnosis of retinal diseases such as diabetic retinopathy has had the attention of many researchers. Deep learning through the introduction of convolutional neural networks has become a prominent solution for image-related tasks such as classification and segmentation. Most tasks in image classification are handled by deep CNNs pretrained and evaluated on imagenet dataset. However, these models do not always translate to the best result on other datasets. Devising a neural network manually from scratch based on heuristics may not lead to an optimal model as there are numerous hyperparameters in play. In this paper, we use two nature-inspired swarm algorithms: particle swarm optimization (PSO) and ant colony optimization (ACO) to obtain TDCN models to perform classification of fundus images into severity classes. The power of swarm algorithms is used to search for various combinations of convolutional, pooling, and normalization layers to provide the best model for the task. It is observed that TDCN-PSO outperforms imagenet models and existing literature, while TDCN-ACO achieves faster architecture search. The best TDCN model achieves an accuracy of 90.3%, AUC ROC of 0.956, and a Cohen's kappa score of 0.967. The results were compared with the previous studies to show that the proposed TDCN models exhibit superior performance.",hyperparameter optimization; identification; selection
Article,"Dou, Peng; Zhang, Yang; Zheng, Rui; Ye, Yu; Mao, Jianbo; Liu, Lei; Wu, Ming; Sun, Mingzhai",RETINAL IMAGING AND ANALYSIS USING MACHINE LEARNING WITH INFORMATION FUSION OF THE FUNCTIONAL AND STRUCTURAL FEATURES BASED ON A DUAL-MODAL FUNDUS CAMERA,journal of mechanics in medicine and biology,2021,Not found,"Retinal diseases and systemic diseases, such as diabetic retinopathy (DR) and Alzheimer's disease, may manifest themselves in the retina, changing the retinal oxygen saturation (SO2) level or the retinal vascular structures. Recent studies explored the correlation of diseases with either retina vascular structures or SO2 level, but not both due to the lack of proper instrument or methodology. In this study, we applied a dual-modal fundus camera and developed a deep learning-based analysis method to simultaneously acquire and quantify the SO2 and vascular structures. Deep learning was used to automatically locate the optic discs and segment arterioles and venules of the blood vessels. We then sought to apply machine learning methods, such as random forest (RF) and support vector machine (SVM), to fuse the SO2 level and retinal vessel parameters as different features to discriminate against the disease from the healthy controls. We showed that the fusion of the functional (oxygen saturation) and structural (vascular parameters) features offers better performance to classify diseased and healthy subjects. For example, we gained a 13.8% and 2.0% increase in the accuracy with fusion using the RF and SVM to classify the nonproliferative DR and the healthy controls.",retinal oxygen saturation; retinal vessel parameters; dual-modal fundus camera; computer-aided diagnosis system; information fusion; deep learning
Article,"Gerendas, B. S.; Waldstein, S. M.; Schmidt-Erfurth, U.",Screening and management of retinal diseases using digital medicine,ophthalmologe,2018,Not found,"BackgroundModern retinal imaging creates gigantic amounts of data (big data) of anatomic information. At the same time patient numbers and interventions are increasing exponentially.ObjectiveIntroduction of artificial intelligence (AI) for optimization of personalized therapy and diagnosis.Material and methodsDeep learning was introduced for automated segmentation and recognition of risk factors and activity levels in retinal diseases.ResultsAutomated algorithms enable the precise identification and quantification of retinal fluid in all compartments.Earlydetection of retinopathy in diabetes or glaucoma or risk determination for the development of age-related macular degeneration (AMD) are possible as well as an individual visual prognosis and evaluation of the need for retreatment in intravitreal injection therapy.ConclusionMethods using AIconstitute abreakthrough perspective for the introduction of individualized medicine and optimization of diagnosis and therapy, screening and prognosis.",artificial intelligence; deep learning; retinal imaging; automated algorithms; personalized medicine
Article,"Lee, Jinho; Kim, Youngwoo; Kim, Jong Hyo; Park, Ki Ho",Screening Glaucoma With Red-free Fundus Photography Using Deep Learning Classifier and Polar Transformation,journal of glaucoma,2019,Not found,"Precis: The novel proposed algorithm using deep learning classifier and polar transformation technique can be an economical as well as an effective tool for early detection of glaucomatous RNFL defect. Purpose: The main purpose of this study was to develop novel software to determine whether there is a retinal nerve fiber layer (RNFL) defect in a given fundus image using deep learning classifier and, if there is, where it presents. Materials and Methods: In the deep learning classifier, the bottleneck features were extracted, followed by application of the softmax classifier, which outputted the glaucoma probability. For localization of RNFL defect, an image processing algorithm was implemented as follows: (1) the given image was normalized to enhance the contrast; (2) the region of interest (ROI) was set as the circumferential area surrounding the optic disc (internal diameter: 2 disc diameters, external diameter: 3 disc diameter), and converted to a polar image; (3) blood vessels were removed and the average curvatures were calculated. If the local maximum curvature was greater than the cut-off value, the sector was considered to be an RNFL defect. The images of 100 normal healthy controls and 100 open-angle glaucoma patients were enrolled. Maximum curvatures and area under receiver operating characteristic curve were compared to determine the diagnostic validity. Results: There were no significant differences in age or sex (P=0.275, P=0.479, respectively) between the 2 groups. In the glaucoma group, the mean deviation was -4.9 +/- 5.4 dB. There was a significant difference of maximum curvature (14.37 +/- 5.13 in control group, 20.67 +/- 10.56 in glaucoma group, P< 0.001). Area under receiver operating characteristic curve was 0.939 in deep learning classifier and 0.711 in maximum curvature. Conclusions: The proposed software can be an effective tool for automated detection of RNFL defect.",glaucoma; computer-aided diagnosis; deep learning
Article,"Burlina, Philippe; Paul, William; Liu, T. Y. Alvin; Bressler, Neil M.","Detecting Anomalies in Retinal Diseases Using Generative, Discriminative, and Self-supervised Deep Learning",jama ophthalmology,2022,Not found,"IMPORTANCE Anomaly detectors could be pursued for retinal diagnoses based on artificial intelligence systems that may not have access to training examples for all retinal diseases in all phenotypic presentations. Possible applications could include screening of population for any retinal disease rather than a specific disease such as diabetic retinopathy, detection of novel retinal diseases or novel presentations of common retinal diseases, and detection of rare diseases with little or no data available for training. OBJECTIVE To study the application of anomaly detection to retinal diseases. DESIGN, SETTING, AND PARTICIPANTS High-resolution retinal images from the publicly available EyePACS data set with fundus images with a corresponding label ranging from 0 to 4 for representing different severities of diabetic retinopathy. Sixteen variants of anomaly detectors were designed. For evaluation, a surrogate problem was constructed, using diabetic retinopathy images, in which only retinas with nonreferable diabetic retinopathy, ie, no diabetic macular edema, and no diabetic retinopathy or mild to moderate nonproliferative diabetic retinopathy were used for training an artificial intelligence system, but both nonreferable and referable diabetic retinopathy (including diabetic macular edema or proliferative diabetic retinopathy) were used to test the system for detecting retinal disease. MAIN OUTCOMES AND MEASURES Anomaly detectors were evaluated by commonly accepted performance metrics, including area under the receiver operating characteristic curve, F1 score, and accuracy. RESULTS A total of 88 692 high-resolution retinal images of 44 346 individuals with varying severity of diabetic retinopathy were analyzed. The best performing across all anomaly detectors had an area under the receiver operating characteristic of 0.808 (95% CI, 0.789-0.827) and was obtained using an embedding method that involved a self-supervised network. CONCLUSIONS AND RELEVANCE This study suggests when abnormal (diseased) data, ie, referable diabetic retinopathy in this study, were not available for training of retinal diagnostic systems wherein only nonreferable diabetic retinopathy was used for training, anomaly detection techniques were useful in identifying images with and without referable diabetic retinopathy. This suggests that anomaly detectors may be used to detect retinal diseases in more generalized settings and potentially could play a role in screening of populations for retinal diseases or identifying novel diseases and phenotyping or detecting unusual presentations of common retinal diseases.",not found
Article,"Sikkandar, Mohamed Yacin",Automatic Detection of Genetics and Genomics of Eye Disease Using Deep Assimilation Learning Algorithm,interdisciplinary sciences-computational life sciences,2021,Not found,"Diabetic retinopathy (DR) is one of the most prevalent genetic diseases in human and it is caused by damage to the blood vessels in the eye retina. If it is undetected and untreated at right time, it can lead to vision loss. There are many medical imaging and processing technologies to improve the diagnostic process of DR to overcome the lack of human experts. In the existing image processing methods, there are issues such as lack of noise removal, improper clustering segmentation and less classification accuracy. This can be accomplished by automatic diagnosis of DR using advanced image processing method. The cotton wool spot (CWS), hard exudates (HE) contains a common manifestation of many diseases in retina including DR and acquired immunodeficiency syndrome. In the present work, super iterative clustering algorithm (SICA) is proposed to identify the CWS, HE on retinal image. Feature-based medical image retrieval (FBMIR) datasets are utilized for this purpose. Noises present on the images and histogram-filtering technique is used to convert red, green, and blue (RGB) images into a perfect greyscale image without noise. After pre-processing, SICA is used to identify the CWS, HE detection on retinal images and eliminates unnecessary areas of interest. In the third stage, after detecting CWS and HE, various statistical features are extracted for further classification using deep assimilation learning algorithm (DALA). The performance of DALA technique is examined with various classification parameters like recall, precision, and F-measure. Finally, the false classification ratios are computed to compare the performance of the trained networks. The proposed method produces accurate detection of affected regions with an accuracy ratio of 98.5% and it is higher than the other conventional methods. This method may improve the accuracy of automatic detection and classification of eye diseases.",deep assimilation learning algorithm (dala); histogram filtering techniques; super iterative clustering algorithm; cotton wool spot (ces); hard exudates (he) detection
Article,"Kuwahara, Takamichi; Hara, Kazuo; Mizuno, Nobumasa; Okuno, Nozomi; Matsumoto, Shimpei; Obata, Masahiro; Kurita, Yusuke; Koda, Hiroki; Toriyama, Kazuhiro; Onishi, Sachiyo; Ishihara, Makoto; Tanaka, Tsutomu; Tajika, Masahiro; Niwa, Yasumasa",Usefulness of Deep Learning Analysis for the Diagnosis of Malignancy in Intraductal Papillary Mucinous Neoplasms of the Pancreas,clinical and translational gastroenterology,2019,Not found,"OBJECTIVES: Intraductal papillary mucinous neoplasms (IPMNs) are precursor lesions of pancreatic adenocarcinoma. Artificial intelligence (AI) is a mathematical concept whose implementation automates learning and recognizing data patterns. The aim of this study was to investigate whether AI via deep learning algorithms using endoscopic ultrasonography (EUS) images of IPMNs could predict malignancy. METHODS: This retrospective study involved the analysis of patients who underwent EUS before pancreatectomy and had pathologically confirmed IPMNs in a single cancer center. In total, 3,970 still images were collected and fed as input into the deep learning algorithm. AI value and AI malignant probability were calculated. RESULTS: The mean AI value of malignant IPMNs was significantly greater than benign IPMNs (0.808 vs 0.104, P < 0.001). The area under the receiver operating characteristic curve for the ability to diagnose malignancies of IPMNs via AI malignant probability was 0.98 (P < 0.001). The sensitivity, specificity, and accuracy of AI malignant probability were 95.7%, 92.6%, and 94.0%, respectively; its accuracy was higher than human diagnosis (56.0%) and the mural nodule (68.0%). Multivariate logistic regression analysis showed AI malignant probability to be the only independent factor for IPMN-associated malignancy (odds ratio: 295.16, 95% confidence interval: 14.13-6, 165.75, P < 0.001). DISCUSSION: AI via deep learning algorithm may be a more accurate and objective method to diagnose malignancies of IPMNs in comparison to human diagnosis and conventional EUS features.",diabetic-retinopathy; validation; guidelines; management; ipmn; classification; marker
Proceedings Paper,"Shen, Yaxin; Fang, Ruogu; Sheng, Bin; Dai, Ling; Li, Huating; Qin, Jing; Wu, Qiang; Jia, Weiping",Multi-task Fundus Image Quality Assessment via Transfer Learning and Landmarks Detection,"machine learning in medical imaging: 9th international workshop, mlmi 2018",2018,Not found,"The quality of fundus images is critical for diabetic retinopathy diagnosis. The evaluation of fundus image quality can be affected by several factors, including image artifact, clarity, and field definition. In this paper, we propose a multi-task deep learning framework for automated assessment of fundus image quality. The network can classify whether an image is gradable, together with interpretable information about quality factors. The proposed method uses images in both rectangular and polar coordinates, and fine-tunes the network from trained model grading of diabetic retinopathy. The detection of optic disk and fovea assists learning the field definition task through coarse-to-fine feature encoding. The experimental results demonstrate that our framework outperform single-task convolutional neural networks and reject ungradable images in automated diabetic retinopathy diagnostic systems.",fundus image quality assessment; multi-task learning; optic disk detection; fovea detection
Article,"Park, Seong Ho; Kressel, Herbert Y.",Connecting Technological Innovation in Artificial Intelligence to Real-world Medical Practice through Rigorous Clinical Validation: What Peer-reviewed Medical Journals Could Do,journal of korean medical science,2018,Not found,"Artificial intelligence (AI) is projected to substantially influence clinical practice in the foreseeable future. However, despite the excitement around the technologies, it is yet rare to see examples of robust clinical validation of the technologies and, as a result, very few are currently in clinical use. A thorough, systematic validation of AI technologies using adequately designed clinical research studies before their integration into clinical practice is critical to ensure patient benefit and safety while avoiding any inadvertent harms. We would like to suggest several specific points regarding the role that peer-reviewed medicaljournals can play, in terms of study design, registration, and reporting, to help achieve proper and meaningful clinical validation of AI technologies designed to make medical diagnosis and prediction, focusing on the evaluation of diagnostic accuracy efficacy. Peer-reviewed medical journals can encourage investigators who wish to validate the performance of AI systems for medical diagnosis and prediction to pay closer attention to the factors listed in this article by emphasizing their importance. Thereby, peer-reviewed medicaljournals can ultimately facilitate translating the technological innovations into real-world practice while securing patient safety and benefit.","artificial intelligence; machine learning; decision support techniques; peer review; journalism, medical; validation studies"
Proceedings Paper,"Li, Pei Lin; O'Neil, Celine; Saberi, Samin; Sinder, Kenneth; Wang, Kathleen; Tan, Bingyao; Hosseinaee, Zohreh; Bizheva, Kostadinka; Lakshminarayanan, Vasudevan",Deep learning algorithm for inferring retinal capillary flow maps from structural images,applications of machine learning 2020,2020,Not found,"Machine learning techniques have proven effective in ophthalmology. Clinicians use optical coherence tomography angiography (OCTA) retinal images for the diagnosis and monitoring of retinal conditions such as diabetic retinopathy. The optical microangiography (OMAG) algorithm used to construct OCTA images requires multiple structural OCT acquisitions per location. We created a system to extrapolate microvasculature from single acquisitions with the aim of lowering the resource costs to obtain improved functional imaging. This model can be used to enhance existing OCT datasets where one might not be able to easily acquire new OCTA images. We used a paired, unsupervised deep learning approach through implementation of a conditional generative adversarial network (cGAN) for inferring detailed retinal capillary flow maps from standard OCT images. Our cGAN architecture is based on the pix2pix image-to-image translation framework, which uses a modified U-Net for the generator and a PatchGAN for the discriminator. OCTA images generated by the OMAG algorithm applied to cross-sections captured in-vivo, non-invasively from sedated rats were used as the ground truth. A collection of 63 rat eye data sets (50 for training, 13 for testing), each with a sequence of 512 paired cross-sections, was provided for this project. Cross-sections were augmented with random jitter and rotations to provide the neural networks with a richer training set. The trained system generates en face blood flow maps of comparable quality to those generated from OMAG. Applying k-folds cross-validation (k=5), a mean Structural Similarity Index Measure (SSIM) of 0.723 was obtained for sum en face and 0.609 for max normalized en face. SSIM has a range from -1.0 to +1.0, inclusive, whereby +1.0 indicates two identical images. Additionally, we compared the cGAN model to a state-of-the-art convolutional neural network trained on the same data.",optical coherence tomography; biomedical optics; retinal imaging; optical microangiography; machine learning; image processing; deep learning; conditional generative adversarial net
Proceedings Paper,"Dayana, A. Mary; Emmanuel, W. R. Sam",Attention-Based Deep Fusion Network for Retinal Lesion Segmentation in Fundus Image,"advances in computing and data sciences, pt i",2021,Not found,"Segmentation of subtle lesions in fundus images has become a vital part of diagnosing ocular diseases such as Diabetic Retinopathy (DR). Diabetic eye disease is characterized by the scattered lesions in the retina. Detection of these lesions at the early stage is important as its progression leads to vision loss if proper treatment is not taken. The main objective of the work is to assist ophthalmologist in the effective diagnosis of eye disease providing timely treatment. This paper focuses on developing a deep learning-based Fusion Network (Fu-Net) with an attention mechanism for lesion segmentation in color fundus images. The network was developed based on the baseline U-Net model with trivial modification in the encoder and decoder part of the model. A multi-feature fusion block (MFuse) is integrated with the encoder of the network to extract the lesion features and a channel attention module is integrated with the decoder part to fuse the feature information effectively. Besides, a modified weighted focal loss function is introduced to mitigate the problem of class imbalance in the fundus image. The computational results obtained signifies the superior performance of the proposed method in the lesion segmentation task.",segmentation; diabetic retinopathy; fusion network; channel attention module
Article,"Bhatia, Kanwal K.; Graham, Mark S.; Terry, Louise; Wood, Ashley; Tranos, Paris; Trikha, Sameer; Jaccard, Nicolas","DISEASE CLASSIFICATION OF MACULAR OPTICAL COHERENCE TOMOGRAPHY SCANS USING DEEP LEARNING SOFTWARE Validation on Independent, Multicenter Data",retina-the journal of retinal and vitreous diseases,2020,Not found,"Purpose: To evaluate Pegasus optical coherence tomography (OCT), a clinical decision support software for the identification of features of retinal disease from macula OCT scans, across heterogenous populations involving varying patient demographics, device manufacturers, acquisition sites, and operators. Methods: Five thousand five hundred and eighty-eight normal and anomalous macular OCT volumes (162,721 B-scans), acquired at independent centers in five countries, were processed using the software. Results were evaluated against ground truth provided by the data set owners. Results: Pegasus-OCT performed with areas under the curve of the receiver operating characteristic of at least 98% for all data sets in the detection of general macular anomalies. For scans of sufficient quality, the areas under the curve of the receiver operating characteristic for general age-related macular degeneration and diabetic macular edema detection were found to be at least 99% and 98%, respectively. Conclusion: The ability of a clinical decision support system to cater for different populations is key to its adoption. Pegasus-OCT was shown to be able to detect age-related macular degeneration, diabetic macular edema, and general anomalies in OCT volumes acquired across multiple independent sites with high performance. Its use thus offers substantial promise, with the potential to alleviate the burden of growing demand in eye care services caused by retinal disease.",age-related macular degeneration; artificial intelligence; clinical decision support; computer-aided diagnosis; deep learning; diabetic macular edema; optical coherence tomography
Article,"Zhang, Guanghua; Pan, Jing; Zhang, Zhaoxia; Zhang, Heng; Xing, Changyuan; Sun, Bin; Li, Ming",Hybrid Graph Convolutional Network for Semi-Supervised Retinal Image Classification,ieee access,2021,Not found,"Diabetic Retinopathy (DR) causes a significant health threat to the patient's vision with diabetic disease, which may result in blindness in severe situations. Various automatic DR diagnosis models have been proposed along with the development of deep learning, while there always relies on a large scale annotated data to train the network. However, annotating medical fundus images is cost-expensive and requires well-trained professional doctors to identity the DR grades. To overcome this drawback, this paper focuses on utilizing the easily-obtained unlabeled data with the help of limited annotated data to identify DR grades accurately. Hence we proposes a semi-supervised retinal image classification method by a Hybrid Graph Convolutional Network (HGCN). This HGCN network designs a modularity-based graph learning module and integrates Convolutional Neural Network (CNN) features into the graph representation by graph convolutional network. The synthesized hybrid features are optimized by a semi-supervised classification task which is assisted by a similarity-based pseudo label estimator. Through the proposed HGCN method, the retinal image classification model can be trained efficiently by partially labeled samples and the complicated annotating work is not required for the most retinal images. The experimental results on MESSIDOR dataset demonstrate the favorable performance of HGCN on semi-supervised retinal image classification, and the fully labeled data training also achieves an obvious superiority to the state-of-the-art supervised learning methods.",retina; diabetes; retinopathy; feature extraction; deep learning; medical diagnostic imaging; blood; retinal image classification; semi-supervised; graph convolutional network; modularity-based graph learning
Article,"Hasan, Md. Kamrul; Alam, Md. Ashraful; Elahi, Md. Toufick E.; Roy, Shidhartho; Marti, Robert",DRNet: Segmentation and localization of optic disc and Fovea from diabetic retinopathy image,artificial intelligence in medicine,2021,Not found,"Background and objective: In modern ophthalmology, automated Computer-aided Screening Tools (CSTs) are crucial non-intrusive diagnosis methods, where an accurate segmentation of Optic Disc (OD) and localization of OD and Fovea centers are substantial integral parts. However, designing such an automated tool remains challenging due to small dataset sizes, inconsistency in spatial, texture, and shape information of the OD and Fovea, and the presence of different artifacts. Methods: This article proposes an end-to-end encoder-decoder network, named DRNet, for the segmentation and localization of OD and Fovea centers. In our DRNet, we propose a skip connection, named residual skip connection, for compensating the spatial information lost due to pooling in the encoder. Unlike the earlier skip connection in the UNet, the proposed skip connection does not directly concatenate low-level feature maps from the encoder's beginning layers with the corresponding same scale decoder. We validate DRNet using different publicly available datasets, such as IDRiD, RIMONE, DRISHTI-GS, and DRIVE for OD segmentation; IDRiD and HRF for OD center localization; and IDRiD for Fovea center localization. Results: The proposed DRNet, for OD segmentation, achieves mean Intersection over Union (mIoU) of 0.845, 0.901, 0.933, and 0.920 for IDRiD, RIMONE, DRISHTI-GS, and DRIVE, respectively. Our OD segmentation result, in terms of mIoU, outperforms the state-of-the-art results for IDRiD and DRIVE datasets, whereas it outperforms state-of-the-art results concerning mean sensitivity for RIMONE and DRISHTI-GS datasets. The DRNet localizes the OD center with mean Euclidean Distance (mED) of 20.23 and 13.34 pixels, respectively, for IDRiD and HRF datasets; it outperforms the state-of-the-art by 4.62 pixels for IDRiD dataset. The DRNet also successfully localizes the Fovea center with mED of 41.87 pixels for the IDRiD dataset, outperforming the state-of-the-art by 1.59 pixels for the same dataset. Conclusion: As the proposed DRNet exhibits excellent performance even with limited training data and without intermediate intervention, it can be employed to design a better-CST system to screen retinal images. Our source codes, trained models, and ground-truth heatmaps for OD and Fovea center localization will be made publicly available upon publication at GitHub.(1)",diabetic retinopathy and glaucoma; ophthalmology; encoder-decoder network; skip connection; segmentation and localization
Article,"Mohammed, Mazin Abed; Abdulkareem, Karrar Hameed; Garcia-Zapirain, Begonya; Mostafa, Salama A.; Maashi, Mashael S.; Al-Waisy, Alaa S.; Subhi, Mohammed Ahmed; Mutlag, Ammar Awad; Dac-Nhuong Le",A Comprehensive Investigation of Machine Learning Feature Extraction and Classification Methods for Automated Diagnosis of COVID-19 Based on X-ray Images,cmc-computers materials & continua,2021,Not found,"The quick spread of the CoronavirusDisease (COVID-19) infection around the world considered a real danger for global health. The biological structure and symptoms of COVID-19 are similar to other viral chest maladies, which makes it challenging and a big issue to improve approaches for efficient identification of COVID-19 disease. In this study, an automatic prediction of COVID-19 identification is proposed to automatically discriminate between healthy and COVID-19 infected subjects in X-ray images using two successful moderns are traditional machine learning methods (e.g., artificial neural network (ANN), support vector machine (SVM), linear kernel and radial basis function (RBF), k-nearest neighbor (k-NN), Decision Tree (DT), andCN2 rule inducer techniques) and deep learning models (e.g., MobileNets V2, ResNet50, GoogleNet, DarkNet andXception). A largeX-ray dataset has been created and developed, namely the COVID-19 vs. Normal (400 healthy cases, and 400 COVID cases). To the best of our knowledge, it is currently the largest publicly accessible COVID-19 dataset with the largest number of X-ray images of confirmed COVID-19 infection cases. Based on the results obtained from the experiments, it can be concluded that all the models performed well, deep learning models had achieved the optimum accuracy of 98.8% in ResNet50 model. In comparison, in traditional machine learning techniques, the SVM demonstrated the best result for an accuracy of 95% and RBF accuracy 94% for the prediction of coronavirus disease 2019.",coronavirus disease; covid-19 diagnosis; machine learning; convolutional neural networks; resnet50; artificial neural network; support vector machine; x-ray images; feature transfer learning
Article,"Rossi, Jesus Gomez; Rojas-Perilla, Natalia; Krois, Joachim; Schwendicke, Falk","Cost-effectiveness of Artificial Intelligence as a Decision-Support System Applied to the Detection and Grading of Melanoma, Dental Caries, and Diabetic Retinopathy",jama network open,2022,Not found,"OBJECTIVE To assess the cost-effectiveness of artificial intelligence (AI) for supporting clinicians in detecting and grading diseases in dermatology, dentistry, and ophthalmology. IMPORTANCE AI has been referred to as a facilitator for more precise, personalized, and safer health care, and AI algorithms have been reported to have diagnostic accuracies at or above the average physician in dermatology, dentistry, and ophthalmology. DESIGN, SETTING, AND PARTICIPANTS This economic evaluation analyzed data from 3 Markov models used in previous cost-effectiveness studies that were adapted to compare AI vs standard of care to detect melanoma on skin photographs, dental caries on radiographs, and diabetic retinopathy on retina fundus imaging. The general US and German population aged 50 and 12 years, respectively, as well as individuals with diabetes in Brazil aged 40 years were modeled over their lifetime. Monte Carlo microsimulations and sensitivity analyses were used to capture lifetime efficacy and costs. An annual cycle length was chosen. Data were analyzed between February 2021 and August 2021. EXPOSURE AI vs standard of care. MAIN OUTCOMES AND MEASURES Association of AI with tooth retention-years for dentistry and quality-adjusted life-years (QALYs) for individuals in dermatology and ophthalmology; diagnostic costs. RESULTS In 1000 microsimulations with 1000 random samples, AI as a diagnostic-support system showed limited cost-savings and gains in tooth retention-years and QALYs. In dermatology, AI showed mean costs of $750 (95% CI, $608-$970) and was associated with 86.5 QALYs (95% CI, 84.9-87.9 QALYs), while the control showed higher costs $759 (95% CI, $618-$970) with similar QALY outcome. In dentistry, AI accumulated costs of (sic)320 (95% CI, (sic)299-(sic)341) (purchasing power parity [PPP] conversion, $429 [95% CI, $400-$458]) with 62.4 years per tooth retention (95% CI, 60.7-65.1 years). The control was associated with higher cost, (sic)342 (95% CI, (sic)318-(sic)368) (PPP, $458; 95% CI, $426-$493) and fewer tooth retention-years (60.9 years; 95% CI, 60.5-63.1 years). In ophthalmology, AI accrued costs of R $1321 (95% CI, R $1283-R $1364) (PPP, $559; 95% CI, $543-$577) at 8.4 QALYs (95% CI, 8.0-8.7 QALYs), while the control was less expensive (R $1260; 95% CI, R $1222-R $1303) (PPP, $533; 95% CI, $517-$551) and associated with similar QALYs. Dominance in favor of AI was dependent on small differences in the fee paid for the service and the treatment assumed after diagnosis. The fee paid for AI was a factor in patient preferences in cost-effectiveness between strategies. CONCLUSIONS AND RELEVANCE The findings of this study suggest that marginal improvements in diagnostic accuracy when using AI may translate into a marginal improvement in outcomes. The current evidence supporting AI as decision support from a cost-effectiveness perspective is limited; AI should be evaluated on a case-specific basis to capture not only differences in costs and payment mechanisms but also treatment after diagnosis.",root-canal treatment; surveillance; strategies; services; outcomes; england; lesions; crowns; field
Article,"Singh, Rajeev Kumar; Gorantla, Rohan",DMENet: Diabetic Macular Edema diagnosis using Hierarchical Ensemble of CNNs,plos one,2020,Not found,"Diabetic Macular Edema (DME) is an advanced stage of Diabetic Retinopathy (DR) and can lead to permanent vision loss. Currently, it affects 26.7 million people globally and on account of such a huge number of DME cases and the limited number of ophthalmologists, it is desirable to automate the diagnosis process. Computer-assisted, deep learning based diagnosis could help in early detection, following which precision medication can help to mitigate the vision loss. Method: In order to automate the screening of DME, we propose a novel DMENet Algorithm which is built on the pillars of Convolutional Neural Networks (CNNs). DMENet analyses the preprocessed color fundus images and passes it through a two-stage pipeline. The first stage detects the presence or absence of DME whereas the second stage takes only the positive cases and grades the images based on severity. In both the stages, we use a novel Hierarchical Ensemble of CNNs (HE-CNN). This paper uses two of the popular publicly available datasets IDRiD and MESSIDOR for classification. Preprocessing on the images is performed using morphological opening and gaussian kernel. The dataset is augmented to solve the class imbalance problem for better performance of the proposed model. Results: The proposed methodology achieved an average Accuracy of 96.12%, Sensitivity of 96.32%, Specificity of 95.84%, and F-1 score of 0.9609 on MESSIDOR and IDRiD datasets. Conclusion: These excellent results establish the validity of the proposed methodology for use in DME screening and solidifies the applicability of the HECNN classification technique in the domain of biomedical imaging.",convolutional neural-networks; retinopathy; mixtures; experts; system
Proceedings Paper,"Bibi, Nasira; Nida, Nudrat; Irtaza, Aun; Anwar, Syed Muhammad",Automatic Detection of Exudates for Daignosis of Non-proliferative Diabetic Retinopathy using Region-based Convolutional Neural Networks,2021 international conference on frontiers of information technology (fit 2021),2021,Not found,"Diabetic Retinopathy (DR) is a severe visual impairment that grows from mild non-proliferative DR to proliferative DR. Exudates are the earliest sign of NPDR and therefore, an earlier detection of exudates would help in the diagnosis of DR Towards this, a deep region-based convolutional neural network (RCNN) is adopted in this study to achieve pixel-wise exudate detection using MobileNet as feature extractor from fundus images. In particular, preprocessing of the retinal images is performed, including data augmentation and bounding boxes generation. The goal is to achieve pixel-level accuracy and reduce computational time. The region proposal are generated which are potential exudate candidate points within the training fundus images. Further, the local region surrounding the candidate points is forwarded to the deep RCNN for model learning and exudate detection. The proposed model is evaluated using two publicly available datasets including DIARETDB1 and e-Ophtha. Our method achieves sensitivity and specificity values of 0.98 and 0.94, respectively for DIARETDB1 data, while for e-Ophtha sensitivity and specificity is 0.96 and 0.99, respectively.",dcnn; npdr; rcnn; region proposal; exudate detection
Article,"Zheng, Bo; Jiang, Qin; Lu, Bing; He, Kai; Wu, Mao-Nian; Hao, Xiu-Lan; Zhou, Hong-Xia; Zhu, Shao-Jun; Yang, Wei-Hua",Five-Category Intelligent Auxiliary Diagnosis Model of Common Fundus Diseases Based on Fundus Images,translational vision science & technology,2021,Not found,"Purpose: The discrepancy of the number between ophthalmologists and patients in China is large. Retinal vein occlusion (RVO), high myopia, glaucoma, and diabetic retinopathy (DR) are common fundus diseases. Therefore, in this study, a five-category intelligent auxiliary diagnosis model for common fundus diseases is proposed; the model's area of focus is marked. Methods: A total of 2000 fundus images were collected; 3 different 5-category intelligent auxiliary diagnosis models for common fundus diseases were trained via different transfer learning and image preprocessing techniques. A total of 1134 fundus images were used for testing. The clinical diagnostic results were compared with the diagnostic results. The main evaluation indicators included sensitivity, specificity, F1-score, area under the concentration-time curve (AUC), 95% confidence interval (CI), kappa, and accuracy. The interpretation methods were used to obtain the model's area of focus in the fundus image. Results: The accuracy rates of the 3 intelligent auxiliary diagnosis models on the 1134 fundus images were all above 90%, the kappa values were all above 88%, the diagnosis consistency was good, and the AUC approached 0.90. For the 4 common fundus diseases, the best results of sensitivity, specificity, and F1-scores of the 3 models were 88.27%, 97.12%, and 84.02%; 89.94%, 99.52%, and 93.90%; 95.24%, 96.43%, and 85.11%; and 88.24%, 98.21%, and 89.55%, respectively. Conclusions: This study designed a five-category intelligent auxiliary diagnosis model for common fundus diseases. It can be used to obtain the diagnostic category of fundus images and the model's area of focus. Translational Relevance: This study will help the primary doctors to provide effective services to all ophthalmologic patients.",deep learning; common fundus diseases; intelligent auxiliary diagnosis model; ophthalmological diagnostic techniques; model interpretability approach
Article,"Eftekhari, Noushin; Pourreza, Hamid-Reza; Masoudi, Mojtaba; Ghiasi-Shirazi, Kamaledin; Saeedi, Ehsan",Microaneurysm detection in fundus images using a two-step convolutional neural network,biomedical engineering online,2019,Not found,"Background and objectivesDiabetic retinopathy (DR) is the leading cause of blindness worldwide, and therefore its early detection is important in order to reduce disease-related eye injuries. DR is diagnosed by inspecting fundus images. Since microaneurysms (MA) are one of the main symptoms of the disease, distinguishing this complication within the fundus images facilitates early DR detection. In this paper, an automatic analysis of retinal images using convolutional neural network (CNN) is presented.MethodsOur method incorporates a novel technique utilizing a two-stage process with two online datasets which results in accurate detection while solving the imbalance data problem and decreasing training time in comparison with previous studies. We have implemented our proposed CNNs using the Keras library.ResultsIn order to evaluate our proposed method, an experiment was conducted on two standard publicly available datasets, i.e., Retinopathy Online Challenge dataset and E-Ophtha-MA dataset. Our results demonstrated a promising sensitivity value of about 0.8 for an average of >6 false positives per image, which is competitive with state of the art approaches.ConclusionOur method indicates significant improvement in MA-detection using retinal fundus images for monitoring diabetic retinopathy.",diabetic retinopathy (dr); microaneurysm (ma); deep learning; convolutional neural network (cnn)
Review,"Khandouzi, Ali; Ariafar, Ali; Mashayekhpour, Zahra; Pazira, Milad; Baleghi, Yasser","Retinal Vessel Segmentation, a Review of Classic and Deep Methods",annals of biomedical engineering,2022,Not found,"Retinal illnesses such as diabetic retinopathy (DR) are the main causes of vision loss. In the early recognition of eye diseases, the segmentation of blood vessels in retina images plays an important role. Different symptoms of ocular diseases can be identified by the geometric features of ocular arteries. However, due to the complex construction of the blood vessels and their different thicknesses, segmenting the retina image is a challenging task. There are a number of algorithms that helped the detection of retinal diseases. This paper presents an overview of papers from 2016 to 2022 that discuss machine learning and deep learning methods for automatic vessel segmentation. The methods are divided into two groups: Deep learning-based, and classic methods. Algorithms, classifiers, pre-processing and specific techniques of each group is described, comprehensively. The performances of recent works are compared based on their achieved accuracy in different datasets in inclusive tables. A survey of most popular datasets like DRIVE, STARE, HRF and CHASE_DB1 is also given in this paper. Finally, a list of findings from this review is presented in the conclusion section.",retinal vessel segmentation; deep learning; convolutional neural network; medical imaging; blood vessels
Article,"Wu, Xiaohang; Huang, Yelin; Liu, Zhenzhen; Lai, Weiyi; Long, Erping; Zhang, Kai; Jiang, Jiewei; Lin, Duoru; Chen, Kexin; Yu, Tongyong; Wu, Dongxuan; Li, Cong; Chen, Yanyi; Zou, Minjie; Chen, Chuan; Zhu, Yi; Guo, Chong; Zhang, Xiayin; Wang, Ruixin; Yang, Yahan; Xiang, Yifan; Chen, Lijian; Liu, Congxin; Xiong, Jianhao; Ge, Zongyuan; Wang, Dingding; Xu, Guihua; Du, Shaolin; Xiao, Chi; Wu, Jianghao; Zhu, Ke; Nie, Danyao; Xu, Fan; Lv, Jian; Chen, Weirong; Liu, Yizhi; Lin, Haotian",Universal artificial intelligence platform for collaborative management of cataracts,british journal of ophthalmology,2019,Not found,"Purpose To establish and validate a universal artificial intelligence (AI) platform for collaborative management of cataracts involving multilevel clinical scenarios and explored an AI-based medical referral pattern to improve collaborative efficiency and resource coverage. Methods The training and validation datasets were derived from the Chinese Medical Alliance for Artificial Intelligence, covering multilevel healthcare facilities and capture modes. The datasets were labelled using a three-step strategy: (1) capture mode recognition; (2) cataract diagnosis as a normal lens, cataract or a postoperative eye and (3) detection of referable cataracts with respect to aetiology and severity. Moreover, we integrated the cataract AI agent with a real-world multilevel referral pattern involving self-monitoring at home, primary healthcare and specialised hospital services. Results The universal AI platform and multilevel collaborative pattern showed robust diagnostic performance in three-step tasks: (1) capture mode recognition (area under the curve (AUC) 99.28%-99.71%), (2) cataract diagnosis (normal lens, cataract or postoperative eye with AUCs of 99.82%, 99.96% and 99.93% for mydriatic-slit lamp mode and AUCs >99% for other capture modes) and (3) detection of referable cataracts (AUCs >91% in all tests). In the real-world tertiary referral pattern, the agent suggested 30.3% of people be 'referred', substantially increasing the ophthalmologist-to-population service ratio by 10.2-fold compared with the traditional pattern. Conclusions The universal AI platform and multilevel collaborative pattern showed robust diagnostic performance and effective service for cataracts. The context of our AI-based medical referral pattern will be extended to other common disease conditions and resource-intensive situations.",diagnostic tests; investigation; lens and zonules; public health; imaging
Article,"Fu, Huazhu; Li, Fei; Xu, Yanwu; Liao, Jingan; Xiong, Jian; Shen, Jianbing; Liu, Jiang; Zhang, Xiulan",A Retrospective Comparison of Deep Learning to Manual Annotations for Optic Disc and Optic Cup Segmentation in Fundus Photographs,translational vision science & technology,2020,Not found,"Purpose: Optic disc (OD) and optic cup (OC) segmentation are fundamental for fundus image analysis. Manual annotation is time consuming, expensive, and highly subjective, whereas an automated system is invaluable to the medical community. The aim of this study is to develop a deep learning system to segment OD and OC in fundus photographs, and evaluate how the algorithm compares against manual annotations. Methods: A total of 1200 fundus photographs with 120 glaucoma cases were collected. The OD and OC annotations were labeled by seven licensed ophthalmologists, and glaucoma diagnoses were based on comprehensive evaluations of the subject medical records. A deep learning system for OD and OC segmentation was developed. The performances of segmentation and glaucoma discriminating based on the cup-to-disc ratio (CDR) of automated model were compared against the manual annotations. Results: The algorithm achieved an OD dice of 0.938 (95% confidence interval [CI] = 0.934-0.941), OC dice of 0.801 (95% CI = 0.793-0.809), and CDR mean absolute error (MAE) of 0.077 (95% CI = 0.073 mean absolute error (MAE)0.082). For glaucoma discriminating based on CDR calculations, the algorithm obtained an area under receiver operator characteristic curve (AUC) of 0.948 (95% CI = 0.920 mean absolute error (MAE)0.973), with a sensitivity of 0.850 (95% CI = 0.794-0.923) and specificity of 0.853 (95% CI = 0.798-0.918). Conclusions: We demonstrated the potential of the deep learning system to assist ophthalmologists in analyzing OD and OC segmentation and discriminating glaucoma from nonglaucoma subjects based on CDR calculations. Translational Relevance: We investigate the segmentation of OD and OC by deep learning system compared against the manual annotations.",optic disc; optic cup; segmentation; artificial intelligence
Article,"Cheng, Chi-Tung; Chen, Chih-Chi; Cheng, Fu-Jen; Chen, Huan-Wu; Su, Yi-Siang; Yeh, Chun-Nan; Chung, I-Fang; Liao, Chien-Hung",A Human-Algorithm Integration System for Hip Fracture Detection on Plain Radiography: System Development and Validation Study,jmir medical informatics,2020,Not found,"Background: Hip fracture is the most common type of fracture in elderly individuals. Numerous deep learning (DL) algorithms for plain pelvic radiographs (PXRs) have been applied to improve the accuracy of hip fracture diagnosis. However, their efficacy is still undetermined. Objective: The objective of this study is to develop and validate a human-algorithm integration (HAI) system to improve the accuracy of hip fracture diagnosis in a real clinical environment. Methods: The HAI system with hip fracture detection ability was developed using a deep learning algorithm trained on trauma registry data and 3605 PXRs from August 2008 to December 2016. To compare their diagnostic performance before and after HAI system assistance using an independent testing dataset, 34 physicians were recruited. We analyzed the physicians' accuracy, sensitivity, specificity, and agreement with the algorithm; we also performed subgroup analyses according to physician specialty and experience. Furthermore, we applied the HAI system in the emergency departments of different hospitals to validate its value in the real world. Results: With the support of the algorithm, which achieved 91% accuracy, the diagnostic performance of physicians was significantly improved in the independent testing dataset, as was revealed by the sensitivity (physician alone, median 95%; HAI, median 99%; P<.001), specificity (physician alone, median 90%; HAI, median 95%; P<.001), accuracy (physician alone, median 90%; HAI, median 96%; P<.001), and human-algorithm agreement [physician alone x, median 0.69 (IQR 0.63-0.74); HAI kappa, median 0.80 (IQR 0.76-0.82); P<.001. With the help of the HAI system, the primary physicians showed significant improvement in their diagnostic performance to levels comparable to those of consulting physicians, and both the experienced and less-experienced physicians benefited from the HAI system. After the HAI system had been applied in 3 departments for 5 months, 587 images were examined. The sensitivity, specificity, and accuracy of the HAI system for detecting hip fractures were 97%, 95.7%, and 96.08%, respectively. Conclusions: HAI currently impacts health care, and integrating this technology into emergency departments is feasible. The developed HAI system can enhance physicians' hip fracture diagnostic performance.",hip fracture; neural network; computer; artificial intelligence; algorithms; human augmentation; deep learning; diagnosis
Article,"Mallah, Ghulam Ali; Ahmed, Jamil; Nazeer, Muhammad Irshad; Dootio, Mazhar Ali; Shaikh, Hidayatullah; Jameel, Aadil",Decision Support System for Diagnosis of Irregular Fovea,cmc-computers materials & continua,2022,Not found,"Detection of abnormalities in human eye is one of the well-established research areas of Machine Learning. Deep Learning techniques are widely used for the diagnosis of Retinal Diseases (RD). Fovea is one of the significant parts of retina which would be prevented before the involvement of Perforated Blood Vessels (PBV). Retinopathy Images (RI) contains sufficient information to classify structural changes incurred upon PBV but Macular Features (MF) and Fovea Features (FF) are very difficult to detect because features of MFand FF could be found with Similar Color Movements (SCM) with minor variations. This paper presents novel method for the diagnosis of Irregular Fovea (IF) to assist the doctors in diagnosis of irregular fovea. By considering all above problems this paper proposes a three-layer decision support system to explore the hindsight knowledge of RI and to solve the classification problem of IF. The first layer involves data preparation, the second layer builds the decision model to extract the hidden patterns of fundus images by using Deep Belief Neural Network (DBN) and the third layer visualizes the results by using confusion matrix. This paper contributes a data preparation algorithm for irregular fovea and a highest estimated classification accuracy measured about 96.90%.",machine learning; deep belief neural network; eye disease; fovea
Article,"Ko, Yu-Chieh; Chen, Wei-Shiang; Chen, Hung-Hsun; Hsu, Tsui-Kang; Chen, Ying-Chi; Liu, Catherine Jui-Ling; Lu, Henry Horng-Shing",Widen the Applicability of a Convolutional Neural-Network-Assisted Glaucoma Detection Algorithm of Limited Training Images across Different Datasets,biomedicines,2022,Not found,"Automated glaucoma detection using deep learning may increase the diagnostic rate of glaucoma to prevent blindness, but generalizable models are currently unavailable despite the use of huge training datasets. This study aims to evaluate the performance of a convolutional neural network (CNN) classifier trained with a limited number of high-quality fundus images in detecting glaucoma and methods to improve its performance across different datasets. A CNN classifier was constructed using EfficientNet B3 and 944 images collected from one medical center (core model) and externally validated using three datasets. The performance of the core model was compared with (1) the integrated model constructed by using all training images from the four datasets and (2) the dataset-specific model built by fine-tuning the core model with training images from the external datasets. The diagnostic accuracy of the core model was 95.62% but dropped to ranges of 52.5-80.0% on the external datasets. Dataset-specific models exhibited superior diagnostic performance on the external datasets compared to other models, with a diagnostic accuracy of 87.50-92.5%. The findings suggest that dataset-specific tuning of the core CNN classifier effectively improves its applicability across different datasets when increasing training images fails to achieve generalization.",deep learning; diagnosis; fundus photograph; glaucoma
Article,"Yasser, Ibrahim; Khalifa, Fahmi; Abdeltawab, Hisham; Ghazal, Mohammed; Sandhu, Harpal Singh; El-Baz, Ayman",Automated Diagnosis of Optical Coherence Tomography Angiography (OCTA) Based on Machine Learning Techniques,sensors,2022,Not found,"Diabetic retinopathy (DR) refers to the ophthalmological complications of diabetes mellitus. It is primarily a disease of the retinal vasculature that can lead to vision loss. Optical coherence tomography angiography (OCTA) demonstrates the ability to detect the changes in the retinal vascular system, which can help in the early detection of DR. In this paper, we describe a novel framework that can detect DR from OCTA based on capturing the appearance and morphological markers of the retinal vascular system. This new framework consists of the following main steps: (1) extracting retinal vascular system from OCTA images based on using joint Markov-Gibbs Random Field (MGRF) model to model the appearance of OCTA images and (2) estimating the distance map inside the extracted vascular system to be used as imaging markers that describe the morphology of the retinal vascular (RV) system. The OCTA images, extracted vascular system, and the RV-estimated distance map is then composed into a three-dimensional matrix to be used as an input to a convolutional neural network (CNN). The main motivation for using this data representation is that it combines the low-level data as well as high-level processed data to allow the CNN to capture significant features to increase its ability to distinguish DR from the normal retina. This has been applied on multi-scale levels to include the original full dimension images as well as sub-images extracted from the original OCTA images. The proposed approach was tested on in-vivo data using about 91 patients, which were qualitatively graded by retinal experts. In addition, it was quantitatively validated using datasets based on three metrics: sensitivity, specificity, and overall accuracy. Results showed the capability of the proposed approach, outperforming the current deep learning as well as features-based detecting DR approaches.",diabetic retinopathy (dr); optical coherence tomography angiography (octa); convolutional neural networks (cnn); image encryption; security analysis
Article,"Guo, Song; Li, Tao; Kang, Hong; Li, Ning; Zhang, Yujun; Wang, Kai",L-Seg: An end-to-end unified framework for multi-lesion segmentation of fundus images,neurocomputing,2019,Not found,"Diabetic retinopathy and diabetic macular edema are the two leading causes for blindness in working-age people, and the quantitative and qualitative diagnosis of these two diseases usually depends on the presence and areas of lesions in fundus images. The main related lesions include soft exudates, hard exudates, microaneurysms, and haemorrhages. However, segmentation of these four kinds of lesions is difficult due to their uncertainty in size, contrast, and high interclass similarity. Therefore, we aim to design a multi-lesion segmentation model. We have designed the first small object segmentation network (L-Seg) that can segment the four kinds of lesions simultaneously. Taking into account that small lesion regions could not response at high level of network, we propose a multi-scale feature fusion method to handle this problem. In addition, when considering the cases of both class-imbalance and loss-imbalance problems, we propose a multi-channel bin loss. We have evaluated L-Seg on three fundus datasets including two publicly available datasets - IDRiD and e-ophtha and one private dataset - DDR. Extensive experiments have demonstrated that L-Seg achieves better performance in small lesion segmentation than other deep learning models and traditional methods. Specially, the mAUC score of L-Seg is over 16.8%, 1.51% and 3.11% higher than that of DeepLab v3 + on IDRiD, e-ophtha and DDR datasets, respectively. Moreover, our framework shows competitive performance compared with top-3 teams in IDRiD challenge. (C) 2019 Elsevier B. V. All rights reserved.",multi-lesion segmentation; fundus image; diabetic retinopathy; class-imbalance
Article,"Guo, Song",Fundus image segmentation via hierarchical feature learning,computers in biology and medicine,2021,Not found,"Fundus Image Segmentation (FIS) is an essential procedure for the automated diagnosis of ophthalmic diseases. Recently, deep fully convolutional networks have been widely used for FIS with state-of-the-art performance. The representative deep model is the U-Net, which follows an encoder-decoder architecture. I believe it is suboptimal for FIS because consecutive pooling operations in the encoder lead to low-resolution representation and loss of detailed spatial information, which is particularly important for the segmentation of tiny vessels and lesions. Motivated by this, a high-resolution hierarchical network (HHNet) is proposed to learn semantic-rich high-resolution representations and preserve spatial details simultaneously. Specifically, a High-resolution Feature Learning (HFL) module with increasing dilation rates was first designed to learn the high-level high-resolution representations. Then, the HHNet was constructed by incorporating three HFL modules and two feature aggregation modules. The HHNet runs in a coarse-to-fine manner, and fine segmentation maps are output at the last level. Extensive experiments were conducted on fundus lesion segmentation, vessel segmentation, and optic cup segmentation. The experimental results reveal that the proposed method shows highly competitive or even superior performance in terms of segmentation performance and computation cost, indicating its potential advantages in clinical application.",high-resolution feature; hierarchical network; vessel segmentation; lesion segmentation
Article,"Bozic-Stulic, Dunja; Braovic, Maja; Stipanicev, Darko",Deep learning based approach for optic disc and optic cup semantic segmentation for glaucoma analysis in retinal fundus images,international journal of electrical and computer engineering systems,2020,Not found,"Optic disc and optic cup are one of the most recognized retinal landmarks, and there are numerous methods for their automatic detection. Segmented optic disc and optic cup are useful in providing the contextual information about the retinal image that can aid in the detection of other retinal features, but it is also useful in the automatic detection and monitoring of glaucoma. This paper proposes a deep learning based approach for the automatic optic disc and optic cup semantic segmentation, but also the new model for possible glaucoma detection. The proposed method was trained on DRIVE and DIARETDBI image datasets and evaluated on MESSIDOR dataset, where it achieved the average accuracy of 97.3% of optic disc and 88.1% of optic cup. Detection rate of glaucoma diesis is 96.75%.",optic disc; optic cup; glaucoma; deep learning
Review,"Latif, Jahanzaib; Xiao, Chuangbai; Tu, Shanshan; Rehman, Sadaqat Ur; Imran, Azhar; Bilal, Anas",Implementation and Use of Disease Diagnosis Systems for Electronic Medical Records Based on Machine Learning: A Complete Review,ieee access,2020,Not found,"Electronic health records are used to extract patient's information instantly and remotely, which can help to keep track of patients' due dates for checkups, immunizations, and to monitor health performance. The Health Insurance Portability and Accountability Act (HIPAA) in the USA protects the patient data confidentiality, but it can be used if data is re-identified using 'HIPAA Safe Harbor' technique. Usually, this re-identification is performed manually, which is very laborious and time captivating exertion. Various techniques have been proposed for automatic extraction of useful information, and accurate diagnosis of diseases. Most of these methods are based on Machine Learning and Deep Learning Methods, while the auxiliary diagnosis is performed using Rule-based methods. This review focuses on recently published papers, which are categorized into Rule-Based Methods, Machine Learning (ML) Methods, and Deep Learning (DL) Methods. Particularly, ML methods are further categorized into Support Vector Machine Methods (SVM), Bayes Methods, and Decision Tree Methods (DT). DL methods are decomposed into Convolutional Neural Networks (CNN), Recurrent Neural Networks (RNN), Deep Belief Network (DBN) and Autoencoders (AE) methods. The objective of this survey paper is to highlight both the strong and weak points of various proposed techniques in the disease diagnosis. Moreover, we present advantage, disadvantage, focused disease, dataset employed, and publication year of each category.",machine learning; diseases; medical diagnosis; electronic medical records; data mining; medical diagnostic imaging; automatic extraction; classification; clinical informatics; deep learning; disease diagnosis; electronic health records; machine learning
Article,"Li, Zhongwen; Guo, Chong; Nie, Danyao; Lin, Duoru; Zhu, Yi; Chen, Chuan; Zhao, Lanqin; Wu, Xiaohang; Dongye, Meimei; Xu, Fabao; Jin, Chenjin; Zhang, Ping; Han, Yu; Yan, Pisong; Lin, Haotian",Deep learning from passive feeding to selective eating of real-world data,npj digital medicine,2020,Not found,"Artificial intelligence (AI) based on deep learning has shown excellent diagnostic performance in detecting various diseases with good-quality clinical images. Recently, AI diagnostic systems developed from ultra-widefield fundus (UWF) images have become popular standard-of-care tools in screening for ocular fundus diseases. However, in real-world settings, these systems must base their diagnoses on images with uncontrolled quality (passive feeding), leading to uncertainty about their performance. Here, using 40,562 UWF images, we develop a deep learning-based image filtering system (DLIFS) for detecting and filtering out poor-quality images in an automated fashion such that only good-quality images are transferred to the subsequent AI diagnostic system (selective eating). In three independent datasets from different clinical institutions, the DLIFS performed well with sensitivities of 96.9%, 95.6% and 96.6%, and specificities of 96.6%, 97.9% and 98.8%, respectively. Furthermore, we show that the application of our DLIFS significantly improves the performance of established AI diagnostic systems in real-world settings. Our work demonstrates that selective eating of real-world data is necessary and needs to be considered in the development of image-based AI systems.",diabetic-retinopathy; system; validation
Article,"Ye, Xin; Wang, Jun; Chen, Yiqi; Lv, Zhe; He, Shucheng; Mao, Jianbo; Xu, Jiahao; Shen, Lijun",Automatic Screening and Identifying Myopic Maculopathy on Optical Coherence Tomography Images Using Deep Learning,translational vision science & technology,2021,Not found,"Purpose: The purpose of this study was to engineer deep learning (DL) models that can identify myopic maculopathy in patients with high myopia based on optical coherence tomography (OCT) images. Methods: An artificial intelligence (AI) system was developed using 2342 qualified OCT macular images from 1041 patients with pathologic myopia admitted to the Affiliated Eye Hospital of Wenzhou Medical University (WMU). We adopted an ResNeSt101 architecture to train five independent models to identify the following five myopic subretinal hyper-reflective material (SHRM), myopic traction maculopathy (MTM), and dome-shaped macula (DSM). We tested the models with an independent test dataset that included 450 images obtained from 297 patients with high myopia. Focal loss was used to address class imbalance, and optimal operating thresholds were determined according to the Youden Index. The performance was quantified using the area under the receiver operating characteristic (AUC), sensitivity, specificity, and confusion matrix. Results: For the identification of myopic maculopathy, the AUCs of receiver operating characteristic (ROC) curves were 0.927 to 0.974 for 5 myopic maculopathies. Our AI system achieved sensitivities equal to or even better than those of junior retinal specialists (56.16-99.73%). The diagnosis of it is also interpretable that we provide visual explanations clearly via heatmaps. Conclusions: We developed a convolutional neural network (CNN)-based DL AI system for detection and classification of myopic maculopathy in patients with high myopia using OCT macular images. Our AI system achieved sensitivities equal to or even better than those of junior retinal specialists. Translational Relevance: This AI system can be widely applied in sophisticated situations in large-scale high myopia screening.",myopic maculopathy; optical coherence tomography (oct); convolutional neural network (cnn); deep learning (dl)
Article,"Phene, Sonia; Dunn, R. Carter; Hammel, Naama; Liu, Yun; Krause, Jonathan; Kitade, Naho; Schaekermann, Mike; Sayres, Rory; Wu, Derek J.; Bora, Ashish; Semturs, Christopher; Misra, Anita; Huang, Abigail E.; Spitze, Arielle; Medeiros, Felipe A.; Maa, April Y.; Gandhi, Monica; Corrado, Greg S.; Peng, Lily; Webster, Dale R.",Deep Learning and Glaucoma Specialists The Relative Importance of Optic Disc Features to Predict Glaucoma Referral in Fundus Photographs,ophthalmology,2019,Not found,"Purpose: To develop and validate a deep learning (DL) algorithm that predicts referable glaucomatous optic neuropathy (GON) and optic nerve head (ONH) features from color fundus images, to determine the relative importance of these features in referral decisions by glaucoma specialists (GSs) and the algorithm, and to compare the performance of the algorithm with eye care providers. Design: Development and validation of an algorithm. Participants: Fundus images from screening programs, studies, and a glaucoma clinic. Methods: A DL algorithm was trained using a retrospective dataset of 86 618 images, assessed for glaucomatous ONH features and referable GON (defined as ONH appearance worrisome enough to justify referral for comprehensive examination) by 43 graders. The algorithm was validated using 3 datasets: dataset A (1205 images, 1 image/patient; 18.1% referable), images adjudicated by panels of GSs; dataset B (9642 images, 1 image/ patient; 9.2% referable), images from a diabetic teleretinal screening program; and dataset C (346 images, 1 image/patient; 81.7% referable), images from a glaucoma clinic. Main Outcome Measures: The algorithm was evaluated using the area under the receiver operating characteristic curve (AUC), sensitivity, and specificity for referable GON and glaucomatous ONH features. Results: The algorithm's AUC for referable GON was 0.945 (95% confidence interval [CI], 0.929-0.960) in dataset A, 0.855 (95% CI, 0.841-0.870) in dataset B, and 0.881 (95% CI, 0.838-0.918) in dataset C. Algorithm AUCs ranged between 0.661 and 0.973 for glaucomatous ONH features. The algorithm showed significantly higher sensitivity than 7 of 10 graders not involved in determining the reference standard, including 2 of 3 GSs, and showed higher specificity than 3 graders (including 1 GS), while remaining comparable to others. For both GSs and the algorithm, the most crucial features related to referable GON were: presence of vertical cup-to-disc ratio of 0.7 or more, neuroretinal rim notching, retinal nerve fiber layer defect, and bared circumlinear vessels. Conclusions: A DL algorithm trained on fundus images alone can detect referable GON with higher sensitivity than and comparable specificity to eye care providers. The algorithm maintained good performance on an independent dataset with diagnoses based on a full glaucoma workup. (C) 2019 by the American Academy of Ophthalmology.",open-angle glaucoma; diabetic-retinopathy; circumlinear vessel; validation; algorithm; agreement; defects
Article,"Zhang, Wei; Zhao, Xiujuan; Chen, Yuanyuan; Zhong, Jie; Yi, Zhang",DeepUWF: An Automated Ultra-Wide-Field Fundus Screening System via Deep Learning,ieee journal of biomedical and health informatics,2021,Not found,"The emerging ultra-wide field of view (UWF) fundus color imaging is a powerful tool for fundus screening. However, manual screening is labor-intensive and subjective. Based on 2644 UWF images, a set of early fundus abnormal screening system named DeepUWF is developed. DeepUWF includes an abnormal fundus screening subsystem and a disease diagnosis subsystem for three kinds of fundus diseases (retinal tear & retinal detachment, diabetic retinopathy and pathological myopia). The components in the system are composed of a set of excellent convolutional neural networks and two custom classifiers. However, the contrast of UWF images used in the research is low, which seriously limits the extraction of fine features of UWF images by depth model. Therefore, the high specificity and low sensitivity of prediction results have always been difficult problems in research. In order to solve this problem, six kinds of image preprocessing techniques are adopted, and their effects on the prediction performance of fundus abnormal and three kinds of fundus diseases models are studied. A variety of experimental indicators are used to evaluate the algorithms for validity and reliability. The experimental results show that these preprocessing methods are helpful to improve the learning ability of the networks and achieve good sensitivity and specificity. Without ophthalmologists, DeepUWF has potential application value, which is helpful for fundus health screening and workflow improvement.",retina; imaging; optical imaging; lesions; optical sensors; optical refraction; visualization; deep learning; fundus screening; image classification; ultra-wide-field
Article,"Avendano-Valencia, Luis David; Yderstraede, Knud B.; Nadimi, Esmaeil S.; Blanes-Vidal, Victoria",Video-based eye tracking performance for computer-assisted diagnostic support of diabetic neuropathy,artificial intelligence in medicine,2021,Not found,"Diabetes is currently one of the major public health threats. The essential components for effective treatment of diabetes include early diagnosis and regular monitoring. However, health-care providers are often short of human resources to closely monitor populations at risk. In this work, a video-based eye-tracking method is proposed as a low-cost alternative for detection of diabetic neuropathy. The method is based on the tracking of the eye-trajectories recorded on videos while the subject follows a target on a screen, forcing saccadic movements. Upon extraction of the eye trajectories, representation of the obtained time-series is made with the help of heteroscedastic ARX (H-ARX) models, which capture the dynamics and latency on the subject?s response, while features based on the H-ARX model?s predictive ability are subsequently used for classification. The methodology is evaluated on a population constituted by 11 control and 20 insulin-treated diabetic individuals suffering from diverse diabetic complications including neuropathy and retinopathy. Results show significant differences on latency and eye movement precision between the populations of control subjects and diabetics, while simultaneously demonstrating that both groups can be classified with an accuracy of 95%. Although this study is limited by the small sample size, the results align with other findings in the literature and encourage further research.",video-based eye tracking; diabetic neuropathy; computer-assisted diagnosis; heteroscedastic arx (h-arx) models
Article,"Xu, Jiawei; Zhang, Xiaoqin; Chen, Huiling; Li, Jing; Zhang, Jin; Shao, Ling; Wang, Gang",Automatic Analysis of Microaneurysms Turnover to Diagnose the Progression of Diabetic Retinopathy,ieee access,2018,Not found,"Diabetic retinopathy (DR) is one of the most common microvascular complications and its early detection is critical for the prevention of vision loss. Recent studies have indicated that microaneurysms (MAs) are the hallmark of DR. However, the detection of MAs relies on trained clinicians and relatively expensive software. Moreover, manual errors often lower the accuracy of this detection. Therefore, an automatic analysis technique is highly demanded in the detection of DR progression. In this paper, we present a novel and complete methodology involving two different ways from the view of MAs turnover and pathological risk factors to diagnose the progression of DR. Specifically, one approach follows the traditional image analysis-based roadmap to obtain MAs turnover. The other investigates seven pathological features, related with MAs turnover, to classify the unchanged, new, and resolved MAs by means of statistical analysis and pattern classification techniques. The evaluations on Grampian diabetes database show that the proposed image analysis method could achieve a sensitivity of 94% and a specificity of 93%, while the classification model could achieve 89% sensitivity and 88% specificity, respectively. We also analyzed the potential weight of pathological risk factors leading to the MAs turnover, which could provide an alternative guidance for the progression of DR than traditional detection methods. In conclusion, this study provides a novel and noninvasive detection technique for early diagnosis of diabetic retinopathy with a competitive accuracy.",mircoaneurysms turnover; lesion coordinates comparison; pathological risk factors
Article,"Aurangzeb, Khursheed; Aslam, Sheraz; Alhussein, Musaed; Naqvi, Rizwan Ali; Arsalan, Muhammad; Haider, Syed Irtaza",Contrast Enhancement of Fundus Images by Employing Modified PSO for Improving the Performance of Deep Learning Models,ieee access,2021,Not found,"Computer-Aided diagnosis (CAD) is a widely used technique to detect and diagnose diseases like tumors, cancers, edemas, etc. Several critical retinal diseases like diabetic retinopathy (DR), hypertensive retinopathy (HR), Macular degeneration, retinitis pigmentosa (RP) are mainly analyzed based on the observation of fundus images. The raw fundus images are of inferior quality to represent the minor changes directly. To detect and analyze minor changes in retinal vasculature or to apply advanced disease detection algorithms, the fundus image should be enhanced enough to visibly present vessel touristy. The performance of deep learning models for diagnosing these critical diseases is highly dependent on accurate segmentation of images. Specifically, for retinal vessels segmentation, accurate segmentation of fundus images is highly challenging due to low vessel contrast, varying widths, branching, and the crossing of vessels. For contrast enhancement, various retinal-vessel segmentation methods apply image-contrast enhancement as a pre-processing step, which can introduce noise in an image and affect vessel detection. Recently, numerous studies applied Contrast Limited Adaptive Histogram Equalization (CLAHE) for contrast enhancement, but with the default values for the contextual region and clip limit. In this study, our aim is to improve the performance of both supervised and unsupervised machine learning models for retinal-vessel segmentation by applying modified particle swarm optimization (MPSO) for CLAHE parameter tuning, with a specific focus on optimizing the clip limit and contextual regions. We subsequently assessed the capabilities of the optimized version of CLAHE using standard evaluation metrics. We used the contrast enhanced images achieved using MPSO-based CLAHE for demonstrating its real impact on performance of deep learning model for semantic segmentation of retinal images. The achieved results proved positive impact on sensitivity of supervised machine learning models, which is highly important. By applying the proposed approach on the enhanced retinal images of the publicly available databases of {DRIVE and STARE}, we achieved a sensitivity, specificity and accuracy of {0.8315 and 0.8433}, {0.9750 and 0.9760} and {0.9620 and 0.9645}, respectively.",image segmentation; diseases; deep learning; histograms; solid modeling; retinal vessels; semantics; cad tools; healthcare; contrast enhancement; clahe; pso; modified pso; semantic segmentation; deep learning
Article,"Ihnaini, Baha; Khan, M. A.; Khan, Tahir Abbas; Abbas, Sagheer; Daoud, Mohammad Sh; Ahmad, Munir; Khan, Muhammad Adnan",A Smart Healthcare Recommendation System for Multidisciplinary Diabetes Patients with Data Fusion Based on Deep Ensemble Learning,computational intelligence and neuroscience,2021,Not found,"The prediction of human diseases precisely is still an uphill battle task for better and timely treatment. A multidisciplinary diabetic disease is a life-threatening disease all over the world. It attacks different vital parts of the human body, like Neuropathy, Retinopathy, Nephropathy, and ultimately Heart. A smart healthcare recommendation system predicts and recommends the diabetic disease accurately using optimal machine learning models with the data fusion technique on healthcare datasets. Various machine learning models and methods have been proposed in the recent past to predict diabetes disease. Still, these systems cannot handle the massive number of multifeatures datasets on diabetes disease properly. A smart healthcare recommendation system is proposed for diabetes disease based on deep machine learning and data fusion perspectives. Using data fusion, we can eliminate the irrelevant burden of system computational capabilities and increase the proposed system's performance to predict and recommend this life-threatening disease more accurately. Finally, the ensemble machine learning model is trained for diabetes prediction. This intelligent recommendation system is evaluated based on a well-known diabetes dataset, and its performance is compared with the most recent developments from the literature. The proposed system achieved 99.6% accuracy, which is higher compared to the existing deep machine learning methods. Therefore, our proposed system is better for multidisciplinary diabetes disease prediction and recommendation. Our proposed system's improved disease diagnosis performance advocates for its employment in the automated diagnostic and recommendation systems for diabetic patients.",prediction
Article,"Ghosh, Swarup Kr; Biswas, Biswajit; Ghosh, Anupam",SDCA: a novel stack deep convolutional autoencoder - an application on retinal image denoising,iet image processing,2019,Not found,"Retinal fundus images are used for the diagnosis and treatment of various eye diseases such as diabetic retinopathy, glaucoma, exudates and so on. The retinal vasculature is difficult to investigate retinal conditions due to the presence of various noises in the retinal image during the capture of the image. Removal of noise is an important aspect for better visibility and diagnosis of the noisy fundus in ophthalmology. This study represents a deep learning based approach to denoising images and restoring features using stack denoising convolutional autoencoder. The proposed scheme is implemented to restore the structural details of fundus as well as to decrease the noise level. Furthermore, the proposed model utilises shared layers with the optimal manner to reduce the noise level of the target image with minimal computational cost. To restore an image, the proposed model brings a patched base training on samples to suppress with one to one manner without any loss of information. To access the denoising effect of the proposed scheme, several standard fundus databases such as DRIVE, STARE and DIARETDB1 have been tested in this study. Comparing the efficiency of the suggested model with state-of-art methods, the proposed scheme gives better result in terms of qualitative and quantitative analysis.",diseases; neural nets; blood vessels; medical image processing; learning (artificial intelligence); biomedical optical imaging; image denoising; convolution; eye; image segmentation; image representation; novel stack deep convolutional autoencoder; retinal image denoising; retinal fundus images; eye diseases; diabetic retinopathy; retinal vasculature; retinal conditions; visibility; noisy fundus; deep learning; denoising images; restoring features; noise level; target image; patched base training; denoising effect; standard fundus databases
Article; Early Access,"Sarki, Rubina; Ahmed, Khandakar; Wang, Hua; Zhang, Yanchun; Wang, Kate",Convolutional Neural Network for Multi-class Classification of Diabetic Eye Disease,eai endorsed transactions on scalable information systems,0,Not found,"Prompt examination increases the chances of effective treatment of Diabetic Eye Disease (DED) and reduces the likelihood of permanent deterioration of vision. A key tool commonly used for the initial diagnosis of patients with DED or other eye disorders is the screening of retinal fundus images. Manual detection with these images is, however, labour intensive and time consuming. As deep learning (DL) has recently been demonstrated to provide impressive benefits to clinical practice, researchers have attempted to use DL method to detect retinal eye diseases from retinal fundus photographs. DL techniques in machine learning (ML) have achieved state-of-the-art performance in the binary classification of healthy and diseased retinal fundus images while the classification of multi-class retinal eye diseases remains an open challenge. Multi-class DED is therefore considered in this study seeking to develop an automated classification framework for DED. Detecting multiple DEDs from retinal fundus images is an important research topic with practical consequences. Our proposed model was tested on various retinal fundus images gathered from the publicly available dataset and annotated by an ophthalmologist. This experiment was conducted employing a new convolutional neural network (CNN) model. Our proposed model for multi-class classification achieved a maximum accuracy of 81.33%, sensitivity of 100%, and specificity of 100%.",diabetic eye disease; deep learning; multi-class classification; image processing
Article,"Nayak, Deepak Ranjan; Das, Dibyasundar; Dash, Ratnakar; Majhi, Snehashis; Majhi, Banshidhar",Deep extreme learning machine with leaky rectified linear unit for multiclass classification of pathological brain images,multimedia tools and applications,2020,Not found,"Automatic binary classification of brain magnetic resonance (MR) images has made remarkable progress in the past decade. In comparison, a few pieces of work has been reported on multiclass classification of brain MR images. However, there exist enough scopes for improved automation and accuracy. Most of the existing schemes follow the multi-stage pipeline structure of conventional machine learning framework, where the features are designed manually or hand-crafted. In recent years, deep learning models have attracted great interest from researchers for analyzing medical images that eliminate the traditional steps of machine learning. In this paper, we present an automated method based on deep extreme learning machine (ELM) also termed as multilayer ELM (ML-ELM) for multiclass classification of the pathological brain. ML-ELM is a multilayer architecture stacked with ELM based autoencoders. The effectiveness of leaky rectified linear unit (LReLU) activation function is investigated with ML-ELM. Extensive simulations on a multiclass brain MR image dataset indicate that the ML-ELM with LReLU activation (ML-ELM+LReLU) achieves higher performance with faster training speed compared to its counterparts as well as state-of-the-art schemes. The basic purpose of employing ML-ELM+LReLU algorithm is to eliminate the need for hand-crafted feature extraction and to develop a more stable and generalized system for multiclass brain MR image classification.",deep learning; pathological brain; magnetic resonance imaging; leaky rectified linear unit; extreme learning machine
Article,"Lo, Ying-Chih; Lin, Keng-Hung; Bair, Henry; Sheu, Wayne Huey-Herng; Chang, Chi-Sen; Shen, Ying-Cheng; Hung, Che-Lun",Epiretinal Membrane Detection at the Ophthalmologist Level using Deep Learning of Optical Coherence Tomography,scientific reports,2020,Not found,"Purpose: Previous deep learning studies on optical coherence tomography (OCT) mainly focused on diabetic retinopathy and age-related macular degeneration. We proposed a deep learning model that can identify epiretinal membrane (ERM) in OCT with ophthalmologist-level performance. Design: Cross-sectional study. Participants: A total of 3,618 central fovea cross section OCT images from 1,475 eyes of 964 patients. Methods: We retrospectively collected 7,652 OCT images from 1,197 patients. From these images, 2,171 were normal and 1,447 were ERM OCT. A total of 3,141 OCT images was used as training dataset and 477 images as testing dataset. DL algorithm was used to train the interpretation model. Diagnostic results by four board-certified non-retinal specialized ophthalmologists on the testing dataset were compared with those generated by the DL model. Main Outcome Measures: We calculated for the derived DL model the following characteristics: sensitivity, specificity, F1 score and area under curve (AUC) of the receiver operating characteristic (ROC) curve. These were calculated according to the gold standard results which were parallel diagnoses of the retinal specialist. Performance of the DL model was finally compared with that of non-retinal specialized ophthalmologists. Results: Regarding the diagnosis of ERM in OCT images, the trained DL model had the following characteristics in performance: sensitivity: 98.7%, specificity: 98.0%, and F1 score: 0.945. The accuracy on the training dataset was 99.7% (95% CI: 99.4 - 99.9%), and for the testing dataset, diagnostic accuracy was 98.1% (95% CI: 96.5 - 99.1%). AUC of the ROC curve was 0.999. The DL model slightly outperformed the average non-retinal specialized ophthalmologists. Conclusions: An ophthalmologist-level DL model was built here to accurately identify ERM in OCT images. The performance of the model was slightly better than the average non-retinal specialized ophthalmologists. The derived model may play a role to assist clinicians to promote the efficiency and safety of healthcare in the future.",diabetic-retinopathy; risk-factors; classification; vitrectomy; validation; diseases
Review,"Wang, Lu; Wang, Hao; Xia, Chen; Wang, Yao; Tang, Qiaohong; Li, Jiage; Zhou, Xiao-Hua",Toward standardized premarket evaluation of computer aided diagnosis/detection products: insights from FDA-approved products,expert review of medical devices,2020,Not found,"Introduction Computer aided detection and diagnosis (CADe and CADx) products are an emerging branch of medical device industry. However, limited technical standard has been developed for product verification and validation. It will be helpful to investigate the current practice of preclinical and clinical evaluation of approved products and provide insights for future standardization. Areas covered Document review was conducted on 56 products approved by the United States Food and Drug Administration, including Summary of Safety and Effectiveness Data, 510(k) decision andde novodecision summaries. Key parameters describing product characteristics, preclinical studies and clinical studies were collected. Evaluation strategies for CADe/CADx products were analyzed and assessed. Expert opinion Preclinical studies were widely adopted in the verification of CADe/CADx products. Standalone performance testing was a common procedure, but the selection of testing dataset and performance metrics showed significant variability and flexibility among manufacturers. Clinical studies were reported by all class III products and some class II products, and Multi-Reader Multi-Case design was commonly used. However, statistical analysis and presentation/interpretation of results was oftentimes incomplete. To resolve above issues, systematic development of standards of CADe/CADx is encouraged, which can be implemented at different aspects through the product lifecycle.",computer aided detection; computer aided diagnosis; deep learning; medical device regulation; clinical study
Article,"Wang, Jing; Deng, Guohua; Li, Wanyue; Chen, Yiwei; Gao, Feng; Liu, Hu; He, Yi; Shi, Guohua",Deep learning for quality assessment of retinal OCT images,biomedical optics express,2019,Not found,"Optical coherence tomography (OCT) is a promising high-speed, non-invasive imaging modality providing high-resolution retinal scans. However, a variety of external factors such as light occlusion and patient movement can seriously degrade OCT image quality, which complicates manual retinopathy detection and computer-aided diagnosis. As such, this study first presents an OCT image quality assessment (OCT-IQA) system, capable of automatic classification based on signal completeness, location, and effectiveness. Four CNN architectures (VGG-16, Inception-V3, ResNet-18, and ResNet-50) from the ImageNet classification task were used to train the proposed OCT-IQA system via transfer learning. The ResNet-50 with the best performance was then integrated into the final OCT-IQA network. The usefulness of this approach was evaluated using retinopathy detection results. A retinopathy classification network was first trained by fine-tuning Inception-V3 model. The model was then applied to two test datasets, created randomly from the original dataset, one of which was screened by the OCT-IQA system and only included high quality images while the other was mixed by high and low quality images. Results showed that retinopathy detection accuracy and area under curve (AUC) were 3.75% and 1.56% higher, respectively, for the filtered data (compared with the unfiltered data). These experimental results demonstrate the effectiveness of the proposed OCT-IQA system and suggest that deep learning could be applied to the design of computer-aided systems (CADSs) for automatic retinopathy detection. (C) 2019 Optical Society of America under the terms of the OSA Open Access Publishing Agreement",optical coherence tomography; diabetic macular edema; degeneration; classification
Article,"Sethuraman, Srivaradharajan; Gopi, Varun Palakuzhiyil",Staircase-Net: a deep learning based architecture for retinal blood vessel segmentation,sadhana-academy proceedings in engineering sciences,2022,Not found,"The retina is one of the most metabolically active tissues in the human body. The retinal vessels provide blood to the inner retinal neurons. The retinal blood vessels are affected by diseases such as Hypertensive retinopathy and Diabetic retinopathy. The early diagnosis prevents the patients from blindness and fatality in some cases. Thus, examining the retinal blood vessels becomes an important work of an ophthalmologist. Thus, automated retinal blood vessel segmentation aids the ophthalmologist and makes their work easier. In this paper, a supervised Convolutional Neural Network (CNN) is suggested that enhances the performance of retinal blood vessel segmentation. Three publicly available datasets are used: STARE, DRIVE, and CHASE_DB1. A novel model, 'Staircase-Net,' is proposed, which has a series of up-sampling and down-sampling processes for feature extraction (extracting the thick and thin blood vessel features, respectively). The images in the datasets undergo a series of transformations in the preprocessing steps. The evaluation metrics considered are specificity, accuracy, sensitivity, and area under the curve. Finally, the proposed model results are compared with the state-of-the-art techniques.",retinal vessel; segmentation; convolutional neural network; fundus image
Article,"Yadav, Sonal; Das, Sanjoy; Murugan, R.; Dutta Roy, Sumantra; Agrawal, Monika; Goel, Tripti; Dutta, Anurag",Performance analysis of deep neural networks through transfer learning in retinal detachment diagnosis using fundus images,sadhana-academy proceedings in engineering sciences,2022,Not found,"Retinal detachment (RD) is a severe condition that causes decreased visual acuity and blindness if left untreated timely. The early screening and identification of retinal detachment can ameliorate the successful rate of visible results and RD. The manual screening of retinal detachment is a labor-intensive and time-consuming task. This paper is concerned with pre-trained deep learning networks for feature extraction and classification. Deep learning models need large amounts of training data since they involve many parameters. This is a severe problem in medical informatics where the amount of data available is very low, and ground truth data is a small fraction of the same. The domain of Retinal Detachment (RD) is no different. Typical public domain databases related to RD typically have a few hundred images, leading to fitting issues for deep learning models. This work investigates the role of transfer learning for feature extraction and classification of RD and Non-RD color fundus images. We have also analyzed the performance of different deep neural networks through fundus imaging to detect (RD) eyes and Non-RD eyes. The deep convolutional networks such as AlexNet, InceptionV3, GoogleNet, VGG19, DenseNet, and ResNet50 were trained and tested on publically available datasets of RD and Non-RD fundus images. A ResNet50 framework through transfer learning shows the best classification performance in terms of Accuracy, Sensitivity, Specificity, Precision, and F1 score values of 99.50%, 99.00%, 99.99%, 99.99%, and 99.49%, respectively, and best for detecting RD and Non-RD fundus images compared to other learning models. This study inferred the promising results for a diagnostic system for retinal detachment with relatively high sensitivity and specificity.",retina; fundus images; retinal detachment; image classification; convolutional neural network
Proceedings Paper,"Lin, Zhiwen; Guo, Ruoqian; Wang, Yanjie; Wu, Bian; Chen, Tingting; Wang, Wenzhe; Chen, Danny Z.; Wu, Jian",A Framework for Identifying Diabetic Retinopathy Based on Anti-noise Detection and Attention-Based Fusion,"medical image computing and computer assisted intervention - miccai 2018, pt ii",2018,Not found,"Automatic diagnosis of diabetic retinopathy (DR) using retinal fundus images is a challenging problem because images of low grade DR may contain only a few tiny lesions which are difficult to perceive even to human experts. Using annotations in the form of lesion bounding boxes may help solve the problem by deep learning models, but fully annotated samples of this type are usually expensive to obtain. Missing annotated samples (i.e., true lesions but not included in annotations) are noise and can affect learning models negatively. Besides, how to utilize lesion information for identifying DR should be considered carefully because different types of lesions may be used to distinguish different DR grades. In this paper, we propose a new framework for unifying lesion detection and DR identification. Our lesion detection model first determines the missing annotated samples to reduce their impact on the model, and extracts lesion information. Our attention-based network then fuses original images and lesion information to identify DR. Experimental results show that our detection model can considerably reduce the impact of missing annotation and our attention-based network can learn weights between the original images and lesion information for distinguishing different DR grades. Our approach outperforms state-of-the-art methods on two grand challenge retina datasets, EyePACS and Messidor.",not found
Proceedings Paper,"Elsharkawy, Mohamed; Sharafeldeen, Ahmed; Soliman, Ahmed; Khalifa, Fahmi; Ghazal, Mohammed; El-Daydamony, Eman; Atwan, Ahmed; Sandhu, Harpal Singh; El-Baz, Ayman",DIABETIC RETINOPATHY DIAGNOSTIC CAD SYSTEM USING 3D-OCT HIGHER ORDER SPATIAL APPEARANCE MODEL,2022 ieee international symposium on biomedical imaging (ieee isbi 2022),2022,Not found,"Diagnoses of Diabetic Retinopathy (DR) at an early stage are of extreme importance so that the retina can be preserved and the risk of substantial damage to the retina or loss of vision is reduced. A new Computer-Aided Diagnosis (CAD) method based on Optical Coherence Tomography (OCT) scans of the retina is presented here for the detection of DR at an early stage. Utilizing an adaptive appearancebased approach that uses prior shape information, the system segments the retinal layers from the 3D-OCT scans. From the layers segmented from the B-scans volume of the OCT, novel texture features are extracted for DR diagnosis. In particular, a 2(nd) -order reflectivity value is calculated for each individual layer using the 2D Markov-Gibbs Random Field (2D-MGRF) model. Then, Cumulative Distribution Function (CDF) descriptors are used to represent the extracted image-derived feature using CDF's percentiles. A feedforward neural network is used for layer-by-layer classification of 3D volume using Gibbs energy features extracted from each individual layer. In the final stage, all twelve layers are fused with a global subject diagnosis based on a majority voting method. We evaluated a 3D-OCT system using 180 subjects using a combination of different k-fold validation techniques. The system performance for this CAD system using 4-, 5-, and 10-fold cross validation achieved accuracies of 89.4%, 91.5%, and 95.7%, respectively. In addition, our system's ability to detect the DR early has been validated by further comparisons with the state-of-the-art deep learning networks.",3-d oct; dr; cad; 2d-mgrf
Article,"Yousef, Rammah; Gupta, Gaurav; Yousef, Nabhan; Khari, Manju",A holistic overview of deep learning approach in medical imaging,multimedia systems,2022,Not found,"Medical images are a rich source of invaluable necessary information used by clinicians. Recent technologies have introduced many advancements for exploiting the most of this information and use it to generate better analysis. Deep learning (DL) techniques have been empowered in medical images analysis using computer-assisted imaging contexts and presenting a lot of solutions and improvements while analyzing these images by radiologists and other specialists. In this paper, we present a survey of DL techniques used for variety of tasks along with the different medical image's modalities to provide critical review of the recent developments in this direction. We have organized our paper to provide significant contribution of deep leaning traits and learn its concepts, which is in turn helpful for non-expert in medical society. Then, we present several applications of deep learning (e.g., segmentation, classification, detection, etc.) which are commonly used for clinical purposes for different anatomical site, and we also present the main key terms for DL attributes like basic architecture, data augmentation, transfer learning, and feature selection methods. Medical images as inputs to deep learning architectures will be the mainstream in the coming years, and novel DL techniques are predicted to be the core of medical images analysis. We conclude our paper by addressing some research challenges and the suggested solutions for them found in literature, and also future promises and directions for further developments.",medical imaging; deep learning (dl); medical data augmentation; transfer learning
Article,"Thakoor, Kaveri A.; Koorathota, Sharath C.; Hood, Donald C.; Sajda, Paul",Robust and Interpretable Convolutional Neural Networks to Detect Glaucoma in Optical Coherence Tomography Images,ieee transactions on biomedical engineering,2021,Not found,"Recent studies suggest that deep learning systems can now achieve performance on par with medical experts in diagnosis of disease. A prime example is in the field of ophthalmology, where convolutional neural networks (CNNs) have been used to detect retinal and ocular diseases. However, this type of artificial intelligence (AI) has yet to be adopted clinically due to questions regarding robustness of the algorithms to datasets collected at new clinical sites and a lack of explainability of AI-based predictions, especially relative to those of human expert counterparts. In this work, we develop CNN architectures that demonstrate robust detection of glaucoma in optical coherence tomography (OCT) images and test with concept activation vectors (TCAVs) to infer what image concepts CNNs use to generate predictions. Furthermore, we compare TCAV results to eye fixations of clinicians, to identify common decision-making features used by both AI and human experts. We find that employing fine-tuned transfer learning and CNN ensemble learning create end-to-end deep learning models with superior robustness compared to previously reported hybrid deep-learning/machine-learning models, and TCAV/eye-fixation comparison suggests the importance of three OCT report sub-images that are consistent with areas of interest fixated upon by OCT experts to detect glaucoma. The pipeline described here for evaluating CNN robustness and validating interpretable image concepts used by CNNs with eye movements of experts has the potential to help standardize the acceptance of new AI tools for use in the clinic.",deep learning; training; testing; robustness; retina; feature extraction; data models; computer-aided decision support; deep learning; eye tracking; medical expert systems; optical coherence tomography; robustness
Article,"Liu, James; Gibson, Ella; Ramchal, Shawn; Shankar, Vikram; Piggott, Kisha; Sychev, Yevgeniy; Li, Albert S.; Rao, Prabakar K.; Margolis, Todd P.; Fondahn, Emily; Bhaskaranand, Malavika; Solanki, Kaushal; Rajagopal, Rithwick",Diabetic Retinopathy Screening with Automated Retinal Image Analysis in a Primary Care Setting Improves Adherence to Ophthalmic Care,ophthalmology retina,2021,Not found,"Purpose: Retinal screening examinations can prevent vision loss resulting from diabetes but are costly and highly underused. We hypothesized that artificial intelligence-assisted nonmydriatic point-of-care screening administered during primary care visits would increase the adherence to recommendations for follow-up eye care in patients with diabetes. Design: Prospective cohort study. Participants: Adults 18 years of age or older with a clinical diagnosis of diabetes being cared for in a metropolitan primary care practice for low-income patients. Methods: All participants underwent nonmydriatic fundus photography followed by automated retinal image analysis with human supervision. Patients with positive or inconclusive screening results were referred for comprehensive ophthalmic evaluation. Adherence to referral recommendations was recorded and compared with the historical adherence rate from the same clinic. Main Outcome Measure: Rate of adherence to eye screening recommendations. Results: By automated screening, 8.3% of the 180 study participants had referable diabetic eye disease, 13.3% had vision-threatening disease, and 29.4% showed inconclusive results. The remaining 48.9% showed negative screening results, confirmed by human overread, and were not referred for follow-up ophthalmic evaluation. Overall, the automated platform showed a sensitivity of 100% (confidence interval, 92.3%-100%) in detecting an abnormal screening results, whereas its specificity was 65.7% (confidence interval, 57.0%-73.7%). Among patients referred for follow-up ophthalmic evaluation, the adherence rate was 55.4% at 1 year compared with the historical adherence rate of 18.7% (P < 0.0001, Fisher exact test). Conclusions: Implementation of an automated diabetic retinopathy screening system in a primary care clinic serving a low-income metropolitan patient population improved adherence to follow-up eye care recommendations while reducing referrals for patients with low-risk features. (C) 2020 by the American Academy of Ophthalmology",eye-care; telemedicine; patterns
Article,"Zong, Yongshuo; Chen, Jinling; Yang, Lvqing; Tao, Siyi; Aoma, Cieryouzhen; Zhao, Jiangsheng; Wang, Shuihua",U-net Based Method for Automatic Hard Exudates Segmentation in Fundus Images Using Inception Module and Residual Connection,ieee access,2020,Not found,"Diabetic retinopathy (DR) is an eye abnormality caused by chronic diabetes that affected patients worldwide. Hard exudate is an important and observable sign of DR and can be used for early diagnosis. In this paper, an automatic hard exudates segmentation method is proposed in order to aid ophthalmologists to diagnose DR in the early stage. We utilized the SLIC superpixel algorithm to generate sample patches, thus overcoming the difficulty of the limited and imbalanced dataset. Furthermore, a U-net based network architecture with inception modules and residual connections is proposed to conduct end-to-end hard exudate segmentation, and focal loss is utilized as the loss function. Extensive experiments have been conducted on the IDRiD dataset to evaluate the performance of the proposed method. The reported sensitivity, specificity, and accuracy achieve 96.38%, 97.14%, and 97.95% respectively, which demonstrates the effectiveness and superiority of our method. The achieved segmentation results prove the potential of the method for clinical diagnosis.",image segmentation; feature extraction; machine learning; diabetes; biomedical imaging; classification algorithms; image color analysis; deep learning; diabetic retinopathy; exudates segmentation; superpixel; u-net
Article,"Guo, Song; Wang, Kai; Kang, Hong; Liu, Teng; Gao, Yingqi; Li, Tao",Bin loss for hard exudates segmentation in fundus images,neurocomputing,2020,Not found,"Diabetic retinopathy is one of the leading reasons that causes blindness. And the segmentation of hard exudates in color fundus images is crucial for early diagnosis of diabetic retinopathy, which is a difficult task due to its uncertainty in size, shape and contrast. Class-balanced cross entropy (CBCE) loss is the most popular objective function for image segmentation task to solve the class-unbalance problem. However, we show that background pixels tend to be misclassified to hard exudates in CBCE since the loss for a misclassified background pixels is much smaller than that for a misclassified hard exudate pixel, which is called loss-unbalance problem here. A top-k loss is proposed in this paper, which considers the cases of both class-unbalance and loss-unbalance by focusing more over the hard-to-classify pixels. Moreover, a fast version of the top-k loss, named bin loss, is implemented for efficiency, which reduces the time complexity from O(nlog n) of top-k loss to O(n), where n is the number of background pixels. We evaluated the proposed bin loss over two public datasets for hard exudates segmentation task, including e-ophtha EX and IDRiD. Furthermore, three popular models for image segmentation, HED, DeepLab v2, and FCRN, were used to evaluate the versatility of bin loss. Extensive experiments show that each model with the proposed bin loss performs better than that with CBCE loss, which demonstrates bin loss is versatile so that it can be applied to different models for performance improvement. Specially, for DeepLab over e-ophtha EX, the F-score increases 5.2 percentage points, and the area under the SE-PPV curve (AUC) increases 10.6 percentage points. Moreover, the AUC increases more than 4 percentage points over IDRiD dataset for both DeepLab and FCRN. The source code of bin loss is available at: https://github.com/guomugong/bin_loss. (C) 2019 Elsevier B.V. All rights reserved.",hard exudates segmentation; diabetic retinopathy; bin loss; deep learning; fundus image
Article,"Gu, Hao; Guo, Youwen; Gu, Lei; Wei, Anji; Xie, Shirong; Ye, Zhengqiang; Xu, Jianjiang; Zhou, Xingtao; Lu, Yi; Liu, Xiaoqing; Hong, Jiaxu",Deep learning for identifying corneal diseases from ocular surface slit-lamp photographs,scientific reports,2020,Not found,"To demonstrate the identification of corneal diseases using a novel deep learning algorithm. A novel hierarchical deep learning network, which is composed of a family of multi-task multi-label learning classifiers representing different levels of eye diseases derived from a predefined hierarchical eye disease taxonomy was designed. Next, we proposed a multi-level eye disease-guided loss function to learn the fine-grained variability of eye diseases features. The proposed algorithm was trained end-to-end directly using 5,325 ocular surface images from a retrospective dataset. Finally, the algorithm's performance was tested against 10 ophthalmologists in a prospective clinic-based dataset with 510 outpatients newly enrolled with diseases of infectious keratitis, non-infectious keratitis, corneal dystrophy or degeneration, and corneal neoplasm. The area under the ROC curve of the algorithm for each corneal disease type was over 0.910 and in general it had sensitivity and specificity similar to or better than the average values of all ophthalmologists. Confusion matrices revealed similarities in misclassification between human experts and the algorithm. In addition, our algorithm outperformed over all four previous reported methods in identified corneal diseases. The proposed algorithm may be useful for computer-assisted corneal disease diagnosis.",diabetic-retinopathy; macular degeneration; automated detection; validation; algorithm; blindness
Article,"Javidi, Malihe; Harati, Ahad; Pourreza, HamidReza",Retinal image assessment using bi-level adaptive morphological component analysis,artificial intelligence in medicine,2019,Not found,"The automated analysis of retinal images is a widely researched area which can help to diagnose several diseases like diabetic retinopathy in early stages of the disease. More specifically, separation of vessels and lesions is very critical as features of these structures are directly related to the diagnosis and treatment process of diabetic retinopathy. The complexity of the retinal image contents especially in images with severe diabetic retinopathy makes detection of vascular structure and lesions difficult. In this paper, a novel framework based on morphological component analysis (MCA) is presented which benefits from the adaptive representations obtained via dictionary learning. In the proposed Bi-level Adaptive MCA (BAMCA), MCA is extended to locally deal with sparse representation of the retinal images at patch level whereas the decomposition process occurs globally at the image level. BAMCA method with appropriately offline learnt dictionaries is adopted to work on retinal images with severe diabetic retinopathy in order to simultaneously separate vessels and exudate lesions as diagnostically useful morphological components. To obtain the appropriate dictionaries, K-SVD dictionary learning algorithm is modified to use a gated error which guides the process toward learning the main structures of the retinal images using vessel or lesion maps. Computational efficiency of the proposed framework is also increased significantly through some improvement leading to noticeable reduction in run time. We experimentally show how effective dictionaries can be learnt which help BAMCA to successfully separate exudate and vessel components from retinal images even in severe cases of diabetic retinopathy. In this paper, in addition to visual qualitative assessment, the performance of the proposed method is quantitatively measured in the framework of vessel and exudate segmentation. The reported experimental results on public datasets demonstrate that the obtained components can be used to achieve competitive results with regard to the state-of-the-art vessel and exudate segmentation methods.",bi-level adaptive morphological component analysis; dictionary learning; diabetic retinopathy image assessment
Article,"Jiang, Yukang; Pan, Jianying; Yuan, Ming; Shen, Yanhe; Zhu, Jin; Wang, Yishen; Li, Yewei; Zhang, Ke; Yu, Qingyun; Xie, Huirui; Li, Huiting; Wang, Xueqin; Luo, Yan",Segmentation of Laser Marks of Diabetic Retinopathy in the Fundus Photographs Using Lightweight U-Net,journal of diabetes research,2021,Not found,"Diabetic retinopathy (DR) is a prevalent vision-threatening disease worldwide. Laser marks are the scars left after panretinal photocoagulation, a treatment to prevent patients with severe DR from losing vision. In this study, we develop a deep learning algorithm based on the lightweight U-Net to segment laser marks from the color fundus photos, which could help indicate a stage or providing valuable auxiliary information for the care of DR patients. We prepared our training and testing data, manually annotated by trained and experienced graders from Image Reading Center, Zhongshan Ophthalmic Center, publicly available to fill the vacancy of public image datasets dedicated to the segmentation of laser marks. The lightweight U-Net, along with two postprocessing procedures, achieved an AUC of 0.9824, an optimal sensitivity of 94.16%, and an optimal specificity of 92.82% on the segmentation of laser marks in fundus photographs. With accurate segmentation and high numeric metrics, the lightweight U-Net method showed its reliable performance in automatically segmenting laser marks in fundus photographs, which could help the AI assist the diagnosis of DR in the severe stage.</p>",not found
Article,"Ragab, Mahmoud; AL-Ghamdi, Abdullah S. AL-Malaise; Fakieh, Bahjat; Choudhry, Hani; Mansour, Romany F.; Koundal, Deepika",Prediction of Diabetes through Retinal Images Using Deep Neural Network,computational intelligence and neuroscience,2022,Not found,"Microvascular problems of diabetes, such as diabetic retinopathy and macular edema, can be seen in the eye's retina, and the retinal images are being used to screen for and diagnose the illness manually. Using deep learning to automate this time-consuming process might be quite beneficial. In this paper, a deep neural network, i.e., convolutional neural network, has been proposed for predicting diabetes through retinal images. Before applying the deep neural network, the dataset is preprocessed and normalised for classification. Deep neural network is constructed by using 7 layers, 5 kernels, and ReLU activation function, and MaxPooling is implemented to combine important features. Finally, the model is implemented to classify whether the retinal image belongs to a diabetic or nondiabetic class. The parameters used for evaluating the model are accuracy, precision, recall, and F1 score. The implemented model has achieved a training accuracy of more than 95%, which is much better than the other states of the art algorithms.",diagnosis
Proceedings Paper,"Adeyinka, Adegun Adekanmi; Adebiyi, Marion Olubunmi; Akande, Noah Oluwatobi; Ogundokun, Roseline Oluwaseun; Kayode, Anthonia Aderonke; Oladele, Tinuke Omolewa",A Deep Convolutional Encoder-Decoder Architecture for Retinal Blood Vessels Segmentation,"computational science and its applications - iccsa 2019, pt v: 19th international conference, saint petersburg, russia, july 14, 2019, proceedings, part v",2019,Not found,"Over the last decades, various methods have been employed in medical images analysis. Some state-of-the-arts techniques such as deep learning have been recently applied to medical images analysis. This research proposes the application of deep learning technique in performing segmentation of retinal blood vessels. Analyzing and segmentation of retina vessels has assisted in diagnosis and monitoring of some diseases. Diseases such as age-related fovea degeneration, diabetic retinopathy, glaucoma, hypertension, arteriosclerosis and choroidal neovascularization can be effectively managed by the analysis of retinal vessels images. In this work, a Deep Convolutional Encoder-Decoder Architecture for the segmentation of retinal vessels images is proposed. The proposed method is a deep learning system composed of an encoder and decoder mechanism allows a low resolution image set of retinal vessels to be analyzed by set of convolutional layers in the encoder unit before been sent into a decoder unit for final segmented output. The proposed system was evaluated using some evaluation metrics such as dice coefficient, jaccard index and mean of intersection. The review of the existing works was also carried out. It could be shown that the proposed system outperforms many existing methods in the segmentation of retinal vessels images.",retinal vessels; deep learning; convolutional layers; encoder; decoder; images; segmentation
Article,"Liu, Sidong; Graham, Stuart L.; Schulz, Angela; Kalloniatis, Michael; Zangerl, Barbara; Cai, Weidong; Gao, Yang; Chua, Brian; Arvind, Hemamalini; Grigg, John; Chu, Dewei; Klistorner, Alexander; You, Yuyi",A Deep Learning-Based Algorithm Identifies Glaucomatous Discs Using Monoscopic Fundus Photographs,ophthalmology glaucoma,2018,Not found,"Purpose: To develop and test the performance of a deep learning-based algorithm for glaucomatous disc identification using monoscopic fundus photographs. Design: Fundus photograph database study. Participants: Four thousand three hundred ninety-four fundus photographs, including 3768 images from previous Sydney-based clinical studies and 626 images from publicly available online RIM-ONE and High-Resolution Fundus (HRF) databases with definitive diagnoses. Methods: We merged all databases except the HRF database, and then partitioned the dataset into a training set (80% of all cases) and a testing set (20% of all cases). We used the HRF images as an additional testing set. We compared the performance of the artificial intelligence (Al) system against a panel of practicing ophthalmologists including glaucoma subspecialists from Australia, New Zealand, Canada, and the United Kingdom. Main Outcome Measures: The sensitivity and specificity of the Al system in detecting glaucomatous optic discs. Results: By using monoscopic fundus photographs, the Al system demonstrated a high accuracy rate in glaucomatous disc identification (92.7%; 95% confidence interval [CI], 91.2%-94.2%), achieving 89.3% sensitivity (95% CI, 86.8%-91.7%) and 97.1% specificity (95% CI, 96.1 %-98.1 %), with an area under the receiver operating characteristic curve of 0.97 (95% CI, 0.96-0.98). Using the independent online HRF database (30 images), the Al system again accomplished high accuracy, with 86.7% in both sensitivity and specificity (for ophthalmologists, 75.6% sensitivity and 77.8% specificity) and an area under the receiver operating characteristic curve of 0.89 (95% CI, 0.76-1.00). Conclusions: This study demonstrated that a deep learning-based algorithm can identify glaucomatous discs at high accuracy level using monoscopic fundus images. Given that it is far easier to obtain monoscopic disc images than high-quality stereoscopic images, this study highlights the algorithm's potential application in large population-based disease screening or telemedicine programs. (C) 2018 by the American Academy of Ophthalmology",diabetic-retinopathy; prevalence; features
Article,"Song, Jingqi; Zheng, Yuanjie; Wang, Jing; Ullah, Muhammad Zakir; Jiao, Wanzhen",Multicolor image classification using the multimodal information bottleneck network (MMIB-Net) for detecting diabetic retinopathy,optics express,2021,Not found,"Multicolor (MC) imaging is an imaging modality that records confocal scanning laser ophthalmoscope (cSLO) fundus images, which can be used for the diabetic retinopathy (DR) detection. By utilizing this imaging technique, multiple modal images can be obtained in a single case. Additional symptomatic features can be obtained if these images are considered during the diagnosis of DR. However, few studies have been carried out to classify MC Images using deep learning methods, let alone using multi modal features for analysis. In this work, we propose a novel model which uses the multimodal information bottleneck network (MMIB-Net) to classify the MC Images for the detection of DR. Our model can extract the features of multiple modalities simultaneously while finding concise feature representations of each modality using the information bottleneck theory. MC Images classification can be achieved by picking up the combined representations and features of all modalities. In our experiments, it is shown that the proposed method can achieve an accurate classification of MC Images. Comparative experiments also demonstrate that the use of multimodality and information bottleneck improves the performance of MC Images classification. To the best of our knowledge, this is the first report of DR identification utilizing the multimodal information bottleneck convolutional neural network in MC Images. (C) 2021 Optical Society of America under the terms of the OSA Open Access Publishing Agreement",retinal lesions; neural-network
Proceedings Paper,"AhmadChoudhry, Zainoor; Shahid, Hira; Naqvi, Syed Zohaib Hassan; Aziz, Sumair; Khan, Muhammad Umar",DarkNet-19 based Decision Algorithm for the Diagnosis of Ophthalmic Disorders,4th international conference on innovative computing (ic)2,2021,Not found,"Performing different medical examinations primarily of which are visual examinations can prove to be beneficial for identification of retinal diseases. An upcoming interdisciplinary technology; computer-aided medical diagnostic system eliminates one of the key issues in the visual diagnosis of diseases caused by human error due to poor decision making. It provides precise detection and prediction of disease. In our proposed methodology, images were treated with Contrast Limited Adaptive Histogram Equalization followed by deep features extraction from the enhanced images. ADASYN was also applied to acquire a balanced dataset. Support Vector Machine classifier has yielded a mean accuracy of 93.8%.",artificial intelligence; retinal diseases; deep features; clahe; cnn; adasyn
Article,"Yildirim, Ozal; Talo, Muhammed; Ay, Betul; Baloglu, Ulas Baran; Aydin, Galip; Acharya, U. Rajendra",Automated detection of diabetic subject using pre-trained 2D-CNN models with frequency spectrum images extracted from heart rate signals,computers in biology and medicine,2019,Not found,"In this study, a deep-transfer learning approach is proposed for the automated diagnosis of diabetes mellitus (DM), using heart rate (HR) signals obtained from electrocardiogram (ECG) data. Recent progress in deep learning has contributed significantly to improvement in the quality of healthcare. In order for deep learning models to perform well, large datasets are required for training. However, a difficulty in the biomedical field is the lack of clinical data with expert annotation. A recent, commonly implemented technique to train deep learning models using small datasets is to transfer the weighting, developed from a large dataset, to the current model. This deep learning transfer strategy is generally employed for two-dimensional signals. Herein, the weighting of models pre-trained using two-dimensional large image data was applied to one-dimensional HR signals. The one-dimensional HR signals were then converted into frequency spectrum images, which were utilized for application to well-known pre-trained models, specifically: AlexNet, VggNet, ResNet, and DenseNet. The DenseNet pre-trained model yielded the highest classification average accuracy of 97.62%, and sensitivity of 100%, to detect DM subjects via HR signal recordings. In the future, we intend to further test this developed model by utilizing additional data along with cloud-based storage to diagnose DM via heart signal analysis.",diabetes mellitus; heart rate signals; deep learning; transfer learning
Article,"Hassan, Bilal; Hassan, Taimur; Li, Bo; Ahmed, Ramsha; Hassan, Omar",Deep Ensemble Learning Based Objective Grading of Macular Edema by Extracting Clinically Significant Findings from Fused Retinal Imaging Modalities,sensors,2019,Not found,"Macular edema (ME) is a retinal condition in which central vision of a patient is affected. ME leads to accumulation of fluid in the surrounding macular region resulting in a swollen macula. Optical coherence tomography (OCT) and the fundus photography are the two widely used retinal examination techniques that can effectively detect ME. Many researchers have utilized retinal fundus and OCT imaging for detecting ME. However, to the best of our knowledge, no work is found in the literature that fuses the findings from both retinal imaging modalities for the effective and more reliable diagnosis of ME. In this paper, we proposed an automated framework for the classification of ME and healthy eyes using retinal fundus and OCT scans. The proposed framework is based on deep ensemble learning where the input fundus and OCT scans are recognized through the deep convolutional neural network (CNN) and are processed accordingly. The processed scans are further passed to the second layer of the deep CNN model, which extracts the required feature descriptors from both images. The extracted descriptors are then concatenated together and are passed to the supervised hybrid classifier made through the ensemble of the artificial neural networks, support vector machines and naive Bayes. The proposed framework has been trained on 73,791 retinal scans and is validated on 5100 scans of publicly available Zhang dataset and Rabbani dataset. The proposed framework achieved the accuracy of 94.33% for diagnosing ME and healthy subjects and achieved the mean dice coefficient of 0.9019 +/- 0.04 for accurately extracting the retinal fluids, 0.7069 +/- 0.11 for accurately extracting hard exudates and 0.8203 +/- 0.03 for accurately extracting retinal blood vessels against the clinical markings.",biomedical image processing; image analysis; image classification; machine intelligence; machine vision; optical coherence tomography; fundus photography
Review,"Iqbal, Shahzaib; Khan, Tariq M.; Naveed, Khuram; Naqvi, Syed S.; Nawaz, Syed Junaid",Recent trends and advances in fundus image analysis: A review,computers in biology and medicine,2022,Not found,"Automated retinal image analysis holds prime significance in the accurate diagnosis of various critical eye diseases that include diabetic retinopathy (DR), age-related macular degeneration (AMD), atherosclerosis, and glaucoma. Manual diagnosis of retinal diseases by ophthalmologists takes time, effort, and financial resources, and is prone to error, in comparison to computer-aided diagnosis systems. In this context, robust classification and segmentation of retinal images are primary operations that aid clinicians in the early screening of patients to ensure the prevention and/or treatment of these diseases. This paper conducts an extensive review of the state-of-the-art methods for the detection and segmentation of retinal image features. Existing notable techniques for the detection of retinal features are categorized into essential groups and compared in depth. Additionally, a summary of quantifiable performance measures for various important stages of retinal image analysis, such as image acquisition and preprocessing, is provided. Finally, the widely used in the literature datasets for analyzing retinal images are described and their significance is emphasized.",classification; segmentation; retinal fundus images; eye diseases; hypertensive retinopathy; diabetic retinopathy
Article; Early Access,"Gadde, Sai Sudha; Kiran, K. V. D.",Entropy-Based Feature Extraction Model for Fundus Images with Deep Learning Model,international journal of image and graphics,0,Not found,"Diabetic retinopathy (DR) is stated as a disease in the eyes that affects the retina blood vessels and causes blindness. The early diagnosis and detection of the DR in patients preserve the patient's vision. In general, for the diagnosis of eye diseases, retinal fundus images are employed. The advancement in the automatic diagnosis of diseases attained higher significance for rapid advancement in computing technology in the medical field. Besides, for the diagnosis of the diseases, fundus image automatic detection is involved in the recognition of blood vessels evaluated based on the length, branching pattern, and width. However, fundus images have low contrast and it is difficult to evaluate the identification of the disease in blood vessels. As a result, it is necessary to adopt a consistent automated method to extract blood vessels in the fundus images for DR. The conventional automated localization of the macula and optic disk in the retinal fundus images needs to be improved for DR disease diagnosis. But existing methods are not sufficient for the early identification and detection of DR. This paper proposed an entropy distributed matching global and local clustering (EDMGL) for fundus images. The developed EDMGL comprises the different uncertainties for the evaluation of the classes based on local and global entropy. The fundus image local entropy is evaluated based on the spatial likelihood fuzzifier membership function estimation for segmentation. The final proposed algorithm membership function is estimated using the addition of weighted parameters through membership estimation based on the global and local entropy. The classification performance of the proposed EDMGL is evaluated based on the dice coefficient, segmentation accuracy, and partition entropy. The performance of the proposed EDMGL is comparatively examined with the conventional technique. The comparative analysis expressed that the performance of the proposed EDMGL exhibits similar to 5% improved performance in terms of accuracy, precision, recall, and F1-score.",segmentation; fundus images; dice coefficient; global entropy; local entropy
Article,"Cen, Ling-Ping; Ji, Jie; Lin, Jian-Wei; Ju, Si-Tong; Lin, Hong-Jie; Li, Tai-Ping; Wang, Yun; Yang, Jian-Feng; Liu, Yu-Fen; Tan, Shaoying; Tan, Li; Li, Dongjie; Wang, Yifan; Zheng, Dezhi; Xiong, Yongqun; Wu, Hanfu; Jiang, Jingjing; Wu, Zhenggen; Huang, Dingguo; Shi, Tingkun; Chen, Binyao; Yang, Jianling; Zhang, Xiaoling; Luo, Li; Huang, Chukai; Zhang, Guihua; Huang, Yuqiang; Ng, Tsz Kin; Chen, Haoyu; Chen, Weiqi; Pang, Chi Pui; Zhang, Mingzhi",Automatic detection of 39 fundus diseases and conditions in retinal photographs using deep neural networks,nature communications,2021,Not found,"Retinal fundus diseases can lead to irreversible visual impairment without timely diagnoses and appropriate treatments. Single disease-based deep learning algorithms had been developed for the detection of diabetic retinopathy, age-related macular degeneration, and glaucoma. Here, we developed a deep learning platform (DLP) capable of detecting multiple common referable fundus diseases and conditions (39 classes) by using 249,620 fundus images marked with 275,543 labels from heterogenous sources. Our DLP achieved a frequency-weighted average F1 score of 0.923, sensitivity of 0.978, specificity of 0.996 and area under the receiver operating characteristic curve (AUC) of 0.9984 for multi-label classification in the primary test dataset and reached the average level of retina specialists. External multihospital test, public data test and tele-reading application also showed high efficiency for multiple retinal diseases and conditions detection. These results indicate that our DLP can be applied for retinal fundus disease triage, especially in remote areas around the world. Systems for automatic detection of a single disease may miss other important conditions. Here, the authors show a deep learning platform can detect 39 common retinal diseases and conditions.",diabetic-retinopathy; macular degeneration; artificial-intelligence; global prevalence; risk-factors; images; classification; validation
Article,"Li, Yiming; Wei, Dong; Liu, Xing; Fan, Xing; Wang, Kai; Li, Shaowu; Zhang, Zhong; Ma, Kai; Qian, Tianyi; Jiang, Tao; Zheng, Yefeng; Wang, Yinyan",Molecular subtyping of diffuse gliomas using magnetic resonance imaging: comparison and correlation between radiomics and deep learning,european radiology,2022,Not found,"Objectives The molecular subtyping of diffuse gliomas is important. The aim of this study was to establish predictive models based on preoperative multiparametric MRI. Methods A total of 1016 diffuse glioma patients were retrospectively collected from Beijing Tiantan Hospital. Patients were randomly divided into the training (n = 780) and validation (n = 236) sets. According to the 2016 WHO classification, diffuse gliomas can be classified into four binary classification tasks (tasks I-IV). Predictive models based on radiomics and deep convolutional neural network (DCNN) were developed respectively, and their performances were compared with receiver operating characteristic (ROC) curves. Additionally, the radiomics and DCNN features were visualized and compared with the t-distributed stochastic neighbor embedding technique and Spearman's correlation test. Results In the training set, areas under the curves (AUCs) of the DCNN models (ranging from 0.99 to 1.00) outperformed the radiomics models in all tasks, and the accuracies of the DCNN models (ranging from 0.90 to 0.94) outperformed the radiomics models in tasks I, II, and III. In the independent validation set, the accuracies of the DCNN models outperformed the radiomics models in all tasks (0.74-0.83), and the AUCs of the DCNN models (0.85-0.89) outperformed the radiomics models in tasks I, II, and III. DCNN features demonstrated more superior discriminative capability than the radiomics features in feature visualization analysis, and their general correlations were weak. Conclusions Both the radiomics and DCNN models could preoperatively predict the molecular subtypes of diffuse gliomas, and the latter performed better in most circumstances.",glioma; magnetic resonance imaging; diagnosis; machine learning; deep learning
Article,"Hwang, Eui Jin; Nam, Ju Gang; Lim, Woo Hyeon; Park, Sae Jin; Jeong, Yun Soo; Kang, Ji Hee; Hong, Eun Kyoung; Kim, Taek Min; Goo, Jin Mo; Park, Sunggyun; Kim, Ki Hwan; Park, Chang Min",Deep Learning for Chest Radiograph Diagnosis in the Emergency Department,radiology,2019,Not found,"Background: The performance of a deep learning (DL) algorithm should be validated in actual clinical situations, before its clinical implementation. Purpose: To evaluate the performance of a DL algorithm for identifying chest radiographs with clinically relevant abnormalities in the emergency department (ED) setting. Materials and Methods: This single-center retrospective study included consecutive patients who visited the ED and underwent initial chest radiography between January 1 and March 31, 2017. Chest radiographs were analyzed with a commercially available DL algorithm.The performance of the algorithm was evaluated by determining the area under the receiver operating characteristic curve (AUC), sensitivity, and specificity at predefined operating cutoffs (high-sensitivity and high-specificity cutoffs). The sensitivities and specificities of the algorithm were compared with those of the on-call radiology residents who interpreted the chest radiographs in the actual practice by using McNemar tests. If there were discordant findings between the algorithm and resident, the residents reinterpreted the chest radiographs by using the algorithm's output. Results: A total of 1135 patients (mean age, 53 years +/- 18; 582 men) were evaluated. In the identification of abnormal chest radiographs,the algorithm showed an AUC of 0.95 (95% confidence interval [CI]: 0.93, 0.96), a sensitivity of 88.7% (227 of 256 radiographs; 95% CI: 84.1%, 92.3%), and a specificity of 69.6% (612 of 879 radiographs; 95% CI: 66.5%, 72.7%) at the high sensitivity cutoff and a sensitivity of 81.6% (209 of 256 radiographs; 95% CI: 76.3%, 86.2%) and specificity of 90.3% (794 of 879 radiographs; 95% CI: 88.2%, 92.2%) at the high-specificity cutoff. Radiology residents showed lower sensitivity (65.6% [168 of 256 radiographs; 95% CI: 59.5%, 71.4%], P < .001) and higher specificity (98.1% [862 of 879 radiographs; 95% CI: 96.9%,98.9%], P < .001) compared with the algorithm. After reinterpretation of chest radiographs with use of the algorithm's outputs,the sensitivity of the residents improved (73.4% [188 of 256 radiographs; 95% CI: 68.0%, 78.8%], P = .003), whereas specificity was reduced (94.3% [829 of 879 radiographs; 95% CI: 92.8%, 95.8%], P < .001). Conclusion: A deep learning algorithm used with emergency department chest radiographs showed diagnostic performance for identifying clinically relevant abnormalities and helped improve the sensitivity of radiology residents' evaluation. Published under a CC BY 4.0 license.",diabetic-retinopathy; validation
Article,"Alyasseri, Zaid Abdi Alkareem; Al-Timemy, Ali H.; Abasi, Ammar Kamal; Lavric, Alexandru; Mohammed, Husam Jasim; Takahashi, Hidenori; Milhomens Filho, Jose Arthur; Campos, Mauro; Hazarbassanov, Rossen M.; Yousefi, Siamak",A Hybrid Artificial Intelligence Model for Detecting Keratoconus,applied sciences-basel,2022,Not found,"Machine learning models have recently provided great promise in diagnosis of several ophthalmic disorders, including keratoconus (KCN). Keratoconus, a noninflammatory ectatic corneal disorder characterized by progressive cornea thinning, is challenging to detect as signs may be subtle. Several machine learning models have been proposed to detect KCN, however most of the models are supervised and thus require large well-annotated data. This paper proposes a new unsupervised model to detect KCN, based on adapted flower pollination algorithm (FPA) and the k-means algorithm. We will evaluate the proposed models using corneal data collected from 5430 eyes at different stages of KCN severity (1520 healthy, 331 KCN1, 1319 KCN2, 1699 KCN3 and 579 KCN4) from Department of Ophthalmology and Visual Sciences, Paulista Medical School, Federal University of Sao Paulo, Sao Paulo in Brazil and 1531 eyes (Healthy = 400, KCN1 = 378, KCN2 = 285, KCN3 = 200, KCN4 = 88) from Department of Ophthalmology, Jichi Medical University, Tochigi in Japan and used several accuracy metrics including Precision, Recall, F-Score, and Purity. We compared the proposed method with three other standard unsupervised algorithms including k-means, Kmedoids, and Spectral cluster. Based on two independent datasets, the proposed model outperformed the other algorithms, and thus could provide improved identification of the corneal status of the patients with keratoconus.",keratoconus detection; feature extraction; machine learning; k-means; flower pollination algorithm
Article,"Du, Jingyu; Zou, Beiji; Ouyang, Pingbo; Zhao, Rongchang",Retinal microaneurysm detection based on transformation splicing and multi-context ensemble learning,biomedical signal processing and control,2022,Not found,"Retinal microaneurysm (MA) detection is essential for diagnosis of diabetic retinopathy (DR) by providing the earliest clinical sign of DR. However, automatically detecting MA has always been a challenge due to the extremely small proportion of MA, the susceptibility to interference from blood vessels, and the obvious contrast difference between MAs. This paper proposed a novel deep learning method to achieve accurate MA detection based on transformation splicing (TS) and multi-context ensemble learning. TS rebalances the proportion of MA and reduces interference from blood vessels by transforming the pixel distribution of each candidate image and reinforcing the features of difficult samples, which enables the subsequent model to better learn the enhanced image features. At the same time, a multi-context ensemble learning combining dual deep learning models and attention mechanism is designed to adaptively learn different spliced image contexts, which improves detection performance for weak MAs. The final scores of the proposed method in e-ophatha-MA, DiaretDB1 and ROC three public datasets are 0.518, 0.429 and 0.306 respectively, which demonstrates the state-of-the-art performance for MA detection.",microaneurysm detection; data enhancement; local cross-section transformation; image splicing; multi-context ensemble learning
Article,"Cheung, Carol Y.; Ran, An Ran; Wang, Shujun; Chan, Victor T. T.; Sham, Kaiser; Hilal, Saima; Venketasubramanian, Narayanaswamy; Cheng, Ching-Yu; Sabanayagam, Charumathi; Tham, Yih Chung; Schmetterer, Leopold; McKay, Gareth J.; Williams, Michael A.; Wong, Adrian; Au, Lisa W. C.; Lu, Zhihui; Yam, Jason C.; Tham, Clement C.; Chen, John J.; Dumitrascu, Oana M.; Heng, Pheng-Ann; Kwok, Timothy C. Y.; Mok, Vincent C. T.; Milea, Dan; Chen, Christopher Li-Hsian; Tien Yin Wong","A deep learning model for detection of Alzheimer's disease based on retinal photographs: a retrospective, multicentre case-control study",lancet digital health,2022,Not found,"Background There is no simple model to screen for Alzheimer's disease, partly because the diagnosis of Alzheimer's disease itself is complex-typically involving expensive and sometimes invasive tests not commonly available outside highly specialised clinical settings. We aimed to develop a deep learning algorithm that could use retinal photographs alone, which is the most common method of non-invasive imaging the retina to detect Alzheimer's disease-dementia. Methods In this retrospective, multicentre case-control study, we trained, validated, and tested a deep learning algorithm to detect Alzheimer's disease-dementia from retinal photographs using retrospectively collected data from 11 studies that recruited patients with Alzheimer's disease-dementia and people without disease from different countries. Our main aim was to develop a bilateral model to detect Alzheimer's disease-dementia from retinal photographs alone. We designed and internally validated the bilateral deep learning model using retinal photographs from six studies. We used the EfficientNet-b2 network as the backbone of the model to extract features from the images. Integrated features from four retinal photographs (optic nerve head-centred and macula-centred fields from both eyes) for each individual were used to develop supervised deep learning models and equip the network with unsupervised domain adaptation technique, to address dataset discrepancy between the different studies. We tested the trained model using five other studies, three of which used PET as a biomarker of significant amyloid beta burden (testing the deep learning model between amyloid beta positive vs amyloid beta negative). Findings 12949 retinal photographs from 648 patients with Alzheimer's disease and 3240 people without the disease were used to train, validate, and test the deep learning model. In the internal validation dataset, the deep learning model had 83.6% (SD 2.5) accuracy, 93.2% (SD 2.2) sensitivity, 82.0% (SD 3.1) specificity, and an area under the receiver operating characteristic curve (AUROC) of 0.93 (0.01) for detecting Alzheimer's disease-dementia. In the testing datasets, the bilateral deep learning model had accuracies ranging from 79.6% (SD 15.5) to 92.1% (11.4) and AUROCs ranging from 0.73 (SD 0.24) to 0.91 (0.10). In the datasets with data on PET, the model was able to differentiate between participants who were amyloid beta positive and those who were amyloid beta negative: accuracies ranged from 80.6 (SD 13.4%) to 89.3 (13.7%) and AUROC ranged from 0.68 (SD 0.24) to 0.86 (0.16). In subgroup analyses, the discriminative performance of the model was improved in patients with eye disease (accuracy 89.6% [SD 12.5%]) versus those without eye disease (71.7% [11.6%]) and patients with diabetes (81.9% [SD 20.3%]) versus those without the disease (72.4% [11.7%]). Interpretation A retinal photograph-based deep learning algorithm can detect Alzheimer's disease with good accuracy, showing its potential for screening Alzheimer's disease in a community setting. Copyright (C) 2022 The Author(s). Published by Elsevier Ltd.",artificial-intelligence; diabetic-retinopathy; macular degeneration; diagnosis; dementia; images; prediction; validation; biomarkers
Review,"Ajaz, Aqsa; Kumar, Himeesh; Kumar, Dinesh",A review of methods for automatic detection of macular edema,biomedical signal processing and control,2021,Not found,"Diabetic Macular Edema (DME) is a sight-threating complication of diabetic retinopathy (DR) and the major cause of vision impairment in people with diabetes. Damage to the retinal vasculature causes them to leak, triggering an inflammatory response and deposition of exudative material on the retina. DME can occur at any stage of DR and diagnosis and severity classification of the disease is done by imaging of the retina. This paper presents a narrative review of the literature to identify the strengths and limitations of the different imaging modalities for automated DME detection and monitoring. Comprehensive literature search was conducted and a total of 143 relevant peer-reviewed articles published from 2000 to 2020 in the English language were selected. The authors observed the large diversity in the journals and conferences where papers on this topic have been published. We also found the obvious rapid uptake of technology by clinicians to investigate Macular edema (ME) and DME. Another observation was inroads made by deep-learning and artificial intelligence in the field. One limitation appears to be that there are not enough publicly available large datasets for different imaging modalities that are annotated and labelled for DME.",diabetic macular edema; retinal image; colour fundus image; optical coherence tomography; angiography
Article,"Natarajan, Deepa; Sankaralingam, Esakkirajan; Balraj, Keerthiveena; Thangaraj, Veerakumar",Automated segmentation algorithm with deep learning framework for early detection of glaucoma,concurrency and computation-practice & experience,2021,Not found,"Early stage of diagnosis of eye diseases through automatic analysis in the retinal image is the emerging technology in the area of retinopathy. Glaucoma is the primary reason for the loss of visibility in people around the world. The separation of the disc and the cup in the optic region is the technique used to identify glaucoma in the human retinal image. In this paper, superpixel segmentation, followed by Modified Kernel Fuzzy C-Means (MKFCM) algorithm is used to segment the optic disc and optic cup. The proposed segmentation method achieves a maximum average of F-score as 0.979, an average boundary distance as 10.016 pixels, and an average correlation coefficient of 0.949. To train convolutional neural networks (CNN), the segmented images obtained by the MKFCM segmentation algorithm is given as the input for the identification of glaucoma. This CNN uses the gray level co-occurrence matrix features calculated from the segmented image. The experiment used for this study demonstrates that CNN gives superior categorization correctness and requires fewer figures of knowledge iterations than the original CNN. The accuracy obtained by this proposed method is 94.2%. The model will help to identify the proper class of severity of glaucoma in retinal images.",correlation; deep learning; fuzzy c means clustering; glaucoma segmentation; modified kernel; retinal image
Article,"Venugopalan, Janani; Tong, Li; Hassanzadeh, Hamid Reza; Wang, May D.",Multimodal deep learning models for early detection of Alzheimer's disease stage,scientific reports,2021,Not found,"Most current Alzheimer's disease (AD) and mild cognitive disorders (MCI) studies use single data modality to make predictions such as AD stages. The fusion of multiple data modalities can provide a holistic view of AD staging analysis. Thus, we use deep learning (DL) to integrally analyze imaging (magnetic resonance imaging (MRI)), genetic (single nucleotide polymorphisms (SNPs)), and clinical test data to classify patients into AD, MCI, and controls (CN). We use stacked denoising auto-encoders to extract features from clinical and genetic data, and use 3D-convolutional neural networks (CNNs) for imaging data. We also develop a novel data interpretation method to identify top-performing features learned by the deep-models with clustering and perturbation analysis. Using Alzheimer's disease neuroimaging initiative (ADNI) dataset, we demonstrate that deep models outperform shallow models, including support vector machines, decision trees, random forests, and k-nearest neighbors. In addition, we demonstrate that integrating multi-modality data outperforms single modality models in terms of accuracy, precision, recall, and meanF1 scores. Our models have identified hippocampus, amygdala brain areas, and the Rey Auditory Verbal Learning Test (RAVLT) as top distinguished features, which are consistent with the known AD literature.",diabetic-retinopathy; cerebrospinal-fluid; feature-selection; diagnosis; classification; biomarkers; representation; validation; criteria; predict
Article,"Wen, Yang; Chen, Leiting; Qiao, Lifeng; Deng, Yu; Chen, Haisheng; Zhang, Tian; Zhou, Chuan",FLeak-Seg: Automated Fundus Fluorescein Leakage Segmentation via Cross-Modal Attention Learning,ieee multimedia,2022,Not found,"Despite the recent success of deep learning-based models for medical image segmentation and the importance of automated fluorescein leakage segmentation for the diagnosis of advanced diabetic retinopathy, segmentation of fluorescein leakage has been neglected because 1) there are no publicly available databases with sufficient annotations to train segmentation models and 2) supervised models struggle to accurately distinguish between different types of fluorescein leakage and localize leakages at different imaging angles. To tackle these challenges, this work presents FLeak-Seg, a cross-modal dual attention learning method to jointly capture visual and language information, for end-to-end fluorescein leakage segmentation in fundus fluorescein angiography. Specifically, both image and text data are used as input, where visual and linguistic features are captured by a cross-modal attention learning module to compensate for the lack of annotations. A keyword classification module is also employed to identify meaningful expressions related to the type and location of fluorescein leakages to further facilitate the segmentation. Experimental results obtained in an in-house fundus fluorescein angiography database demonstrate the superiority of our method. We show how erroneous segmentation masks can be improved using FLeak-Seg, its advantages in the context of limited samples, and its behavior on segmenting different types of fluorescein leakages.",image segmentation; linguistics; visualization; optical imaging; feature extraction; biomedical optical imaging; training; deep learning; fundus fluorescein angiography; fluorescein leakage segmentation; cross-modal; attention learning
Proceedings Paper,"Sadhukhan, Sandip; Ghorai, Goutam Kumar; Maiti, Souvik; Sarkar, Gautam; Dhara, Ashis Kumar",Optic Disc Localization in Retinal Fundus Images using Faster R-CNN,proceedings of 2018 fifth international conference on emerging applications of information technology (eait),2018,Not found,"Now a days lot of people are suffering from Diabetic Retinopathy throughout the world. This is one kind of eye disease which affects people having diabetes for long time. If this is undiagnosed and not treated for long time, it can lead to blindness. Several studies have shown that an early detection and timely treatment is the only way to reduce the sufferings from diabetic retinopathy. The development of an automated screening system is the right approach for screening of diabetic retinopathy. Automated detection of several anatomical regions such as optic disc, retinal vasculature and macula is important to design a tool for the screening purpose. In our work we have presented a novel and fast optic disc detection method using Faster R-CNN. The proposed method is validated on 1200 fundus images from the MESSIDOR database which is widely accepted publicly available dataset for research purpose. We propose a supervised detection technique that uses a deep learning network trained on 6, 992 retinal fundus images augmented using geometrical transformations from MESSIDOR-II database. The proposed method shows satisfactory robustness on both normal and images affected by diabetic retinopathy. It outperforms many previous methods in terms of speed with satisfactory accuracy of optic disc localization.",convolution neural network; faster r-cnn; softmax classifier; regression; computer aided diagnosis of diabetic retinopathy; messidor database
Article,"Rodrigues, Erick; Conci, Aura; Liatsis, Panos",ELEMENT: Multi-Modal Retinal Vessel Segmentation Based on a Coupled Region Growing and Machine Learning Approach,ieee journal of biomedical and health informatics,2020,Not found,"Vascular structures in the retina contain important information for the detection and analysis of ocular diseases, including age-related macular degeneration, diabetic retinopathy and glaucoma. Commonly used modalities in diagnosis of these diseases are fundus photography, scanning laser ophthalmoscope (SLO) and fluorescein angiography (FA). Typically, retinal vessel segmentation is carried out either manually or interactively, which makes it time consuming and prone to human errors. In this research, we propose a new multi-modal framework for vessel segmentation called ELEMENT (vEsseL sEgmentation using Machine lEarning and coNnecTivity). This framework consists of feature extraction and pixel-based classification using region growing and machine learning. The proposed features capture complementary evidence based on grey level and vessel connectivity properties. The latter information is seamlessly propagated through the pixels at the classification phase. ELEMENT reduces inconsistencies and speeds up the segmentation throughput. We analyze and compare the performance of the proposed approach against state-of-the-art vessel segmentation algorithms in three major groups of experiments, for each of the ocular modalities. Our method produced higher overall performance, with an overall accuracy of 97.40%, compared to 25 of the 26 state-of-the-art approaches, including six works based on deep learning, evaluated on the widely known DRIVE fundus image dataset. In the case of the STARE, CHASE-DB, VAMPIRE FA, IOSTAR SLO and RC-SLO datasets, the proposed framework outperformed all of the state-of-the-art methods with accuracies of 98.27%, 97.78%, 98.34%, 98.04% and 98.35%, respectively.",feature extraction; image segmentation; machine learning; retinal vessels; task analysis; predictive models; machine learning; pixel-based classi-fication; pixel connectivity; retinal vessel segmentation; region growing
Article,"Subramanian, Malliga; Kumar, M. Sandeep; Sathishkumar, V. E.; Prabhu, Jayagopal; Karthick, Alagar; Ganesh, S. Sankar; Meem, Mahseena Akter",Diagnosis of Retinal Diseases Based on Bayesian Optimization Deep Learning Network Using Optical Coherence Tomography Images,computational intelligence and neuroscience,2022,Not found,"Retinal abnormalities have emerged as a serious public health concern in recent years and can manifest gradually and without warning. These diseases can affect any part of the retina, causing vision impairment and indeed blindness in extreme cases. This necessitates the development of automated approaches to detect retinal diseases more precisely and, preferably, earlier. In this paper, we examine transfer learning of pretrained convolutional neural network (CNN) and then transfer it to detect retinal problems from Optical Coherence Tomography (OCT) images. In this study, pretrained CNN models, namely, VGG16, DenseNet201, InceptionV3, and Xception, are used to classify seven different retinal diseases from a dataset of images with and without retinal diseases. In addition, to choose optimum values for hyperparameters, Bayesian optimization is applied, and image augmentation is used to increase the generalization capabilities of the developed models. This research also provides a comparison of the proposed models as well as an analysis of them. The accuracy achieved using DenseNet201 on the Retinal OCT Image dataset is more than 99% and offers a good level of accuracy in classifying retinal diseases compared to other approaches, which only detect a small number of retinal diseases.",diabetic-retinopathy; segmentation
Article,"Nirschl, Jeffrey J.; Janowczyk, Andrew; Peyster, Eliot G.; Frank, Renee; Margulies, Kenneth B.; Feldman, Michael D.; Madabhushi, Anant",A deep-learning classifier identifies patients with clinical heart failure using whole-slide images of H&E tissue,plos one,2018,Not found,"Over 26 million people worldwide suffer from heart failure annually. When the cause of heart failure cannot be identified, endomyocardial biopsy (EMB) represents the gold-standard for the evaluation of disease. However, manual EMB interpretation has high inter-rater variability. Deep convolutional neural networks (CNNs) have been successfully applied to detect cancer, diabetic retinopathy, and dermatologic lesions from images. In this study, we develop a CNN classifier to detect clinical heart failure from H&E stained whole-slide images from a total of 209 patients, 104 patients were used for training and the remaining 105 patients for independent testing. The CNN was able to identify patients with heart failure or severe pathology with a 99% sensitivity and 94% specificity on the test set, outperforming conventional feature-engineering approaches. Importantly, the CNN outperformed two expert pathologists by nearly 20%. Our results suggest that deep learning analytics of EMB can be used to predict cardiac outcome.",college-of-cardiology; working formulation; neural-networks; class discovery; diagnosis; association; information; management; disease; update
Article,"Kou, Caixia; Li, Wei; Liang, Wei; Yu, Zekuan; Hao, Jianchen",Microaneurysms segmentation with a U-Net based on recurrent residual convolutional neural network,journal of medical imaging,2019,Not found,"Microaneurysms (MAs) play an important role in the diagnosis of clinical diabetic retinopathy at the early stage. Annotation of MAs manually by experts is laborious and so it is essential to develop automatic segmentation methods. Automatic MA segmentation remains a challenging task mainly due to the low local contrast of the image and the small size of MAs. A deep learning-based method called U-Net has become one of the most popular methods for the medical image segmentation task. We propose an architecture for U-Net, named deep recurrent U-Net (DRU-Net), obtained by combining the deep residual model and recurrent convolutional operations into U-Net. In the MA segmentation task, DRU-Net can accumulate effective features much better than the typical U-Net. The proposed method is evaluated on two publicly available datasets: E-Ophtha and IDRiD. Our results show that the proposed DRU-Net achieves the best performance with 0.9999 accuracy value and 0.9943 area under curve (AUC) value on the E-Ophtha dataset. And on the IDRiD dataset, it has achieved 0.987 AUC value (to our knowledge, this is the first result of segmenting MAs on this dataset). Compared with other methods, such as U-Net, FCNN, and ResU-Net, our architecture (DRU-Net) achieves state-of-the-art performance. (C) 2019 Society of Photo-Optical Instrumentation Engineers (SPIE)",u-net; microaneurysms; segmentation; deep recurrent u-net
Article,"Hemalakshmi, G. R.; Santhi, D.; Mani, V. R. S.; Geetha, A.; Prakash, N. B.",Deep Residual Network Based on Image Priors for Single Image Super Resolution in FFA Images,cmes-computer modeling in engineering & sciences,2020,Not found,"Diabetic retinopathy, aged macular degeneration, glaucoma etc. are widely prevalent ocular pathologies which are irreversible at advanced stages. Machine learning based automated detection of these pathologies facilitate timely clinical interventions, preventing adverse outcomes. Ophthalmologists screen these pathologies with fundus Fluorescein Angiography Images (FFA) which capture retinal components featuring diverse morphologies such as retinal vasculature, macula, optical disk etc. However, these images have low resolutions, hindering the accurate detection of ocular disorders. Construction of high resolution images from these images, by super resolution approaches expedites the diagnosis of pathologies with better accuracy. This paper presents a deep learning network for Single Image Super Resolution (SISR) of fundus fluorescein angiography images, modeled on residual learning, gridded interpolation and Swish activation functions. The image prior for this network is constructed by gridded interpolation which provides better image fidelity compared to other priors. Evaluation of the performance of this network and comparative analysis with benchmark architectures, on a standard dataset shows that the proposed network is superior with respect to performance metrics and computational time.",sisr; ffa; residual network; gridded interpolation; swish function
Proceedings Paper,"Wargnier-Dauchelle, Valentine; Simon-Chane, Camille; Histace, Aymeric",Retinal Blood Vessels Segmentation: Improving State-of-the-Art Deep Methods,computer analysis of images and patterns (caip 2019),2019,Not found,"Retinal blood vessels segmentation is an important step for computer-aided early diagnosis of several retinal vascular diseases, in particular diabetic retinopathy. This segmentation is necessary to evaluate the state of the vascular network and to detect abnormalities (aneurysms, hemorrhages, etc). Many image processing and machine learning methods have been developed in recent years in order to achieve this segmentation. These methods are difficult to compare with one another since the evaluation conditions vary greatly. Moreover, public databases often provide multiple ground truths. In this paper, we implement a competitive state-of-the art method and evaluate it on the DRIVE (Digital Retinal Images for Vessel Extraction) public database. Based on this method, we test and present several improvements which are evaluated using a dedicated performance evaluation protocol. This protocol uses five criteria and three different evaluations in order to assess the robustness of the methods' performances.",retinal blood vessels segmentation; deep learning; convolutional neural network; u-net; drive
Article,"Turki, Turki; Wei, Zhi",Improved Deep Convolutional Neural Networks via Boosting for Predicting the Quality of In Vitro Bovine Embryos,electronics,2022,Not found,"Automated diagnosis for the quality of bovine in vitro-derived embryos based on imaging data is an important research problem in developmental biology. By predicting the quality of embryos correctly, embryologists can (1) avoid the time-consuming and tedious work of subjective visual examination to assess the quality of embryos; (2) automatically perform real-time evaluation of embryos, which accelerates the examination process; and (3) possibly avoid the economic, social, and medical implications caused by poor-quality embryos. While generated embryo images provide an opportunity for analyzing such images, there is a lack of consistent noninvasive methods utilizing deep learning to assess the quality of embryos. Hence, designing high-performance deep learning algorithms is crucial for data analysts who work with embryologists. A key goal of this study is to provide advanced deep learning tools to embryologists, who would, in turn, use them as prediction calculators to evaluate the quality of embryos. The proposed deep learning approaches utilize a modified convolutional neural network, with or without boosting techniques, to improve the prediction performance. Experimental results on image data pertaining to in vitro bovine embryos show that our proposed deep learning approaches perform better than existing baseline approaches in terms of prediction performance and statistical significance.",deep learning; boosting; reproductive biology; developmental biology; applications in biology and medicine
Article; Early Access,"Pham, Vu-Thu-Nguyet; Nguyen, Quang-Chung; Nguyen, Quang-Vu",Chest X-Rays Abnormalities Localization and Classification Using an Ensemble Framework of Deep Convolutional Neural Networks,vietnam journal of computer science,0,Not found,"Medical X-rays are one of the primary choices for diagnosis because of their potential to disclose previously undetected pathologic changes, non-invasive qualities, radiation dosage, and cost concerns. There are several advantages to creating computer-aided detection (CAD) technologies for X-Ray analysis. With the advancement of technology, researchers have lately used the deep learning approach to obtain high accuracy outcomes in the CAD system. With CAD, computer output may be utilized as a backup option for radiologists, assisting doctors in making the best selections. Chest X-Rays (CXRs) are commonly used to diagnose heart and lung problems. Automatically recognizing these problems with high accuracy might considerably improve real-world diagnosis processes. However, the lack of standard publicly available datasets and benchmark research makes comparing and establishing the best detection algorithms challenging. In order to overcome these difficulties, we have used the VinDr-CXR dataset, which is one of the latest public datasets including 18,000 expert-annotated images labeled into 22 local position-specific abnormalities and 6 globally suspected diseases. To improve the identification of chest abnormalities, we proposed a data preparation procedure and a novel model based on YOLOv5 and ResNet50. YOLOv5 is the most recent YOLO series, and it is more adaptable than previous one-stage detection algorithms. In our paper, the role of YOLOv5 is to locate the abnormality location. On the other side, we employ ResNet for classification, avoiding gradient explosion concerns in deep learning. Then we filter the YOLOv5 and ResNet results. The YOLOv5 detection result is updated if ResNet determines that the image is not anomalous.",chest x-rays; abnormalities detection; deep learning; yolov5; resnet50; medical informatics
Article,"Abdel-Hamid, Lamiaa",Retinal image quality assessment using transfer learning: Spatial images vs. wavelet detail subbands,ain shams engineering journal,2021,Not found,"Retinal image quality assessment (RIQA) is essential to assure that images used for medical analysis are of sufficient quality for reliable diagnosis. A modified VGG16 network with transfer learning is introduced in order to classify retinal images into good or bad quality images. Both spatial and wavelet detail subbands are compared as inputs to the modified VGG16 network. Three public retinal image datasets captured with different imaging devices are used, both individually and collectively. Superior performance was attained by the modified VGG16 network, where accuracies in the range of 99-100% were achieved regardless of whether retinal images from the same or different sources were considered and whether the spatial or wavelet images were used. The implemented RIQA algorithm was also found to outperform other RIQA deep learning algorithms from literature by 1.5-10% and to achieve accuracies that are up to 32% higher than traditional RIQA methods for the same dataset. (C) 2021 THE AUTHORS. Published by Elsevier BV on behalf of Faculty of Engineering, Ain Shams University.y Elsevier B.V.",retinal image quality assessment (riqa); wavelet transform; transfer learning; vgg network; deep learning
Article,"Biswas, Raj; Vasan, Ashwin; Roy, Sanjiban Sekhar",Dilated Deep Neural Network for Segmentation of Retinal Blood Vessels in Fundus Images,iranian journal of science and technology-transactions of electrical engineering,2020,Not found,"Medical diagnosis is being assisted by numerous expert systems that have been developed to increase the accuracy of such diagnoses. The development of image processing techniques along with the rapid development in areas like machine learning and computer vision help in creating such expert systems that almost nearly match the accuracy of the expert human eye. The medical condition of diabetic retinopathy is diagnosed by analyzing the retinal blood vessels for damages, abnormal new growths and ruptures. Various techniques using convolutional neural networks have been used to segment retinal blood vessels from fundus images, but these techniques often do not segment the retinal blood vessels accurately and add additional noise due to the limited receptive field of the convolutional filters. The limited receptive field of the convolutional layer prevents the convolutional neural network from getting an accurate context of objects that extend beyond the size of the filter. The proposed architecture uses a dilated convolutional filter to obtain a larger receptive field which leads to a greater accuracy in segmenting the retinal blood vessels with near human accuracy. The convolutional neural networks were trained using the popular datasets. The proposed architecture produced an area under ROC curve (AUC) of 0.9794 and an accuracy of 95.61% and required very few iterations to train the network.",deep neural network; dilated convolution; blood vessel segmentation; medical imaging
Proceedings Paper,"Abbas, Waseem; Shakeel, Muhammad Haroon; Khurshid, Numan; Taj, Murtaza",Patch-Based Generative Adversarial Network Towards Retinal Vessel Segmentation,"neural information processing (iconip 2019), pt iv",2019,Not found,"Retinal blood vessels are considered to be the reliable diagnostic biomarkers of ophthalmologic and diabetic retinopathy. Monitoring and diagnosis totally depends on expert analysis of both thin and thick retinal vessels which has recently been carried out by various artificial intelligent techniques. Existing deep learning methods attempt to segment retinal vessels using a unified loss function optimized for both thin and thick vessels with equal importance. Due to variable thickness, biased distribution, and difference in spatial features of thin and thick vessels, unified loss function are more influential towards identification of thick vessels resulting in weak segmentation. To address this problem, a conditional patch-based generative adversarial network is proposed which utilizes a generator network and a patch-based discriminator network conditioned on the sample data with an additional loss function to learn both thin and thick vessels. Experiments are conducted on publicly available STARE and DRIVE datasets which show that the proposed model outperforms the state-of-the-art methods.",deep learning; generative adversarial network; segmentation; retinal vessels
Article,"Li, Zhongwen; Guo, Chong; Nie, Danyao; Lin, Duoru; Cui, Tingxin; Zhu, Yi; Chen, Chuan; Zhao, Lanqin; Zhang, Xulin; Dongye, Meimei; Wang, Dongni; Xu, Fabao; Jin, Chenjin; Zhang, Ping; Han, Yu; Yan, Pisong; Lin, Haotian",Automated detection of retinal exudates and drusen in ultra-widefield fundus images based on deep learning,eye,2022,Not found,"Background Retinal exudates and/or drusen (RED) can be signs of many fundus diseases that can lead to irreversible vision loss. Early detection and treatment of these diseases are critical for improving vision prognosis. However, manual RED screening on a large scale is time-consuming and labour-intensive. Here, we aim to develop and assess a deep learning system for automated detection of RED using ultra-widefield fundus (UWF) images. Methods A total of 26,409 UWF images from 14,994 subjects were used to develop and evaluate the deep learning system. The Zhongshan Ophthalmic Center (ZOC) dataset was selected to compare the performance of the system to that of retina specialists in RED detection. The saliency map visualization technique was used to understand which areas in the UWF image had the most influence on our deep learning system when detecting RED. Results The system for RED detection achieved areas under the receiver operating characteristic curve of 0.994 (95% confidence interval [CI]: 0.991-0.996), 0.972 (95% CI: 0.957-0.984), and 0.988 (95% CI: 0.983-0.992) in three independent datasets. The performance of the system in the ZOC dataset was comparable to that of an experienced retina specialist. Regions of RED were highlighted by saliency maps in UWF images. Conclusions Our deep learning system is reliable in the automated detection of RED in UWF images. As a screening tool, our system may promote the early diagnosis and management of RED-related fundus diseases.",diabetic-retinopathy; bright lesions; differentiation; validation; disease
Article,"Wang, Rui; Li, Ping; Yang, Zhengfei",Analysis and Recognition of Clinical Features of Diabetes Based on Convolutional Neural Network,computational and mathematical methods in medicine,2022,Not found,"Diabetes mellitus is a common chronic noncommunicable disease, the main manifestation of which is the long-term high blood sugar level in patients due to metabolic disorders. However, due to excessive reliance on the clinical experience of ophthalmologists, our diagnosis takes a long time, and it is prone to missed diagnosis and misdiagnosis. In recent years, with the development of deep learning, its application in the auxiliary diagnosis of diabetic retinopathy has become possible. How to use the powerful feature extraction ability of deep learning algorithm to realize the mining of massive medical data is of great significance. Therefore, under the action of computer-aided technology, this paper processes and analyzes the retinal images of the fundus through traditional image processing and convolutional neural network-related methods, so as to achieve the role of assisting clinical treatment. Based on the admission records of diabetic patients after data analysis and feature processing, this paper uses an improved convolutional neural network algorithm to establish a model for predicting changes in diabetic conditions. The model can assist doctors to judge the patient's treatment effect by using it based on the case records of inpatient diagnosis and treatment and to predict the risk of readmission of inpatients after discharge. It also can help to judge the effectiveness of the treatment plan. The results of the study show that the model proposed in this paper has a lower probability of misjudging patients with poor recovery as good recovery, and the prediction is more accurate.",automatic detection; classification; diagnosis
Proceedings Paper,"Tavakoli, Meysam",Automated Optic Disk Detection in Fundus Images using a Combination of Deep Learning and Local Histogram Matching,"medical imaging 2022: biomedical applications in molecular, structural, and functional imaging",2022,Not found,"Retinal images have been used in the diagnosis of many ocular diseases such as glaucoma and diabetic retinopathy. Here, automatic detection of optic disk (OD) is essential in deriving clinical parameters to assist clinical diagnosis. In fact, detecting OD center and its boundary is the essential step of most vessel segmentation, disease diagnostic, and retinal recognition algorithms. In this study, we proposed a new approach for localizing OD by combining local histogram matching and the concept of deep learning. The algorithm is composed of 4 steps, Image partitioning, Local histogram matching and validation, Convolutional Neural Network (CNN) classification, and OD detection. Here, we used OD of the five reference retinal images in each dataset to extract the histograms of each color channel. Then, we calculated the mean of histograms for each channel as template for creating some OD candidates. An AlexNet-like CNN was applied to classify candidates as ODs or nonODs. The candidates used as an input to feed the CNN for final classification. In this study, we worked on three databases (one rural, MUMS-DB, and two publicly available databases, DRIVE, STARE) including 520 retinal images to evaluate the proposed method. The accuracy of our algorithm was 100%, 90%, and 95% for the DRIVE, STARE, and MUMS-DB respectively. It is shown that this method provides higher detection rates than the existing methods that have reported.",retinal images; nerve head; vision impairment; microaneurysms; extraction; blindness; boundary; distance
Article,"Das, Arun; Rad, Paul; Choo, Kim-Kwang Raymond; Nouhi, Babak; Lish, Jonathan; Martel, James",Distributed machine learning cloud teleophthalmology IoT for predicting AMD disease progression,future generation computer systems-the international journal of escience,2019,Not found,"The ability to perform screening of potential vision-impairing diseases remotely with an Ophthalmologist-in-the-loop is crucial in serving the Medically Underserved Areas/Population (MUAS/P) and in acute medical settings, such as emergency departments. With an estimated 217 million individuals affected by moderate to severe vision-impairing diseases worldwide and an increasing number of new patients with such diseases, the need for access to faster (or real-time) diagnosis on a large scale is imperative. It is evident that early diagnosis of chronic diseases such as diabetic retinopathy and age-related macular degeneration (AMD) could better prevent vision loss. In this paper, a scalable cloud based teleophthalmology architecture via the Internet of Medical Things (IoMT) for diagnosis of AMD is presented. In the proposed architecture, patients wear a head-mounted camera (OphthoAl IoMT headset) to send their retinal fundus images to their secure and private cloud drive storage for personalized disease severity detection and predictive progression analysis. A proposed AMD-ResNet convolution neural network with 152 layers will then analyze the images to identify and determine AMD disease severity. The algorithm is trained with AREDS (age related eye disease study) images from the National Institute of Health (NIH) with over 130,000 fundus images captured over 12 years, and for determining AMD severity, we achieve a sensitivity and specificity of 94.97 +/- 0.5% and 98.32 +/- 0.1% respectively. A temporal Long-Short Term Memory (LSTM) deep neural network for precision medicine and AMD predictive progression is also proposed. Patient personalization allows better targeted care, lesser side effects, and a greater likelihood of responding to treatments by tailoring healthcare on a per-patient basis. (C) 2018 Elsevier B.V. All rights reserved.",internet of medical things (iomt); deep learning; telemedicine; teleophthalmology; macular degeneration; mobile-cloud teleophthalmology; wearable iomt
Proceedings Paper,"Wu, Jun; Zhang, Yao; Wang, Jie; Zhao, Jianchun; Ding, Dayong; Chen, Ningjiang; Wang, Lingling; Chen, Xuan; Jiang, Chunhui; Zou, Xuan; Liu, Xing; Xiao, Hui; Tian, Yuan; Shang, Zongjiang; Wang, Kaiwei; Li, Xirong; Yang, Gang; Fan, Jianping",AttenNet: Deep Attention Based Retinal Disease Classification in OCT Images,"multimedia modeling (mmm 2020), pt ii",2020,Not found,"An optical coherence tomography (OCT) image is becoming the standard imaging modality in diagnosing retinal diseases and the assessment of their progression. However, the manual evaluation of the volumetric scan is time consuming, expensive and the signs of the early disease are easy to miss. In this paper, we mainly present an attentionbased deep learning method for the retinal disease classification in OCT images, which can assist the large-scale screening or the diagnosis recommendation for an ophthalmologist. First, according to the unique characteristic of a retinal OCT image, we design a customized pre-processing method to improve image quality. Second, in order to guide the network optimization more effectively, a specially designed attention model, which pays more attention to critical regions containing pathological anomalies, is integrated into a typical deep learning network. We evaluate our proposed method on two data sets, and the results consistently show that it outperforms the state-of-the-art methods. We report an overall fourclass accuracy of 97.4%, a two-class sensitivity of 100.0%, and a two-class specificity of 100.0% on a public data set shared by Zhang et al. with 1,000 testing B-scans in four disease classes. Compared to their work, our method improves the numbers by 0.8%, 2.2%, and 2.6% respectively.",optical coherence tomography (oct); retinal disease classification; deep learning; attention model
Article,"Lois, Noemi; Cook, Jonathan; Wang, Ariel; Aldington, Stephen; Mistry, Hema; Maredza, Mandy; McAuley, Danny; Aslam, Tariq; Bailey, Clare; Chong, Victor; Ghanchi, Faruque; Scanlon, Peter; Sivaprasad, Sobha; Steel, David; Styles, Caroline; Azuara-Blanco, Augusto; Prior, Lindsay; Waugh, Norman",Multimodal imaging interpreted by graders to detect re-activation of diabetic eye disease in previously treated patients: the EMERALD diagnostic accuracy study,health technology assessment,2021,Not found,"Background: Owing to the increasing prevalence of diabetes, the workload related to diabetic macular oedema and proliferative diabetic retinopathy is rising, making it difficult for hospital eye services to meet demands. Objective: The objective was to evaluate the diagnostic performance, cost-effectiveness and acceptability of a new pathway using multimodal imaging interpreted by ophthalmic graders to detect reactivation of diabetic macular oedema/proliferative diabetic retinopathy in previously treated patients. Design: This was a prospective, case-referent, cross-sectional diagnostic study. Setting: The setting was ophthalmic clinics in 13 NHS hospitals. Participants: Adults with type 1 or type 2 diabetes with previously successfully treated diabetic macular oedema/proliferative diabetic retinopathy in one/both eyes in whom, at the time of enrolment, diabetic macular oedema/proliferative diabetic retinopathy could be active or inactive. Methods: For the ophthalmic grader pathway, review of the spectral domain optical coherence tomography scans to detect diabetic macular oedema, and seven-field Early Treatment Diabetic Retinopathy Study/ultrawide field fundus images to detect proliferative diabetic retinopathy, by trained ophthalmic graders. For the current standard care pathway (reference standard), ophthalmologists examined patients face to face by slit-lamp biomicroscopy for proliferative diabetic retinopathy and, in addition, spectral domain optical coherence tomography imaging for diabetic macular oedema. Outcome measures: The primary outcome measure was sensitivity of the ophthalmic grader pathway to detect active diabetic macular oedema/proliferative diabetic retinopathy. The secondary outcomes were specificity, agreement between pathways, cost-consequences, acceptability and the proportion of patients requiring subsequent ophthalmologist assessment, unable to undergo imaging and with inadequate quality images/indeterminate findings. It was assumed for the main analysis that all patients in whom graders diagnosed active disease or were 'unsure' or images were 'ungradable' required examination by an ophthalmologist. Results: Eligible participants with active and inactive diabetic macular oedema (152 and 120 participants, respectively) and active and inactive proliferative diabetic retinopathy (111 and 170 participants, respectively) were recruited. Under the main analysis, graders had a sensitivity of 97% (142/147) (95% confidence interval 92% to 99%) and specificity of 31% (35/113) (95% confidence interval 23% to 40%) to detect diabetic macular oedema. For proliferative diabetic retinopathy, graders had a similar sensitivity and specificity using seven-field Early Treatment Diabetic Retinopathy Study [sensitivity 85% (87/102), 95% confidence interval 77% to 91%; specificity 48% (77/160), 95% confidence interval 41% to 56%] or ultra-wide field imaging [sensitivity 83% (87/105), 95% confidence interval 75% to 89%; specificity 54% (86/160), 95% confidence interval 46% to 61%]. Participants attending focus groups expressed preference for face-to-face evaluations by ophthalmologists. In the ophthalmologists' absence, patients voiced the need for immediate feedback following grader's assessments, maintaining periodic evaluations by ophthalmologists. Graders and ophthalmologists were supportive of the new pathway. When compared with the reference standard (current standard pathway), the new grader pathway could save 1390 pound per 100 patients in the review of people with diabetic macular oedema and, depending on the imaging modality used, between 461 pound and 1189 pound per 100 patients in the review of people with proliferative diabetic retinopathy. Conclusions: For people with diabetic macular oedema, the ophthalmic grader pathway appears safe and cost saving. The sensitivity of the new pathway to detect active proliferative diabetic retinopathy was lower, but may still be considered acceptable for patients with proliferative diabetic retinopathy previously treated with laser. Suggestions from focus group discussions should be taken into consideration if the new pathway is introduced to ensure its acceptability to users. Limitations: Lack of fundus fluorescein angiography to confirm diagnosis of active proliferative diabetic retinopathy. Future work: Could refinement of the new pathway increase its sensitivity to detect proliferative diabetic retinopathy? Could artificial intelligence be used for automated reading of images in this previously treated population?",quality-of-life; macular edema; virtual clinics; retinopathy; ranibizumab; prevalence; laser; care; photocoagulation; proportions
Article,"Gian, Michelle K. S.; Raman, Valliappan; Then, Patrick H. H.",Deep Learning for The Automatic Diagnosis and Detection of Multiple Retinal Abnormalities,journal of integrated design & process science,2019,Not found,"This paper presents a fully-automated method to detect retinal abnormalities in both a global and local context by generating: (1) a disease label with a probability score and (2) a 4-channel pixel-level segmentation map of retinal lesions. The characteristics of retinal abnormalities, which occur as various shapes, sizes, and distribution at different regions, are a challenge in accomplishing these tasks. In addition, the small amount of image-level labelled images in public databases and the unavailability of lesion-level annotations for most of these publicly available images also pose as challenges. These shortcomings motivate our exploration of various CNN architectures to extract multi-scale contextual information, such that we investigate the impact of different arrangements of multi-sized convolutional kernels appended to a modified pre-trained encoder. Additionally, to prevent the loss of detailed information for small lesions, we exploit the advantages of feature map concatenation from the output of these multiscale convolutions to its corresponding decoder layer. A new two-phase training strategy is also implemented to tackle the problem of dataset imbalance between image-level label and lesion-level label classes. The direct comparison between our proposed methods and currently published state-of-the-art methods with the same databases confirms that our best model outperforms is existing published methods.",convolutional neural network; retinal abnormalities; segmentation; classification; multi-scale convolutions
Review,"Martinez-Millana, Antonio; Saez-Saez, Aida; Tornero-Costa, Roberto; Azzopardi-Muscat, Natasha; Traver, Vicente; Novillo-Ortiz, David","Artificial intelligence and its impact on the domains of universal health coverage, health emergencies and health promotion: An overview of systematic reviews",international journal of medical informatics,2022,Not found,"Background: Artificial intelligence is fueling a new revolution in medicine and in the healthcare sector. Despite the growing evidence on the benefits of artificial intelligence there are several aspects that limit the measure of its impact in people & rsquo;s health. It is necessary to assess the current status on the application of AI towards the improvement of people & rsquo;s health in the domains defined by WHO & rsquo;s Thirteenth General Programme of Work (GPW13) and the European Programme of Work (EPW), to inform about trends, gaps, opportunities, and challenges. Objective: To perform a systematic overview of systematic reviews on the application of artificial intelligence in the people & rsquo;s health domains as defined in the GPW13 and provide a comprehensive and updated map on the application specialties of artificial intelligence in terms of methodologies, algorithms, data sources, outcomes, predictors, performance, and methodological quality. Methods: A systematic search in MEDLINE, EMBASE, Cochrane and IEEEXplore was conducted between January 2015 and June 2021 to collect systematic reviews using a combination of keywords related to the domains of universal health coverage, health emergencies protection, and better health and wellbeing as defined by the WHO & rsquo;s PGW13 and EPW. Eligibility criteria was based on methodological quality and the inclusion of practical implementation of artificial intelligence. Records were classified and labeled using ICD-11 categories into the domains of the GPW13. Descriptors related to the area of implementation, type of modeling, data entities, outcomes and implementation on care delivery were extracted using a structured form and methodological aspects of the included reviews studies was assessed using the AMSTAR checklist. Results: The search strategy resulted in the screening of 815 systematic reviews from which 203 were assessed for eligibility and 129 were included in the review. The most predominant domain for artificial intelligence applications was Universal Health Coverage (N = 98) followed by Health Emergencies (N = 16) and Better Health and Wellbeing (N = 15). Neoplasms area on Universal Health Coverage was the disease area featuring most of the applications (21.7 %, N = 28). The reviews featured analytics primarily over both public and private data sources (67.44 %, N = 87). The most used type of data was medical imaging (31.8 %, N = 41) and predictors based on regions of interest and clinical data. The most prominent subdomain of Artificial Intelligence was Machine Learning (43.4 %, N = 56), in which Support Vector Machine method was predominant (20.9 %, N = 27). Regarding the purpose, the application of Artificial Intelligence I is focused on the prediction of the diseases (36.4 %, N = 47). With respect to the validation, more than a half of the reviews (54.3 %, N = 70) did not report a validation procedure and, whenever available, the main performance indicator was the accuracy (28.7 %, N = 37). According to the methodological quality assessment, a third of the reviews (34.9 %, N = 45) implemented methods for analysis the risk of bias and the overall AMSTAR score below was 5 (4.01 +/- 1.93) on all the included systematic reviews. Conclusion: Artificial intelligence is being used for disease modelling, diagnose, classification and prediction in the three domains of GPW13. However, the evidence is often limited to laboratory and the level of adoption is largely unbalanced between ICD-11 categoriesand diseases. Data availability is a determinant factor on the developmental stage of artificial intelligence applications. Most of the reviewed studies show a poor methodo-logical quality and are at high risk of bias, which limits the reproducibility of the results and the reliability of translating these applications to real clinical scenarios. The analyzed papers show results only in laboratory and testing scenarios and not in clinical trials nor case studies, limiting the supporting evidence to transfer artificial intelligence to actual care delivery. <comment>Superscript/Subscript Available</comment",machine learning; universal health coverage; health emergencies; health and well-being; european region
Article,"Kazeminasab, Elahe Sadat; Almasi, Ramin; Shoushtarian, Bijan; Golkar, Ehsan; Rabbani, Hossein",Automatic Detection of Microaneurysms in OCT Images Using Bag of Features,computational and mathematical methods in medicine,2022,Not found,"Diabetic retinopathy (DR) caused by diabetes occurs as a result of changes in the retinal vessels and causes visual impairment. Microaneurysms (MAs) are the early clinical signs of DR, whose timely diagnosis can help detecting DR in the early stages of its development. It has been observed that MAs are more common in the inner retinal layers compared to the outer retinal layers in eyes suffering from DR. Optical coherence tomography (OCT) is a noninvasive imaging technique that provides a cross-sectional view of the retina, and it has been used in recent years to diagnose many eye diseases. As a result, this paper attempts to identify areas with MA from normal areas of the retina using OCT images. This work is done using the dataset collected from FA and OCT images of 20 patients with DR. In this regard, firstly fluorescein angiography (FA) and OCT images were registered. Then, the MA and normal areas were separated, and the features of each of these areas were extracted using the Bag of Features (BOF) approach with the Speeded-Up Robust Feature (SURF) descriptor. Finally, the classification process was performed using a multilayer perceptron network. For each of the criteria of accuracy, sensitivity, specificity, and precision, the obtained results were 96.33%, 97.33%, 95.4%, and 95.28%, respectively. Utilizing OCT images to detect MAs automatically is a new idea, and the results obtained as preliminary research in this field are promising.",optical coherence tomography; diabetic-retinopathy; fluorescein angiography; internal reflectivity; segmentation
Article,"Han, Ji Eun Diana; Liu, Xiaoxuan; Bunce, Catey; Douiri, Abdel; Vale, Luke; Blandford, Ann; Lawrenson, John; Hussain, Rima; Grimaldi, Gabriela; Learoyd, Annastazia E.; Kernohan, Ashleigh; Dinah, Christiana; Minos, Evangelos; Sim, Dawn; Aslam, Tariq; Patel, Praveen J.; Denniston, Alastair K.; Keane, Pearse A.; Balaskas, Konstantinos",Teleophthalmology-enabled and artificial intelligence-ready referral pathway for community optometry referrals of retinal disease (HERMES): a Cluster Randomised Superiority Trial with a linked Diagnostic Accuracy Study - HERMES study report 1-study protocol,bmj open,2022,Not found,"Introduction Recent years have witnessed an upsurge of demand in eye care services in the UK. With a large proportion of patients referred to Hospital Eye Services (HES) for diagnostics and disease management, the referral process results in unnecessary referrals from erroneous diagnoses and delays in access to appropriate treatment. A potential solution is a teleophthalmology digital referral pathway linking community optometry and HES. Methods and analysis The HERMES study (Teleophthalmology-enabled and artificial intelligence-ready referral pathway for community optometry referrals of retinal disease: a cluster randomised superiority trial with a linked diagnostic accuracy study) is a cluster randomised clinical trial for evaluating the effectiveness of a teleophthalmology referral pathway between community optometry and HES for retinal diseases. Nested within HERMES is a diagnostic accuracy study, which assesses the accuracy of an artificial intelligence (AI) decision support system (DSS) for automated diagnosis and referral recommendation. A postimplementation, observational substudy, a within-trial economic evaluation and discrete choice experiment will assess the feasibility of implementation of both digital technologies within a real-life setting. Patients with a suspicion of retinal disease, undergoing eye examination and optical coherence tomography (OCT) scans, will be recruited across 24 optometry practices in the UK. Optometry practices will be randomised to standard care or teleophthalmology. The primary outcome is the proportion of false-positive referrals (unnecessary HES visits) in the current referral pathway compared with the teleophthalmology referral pathway. OCT scans will be interpreted by the AI DSS, which provides a diagnosis and referral decision and the primary outcome for the AI diagnostic study is diagnostic accuracy of the referral decision made by the Moorfields-DeepMind AI system. Secondary outcomes relate to inappropriate referral rate, cost-effectiveness analyses and human-computer interaction (HCI) analyses. Ethics and dissemination Ethical approval was obtained from the London-Bromley Research Ethics Committee (REC 20/LO/1299). Findings will be reported through academic journals in ophthalmology, health services research and HCI.",ophthalmology; medical retina; health services administration & management; health economics; telemedicine
Proceedings Paper,"Khan, Muhammad Zubair; Lee, Yugyung",Dynamic Inductive Transfer Learning with Decision Support Feedback to Optimize Retina Analysis,2021 ieee 9th international conference on healthcare informatics (ichi 2021),2021,Not found,"The retina is a unique tissue considered an extension of a brain that transforms the incoming light into neural signals. Numerous deep neural networks are developed to segment retinal images precisely for detecting diabetic retinopathy and glaucoma. However, these networks are limited in selecting evaluation metrics and tuning hyperparameters subjectively in the model validation process. Furthermore, the segmentation networks lack a progressive mode of model tuning for active transfer learning. This article proposed a novel technique of dynamic inductive learning with single-point decision criteria, striving to optimize the image segmentation model using multi-criteria decision support feedback. A case study is conducted to reveal the problems related to the conventional approach and establish the significance of a proposed concept with empirical evidence. It is found that dynamic inductive transfer learning reduces the subjectivity of hyperparameter selection in a model validation process. For a given challenge of retinal vessel extraction, stochastic gradient descent is considered an optimal candidate for two variants of dynamic inductive transfer learning with a decision score of 0.9634 and 0.9951, respectively. This effort would serve as a vital step towards an optimal disease diagnosis.",transfer learning; optimization; retinal vessels; segmentation model; decision system
Article,"Schlegl, Thomas; Waldstein, Sebastian M.; Bogunovic, Hrvoje; Endstrasser, Franz; Sadeghipour, Amir; Philip, Ana-Maria; Podkowinski, Dominika; Gerendas, Bianca S.; Langs, Georg; Schmidt-Erfurth, Ursula",Fully Automated Detection and Quantification of Macular Fluid in OCT Using Deep Learning,ophthalmology,2018,Not found,"Purpose: Development and validation of a fully automated method to detect and quantify macular fluid in conventional OCT images. Design: Development of a diagnostic modality. Participants: The clinical dataset for fluid detection consisted of 1200 OCT volumes of patients with neovascular age-related macular degeneration (AMD, n = 400), diabetic macular edema (DME, n = 400), or retinal vein occlusion (RVO, n = 400) acquired with Zeiss Cirrus (Carl Zeiss Meditec, Dublin, CA) (n = 600) or Heidelberg Spectralis (Heidelberg Engineering, Heidelberg, Germany) (n = 600) OCT devices. Methods: A method based on deep learning to automatically detect and quantify intraretinal cystoid fluid (IRC) and subretinal fluid (SRF) was developed. The performance of the algorithm in accurately identifying fluid localization and extent was evaluated against a manual consensus reading of 2 masked reading center graders. Main Outcome Measures: Performance of a fully automated method to accurately detect, differentiate, and quantify intraretinal and SRF using area under the receiver operating characteristics curves, precision, and recall. Results: The newly designed, fully automated diagnostic method based on deep learning achieved optimal accuracy for the detection and quantification of IRC for all 3 macular pathologies with a mean accuracy (AUC) of 0.94 (range, 0.91-0.97), a mean precision of 0.91, and a mean recall of 0.84. The detection and measurement of SRF were also highly accurate with an AUC of 0.92 (range, 0.86-0.98), a mean precision of 0.61, and a mean recall of 0.81, with superior performance in neovascular AMD and RVO compared with DME, which was represented rarely in the population studied. High linear correlation was confirmed between automated and manual fluid localization and quantification, yielding an average Pearson's correlation coefficient of 0.90 for IRC and of 0.96 for SRF. Conclusions: Deep learning in retinal image analysis achieves excellent accuracy for the differential detection of retinal fluid types across the most prevalent exudative macular diseases and OCT devices. Furthermore, quantification of fluid achieves a high level of concordance with manual expert assessment. Fully automated analysis of retinal OCT images from clinical routine provides a promising horizon in improving accuracy and reliability of retinal diagnosis for research and clinical practice in ophthalmology. (C) 2017 by the American Academy of Ophthalmology. This is an open access article under the CC BY-NC-ND license (http://creativecommons.org/licenses/by-nc-nd/4.0/).",optical coherence tomography; visual-acuity; diabetic-retinopathy; anatomic outcomes; subretinal fluid; degeneration; edema; identification; segmentation; ranibizumab
Proceedings Paper,"Zhou, Yi; Huang, Lei; Zhou, Tao; Shao, Ling",CCT-Net: Category-Invariant Cross-Domain Transfer for Medical Single-to-Multiple Disease Diagnosis,2021 ieee/cvf international conference on computer vision (iccv 2021),2021,Not found,"A medical imaging model is usually explored for the diagnosis of a single disease. However, with the expanding demand for multi-disease diagnosis in clinical applications, multi-function solutions need to be investigated. Previous works proposed to either exploit different disease labels to conduct transfer learning through fine-tuning, or transfer knowledge across different domains with similar diseases. However, these methods still cannot address the real clinical challenge - a multi-disease model is required but annotations for each disease are not always available. In this paper, we introduce the task of transferring knowledge from single-disease diagnosis (source domain) to enhance multidisease diagnosis (target domain). A category-invariant cross-domain transfer (CCT) method is proposed to address this single-to-multiple extension. First, for domain-specific task learning, we present a confidence weighted pooling (CWP) to obtain coarse heatmaps for different disease categories. Then, conditioned on these heatmaps, categoryinvariant feature refinement (CIFR) blocks are proposed to better localize discriminative semantic regions related to the corresponding diseases. The category-invariant characteristic enables transferability from the source domain to the target domain. We validate our method in two popular areas: extending diabetic retinopathy to identifying multiple ocular diseases, and extending glioma identification to the diagnosis of other brain tumors.",deep; segmentation
Proceedings Paper,"Beluch, William H.; Genewein, Tim; Nuernberger, Andreas; Koehler, Jan M.",The power of ensembles for active learning in image classification,2018 ieee/cvf conference on computer vision and pattern recognition (cvpr),2018,Not found,"Deep learning methods have become the de-facto standard for challenging image processing tasks such as image classification. One major hurdle of deep learning approaches is that large sets of labeled data are necessary, which can be prohibitively costly to obtain, particularly in medical image diagnosis applications. Active learning techniques can alleviate this labeling effort. In this paper we investigate some recently proposed methods for active learning with high-dimensional data and convolutional neural network classifiers. We compare ensemble-based methods against Monte-Carlo Dropout and geometric approaches. We find that ensembles perform better and lead to more calibrated predictive uncertainties, which are the basis for many active learning algorithms. To investigate why Monte-Carlo Dropout uncertainties perform worse, we explore potential differences in isolation in a series of experiments. We show results for MNIST and CIFAR-10, on which we achieve a test set accuracy of 90% with roughly 12,200 labeled images, and initial results on ImageNet. Additionally, we show results on a large, highly class-imbalanced diabetic retinopathy dataset. We observe that the ensemble-based active learning effectively counteracts this imbalance during acquisition.",backpropagation; worldwide
Article,"Naghshvarianjahromi, Mahdi; Majumder, Sumit; Kumar, Shiva; Naghshvarianjahromi, Narjes; Deen, M. Jamal",Natural Brain-Inspired Intelligence for Screening in Healthcare Applications,ieee access,2021,Not found,"In recent years, there has been a growing interest in smart e-Health systems to improve people's quality-of-life by enhancing healthcare accessibility and reducing healthcare costs. Continuous monitoring of health through the smart e-Health system may enable automatic diagnosis of diseases like Arrhythmia at its early onset that otherwise may become fatal if not detected on time. In this work, we developed a cognitive dynamic system (CDS)-based framework for the smart e-Health system to realize an automatic screening process in the presence of a defective or abnormal dataset. A defective dataset may have poor labeling and/or lack enough training patterns. To mitigate the adverse effect of such a defective dataset, we developed a decision-making system that is inspired by the decision-making processes in humans in case of conflict-of-opinions (CoO). We present a proof-of-concept implementation of this framework to automatically identify people having Arrhythmia from single lead Electrocardiogram (ECG) traces. It is shown that the proposed CDS performs well with the diagnosis errors of 13.2%, 9.9%, 6.6%, and 4.6%, being in good agreement with the desired diagnosis errors of 25%, 10%, 5.9%, and 2.5%, respectively. The proposed CDS algorithm can be incorporated in the autonomic computing layer of a smart-e-Health-home platform to achieve a pre-defined degree of screening accuracy in the presence of a defective dataset.",artificial intelligence; machine learning; decision making; medical services; prediction algorithms; classification algorithms; supervised learning; autonomic decision-making system; autonomic computing layer; cognitive dynamic system (cds); cognitive decision making (cdm); non-gaussian and non-linear environment; ngnle; screening; smart systems; defective dataset; e-health; smart home; conflict of opinions
Proceedings Paper,"Chen, Chunhui; Chuah, Joon Huang; Ali, Raza",Retinal Vessel Segmentation In Fundus Images Using Convolutional Neural Network,2021 international conference on high performance big data and intelligent systems (hpbd&is),2021,Not found,"The structure of retinal vessel can reflect health status of patients, and a clear representation of retinal vessel map helps ophthalmologist to make diagnosis of some disease, such as diabetic retinopathy (DR) and hypertension. However most automatic methods for the task cannot produce a good performance, they always misclassify pixels in vessel boundaries and thin vessels. In this paper, we propose a deep learning-based model for automatic accurate retinal vessel segmentation. We cascaded two U-net to construct a multi-model network and then obtain a coarse-to-fine segmentation. We introduced residual learning and added sufficient skip connections to reuse feature maps. We adopted dilated convolution and arranged dilation rates carefully to enable the model to capture more context information. Finally, we conducted intensive experiments on DRIVE, STARE, and CHASE_DB1 databases. Our proposed model can produce an accuracy of 0.9552/0.9699/0.9642, an AUC of 0.9787/0.9852/0.9846, a sensitivity of 0.8211/0.8466/0.8395 on DRIVE, STARE and CHASE_DB1 databases, respectively.",retinal vessel segmentation; fundus image; deep learning; convolutional neural network
Proceedings Paper,"Braovic, Maja; Bozic-Stulic, Dunja; Stipanicev, Darko",A Review of Image Processing and Deep Learning Based Methods for Automated Analysis of Digital Retinal Fundus Images,2018 3rd international conference on smart and sustainable technologies (splitech),2018,Not found,"Retinal fundus imaging is a medical procedure used by medical professionals in the discovery and tracking of various retinal abnormalities. Sometimes the analysis of retinal fundus images can be slow and difficult when performed by medical staff, and in response to this many automated, image-processing based methods for the analysis of these images exist. In recent years, deep learning methods have become increasingly popular in machine learning applications, so it is no surprise that they are also being used in the image processing based analysis of retinal fundus images. In this paper we discuss recently proposed methods that use deep learning techniques in the image processing based analysis of digital retinal fundus images. Special attention is given to the analysis of retinal fundus image datasets and various techniques employed to the images from these datasets in order to make them suitable for deep learning based applications.",diabetic-retinopathy; vessel segmentation; blood-vessels; lesion detection; neural-networks; matched-filter; optic-nerve; diagnosis; photographs; disk
Article,"Gargari, Manizheh Safarkhani; Seyedi, Mir Hojjat; Alilou, Mehdi",Segmentation of Retinal Blood Vessels Using U-Net++ Architecture and Disease Prediction,electronics,2022,Not found,"This study presents a segmentation method for the blood vessels and provides a method for disease diagnosis in individuals based on retinal images. Blood vessel segmentation in images of the retina is very challenging in medical analysis and diagnosis. It is an essential tool for a wide range of medical diagnoses. After segmentation and binary image improvement operations, the resulting binary images are processed and the features in the blood vessels are used as feature vectors to categorize retinal images and diagnose the type of disease available. To carry out the segmentation task and disease diagnosis, we used a deep learning approach involving a convolutional neural network (CNN) and U-Net++ architecture. A multi-stage method is used in this study to better diagnose the disease using retinal images. Our proposed method includes improving the color image of the retina, applying the Gabor filter to produce images derived from the green channel, segmenting the green channel by receiving images produced from the Gabor filter using U-Net++, extracting HOG and LBP features from binary images, and finally disease diagnosis using a one-dimensional convolutional neural network. The DRIVE and MESSIDOR image banks have been used to segment the image, determine the areas related to blood vessels in the retinal image, and evaluate the proposed method for retinal disease diagnosis. The achieved results for accuracy, sensitivity, specificity, and F1-score are 98.9, 94.1, 98.8, 85.26, and, 98.14, respectively, in the DRIVE dataset and the obtained results for accuracy, sensitivity, and specificity are 98.6, 99, 98, respectively, in MESSIDOR dataset. Hence, the presented system outperforms the manual approach applied by skilled ophthalmologists.",u-net++; convolutional neural network; deep learning; medical imaging; segmentation; blood vessels; gabor filter; disease diagnosis
Article,"Ai, Zhuang; Huang, Xuan; Feng, Jing; Wang, Hui; Tao, Yong; Zeng, Fanxin; Lu, Yaping",FN-OCT: Disease Detection Algorithm for Retinal Optical Coherence Tomography Based on a Fusion Network,frontiers in neuroinformatics,2022,Not found,"Optical coherence tomography (OCT) is a new type of tomography that has experienced rapid development and potential in recent years. It is playing an increasingly important role in retinopathy diagnoses. At present, due to the uneven distributions of medical resources in various regions, the uneven proficiency levels of doctors in grassroots and remote areas, and the development needs of rare disease diagnosis and precision medicine, artificial intelligence technology based on deep learning can provide fast, accurate, and effective solutions for the recognition and diagnosis of retinal OCT images. To prevent vision damage and blindness caused by the delayed discovery of retinopathy, a fusion network (FN)-based retinal OCT classification algorithm (FN-OCT) is proposed in this paper to improve upon the adaptability and accuracy of traditional classification algorithms. The InceptionV3, Inception-ResNet, and Xception deep learning algorithms are used as base classifiers, a convolutional block attention mechanism (CBAM) is added after each base classifier, and three different fusion strategies are used to merge the prediction results of the base classifiers to output the final prediction results (choroidal neovascularization (CNV), diabetic macular oedema (DME), drusen, normal). The results show that in a classification problem involving the UCSD common retinal OCT dataset (108,312 OCT images from 4,686 patients), compared with that of the InceptionV3 network model, the prediction accuracy of FN-OCT is improved by 5.3% (accuracy = 98.7%, area under the curve (AUC) = 99.1%). The predictive accuracy and AUC achieved on an external dataset for the classification of retinal OCT diseases are 92 and 94.5%, respectively, and gradient-weighted class activation mapping (Grad-CAM) is used as a visualization tool to verify the effectiveness of the proposed FNs. This finding indicates that the developed fusion algorithm can significantly improve the performance of classifiers while providing a powerful tool and theoretical support for assisting with the diagnosis of retinal OCT.",fusion network; optical coherence tomography; attention mechanism; retinal disease; model interpretability
Article,"Park, Sang Jun; Shin, Joo Young; Kim, Sangkeun; Son, Jaemin; Jung, Kyu-Hwan; Park, Kyu Hyung",A Novel Fundus Image Reading Tool for Efficient Generation of a Multi-dimensional Categorical age Database for Machine Learning Algorithm Training,journal of korean medical science,2018,Not found,"Background: We described a novel multi-step retinal fundus image reading system for providing high-quality large data for machine learning algorithms, and assessed the grader variability in the large-scale dataset generated with this system. Methods: A 5-step retinal fundus image reading tool was developed that rates image quality, presence of abnormality, findings with location information, diagnoses, and clinical significance. Each image was evaluated by 3 different graders. Agreements among graders for each decision were evaluated. Results: The 234,242 readings of 79,458 images were collected from 55 licensed ophthalmologists during 6 months. The 34,364 images were graded as abnormal by at-least one rater. Of these, all three raters agreed in 46.6% in abnormality, while 69.9% of the images were rated as abnormal by two or more raters. Agreement rate of at-least two raters on a certain finding was 26.7%-65.2%, and complete agreement rate of all-three raters was 5.7%-43.3%. As for diagnoses, agreement of at-least two raters was 35.6%-65.6%, and complete agreement rate was 11.0%-0-40.0%. Agreement of findings and diagnoses were higher when restricted to images with prior complete agreement on abnormality. Retinal/glaucoma specialists showed higher agreements on findings and diagnoses of their corresponding subspecialties. Conclusion: This novel reading tool for retinal fundus images generated a large-scale dataset with high level of information, which can be utilized in future development of machine learning-based algorithms for automated identification of abnormal conditions and clinical decision supporting system. These results emphasize the importance of addressing grader variability in algorithm developments.",retina fundus image; reading tool; grader; machine learning; deep learning
Article,"Yang, Hyunmo; Ahn, Yujin; Askaruly, Sanzhar; You, Joon S. S.; Kim, Sang Woo; Jung, Woonggyu",Deep Learning-Based Glaucoma Screening Using Regional RNFL Thickness in Fundus Photography,diagnostics,2022,Not found,"Since glaucoma is a progressive and irreversible optic neuropathy, accurate screening and/or early diagnosis is critical in preventing permanent vision loss. Recently, optical coherence tomography (OCT) has become an accurate diagnostic tool to observe and extract the thickness of the retinal nerve fiber layer (RNFL), which closely reflects the nerve damage caused by glaucoma. However, OCT is less accessible than fundus photography due to higher cost and expertise required for operation. Though widely used, fundus photography is effective for early glaucoma detection only when used by experts with extensive training. Here, we introduce a deep learning-based approach to predict the RNFL thickness around optic disc regions in fundus photography for glaucoma screening. The proposed deep learning model is based on a convolutional neural network (CNN) and utilizes images taken with fundus photography and with RNFL thickness measured with OCT for model training and validation. Using a dataset acquired from normal tension glaucoma (NTG) patients, the trained model can estimate RNFL thicknesses in 12 optic disc regions from fundus photos. Using intuitive thickness labels to identify localized damage of the optic nerve head and then estimating regional RNFL thicknesses from fundus images, we determine that screening for glaucoma could achieve 92% sensitivity and 86.9% specificity. Receiver operating characteristic (ROC) analysis results for specificity of 80% demonstrate that use of the localized mean over superior and inferior regions reaches 90.7% sensitivity, whereas 71.2% sensitivity is reached using the global RNFL thicknesses for specificity at 80%. This demonstrates that the new approach of using regional RNFL thicknesses in fundus images holds good promise as a potential screening technique for early stage of glaucoma.",glaucoma; normal-tension glaucoma; color fundus photographs; optical coherence tomography; retinal nerve fiber layer; convolutional neural networks; screening
Proceedings Paper,"Ozgunalp, Umar; Fan, Rui; Serener, Ali",Semantic Segmentation of Retinal Vessels Using SegNet,2020 28th signal processing and communications applications conference (siu),2020,Not found,"Automated retinal vessel segmentation is useful for diagnosis of many pathological diseases such as diabetic retinopathy, hypertensive retinopathy, and glaucoma. In this paper, an algorithm for semantic segmentation of retinal vessels based on semantic pixel-wise segmentation (SegNet) is presented where the network is initialized using the VGG-16 network. The High-Resolution Fundus (HRF) image database has been used for training and testing the network, where in this dataset 15 images from healthy, 15 images from diabetic, and 15 images from eyes with glaucoma are hand labeled for retinal vessels. Because of the limited number of hand-labeled images, first, a data augmentation has been applied where reflection, scaling, translation, and rotation are used for this purpose. Then class weighting is applied to minimize the issues due to the imbalanced dataset. When tested with HRF dataset, sensitivity has been estimated as 73.72%, specificity has been estimated as 94.85%, and accuracy has been estimated as 93.23%.",deep learning; retinal vessel segmentation; segnet; semantic segmentation; vgg16
Article,"Zheng, Ce; Xie, Xiaolin; Zhou, Kang; Chen, Bang; Chen, Jili; Ye, Haiyun; Li, Wen; Qiao, Tong; Gao, Shenghua; Yang, Jianlong; Liu, Jiang",Assessment of Generative Adversarial Networks Model for Synthetic Optical Coherence Tomography Images of Retinal Disorders,translational vision science & technology,2020,Not found,"Purpose: To assess whether a generative adversarial network (GAN) could synthesize realistic optical coherence tomography (OCT) images that satisfactorily serve as the educational images for retinal specialists, and the training datasets for the classification of various retinal disorders using deep learning (DL). Methods: The GANs architecture was adopted to synthesize high-resolution OCT images trained on a publicly available OCT dataset, including urgent referrals (37,206 OCT images from eyes with choroidal neovascularization, and 11,349 OCT images from eyes with diabetic macular edema) and nonurgent referrals (8617 OCT images from eyes with drusen, and 51,140 OCT images from normal eyes). Four hundred real and synthetic OCT images were evaluated by two retinal specialists (with over 10 years of clinical retinal experience) to assess image quality. We further trained two DL models on either real or synthetic datasets and compared the performance of urgent versus nonurgent referrals diagnosis tested on a local (1000 images from the public dataset) and clinical validation dataset (278 images from Shanghai Shibei Hospital). Results: The image quality of real versus synthetic OCT images was similar as assessed by two retinal specialists. The accuracy of discrimination of real versus synthetic OCT images was 59.50% for retinal specialist 1 and 53.67% for retinal specialist 2. For the local dataset, the DL model trained on real (DL_Model_R) and synthetic OCT images (DL_Model_S) had an area under the curve (AUC) of 0.99, and 0.98, respectively. For the clinical dataset, the AUC was 0.94 for DL_Model_R and 0.90 for DL_Model_S. Conclusions: The GAN synthetic OCT images can be used by clinicians for educational purposes and for developing DL algorithms. Translational Relevance: The medical image synthesis based on GANs is promising in humans and machines to fulfill clinical tasks.",optical coherence tomography; retinal disorders; deep learning; generative adversarial networks
Article,"Zhang, Wei; Dai, Yan; Liu, Miao; Chen, Yuanyuan; Zhong, Jie; Yi, Zhang",DeepUWF-plus: automatic fundus identification and diagnosis system based on ultrawide-field fundus imaging,applied intelligence,2021,Not found,"Poor eye health is a major public health problem, and the timely detection and diagnosis of fundus abnormalities is important for eye health protection. Traditional imaging models can hinder the comprehensive evaluation of fundus abnormalities due to the use of a narrow field of view. The emerging ultrawide-field (UWF) imaging model surpasses this limitation in a non invasive, wide-view manner and is suitable for fundus observation and screening. Nevertheless, manual screening is labour intensive and subjective, especially in the absence of an ophthalmologist. Therefore, a set of auxiliary screening methods for a fundus screening service using a combination of deep learning and UWF imaging technology, which is designated as DeepUWF-Plus, is proposed. This service includes a subsystem for the screening of fundus, a subsystem for the identification of abnormalities regarding four important fundus locations, and a subsystem for the diagnosis of four retinal diseases that threaten vision. The influence of two-stage and one-stage classification strategies on the prediction performance of the model is experimentally investigated to alleviate severe class imbalance and similarity between classes, and evaluate the effectiveness and reliability of the system. Our experimental results show that DeepUWF-Plus is effective when using the two-stage strategy, especially for identifying signs or symptoms of minor diseases. DeepUWF-Plus can improve the practicality of fundus screening and enable ophthalmologists to provide more comprehensive fundus assessments.",deep learning; convolutional neural network; ultra-wide-field (uwf) imaging; fundus screening
Article,"Guo, Tianjiao; Liang, Ziyun; Gu, Yun; Yang, Jie; Yu, Qi",Deep multi-task framework for optic disc and fovea detection,journal of electronic imaging,2021,Not found,"The detection of the optic disk (OD) and fovea is crucial to the automatic diagnosis based on fundus images. This task is very challenging, especially when varieties of lesions exist. Traditional handcrafted feature-based methods are inaccurate, and deep learning based methods fail easily in abnormal cases. We propose a framework that simultaneously detects the OD and fovea based on deep convolutional neural networks. The original image is first preprocessed and then followed by pseudo label generation. These labels are then fed into a fully convolutional neural network with residual modules for localization of the OD and fovea. Polar transformation is then introduced to the segmentation of the OD. The proposed algorithm achieves a relatively high success rate for OD localization and a 100% success rate for fovea localization on several public datasets. For the segmentation of the OD, the proposed algorithm achieves a low overlapping error on several public datasets. Compared with previous work, the proposed method achieves promising accuracy and robustness, and it is useful for practical applications since it detects the OD and fovea simultaneously and completely. (c) 2021 SPIE and IS&T [DOI: 10.1117/1. JEI.30.4.043002]",retinal image; convolutional neural network; detection; optic disc; fovea
Article,"Deng, Liwei; Wang, Xiaofei; Xu, Jiazhong",Multifeature Detection of Microaneurysms Based on Improved SSA,symmetry-basel,2021,Not found,"The early diagnosis of retinopathy is crucial to the prevention and treatment of diabetic retinopathy. The low proportion of positive cases in the asymmetric microaneurysm detection problem causes preprocessing to treat microaneurysms as noise to be eliminated. To obtain a binary image containing microaneurysms, the object was segmented by a symmetry algorithm, which is a combination of the connected components and SSA methods. Next, a candidate microaneurysm set was extracted by multifeature clustering of binary images. Finally, the candidate microaneurysms were mapped to the Radon frequency domain to achieve microaneurysm detection. In order to verify the feasibility of the algorithm, a comparative experiment was conducted on the combination of the connected components and SSA methods. In addition, PSNR, FSIM, SSIM, fitness value, average CPU time and other indicators were used as evaluation standards. The results showed that the overall performance of the binary image obtained by the algorithm was the best. Last but not least, the accuracy of the detection method for microaneurysms in this paper reached up to 93.24%, which was better than that of several classic microaneurysm detection methods in the same period.",ssa; connection components; diabetic retina; asymmetric microaneurysm; radon transform
Article,"Almasi, Ramin; Vafaei, Abbas; Kazeminasab, Elahe; Rabbani, Hossein",Automatic detection of microaneurysms in optical coherence tomography images of retina using convolutional neural networks and transfer learning,scientific reports,2022,Not found,"Microaneurysms (MAs) are pathognomonic signs that help clinicians to detect diabetic retinopathy (DR) in the early stages. Automatic detection of MA in retinal images is an active area of research due to its application in screening processes for DR which is one of the main reasons of blindness amongst the working-age population. The focus of these works is on the automatic detection of MAs in en face retinal images like fundus color and Fluorescein Angiography (FA). On the other hand, detection of MAs from Optical Coherence Tomography (OCT) images has 2 main advantages: first, OCT is a non-invasive imaging technique that does not require injection, therefore is safer. Secondly, because of the proven application of OCT in detection of Age-Related Macular Degeneration, Diabetic Macular Edema, and normal cases, thanks to detecting MAs in OCT, extensive information is obtained by using this imaging technique. In this research, the concentration is on the diagnosis of MAs using deep learning in the OCT images which represent in-depth structure of retinal layers. To this end, OCT B-scans should be divided into strips and MA patterns should be searched in the resulted strips. Since we need a dataset comprising OCT image strips with suitable labels and such large labelled datasets are not yet available, we have created it. For this purpose, an exact registration method is utilized to align OCT images with FA photographs. Then, with the help of corresponding FA images, OCT image strips are created from OCT B-scans in four labels, namely MA, normal, abnormal, and vessel. Once the dataset of image strips is prepared, a stacked generalization (stacking) ensemble of four fine-tuned, pre-trained convolutional neural networks is trained to classify the strips of OCT images into the mentioned classes. FA images are used once to create OCT strips for training process and they are no longer needed for subsequent steps. Once the stacking ensemble model is obtained, it will be used to classify the OCT strips in the test process. The results demonstrate that the proposed framework classifies overall OCT image strips and OCT strips containing MAs with accuracy scores of 0.982 and 0.987, respectively.",fluorescein angiography; diabetic-retinopathy
Article,"Li, Feng; Chen, Hua; Liu, Zheng; Zhang, Xue-Dian; Jiang, Min-Shan; Wu, Zhi-Zheng; Zhou, Kai-Qian",Deep learning-based automated detection of retinal diseases using optical coherence tomography images,biomedical optics express,2019,Not found,"Retinal disease classification is a significant problem in computer-aided diagnosis (CAD) for medical applications. This paper is focused on a 4-class classification problem to automatically detect choroidal neovascularization (CNV), diabetic macular edema (DME), DRUSEN, and NORMAL in optical coherence tomography (OCT) images. The proposed classification algorithm adopted an ensemble of four classification model instances to identify retinal OCT images, each of which was based on an improved residual neural network (ResNet50). The experiment followed a patient-level 10-fold cross-validation process, on development retinal OCT image dataset. The proposed approach achieved 0.973 (95% confidence interval [CI], 0.971-0.975) classification accuracy, 0.963 (95% CI, 0.960-0.966) sensitivity, and 0.985 (95% CI, 0.983-0.987) specificity at the B-scan level, achieving a matching or exceeding performance to that of ophthalmologists with significant clinical experience. Other performance measures used in the study were the area under receiver operating characteristic curve (AUC) and kappa value. The observations of the study implied that multi-ResNet50 ensembling was a useful technique when the availability of medical images was limited. In addition, we performed qualitative evaluation of model predictions, and occlusion testing to understand the decision-making process of our model. The paper provided an analytical discussion on misclassification and pathology regions identified by the occlusion testing also. Finally, we explored the effect of the integration of retinal OCT images and medical history data from patients on model performance. (C) 2019 Optical Society of America under the terms of the OSA Open Access Publishing Agreement",diabetic macular edema; layer boundaries; degeneration; segmentation; fluid; classification; identification; retinopathy
Article,"Sotoudeh-Paima, Saman; Jodeiri, Ata; Hajizadeh, Fedra; Soltanian-Zadeh, Hamid",Multi-scale convolutional neural network for automated AMD classification using retinal OCT images,computers in biology and medicine,2022,Not found,"Background and objective: Age-related macular degeneration (AMD) is the most common cause of blindness in developed countries, especially in people over 60 years of age. The workload of specialists and the healthcare system in this field has increased in recent years mainly due to three reasons: 1) increased use of retinal optical coherence tomography (OCT) imaging technique, 2) prevalence of population aging worldwide, and 3) chronic nature of AMD. Recent advancements in the field of deep learning have provided a unique opportunity for the development of fully automated diagnosis frameworks. Considering the presence of AMD-related retinal pa-thologies in varying sizes in OCT images, our objective was to propose a multi-scale convolutional neural network (CNN) that can capture inter-scale variations and improve performance using a feature fusion strategy across convolutional blocks.& nbsp;Methods: Our proposed method introduces a multi-scale CNN based on the feature pyramid network (FPN) structure. This method is used for the reliable diagnosis of normal and two common clinical characteristics of dry and wet AMD, namely drusen and choroidal neovascularization (CNV). The proposed method is evaluated on the national dataset gathered at Hospital (NEH) for this study, consisting of 12649 retinal OCT images from 441 patients, and the UCSD public dataset, consisting of 108312 OCT images from 4686 patients.& nbsp;Results: Experimental results show the superior performance of our proposed multi-scale structure over several well-known OCT classification frameworks. This feature combination strategy has proved to be effective on all tested backbone models, with improvements ranging from 0.4% to 3.3%. In addition, gradual learning has proved to be effective in improving performance in two consecutive stages. In the first stage, the performance was boosted from 87.2% +/- 2.5% to 92.0% +/- 1.6% using pre-trained ImageNet weights. In the second stage, another performance boost from 92.0% +/- 1.6% to 93.4% +/- 1.4% was observed as a result of fine-tuning the previous model on the UCSD dataset. Lastly, generating heatmaps provided additional proof for the effectiveness of our multi-scale structure, enabling the detection of retinal pathologies appearing in different sizes.& nbsp;Conclusion: The promising quantitative results of the proposed architecture, along with qualitative evaluations through generating heatmaps, prove the suitability of the proposed method to be used as a screening tool in healthcare centers assisting ophthalmologists in making better diagnostic decisions.",age-related macular degeneration; feature pyramid networks; multi-scale convolutional neural networks; deep learning; optical coherence tomography (oct)
Article,"Mitra, Anirban; Banerjee, Priya Shankar; Roy, Sudipta; Roy, Somasis; Setua, Sanjit Kumar",The region of interest localization for glaucoma analysis from retinal fundus image using deep learning,computer methods and programs in biomedicine,2018,Not found,"Background and objectives: Retinal fundus image analysis without manual intervention has been rising as an imperative analytical approach for early detection of eye-related diseases such as glaucoma and diabetic retinopathy. For analysis and detection of Glaucoma and some other disease from retinal image, there is a significant role of predicting the bounding box coordinates of Optic Disc (OD) that acts as a Region of Interest (ROI). Methods: We reframe ROI detection as a solitary regression predicament, from image pixel values to ROI coordinates including class probabilities. A Convolution Neural Network (CNN) has trained on full images to predict bounding boxes along with their analogous probabilities and confidence scores. The publically available MESSIDOR and Kaggle datasets have been used to train the network. We adopted various data augmentation techniques to amplify our dataset so that our network becomes less sensitive to noise. From a very high-level perspective, every image is divided into a 13 x 13 grid. Every grid cell envisages 5 bounding boxes along with the corresponding class probability and a confidence score. Before training, the network and the bounding box priors or anchors are initialized using k-means clustering on the original dataset using a distance metric based on Intersection of the Union (IOU) over ground-truth bounding boxes. During training in fact, a sum-squared loss function is used as the prediction's error function. Finally, Non-maximum suppression is applied by the proposed methodology to reach the concluding prediction. Results: The following projected method accomplish an accuracy of 99.05% and 98.78% on the Kaggle and MESSIDOR test sets for ROI detection. Results of proposed methodology indicates that proposed network is able to perceive ROI in fundus images in 0.0045 s at 25 ms of latency, which is far better than the recent-time and using no handcrafted features. Conclusions: The network predicts accurate results even on low-quality images without being biased towards any particular type of image. The network prepared to see more summed up depiction rather than past works in the field. Going by the results, our novel method has better diagnosis of eye diseases in the future in a faster and reliable way. (C) 2018 Elsevier B.V. All rights reserved.","optic disc localization; anchor boxes; k-means clustering; intersection over union; convolution neural networks; batch normalization; leaky relu, max pooling; non-maximum suppression"
Proceedings Paper,"Lv, Wenqi; Fu, Rongxin; Lin, Xue; Su, Ya; Jin, Xiangyu; Yang, Han; Shan, Xiaohui; Du, Wenli; Jiang, Kai; Lin, Yuanhua; Huang, Guoliang",A non-invasive diabetes diagnosis method based on novel scleral imaging instrument and AI,optics in health care and biomedical optics xi,2021,Not found,"Type 2 diabetes mellitus is one of the most common metabolic diseases in the world. However, frequent blood glucose testing causes continual harm to diabetics, which cannot meet the needs of early diagnosis and long-term tracking of diabetes. Thus non-invasive adjuvant diagnosis methods are urgently needed, enabling early screening of the population for diabetes, the evaluation of diabetes risk, and assessment of therapeutic effects. The human eye plays an important role in painless and non-invasive approaches, because it is considered an internal organ but can be easily be externally observed. We developed an AI model to predict the probability of diabetes from scleral images taken by a specially developed instrument, which could conveniently and quickly collect complete scleral images in four directions and perform artificial intelligence (AI) analysis in 3 min without any reagent consumption or the need for a laboratory. The novel optical instrument could adaptively eliminate reflections and collected shadow-free scleral images. 177 subjects were recruited to participate in this experiment, including 127 benign subjects and 50 malignant subjects. The blood sample and sclera images from each subject was obtained. The scleral image classification model achieved a mean AUC over 0.85, which indicates great potential for early screening of practical diabetes during periodic physical checkups or daily family health monitoring. With this AI scleral features imaging and analysis method, diabetic patients' health conditions can be rapidly, noninvasively, and accurately analyzed, which offers a platform for noninvasive forecasting, early diagnosis, and long-term monitoring for diabetes and its complications.",type 2 diabetes mellitus; shadow-free scleral images; u-net; resnet-18; mil
Article; Early Access,"Panahi, Amirhossein; Moghadam, Reza Askari; Tarvirdizadeh, Bahram; Madani, Kurosh",Simplified U-Net as a deep learning intelligent medical assistive tool in glaucoma detection,evolutionary intelligence,0,Not found,"Glaucoma is looked on as the most important cause of irremediable vision loss worldwide. Early detection of eye diseases, especially glaucoma is serious for preparing timely medical care and keep downing the vision loss. In this paper, a fast segmentation algorithm is proposed which is based on a new simplified U-Net architecture for optic disc and retinal vessels segmentation. The proposed method includes a modified and reinforced structure that will reduce the prediction time while maintaining the performance and accuracy at an comparable level due to other state of the art methods. For example, for optic disc segmentation, the proposed method can segment the optic disc in 0.008 seconds on DRIONS-DB dataset, and for vessels segmentation,it can segment in 0.03 seconds on DRIVE dataset. According to these results and an extension of the proposed method can be used as a real-time intelligent medical system which able to be implemented on the usual hardware equipement in the ophthalmology clinics. This method, which can perform optic disc and retinal vessels segmentation tasks in a short time, increases the performance of ophthalmologists in glaucoma diagnosing.",deep learning; simplified u-net; image processing; glaucoma; optic disc segmentation; blood vessel segmentation; medical applications
Article,"Zhao, Hanli; Qiu, Xiaqing; Lu, Wanglong; Huang, Hui; Jin, Xiaogang",High-quality retinal vessel segmentation using generative adversarial network with a large receptive field,international journal of imaging systems and technology,2020,Not found,"Retinal vessel segmentation is of great significance for assisting doctors in diagnosis of ophthalmological diseases such as diabetic retinopathy, macular degeneration and glaucoma. This article proposes a new retinal vessel segmentation algorithm using generative adversarial learning with a large receptive field. A generative network maps an input retinal fundus image to a realistic vessel image while a discriminative network differentiates between images drawn from the database and the generative network. Firstly, the proposed generative network combines shallow features with the upsampled deep features to assemble a more precise vessel image. Secondly, the residual module in the proposed generative and discriminative networks can effectively help deep nets easy to optimize. Moreover, the dilated convolutions in the proposed generative network effectively enlarge the receptive field without increasing the amount of computations. A number of experiments are conducted on two publicly available datasets (DRIVE and STARE) achieving the segmentation accuracy rates of 95.63% and 96.84%, and the average areas under the ROC curve of 98.12% and 98.53%. Performance results show that the proposed automatic retinal vessel segmentation algorithm outperforms state-of-the-art algorithms in many validation metrics. The proposed algorithm can not only detect small tiny blood vessels but also capture large-scale high-level semantic vessel features.",dilated convolution; generative adversarial network; receptive field; retinal vessel segmentation
Article,"Guo, Song",CSGNet: Cascade semantic guided net for retinal vessel segmentation,biomedical signal processing and control,2022,Not found,"Retinal vessels are essential biomarkers for the early diagnosis of ophthalmic diseases. Accurate segmentation of retinal vessels is necessary for further quantitative analysis of fundus images. With the development of deep learning, many deep segmentation models have been proposed and show promising results. Nevertheless, segmentation performance is not satisfactory in tiny vessels and low-contrast vessels. A cascade semantic guided network (CSGNet) is proposed to address this problem. CSGNet follows a low-to-high pipeline, where low-resolution semantic-rich features are first learned. Then, higher-resolution features are learned under the guidance of low-resolution features. In this way, CSGNet is expected to learn both semantic-rich and detail-preserved high-resolution representations to facilitate the segmentation of thin vessels. Meantime, a multi-scale and multi-directional feature learning (M2FL) module is developed, which leverages two strip convolutions and two dilated convolutions to align with the shape of vessels and encode context information. Extensive experiments are conducted to validate the segmentation performance of the proposed method over six public datasets, including four photography datasets (CHASE_DB1, DRIVE, STARE, HRF) and two color scanning laser ophthalmoscopy datasets (IOSTAR, RC-SLO). Also, the proposed method is compared with several popular deep learning-based models. Experimental results show that the proposed method achieves comparable or superior segmentation performance compared with other deep learning-based models with fewer parameters and faster segmentation speed. Meantime, cross-training experiments demonstrate the competitive generalization capability of the proposed method.",semantic guided; high-resolution feature; strip convolution; vessel segmentation; fundus image
Article,"Dai, Guangzheng; He, Wei; Xu, Ling; Pazo, Eric E.; Lin, Tiezhu; Liu, Shasha; Zhang, Chenguang",Exploring the effect of hypertension on retinal microvasculature using deep learning on East Asian population,plos one,2020,Not found,"Hypertension is the leading risk factor of cardiovascular disease and has profound effects on both the structure and function of the microvasculature. Abnormalities of the retinal vasculature may reflect the degree of microvascular damage due to hypertension, and these changes can be detected with fundus photographs. This study aimed to use deep learning technique that can detect subclinical features appearing below the threshold of a human observer to explore the effect of hypertension on morphological features of retinal microvasculature. We collected 2012 retinal photographs which included 1007 from patients with a diagnosis of hypertension and 1005 from normotensive control. By method of vessel segmentation, we removed interference information other than retinal vasculature and contained only morphological information about blood vessels. Using these segmented images, we trained a small convolutional neural networks (CNN) classification model and used a deep learning technique called Gradient-weighted Class Activation Mapping (Grad-CAM) to generate heat maps for the class hypertension. Our model achieved an accuracy of 60.94%, a specificity of 51.54%, a precision of 59.27%, and a recall of 70.48%. The AUC was 0.6506. In the heat maps for the class hypertension, red patchy areas were mainly distributed on or around arterial/venous bifurcations. This indicated that the model has identified these regions as being the most important for predicting hypertension. Our study suggested that the effect of hypertension on retinal microvascular morphology mainly occurred at branching of vessels. The change of the branching pattern of retinal vessels was probably the most significant in response to elevated blood pressure.",cardiovascular risk-factors; elevated blood-pressure; vessel diameters; diabetic-retinopathy; atherosclerosis risk; arteriolar diameter; vascular caliber; microcirculation; age; abnormalities
Article,"Li, Yanhan; Zhao, Hongyun; Gan, Tian; Liu, Yang; Zou, Lian; Xu, Ting; Chen, Xuan; Fan, Cien; Wu, Meng",Automated Multi-View Multi-Modal Assessment of COVID-19 Patients Using Reciprocal Attention and Biomedical Transform,frontiers in public health,2022,Not found,"Automated severity assessment of coronavirus disease 2019 (COVID-19) patients can help rationally allocate medical resources and improve patients' survival rates. The existing methods conduct severity assessment tasks mainly on a unitary modal and single view, which is appropriate to exclude potential interactive information. To tackle the problem, in this paper, we propose a multi-view multi-modal model to automatically assess the severity of COVID-19 patients based on deep learning. The proposed model receives multi-view ultrasound images and biomedical indices of patients and generates comprehensive features for assessment tasks. Also, we propose a reciprocal attention module to acquire the underlying interactions between multi-view ultrasound data. Moreover, we propose biomedical transform module to integrate biomedical data with ultrasound data to produce multi-modal features. The proposed model is trained and tested on compound datasets, and it yields 92.75% for accuracy and 80.95% for recall, which is the best performance compared to other state-of-the-art methods. Further ablation experiments and discussions conformably indicate the feasibility and advancement of the proposed model.",covid-19; deep learning; multi-view; multi-modal; computer aided diagnosis
Article,"Wu, Yicheng; Xia, Yong; Song, Yang; Zhang, Yanning; Cai, Weidong",NFN plus : A novel network followed network for retinal vessel segmentation,neural networks,2020,Not found,"In the early diagnosis of diabetic retinopathy, the morphological attributes of blood vessels play an essential role to construct a retinal computer-aided diagnosis system. However, due to the challenges including limited densely annotated data, inter-vessel differences and structured prediction problem, it remains challenging to segment accurately the retinal vessels, particularly the capillaries on color fundus images. To address these issues, in this paper, we propose a novel deep learning-based model called NFN+ to effectively extract multi-scale information and make full use of deep feature maps. In NFN+, the front network converts an image patch into a probabilistic retinal vessel map, and the followed network further refines the map to achieve a better post-processing module, which helps represent the vessel structures implicitly. We employ the inter-network skip connections to unite two identical multi-scale backbones, which enables the useful multi-scale features to be directly transferred from shallow layers to deeper layers. The refined probabilistic retinal vessel maps produced from the augmented images are then averaged to construct the segmentation results. We evaluated this model on the digital retinal images for vessel extraction (DRIVE), structured analysis of the retina (STARE), and the child heart and health study (CHASE) databases. Our results indicate that the elaborated cascaded designs can produce performance gain and the proposed NFN+ model, to our best knowledge, achieved the state-of-the-art retinal vessel segmentation accuracy on color fundus images (AUC: 98.30%, 98.75% and 98.94%, respectively). (c) 2020 Elsevier Ltd. All rights reserved.",retinal vessel segmentation; deep learning; cascaded networks; skip connections
Article,"Amin, Samina; Alouffi, Bader; Uddin, M. Irfan; Alosaimi, Wael",Optimizing Convolutional Neural Networks with Transfer Learning for Making Classification Report in COVID-19 Chest X-Rays Scans,scientific programming,2022,Not found,"The coronavirus disease (COVID-19) outbreak, which began in December 2019, has claimed numerous lives and impacted all aspects of human life. COVID-19 was deemed an outbreak by the World Health Organization (WHO) as time passed, putting a tremendous strain on substantially all countries, particularly those with poor health services and delayed reaction times. This recently identified virus is highly contagious. Controlling the rapid spread of this infection requires early detection of infected people through comprehensive screening. For COVID-19 viral diagnosis and follow-up, chest radiography imaging is an excellent tool. Deep learning (DL) has been used for a variety of healthcare purposes, including diabetic retinopathy detection, image classification, and thyroid diagnosis. DL is a useful strategy for combating the COVID-19 outbreak because there are so many streams of medical images (e.g., X-rays, CT, and MRI). In this study, we used the benchmark chest X-ray scan (CXRS) dataset for both COVID-19-infected and noninfected patients. We evaluate the results of DL-based convolutional neural network (CNN) models after preprocessing the scans and using data augmentation. Transfer learning (TL) is used to improve the algorithm's classification performance for chest radiography imaging. Finally, features of the attention and feature interweave modules are combined to create a more accurate feature map. The architecture is trained for COVID-19 CXRS using CNN, and the newly generated feature layer is applied to TL architecture. The experimental results found that training enhances the CNN + TL algorithm's ability to classify CXRS with an overall detection accuracy of 99.3%, precision (0.97), recall (0.98), f-measure (0.98), and receiver operating characteristic (ROC) curve (area = 0.97). The results show that further training improves the classification architecture's performance by 99.3%.",automatic detection; coronavirus; ct; sars-cov-2
Article,"Bernabe, Omar; Acevedo, Elena; Acevedo, Antonio; Carreno, Ricardo; Gomez, Sandra",Classification of Eye Diseases in Fundus Images,ieee access,2021,Not found,"Eye diseases have been a severe problem worldwide, especially in developing countries where technology and finance are limited. Today, the problem is being resolved thanks to the task of classification that is part of pattern recognition. Its primary goal is to group standard features from any entity, object, phenomenon, or event belonging to the real or abstract world. Convolutional Neural Networks are a type of Artificial Neural Network used in intelligent pattern classification, Machine Learning, and Data Mining. Also, medicine and ophthalmology used these algorithms for detecting diseases in the human body. This work presents a novel intelligent pattern classification algorithm based on a Convolutional Neural network, which is validated through the K-Fold Cross Validation test. Two different groups of retinography images are given: Glaucoma and Diabetic Retinopathy. The result of accuracy percentage was 99.89%. Numerical metrics: Accuracy, Recall, Specificity Precision, and F-1 score with values close to 1, and ROC curves support the suitable performance of the proposed classifier.",retinopathy; diabetes; retina; optical imaging; optical filters; nonlinear filters; maximum likelihood detection; artificial intelligence; convolutional neural networks; machine learning; supervised learning
Proceedings Paper,"Adarsh, R.; Amarnageswarao, Gadipudi; Pandeeswari, R.; Deivalakshmi, S.",Dense Residual Convolutional Auto Encoder For Retinal Blood Vessels Segmentation,2020 6th international conference on advanced computing and communication systems (icaccs),2020,Not found,"In order to overcome the difficulties in retinal blood vessel segmentation and aid ophthalmologists in diagnosis of diabetic retinopathy and glaucoma, there is a need for effective segmentation techniques. One such efficient technique is to use a model for segmentation using deep learning In this paper, an auto encoder deep learning network model based on residual path and U-net has been implemented to effectively segment the retinal blood vessels. Our network model has been implemented and tested on DRIVE dataset. This proposed model is reporting an increase in efficiency and Area under ROC compared to previous methods.",residual network; u-net; retinal vessels; medical image segmentation
Article,"Badgeley, Marcus A.; Liu, Manway; Glicksberg, Benjamin S.; Shervey, Mark; Zech, John; Shameer, Khader; Lehar, Joseph; Oermann, Eric K.; McConnell, Michael V.; Snyder, Thomas M.; Dudley, Joel T.",CANDI: an R package and Shiny app for annotating radiographs and evaluating computer-aided diagnosis,bioinformatics,2019,Not found,"Motivation Radiologists have used algorithms for Computer-Aided Diagnosis (CAD) for decades. These algorithms use machine learning with engineered features, and there have been mixed findings on whether they improve radiologists' interpretations. Deep learning offers superior performance but requires more training data and has not been evaluated in joint algorithm-radiologist decision systems. Results We developed the Computer-Aided Note and Diagnosis Interface (CANDI) for collaboratively annotating radiographs and evaluating how algorithms alter human interpretation. The annotation app collects classification, segmentation, and image captioning training data, and the evaluation app randomizes the availability of CAD tools to facilitate clinical trials on radiologist enhancement. Availability and implementation Demonstrations and source code are hosted at (https://candi.nextgenhealthcare.org), and (https://github.com/mbadge/candi), respectively, under GPL-3 license. Supplementary information Supplementary material is available at Bioinformatics online.",diabetic-retinopathy; lung nodules; validation
Article,"Rahman, Aamer Abdul; Biswal, Birendra; Pavani, P. Geetha; Hasan, Shazia; Sairam, M. V. S.",Robust segmentation of vascular network using deeply cascaded AReN-UNet,biomedical signal processing and control,2021,Not found,"Retinal vessel segmentation is an essential step for non-invasive diagnosis and analysis of ocular pathologies such as diabetic retinopathy, glaucoma, etc. Although several deep learning networks have been implemented for segmenting vascular maps, still further modification can be carried out on the existing deep learning networks for precise segmentation of vascular maps. This paper presents a novel cascaded AReN-UNet (Attention Residual U Network), driven by the integration of attention and residual modules. The proposed network is implemented by cascading two deep learning networks of depth 4. In the second network, each encoder receives the feature maps from the previous convolutional block. In addition to this, the feature maps of a respective convolutional block of the preceding network are also fed as input to the convolutional block of the second network. Furthermore, aggregated residual and attention modules in the cascaded AReN-UNet are used to improve convergence and stability of the network which eventually reduces the vessel breakdowns in the vascular map. The proposed model is trained and evaluated on different datasets such as DRIVE, CHASE_DB1, and one locally collected dataset. The proposed network illustrates the state-of-the-art performance by achieving an accuracy, F1 score, sensitivity, specificity, and Area Under the Curve (AUC) of 96.96%, 82.63%, 83.68%, 98.35%, and 98.67% respectively on the DRIVE dataset and 97.70%, 82.01%, 85.60%, 98.35%, and 99.01% respectively on the CHASE_DB1 dataset.",retinal fundus images; convolutional neural networks; segmentation; cascaded aren-unet; attention module; residual module
Article,"Imran, Azhar; Li, Jianqiang; Pei, Yan; Yang, Ji-Jiang; Wang, Qing",Comparative Analysis of Vessel Segmentation Techniques in Retinal Images,ieee access,2019,Not found,"The blood vessels are the primary anatomical structure that can be visible in retinal images. The segmentation of retinal blood vessels has been accepted worldwide for the diagnosis of both cardiovascular (CVD) and retinal diseases. Thus, it requires an appropriate vessel segmentation method for automatic detection of retinal diseases such as diabetic retinopathy and cataract. The detection of retinal diseases using computer-aided diagnosis (CAD) can help people to avoid the risks of visual impairment and save medical resources. This survey presents a comparative analysis of various machine learning and deep learning-based methods for automated blood vessel segmentation in retinal images. This paper briefiy describes fundus photography, publicly available retinal databases, pre-processing and post-processing techniques for retinal vessels segmentation. A comprehensive review of the state of the art supervised and unsupervised blood vessel segmentation methodologies are presented in this paper. The objective of this study is to establish a professional structure to familiarize an individual with up-to-date vessel segmentation techniques. Moreover, we compared these approaches to the dataset, evaluation metrics, pre-processing and post-processing steps, feature extraction, segmentation methods, and induced results.",vessel segmentation; retinal diseases; image segmentation; retinal fundus images; medical imaging
Article,"Raza, Mohsin; Naveed, Khuram; Akram, Awais; Salem, Nema; Afaq, Amir; Madni, Hussain Ahmad; Khan, Mohammad A. U.; Mui-zzud-din",DAVS-NET: Dense Aggregation Vessel Segmentation Network for retinal vasculature detection in fundus images,plos one,2021,Not found,"In this era, deep learning-based medical image analysis has become a reliable source in assisting medical practitioners for various retinal disease diagnosis like hypertension, diabetic retinopathy (DR), arteriosclerosis glaucoma, and macular edema etc. Among these retinal diseases, DR can lead to vision detachment in diabetic patients which cause swelling of these retinal blood vessels or even can create new vessels. This creation or the new vessels and swelling can be analyzed as biomarker for screening and analysis of DR. Deep learning-based semantic segmentation of these vessels can be an effective tool to detect changes in retinal vasculature for diagnostic purposes. This segmentation task becomes challenging because of the low-quality retinal images with different image acquisition conditions, and intensity variations. Existing retinal blood vessels segmentation methods require a large number of trainable parameters for training of their networks. This paper introduces a novel Dense Aggregation Vessel Segmentation Network (DAVS-Net), which can achieve high segmentation performance with only a few trainable parameters. For faster convergence, this network uses an encoder-decoder framework in which edge information is transferred from the first layers of the encoder to the last layer of the decoder. Performance of the proposed network is evaluated on publicly available retinal blood vessels datasets of DRIVE, CHASE_DB1, and STARE. Proposed method achieved state-of-the-art segmentation accuracy using a few number of trainable parameters.",blood-vessels; diabetic-retinopathy; sensitivity
Article,"Ou, Xingyuan; Gao, Li; Quan, Xiongwen; Zhang, Han; Yang, Jinglong; Li, Wei",BFENet: A two-stream interaction CNN method for multi-label ophthalmic diseases classification with bilateral fundus images,computer methods and programs in biomedicine,2022,Not found,"Background and objective: Early fundus screening and timely treatment of ophthalmology diseases can effectively prevent blindness. Previous studies just focus on fundus images of single eye without utilizing the useful relevant information of the left and right eyes. While clinical ophthalmologists usually use binocular fundus images to help ocular disease diagnosis. Besides, previous works usually target only one ocular diseases at a time. Considering the importance of patient-level bilateral eye diagnosis and multi-label ophthalmic diseases classification, we propose a bilateral feature enhancement network (BFENet) to address the above two problems. Methods: We propose a two-stream interactive CNN architecture for multi-label ophthalmic diseases classification with bilateral fundus images. Firstly, we design a feature enhancement module, which makes use of the interaction between bilateral fundus images to strengthen the extracted feature information. Specifically, attention mechanism is used to learn the interdependence between local and global information in the designed interactive architecture for two-stream, which leads to the reweighting of these features, and recover more details. In order to capture more disease characteristics, we further design a novel multiscale module, which enriches the feature maps by superimposing feature information of different resolutions images extracted through dilated convolution. Results: In the off-site set, the Kappa, F-1, AUC and Final score are 0.535, 0.892, 0.912 and 0.780, respectively. In the on-site set, the Kappa, F-1, AUC and Final score are 0.513, 0.886, 0.903 and 0.767 respectively. Comparing with existing methods, BFENet achieves the best classification performance. Conclusions: Comprehensive experiments are conducted to demonstrate the effectiveness of this proposed model. Besides, our method can be extended to similar tasks where the correlation between different images is important. (C) 2022 Elsevier B.V. All rights reserved.",ocular disease classification; feature enhancement; patient-level diagnosis; multi-label; convolutional neural network
Article,"Arsalan, Muhammad; Haider, Adnan; Koo, Ja Hyung; Park, Kang Ryoung",Segmenting Retinal Vessels Using a Shallow Segmentation Network to Aid Ophthalmic Analysis,mathematics,2022,Not found,"Retinal blood vessels possess a complex structure in the retina and are considered an important biomarker for several retinal diseases. Ophthalmic diseases result in specific changes in the retinal vasculature; for example, diabetic retinopathy causes the retinal vessels to swell, and depending upon disease severity, fluid or blood can leak. Similarly, hypertensive retinopathy causes a change in the retinal vasculature due to the thinning of these vessels. Central retinal vein occlusion (CRVO) is a phenomenon in which the main vein causes drainage of the blood from the retina and this main vein can close completely or partially with symptoms of blurred vision and similar eye problems. Considering the importance of the retinal vasculature as an ophthalmic disease biomarker, ophthalmologists manually analyze retinal vascular changes. Manual analysis is a tedious task that requires constant observation to detect changes. The deep learning-based methods can ease the problem by learning from the annotations provided by an expert ophthalmologist. However, current deep learning-based methods are relatively inaccurate, computationally expensive, complex, and require image preprocessing for final detection. Moreover, existing methods are unable to provide a better true positive rate (sensitivity), which shows that the model can predict most of the vessel pixels. Therefore, this study presents the so-called vessel segmentation ultra-lite network (VSUL-Net) to accurately extract the retinal vasculature from the background. The proposed VSUL-Net comprises only 0.37 million trainable parameters and uses an original image as input without preprocessing. The VSUL-Net uses a retention block that specifically maintains the larger feature map size and low-level spatial information transfer. This retention block results in better sensitivity of the proposed VSUL-Net without using expensive preprocessing schemes. The proposed method was tested on three publicly available datasets: digital retinal images for vessel extraction (DRIVE), structured analysis of retina (STARE), and children's heart health study in England database (CHASE-DB1) for retinal vasculature segmentation. The experimental results demonstrated that VSUL-Net provides robust segmentation of retinal vasculature with sensitivity (Sen), specificity (Spe), accuracy (Acc), and area under the curve (AUC) values of 83.80%, 98.21%, 96.95%, and 98.54%, respectively, for DRIVE, 81.73%, 98.35%, 97.17%, and 98.69%, respectively, for CHASE-DB1, and 86.64%, 98.13%, 97.27%, and 99.01%, respectively, for STARE datasets. The proposed method provides an accurate segmentation mask for deep ophthalmic analysis.",retina; fundus image; retinal vasculature; retinal disorders; semantic segmentation
Article,"Zheng, Rui; Liu, Lei; Zhang, Shulin; Zheng, Chun; Bunyak, Filiz; Xu, Ronald; Li, Bin; Sun, Mingzhai",Detection of exudates in fundus photographs with imbalanced learning using conditional generative adversarial network,biomedical optics express,2018,Not found,"Diabetic retinopathy (DR) is a leading cause of blindness worldwide. However, 90% of DR caused blindness can be prevented if diagnosed and intervened early. Retinal exudates can be observed at the early stage of DR and can be used as signs for early DR diagnosis. Deep convolutional neural networks (DCNNs) have been applied for exudate detection with promising results. However, there exist two main challenges when applying the DCNN based methods for exudate detection. One is the very limited number of labeled data available from medical experts, and another is the severely imbalanced distribution of data of different classes. First, there are many more images of normal eyes than those of eyes with exudates, particularly for screening datasets. Second, the number of normal pixels (non-exudates) is much greater than the number of abnormal pixels (exudates) in images containing exudates. To tackle the small sample set problem, an ensemble convolutional neural network (MU-net) based on a U-net structure is presented in this paper. To alleviate the imbalance data problem, the conditional generative adversarial network (cGAN) is adopted to generate label-preserving minority class data specifically to implement the data augmentation. The network was trained on one dataset (e_ophtha_EX) and tested on the other three public datasets (DiaReTDB1, HEI-MED and MESSIDOR). CLAN, as a data augmentation method, significantly improves network robustness and generalization properties, achieving F1-scores of 92.79%, 92.46%, 91.27%, and 94.34%, respectively, as measured at the lesion level. While without cGAN, the corresponding F1-scores were 92.66%, 91.41%, 90.72%, and 90.58%, respectively. When measured at the image level, with cGAN we achieved the accuracy of 95.45%, 92.13%, 88.76%, and 89.58%, compared with the values achieved without cGAN of 86.36%, 87.64%, 76.33%, and 86.42%, respectively. (C) 2018 Optical Society of America under the terms of the OSA Open Access Publishing Agreement",color retinal images; diabetic-retinopathy; automated detection; segmentation
Article,"Wang, Jing; Yang, Liu; Huo, Zhanqiang; He, Weifeng; Luo, Junwei",Multi-Label Classification of Fundus Images With EfficientNet,ieee access,2020,Not found,"Convolutional neural network (CNN) has achieved remarkable success in the field of fundus images due to its powerful feature learning ability. Computer-aided diagnosis can obtain information with reference value for doctors in clinical diagnosis or screening through proper processing and analysis of fundus images. However, most of the previous studies have focused on the detection of a certain fundus disease, and the simultaneous diagnosis of multiple fundus diseases still faces great challenges. We propose a multi-label classification ensemble model of fundus images based on CNN to directly detect one or more fundus diseases in the retinal fundus images. Every single model consists of two parts. The first part is a feature extraction network based on EfficientNet, and the second part is a custom classification neural network for multi-label classification problems. Finally, the output probabilities of different models are fused as the final recognition result. And it was trained and tested on the data set provided by ODIR 2019 (Peking University International Competition on Ocular Disease Intelligent Recognition). The experimental results show that our model can be trained on fewer data sets and get good results.",diseases; feature extraction; neural networks; deep learning; data models; training; diabetes; cnn; deep learning; ensemble learning; fundus images; multi label classification; transfer learning
Article,"Henry, Asha Gnana Priya; Jude, Anitha",Convolutional neural-network-based classification of retinal images with different combinations of filtering techniques,open computer science,2021,Not found,"Retinal image analysis is one of the important diagnosis methods in modern ophthalmology because eye information is present in the retina. The image acquisition process may have some effects and can affect the quality of the image. This can be improved by better image enhancement techniques combined with the computer-aided diagnosis system. Deep learning is one of the important computational application techniques used for a medical imaging application. The main aim of this article is to find the best enhancement techniques for the identification of diabetic retinopathy (DR) and are tested with the commonly used deep learning techniques, and the performances are measured. In this article, the input image is taken from the Indian-based database named as Indian Diabetic Retinopathy Image Dataset, and 13 filters are used including smoothing and sharpening filters for enhancing the images. Then, the quality of the enhancement techniques is compared using performance metrics and better results are obtained for Median, Gaussian, Bilateral, Wiener, and partial differential equation filters and are combined for improving the enhancement of images. The output images from all the enhanced filters are given as the convolutional neural network input and the results are compared to find the better enhancement method.",dr; retinal image enhancement; filters; performance metrics; cnn
Article,"Liu, Xiaofeng; Fan, Fangfang; Kong, Lingsheng; Diao, Zhihui; Xie, Wanqing; Lu, Jun; You, Jane",Unimodal regularized neuron stick-breaking for ordinal classification,neurocomputing,2020,Not found,"This paper targets for the ordinal regression/classification, which objective is to learn a rule to predict labels from a discrete but ordered set. For instance, the classification for medical diagnosis usually involves inherently ordered labels corresponding to the level of health risk. Previous multi-task classifiers on ordinal data often use several binary classification branches to compute a series of cumulative probabilities. However, these cumulative probabilities are not guaranteed to be monotonically decreasing. It also introduces a large number of hyper-parameters to be fine-tuned manually. This paper aims to eliminate or at least largely reduce the effects of those problems. We propose a simple yet efficient way to rephrase the output layer of the conventional deep neural network. Besides, in order to alleviate the effects of label noise in ordinal datasets, we propose a unimodal label regularization strategy. It also explicitly encourages the class predictions to distribute on nearby classes of ground truth. We show that our methods lead to the state-of-the-art accuracy on the medical diagnose task (e.g., Diabetic Retinopathy and Ultrasound Breast dataset) as well as the face age prediction (e.g., Adience face and MORPH Album II) with very little additional cost. (C) 2020 Elsevier B.V. All rights reserved.",ordinal regression; deep neural network; stick-breaking
Proceedings Paper,"Joshi, Vinayak; Wigdahl, Jeffery; Benson, Jeremy; Nemeth, Sheila; Soliz, Peter",Computer-based detection of Age-Related Macular Degeneration and Glaucoma using retinal images and clinical data,medical imaging 2019: computer-aided diagnosis,2019,Not found,"Worldwide, glaucoma and age-related macular degeneration (AMD) cause 12.3% and 8.7% of the cases of blindness and/or vision loss, respectively. According to a 5-year study of Medicare beneficiaries, patients who undergo a regular eye screening, experience less decline of vision than those who had less-frequent examinations. A computer-based screening of retinopathies can be highly cost-effective and efficient; however, most auto-screening software address only one eye disease, limiting their clinical utility and cost-effectiveness. Therefore, we propose a computer-based retinopathy screening system for detection of AMD and glaucoma by integrating information from retinal fundus images and clinical data. First, the retinal image analysis algorithms were developed using Transfer Learning approach to determine presence or absence of the eye disease. The clinical data was then utilized to improve disease detection performance where the image-analysis based algorithms provided sub-optimal classification. The results for binary detection (present/absent) of AMD and Glaucoma were compared with the ground truth provided by a certified retinal reader. We applied the proposed method to a dataset of 304 retinal images with AMD, 299 retinal images with Glaucoma, and 2,341 control retinal images. The algorithms demonstrated sensitivity/specificity of 100%/99.5% for detection of any AMD, 82%/70% for detection of referable AMD, and 75%/81% for detection of referable Glaucoma. The automated detection results agree well with the ground truth suggesting its potential in screening for AMD and Glaucoma.",age-related macular degeneration (amd); glaucoma; retina; eye disease screening; deep learning
Article,"Fu, Huazhu; Li, Fei; Sun, Xu; Cao, Xingxing; Liao, Jingan; Orlando, Jose Ignacio; Tao, Xing; Li, Yuexiang; Zhang, Shihao; Tan, Mingkui; Yuan, Chenglang; Bian, Cheng; Xie, Ruitao; Li, Jiongcheng; Li, Xiaomeng; Wang, Jing; Geng, Le; Li, Panming; Hao, Huaying; Liu, Jiang; Kong, Yan; Ren, Yongyong; Bogunovic, Hrvoje; Zhang, Xiulan; Xu, Yanwu; Zhang, Yichi; Li, Nuhui; Yang, Chunman; Luo, Huang; Li, Xingyi; Deng, Feiyan; Sun, Yi; Zhou, Rouxi",AGE challenge: Angle Closure Glaucoma Evaluation in Anterior Segment Optical Coherence Tomography,medical image analysis,2020,Not found,"Angle closure glaucoma (ACG) is a more aggressive disease than open-angle glaucoma, where the abnormal anatomical structures of the anterior chamber angle (ACA) may cause an elevated intraocular pressure and gradually lead to glaucomatous optic neuropathy and eventually to visual impairment and blindness. Anterior Segment Optical Coherence Tomography (AS-OCT) imaging provides a fast and contactless way to discriminate angle closure from open angle. Although many medical image analysis algorithms have been developed for glaucoma diagnosis, only a few studies have focused on AS-OCT imaging. In particular, there is no public AS-OCT dataset available for evaluating the existing methods in a uniform way, which limits progress in the development of automated techniques for angle closure detection and assessment. To address this, we organized the Angle closure Glaucoma Evaluation challenge (AGE), held in conjunction with MICCAI 2019. The AGE challenge consisted of two tasks: scleral spur localization and angle closure classification. For this challenge, we released a large dataset of 4800 annotated AS-OCT images from 199 patients, and also proposed an evaluation framework to benchmark and compare different models. During the AGE challenge, over 200 teams registered online, and more than 1100 results were submitted for online evaluation. Finally, eight teams participated in the onsite challenge. In this paper, we summarize these eight onsite challenge methods and analyze their corresponding results for the two tasks. We further discuss limitations and future directions. In the AGE challenge, the top-performing approach had an average Euclidean Distance of 10 pixels (10 mu m) in scleral spur localization, while in the task of angle closure classification, all the algorithms achieved satisfactory performances, with two best obtaining an accuracy rate of 100%. These artificial intelligence techniques have the potential to promote new developments in AS-OCT image analysis and image-based angle closure glaucoma assessment in particular. (C) 2020 Elsevier B.V. All rights reserved.",as-oct; anterior chamber angle; angle closure classification; scleral spur localization
Proceedings Paper,"Gende, Mateo; de Moura, Joaquim; Novo, Jorge; Ortega, Marcos",High/Low Quality Style Transfer for Mutual Conversion of OCT Images Using Contrastive Unpaired Translation Generative Adversarial Networks,"image analysis and processing, iciap 2022, pt i",2022,Not found,"Recent advances in artificial intelligence and deep learning models are contributing to the development of advanced computer-aided diagnosis (CAD) systems. In the context of medical imaging, Optical Coherence Tomography (OCT) is a valuable technique that is able to provide cross-sectional visualisations of the ocular tissue. However, OCT is constrained by a limitation between the quality of the visualisations that it can produce and the overall amount of tissue that can be analysed at once. This limitation leads to a scarcity of high quality data, a problem that is very prevalent when developing machine learning-based CAD systems intended for medical imaging. To mitigate this problem, we present a novel methodology for the unpaired conversion of OCT images acquired with a low quality extensive scanning preset into the visual style of those taken with a high quality intensive scan and vice versa. This is achieved by employing contrastive unpaired translation generative adversarial networks to convert between the visual styles of the different acquisition presets. The results we obtained in the validation experiments show that these synthetic generated images can mirror the visual features of the original ones while preserving the natural tissue texture, effectively increasing the total number of available samples that can be used to train robust machine learning-based CAD systems.",optical coherence tomography; generative adversarial networks; style transfer; synthetic images
Article,"Zhang, Dan; Huang, Fan; Khansari, Maziyar; Berendschot, Tos T. J. M.; Xu, Xiayu; Dashtbozorg, Behdad; Sun, Yue; Zhang, Jiong; Tan, Tao",Automatic corneal nerve fiber segmentation and geometric biomarker quantification,european physical journal plus,2020,Not found,"Geometric and topological features of corneal nerve fibers in confocal microscopy images are important indicators for the diagnosis of common diseases such as diabetic neuropathy. Quantitative analysis of these important biomarkers requires an accurate segmentation of the nerve fiber network. Currently, most of the analysis are performed based on manual annotations of the nerve fiber segments, while a fully automatic corneal nerve fiber extraction and analysis framework is still needed. In this paper, we establish a fully convolutional network method to precisely enhance and segment corneal nerve fibers in microscopy images. Based on the segmentation results, automatic tortuosity measurement and branching detection modules are established to extract valuable geometric and topological biomarkers. The proposed segmentation method is validated on a dataset with 142 images. The experimental results show that our deep learning-based framework outperforms state-of-the-art segmentation approaches. The biomarker extraction methods are validated on two different datasets, demonstrating high effectiveness and reliability of the proposed methods.",confocal-microscopy; diabetic-retinopathy; diagnosis; tortuosity; images; damage
Article,"Jiang, Yun; Yao, Huixia; Wu, Chao; Liu, Wenhuan",A Multi-Scale Residual Attention Network for Retinal Vessel Segmentation,symmetry-basel,2021,Not found,"Accurate segmentation of retinal blood vessels is a key step in the diagnosis of fundus diseases, among which cataracts, glaucoma, and diabetic retinopathy (DR) are the main diseases that cause blindness. Most segmentation methods based on deep convolutional neural networks can effectively extract features. However, convolution and pooling operations also filter out some useful information, and the final segmented retinal vessels have problems such as low classification accuracy. In this paper, we propose a multi-scale residual attention network called MRA-UNet. Multi-scale inputs enable the network to learn features at different scales, which increases the robustness of the network. In the encoding phase, we reduce the negative influence of the background and eliminate noise by using the residual attention module. We use the bottom reconstruction module to aggregate the feature information under different receptive fields, so that the model can extract the information of different thicknesses of blood vessels. Finally, the spatial activation module is used to process the up-sampled image to further increase the difference between blood vessels and background, which promotes the recovery of small blood vessels at the edges. Our method was verified on the DRIVE, CHASE, and STARE datasets. Respectively, the segmentation accuracy rates reached 96.98%, 97.58%, and 97.63%; the specificity reached 98.28%, 98.54%, and 98.73%; and the F-measure scores reached 82.93%, 81.27%, and 84.22%. We compared the experimental results with some state-of-art methods, such as U-Net, R2U-Net, and AG-UNet in terms of accuracy, sensitivity, specificity, F-measure, and AUCROC. Particularly, MRA-UNet outperformed U-Net by 1.51%, 3.44%, and 0.49% on DRIVE, CHASE, and STARE datasets, respectively.",deep convolutional neural work; multi-scale; retinal vessel segmentation; attention mechanism; skip connection
Article,"Wang, Hua; Hu, Jingfei; Zhang, Jicong",SCRD-Net: A Deep Convolutional Neural Network Model for Glaucoma Detection in Retina Tomography,complexity,2021,Not found,"Early and accurate diagnosis of glaucoma is critical for avoiding human vision deterioration and preventing blindness. A deep-neural-network model has been developed for the diagnosis of glaucoma based on Heidelberg retina tomography (HRT), called Seeking Common Features and Reserving Differences Net (SCRD-Net) to make full use of the HRT data. In this work, the proposed SCRD-Net model achieved an area under the curve (AUC) of 94.0%. For the two HRT image modalities, the model sensitivities were 91.2% and 78.3% at specificities of 0.85 and 0.95, respectively. These results demonstrate a significant improvement over earlier results. In addition, we visualized the network outputs to develop an interpretation of the learned mechanism for discriminating glaucoma and normal images. Thus, the SCRD-Net can be an effective diagnostic indicator of glaucoma during clinical screening. To facilitate SCRD-Net utilization by the scientific community, the code implementation will be made publicly available.",optic-nerve head; diabetic-retinopathy; learning algorithm; classification; segmentation; images; identification; validation; diagnosis; disc
Article; Early Access,"Sivamurugan, V.; Indumathi, P.; Thanikachalam, V.; Rajakumar, R.",Clinical Decision Support System for Ophthalmologists for Eye Disease Classification,iete journal of research,0,Not found,"In medical applications, ocular OCT (optical coherence tomography) is used to assess glaucoma, macular degeneration, diabetic macular edema and other eye diseases as it is capable of showing the cross-sections of tissue layers. The creation of new blood vessels in the choroid layer of the eye is known as choroidal neovascularization (CNV). The aging and macular degeneration will represent the symptom DRUSEN. Our sharp central vision is affected due to DRUSEN. An irreversible vision loss is caused in diabetic patients due to diabetic macular edema (DME). It is mainly due to the leaking of blood vessels in the retina. This research work focus on designing a clinical decision support system to assist the ophthalmologist in classifying the three different types of eye diseases. The existing nine pre-trained CNN models are used for this purpose. The extracted features are used to generate the trained model that is further used for eye disease classification. The training accuracy, validation accuracy, training loss and validation loss are computed for 100 iterations for each pre-trained CNN models during training and validation. The trained model obtained after training is used as input to the classifier, which classifies the images under-diagnosis into NORMAL (normal eye), CNV, DME and DRUSEN. The performance metrics of the classifier designed using each pre-trained models are evaluated and compared for four classes independently. The test results show that the performance of the classifier implemented using the pre-trained model InceptionV3 is better than all other models.",age-related macular degeneration (amd); choroidal neovascularization (cnv); convolution neural networks (cnn); deep learning (dl); diabetic retinopathy (dr); ophthalmologist; optical coherence tomography (oct); transfer learning (tl)
Article,"He, Junjun; Li, Cheng; Ye, Jin; Qiao, Yu; Gu, Lixu",Multi-label ocular disease classification with a dense correlation deep neural network,biomedical signal processing and control,2021,Not found,"Early diagnosis and timely treatment of ocular diseases are vital to prevent irreversible vision loss. Color fundus photography is an effective and economic tool for fundus screening. Since few symptoms are visible in the early disease stages, automatic and robust diagnosing algorithms according to color fundus photographs are in urgent need. Existing studies concentrate on image-level diagnoses treating the eyes independently without utilizing the useful correlation information between the left and right eyes. Besides, they commonly target only one or several ocular disease categories at a time. Considering the importance of both patient-level diagnosis correlating bilateral eyes and multi-label disease classification, we propose a patient-level multi-label ocular disease classification model based on convolutional neural networks. Specifically, a dense correlation network (DCNet) is designed to tackle the problem. DCNet consists of three major modules, a backbone CNN for feature extraction, a spatial correlation module for feature correlation, and a classifier for classification score generation. The backbone CNN extracts two sets of features from the left and right color fundus photographs, respectively. Subsequently, the spatial correlation module captures the pixel-wise correlations between the two feature sets. Then, the processed features are fused to get a patient-level representation. The final disease classification is conducted with the patient-level representation. Adopting a multi-label soft margin loss, the effectiveness of the proposed model is evaluated on a publicly available dataset, and the classification performance is improved with a large margin compared with multiple baseline methods.",ocular disease classification; dense correlation network; patient-level diagnosis; multi-label annotation
Article,"Groza, Adrian; Toderean, Liana; Muntean, George Adrian; Nicoara, Simona Delia",Agents that Argue and Explain Classifications of Retinal Conditions,journal of medical and biological engineering,2021,Not found,"Purpose Expertise for auditing AI systems in medical domain is only now being accumulated. Conformity assessment procedures will require AI systems: (1) to be transparent, (2) not to rely decisions solely on algorithms, or (3) to include safety assurance cases in the documentation to facilitate technical audit. We are interested here in obtaining transparency in the case of machine learning (ML) applied to classification of retina conditions. High performance metrics achieved using ML has become common practice. However, in the medical domain, algorithmic decisions need to be sustained by explanations. We aim at building a support tool for ophthalmologists able to: (i) explain algorithmic decision to the human agent by automatically extracting rules from the ML learned models; (ii) include the ophthalmologist in the loop by formalising expert rules and including the expert knowledge in the argumentation machinery; (iii) build safety cases by creating assurance argument patterns for each diagnosis. Methods For the learning task, we used a dataset consisting of 699 OCT images: 126 Normal class, 210 with Diabetic Retinopathy (DR) and 363 with Age Related Macular Degeneration (AMD). The dataset contains patients from the Ophthalmology Department of the County Emergency Hospital of Cluj-Napoca. All ethical norms and procedures, including anonymisation, have been performed. We applied three machine learning algorithms: decision tree (DT), support vector machine (SVM) and artificial neural network (ANN). For each algorithm we automatically extract diagnosis rules. For formalising expert knowledge, we relied on the normative dataset (Invernizzi et al. in Ophthalmol Retina 2(8):808-815, 2018). For arguing between agents, we used the Jason multi-agent platform. We assume different knowledge base and reasoning capabilities for each agent. The agents have their own optical coherence tomography (OCT) images on which they apply a distinct machine learning algorithm. The learned model is used to extract diagnosis rules. With distinct learned rules, the agents engage in an argumentative process. The resolution of the debate outputs a diagnosis that is then explained to the ophthalmologist, by means of assurance cases. Results For diagnosing the retina condition, our AI solution deals with the following three issues: first, the learned models are automatically translated into rules. These rules are then used to build an explanation by tracing the reasoning chain supporting the diagnosis. Hence, the proposed AI solution complies with the requirement that algorithmic decision should be explained to the human agent. Second, the decision is not solely based on ML-algorithms. The proposed architecture includes expert knowledge. The diagnosis is taken based on exchanging arguments between ML-based algorithms and expert knowledge. The conflict resolution among arguments is verbalised, so that the ophthalmologist can supervise the diagnosis. Third, the assurance cases are generated to facilitate technical audit. The assurance cases structure the evidence among various safety goals such as: machine learning methodology, transparency, or data quality. For each dimension, the auditor can check the provided evidence against the current best practices or safety standards. Conclusion We developed a multi-agent system for retina conditions in which algorithmic decisions are sustained by explanations. The proposed tool goes behind most software in medical domain that focuses only on performance metrics. Our approach helps the technical auditor to approve software in the medical domain. Interleaving knowledge extracted from ML-models with expert knowledge is a step towards balancing the benefits of ML with explainability, aiming at engineering reliable medical applications.",explainable artificial intelligence; argumentative agents; machine learning; agentspeak; retina conditions
Article,"Rehman, Amjad; Harouni, Majid; Karimi, Mohsen; Saba, Tanzila; Bahaj, Saeed Ali; Awan, Mazar Javed",Microscopic retinal blood vessels detection and segmentation using support vector machine and K-nearest neighbors,microscopy research and technique,2022,Not found,"The retina is the deepest layer of texture covering the rear of the eye, recorded by fundus images. Vessel detection and segmentation are useful in disease diagnosis. The retina's blood vessels could help diagnose maladies such as glaucoma, diabetic retinopathy, and blood pressure. A mix of supervised and unsupervised strategies exists for the detection and segmentation of blood vessels images. The tree structure of retinal blood vessels, their random area, and different thickness have caused vessel detection difficulties at machine learning calculations. Since the green band of retinal images conveys more information about the vessels, they are utilized for microscopic vessels detection. The current research proposes an administered calculation for segmentation of retinal vessels, where two upgrading stages depending on filtering and comparative histogram were applied after pre-processing and image quality improvement. At that point, statistical features of vessel tracking, maximum curvature and curvelet coefficient are extracted for each pixel. The extracted features are classified by support vector machine and the k-nearest neighbors. The morphological operators then enhance the classified image at the final stage to segment with higher accuracy. The dice coefficient is utilized for the evaluation of the proposed method. The proposed approach is concluded to be better than different strategies with a normal of 92%.",blood vessels; healthcare; human and disease; microscopic retina; public health; segmentation; tracking
Proceedings Paper,"Lei, Gaoyi; Xia, Yuanqing; Zhang, Wei; Chen, Duanduan; Wang, Defeng",Comparative Analysis of Pre-process Pipelines For Automatic Retinal Vessel Segmentation,proceedings of the 39th chinese control conference,2020,Not found,"Retinal vessel structure is an unique individual characteristic and important biology marker of many diseases, like Diabetic Retinopathy (DR). cardiovascular ailment, and so on. Automatic retinal vessel segmentation can be used to assist the early diagnosis of above diseases, but suffers from the poor quality and low contrast of fundus images. To eliminate the noise in the fundus images, many pre-process pipelines are designed to normalize and enhance the fundus images. However, the specific operations in pre-process pipelines of the fundus images haven't been distinguished from operations in normalization of natural images. This paper collects a dozen of pre-process pipelines from published retinal vessel segmentation researches, and proposes live general patterns of these pre-process pipelines. Furthermore, we test the flexibility of five classical pre-process pipelines on public retinal vessel datasets with a Dense-UNet model. Experiments demonstrate that the Hiera pre-process pipeline and the DUNet' pre-process pipeline outperform the rest pipelines in assisting the Dense-UNet to segment the retinal vessels.",retinal vessel segmentation; deep learning; pre-process pipeline
Article,"Gao, Qitong; Amason, Joshua; Cousins, Scott; Pajic, Miroslav; Hadziahmetovic, Majda",Automated Identification of Referable Retinal Pathology in Teleophthalmology Setting,translational vision science & technology,2021,Not found,"Purpose: This study aims to meet a growing need for a fully automated, learningbased interpretation tool for retinal images obtained remotely (e.g. teleophthalmology) through different imaging modalities that may include imperfect (uninterpretable) images. Methods: A retrospective study of 1148 optical coherence tomography (OCT) and color fundus photography (CFP) retinal images obtained using Topcon's Maestro care unit on 647 patients with diabetes. To identify retinal pathology, a Convolutional Neural Network (CNN) with dual-modal inputs (i.e. CFP and OCT images) was developed. We developed a novel alternate gradient descent algorithm to train the CNN, which allows for the use of uninterpretable CFP/OCT images (i.e. ungradable images that do not contain sufficient image biomarkers for the reviewer to conclude absence or presence of retinal pathology). Specifically, a 9:1 ratio to split the training and testing dataset was used for training and validating the CNN. Paired CFP/OCT inputs (obtained from a single eye of a patient) were grouped as retinal pathology negative (RPN; 924 images) in the absence of retinal pathology in both imaging modalities, or if one of the imaging modalities was uninterpretable and the other without retinal pathology. If any imaging modality exhibited referable retinal pathology, the corresponding CFP/OCT inputs were deemed retinal pathology positive (RPP; 224 images) if any imaging modality exhibited referable retinal pathology. Results: Our approach achieved 88.60% (95% confidence interval [CI] = 82.76% to 94.43%) accuracy in identifying pathology, along with the false negative rate (FNR) of 12.28% (95% CI = 6.26% to 18.31%), recall (sensitivity) of 87.72% (95% CI = 81.69% to 93.74%), specificity of 89.47% (95% CI = 83.84% to 95.11%), and area under the curve of receiver operating characteristic (AUC-ROC) was 92.74% (95% CI = 87.71% to 97.76%). Conclusions: Our model can be successfully deployed in clinical practice to facilitate automated remote retinal pathology identification. Translational Relevance: A fully automated tool for early diagnosis of retinal pathology might allow for earlier treatment and improved visual outcomes.",deep learning; automated diagnosis; retinal pathology; image analysis; teleophthalmology
Article,"Qian, Yu; Qiu, Yue; Li, Cheng-Cheng; Wang, Zhong-Yuan; Cao, Bo-Wen; Huang, Hong-Xin; Ni, Yi-Hong; Chen, Lu-Lu; Sun, Jin-Yu",A novel diagnostic method for pituitary adenoma based on magnetic resonance imaging using a convolutional neural network,pituitary,2020,Not found,"Purpose This study was designed to develop a computer-aided diagnosis (CAD) system based on a convolutional neural network (CNN) to diagnose patients with pituitary tumors. Methods We included adult patients clinically diagnosed with pituitary adenoma (pituitary adenoma group), or adult individuals without pituitary adenoma (control group). After pre-processing, all the MRI data were randomly divided into training or testing datasets in a ratio of 8:2 to create or evaluate the CNN model. Multiple CNNs with the same structure were applied for different types of MR images respectively, and a comprehensive diagnosis was performed based on the classification results of different types of MR images using an equal-weighted majority voting strategy. Finally, we assessed the diagnostic performance of the CAD system by accuracy, sensitivity, specificity, positive predictive value, and F1 score. Results We enrolled 149 participants with 796 MR images and adopted the data augmentation technology to create 7960 new images. The proposed CAD method showed remarkable diagnostic performance with an overall accuracy of 91.02%, sensitivity of 92.27%, specificity of 75.70%, positive predictive value of 93.45%, and F1-score of 92.67% in separate MRI type. In the comprehensive diagnosis, the CAD achieved better performance with accuracy, sensitivity, and specificity of 96.97%, 94.44%, and 100%, respectively. Conclusion The CAD system could accurately diagnose patients with pituitary tumors based on MR images. Further, we will improve this CAD system by augmenting the amount of dataset and evaluate its performance by external dataset.",pituitary adenoma; diagnose; magnetic resonance imaging; convolutional neural network; artificial intelligence
Proceedings Paper,"Chelaramani, Sahil; Gupta, Manish; Agarwal, Vipul; Gupta, Prashant; Habash, Ranya",Multi-Task Knowledge Distillation for Eye Disease Prediction,2021 ieee winter conference on applications of computer vision wacv 2021,2021,Not found,"While accurate disease prediction from retinal fundus images is critical, collecting large amounts of high quality labeled training data to build such supervised models is difficult. Deep learning classifiers have led to high accuracy results across a wide variety of medical imaging problems, but they need large amounts of labeled data. Given a fundus image, we aim to evaluate various solutions for learning deep neural classifiers using small labeled data for three tasks related to eye disease prediction: (T-1) predicting one of the five broad categories - diabetic retinopathy, age-related macular degeneration, glaucoma, melanoma and normal, (T-2) predicting one of the 320 fine-grained disease sub-categories, (T-3) generating a textual diagnosis. The problem is challenging because of small data size, need for predictions across multiple tasks, handling image variations, and large number of hyper-parameter choices. Modeling the problem under a multi-task learning (MTL) setup, we investigate the contributions of each of the proposed tasks while dealing with a small amount of labeled data. Further, we suggest a novel MTL-based teacher ensemble method for knowledge distillation. On a dataset of 7212 labeled and 35854 unlabeled images across 3502 patients, our technique obtains similar to 83% accuracy, similar to 75% top-5 accuracy and similar to 48 BLEU for tasks T-1, T-2 and T-3 respectively. Even with 15% training data, our method outperforms baselines by 8.1, 3.2 and 11.2 points for the three tasks respectively.",deep; classification; network; cancer
Article,"He, Xingxin; Deng, Ying; Fang, Leyuan; Peng, Qinghua",Multi-Modal Retinal Image Classification With Modality-Specific Attention Network,ieee transactions on medical imaging,2021,Not found,"Recently, automatic diagnostic approaches have been widely used to classify ocular diseases. Most of these approaches are based on a single imaging modality (e.g., fundus photography or optical coherence tomography (OCT)), which usually only reflect the oculopathy to a certain extent, and neglect the modality-specific information among different imaging modalities. This paper proposes a novel modality-specific attention network (MSAN) for multi-modal retinal image classification, which can effectively utilize the modality-specific diagnostic features from fundus and OCT images. The MSAN comprises two attention modules to extract the modality-specific features from fundus and OCT images, respectively. Specifically, for the fundus image, ophthalmologists need to observe local and global pathologies at multiple scales (e.g., from microaneurysms at the micrometer level, optic disc at millimeter level to blood vessels through the whole eye). Therefore, we propose a multi-scale attention module to extract both the local and global features from fundus images. Moreover, large background regions exist in the OCT image, which is meaningless for diagnosis. Thus, a region-guided attention module is proposed to encode the retinal layer-related features and ignore the background in OCT images. Finally, we fuse the modality-specific features to form a multi-modal feature and train the multi-modal retinal image classification network. The fusion of modality-specific features allows the model to combine the advantages of fundus and OCT modality for a more accurate diagnosis. Experimental results on a clinically acquired multi-modal retinal image (fundus and OCT) dataset demonstrate that our MSAN outperforms other well-known single-modal and multi-modal retinal image classification methods.",retina; deep learning; feature extraction; biomedical imaging; optical imaging; image segmentation; training; fundus photography; optical coherence tomography; classification; multi-modal; attention; convolutional neural network
Article,"Kaskar, Omkar G.; Wells-Gray, Elaine; Fleischman, David; Grace, Landon",Evaluating machine learning classifiers for glaucoma referral decision support in primary care settings,scientific reports,2022,Not found,"Several artificial intelligence algorithms have been proposed to help diagnose glaucoma by analyzing the functional and/or structural changes in the eye. These algorithms require carefully curated datasets with access to ocular images. In the current study, we have modeled and evaluated classifiers to predict self-reported glaucoma using a single, easily obtained ocular feature (intraocular pressure (IOP)) and non-ocular features (age, gender, race, body mass index, systolic and diastolic blood pressure, and comorbidities). The classifiers were trained on publicly available data of 3015 subjects without a glaucoma diagnosis at the time of enrollment. 337 subjects subsequently self-reported a glaucoma diagnosis in a span of 1-12 years after enrollment. The classifiers were evaluated on the ability to identify these subjects by only using their features recorded at the time of enrollment. Support vector machine, logistic regression, and adaptive boosting performed similarly on the dataset with F1 scores of 0.31, 0.30, and 0.28, respectively. Logistic regression had the highest sensitivity at 60% with a specificity of 69%. Predictive classifiers using primarily non-ocular features have the potential to be used for identifying suspected glaucoma in non-eye care settings, including primary care. Further research into finding additional features that improve the performance of predictive classifiers is warranted.",open-angle glaucoma; artificial neural-network; diabetic-retinopathy; macular edema; eye disease; population; prevalence; algorithm; pressure; areds
Article,"Ghosh, Swarup Kr; Ghosh, Anupam",A novel retinal image segmentation using rSVM boosted convolutional neural network for exudates detection,biomedical signal processing and control,2021,Not found,"Retinal image analysis is an emerging research field in ophthalmological disease diagnosis since falsely detected optic disc, fovea, and blood vessels have become essential levels for automated diagnosis practices. In this article, we introduce a novel retinal image segmentation based on ranking support vector machine (rSVM) with convolutional neural network in deep learning field for the detection of diabetic retinopathy. Firstly, the spatial features of the retinal images have been extracted from RGB channel and mapped into a single binary features plane by the computing of pixel by pixel score using rSVM. Thereafter, we have designed a deep convolutional neural network for the retinal image segmentation followed by automatic anomaly detection using morphological operations. The rSVM computes a score function which is more suitable for multi-level classification to binary features classification in order to reduce the overall execution time in the segmentation task. The CNN has been designed with rSVM to define a consistent feature label in the network that reduces the number of channels in the CNN which lead to fast convergence. As a consequence, we have achieved good segmentation accuracy such as 96.4%, 97% and 98.2% for three different databases through post processing steps in comparison with other existing model.",retinal image; convolutional neural network; rsvm; optic disc segmentation; exudates; froc
Proceedings Paper,"Chakravarthy, Adithi D.; Abeyrathna, Dilanga; Subramaniam, Mahadevan; Chundi, Parvathi; Halim, Muhammad Sohail; Hasanreisoglu, Murat; Sepah, Yasir J.; Quan Dong Nguyen",An Approach Towards Automatic Detection of Toxoplasmosis using Fundus Images,2019 ieee 19th international conference on bioinformatics and bioengineering (bibe),2019,Not found,Ocular Toxoplasmosis (OT) is a widespread infectious chorioretinal disease whose timely diagnosis and treatment are crucial to prevent potential vision loss. Diagnosing OT is a challenging task ranging from tedious analyses of fundus images of the eye to serological clinical tests. An automated approach using convolutional neural networks (CNNs) towards diagnosing OT by analyzing fundus images is described. Fundus images are segmented to patches using a sliding window and are classified into healthy and unhealthy fundus image patches using a CNN model. An OT lesion heat map of a fundus image is generated from these patches. The heat map and patch features are then combined to develop a dual input hybrid CNN model detecting OT fundus images with high accuracy. The approach was applied to a dataset of fundus images involving OT and normal subjects and was highly effective in identifying fundus images having OT lesions.,neural networks; deep learning; medical imaging; ocular toxoplasmosis
Article,"Gende, Mateo; De Moura, Joaquim; Novo, Jorge; Charlon, Pablo; Ortega, Marcos",Automatic Segmentation and Intuitive Visualisation of the Epiretinal Membrane in 3D OCT Images Using Deep Convolutional Approaches,ieee access,2021,Not found,"Epiretinal Membrane (ERM) is a disease caused by a thin layer of scar tissue that is formed on the surface of the retina. When this membrane appears over the macula, it can cause distorted or blurred vision. Although normally idiopathic, its presence can also be indicative of other pathologies such as diabetic macular edema or vitreous haemorrhage. ERM removal surgery can preserve more visual acuity the earlier it is performed. For this purpose, we present a fully automatic segmentation system that can help the clinicians to determine the ERM presence and location over the eye fundus using 3D Optical Coherence Tomography (OCT) volumes. The proposed system uses a convolutional neural network architecture to classify patches of the retina surface. All the 2D OCT slices of the 3D OCT volume of a patient are combined to produce an intuitive colour map over the 2D fundus reconstruction, providing a visual representation of the presence of ERM which therefore facilitates the diagnosis and treatment of this relevant eye disease. A total of 2.428 2D OCT slices obtained from 20 OCT 3D volumes was used in this work. To validate the designed methodology, several representative experiments were performed. We obtained satisfactory results with a Dice Coefficient of 0.826 +/- 0.112 and a Jaccard Index of 0.714 +/- 0.155, proving its applicability for diagnosis purposes. The proposed system also demonstrated its simplicity and competitive performance with respect to other state-of-the-art approaches.",retina; feature extraction; diseases; visualization; three-dimensional displays; pathology; image segmentation; epiretinal membrane; machine learning; medical diagnostic imaging; optical coherence tomography
Review,"Louka, Anna Maria; Tsagkaris, Christos; Christoforou, Panagiotis; Khan, Andleeb; Alexiou, Filia; Simou, Panagiota; Haranas, Ioannis; Gkigkitzis, Ioannis; Zouganelis, Georgios; Jha, Niraj Kumar; Uddin, Md Sahab; Shen, Bairong; Kamal, Mohammad A.; Ashraf, Ghulam Md; Alexiou, Athanasios",Current Trends of Computational Tools in Geriatric Medicine and Frailty Management,frontiers in bioscience-landmark,2022,Not found,"While frailty corresponds to a multisystem failure, geriatric assessment can recognize multiple pathophysiological lesions and age changes. Up to now, a few frailty indexes have been introduced, presenting definitions of psychological problems, dysregulations in nutritional intake, behavioral abnormalities, and daily functions, genetic, environmental, and cardiovascular comorbidities. The geriatric evaluation includes a vast range of health professionals; therefore, we describe a broad range of applications and frailty scales-biomarkers to investigate and formulate the relationship between frailty lesions, diagnosis, monitoring, and treatment. Additionally, artificial intel-ligence applications and computational tools are presented, targeting a more efficacy individualized geriatric management of healthy aging.",aging; artificial intelligence; bioinformatics; brain -computer interface; dementia; expert systems; frailty; geriatrics
Article,Chen Sisi; Chen Minghui; Ma Wenfei,Research on Automatic Classification of Optical Coherence Tomography Retina Image Based on Multi-Channel,chinese journal of lasers-zhongguo jiguang,2021,Not found,"Objective Vision loss is caused by age-related macular degeneration because of soft drusen, diabetic macular edema and choroidal neovascular disease. Early detection and treatment of these fundus diseases have emerged as a major health concern for all countries. Professional doctors often use retinal images from optical coherence tomography (OCT) to diagnose eye diseases. However, because there are several types of retinopathy images and the lesion area is similar, manually classifying OCT retina images is a time-consuming and difficult task. With the development of artificial intelligence, researchers began classifying medical images using classic machine learning algorithms and deep learning in its branch areas, eventually progressing to the automatic classification of OCT retinal images. Several researchers are only concerned with classification accuracy and ignore the possibility of clinical application. Consequently, the network model's parameter amount, computational complexity and floating-point operations (FLOPs) calculation amount are increasing, and the model is making inference predictions, which consumes a long time to complete. In this paper, a multi-channel, multi-scale lightweight convolutional neural network is proposed to automatically classify OCT retinal images for achieving high ophthalmic disease classification accuracy. In the future, doctors will be able to quickly view detection results in the clinic. Methods In this study, a multi-channel OCT retinal image automatic classification deep neural network is used. The neural network model is based on the GM-OCTnet algorithm, which includes a light quantum spatial attention mechanism distinct from the convolution operator and a lightweight convolution block to replace the two modules in the original model for automatically classifying OCT retinal images. Image pre-processing, dataset division and classification using the model algorithm are the steps taken to achieve the automatic classification of the entire OCT retina. First, image cropping is performed on the collected OCT image, the blank area of the OCT image is cropped, the marginal blank area is filled and bilateral filter denoising and other pre-processing methods are used to overcome the interference of image background noise on the classification accuracy. Then, the pre-processed image is divided into three sets: training, validation, and test sets. Afterwards, the OCT images from the training set are trained using the proposed multi-channel lightweight deep neural network GM-OCTnet model algorithm. Following the test, the well-trained model is used to classify unclassified retinal images automatically. In addition, the results of this work on the automatic classification of OCT retinal images are validated by comparing the proposed model with three traditional lightweight models on the OCT data set, and different data sets are used to further validate the algorithm's performance. Results and Discussions Different pre-processing methods were used to process the OCT images after evaluating the quality of two different data sets (Figs. 4 and 5). The experimental results show that when the number of groups is 4, the proposed multi-channel OCT automatic retina classification network achieves an average accuracy of 96.1 % , which is 2.6 % higher than that of the original model GhostNet in the automatic classification of OCT retina images. Its file size is 2.64 x 10(6) smaller than that of MobileNetV3. The training and verification accuracies of the GM-OCTnet model when the grouping g = 4 increase gradually with the increase of the training period and tend to stabilise, based on the relationship between the verification loss rate and the verification accuracy rate and the training loss rate and the training accuracy rate curve. When comparing the 50 training processes of different models, the proposed model is found to exhibit a higher accuracy rate than other models when the number of groups is equal to 4 and prioritises reaching the best value (Fig. 6). Overall, the model algorithm proposed in this paper has achieved high accuracy in the automatic classification of OCT retinal images. In addition, when the experimental results of two different datasets are compared, it is discovered that the automatic classification of datasets 1 and 2 achieved high classification accuracy using this algorithm (Tables 1 and 2). Conclusions This study proposes a multi-channel, multi-scale lightweight network for automatically classifying OCT retinal images. The effect of the lightweight neural network GM-OCTnet based on the OCT image datasets in classifying and diagnosing the four types of ophthalmic conditions, i. e. choroidal neovascular disease(CNV), diabetic macular edema(DME), drusen and normal patients, were tested and evaluated. Two different datasets are used to further validate the performance of the algorithm proposed in this work. To validate the effectiveness of the GMOCTnet model for OCT image classification, accuracy, parameter amount, calculation amount and weight file size are used as evaluation criteria. It is found the proposed OCT classification model has improved classification accuracy through experimental results. When used in the clinic, it can improve professional ophthalmologists' diagnosis efficiency for patients with ophthalmic diseases and also reduce missed diagnosis and misdiagnosis of patients.",medical optics; optical coherence tomography; mixed depth separation convolution; lightweight attention mechanism; multi-channel; multi-scale
Article,"Playout, Clement; Duval, Renaud; Cheriet, Farida",A Novel Weakly Supervised Multitask Architecture for Retinal Lesions Segmentation on Fundus Images,ieee transactions on medical imaging,2019,Not found,"Obtaining the complete segmentation map of retinal lesions is the first step toward an automated diagnosis tool for retinopathy that is interpretable in its decision-making. However, the limited availability of ground truth lesion detection maps at a pixel level restricts the ability of deep segmentation neural networks to generalize over large databases. In this paper, we propose a novel approach for training a convolutional multi-task architecture with supervised learning and reinforcing it with weakly supervised learning. The architecture is simultaneously trained for three tasks: segmentation of red lesions and of bright lesions, those two tasks done concurrently with lesion detection. In addition, we propose and discuss the advantages of a new preprocessing method that guarantees the color consistency between the raw image and its enhanced version. Our complete system produces segmentations of both red and bright lesions. The method is validated at the pixel level and per-image using four databases and a cross-validation strategy. When evaluated on the task of screening for the presence or absence of lesions on the Messidor image set, the proposed method achieves an area under the ROC curve of 0.839, comparable with the state-of-the-art.",lesions; retina; image segmentation; diseases; training; task analysis; feature extraction; computer-aided diagnostic; fundus imaging; lesions segmentations; retina; screening
Article,"Gao, Zhijun; Chen, Lun",Research on Semantic Segmentation Method of Macular Edema in Retinal OCT Images Based on Improved Swin-Unet,electronics,2022,Not found,"Optical coherence tomography (OCT), as a new type of tomography technology, has the characteristics of non-invasive, real-time imaging and high sensitivity, and is currently an important medical imaging tool to assist ophthalmologists in the screening, diagnosis, and follow-up treatment of patients with macular disease. In order to solve the problem of irregular occurrence area of diabetic retinopathy macular edema (DME), multi-scale and multi-region cluster of macular edema, which leads to inaccurate segmentation of the edema area, an improved Swin-Unet networks model was proposed for automatic semantic segmentation of macular edema lesion areas in OCT images. Firstly, in the deep bottleneck of the Swin-Unet network, the Resnet network layer was used to increase the extraction of pairs of sub-feature images. Secondly, the Swin Transformer block and skip connection structure were used for global and local learning, and the regions after semantic segmentation were morphologically smoothed and post-processed. Finally, the proposed method was performed on the macular edema patient dataset publicly available at Duke University, and was compared with previous segmentation methods. The experimental results show that the proposed method can not only improve the overall semantic segmentation accuracy of retinal macular edema, but also further to improve the semantic segmentation effect of multi-scale and multi-region edema regions.",oct; swin-unet; macular edema; resnet
Article,"Chen, Yu; Long, Jun; Guo, Jifeng",RF-GANs: A Method to Synthesize Retinal Fundus Images Based on Generative Adversarial Network,computational intelligence and neuroscience,2021,Not found,"Diabetic retinopathy (DR) is a diabetic complication affecting the eyes, which is the main cause of blindness in young and middle-aged people. In order to speed up the diagnosis of DR, a mass of deep learning methods have been used for the detection of this disease, but they failed to attain excellent results due to unbalanced training data, i.e., the lack of DR fundus images. To address the problem of data imbalance, this paper proposes a method dubbed retinal fundus images generative adversarial networks (RF-GANs), which is based on generative adversarial network, to synthesize retinal fundus images. RF-GANs is composed of two generation models, RF-GAN1 and RF-GAN2. Firstly, RF-GAN1 is employed to translate retinal fundus images from source domain (the domain of semantic segmentation datasets) to target domain (the domain of EyePACS dataset connected to Kaggle (EyePACS)). Then, we train the semantic segmentation models with the translated images, and employ the trained models to extract the structural and lesion masks (hereafter, we refer to it as Masks) of EyePACS. Finally, we employ RF-GAN2 to synthesize retinal fundus images using the Masks and DR grading labels. This paper verifies the effectiveness of the method: RF-GAN1 can narrow down the domain gap between different datasets to improve the performance of the segmentation models. RF-GAN2 can synthesize realistic retinal fundus images. Adopting the synthesized images for data augmentation, the accuracy and quadratic weighted kappa of the state-of-the-art DR grading model on the testing set of EyePACS increase by 1.53% and 1.70%, respectively.",smote
Article,"Luo, Yu; Zhang, Yifan; Sun, Xize; Dai, Hengwei; Chen, Xiaohui",Intelligent Solutions in Chest Abnormality Detection Based on YOLOv5 and ResNet50,journal of healthcare engineering,2021,Not found,"Computer-aided diagnosis (CAD) has nearly fifty years of history and has assisted many clinicians in the diagnosis. With the development of technology, recently, researches use the deep learning method to get high accuracy results in the CAD system. With CAD, the computer output can be used as a second choice for radiologists and contribute to doctors doing the final right decisions. Chest abnormality detection is a classic detection and classification problem; researchers need to classify common thoracic lung diseases and localize critical findings. For the detection problem, there are two deep learning methods: one-stage method and two-stage method. In our paper, we introduce and analyze some representative model, such as RCNN, SSD, and YOLO series. In order to better solve the problem of chest abnormality detection, we proposed a new model based on YOLOv5 and ResNet50. YOLOv5 is the latest YOLO series, which is more flexible than the one-stage detection algorithms before. The function of YOLOv5 in our paper is to localize the abnormality region. On the other hand, we use ResNet, avoiding gradient explosion problems in deep learning for classification. And we filter the result we got from YOLOv5 and ResNet. If ResNet recognizes that the image is not abnormal, the YOLOv5 detection result is discarded. The dataset is collected via VinBigData's web-based platform, VinLab. We train our model on the dataset using Pytorch frame and use the mAP, precision, and F1-score as the metrics to evaluate our model's performance. In the progress of experiments, our method achieves superior performance over the other classical approaches on the same dataset. The experiments show that YOLOv5's mAP is 0.010, 0.020, 0.023 higher than those of YOLOv5, Fast RCNN, and EfficientDet. In addition, in the dimension of precision, our model also performs better than other models. The precision of our model is 0.512, which is 0.018, 0.027, 0.033 higher than YOLOv5, Fast RCNN, and EfficientDet.",computer-aided diagnosis; diabetic-retinopathy
Article,"Zech, John R.; Badgeley, Marcus A.; Liu, Manway; Costa, Anthony B.; Titano, Joseph J.; Oermann, Eric Karl",Variable generalization performance of a deep learning model to detect pneumonia in chest radiographs: A cross-sectional study,plos medicine,2018,Not found,"Background There is interest in using convolutional neural networks (CNNs) to analyze medical imaging to provide computer-aided diagnosis (CAD). Recent work has suggested that image classification CNNs may not generalize to new data as well as previously believed. We assessed how well CNNs generalized across three hospital systems for a simulated pneumonia screening task. Methods and findings A cross-sectional design with multiple model training cohorts was used to evaluate model generalizability to external sites using split-sample validation. A total of 158,323 chest radiographs were drawn from three institutions: National Institutes of Health Clinical Center (NIH; 112,120 from 30,805 patients), Mount Sinai Hospital (MSH; 42,396 from 12,904 patients), and Indiana University Network for Patient Care (IU; 3,807 from 3,683 patients). These patient populations had an age mean (SD) of 46.9 years (16.6), 63.2 years (16.5), and 49.6 years (17) with a female percentage of 43.5%, 44.8%, and 57.3%, respectively. We assessed individual models using the area under the receiver operating characteristic curve (AUC) for radiographic findings consistent with pneumonia and compared performance on different test sets with DeLong's test. The prevalence of pneumonia was high enough at MSH (34.2%) relative to NIH and IU (1.2% and 1.0%) that merely sorting by hospital system achieved an AUC of 0.861 (95% CI 0.855-0.866) on the joint MSH-NIH dataset. Models trained on data from either NIH or MSH had equivalent performance on IU (Pvalues 0.580 and 0.273, respectively) and inferior performance on data from each other relative to an internal test set (i.e., new data from within the hospital system used for training data; Pvalues both <0.001). The highest internal performance was achieved by combining training and test data from MSH and NIH (AUC 0.931, 95% CI 0.927-0.936), but this model demonstrated significantly lower external performance at IU (AUC 0.815, 95% CI 0.7450.885, P= 0.001). To test the effect of pooling data from sites with disparate pneumonia prevalence, we used stratified subsampling to generate MSH-NIH cohorts that only differed in disease prevalence between training data sites. When both training data sites had the same pneumonia prevalence, the model performed consistently on external IU data (P= 0.88). When a 10-fold difference in pneumonia rate was introduced between sites, internal test performance improved compared to the balanced model (10x MSH risk P < 0.001; 10x NIH P = 0.002), but this outperformance failed to generalize to IU (MSH 10x P< 0.001; NIH 10x P= 0.027). CNNs were able to directly detect hospital system of a radiograph for 99.95% NIH (22,050/22,062) and 99.98% MSH (8,386/8,388) radiographs. The primary limitation of our approach and the available public data is that we cannot fully assess what other factors might be contributing to hospital system-specific biases. Conclusion Pneumonia-screening CNNs achieved better internal than external performance in 3 out of 5 natural comparisons. When models were trained on pooled data from sites with different pneumonia prevalence, they performed better on new pooled data from these sites but not on external data. CNNs robustly identified hospital system and department within a hospital, which can have large differences in disease burden and may confound predictions.",diabetic-retinopathy; diseases; validation
Article,"You, Qi Sheng; Tsuboi, Kotaro; Guo, Yukun; Wang, Jie; Flaxel, Christina J.; Bailey, Steven T.; Huang, David; Jia, Yali; Hwang, Thomas S.",Comparison of Central Macular Fluid Volume With Central Subfield Thickness in Patients With Diabetic Macular Edema Using Optical Coherence Tomography Angiography,jama ophthalmology,2021,Not found,"IMPORTANCE Diabetic macular edema (DME) is the predominant cause of visual impairment in patients with type 1 or 2 diabetes. Automated fluid volume measurements using optical coherence tomography (OCT) may improve the diagnostic accuracy of DME screening. OBJECTIVE To assess the diagnostic accuracy of an automated central macular fluid volume (CMFV) quantification using OCT for DME. DESIGN, SETTING, AND PARTICIPANTS A cross-sectional observational study was conducted at a tertiary academic center among 215 patients with diabetes (1 eye each) enrolled from January 26, 2015, to December 23, 2019. All participants underwent comprehensive examinations, 6 x 6-mm macular structural OCT horizontal raster scans, and 6 x 6-mm macular OCT angiography volumetric scans. From January 1 to March 30, 2020, 2 retinal specialists reviewed the structural OCT scans independently and diagnosed DME if intraretinal or subretinal fluid was present. Diabetic macular edema was considered center involved if fluid was present within the central fovea (central 1-mm circle). A third retinal specialist arbitrated any discrepancy. The mean central subfield thickness (CST) within the central fovea was measured on structural OCT horizontal raster scans. A deep learning algorithm automatically quantified fluid volumes on 6 x 6-mm OCT angiography volumetric scans and within the central foveas (CMFV). MAIN OUTCOMES AND MEASURES The area under the receiver operating characteristic curve (AUROC) and the sensitivity and specificity of CST and CMFV for DME diagnosis. RESULTS We enrolled 1 eye each of 215 patients with diabetes (117 women [54.4%]; mean [SD] age, 59.6 [12.4] years). Diabetic macular edema was present in 136 eyes; 93 cases of DME were center involved. The AUROC of CMFV for diagnosis of center-involved DME (0.907 [95% CI, 0.861-0.954]) was greater than the AUROC of CST (0.832 [95% CI, 0.775-0.889]; P =.02). With the specificity set at 95%, the sensitivity of CMFV for detection of center-involved DME (78.5%[95% CI, 68.8%-86.3%]) was higher than that of CST (53.8% [95% CI, 43.1%-64.2%]; P =.002). Center-involved DME cases not detected by CST but detected by CMFV were associated with a thinner CST (290.8 mu m [95% CI, 282.3-299.3 mu m] vs 369.4 mu m[95% CI, 347.1-391.7 mu m]; P <.001), higher proportion of previous macular laser treatment (11 of 28 [39.3%; 95% CI, 21.5%-59.4%] vs 12 of 65 [18.5%; 95% CI, 9.9%-30.0%]; P =.03), and female sex (20 of 28 [71.4%; 95% CI, 51.3%-86.8%] vs 31 of 65 [47.7%; 95% CI, 35.1%-60.5%]; P =.04). CONCLUSIONS AND RELEVANCE These findings suggest that an automated CMFV is a more accurate diagnostic biomarker than CST for DME and may improve screening for DME.",healthy eyes; retinal thickness; retinopathy; determinants; ranibizumab; multicenter; features
Article,"Shi, Chuying; Lee, Jack; Wang, Gechun; Dou, Xinyan; Yuan, Fei; Zee, Benny",Assessment of image quality on color fundus retinal images using the automatic retinal image analysis,scientific reports,2022,Not found,"Image quality assessment is essential for retinopathy detection on color fundus retinal image. However, most studies focused on the classification of good and poor quality without considering the different types of poor quality. This study developed an automatic retinal image analysis (ARIA) method, incorporating transfer net ResNet50 deep network with the automatic features generation approach to automatically assess image quality, and distinguish eye-abnormality-associated-poor-quality from artefact-associated-poor-quality on color fundus retinal images. A total of 2434 retinal images, including 1439 good quality and 995 poor quality (483 eye-abnormality-associated-poor-quality and 512 artefact-associated-poor-quality), were used for training, testing, and 10-ford cross-validation. We also analyzed the external validation with the clinical diagnosis of eye abnormality as the reference standard to evaluate the performance of the method. The sensitivity, specificity, and accuracy for testing good quality against poor quality were 98.0%, 99.1%, and 98.6%, and for differentiating between eye-abnormality-associated-poor-quality and artefact-associated-poor-quality were 92.2%, 93.8%, and 93.0%, respectively. In external validation, our method achieved an area under the ROC curve of 0.997 for the overall quality classification and 0.915 for the classification of two types of poor quality. The proposed approach, ARIA, showed good performance in testing, 10-fold cross validation and external validation. This study provides a novel angle for image quality screening based on the different poor quality types and corresponding dealing methods. It suggested that the ARIA can be used as a screening tool in the preliminary stage of retinopathy grading by telemedicine or artificial intelligence analysis.",diabetic-retinopathy; hypermature cataract; asteroid hyalosis; photography; population
Proceedings Paper,"Wang, Changwei; Xu, Rongtao; Xu, Shibiao; Meng, Weiliang; Zhang, Xiaopeng",DA-Net: Dual Branch Transformer and Adaptive Strip Upsampling for Retinal Vessels Segmentation,"medical image computing and computer assisted intervention, miccai 2022, pt ii",2022,Not found,"Since the morphology of retinal vessels plays a pivotal role in clinical diagnosis of eye-related diseases and diabetic retinopathy, retinal vessels segmentation is an indispensable step for the screening and diagnosis of retinal diseases, yet it is still a challenging problem due to the complex structure of retinal vessels. Current retinal vessels segmentation approaches roughly fall into image-level and patches-level methods based on the input type, while each has its own strengths and weaknesses. To benefit from both of the input forms, we introduce a Dual Branch Transformer Module (DBTM) that can simultaneously and fully enjoy the patches-level local information and the image-level global context. Besides, the retinal vessels are long-span, thin, and distributed in strips, making the square kernel of classic convolutional neural network false as it is only suitable for most natural objects with bulk shape. To better capture context information, we further design an Adaptive Strip Upsampling Block (ASUB) to adapt to the striped distribution of the retinal vessels. Based on the above innovations, we propose a retinal vessels segmentation Network with Dual Branch Transformer and Adaptive Strip Upsampling (DA-Net). Experiments validate that our DA-Net outperforms other state-of-the-art methods on both DRIVE and CHASE-DB1 datasets.",retinal vessels segmentation; dual branch transformer module; adaptive strip upsampling block
Article,"Hallac, Rami R.; Lee, Jeon; Pressler, Mark; Seaward, James R.; Kane, Alex A.",Identifying Ear Abnormality from 2D Photographs Using Convolutional Neural Networks,scientific reports,2019,Not found,"Quantifying ear deformity using linear measurements and mathematical modeling is difficult due to the ear's complex shape. Machine learning techniques, such as convolutional neural networks (CNNs), are well-suited for this role. CNNs are deep learning methods capable of finding complex patterns from medical images, automatically building solution models capable of machine diagnosis. In this study, we applied CNN to automatically identify ear deformity from 2D photographs. Institutional review board (IRB) approval was obtained for this retrospective study to train and test the CNNs. Photographs of patients with and without ear deformity were obtained as standard of care in our photography studio. Profile photographs were obtained for one or both ears. A total of 671 profile pictures were used in this study including: 457 photographs of patients with ear deformity and 214 photographs of patients with normal ears. Photographs were cropped to the ear boundary and randomly divided into training (60%), validation (20%), and testing (20%) datasets. We modified the softmax classifier in the last layer in GoogLeNet, a deep CNN, to generate an ear deformity detection model in Matlab. All images were deemed of high quality and usable for training and testing. It took about 2 hours to train the system and the training accuracy reached almost 100%. The test accuracy was about 94.1%. We demonstrate that deep learning has a great potential in identifying ear deformity. These machine learning techniques hold the promise in being used in the future to evaluate treatment outcomes.",diabetic-retinopathy; learning algorithm; classification; segmentation; recognition; deformities; biometrics
Article,"Popescu, Dan; Ichim, Loretta",Intelligent Image Processing System for Detection and Segmentation of Regions of Interest in Retinal Images,symmetry-basel,2018,Not found,"The automatic detection, segmentation, localization, and evaluation of the optic disc, macula, exudates, and hemorrhages are very important for diagnosing retinal diseases. One of the difficulties in detecting such regions of interest (RoIs) with computer vision is their symmetries, e.g., between the optic disc and exudates and also between exudates and hemorrhages. This paper proposes an original, intelligent, and high-performing image processing system for the simultaneous detection and segmentation of retinal RoIs. The basic principles of the method are image decomposition in small boxes and local texture analysis. The processing flow contains three phases: preprocessing, learning, and operating. As a first novelty, we propose proper feature selection based on statistical analysis in confusion matrices for different feature types (extracted from a co-occurrence matrix, fractal type, and local binary patterns). Mainly, the selected features are chosen to differentiate between similar RoIs. The second novelty consists of local classifier fusion. To this end, the local classifiers associated with features are grouped in global classifiers corresponding to the RoIs. The local classifiers are based on minimum distances to the representatives of classes and the global classifiers are based on confidence intervals, weights, and a voting scheme. A deep convolutional neural network, based on supervised learning, for blood vessel segmentation is proposed in order to improve the RoI detection performance. Finally, the experimental results on real images from different databases demonstrate the rightness of our methodologies and algorithms.",biomedical image processing; retinal image segmentation; feature selection; texture analysis; convolutional neural network; optic disc; macula; exudates; hemorrhages
Review,"Consejo, Alejandra; Melcer, Tomasz; Rozema, Jos J.",Introduction to Machine Learning for Ophthalmologists,seminars in ophthalmology,2019,Not found,"New diagnostic and imaging techniques generate such an incredible amount of data that it is often a challenge to extract all information that could be possibly useful in clinical practice. Machine Learning techniques emerged as an objective tool to assist practitioners to diagnose certain conditions and take clinical decisions. In particular, Machine Learning techniques have repeatedly shown their usefulness for ophthalmologists. The possible applications of this technology go much further than been used as diagnostic tool, as it may also be used to grade the severity of a pathology, perform early disease detection, or predict the evolution of a condition. This work reviews not only the latest achievements of Machine Learning in ocular sciences, but also aims to be a comprehensive and concise overview of all steps of the process, with clear and easy explanation for each technical term, focusing on the basic knowledge required to understand Machine Learning.",automated diagnosis; artificial intelligence; vision sciences; machine learning; neural networks
Proceedings Paper,"Wang, Changwei; Xu, Rongtao; Zhang, Yuyang; Xu, Shibiao; Zhang, Xiaopeng",RETINAL VESSEL SEGMENTATION VIA CONTEXT GUIDE ATTENTION NET WITH JOINT HARD SAMPLE MINING STRATEGY,2021 ieee 18th international symposium on biomedical imaging (isbi),2021,Not found,"Retinal vessel segmentation is of great significance for clinical diagnosis of eye-related diseases and diabetic retinopathy. However, due to the imbalance of retinal vessel thickness distribution and the existence of a large number of capillaries, it is difficult to segment the retinal vessels correctly. To better solve this problem, we propose a novel Context Guided Attention Net (CGA-Net) with Joint hard sample mining strategy. Specifically, we propose a Context Guided Attention Module (CGAM) which can utilize both the surrounding context information and spatial attention information to promote the precision of segmentation results. As the CGAM is flexible and lightweight, it can be easily integrated into CNN architecture. To solve the problem of retinal vessel pixel imbalance, we further propose a novel Joint hard sample mining strategy (JHSM) in network training, which combines both the pixel-wise and patch-wise hard mining to largely improve the network's robustness for hard samples. Experiments on publicly DRIVE and CHASE_DB 1 datasets show that our model outperforms state-of-the-art methods.",retinal vessel segmentation; context guide; attention mechanism; hard sample mining
Review,"Panda, Nihar Ranjan; Sahoo, Ajit Kumar",A Detailed Systematic Review on Retinal Image Segmentation Methods,journal of digital imaging,2022,Not found,"The separation of blood vessels in the retina is a major aspect in detecting ailment and is carried out by segregating the retinal blood vessels from the fundus images. Moreover, it helps to provide earlier therapy for deadly diseases and prevent further impacts due to diabetes and hypertension. Many reviews already exist for this problem, but those reviews have presented the analysis of a single framework. Hence, this article on retinal segmentation review has revealed distinct methodologies with diverse frameworks that are utilized for blood vessel separation. The novelty of this review research lies in finding the best neural network model by comparing its efficiency. For that, machine learning (ML) and deep learning (DL) were compared and have been reported as the best model. Moreover, different datasets were used to segment the retinal blood vessels. The execution of each approach is compared based on the performance metrics such as sensitivity, specificity, and accuracy using publically accessible datasets like STARE, DRIVE, ROSE, REFUGE, and CHASE. This article discloses the implementation capacity of distinct techniques implemented for each segmentation method. Finally, the finest accuracy of 98% and sensitivity of 96% were achieved for the technique of Convolution Neural Network with Ranking Support Vector Machine (CNN-rSVM). Moreover, this technique has utilized public datasets to verify efficiency. Hence, the overall review of this article has revealed a method for earlier diagnosis of diseases to deliver earlier therapy.",fundus image; matched filtering; multi-scale approach; neural network methods; retinal segmentation; supervised segmentation; vessel tracing
Article,"Prasad, Puja Sahay; Bethel, G. N. Beena; Singh, Ninni; Gunjan, Vinit Kumar; Basir, Samar; Miah, Shahajan",Blockchain-Based Privacy Access Control Mechanism and Collaborative Analysis for Medical Images,security and communication networks,2022,Not found,"Medical image analysis technology based on deep learning has played an important role in computer-aided disease diagnosis and treatment. Classification accuracy has always been the primary goal pursued by researchers. However, the image transmission process also faces the problems of limited wireless ad-hoc network (WAN) bandwidth and increased security risks. Moreover, when user data are exposed to unauthorized users, platforms can easily leak personal privacy. Aiming at the abovementioned problems, a system model and an access control scheme for the collaborative analysis of the diagnosis of diabetic retinopathy (DR) are constructed in this paper. The system model includes two stages of data cleaning and lesion classification. In the data cleaning phase, the private cloud writes the model obtained after training into the blockchain, and other private clouds use the best-performing model on the chain to identify the image quality when cleaning data and pass the high-quality image to the lesion classification model for use. In the lesion classification stage, each private cloud trains the classification model separately; uploads its own model parameters to the public cloud for aggregation to obtain a global model; and then sends the global model to each private cloud to achieve collaborative learning, reduce the amount of data transmission, and protect personal privacy. Access control schemes include improved role-based access control (RAC) used within the private cloud and blockchain-based access control used during the interaction between the private cloud and the public cloud program (BAC). RAC grants both functional rights and data access rights to roles and takes into account object attributes for fine-grained level control. Based on certificateless public-key encryption technology and blockchain technology, BAC can realize the identity authentication and authority identification of the private cloud while requesting the transmission of model parameters from the private cloud to the public cloud and protect the security of the identity, authority, and model parameters of the private cloud to achieve the effect of lightweight access control. In the experimental part, two retinal datasets are used for DR classification analysis. The results show that data cleaning can effectively remove low-quality images and improve the accuracy of early lesion classification for doctors, with an accuracy rate of 90.2%.",not found
Article,"Liu, Gao-Shuang; Huang, Pei-Yun; Wen, Min-Li; Zhuang, Shuai-Shuai; Hua, Jie; He, Xiao-Pu",Application of endoscopic ultrasonography for detecting esophageal lesions based on convolutional neural network,world journal of gastroenterology,2022,Not found,"BACKGROUNDA convolutional neural network (CNN) is a deep learning algorithm based on the principle of human brain visual cortex processing and image recognition.AIMTo automatically identify the invasion depth and origin of esophageal lesions based on a CNN.METHODSA total of 1670 white-light images were used to train and validate the CNN system. The method proposed in this paper included the following two parts: (1) Location module, an object detection network, locating the classified main image feature regions of the image for subsequent classification tasks; and (2) Classification module, a traditional classification CNN, classifying the images cut out by the object detection network.RESULTSThe CNN system proposed in this study achieved an overall accuracy of 82.49%, sensitivity of 80.23%, and specificity of 90.56%. In this study, after follow-up pathology, 726 patients were compared for endoscopic pathology. The misdiagnosis rate of endoscopic diagnosis in the lesion invasion range was approximately 9.5%; 41 patients showed no lesion invasion to the muscularis propria, but 36 of them pathologically showed invasion to the superficial muscularis propria. The patients with invasion of the tunica adventitia were all treated by surgery with an accuracy rate of 100%. For the examination of submucosal lesions, the accuracy of endoscopic ultrasonography (EUS) was approximately 99.3%. Results of this study showed that EUS had a high accuracy rate for the origin of submucosal lesions, whereas the misdiagnosis rate was slightly high in the evaluation of the invasion scope of lesions. Misdiagnosis could be due to different operating and diagnostic levels of endoscopists, unclear ultrasound probes, and unclear lesions.CONCLUSIONThis study is the first to recognize esophageal EUS images through deep learning, which can automatically identify the invasion depth and lesion origin of submucosal tumors and classify such tumors, thereby achieving good accuracy. In future studies, this method can provide guidance and help to clinical endoscopists.",endoscopic ultrasonography; convolutional neural network; esophageal lesion; automatically; classify; identify
Article,Yuan Yuan; Chen Minghui; Ke Shuting; Wang Teng; He Longxi; Lu Linjie; Sun Hao; Liu Jiannan,Fundus Image Classification Research Based on Ensemble Convolutional Neural Network and Vision Transformer,chinese journal of lasers-zhongguo jiguang,2022,Not found,"Objective With the increasing prevalence and blindness rate of fundus diseases, the lack of ophthalmologist resources is increasingly unable to meet the demand for medical examination. Given the shortage of ophthalmic medical staff, long waiting process for medical treatment, and challenges in remote areas, there is an irresistible trend to reduce the workload of medical staff via artificial intelligence. Several studies have applied convolutional neural network (CNN) in the classification task of fundus diseases; however with the advancement of Transformer model application, Vision Transformer (ViT) model has shown higher performance in the field of medical images. ViT models require pretraining on large datasets and are limited by the high cost of medical image acquisition. Thus, this study proposes an ensemble model. The ensemble model combines CNN (EfficientNetV2-S) and Transformer models (ViT). Compared with the existing advanced model, the proposed model can extract the features of fundus images in two completely different ways to achieve better classification results, which not only have high accuracy but also have precision and sensitivity. Specifically, it can be used to diagnose fundus diseases. This model can improve the work efficiency of the fundamental doctor if applied to the medical secondary diagnosis process, thus effectively alleviating the difficulties in diagnosis of fundus diseases caused by the shortage of ophthalmologist staff, long medical treatment process, and difficult medical treatment in remote areas. Methods We propose the EfficientNet-ViT ensemble model for the classification of fundus images. This model integrates the CNN and Transformer models, which adopt the EfficientNetV2-S and ViT models, respectively. First, train the EfficientNetV2-S and ViT models. Then, apply adaptive weighting data fusion technology to accomplish the complementation of the function of the two types of models. The optimal weighting factors of the EfficientNetV2-S and ViT models are calculated using the adaptive weighting algorithm and then the new model (EfficientNet-ViT) is integrated with them. After calculating the weighting factors 0. 4 and 0. 6, multiply the output of the ViT model by a weighting factor of 0.4, multiply the output of the EfficientNetV2-S model by a weighting factor of 0.6, and then weigh the two to obtain the final prediction result. According to clinical statistics, the current common fundamental disease in my country includes the following diseases: diabetic retinopathy (DR), age-related macular degeneration (ARMD) , cataract, and myopia. These fundus diseases are the main factors that cause irreversible blindness in my country. Thus, we classify fundus images into the following five categories: normal, DR, ARMD, myopia, and cataract. Furthermore, we use three indicators, such as accuracy, precision, and specificity. The EfficientNet-ViT ensemble model can extract the features of fundus images in two completely different ways to achieve better classification results and higher accuracy. Finally, we compare the performance indicators of this model and other models. The superiority of the integrated model in the fundus classification is verified. Results and Discussions The accuracy of EfficientNet-ViT ensemble model in fundus image classification reaches 92.70 0, the precision is 88.3 , and the specificity reaches 98.1%. Compared with EfficientNetV2-S and ViT models, the precision of EfficientNet-ViT ensemble model improves by 0.5% and 1.6%, accuracy improves by 0.7% and 1.9%, and specificity increases by 0.6% and 0.9%, respectively (Table 3) . Compared with Resnet50, Densenet121, ResNeSt-101, and EfficientNet-B0, the accuracy of the EfficientNet-ViT ensemble model increases by 5. 4 , 3. 2%, 2. 0%,1.4%, respectively (Table 4), showing its superiority in the fundus image classification task. Conclusions The EfficientNet-ViT ensemble model proposed in this study is a network model combining a CNN and a transformer. The core of the CNN is the convolution kernel, which has inductive biases, such as translation invariance and local sensitivity, and can capture local spatio-temporal information but lacks a global understanding of the image itself. Compared with the CNN, the self-attention mechanism of the transformer is not limited by local interactions and can not only mine long-distance dependencies but also perform parallel computation. This study uses the EfficientNetV2-S and ViT models to calculate the most weighted factors for the CNN and Transformer models through the adaptive weighted fusion method. The EfficientNet-ViT can extract image features in two completely different ways. Our experimental results show that the accuracy and precision of fundus image classification can be improved by integrating the two models. If applied in the process of medical auxiliary diagnosis, this model can improve the work efficiency of fundus doctors and effectively alleviate the difficulties in diagnosis of fundus diseases caused by the shortage of ophthalmic medical staff, long waiting process for medical treatment, and difficult medical treatment in remote areas in China. When more datasets are used to train the model in the future, the accuracy, precision, and sensitivity of automatic classification may be further improved to achieve better clinical results.",bio-optics; ophthalmology; fundus disease; image classification; ensemble model; weighted fusion
Article,"Wu, Jo-Hsuan; Nishida, Takashi; Weinreb, Robert N.; Lin, Jou-Wei",Performances of Machine Learning in Detecting Glaucoma Using Fundus and Retinal Optical Coherence Tomography Images: A Meta-Analysis,american journal of ophthalmology,2022,Not found,"PURPOSE: To evaluate the performance of machine learning (ML) in detecting glaucoma using fundus and retinal optical coherence tomography (OCT) images. DESIGN: Meta-analysis. METHODS: PubMed and EMBASE were searched on August 11, 2021. A bivariate random-effects model was used to pool ML's diagnostic sensitivity, specificity, and area under the curve (AUC). Subgroup analyses were performed based on ML classifier categories and dataset types. RESULTS: One hundred and five studies (3.3%) were retrieved. Seventy-three (69.5%), 30 (28.6%), and 2 (1.9%) studies tested ML using fundus, OCT, and both image types, respectively. Total testing data numbers were 197,174 for fundus and 16,039 for OCT. Overall, ML showed excellent performances for both fundus (pooled sensitivity = 0.92 [95% CI, 0.91-0.93]; speci-ficity = 0.93 [95% CI, 0.91-0.94]; and AUC = 0.97 [95% CI, 0.95-0.98]) and OCT (pooled sensitiv-ity = 0.90 [95% CI, 0.86-0.92]; specificity = 0.91 [95% CI, 0.89-0.92]; and AUC = 0.96 [95% CI, 0.930.97]). ML performed similarly using all data and ex-ternal data for fundus and the external test result of OCT was less robust (AUC = 0.87). When comparing different classifier categories, although support vec-tor machine showed the highest performance (pooled sen-sitivity, specificity, and AUC ranges, 0.92-0.96, 0.950.97, and 0.96-0.99, respectively), results by neural net-work and others were still good (pooled sensitivity, specificity, and AUC ranges, 0.88-0.93, 0.90-0.93, 0.95-0.97, respectively). When analyzed based on dataset types, ML demonstrated consistent performances on clinical datasets (fundus AUC = 0.98 [95% CI, 0.97-0.99] and OCT AUC = 0.95 [95% 0.93-0.97]). CONCLUSIONS: Performance of ML in detecting glau-coma compares favorably to that of experts and is promis-ing for clinical application. Future prospective studies are needed to better evaluate its real-world utility. (C) 2021 Elsevier Inc. All rights reserved.",nerve-fiber layer; decision-support-system; neural-network; artificial-intelligence; diabetic-retinopathy; automatic diagnosis; time-domain; classification; segmentation; features
Review,"Adlung, Lorenz; Cohen, Yotam; Mor, Uria; Elinav, Eran",Machine learning in clinical decision making,med,2021,Not found,"Machine learning is increasingly integrated into clinical practice, with applications ranging from pre-clinical data processing, bedside diagnosis assistance, patient stratification, treatment decision making, and early warning as part of primary and secondary prevention. However, a multitude of technological, medical, and ethical considerations are critical in machine-learning utilization, including the necessity for careful validation of machine-learning-based technologies in real-life contexts, unbiased evaluation of benefits and risks, and avoidance of technological over-dependence and associated loss of clinical, ethical, and social-related decision-making capacities. Other challenges include the need for careful benchmarking and external validations, dissemination of end-user knowledge from computational experts to field users, and responsible code and data sharing, enabling transparent assessment of pipelines. In this review, we highlight key promises and achievements in integration of machine-learning platforms into clinical medicine while highlighting limitations, pitfalls, and challenges toward enhanced integration of learning systems into the medical realm.",computer-aided diagnosis; artificial-intelligence; diabetic-retinopathy; heart-failure; intraoperative hypotension; colorectal-cancer; cardiovascular-disease; breast-cancer; psychological consequences; management strategies
Article,"Jazdarehee, Aria; Huget-Penner, Sawyer; Pawlowska, Monika",Pseudo-pheochromocytoma due to obstructive sleep apnea: a case report,endocrinology diabetes and metabolism case reports,2022,Not found,"Obstructive sleep apnea (OSA) is a condition of intermittent nocturnal upper airway obstruction. OSA increases sympathetic drive which may result in clinical and biochemical features suggestive of pheochromocytoma. We present the case of a 65-year-old male with a 2.9-cm left adrenal incidentaloma on CT, hypertension, symptoms of headache, anxiety and diaphoresis, and persistently elevated 24-h urine norepinephrine (initially 818 nmol/day (89-470)) and normetanephrine (initially 11.2 mu mol/day (0.6-2.7)). He was started on prazosin and underwent left adrenalectomy. Pathology revealed an adrenal corticoadenoma with no evidence of pheochromocytoma. Over the next 2 years, urine norepinephrine and normetanephrine remained significantly elevated with no MIBG avid disease. Years later, he was diagnosed with severe OSA and treated with continuous positive airway pressure. Urine testing done once OSA was well controlled revealed complete normalization of urine norepinephrine and normetanephrine with substantial symptom improvement. It was concluded that the patient never had a pheochromocytoma but rather an adrenal adenoma with biochemistry and symptoms suggestive of pheochromocytoma due to untreated severe OSA. Pseudo-pheochromocytoma is a rare presentation of OSA and should be considered on the differential of elevated urine catecholamines and metanephrines in the right clinical setting.",adolescent; young adult; adult; geriatric; neonatal; paediatric; pregnant adult; female; male; american indian or alaska native; asian - bangladeshi; asian - chinese; asian - filipino; asian - indian; asian - japanese; asian - korean; asian - pakistani; asian - vietnamese; asian - other; black - african; black - caribbean; black - other; hispanic or latino - central american or south american; hispanic or latino - cuban; hispanic or latino - dominican; hispanic or latino - mexican; mexican american; chicano; hispanic or latino - puerto rican; hispanic or latino - other; native hawaiian; other pacific islander; white; other; afghanistan; aland islands; albania; algeria; american samoa; andorra; angola; anguilla; antarctica; antigua and barbuda; argentina; armenia; aruba; australia; austria; azerbaijan; bahamas; bahrain; bangladesh; barbados; belarus; belgium; belize; benin; bermuda; bhutan; bolivia; bosnia and herzegovina; botswana; bouvet island; brazil; british indian ocean territory; brunei darussalam; bulgaria; burkina faso; burundi; cambodia; cameroon; canada; cape verde; cayman islands; central african republic; chad; chile; china; christmas island; cocos (keeling) islands; colombia; comoros; congo; congo; the democratic republic of the; cook islands; costa rica; cote d'ivoire; croatia; cuba; cyprus; czech republic; denmark; djibouti; dominica; dominican republic; ecuador; egypt; el salvador; equatorial guinea; eritrea; estonia; ethiopia; falkland islands (malvinas); faroe islands; fiji; finland; france; french guiana; french polynesia; french southern territories; gabon; gambia; georgia; germany; ghana; gibraltar; greece; greenland; grenada; guadeloupe; guam; guatemala; guernsey; guinea; guinea-bissau; guyana; haiti; heard island and mcdonald islands; holy see (vatican city state); honduras; hong kong; hungary; iceland; india; indonesia; iran; islamic republic of; iraq; ireland; isle of man; israel; italy; jamaica; japan; jersey; jordan; kazakhstan; kenya; kiribati; korea; democratic people's republic of; korea; republic of; kuwait; kyrgyzstan; lao people's democratic republic; latvia; lebanon; lesotho; liberia; libyan arab jamahiriya; liechtenstein; lithuania; luxembourg; macao; macedonia; the former yugoslav republic of; madagascar; malawi; malaysia; maldives; mali; malta; marshall islands; martinique; mauritania; mauritius; mayotte; mexico; micronesia; federated states of; moldova; republic of; monaco; mongolia; montenegro; montserrat; morocco; mozambique; myanmar; namibia; nauru; nepal; netherlands; netherlands antilles; new caledonia; new zealand; nicaragua; niger; nigeria; niue; norfolk island; northern mariana islands; norway; oman; pakistan; palau; palestinian territory; occupied; panama; papua new guinea; paraguay; peru; philippines; pitcairn; poland; portugal; puerto rico; qatar; reunion; romania; russian federation; rwanda; saint barthelemy; saint helena; saint kitts and nevis; saint lucia; saint martin; saint pierre and miquelon; saint vincent and the grenadines; samoa; san marino; sao tome and principe; saudi arabia; senegal; serbia; seychelles; sierra leone; singapore; slovakia; slovenia; solomon islands; somalia; south africa; south georgia and the south sandwich islands; spain; sri lanka; sudan; suriname; svalbard and jan mayen; swaziland; sweden; switzerland; syrian arab republic; taiwan; province of china; tajikistan; tanzania; united republic of; thailand; timor-leste; togo; tokelau; tonga; trinidad and tobago; tunisia; turkey; turkmenistan; turks and caicos islands; tuvalu; uganda; ukraine; united arab emirates; united kingdom; united states; united states minor outlying islands; uruguay; uzbekistan; vanuatu; vatican city state; venezuela; viet nam; virgin islands; british; virgin islands; u; s; wallis and futuna; western sahara; yemen; zambia; zimbabwe; maylaysia; adipose tissue; adrenal; bone; duodenum; heart; hypothalamus; kidney; liver; ovaries; pancreas; parathyroid; pineal; pituitary; placenta; skin; stomach; testes; thymus; thyroid; adrenal; andrology; autoimmunity; bone; cardiovascular endocrinology; developmental endocrinology; diabetes; emergency; endocrine disruptors; endocrine-related cancer; epigenetics; genetics and mutation; growth factors; gynaecological endocrinology; immunology; infectious diseases; late effects of cancer therapy; mineral; neuroendocrinology; obesity; ophthalmology; paediatric endocrinology; pituitary; puberty; thyroid; tumours and neoplasia; vitamin d; 17ohp; acth; adiponectin; adrenaline; aldosterone; amh; androgens; androstenedione; androsterone; angiotensin; antidiuretic hormone; atrial natriuretic hormone; avp; beta-endorphin; big igf2; brain natriuretic peptide; calcitonin; calcitriol; cck; corticosterone; corticotrophin; cortisol; cortisone; crh; dehydroepiandrostenedione; deoxycorticosterone; deoxycortisol; dhea; dihydrotestosterone; dopamine; endothelin; enkephalin; epitestosterone; epo; fgf23; fsh; gastrin; gh; ghrelin; ghrh; gip; glp1; glp2; glucagon; glucocorticoids; gnrh; gonadotropins; hcg; hepcidin; histamine; human placental lactogen; hydroxypregnenolone; igf1; igf2; inhibin; insulin; kisspeptin; leptin; lh; melanocyte-stimulating hormone; melatonin; metanephrines; mineralocorticoids; motilin; nandrolone; neuropeptide y; noradrenaline; normetanephrine; oestetrol (e4); oestradiol (e2); oestriol (e3); oestrogens; oestrone (e1); osteocalcin; oxyntomodulin; oxytocin; pancreatic polypeptide; peptide yy; pregnenolone; procalcitonin; progesterone; prolactin; prostaglandins; pth; relaxin; renin; resistin; secretin; somatostatin; testosterone; thpo; thymosin; thymulin; thyroxine (t4); trh; triiodothyronine (t3); tsh; vip; vitamin d; 17-alpha hydroxylase; 17; 20 lyase deficiency; 17-beta-hydroxysteroid dehydrogenase type 3 deficiency; 3-m syndrome; 22q11 deletion syndrome; 49xxxxy syndrome; abscess; acanthosis nigricans; acromegaly; acute adrenocortical insufficiency; addisonian crisis; addison's disease; adenocarcinoma; aip gene mutation; adrenal insufficiency; adrenal salt-wasting crisis; adrenarche; adrenocortical adenoma; adrenocortical carcinoma; adrenoleukodystrophy; aip gene variant; amenorrhoea (primary); amenorrhoea (secondary); amyloid goitre; amyloidosis; anaplastic thyroid cancer; anaemia; aneuploidy; androgen insensitivity syndrome; anti-phospholipid antibody syndrome; asthma; autoimmune disorders; autoimmune polyendocrine syndrome 1; autoimmune polyendocrine syndrome 2; autoimmune polyglandular syndrome; autoimmune hypophysitis; autosomal dominant hypophosphataemic rickets; autosomal dominant osteopetrosis; bardet-biedl syndrome; bartter syndrome; bilateral adrenal hyperplasia; biliary calculi; breast cancer; brenner tumour; brown tumour; burkitt's lymphoma; casr gene mutation; catecholamine secreting carotid body paraganglionoma; cancer-prone syndrome; carcinoid syndrome; carcinoid tumour; carney complex; carotid body paraganglioma; c-cell hyperplasia; cerebrospinal fluid leakage; chronic fatigue syndrome; circadian rhythm sleep disorders; congenital adrenal hyperplasia; congenital hypothyroidism; congenital hyperinsulinism; conn's syndrome; corticotrophic adenoma; craniopharyngioma; cretinism; crohn's disease; cryptorchidism; cushing's disease; cushing's syndrome; cystolithiasis; de quervain's thyroiditis; denys-drash syndrome; desynchronosis; developmental abnormalities; diabetes - lipoatrophic; diabetes - mitochondrial; diabetes - steroid-induced; diabetes insipidus - dipsogenic; diabetes insipidus - gestational; diabetes insipidus - nephrogenic; diabetes insipidus - neurogenic; central; diabetes mellitus type 1; diabetes mellitus type 2; diabetic foot syndrome; diabetic hypoglycaemia; diabetic ketoacidosis; diabetic muscle infarction; diabetic nephropathy; diverticular disease; donohue syndrome; down syndrome; eating disorders; ectopic acth syndrome; ectopic cushing's syndrome; ectopic parathyroid adenoma; empty sella syndrome; endometrial cancer; endometriosis; eosinophilic myositis; euthyroid sick syndrome; familial hypocalciuric hypercalcaemia; familial dysalbuminaemic hyperthyroxinaemia; familial euthyroid hyperthyroxinaemia; fat necrosis; female athlete triad syndrome; fetal demise; fetal macrosomia; follicular thyroid cancer; fractures; frasier syndrome; friedreich's ataxia; functional parathyroid cyst; galactorrhoea; gastrinoma; gastritis; gastrointestinal perforation; gastrointestinal stromal tumour; gck mutation; gender identity disorder; gestational diabetes mellitus; giant ovarian cysts; gigantism; gitelman syndrome; glucagonoma; glucocorticoid remediable aldosteronism; glycogen storage disease; goitre; goitre (multinodular); gonadal dysgenesis; gonadoblastoma; gonadotrophic adenoma; gorham's disease; granuloma; granulosa cell tumour; graves' disease; graves' ophthalmopathy; growth hormone deficiency (adult); growth hormone deficiency (childhood onset); gynaecomastia; hamman's syndrome; haemorrhage; hajdu-cheney syndrome; hashimoto's disease; hemihypertrophy; hepatitis c; hereditary multiple osteochondroma; hirsutism; histiocytosis; huntington's disease; hurthle cell adenoma; hyperaldosteronism; hyperandrogenism; hypercalcaemia; hypercalcaemic crisis; hyperglucogonaemia; hyperglycaemia; hypergonadotropic hypogonadism; hypergonadotropism; hyperinsulinaemia; hyperinsulinaemic hypoglycaemia; hyperkalaemia; hyperlipidaemia; hypernatraemia; hyperosmolar hyperglycaemic state; hyperparathyroidism (primary); hyperparathyroidism (secondary); hyperparathyroidism (tertiary); hyperpituitarism; hyperprolactinaemia; hypersexuality; hypertension; hyperthyroidism; hypoaldosteronism; hypocalcaemia; hypoestrogenism; hypoglycaemia; hypoglycaemic coma; hypogonadism; hypogonadotrophic hypogonadism; hypoinsulinaemia; hypokalaemia; hyponatraemia; hypoparathyroidism; hypophosphataemia; hypophosphatasia; hypophysitis; hypopituitarism; hypothyroidism; iatrogenic disorder; idiopathic bilateral adrenal hyperplasia; idiopathic pituitary hyperplasia; igg4-related systemic disease; inappropriate tsh secretion; incidentaloma; infertility; insulin autoimmune syndrome; insulin resistance; insulinoma; intracranial vasospasm; intrauterine growth retardation; iodine allergy; ischaemic heart disease; kallmann syndrome; ketoacidosis; klinefelter syndrome; kwashiorkor; kwashiorkor (marasmic); leg ulcer; laron syndrome; latent autoimmune diabetes of adults (lada); laurence-moon syndrome; left ventricular hypertrophy; leukocytoclastic vasculitis; leydig cell tumour; lipodystrophy; lipomatosis; liver failure; lung metastases; luteoma; lymphadenopathy; macronodular adrenal hyperplasia; macronodular hyperplasia; macroprolactinoma; marasmus; maturity onset diabetes of young (mody); mccune-albright syndrome; mckittrick-wheelock syndrome; medullary thyroid cancer; meigs syndrome; membranous nephropathy; men1; men2a; men2b; men4; menarche; meningitis; menopause; metabolic acidosis; metabolic syndrome; metastatic carcinoma; metastatic chromaffin cell tumour; metastatic gastrinoma; metastatic melanoma; metastatic tumour; microadenoma; microprolactinoma; motor neurone disease; myasthenia gravis; myelolipoma; myocardial infarction; myositis; myotonic dystrophy type 1; myotonic dystrophy type 2; myxoedema; myxoedema coma; nelson's syndrome; neonatal diabetes; nephrolithiasis; neuroblastoma; neuroendocrine tumour; neurofibromatosis; nodular hyperplasia; non-functioning pituitary adenoma; non-hodgkin lymphoma; non-islet-cell tumour hypoglycaemia; noonan syndrome; obesity; oculocerebrorenal syndrome; osteogenesis imperfecta; osteomalacia; osteomyelitis; osteoporosis; osteoporosis (pregnancy; lactation-associated); osteosclerosis; ovarian cancer; ovarian dysgenesis; ovarian hyperstimulation syndrome; ovarian tumour; paget's disease; paget's disease (juvenille); pancreatic neuroendocrine tumour; pancreatitis; panhypopituitarism; papillary thyroid cancer; paraganglioma; paranasal sinus lesion; paraneoplastic syndromes; parasitic thyroid nodules; parathyroid adenoma; parathyroid adenoma (ectopic); parathyroid carcinoma; parathyroid cyst; parathroid hyperplasia; pcos; periodontal disease; phaeochromocytoma; phaeochromocytoma crisis; pickardt syndrome; pituitary abscess; pituitary adenoma; pituitary apoplexy; pituitary carcinoma; pituitary cyst; pituitary haemorrhage; pituitary hyperplasia; pituitary hypoplasia; pituitary tumour (malignant); plurihormonal pituitary adenoma; poems syndrome; polycythaemia; porphyria; pneumonia; posterior reversible encephalopathy syndrome; post-prandial hypoglycaemia; prader-willi syndrome; prediabetes; pre-eclampsia; pregnancy; premature ovarian failure; premenstrual dysphoric disorder; premenstrual syndrome; primary hypertrophic osteoarthropathy; prolactinoma; prostate cancer; pseudohypoaldosteronism type 1; pseudohypoaldosteronism type 2; pseudohypoparathyroidism; psychosocial short stature; puberty (delayed or absent); puberty (precocious); pulmonary oedema; quadrantanopia; rabson-mendenhall syndrome; rhabdomyolysis; rheumatoid arthritis; rickets; schwannoma; sellar reossification; sertoli cell tumour; sertoli-leydig cell tumour; sexual development disorders; sheehan's syndrome; short stature; siadh; small-cell carcinoma; small intestine neuroendocrine tumour; solitary fibrous tumour; solitary sellar plasmacytoma; somatostatinoma; somatotrophic adenoma; squamous cell thyroid carcinoma; stiff person syndrome; struma ovarii; subcutaneous insulin resistance; systemic lupus erythematosus; takotsubo cardiomyopathy; tarts; testicular cancer; thecoma; thyroid adenoma; thyroid carcinoma; thyroid cyst; thyroid dysgenesis; thyroid fibromatosis; thyroid hormone resistance syndrome; thyroid lymphoma; thyroid nodule; thyroid storm; thyroiditis; thyrotoxicosis; thyrotrophic adenoma; traumatic brain injury; tuberculosis; tuberous sclerosis complex; tumour-induced osteomalacia; turner syndrome; unilateral adrenal hyperplasia; ureterolithiasis; urolithiasis; von hippel-lindau disease; wagr syndrome; waterhouse-friderichsen syndrome; williams syndrome; wolcott-rallison syndrome; wolfram syndrome; xanthogranulomatous hypophysitis; xlaad; ipex; zollinger-ellison syndrome; abdominal adiposity; abdominal distension; abdominal cramp; abdominal discomfort; abdominal guarding; abdominal lump; abdominal pain; abdominal tenderness; abnormal posture; abdominal wall defects; abrasion; acalculia; acanthosis nigricans; accelerated growth; acne; acrochorda; acroosteolysis; acute stress reaction; adverse breast development; aggression; agitation; agnosia; akathisia; akinesia; albuminuria; alcohol intolerance; alexia; alopecia; altered level of consciousness; amaurosis; amaurosis fugax; ambiguous genitalia; amblyopia; amenorrhoea; ameurosis; amnesia; amusia; anaemia; anasarca; angiomyxoma; anhedonia; anisocoria; ankle swelling; anorchia; anorectal malformations; anorexia; anosmia; anosognosia; anovulation; antepartum haemorrhage; anuria; anxiety; apathy; aphasia; aphonia; apnoea; appendicitis; appetite increase; appetite reduction; loss; apraxia; aqueductal stenosis; arteriosclerosis; arthralgia; articulation impairment; ascites; asperger syndrome; asphyxia; asthenia; astigmatism; asymptomatic; ataxia; atrial fibrillation; atrial myxoma; atrophy; adhd; autism; autonomic neuropathy; avulsion; babinski's sign; back pain; bacteraemia; behavioural problems; belching; bifid scrotum; biliary colic; bitemporal hemianopsia; blindness; blistering; bloating; bloody show; boil(s); bone cyst; bone fracture(s); bone lesions; bone pain; bony metastases; borborygmus; bowel movements - bleeding; bowel movements - increased frequency; bowel movements - pain; bowel obstruction; bowel perforation; brachycephaly; brachydactyly; bradycardia; bradykinesia; bradyphrenia; bradypnea; breast contour change; breast enlargement; breast lump; breast reduction; breast tenderness; breastfeeding difficulties; breathing difficulties; bronchospasms; brushfield spots; bruxism; buffalo hump; cachexia; calcification; cardiac fibrosis; cardiac malformations; cardiac tamponade; cardiogenic shock; cardiomegaly; cardiomyopathy; cardiopulmonary arrest; carpal tunnel syndrome; caruncle - inflammation; cataplexy; cataract(s); catathrenia; central obesity; cerebrospinal fluid rhinorrhoea; cervical pain; cheeks - full; cheiloschisis; chemosis; chest pain; chest pain (pleuritic); chest pain (precordial); cheyne-stokes respiration; chills; cholecystitis; cholestasis; chondrocalcinosis; chordee; chorea; choroidal atrophy; chronic pain; circulatory collapse; cirrhosis; citraturia; claudication; clitoromegaly; cloacal exstrophy; clonus; club foot; clumsiness; coagulopathy; coarctation; coeliac disease; cognitive problems; cold intolerance; collapse; colour blindness; coma; concentration difficulties; confusion; congenital heart defect; conjunctivitis; constipation; convulsions; coordination difficulties; coughing; crackles; cramps; craniofacial abnormalities; craniotabes; cryptorchidism; cutaneous ischaemia; cutaneous myxoma; cutaneous pigmentation; cyanosis; dalrymple's sign; deafness; deep vein thrombosis; dehydration; delayed puberty; delirium; dementia; dental abscess(es); dental problems; depression; diabetes insipidus; diabetes mellitus type 1; diabetes mellitus type 2; diabetic neuropathy; diabetic foot infection; diabetic nephropathy; diabetic foot neuropathy; diabetic foot ulceration; diabetic ketoacidosis; diarrhoea; diplopia; dizziness; duodenal atresia; duplex kidney(s); dysarthria; dysdiadochokinesia; dysgraphia; dyslexia; dyslipidaemia; dysmenorrhoea; dyspareunia; dyspepsia; dysphagia; dysphonia; dysphoria; dyspnoea; dystonia; dysuria; ear; nose and; or throat infection; early menarche; ears - low set; ears - pinna abnormalities; ears - small; ecchymoses; ectopic ureter; emotional immaturity; encopresis; endometrial hyperplasia; enlarged bladder; enlarged prostate; eosinophilia; epicanthic fold; epilepsy; epistaxis; erectile dysfunction; erythema; euphoria; eyebrows - bushy; eyelid retraction; eyelid swelling; eyelids - redness; eyes - almond-shaped; eyes - dry; eyes - feeling of grittiness; eyes - inflammation; eyes - irritation; eyes - itching; eyes - pain (gazing down); eyes - pain (gazing up); eyes - redness; eyes - watering; face - change in appearance; face - coarse features; face - numbness; facial fullness; facial palsy; facial plethora; facial weakness; facies - abnormal; facies - hippocratic; facies - moon; faecal incontinence; failure to thrive; fallopian tube hyperplasia; fasciculation; fatigue; fatigue (post-exertional); feet - cold; feet - increased size; feet - large; feet - pain; feet - small; fingers - thick; flaccid paralysis; flatulence; flushing; fontanelles - enlarged; frontal bossing; fungating lesion; fungating mass; funny turns; gait abnormality; gait unsteadiness; galactorrhoea; gallbladder calculi; gallstones; gangrene; gastro-oesophageal reflux; genital oedema; genu valgum; genu varum; gestational diabetes; glaucoma; glucose intolerance; glucosuria; goitre; growth hormone deficiency; growth retardation; gynaecomastia; haematemesis; haematochezia; haematoma; haematuria; haemoglobinuria; haemoptysis; hair - coarse; hair - dry; hair - temporal balding; hairline - low; hallucination; hands - enlargement; hands - large; hands - single palmar crease; hands - small; head - large; headache; hearing loss; heart failure; heart murmur; heat intolerance; height loss; hemiballismus; hemianopia; hemiparesis; hemispatial neglect; hepatic cysts; hepatic metastases; hepatomegaly; hidradenitis suppurativa; high-arched palate; hip dislocation; hippocampal dysgenesis; hirschsprung's disease; hirsutism; hot flushes; hydronephrosis; hypolipidaemia; hyperactivity; hyperacusis; hyperandrogenaemia; hyperandrogenism; hypercalcaemia; hypercalciuria; hypercapnea; hypercholesterolaemia; hypercortisolaemia; hyperflexibility; hyperglucagonaemia; hyperglycaemia; hyperhidrosis; hyperhomocysteinaemia; hyperinsulinaemia; hyperkalaemia; hypernasal speech; hypernatraemia; hyperopia; hyperoxaluria; hyperpigmentation; hyperplasia; hyperpnoea; hyperprolactinaemia; hypersalivation; hyperseborrhea; hypersomnia; hypertension; hyperthermia; hyperthyroidism; hypertrichosis; hypertrophy; hyperuricaemia; hyperventilation; hypoadrenalism; hypoalbuminaemia; hypocalciuria; hypocitraturia; hypoglycaemia; hypogonadism; hypoinsulinaemia; hypokalaemia; hypomagnesaemia; hyponatraemia; hypoparathyroidism; hypophosphataemia; hypopigmentation; hypopituitarism; hypoplastic scrotum; hypopotassaemia; hypoprolactinaemia; hyporeflexia; hyposmia; hypospadias; hypotension; hypothermia; hypothyroidism; hypotonia; hypoventilation; hypovitaminosis d; hypovolaemia; hypovolaemic shock; hypoxia; immunodeficiency; impulsivity; inattention; infections; infertility; inflexibility; insomnia; instability; insulin resistance; intussusception; irritability; ischaemia; ischuria; itching; jaundice; keratoconus; ketonuria; ketotic odour; kidney dysplasia; kidney stones; kyphoscoliosis; kyphosis; labioscrotal fold abnormalities; laceration; late dentition; learning difficulties; leg pain; legs - increased length; leukaemia; leukocytosis; libido increase; libido reduction; loss; lichen sclerosus; lips - dry; lips - thin; little finger - in-curved; little finger - short; liver masses; lordosis; lordosis (loss of); lymphadenectomy; lymphadenitis; lymphocytosis; lymphoedema; macroglossia; malaise; malaise (post-exertional); malodorous perspiration; mania; marcus gunn pupil; mastalgia; meckel's diverticulum; melena; menorrhagia; menstrual disorder; mesenteric ischaemia; metabolic acidosis; metabolic alkalosis; microalbuminuria; microcephaly; micrognathia; micropenis; milk-alkali syndrome; miscarriage; mood changes; swings; mouth - down-turned; mouth - small; movement - limited range of; mucosal pigmentation; muscle atrophy; muscle freezing; muscle hypertrophy; muscle rigidity; myalgia; myasthaenia; mydriasis; myelodysplasia; myeloma; myocardial infarction; myoclonus; myodesopsia; myokymia; myopathy; myopia; myosis; myxoedema; nail clubbing; nail dystrophy; nasal obstruction; nausea; neck - loose skin (nape); neck - short; neck mass; neck pain; discomfort; necrolytic migratory erythema; necrosis; nephrocalcinosis; nephropathy; neuroblastoma; neurofibromas; night terrors; nipple change; nipple discharge; nipple inversion; nipple retraction; nipples widely spaced; nocturia; normochromic normocytic anaemia; nose - depressed bridge; nose - flat bridge; nose - thickening; nystagmus; obesity; obsessive-compulsive disorder; obstetrical haemorrhage; obstructive sleep apnoea; odynophagia; oedema; oesophageal atresia; oesophagitis; oligomenorrhoea; oliguria; onychauxis; oophoritis; ophthalmoplegia; optic atrophy; orbital fat prolapse; orbital hypertelorism; orthostatic hypotension; osteoarthritis; osteomalacia; osteopenia; osteoporosis; osteosclerosis; otitis media; ovarian cysts; ovarian hyperplasia; palatoschisis; pallor; palmar erythema; palpebral fissure (downslanted); palpebral fissure (extended); palpebral fissure (reduced); palpebral fissure (upslanted); palpitations; pancreatic fibrosis; pancreatitis; pancytopaenia; panic attacks; papilloedema; paraesthesia; paralysis; paranoia; patellar dislocation; patellar subluxation; pedal ulceration; pellagra; pelvic mass; pelvic pain; penile agenesis; peptic ulcer; pericardial effusion; periodontitis; periosteal bone reactions; peripheral oedema; personality change; pes cavus; petechiae; peyronie's disease; pharyngitis; philtrum - long; philtrum - short; phosphaturia; photophobia; photosensitivity; pleurisy; pneumonia; poikiloderma; polycythaemia; polydactyly; polydipsia; polyphagia; polyuria; poor wound healing; postmenopausal bleeding; post-nasal drip; postprandial fullness; postural instability; prehypertension; premature birth; premature labour; prenatal growth retardation; presbyopia; pretibial myxoedema; proctalgia fugax; prognathism; proptosis; prosopagnosia; proteinuria; pruritus; pruritus scroti; pruritus vulvae; pseudarthrosis; psoriatic arthritis; psychiatric problems; psychomotor retardation; psychosis; pterygium colli; ptosis; puberty (delayed; absent); puberty (early; precocious); puffiness; pulmonary embolism; purpura; pyelonephritis; pyloric stenosis; pyrexia; pyrosis; pyuria; rash; rectal pain; rectorrhagia; refractory anemia; reluctance to weight-bear; renal agenesis; renal clubbing; renal colic; renal cyst; renal failure; renal insufficiency; renal phosphate wasting (isolated); renal tubular acidosis; respiratory failure; reticulocytosis; retinitis pigmentosa; retinopathy; retrobulbar pain; retrograde ejaculation; retroperitoneal fibrosis; rhabdomyolysis; rheumatoid arthritis; rickets; salivary gland swelling; salpingitis; salt craving; salt wasting; sarcoidosis; schizophrenia; scoliosis; scotoma; seborrhoeic dermatitis; seizures; sensory loss; sepsis; septic arthritis; septic shock; shivering; short stature; singultus; sinusitis; sixth nerve palsy; skeletal deformity; skeletal dysplasia; skin - texture change; skin infections; skin necrosis; skin pigmentation - spotty; skin thickening; skin thinning; sleep apnoea; sleep difficulties; sleep disturbance; sleep hyperhidrosis; slow growth; slurred speech; social difficulties; soft tissue swelling; somnambulism; somniloquy; somnolence; sore throat; spasms; spastic paraplegia; spasticity; speech delay; spider naevi; splenomegaly; sputum production; steatorrhoea; stomatitis; strabismus; strangury; striae; stridor; stroke; subfertility; suicidal ideation; supraclavicular fat pads; supranuclear gaze palsy; sweating; syncope; syndactyly; tachycardia; tachypnoea; teeth gapping; telangiectasias; telecanthus; tetraparesis; t-reflex (absent); t-reflex (depressed); tarts; tetany; thermodysregulation; thrombocytopenia; thrombocytosis; thrombophilia; thrush; thyroid nodule; thyrotoxicosis; tics; tinnitus; toe clubbing; toe deformities; toes - thick; toes - widely spaced; tongue - protruding; tracheo-oesophageal compression; tracheo-oesophageal fistula; tremulousness; tricuspid insufficiency; umbilical hernia; uraemia; ureter duplex; uricaemia; urinary frequency; urinary incontinence; urogenital sinus; urticaria; uterine hyperplasia; uterus duplex; vagina duplex; vaginal bleeding; vaginal discharge; vaginal dryness; vaginal pain; tenderness; vaginism; ventricular fibrillation; ventricular hypertrophy; vertigo; viraemia; virilisation (abnormal); vision - acuity reduction; vision - blurred; visual disturbance; visual field defect; visual impairment; visual loss; vitiligo; vocal cord paresis; vomiting; von graefe's sign; weight gain; weight loss; wheezing; widened joint space(s); xeroderma; xerostomia; 3-methoxy 4-hydroxy mandelic acid; 17ohp; 17-hydroxypregnenolone (urine); 17-ketosteroids; 25-hydroxyvitamin-d3; 5hiaa; aberrant adrenal receptors; acid-base balance; acth; acth stimulation; activated partial thromboplastin time; acyl-ghrelin; adiponectin; adrenal antibodies; adrenal function; adrenal scintigraphy; adrenal venous sampling; adrenaline; afp tumour marker; alanine aminotransferase; albumin; albumin to creatinine ratio; aldosterone (24-hour urine); aldosterone (blood); aldosterone (plasma); aldosterone (serum); aldosterone to renin ratio; alkaline phosphatase; alkaline phosphatase (bone-specific); alpha-fetoprotein; amh; ammonia; amniocentesis; amylase; androstenedione; angiography; anion gap; anti-acetylcholine antibodies; anticardiolipin antibody; anti-insulin antibodies; anti-islet cell antibody; anti-gh antibodies; antinuclear antibody; anti-tyrosine phosphatase antibodies; asvs; barium studies; basal insulin; base excess; apolipoprotein h; beta-hydroxybutyrate; bicarbonate; bilirubin; biopsy; blood film; blood pressure; bmi; body fat mass; bone age; bone biopsy; bone mineral content; bone mineral density; bone mineral density test; bone scintigraphy; bone sialoprotein; bound insulin; brain natriuretic peptide; brca1; brca2; c1np; c3 complement; c4 complement; ca125; calcifediol; calcitonin; calcitriol; calcium (serum); calcium (urine); calcium to creatinine clearance ratio; carcinoembryonic antigen; cardiac index; catecholamines (24-hour urine); catecholamines (plasma); cd-56; chemokines; chest auscultation; chloride; chorionic villus sampling; chromatography; chromogranin a; chromosomal analysis; clomid challenge; clonidine suppression; collagen; colonoscopy; colposcopy; continuous glucose monitoring; core needle biopsy; corticosterone; corticotropin-releasing hormone stimulation test; cortisol; cortisol (9am); cortisol (plasma); cortisol (midnight); cortisol (salivary); cortisol (serum); cortisol day curve; cortisol; free (24-hour urine); c-peptide (24-hour urine); c-peptide (blood); c-reactive protein; creatinine; creatine kinase; creatinine (24-hour urine); creatinine (serum); creatinine clearance; crh; crh stimulation; ctpa scan; ct scan; c-telopeptide; cytokines; dehydroepiandrostenedione; deoxycorticosterone; deoxypyridinoline; dexa scan; dexamethasone suppression; dexamethasone suppression (high dose); dexamethasone suppression (low dose); dhea sulphate; discectomy; dldl cholesterol; dmsa scan; dna sequencing; dopamine; domperidone; down syndrome screening; ductal lavage; echocardiogram; eeg; electrocardiogram; electrolytes; electromyography; endoscopic ultrasound; endoscopy; endosonography; enzyme immunoassay; epinephrine (plasma); epinephrine (urine); erythrocyte sedimentation rate; estimated glomerular filtration rate; ethanol ablation; ewing and clarke autonomic function; exercise tolerance; fbc; ferritin; fgf23; fine needle aspiration biopsy; flow cytometry; fludrocortisone suppression; fluticasone-propionate-17-beta carboxylic acid; fmri; folate; fsh; ft3; ft4; gada; gallium nitrate; gallium scan; gastric biopsy; gastrin; genetic analysis; genitography; gh; gh day curve; gh stimulation; gh suppression; ghrh; glp-1; glp-2; glucagon; glucose suppression test; glucose (blood); glucose (blood; fasting); glucose (blood; postprandial); glucose (urine); glucose tolerance; glucose tolerance (intravenous); glucose tolerance (oral); glucose tolerance (prolonged); gluten sensitivity; gnrh stimulation; gonadotrophins; growth hormone-releasing peptide-2 test; gut hormones (fasting); haematoxylin and eosin staining; haemoglobin; haemoglobin a1c; hcg (serum); hcg (urine); hcg stimulation; hdl cholesterol; hearing test; heart rate; hepatic venous sampling with arterial stimulation; high-sensitivity c-reactive protein; histopathology; hla genotyping; holter monitoring; homa; homocysteine; hyaluronic acid; hydrocortisone day curve; hydroxyproline; hydroxyprogesterone; hydroxypregnenolone; hysteroscopy; igf1; igf2; igfbp2; igfbp3; igg4; igg ratio; immunocytochemistry; immunohistochemistry; immunoglobulins; immunoglobulin g2; immunoglobulin g4; immunoglobulin a; immunoglobulin m; immunostaining; inferior petrosal sinus sampling; inhibin b; insulin; insulin (fasting); insulin suppression; insulin tissue resistance tests; insulin tolerance; intracranial pressure; irm imaging; ketones (plasma); ketones (urine); kidney function; lactate; lactate dehydrogenase; laparoscopy; laparoscopy and dye; laparotomy; ldl cholesterol; leuprolide acetate stimulation; leukocyte esterase (urine); levothyroxine absorption; lh; lipase (serum); lipid profile; liquid-based cytology; liquid chromatography-mass spectrometry; liver biopsy; liver function; lumbar puncture; lung function testing; luteinising hormone releasing hormone test; macroprolactin; magnesium; mag3 scan; mammogram; mantoux test; metanephrines (plasma); metanephrines (urinary); methoxytyramine; metoclopramide; metyrapone cortisol day curve; metyrapone suppression; metyrapone test dose; mibg scan; microarray analysis; molecular genetic analysis; mri; myocardial biopsy; nerve conduction study; neuroendocrine markers; neuron-specific enolase; noradrenaline; norepinephrine; normetanephrine; ntx; oct; octreotide scan; octreotide suppression test; oestradiol (e2); oestriol (e3); oestrogens; oestrone (e1); osmolality; osteocalcin; ovarian venous sampling; p1np; palpation; pancreatic polypeptide; pap test; parathyroid scintigraphy; pentagastrin; perchlorate discharge; percutaneous umbilical blood sampling; peripheral blood film; pet scan; ph (blood); phosphate (serum); phosphate (urine); pituitary function; plasma osmolality; plasma viscosity; platelet count; pneumococcal antigen; pneumococcal pcr; polymerase chain reaction; polysomnography; porter-silber chromogens; potassium; pregnancy test; pregnenolone; procalcitonin; progesterone; proinsulin; prolactin; prostate-specific antigen; protein electrophoresis; protein fingerprinting; ; 
