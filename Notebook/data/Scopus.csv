Document Type,Authors,Title,Source,Year,Link,Abstract,Keywords
Article,"Nawaz F., Ramzan M., Mehmood K., Khan H.U., Khan S.H., Bhutta M.R.",Early detection of diabetic retinopathy using machine intelligence through deep transfer and representational learning,"Computers, Materials and Continua",2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097200933&doi=10.32604%2fcmc.2020.012887&partnerID=40&md5=28ed27a998be132ff3982660760e1df5,"Diabetic retinopathy (DR) is a retinal disease that causes irreversible blindness. DR occurs due to the high blood sugar level of the patient, and it is clumsy to be detected at an early stage as no early symptoms appear at the initial level. To prevent blindness, early detection and regular treatment are needed. Automated detection based on machine intelligence may assist the ophthalmologist in examining the patients' condition more accurately and efficiently. The purpose of this study is to produce an automated screening system for recognition and grading of diabetic retinopathy using machine learning through deep transfer and representational learning. The artificial intelligence technique used is transfer learning on the deep neural network, Inception-v4. Two configuration variants of transfer learning are applied on Inception-v4: Fine-tune mode and fixed feature extractor mode. Both configuration modes have achieved decent accuracy values, but the fine-tuning method outperforms the fixed feature extractor configuration mode. Fine-tune configuration mode has gained 96.6% accuracy in early detection of DR and 97.7% accuracy in grading the disease and has outperformed the state of the art methods in the relevant literature. © 2021 Tech Science Press. All rights reserved.",Artificial intelligence; Automated screening system; Deep neural network; Diabetic retinopathy; Machine learning; Transfer and representational learning
Article,"Aladawi W., Jayakumari C., Sumesh E.P., Vidhyalavanya",Recent innovations in automated detection and classification of diabetic retinopathy,International Journal of Innovative Technology and Exploring Engineering,2019,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85071277303&doi=10.35940%2fijitee.J9306.0881019&partnerID=40&md5=dce58d91544e8edb284ed11b9c1e178e,"Due to the increasing prevalence of diabetic retinopathy worldwide, it’s an urgent need to develop smart system that help to detect disease using one of the modern technologies. Artificial intelligence is one of the popular techniques nowadays which has the ability to learn from experience and carry out human-like tasks. Large number of researches have been conducted to find out effective medical diagnosis methods for numerous diseases. Likewise, huge number of researches have been done that discuss automated detection and classification of diabetic retinopathy. This paper reviews the existing methodologies, datasets, sensitivity, specificity and classification accuracy in diabetic retinopathy. © BEIESP.",Accuracy; Artificial intelligence; Autoencoders; CNN; Deep Learning; Diabetes Mellitus; Diabetic Retinopathy; DRIVE; Image Preprocessing; Kaggle; Keras; Machine Learning; Messidor-2; NPDR; PDR; RBM; RNN; Sensitivity; Specificity; TensorFlow; Theano
Conference Paper,"Gothane S., Raju K.S., Bhaskar N., Divya G.",Diabetic Retinopathy Detection Using Deep Learning,Lecture Notes in Networks and Systems,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85135076504&doi=10.1007%2f978-981-19-1559-8_39&partnerID=40&md5=26b78a7c647ca7e6d86d319ab5cb37cb,"Diabetes sickness upsurges the quantity of glucose in the blood triggered by a deficiency of insulin. Diabetes affects retina, heart, nerves and kidney. One important complication is Diabetic Retinopathy. The mechanized methods for Diabetic Retinopathy recognition are flexible for cost and time reduction and are more competent over manual analysis. Deep Learning technique performs computer aided medical diagnosis. This paper is an attempt toward finding an automatic solution for Diabetic Retinopathy disease in initial stage. Using Artificial Intelligence and Deep Learning, doctors can find blindness before it happens. In this project we are using supervised learning approach to perform classification on fundus images. For this task we are employing several image processing procedures and filters to improve many significant features like microaneurysm, hemorrhages, exudates, swollen blood vessels which are the features of fundus image that imply that particular person has Diabetic Retinopathy and then using neural networks for classification. This classifies the fundus images with an accuracy of 82% by using ResNet architecture. © 2022, The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd.",Deep learning; Diabetic Retinopathy; ResNet
Article,"Arsalan M., Owais M., Mahmood T., Cho S.W., Park K.R.",Aiding the diagnosis of diabetic and hypertensive retinopathy using artificial intelligence-based semantic segmentation,Journal of Clinical Medicine,2019,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85086632926&doi=10.3390%2fjcm8091446&partnerID=40&md5=3d9cc6cb6c379f89afeff63587d7a73f,"Automatic segmentation of retinal images is an important task in computer-assisted medical image analysis for the diagnosis of diseases such as hypertension, diabetic and hypertensive retinopathy, and arteriosclerosis. Among the diseases, diabetic retinopathy, which is the leading cause of vision detachment, can be diagnosed early through the detection of retinal vessels. The manual detection of these retinal vessels is a time-consuming process that can be automated with the help of artificial intelligence with deep learning. The detection of vessels is difficult due to intensity variation and noise from non-ideal imaging. Although there are deep learning approaches for vessel segmentation, these methods require many trainable parameters, which increase the network complexity. To address these issues, this paper presents a dual-residual-stream-based vessel segmentation network (Vess-Net), which is not as deep as conventional semantic segmentation networks, but provides good segmentation with few trainable parameters and layers. The method takes advantage of artificial intelligence for semantic segmentation to aid the diagnosis of retinopathy. To evaluate the proposed Vess-Net method, experiments were conducted with three publicly available datasets for vessel segmentation: digital retinal images for vessel extraction (DRIVE), the Child Heart Health Study in England (CHASE-DB1), and structured analysis of retina (STARE). Experimental results show that Vess-Net achieved superior performance for all datasets with sensitivity (Se), specificity (Sp), area under the curve (AUC), and accuracy (Acc) of 80.22%, 98.1%, 98.2%, and 96.55% for DRVIE; 82.06%, 98.41%, 98.0%, and 97.26% for CHASE-DB1; and 85.26%, 97.91%, 98.83%, and 96.97% for STARE dataset. © 2019 by the authors. Licensee MDPI, Basel, Switzerland.",Diabetic retinopathy; Retinal vessels; Vess-Net; Vessel segmentation
Article,"Tsai C.-Y., Chen C.-T., Chen G.-A., Yeh C.-F., Kuo C.-T., Hsiao Y.-C., Hu H.-Y., Tsai I.-L., Wang C.-H., Chen J.-R., Huang S.-C., Lu T.-C., Woung L.-C.",Necessity of Local Modification for Deep Learning Algorithms to Predict Diabetic Retinopathy,International Journal of Environmental Research and Public Health,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85122995569&doi=10.3390%2fijerph19031204&partnerID=40&md5=62747d1014bbd67a9066cb2424560e61,"Deep learning (DL) algorithms are used to diagnose diabetic retinopathy (DR). However, most of these algorithms have been trained using global data or data from patients of a single region. Using different model architectures (e.g., Inception-v3, ResNet101, and DenseNet121), we assessed the necessity of modifying the algorithms for universal society screening. We used the open-source dataset from the Kaggle Diabetic Retinopathy Detection competition to develop a model for the detection of DR severity. We used a local dataset from Taipei City Hospital to verify the necessity of model localization and validated the three aforementioned models with local datasets. The experimental results revealed that Inception-v3 outperformed ResNet101 and DenseNet121 with a foreign global dataset, whereas DenseNet121 outperformed Inception-v3 and ResNet101 with the local dataset. The quadratic weighted kappa score (κ) was used to evaluate the model performance. All models had 5–8% higher κ for the local dataset than for the foreign dataset. Confusion matrix analysis revealed that, compared with the local ophthalmologists’ diagnoses, the severity predicted by the three models was overestimated. Thus, DL algorithms using artificial intelligence based on global data must be locally modified to ensure the applicability of a well-trained model to make diagnoses in clinical environments. © 2022 by the authors. Licensee MDPI, Basel, Switzerland.",Deep learning algorithms; Diabetic retinopathy; Model localised; Predict; Taiwan
Article,"Nasir N., Afreen N., Patel R., Kaur S., Sameer M.",A Transfer Learning Approach for Diabetic Retinopathy and Diabetic Macular Edema Severity Grading,Revue d'Intelligence Artificielle,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85122763647&doi=10.18280%2fria.350608&partnerID=40&md5=e2abecd815032cf464662254c753cbb8,"Diabetic Retinopathy (DR) and Diabetic Macular Edema (DME) are complication that occurs in diabetic patient especially among working age group that leads to vision impairment problem and sometimes even permanent blindness. Early detection is very much needed for diagnosis and to reduce blindness or deterioration. The diagnosis phase of DR consumes more time, effort and cost when manually performed by ophthalmologists and more chances of misdiagnosis still there. Research community is working on to design computer aided diagnosis system for prior detection and for DR grading based on its severity. Ongoing researches in Artificial Intelligence (AI) have set out the advancement of deep learning technique which comes as a best technique to perform analysis and classification of medical images. In this paper, research is applied on Resnet50 model for classification of DR and DME based on its severity grading on public benchmark dataset. Transfer learning approach accomplishes the best outcome on Indian Diabetic Retinopathy Image Dataset (IDRiD). © 2021 Lavoisier. All rights reserved.",Diabetic macular edema; Diabetic retinopathy; ResNet50; Transfer learning
Conference Paper,"Krupalin V.A.H., Sowmya M.L., Kumar M.M.",Intelligent Computing Method for Detecting Diabetic Retinopathy (DBRP),Lecture Notes in Networks and Systems,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85127675069&doi=10.1007%2f978-981-16-8987-1_58&partnerID=40&md5=c2b6e8f96ddf87f1d29fe988b4e8f75a,"Diabetes mellitus is a metabolic disease that increases the glucose levels in blood. According to the International Diabetes Federation (IDF), 463 million people worldwide have diabetes (1 in 11 adults (20–79 years)). Diabetic retinopathy is an eye condition that can cause visual loss in individuals who have diabetes. Deep learning is one of the emerging tools in recent years for machine learning problem-solving with artificial intelligence. In this paper, we applied its methods for diagnosis of diabetic retinopathy. We can implement the retinal detection by using convolutional neural networks (CNNs) for the recognition task on color fundus images, various retinal feature extractions and automated analysis. Therefore, an intelligent computing method for detection of DBRP is proposed for diagnosing the diabetic retinopathy based on deep learning algorithms through the classification of retinal fundus. © 2022, The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd.",Convolutional neural network (CNN); Deep learning; Diabetic retinopathy; Feature extraction; Retinal fundus photograph; Siamese network
Conference Paper,"Ghebrechristos H., Alaghband G., Hwang R.Y.",RetiNet - Feature Extractor for Learning Patterns of Diabetic Retinopathy and Age-Related Macular Degeneration from Publicly Available Datasets,"Proceedings - 2017 International Conference on Computational Science and Computational Intelligence, CSCI 2017",2018,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85060641418&doi=10.1109%2fCSCI.2017.286&partnerID=40&md5=354e7cd8a8c5b04caffa344728a5a645,"Diabetic Retinopathy (DR) and Age-related Macular Degeneration (AMD) are two common vision threatening eye conditions. In a large-scale screening environment DR and AMD can be assessed by detecting specific retinal findings in fundus images. In this paper, we introduce a new deep learning based feature extractor for automatic classification of DR and AMD from fundus images. We used a small dataset containing 60000 images with four severity levels of DR and two classes of AMD to design and fine-tune a deep learning model called RetiNet. This dataset, which consisted of two publicly available datasets (MESSIDOR and Kaggle), was augmented and employed to evaluate RetiNet. RetiNet can achieve diagnosis performance comparable to retina experts on the MESSIDOR dataset with cross-dataset testing (i.e., the feature extractor was trained on an independent dataset and tested on MESSIDOR). Our algorithm obtained an average accuracy of 88% on the validation set. © 2017 IEEE.",Age-related Macular Degeneration (AMD); Artificial Neural Network (ANN); Convolutional Neural Network(CNN); Deep Learning; Diabetic Retinopathy(DR)
Conference Paper,"Vipparthi V., Rao D.R., Mullu S., Patlolla V.",Diabetic Retinopathy Classification using Deep Learning Techniques,"3rd International Conference on Electronics and Sustainable Communication Systems, ICESC 2022 - Proceedings",2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85139559867&doi=10.1109%2fICESC54411.2022.9885687&partnerID=40&md5=283ac6d13b7feb41c5249c821a2d6aa4,"Diabetic Retinopathy is a disease that damages the eyes and is caused by a consequence of diabetes. If blood sugar levels aren't controlled for an extended period of time, the disease can develop. It is mainly caused due to the damage of blood vessels in the retina. Retinopathy is the main cause of blindness in the world. Doctors can diagnose blindness before it occurs using Artificial Intelligence and Deep Learning. Medical imaging plays a very crucial role in a variety of medical issues and at all major levels of health issues. Medical imaging can be used to identify a variety of common eye illnesses. However, for a variety of reasons, including uneven lighting, picture blurring, and low contrast and brightness, poor-quality retinal images are ineffective for further diagnosis, particularly in automated analyzing systems. Ophthalmologists' manual Diabetic Retinopathy diagnostic procedure is time-consuming, requires more work, costly, and might result in misdiagnosis. Basing on the vision like having trouble in reading distant objects or seeing distant objects, blindness or any other changes may happen in eye retina that affects diabetes. Diabetic retinopathy is one of the most frequent eye illnesses, affecting mostly diabetics. This model can assist the opthmologists for clinical diagnosis and detect and classify the diabetic retinopathy. There are three phases in this diabetic retinopathy detection and classification technique (i) enhancement (ii) Feature Extraction and (iii) Retinopathy Detection and Classification. Feature extraction involves blood vessels extraction and exudates extraction. First two phases assist the opthmologists by providing clear images of the retina and blood vessels and exudates extracted images. In this work, from the presented retinal fundus pictures, the Res-Block model is used to classify and diagnose diabetic retinopathy. © 2022 IEEE.",Artificial Intelligence; Deep Learning; Diabetic Retinopathy; Fundus; Medical Imaging
Conference Paper,"Sriman B., Muangnak N., Sirawattananon C.",Automated Clinical Assessment in Diabetic Retinopathy Retinal Images: A Review,"2022 19th International Joint Conference on Computer Science and Software Engineering, JCSSE 2022",2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85136226644&doi=10.1109%2fJCSSE54890.2022.9836245&partnerID=40&md5=281ab1047fa5a348382bd8a66e68e472,"There are no early symptoms associated with retinal diseases. Diabetic retinopathy (DR) is the leading cause of macular degeneration in people with diabetes in their 40s and 50s. It is a critical step in determining the stage of an ophthalmology preliminary abnormality diagnosis. DR lesions detected on images taken with the hospital's high-quality imaging equipment can now be screened and identified automatically by an image processing system. It is proposed to screen for early symptoms of DR by detecting abnormalities within retinal images using computer-based imaging. The purpose of this study is to conduct a review of existing works in the fields of artificial intelligence and image processing to develop an algorithm for an automatic DR screening system. A review paper on the use of deep learning with DR detection was introduced, as well as a section experimenting with DR in retinal fundus images from publicly available datasets. To enhance DR detection performance, feature extraction techniques would be suggested. © 2022 IEEE.",deep learning; diabetic retinopathy detection; machine learning; retinal image processing
Conference Paper,"Agustin T., Utami E., Fatta H.A.",Implementation of Data Augmentation to Improve Performance CNN Method for Detecting Diabetic Retinopathy,"2020 3rd International Conference on Information and Communications Technology, ICOIACT 2020",2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85100871869&doi=10.1109%2fICOIACT50329.2020.9332019&partnerID=40&md5=c516af2b5dd68b4550eff1ca72b32e02,"The most common causes of blindness in adults worldwide, 2.6% of them are caused by diabetic retinopathy, which is a progressive disease caused by complications of diabetes mellitus. Early detection and prompt treatment help save eyesight. The artificial intelligence technology can provide objective and accurate screening results. Deep learning, especially the Convolutional Neural Network(CNN), which is part of artificial intelligence, has proven successful in solving image problems and is very well used in medical image analysis. CNN works well on large datasets, but it will affectnetwork performance to overfitting in fewer datasets. So to solve the problem of small data, data augmentation techniques can be used. There are various kinds of data augmentation techniques. This study used the CNN method to classify diabetic retinopathy disease, compared several suitable data augmentation techniques for retinal fundus images, and used Contrast Limited Adaptive Histogram Equalization (CLAHE) for image enhancement. This study found that the augmented random zoom technique, together with CLAHE, provided the best accuracy of 98% with 96% sensitivity and 100% specificity. © 2020 IEEE.",Contrast Limited Adaptive Histogram Equalization; Convolutional Neural Network; Data Augmentation; Diabetic Retinopathy
Conference Paper,"Rahhal D., Alhamouri R., Albataineh I., Duwairi R.",Detection and Classification of Diabetic Retinopathy Using Artificial Intelligence Algorithms,"2022 13th International Conference on Information and Communication Systems, ICICS 2022",2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85135044847&doi=10.1109%2fICICS55353.2022.9811197&partnerID=40&md5=134d6901a145a60b5ee387ab6af95ed1,"Diabetic Retinopathy (DR) is considered as a sight-threatening complication of diabetes mellitus, the primary cause of blindness among working-age individuals. Ophthalmologists use fundus images to diagnose diabetic retinopathy and measure its severity by observing retinal lesions with high accuracy. However, diagnosing DR manually from fundus images requires a high level of expertise and effort from professional ophthalmologists. Early diagnosis of diabetes helps in saving the patient's eye and preventing possible risky complications. In this context, the current paper proposed a model aims to detect DR using image processing and deep learning methods. A fully automatic diagnosis system that exceeds manual techniques to avoid misdiagnosis, reducing time, effort and cost were presented through this paper. A publicly available dataset of fundus images was used to apply the current paper's proposed neural network model and transfer learning models, to classify each image into one of the five diabetic retinopathy stages. The simple proposed model achieved an accuracy of 66.68% in predicting the right label of the image. On the other hand, the second approach of fine-tuning the pre-trained models achieved higher testing accuracy (ranging from 93.13% to 100%,), which exceeds the current state-of-the-art results. © 2022 IEEE.",Classification; CNN; Deep Learning; Diabetic Retinopathy; Fundus; Transfer Learning
Conference Paper,"Bootwala A., Breininger K., Maier A., Christlein V.",Assistive diagnosis in opthalmology using deep learning-based image retrieval,Informatik aktuell,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85083075697&doi=10.1007%2f978-3-658-29267-6_30&partnerID=40&md5=a234d44d52d7a5a6aa078e065cc87485,"Image-based diagnosis of the human eye is crucial for the early detection of several diseases in ophthalmology. In this work, we investigate the possibility to use image retrieval to support the diagnosis of diabetic retinopathy. To this end, we evaluate different feature learning techniques. In particular, we evaluate the performance of cost functions specialized for metric learning, namely, contrastive loss, triplet loss and histogram loss, and compare them with the classification crossentropy loss. Additionally, we train the network on images graded by diabetic retinopathy severity and transfer the knowledge learned, to retrieve images that are graded by diabetic macular edema severity and evaluate our algorithm on three different datasets. For the task of detecting referable/non-referable diabetic retinopathy, we achieve a sensitivity of 0.84 and specificity of 0.88 on the Kaggle dataset using histogram loss. On the Messidor dataset, we achieve a sensitivity and specificity score of 0.79 and 0.84, respectively. © Springer Fachmedien Wiesbaden GmbH, ein Teil von Springer Nature 2020.",Cost functions; Diagnosis; Eye protection; Graphic methods; Image retrieval; Cross entropy; Diabetic retinopathy; Feature learning; Image-based diagnosis; Macular edema; Metric learning; Opthalmology; Sensitivity and specificity; Deep learning
Article,"Saini M., Susan S.",Diabetic retinopathy screening using deep learning for multi-class imbalanced datasets,Computers in Biology and Medicine,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85136527802&doi=10.1016%2fj.compbiomed.2022.105989&partnerID=40&md5=af4eaf0d81ceb0984665fc022797ff29,"Screening and diagnosis of diabetic retinopathy disease is a well known problem in the biomedical domain. The use of medical imagery from a patient's eye for detecting the damage caused to blood vessels is a part of the computer-aided diagnosis that has immensely progressed over the past few years due to the advent and success of deep learning. The challenges related to imbalanced datasets, inconsistent annotations, less number of sample images and inappropriate performance evaluation metrics has caused an adverse impact on the performance of the deep learning models. In order to tackle the effect caused by class imbalance, we have done extensive comparative analysis between various state-of-the-art methods on three benchmark datasets of diabetic retinopathy: - Kaggle DR detection, IDRiD and DDR, for classification, object detection and segmentation tasks. This research could serve as a concrete baseline for future research in this field to find appropriate approaches and deep learning architectures for imbalanced datasets. © 2022 Elsevier Ltd",Deep learning; Diabetic retinopathy; Image classification; Object detection; Segmentation; Transfer learning
Conference Paper,Zhang Z.,Deep-Learning-Based Early Detection of Diabetic Retinopathy on Fundus Photography Using EfficientNet,ACM International Conference Proceeding Series,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85086502623&doi=10.1145%2f3390557.3394303&partnerID=40&md5=666467c0d855c0d893eccc91f6539147,"Diabetic retinopathy, which is the leading cause of blindness among working aged adults, is a serious health problem worldwide. As millions of people suffer from diabetic retinopathy, the need for an automated method of diabetic retinopathy detection to prevent lifelong blindness has long been recognized. Therefore, it's a key challenge to build an automated diagnosis system to detect such disease early and efficiently. For that purpose, we propose a deep-learning-based method to early detect diabetic retinopathy on fundus photography in this paper. The dataset of fundus images is provided by Aravind Eye Hospital in India through a featured competition on the Kaggle platform. Deep convolutional neural networks based on EfficientNet-B3 are utilized to simultaneously extract features from fundus images, where the severity level of diabetic retinopathy is subsequently identified through a regression method. The results show that our deep learning model can achieve an expert-level performance on diagnosing the severity level of diabetic retinopathy, with a quadratic weighted kappa score 0.935 on the private dataset. Such performance locates at the top 1% among all teams and can get a gold medal prize in the Kaggle competition. © 2020 ACM.",Computer vision; Deep learning; Diabetic retinopathy; EfficientNet; Various applications
Article,"Shorfuzzaman M., Hossain M.S., El Saddik A.",An explainable deep learning ensemble model for robust diagnosis of diabetic retinopathy grading,"ACM Transactions on Multimedia Computing, Communications and Applications",2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85122078299&doi=10.1145%2f3469841&partnerID=40&md5=8b32e8096812829db91b2121069d5ed4,"Diabetic retinopathy (DR) is one of the most common causes of vision loss in people who have diabetes for a prolonged period. Convolutional neural networks (CNNs) have become increasingly popular for computer-aided DR diagnosis using retinal fundus images. While these CNNs are highly reliable, their lack of sufficient explainability prevents them from being widely used in medical practice. In this article, we propose a novel explainable deep learning ensemble model where weights from different models are fused into a single model to extract salient features from various retinal lesions found on fundus images. The extracted features are then fed to a custom classifier for the final diagnosis of DR severity level. The model is trained on an APTOS dataset containing retinal fundus images of various DR grades using a cyclical learning rates strategy with an automatic learning rate finder for decaying the learning rate to improve model accuracy. We develop an explainability approach by leveraging gradient-weighted class activation mapping and shapely adaptive explanations to highlight the areas of fundus images that are most indicative of different DR stages. This allows ophthalmologists to view our model's decision in a way that they can understand. Evaluation results using three different datasets (APTOS, MESSIDOR, IDRiD) show the effectiveness of our model, achieving superior classification rates with a high degree of precision (0.970), sensitivity (0.980), and AUC (0.978). We believe that the proposed model, which jointly offers state-of-the-art diagnosis performance and explainability, will address the black-box nature of deep CNN models in robust detection of DR grading. © 2021 Association for Computing Machinery.",Diabetic retinopathy diagnosis; Ensemble model; Explainable deep CNN; Retinal fundus images; Transfer learning
Conference Paper,"Rodriguez-Leon C., Arevalo W., Banos O., Villalonga C.",Deep Learning for Diabetic Retinopathy Prediction,Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85115147446&doi=10.1007%2f978-3-030-85030-2_44&partnerID=40&md5=a0ecb28031ecb491bde70455a70aaca5,"Diabetic retinopathy is a complication of diabetes mellitus. Its early diagnosis can prevent its progression and avoid the development of other major complications such as blindness. Deep learning and transfer learning appear in this context as powerful tools to aid in diagnosing this condition. The present work proposes to experiment with different models of pre-trained convolutional neural networks to determine which one fits best the problem of predicting diabetic retinopathy. The Diabetic Retinopathy Detection dataset supported by the EyePACS competition is used for evaluation. Seven pre-trained CNN models implemented in the Keras library developed in Python and, in this case, executed in the Kaggle platform, are used. Results show that no architecture performs better in all evaluation metrics. From a balanced behaviour perspective, the MobileNetV2 model stands out, with execution times almost half that of the slowest CNNs and without falling into overfitting with 20 learning epochs. InceptionResNetV2 stands out from the perspective of best performance, with a Kappa coefficient of 0.7588. © 2021, Springer Nature Switzerland AG.",Deep learning; Diabetic retinopathy; Transfer learning
Conference Paper,"Islam K.T., Wijewickrema S., O'Leary S.",Identifying diabetic retinopathy from OCT images using deep transfer learning with artificial neural networks,Proceedings - IEEE Symposium on Computer-Based Medical Systems,2019,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85070964197&doi=10.1109%2fCBMS.2019.00066&partnerID=40&md5=b0d487ded641d679a89fdba6fad0da36,"Diabetic retinopathy occurs when the blood vessels inside the retina are damaged as a result of diabetes. Early diagnosis and treatment of this disease is crucial to avoid blindness. Analysis of retinal images such as funduscopy, ultrasonography, and optical coherence tomography (OCT) is typically used in the diagnosis of diabetic retinopathy. In recent years, various automated techniques including deep learning have been used for this purpose. In this paper, we explore how to use deep transfer learning for the diagnosis of diabetic retinopathy using OCT images. We retrain existing deep learning models for this task and investigate how a retrained model can be optimized. We demonstrate that using an optimized pre-trained model as a feature extractor and training a conventional classifier on these features is an effective way to diagnose diabetic retinopathy using OCT images. We show through experiments that the proposed method outperforms similar existing methods with respect to accuracy and training time. © 2019 IEEE.",Artificial Neural Networks; Deep Learning; Diabetic Retinopathy; Feature Extraction; OCT Image; Transfer Learning
Conference Paper,"Chen H., Cao P.",Deep Learning Based Data Augmentation and Classification for Limited Medical Data Learning,"2019 IEEE International Conference on Power, Intelligent Computing and Systems, ICPICS 2019",2019,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85077955687&doi=10.1109%2fICPICS47731.2019.8942411&partnerID=40&md5=a3a5d6a5efce21665965749f5a5ab3cd,"Deep learning methods, especially convolutional neural network (CNN), which have made breakthroughs in many fields of computer vision, and one of the most prominent features of deep learning is that large-scale dataset with annotations should be used. However, obtaining such a dataset in the medical field is really a challenge due to scarcity of annotated data. In our work, a deep learning based framework is proposed to generate more real data from the existing data with Generative Adversarial Networks (GAN) and classify the suspicious lesions with CNN. The proposed method is applied on the diagnosis of diabetic retinopathy. The experimental results show that our deep learning framework achieve a better classification performance than the traditional deep learning methods. © 2019 IEEE.",Convolution neural networks; data augmentation; deep learning; diabetic retinopathy; generative adversarial networks; lesion classification
Article,"Das D., Biswas S.K., Bandyopadhyay S.",A critical review on diagnosis of diabetic retinopathy using machine learning and deep learning,Multimedia Tools and Applications,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85126831908&doi=10.1007%2fs11042-022-12642-4&partnerID=40&md5=9c0f3a8c3da1359c2793fbda76870515,"Diabetic Retinopathy (DR) is a health condition caused due to Diabetes Mellitus (DM). It causes vision problems and blindness due to disfigurement of human retina. According to statistics, 80% of diabetes patients battling from long diabetic period of 15 to 20 years, suffer from DR. Hence, it has become a dangerous threat to the health and life of people. To overcome DR, manual diagnosis of the disease is feasible but overwhelming and cumbersome at the same time and hence requires a revolutionary method. Thus, such a health condition necessitates primary recognition and diagnosis to prevent DR from developing into severe stages and prevent blindness. Innumerable Machine Learning (ML) models are proposed by researchers across the globe, to achieve this purpose. Various feature extraction techniques are proposed for extraction of DR features for early detection. However, traditional ML models have shown either meagre generalization throughout feature extraction and classification for deploying smaller datasets or consumes more of training time causing inefficiency in prediction while using larger datasets. Hence Deep Learning (DL), a new domain of ML, is introduced. DL models can handle a smaller dataset with help of efficient data processing techniques. However, they generally incorporate larger datasets for their deep architectures to enhance performance in feature extraction and image classification. This paper gives a detailed review on DR, its features, causes, ML models, state-of-the-art DL models, challenges, comparisons and future directions, for early detection of DR. © 2022, The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature.",Deep learning; Diabetic retinopathy; Feature extraction; Image processing; Machine learning; Retinal lesions
Article,"Alfian G., Syafrudin M., Fitriyani N.L., Anshari M., Stasa P., Svub J., Rhee J.",Deep neural network for predicting diabetic retinopathy from risk factors,Mathematics,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85091360487&doi=10.3390%2fmath8091620&partnerID=40&md5=dfa90eb871bbe1265703388f63d45fc7,"Extracting information from individual risk factors provides an effective way to identify diabetes risk and associated complications, such as retinopathy, at an early stage. Deep learning and machine learning algorithms are being utilized to extract information from individual risk factors to improve early-stage diagnosis. This study proposes a deep neural network (DNN) combined with recursive feature elimination (RFE) to provide early prediction of diabetic retinopathy (DR) based on individual risk factors. The proposed model uses RFE to remove irrelevant features and DNN to classify the diseases. A publicly available dataset was utilized to predict DR during initial stages, for the proposed and several current best-practice models. The proposed model achieved 82.033% prediction accuracy, which was a significantly better performance than the current models. Thus, important risk factors for retinopathy can be successfully extracted using RFE. In addition, to evaluate the proposed prediction model robustness and generalization, we compared it with other machine learning models and datasets (nephropathy and hypertension-diabetes). The proposed prediction model will help improve early-stage retinopathy diagnosis based on individual risk factors. © 2020 by the authors.",Deep learning; Deep neural network; Machine learning; Recursive feature elimination; Retinopathy; Risk factor
Conference Paper,"Jancy P.L., Latha B.",Deep Learning Techniques for Diabetic Retinopathy Diagnosis using Optical Coherence Tomography: A Review,"2022 International Conference on Advanced Computing Technologies and Applications, ICACTA 2022",2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85129201776&doi=10.1109%2fICACTA54488.2022.9753418&partnerID=40&md5=9ce0e7b08a1cf7edb71e543b91ad29f6,"Diabetic Retinopathy is an eye disease that prevails among patients suffering from diabetic mellitus. Due to high glucose level in blood, the retina of the eye gets affected. Diabetic Retinopathy cause vision loss if left undiagnosed. Regular annual inspection is required for the Diabetic patients to prevent the disease. Optical Coherence Tomography, an non-invasive imaging modality that captures retina with high resolution. Deep learning Algorithms are showing successful solutions regarding medical images examinations. This paper reviews the deep learning methods used for the detection of Diabetic Retinopathy based on Optical Coherence Tomography for past four years. The segmentation of Optical Coherence Tomography images into retinal layer using deep learning methods are also reviewed. The features used for Diabetic Retinopathy classification are also reviewed. © 2022 IEEE.",Deep learning applications; Diabetic Mellitus; Diabetic Retinopathy; Optical Coherence Tomography; Retinal layer and fluid segmentation
Conference Paper,"Metan A.C., Lambert A., Pickering M.",Small Scale Feature Propagation Using Deep Residual Learning for Diabetic Retinopathy Classification,"2019 IEEE 4th International Conference on Image, Vision and Computing, ICIVC 2019",2019,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85084303719&doi=10.1109%2fICIVC47709.2019.8981096&partnerID=40&md5=86c489012ae8d4ed2bef12a8a78fa1f5,"Automated diagnosis of diabetic retinopathy from fundus images involves detecting both small- and large-scale lesions, which makes this a difficult task for deep learning applications. In this paper we investigate the effects of small scale feature propagation for improving diabetic retinopathy classification. To accomplish this, we have utilized a publicly available dataset with 88,702 images, which contains unbalanced number of examples for different classes. A linear equation for class-specific gradient weighting has been proposed and has found to be beneficial. Three different residual architectures with residual and skip connections have been tested and their efficacy for this task is examined. The residual connections have been verified to improve the results for detecting small scale features for deep architectures. Skip connections within the current experimental setting have been found to be detrimental for the overall performance, potential solutions and their resulting effects have been discussed. © 2019 IEEE.",convolutional neural networks; diabetic retinopathy; fundus photography; residual networks; small scale features
Article,"Errabih A., Boussarhane M., Nsiri B., Sadiq A., El Yousfi Alaoui M.H., Thami R.O.H., Benaji B.",Identifying Retinal Diseases on OCT Image Based on Deep Learning,International journal of online and biomedical engineering,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85144724150&doi=10.3991%2fijoe.v18i15.33639&partnerID=40&md5=a7eb0470f430998c9d1aae5c11d204ce,"Computer-aided diagnosis has the potential to replace or at least support medical personnel in their everyday responsibilities, such as diagnosis, therapy, and surgery. In the area of ophthalmology, artificial intelligence approaches have been incorporated in the diagnosis of the most frequent ocular disorders, namely choroidal neovascularization (CNV), diabetic macular edema (DMO), and DRUSEN; these illnesses pose a significant risk of vision loss. Optical coherence tomography (OCT) is an imaging technology used to diagnose the aforementioned eye disorders. It enables ophthalmologists to see the back of the eye and take various slices of the retina. The present research seeks to automate the diagnosis of retinopathy, which includes CNV, DME, and DRUSEN. The approach employed is a deep learning-based, and transfer learning technique, applying to a public dataset of OCT pictures and two pertained neural network models VGG16 and InceptionV3, which are trained on the big database “ImageNET.” That allows them to be able to extract the main features of millions of images. Furthermore, fine-tuning approaches are applied to outperform the feature extraction method, by modifying the hyperparameters. The findings showed that the VGG16 model performed better in classification than the InceptionV3 architecture, with a 0.93 accuracy. © 2022,International journal of online and biomedical engineering.All Rights Reserved.",Artificial intelligence; Choroidal neovascularization; Convolutional neural network; Deep learning; Diabetic macular edema; Drusen; Optical coherence tomography; Transfer learning
Conference Paper,"Shreyas M.D., Asha Rani K.P., Gowrishankar S.",A Study on Machine Learning Based Diabetic Retinopathy,"5th International Conference on Inventive Computation Technologies, ICICT 2022 - Proceedings",2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137319141&doi=10.1109%2fICICT54344.2022.9850729&partnerID=40&md5=e88e7c053f98a5faa49182a43375437f,"Diabetic Retinopathy (DR), one of the main causes of blindness in the eyes, is curable in its early stages. The first indicators are red lesions, which include both micro aneurysms (MAs) and hemorrhages (HEs). Diabetic Retinopathy diagnosis by color fundus images is challenging and time-consuming as it takes trained doctors to recognize the presence and significance of many characteristics, as well as a complex classification method. Even though various Machine Learning based automatic Diabetic Retinopathy diagnosis approaches exist, they are still unable to offer point-of-care diagnosis, which would allow one to upload an input image, segment the retinal blood vessels, examine each vessel's expansion, and provide accurate result. Machine Learning and Deep Learning techniques have swiftly gained traction to understand medical images with promising results. Machine Learning can quantify and get more accurate results for the challenges mentioned above, as well as calculate the severity level of the given input eye image as an accuracy rate or predict Diabetic Retinopathy through feature extraction. In this research, a study is conducted to aid in the development of better Diabetic Retinopathy based models, with the aim of enhancing the detection accuracy of Diabetic Retinopathy by evaluating existing Machine Learning models and mobile applications with multiple datasets. © 2022 IEEE.",Deep Learning(DL); Diabetic Retinopathy (DR); Image Processing; Machine Learning(ML); Mobile Systems; Survey
Conference Paper,"Han Y., Tao M., Zheng X.",Ensembling Learning for Automated Detection of Diabetic Retinopathy,Lecture Notes in Electrical Engineering,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85115169282&doi=10.1007%2f978-981-16-3880-0_4&partnerID=40&md5=06f078a3770f53e4aa77092e2c0d6c4f,"It is widely known that diabetic retinopathy has become the main cause of irreversible vision loss among the working-age population world-widely. For clinical treatment, early and accurate identification of diabetic retinopathy using fundus image is a high-priority step, as early detection of diabetic retinopathy occurrence can be very helpful to prevent vision loss. Previous attempts for the detection task are based on the handcrafted-feature extraction and shallow architecture-based classifier (such as random forest, support vector machine). Recently, deep convolutional neural network (CNN) was successfully applied for the classification task. Despite sustainable efforts have been made, the task is still short of accuracy and time-consuming. In this paper, we propose an ensemble learning framework with the goal to improve the detection performance, using both handcrafted features and deep learning approaches. By leveraging the complementary information provided by handcrafted features and deep learning approaches, the ensemble learning framework is endowed with more discriminative power. Extensive experiments are conducted on the benchmark dataset, and the proposed framework provides superior performance, which demonstrated the effectiveness of proposed method. © 2022, The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd.",Convolutional neural network; Deep learning; Ensemble learning; Medical image classification
Conference Paper,"Pathak K.C., Shah R.B., Tharakan R.R., Patel B.N., Jariwala D.C.",Diabetic retinopathy diagnosis and categorization using deep learning - A review,"Proceedings - 5th International Conference on Intelligent Computing and Control Systems, ICICCS 2021",2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85107542339&doi=10.1109%2fICICCS51141.2021.9432312&partnerID=40&md5=d421f198ac9520fa53efed101af936ed,"Diabetic Retinopathy (DR), the foremost root which leads to blindness is found among working-age adults. It is caused due to diabetes that affects human eye. When such a disease is detected, then at first it does not show any symptoms or shows only mild symptoms. Gradually, it leads to blindness. There are various symptoms of DR. They may include: fluctuating vision, blurred vision, spots floating in your vision, vision loss, empty areas in vision, impaired color vision. It is critical to detect this condition in its early stage for good diagnosis. In fact, earliest stage was unable to help in diagnosing of normal eye sight. Hence, requirement of finding a DR as early as possible increased which would prevent visual impairment for patients having elongated diabetes although one is suffering from young. Microaneurysms, exudates, neovascularization and hemorrhages all these parameters decide the acuteness of DR. DR is categorized in to five stages such as normal, mild, moderate, severe Non proliferative (NPDR) or Proliferative diabetic retinopathy patient (PDR). We aim to categorize early-stage DR for better clinical benefits with more useful means. In this project we aim to use Deep Learning algorithm. This paper comprises of analysis and evaluation of the different techniques of DR diagnosis and categorization using retinal images was regulated. Accordingly, 14 research papers were studied and analyzed to provide an examination related to extracted features, classification accuracy, and the usage of different data sets, such as Indian Diabetic Retinopathy Image Dataset (IDRiD), High-Resolution Fundus (HRF) Image Database, Kaggle dataset. IDRiD is an Indian dataset which is the first retinal database representative. It is the mixture of normal retinal dataset and diabetic retinopathy retinal eye image. All in all to show different issues and to provide results that can be helpful for researchers to obtain further research on diabetic retinopathy diagnosis and categorization. © 2021 IEEE.",Classification; CNN; Deep learning; Detection; Diabetic; Glaucoma; Retinopathy
Article,"Gupta K., Reddy S.","Heart, Eye, and Artificial Intelligence: A Review",Cardiology Research,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85109977534&doi=10.14740%2fcr1179&partnerID=40&md5=e94781961bfe46d2a9cef2767a399ffb,"Heart disease continues to be the leading cause of death in the USA. Deep learning-based artificial intelligence (AI) methods have become increasingly common in studying the various factors involved in cardiovascular disease. The usage of retinal scanning techniques to diagnose retinal diseases, such as diabetic retinopathy, age-related macular degeneration, glaucoma and others, using fundus photographs and optical coherence tomography angiography (OCTA) has been extensively documented. Researchers are now looking to combine the power of AI with the non-invasive ease of retinal scanning to examine the workings of the heart and predict changes in the macrovasculature based on microvascular features and function. In this review, we summarize the current state of the field in using retinal imaging to diagnose cardiovascular issues and other diseases. Articles © The authors | Journal compilation © Cardiol Res and Elmer Press Inc™ | www.cardiologyres.org",Cardiovascular disease; Deep learning; Retinal imaging
Conference Paper,Taspinar Y.S.,Diabetic Rethinopathy Phase Identification with Deep Features,"2022 11th Mediterranean Conference on Embedded Computing, MECO 2022",2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85133969732&doi=10.1109%2fMECO55406.2022.9797136&partnerID=40&md5=fdadc783febf070c01a21cf2200151ba,"One of the most prevalent diabetes symptoms is diabetic retinopathy. Pain is one of the most common causes of vision loss. Years of research have gone into finding a way to diagnose and treat this condition early. In this study (DR) Diabetic Rethinopathy dataset containing 35,126 images was used. The dataset includes 5 classes. Each class represents the diabetic retinopathy stage. For example, 0 was determined as no diagnosis, 4 as the last stage. The pre-trained SqueezeNet model was used to extract image features. 1000 features obtained for each image are given as input to the Logistic Regression (LR) and k-Nearest Neighbor (kNN) machine learning models. As a result of the classifications made with LR and kNN models, 74.4% classification accuracy was obtained from the LR model and 72.2 % from the kNN model. The F -1 Score, Precision, and Recall measures were used to assess the models' performance. ROC curve and The learning levels of the models were assessed using AUC values. © 2022 IEEE.",classification; deep features; Diabetic retinopathy; early detection; transfer learning
Conference Paper,"Kaya E., Saritas I.",Performances of CNN Architectures on Diabetic Retinopathy Detection Using Transfer Learning,"2022 57th International Scientific Conference on Information, Communication and Energy Systems and Technologies, ICEST 2022",2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85136109562&doi=10.1109%2fICEST55168.2022.9828576&partnerID=40&md5=5f0ef37d3924368b9c5ffc57a770b580,"Deep Learning (DL) methods have become popular because they automatically extract and learn features without other feature extraction algorithms. Diabetic Retinopathy (DR) is a disease that is solely determined by blood vessel segmentation, but the diagnosis can differ from person to person. Thus, deep learning can simplify and improve the process of diagnosing DR. In this study, known Convolutional Neural Network (CNN) architectures were used as a transfer learning method to classify DRIVE dataset images of DR patients and healthy individuals to determine the most efficient architecture. In this study, CNN architectures were used both as classifiers and feature extraction methods. The most efficient CNN architecture was found to be ResNet18 with 100.0% accuracy when the classification was realized with ResNet18 itself and ANN which uses the activations of ResNet18 as features. © 2022 IEEE.",CNN; Deep Learning; Diabetic Retinopathy; Transfer Learning
Conference Paper,"Das D., Biswas S.K., Bandyopadhyay S., Laskar R.H.",Deep learning techniques for early detection of diabetic retinopathy: Recent developments and techniques,"Proceedings of the 2020 International Conference on Computing, Communication and Security, ICCCS 2020",2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85098848142&doi=10.1109%2fICCCS49678.2020.9276781&partnerID=40&md5=ba7f4b4e128202f81144d7ba7d31b7fd,"Diabetic Retinopathy (DR) is a health disorder in human retina, caused as a result of Diabetes Mellitus (DM). It leads to loss of vision and in severe cases it results in blindness, as a result of mutilation of the retina. Statistical data estimates that 80% of diabetic patients, suffering from prolonged diabetes, also suffer from DR. Hence, in the present time DR has become an imperative matter and requires primary stage evaluation and assessment such that loss of vision and blindness can be averted. However, the physical diagnosis of the disease is laborious and susceptible to error. Besides, the convenience of availing Ophthalmologist irrespective of place and time, is not possible. Thus, the necessity of an exceedingly enhanced and computerized intelligent system arises, that can be engaged for the initial stage detection of DR. A number of Machine Learning models are proposed by researchers since decades, for the diagnosis of DR. Various feature extraction techniques are also proposed for deriving prominent retinal lesions, for initial stage diagnosis of DR. However, traditional Machine Learning models showcase poor generalization during feature extraction because of smaller datasets. This can be overcome through use of Deep Learning models, larger dataset and high computing processing units for generalization. This paper aims to give an overview about DR, a brief description of the earlier works, and the current automated systems and advancements, for the purpose of early detection of DR. This paper also focuses on the state-of-the-art DR lesions, origin and signs of DR, categories of DR and state-of-the-art Deep Learning models, that are proposed and applied for DR detection, at the preliminary stage. © 2020 IEEE.",Deep Learning; Diabetic Macular Edema; Diabetic Retinopathy; Image Processing; Retinal Lesions
Article,"Bhardwaj P., Gupta P., Guhan T., Srinivasan K.",Early Diagnosis of Retinal Blood Vessel Damage via Deep Learning-Powered Collective Intelligence Models,Computational and Mathematical Methods in Medicine,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85133280289&doi=10.1155%2f2022%2f3571364&partnerID=40&md5=59c885027cbf72382e1ecfbb27c17163,"Early diagnosis of retinal diseases such as diabetic retinopathy has had the attention of many researchers. Deep learning through the introduction of convolutional neural networks has become a prominent solution for image-related tasks such as classification and segmentation. Most tasks in image classification are handled by deep CNNs pretrained and evaluated on imagenet dataset. However, these models do not always translate to the best result on other datasets. Devising a neural network manually from scratch based on heuristics may not lead to an optimal model as there are numerous hyperparameters in play. In this paper, we use two nature-inspired swarm algorithms: particle swarm optimization (PSO) and ant colony optimization (ACO) to obtain TDCN models to perform classification of fundus images into severity classes. The power of swarm algorithms is used to search for various combinations of convolutional, pooling, and normalization layers to provide the best model for the task. It is observed that TDCN-PSO outperforms imagenet models and existing literature, while TDCN-ACO achieves faster architecture search. The best TDCN model achieves an accuracy of 90.3%, AUC ROC of 0.956, and a Cohen's kappa score of 0.967. The results were compared with the previous studies to show that the proposed TDCN models exhibit superior performance. © 2022 Pranjal Bhardwaj et al.","Ant colony optimization; Biomimetics; Blood vessels; Convolution; Convolutional neural networks; Deep learning; Diagnosis; Eye protection; Image classification; Image segmentation; Ophthalmology; Particle swarm optimization (PSO); Collective intelligences; Diabetic retinopathy; Early diagnosis; Intelligence models; Particle swarm; Retinal blood vessels; Retinal disease; Swarm algorithms; Swarm optimization; Vessel damage; Classification (of information); ant colony optimization; area under the curve; Article; artificial intelligence; comparative study; controlled study; convolutional neural network; deep learning; deep learning powered collective intelligence model; diabetic retinopathy; diagnostic accuracy; diagnostic test accuracy study; disease severity; early diagnosis; eye fundus; false positive result; feature extraction; heuristics; human; image segmentation; particle swarm optimization; receiver operating characteristic; retina blood vessel; retinal vascular disease; swarm intelligence algorithm; transfer of learning; diagnostic imaging; early diagnosis; intelligence; retina blood vessel; Deep Learning; Early Diagnosis; Humans; Intelligence; Neural Networks, Computer; Retinal Vessels"
Conference Paper,"Mohamed E., Elmohsen M.A., Basha T.",Improved Automatic Grading of Diabetic Retinopathy Using Deep Learning and Principal Component Analysis,"Proceedings of the Annual International Conference of the IEEE Engineering in Medicine and Biology Society, EMBS",2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85122491030&doi=10.1109%2fEMBC46164.2021.9630919&partnerID=40&md5=6a37c3721bbc91e0cec8c0b56c2c6918,"Diabetic retinopathy (DR) is one of the most common chronic diseases around the world. Early screening and diagnosis of DR patients through retinal fundus is always preferred. However, image screening and diagnosis is a highly time-consuming task for clinicians. So, there is a high need for automatic diagnosis. The objective of our study is to develop and validate a new automated deep learning-based approach for diabetic retinopathy multi-class detection and classification. In this study we evaluate the contribution of the DR features in each color channel then we pick the most significant channels and calculate their principal components (PCA) which are then fed to the deep learning model, and the grading decision is decided based on a majority voting scheme applied to the out of the deep learning model. The developed models were trained on a publicly available dataset with around 80K color fundus images and were tested on our local dataset with around 100 images. Our results show a significant improvement in DR multi-class classification with 85% accuracy, 89% sensitivity, and 96% specificity. © 2021 IEEE.",Classification (of information); Deep learning; Diagnosis; Grading; Principal component analysis; Automatic diagnosis; Automatic grading; Chronic disease; Color channels; Diabetic retinopathy; Learning models; Learning-based approach; Principal Components; Principal-component analysis; Time-consuming tasks; Eye protection; diabetes mellitus; diabetic retinopathy; eye fundus; human; mass screening; principal component analysis; Deep Learning; Diabetes Mellitus; Diabetic Retinopathy; Fundus Oculi; Humans; Mass Screening; Principal Component Analysis
Conference Paper,"Krishnan A.S., Clive D.R., Bhat V., Ramteke P.B., Koolagudi S.G.",A Transfer Learning Approach for Diabetic Retinopathy Classification Using Deep Convolutional Neural Networks,INDICON 2018 - 15th IEEE India Council International Conference,2018,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85082567834&doi=10.1109%2fINDICON45594.2018.8987131&partnerID=40&md5=d16ad6634cf16f1ec929b6a7ac7442ce,"Diabetic Retinopathy is a disease in which the retina is damaged due to diabetes mellitus. It is a leading cause for blindness today. Detection and quantification of such mellitus from retinal images is tedious and requires expertise. In this paper, an automatic identification of severity of Diabetic Retinopathy using Convolutional Neural Networks (CNNs) with a transfer learning approach has been proposed to aid the diagnostic process. A comparison of different CNN architectures such as ResNet, Inception-ResNet-v2 etc. is done using the quadratic weighted kappa metric. The qualitative and quantitative evaluation of the proposed approach is carried out on the Diabetic Retinopathy detection dataset from Kaggle. From the results, we observe that the proposed model achieves a kappa score of 0.76. © 2018 IEEE.",Convolutional Neural Networks; Deep learning; Diabetic Retinopathy; Image Classification; Inception-ResNet-v2
Conference Paper,"Goel N., Singh S.K.",Diabetic Retinopathy Image Analysis Using Deep Learning Techniques,"9th IEEE Uttar Pradesh Section International Conference on Electrical, Electronics and Computer Engineering, UPCON 2022",2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85146369622&doi=10.1109%2fUPCON56432.2022.9986469&partnerID=40&md5=4b575f09cd294a7755f49102598612e5,"In the whole world, one among the leading factors of blindness in the citizens is the diabetic retinopathy (DR). Detection of DR at an early stage can provide crucial assistance in managing with this disease. Deep learning (DL) has excelled in a variety of domains, particularly in the analysis of biomedical images. The diagnosis of DR is made by scanning retinal fundus images. We have done an empirical evaluation for the automatic detection of DR as part of our research. Convolutional Neural Networks (CNN) approach has been used in this research by using two of its architectures i.e. MobileNetV2 and DenseNet-201. For this research work, we have utilized the Indian Diabetic Retinopathy Dataset (IDRID) dataset, which is an online dataset available containing retinal fundus images of size 4288×2848. The outcomes of this research work shows that the DenseNet-201 model detects DR better than MobileNetV2 with the following metrics: accuracy, recall, precision and fl-score of 87.6%, 97.2%, 82.6%, and 88.4%, respectively are the most dependable findings from the DenseNet-201 model's case testing. © 2022 IEEE.",Deep Learning; DenseNet201; Diabetic Retinopathy; Fundus Image; MobileNetV2
Conference Paper,"Sazzad Hossen Md., Reza A.A., Mishu M.C.",An automated model using deep convolutional neural network for retinal image classification to detect diabetic retinopathy,ACM International Conference Proceeding Series,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123040041&doi=10.1145%2f3377049.3377067&partnerID=40&md5=a966b9e3df157aa7376a52fdb902401a,"Diabetic Retinopathy is considered as one of the significant reasons for vision impairment. Its identification involves detecting the presence of some features in retinal fundus images by clinicians which is a time and resource consuming procedure and a difficult manual diagnosis. In this article, a deep learning-based approach using Deep Convolutional Neural Network is developed for the diagnosis of Diabetic Retinopathy. By classifying from retinal fundus images with its severity level, it is possible to detect Diabetic Retinopathy. A Diabetic Retinopathy classifier is constructed followed by a transfer learning technique, DenseNet architecture based pre-trained model. Identification of Diabetic Retinopathy is done by detecting the presence of features like micro-aneurysms, exudates, hemorrhages in retinal images. We have also shown the preprocessing and augmentation of image data that benefits the model to detect retinopathy. After the training and validating procedure, the developed classifier achieves significant training accuracy of 96.3% and validation accuracy of 94.9% along with 0.88 quadratic weighted kappa. © 2020 Association for Computing Machinery.",Convolutional neural network; Deep learning; Diabetic retinopathy; Transfer learning
Article,"Thiagarajan A.S., Adikesavan J., Balachandran S., Ramamoorthy B.G.",Diabetic retinopathy detection using deep learning techniques,Journal of Computer Science,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85086867951&doi=10.3844%2fJCSSP.2020.305.313&partnerID=40&md5=2ae6782deffec69900829e6297874e12,"Diabetic Retinopathy is a type of eye condition induced by diabetes, which damages the blood vessels in the retinal region and the area covered with lesions of varying magnitude determines the severity of the disease. It is one of the most leading causes of blindness amongst the employed community. A variety of factors are observed to play a role in a person to get this disease. Stress and prolonged diabetes are two of the most critical factors to top the list. This disease, if not predicted early, can lead to a permanent impairment of vision. If predicted in advance, the rate of impairment can be brought down or averted. However, it is not easy to detect the presence of this disease, given the time-consuming and tedious process of diagnosis. Presently, digital color photographs are evaluated manually by trained clinicians to observe the presence of lesions caused due to vascular abnormalities, which is the major effect of Diabetic Retinopathy. This method, although it is pretty accurate, proves to be costly. The delay brings out the need to automate the diagnosing, which will, in turn, have a significant positive impact on the health sector. In recent times, the adoption of AI in disease diagnosis has ensured promising and reliable results and this serves as the motivation for this journal. The paper employs Deep learning methodologies for automatic detection of Diabetic Retinopathy, resulting in a maximum accuracy of 80%, as compared to traditional Machine learning approaches giving only a maximum accuracy of 48% on the same IRDiR Disease Grading Dataset (413 images with 5 levels of DR-Training set; 103 images with 5 levels of DR-Test set). The data set contains digital fundus images of different levels of Diabetic Retinopathy in discrete frequency distributions. © 2020 Aswin Shriram Thiagarajan, Jithendran Adikesavan.",Artificial intelligence; CNN; Deep learning; Diabetic retinopathy; Feature engineering
Article,"Wang J., Bai Y., Xia B.",Simultaneous Diagnosis of Severity and Features of Diabetic Retinopathy in Fundus Photography Using Deep Learning,IEEE Journal of Biomedical and Health Informatics,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097571593&doi=10.1109%2fJBHI.2020.3012547&partnerID=40&md5=2673e046aef0757a5dc62bbbb831a86d,"Deep learning methods for diabetic retinopathy (DR) diagnosis are usually criticized as being lack of interpretability in the diagnostic result, thus limiting their application in clinic. Simultaneous prediction of DR related features during the DR severity diagnosis is able to resolve this issue by providing supporting evidence (i.e. DR related features) for the diagnostic result (i.e. DR severity). In this study, we propose a hierarchical multi-task deep learning framework for simultaneous diagnosis of DR severity and DR related features in fundus images. A hierarchical structure is introduced to incorporate the casual relationship between DR related features and DR severity levels. In the experiments, the proposed approach was evaluated on two independent testing sets using quadratic weighted Cohen's kappa coefficient, receiver operating characteristic analysis, and precision-recall analysis. A grader study was also conducted to compare the performance of the proposed approach with those of general ophthalmologists with different levels of experience. The results demonstrate that the proposed approach could improve the performance for both DR severity diagnosis and DR related feature detection when comparing with the traditional deep learning-based methods. It achieves performance close to general ophthalmologists with five years of experience when diagnosing DR severity levels, and general ophthalmologists with ten years of experience for referable DR detection. © 2013 IEEE.",deep learning; Diabetic retinopathy (DR); DR related features; DR severity
Article,"Majumder S., Kehtarnavaz N.",Multitasking Deep Learning Model for Detection of Five Stages of Diabetic Retinopathy,IEEE Access,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85115235971&doi=10.1109%2fACCESS.2021.3109240&partnerID=40&md5=19d6cd60d4a75887fd0113585fa85203,"Early diagnosis and treatment of diabetic retinopathy (DR) can reduce the risk of vision loss. There are five stages of DR consisting of no DR, mild DR, moderate DR, severe DR, and proliferate DR. This paper presents a multitask deep learning model to detect all the five stages of DR more accurately than existing methods. The developed multitask model consists of one classification model and one regression model, each with its own loss function. After training the regression model and the classification model separately, the features extracted by these two models are concatenated and inputted to a multilayer perceptron network to classify the five stages of DR. A modified Squeeze Excitation Densely Connected deep neural network is also developed as part of this multitasking approach. The developed multitask model is applied to the two large Kaggle datasets of APTOS and EyePACS. The results obtained indicate that the developed multitask model achieved a weighted Kappa score of 0.90 and 0.88 for the APTOS and EyePACS datasets, respectively. In addition, the micro and macro average area under the receiver operating characteristic (ROC) curve was found to be 0.96, and 0.93, respectively, which are higher than existing methods for detecting the five stages of DR. © 2013 IEEE.",Diabetic retinopathy (DR); eye fundus images; five stages of diabetic retinopathy; multitasking deep neural network; squeeze excitation densely connected network
Article,"Lin P.-K., Chiu Y.-H., Huang C.-J., Wang C.-Y., Pan M.-L., Wang D.-W., Liao H.-Y.M., Chen Y.-S., Kuan C.-H., Lin S.-Y., Chen L.-F.",PADAr: physician-oriented artificial intelligence-facilitating diagnosis aid for retinal diseases,Journal of Medical Imaging,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85142181333&doi=10.1117%2f1.JMI.9.4.044501&partnerID=40&md5=8999ed10d7823346aa8f0c6c13f4e8c8,"Purpose: Retinopathy screening via digital imaging is promising for early detection and timely treatment, and tracking retinopathic abnormality over time can help to reveal the risk of disease progression. We developed an innovative physician-oriented artificial intelligence-facilitating diagnosis aid system for retinal diseases for screening multiple retinopathies and monitoring the regions of potential abnormality over time. Approach: Our dataset contains 4908 fundus images from 304 eyes with image-level annotations, including diabetic retinopathy, age-related macular degeneration, cellophane maculopathy, pathological myopia, and healthy control (HC). The screening model utilized a VGG-based feature extractor and multiple-binary convolutional neural network-based classifiers. Images in time series were aligned via affine transforms estimated through speeded-up robust features. Heatmaps of retinopathy were generated from the feature extractor using gradient-weighted class activation mapping++, and individual candidate retinopathy sites were identified from the heatmaps using clustering algorithm. Nested cross-validation with a train-to-test split of 80% to 20% was used to evaluate the performance of the screening model. Results: Our screening model achieved 99% accuracy, 93% sensitivity, and 97% specificity in discriminating between patients with retinopathy and HCs. For discriminating between types of retinopathy, our model achieved an averaged performance of 80% accuracy, 78% sensitivity, 94% specificity, 79% F1-score, and Cohen's kappa coefficient of 0.70. Moreover, visualization results were also shown to provide reasonable candidate sites of retinopathy. Conclusions: Our results demonstrated the capability of the proposed model for extracting diagnostic information of the abnormality and lesion locations, which allows clinicians to focus on patient-centered treatment and untangles the pathological plausibility hidden in deep learning models. © The Authors. Published by SPIE under a Creative Commons Attribution 4.0 International License. Distribution or reproduction of this work in whole or in part requires full attribution of the original publication, including its DOI.",computer-aided diagnosis; lesion-sites visualization; multi-retinopathy classification
Article,Canayaz M.,Classification of diabetic retinopathy with feature selection over deep features using nature-inspired wrapper methods,Applied Soft Computing,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85136575481&doi=10.1016%2fj.asoc.2022.109462&partnerID=40&md5=cb1a065bb13b2faa1b2dd8c2ec39d1e6,"Diabetic retinopathy (DR) is the most common cause of blindness in middle-aged people. It shows that an automatic image evaluation system is needed in the diagnosis of this disease due to the low number of scans. It is critical to meet this need that these systems are large-scale, cost-effective, and minimally invasive screening programs. With the use of deep learning techniques, it has become possible to develop these systems faster. In this study, a new approach based on feature selection with wrapper methods used for fundus images is presented that can be used for the classification of diabetic retinopathy. The fundus images used in the approach were improved with image processing techniques, thus eliminating unnecessary dark areas in the image. In this new approach, the most effective features are selected by wrapping methods over 512 deep features obtained from EfficientNet and DenseNet models. Binary Bat Algorithm (BBA), Equilibrium Optimizer (EO), Gravity Search Algorithm (GSA), and Gray Wolf Optimizer (GWO) were chosen as wrappers for the proposed approach. Selected features are classified by support vector machines and random forest machine learning methods. Considering the performance of this new approach, it gives the highest value of 96.32 accuracy and 0.98 kappa. These performance values were obtained with a minimum of 250 selected features. The Asia Pacific Tele-Ophthalmology Society (APTOS) dataset used to obtain these values was taken from a competition organized by Kaggle. The highest kappa value in this competition was reported as 0.93. This parameter clearly demonstrates the success of our approach. © 2022 Elsevier B.V.",Deep learning models; Diabetic retinopathy; Feature selection; Wrapper methods
Article,"Erciyas A., Barişçi N.",An Effective Method for Detecting and Classifying Diabetic Retinopathy Lesions Based on Deep Learning,Computational and Mathematical Methods in Medicine,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85108115052&doi=10.1155%2f2021%2f9928899&partnerID=40&md5=f620f8bd537a90af6cc9551d28503fdd,"Diabetic retinopathy occurs as a result of the harmful effects of diabetes on the eyes. Diabetic retinopathy is also a disease that should be diagnosed early. If not treated early, vision loss may occur. It is estimated that one third of more than half a million diabetic patients will have diabetic retinopathy by the 22nd century. Many effective methods have been proposed for disease detection with deep learning. In this study, unlike other studies, a deep learning-based method has been proposed in which diabetic retinopathy lesions are detected automatically and independently of datasets, and the detected lesions are classified. In the first stage of the proposed method, a data pool is created by collecting diabetic retinopathy data from different datasets. With Faster RCNN, lesions are detected, and the region of interests are marked. The images obtained in the second stage are classified using the transfer learning and attention mechanism. The method tested in Kaggle and MESSIDOR datasets reached 99.1% and 100% ACC and 99.9% and 100% AUC, respectively. When the obtained results are compared with other results in the literature, it is seen that more successful results are obtained. © 2021 Abdüssamed Erciyas and Necaattin Barişçi.","Eye protection; Learning systems; Transfer learning; Attention mechanisms; Diabetic patient; Diabetic retinopathy; Disease detection; Harmful effects; Learning-based methods; Region of interest; Vision loss; Deep learning; area under the curve; Article; attention; automation; deep learning; diabetic retinopathy; human; microaneurysm; transfer of learning; biology; classification; computer assisted diagnosis; diabetic retinopathy; diagnostic imaging; eye fundus; factual database; ophthalmoscopy; optic disk; procedures; receiver operating characteristic; Computational Biology; Databases, Factual; Deep Learning; Diabetic Retinopathy; Diagnosis, Computer-Assisted; Fundus Oculi; Humans; Image Interpretation, Computer-Assisted; Neural Networks, Computer; Ophthalmoscopy; Optic Disk; ROC Curve"
Conference Paper,"Gonçalves J., Conceição T., Soares F.",Inter-observer reliability in computer-aided diagnosis of diabetic retinopathy,"HEALTHINF 2019 - 12th International Conference on Health Informatics, Proceedings; Part of 12th International Joint Conference on Biomedical Engineering Systems and Technologies, BIOSTEC 2019",2019,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85064620028&doi=10.5220%2f0007580904810491&partnerID=40&md5=9b7db5894155941c0d3938d3c8a5ce8a,"The rapid growth of digital data in healthcare demands medical image analysis to be faster, precise and, at the same time, decentralized. Deep Learning (DL) fits well in this scenario, as there is an enormous data to sift through. Diabetic Retinopathy (DR) is one of the leading causes of blindness that can be avoided if detected in early stages. In this paper, we aim to compare the agreement of different machine learning models against the performance of highly trained ophthalmologists (human graders). Overall results show that transfer learning in the renowned CNNs has a strong agreement even in different datasets. This work also presents an objective comparison between classical feature-based approaches and DL for DR classification, specifically, the interpretability of these approaches. The results show that Inception-V3 CNN was indeed the best-tested model across all the performance metrics in distinct datasets, but with lack of interpretability. In particular, this model reaches the accuracy of 89% on the EyePACS dataset. © 2019 by SCITEPRESS - Science and Technology Publications, Lda. All rights reserved.",Convolution Neural Networks; Diabetic Retinopathy; Feature-based Machine Learning; Inter-observer Reliability
Conference Paper,"Kassani S.H., Kassani P.H., Khazaeinezhad R., Wesolowski M.J., Schneider K.A., Deters R.",Diabetic Retinopathy Classification Using a Modified Xception Architecture,"2019 IEEE 19th International Symposium on Signal Processing and Information Technology, ISSPIT 2019",2019,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85081349377&doi=10.1109%2fISSPIT47144.2019.9001846&partnerID=40&md5=91e4b235cd89daac9bf2c739b9ed404d,"Diabetic retinopathy (DR) is one of the major causes of blindness worldwide. With proper treatment, early diagnosis of DR can prevent the progression of the disease. In this paper, we present a new feature extraction method using a modified Xception architecture for the diagnosis of DR disease. The proposed method is based on deep layer aggregation that combines multilevel features from different convolutional layers of Xception architecture. The extracted features are subsequently fed into a multi-layer perceptron (MLP) to be trained for DR severity classification. The performance of the proposed approach was assessed with four deep feature extractors, including Inception V3, MobileNet, and ResNet50 and original Xception architecture. Compared with typical Xception architecture, the aggregation of deep CNN layers can effectively fuse deep features and improve the learning process. Additionally, a transfer learning strategy and hyper-parameter tuning are adopted to further improve the overall classification performance. The performance of the proposed model was validated on the Kaggle APTOS 2019 contest dataset. Experiments demonstrate that the modified Xception deep feature extractor improves DR classification with a classification accuracy of 83.09% versus 79.59%, sensitivity of 88.24% versus 82.35% and specificity of 87.00% versus 86.32% when compared with the original Xception architecture. © 2019 IEEE.",Computer-aided diagnosis; Convolutional neural network; Deep learning; Diabetic retinopathy; Transfer learning
Conference Paper,"Pedrosa M., Silva J.M., Matos S., Costa C.",SCREEN-DR: Software architecture for the diabetic retinopathy screening,Studies in Health Technology and Informatics,2018,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85046539905&doi=10.3233%2f978-1-61499-852-5-396&partnerID=40&md5=6431a91e3db3d08991bf7734ed15635f,"Diabetic Retinopathy (DR) is a common complication of diabetes that may lead to blindness if not treated. However, since DR evolves without any symptoms in the initial stages, early detection and treatment can only be achieved through routine checks. This article presents the collaborative platform of the SCREEN-DR project that promotes partnership between physicians and researchers in the scope of a regional DR screening program. The role of researchers is to create classification algorithms to evaluate image quality, discard non-pathological cases, locate possible lesions and grade DR severity. Physicians are responsible for annotating datasets, including the visual delineation of lesions. The collaborative platform collects the studies, indexes the images metadata, and manages the creation of datasets and the respective annotation process. An advanced searching mechanism supports multimodal queries over annotated datasets and exporting of results for feeding artificial intelligence algorithms. © 2018 European Federation for Medical Informatics (EFMI) and IOS Press.",Computer-aided diagnosis; Diabetic retinopathy; Image annotation
Article,"Govindaswamy N., Ratra D., Dalan D., Doralli S., Tirumalai A.A., Nagarajan R., Mochi T., Shetty N., Sinha Roy A.",Vascular changes precede tomographic changes in diabetic eyes without retinopathy and improve artificial intelligence diagnostics,Journal of Biophotonics,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85087305548&doi=10.1002%2fjbio.202000107&partnerID=40&md5=798d2ec238c641454b29d6e8f992ba76,"The purpose of this study was to evaluate early vascular and tomographic changes in the retina of diabetic patients using artificial intelligence (AI). The study included 74 age-matched normal eyes, 171 diabetic eyes without retinopathy (DWR) eyes and 69 mild non-proliferative diabetic retinopathy (NPDR) eyes. All patients underwent optical coherence tomography angiography (OCTA) imaging. Tomographic features (thickness and volume) were derived from the OCTA B-scans. These features were used in AI models. Both OCT and OCTA features showed significant differences between the groups (P <.05). However, the OCTA features indicated early retinal changes in DWR eyes better than OCT (P <.05). In the AI model using both OCT and OCTA features simultaneously, the best area under the curve of 0.91 ± 0.02 was obtained (P <.05). Thus, the combined use of AI, OCT and OCTA significantly improved the early diagnosis of diabetic changes in the retina. © 2020 WILEY-VCH Verlag GmbH & Co. KGaA, Weinheim",angiography; artificial intelligence; diabetic retinopathy; optical coherence tomography
Article,"Murugappan M., Prakash N.B., Jeya R., Mohanarathinam A., Hemalakshmi G.R., Mahmud M.",A novel few-shot classification framework for diabetic retinopathy detection and grading,Measurement: Journal of the International Measurement Confederation,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85134564361&doi=10.1016%2fj.measurement.2022.111485&partnerID=40&md5=fc7794de9b6eaa2b16a6dcd804ba7535,"Diabetes Retinopathy (DR) is a major microvascular complication of diabetes. Computer-Aided Diagnosis (CAD) tools for DR management are primarily developed using Artificial Intelligence (AI) methods, such as machine and deep learning algorithms. DR diagnostic tools have been developed in recent years using deep learning models. Thus, these models require large amounts of data for training. Consequently, these huge amounts of data are not balanced due to fewer cases in the dataset. To solve the problems associated with training models with small datasets, such as overfitting and poor approximation, this paper proposes a paradigm called Few-Shot Learning (FSL) which uses a relatively small amount of training data to train the models effectively. This paper proposes a novel prototype network, a type of FSL classification network capable of grading and detecting DR based on attention. The DRNet framework uses episodic learning to train its model on few-shot classification tasks. We developed a DRNet based on the APTOS2019 dataset for diabetic detection and grading. In the proposed network, aggregated transformations and gradient activations of classes are leveraged to design the attention mechanism to capture image representations. As a result, the system achieves 99.73 % accuracy, 99.82 % sensitivity, 99.63 % specificity in DR detection, 98.18 % accuracy, 97.41% sensitivity, and 99.55% specificity in DR grading. An analysis of objective performance metrics and model interpretation shows that the proposed model can detect DR more efficiently and grade the severity more accurately when using unseen fundus images than existing state-of-the-art methods. Therefore, this tool could help provide a second opinion to an ophthalmologist about the severity level of DR. © 2022 The Authors",Aggregated transformations; Class activation; Detection; Diabetic Retinopathy; Grading
Conference Paper,"Tymchenko B., Marchenko P., Spodarets D.",Deep learning approach to diabetic retinopathy detection,ICPRAM 2020 - Proceedings of the 9th International Conference on Pattern Recognition Applications and Methods,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85082986402&partnerID=40&md5=b9db9c3459f0825448ba389d3a075ed7,"Diabetic retinopathy is one of the most threatening complications of diabetes that leads to permanent blindness if left untreated. One of the essential challenges is early detection, which is very important for treatment success. Unfortunately, the exact identification of the diabetic retinopathy stage is notoriously tricky and requires expert human interpretation of fundus images. Simplification of the detection step is crucial and can help millions of people. Convolutional neural networks (CNN) have been successfully applied in many adjacent subjects, and for diagnosis of diabetic retinopathy itself. However, the high cost of big labeled datasets, as well as inconsistency between different doctors, impede the performance of these methods. In this paper, we propose an automatic deep-learning-based method for stage detection of diabetic retinopathy by single photography of the human fundus. Additionally, we propose the multistage approach to transfer learning, which makes use of similar datasets with different labeling. The presented method can be used as a screening method for early detection of diabetic retinopathy with sensitivity and specificity of 0.99 and is ranked 54 of 2943 competing methods (quadratic weighted kappa score of 0.925466) on APTOS 2019 Blindness Detection Dataset (13000 images). Copyright © 2020 by SCITEPRESS – Science and Technology Publications, Lda. All rights reserved",APTOS; Classification; Deep Convolutional Neural Network; Deep Learning; Diabetic Retinopathy; Kaggle; Multi-target Learning; Ordinal Regression; SHAP
Conference Paper,"Ramya N., Hemavathi D.",Detection Of Diabetic Retinal Pathogen Using Deep Learning,"IEEE International Conference on Data Science and Information System, ICDSIS 2022",2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85141481260&doi=10.1109%2fICDSIS55133.2022.9915991&partnerID=40&md5=b4b6d843cecdb41abbcb5e5282f877fb,"With Numerous changes in the current lifestyle of people, diabetes has become one of the most commonly occurring chronic diseases that lead to many other problems in the body in the long run. Most diabetic patients have the common problem of vision reduction, and joint pain and severe diabetic patients have liver problems, kidney problems, etc. Many pathological and clinical features are required to treat diabetics at a constant interval to maintain the limit and monitor the health of other organs. Diabetic Retinopathy is diabetic retinal pathogen that, if left untreated, might cause lifelong blindness. Diabetic Retinopathy disorder affects 60 % to 70 % of diabetic people with a prolonged diagnosis. Henceforth study of Diabetic Retinopathy and its impacts on diabetic patients is important. On the other hand studies of available methodologies to predict disease in early-stage are considered. The present study focused on a detailed evaluation and analysis of Diabetic Retinopathy with various existing methodologies, treatment procedures, algorithms, and research data available so far and to formulate a prediction model that could help the early prediction of Diabetic Retinopathy. © 2022 IEEE.",Convolutional Neural Network (CNN); Deep Learning(DL); Diabetic Retinopathy (DR); Generative Adversarial Networks (GAN); Segmentation; transfer learning
Conference Paper,"Harangi B., Toth J., Baran A., Hajdu A.",Automatic screening of fundus images using a combination of convolutional neural network and hand-crafted features,"Proceedings of the Annual International Conference of the IEEE Engineering in Medicine and Biology Society, EMBS",2019,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85077904591&doi=10.1109%2fEMBC.2019.8857073&partnerID=40&md5=661bf03b89f4833398f4d6e9c0034da7,"Diabetic retinopathy (DR) and especially diabetic macular edema (DME) are common causes of vision loss as complications of diabetes. In this work, we consider an ensemble that organizes a convolutional neural network (CNN) and traditional hand-crafted features into a single architecture for retinal image classification. This approach allows the joint training of a CNN and the fine-tuning of the weights of handcrafted features to provide a final prediction. Our solution is dedicated to the automatic classification of fundus images according to the severity level of DR and DME. For an objective evaluation of our approach, we have tested its performance on the official test datasets of the IEEE International Symposium on Biomedical Imaging (ISBI) 2018 Challenge 2: Diabetic Retinopathy Segmentation and Grading Challenge, section B. Disease Grading: Classification of fundus images according to the severity level of diabetic retinopathy and diabetic macular edema. As for our experimental results based on testing on the Indian Diabetic Retinopathy Image Dataset (IDRiD), the classification accuracies have been found to be 90.07% for the 5-class DR challenge, and 96.85% for the 3-class DME one. © 2019 IEEE.",deep learning; diabetic retinopathy screening; ensemble learning; hand-crafted features
Conference Paper,"Sambyal N., Saini P., Syal R.",A Discriminative Learning-Based Deep Learning Approach for Diabetic Retinopathy Classification,Lecture Notes in Electrical Engineering,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85128710401&doi=10.1007%2f978-981-16-8546-0_26&partnerID=40&md5=79bbffba318422620a34cedaa2d7f6cb,"Diabetic retinopathy (DR) is a vision-threatening disease affecting the diabetic population worldwide. Early detection of DR is very crucial to avoid irreversible loss to eyesight. Manual diagnosis of DR is time-consuming task and subjected to high error. The research paper proposes a deep learning (DL)-based DR classification model using discriminative learning. The work has been validated on publicly available MESSIDOR dataset using 16 and 19-layer Vgg networks. The proposed Vgg-16 model for DR classification achieved 98.64% accuracy, 97.94% sensitivity, 99.36% specificity and 99.37% precision. Whereas Vgg-19 model achieved 98.64% accuracy, 99.78% sensitivity, 97.55% specificity and 97.50% precision. The proposed work also outperforms the models in the literature and exhibits improvement in accuracy by at least 1.64%, sensitivity by 1.94% and specificity by 6.48% on the aforementioned dataset. © 2022, The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd.",Computer-aided diagnosis; Deep learning; Diabetic retinopathy; Fundus image; Vgg-16; Vgg-19
Conference Paper,"Sbai A., Touil A., Oukhouya L.",Diabetic retinopathy detection using a pretrained machine learning model,"2022 IEEE 3rd International Conference on Electronics, Control, Optimization and Computer Science, ICECOCS 2022",2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85146221412&doi=10.1109%2fICECOCS55148.2022.9982836&partnerID=40&md5=9216024bea12c637b9cbfa30871d5884,"One of the possible side effects of diabetes is Diabetic Retinopathy. Early diagnosis of diabetic retinopathy is an important step toward healing and can prevent many patients from potential blindness. To identify diabetic retinopathy, practitioners may need an artificial intelligence tool to provide a second opinion to confirm or refute a diagnosis. In this article we use a pretrained machine learning model to find a solution to the issue of low-quality inputs by implementing, in the pre-processing step, the technique of Contrast Limited Adaptive Histogram Equalization to extract more features especially the blood vessels. © 2022 IEEE.",abnormalities detection; computer-aided diagnosis; Diabetic Retinopathy; fundus images; machine learning; pretrained model
Conference Paper,"Sam H.Y., Zikri B Sayed Aluwee S.A., Bt Che Lah N.S., Goh C.M., Tyng C.M., Ikhwan B Murat H.",Preliminary Study of Diabetic Retinopathy Classification from Fundus Images Using Deep Learning Model,"2022 3rd International Conference on Artificial Intelligence and Data Sciences: Championing Innovations in Artificial Intelligence and Data Sciences for Sustainable Future, AiDAS 2022 - Proceedings",2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85141783879&doi=10.1109%2fAiDAS56890.2022.9918681&partnerID=40&md5=8bd351f18c1c94a3c71b3b198ffc2fa9,"The soaring of diabetes cases in Malaysia has resulted in the appearance of diabetic retinopathy among diabetic patients. Diabetic retinopathy is a chronic eye disease triggered by diabetes, which could worsen eyesight functions and even blindness. Even though the cases were found to be common, medical experts still diagnose the disease manually, which increase the risk of incorrect diagnosis. To overcome this, the preliminary study on severity levels classifications of diabetic retinopathy from fundus images has been conducted by applying a deep learning model. A Convolutional Neural Network (CNN) deep learning model architecture is used to train the dataset, which is DenseNet. Various image pre-processing techniques have been applied to enhance the trained images. Moreover, data augmentation and test-time augmentation (TTA) are implemented in evaluating the training results and lower the overfitting, respectively. Prediction evaluation on the images and the effects of data augmentation and TTA by observing the quadratic weighted kappa values were conducted. Ultimately, a prediction model that is to predict and classify the severity labels of fundus images was developed. The prediction model achieved the quadratic weighted kappa score of 0.9308, with the accuracy of 65% on the Messidor-2 dataset, which were moderately accurate. © 2022 IEEE.",data augmentation; deep learning; DenseNet; Diabetic retinopathy; disease scanning; fundus image; prediction model; test-time augmentation (TTA)
Conference Paper,"Jain L., Murthy H.V.S., Patel C., Bansal D.",Retinal Eye Disease Detection Using Deep Learning,"14th International Conference on Information Processing: Internet of Things, ICInPro 2018 - Proceedings",2018,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85085931994&doi=10.1109%2fICINPRO43533.2018.9096838&partnerID=40&md5=7b5da4a659072d4d95e166b386a3098f,"Retinal fundus images are a valuable source of information for ophthalmologists to diagnose retina problems. Early detection can improve chances of cure and also prevent blindness. Retinal problems like diabetic retinopathy, retinitis pigmentosa can be diagnosed using retinal fundus images by medical experts. In recent times, machine learning research has focused on diagnosing diseases like diabetic retinopathy by extracting features and then classifying the image. In this research our goal is to automatically classify images with retinal problems from those of the healthy ones without performing any explicit segmentation or feature extraction. Rather, we use a deep learning model to automatically classify any retinal fundus image as healthy or diseased. The architecture of the network is both simple and fast. The model has been tested on two datasets, including real patient retinal fundus images obtained from a local hospital. The accuracy of this model has been found to be in the range 96.5 % to 99.7%. © 2018 IEEE.",Automated Diagnosis; CNN; Deep Learning; Machine Learning; Retinal Diagnosis
Conference Paper,"Alves S.S.A., Matos A.G., Almeida J.S., Benevides C.A., Cunha C.C.H., Santiago R.V.C., Pereira R.F., Reboucas Filho P.P.",A New strategy for the detection of diabetic retinopathy using a smartphone app and machine learning methods embedded on cloud computer,Proceedings - IEEE Symposium on Computer-Based Medical Systems,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85091140235&doi=10.1109%2fCBMS49503.2020.00108&partnerID=40&md5=1bd0b29106e9d704feaddf74de4abe1a,"Diabetes is a major cause of blindness, kidney failure, heart attacks, stroke and lower limb amputation according to World Health Organization (WHO). Complications from poor diabetes management lead to the Diabetic Retinopathy (DR) which is a leading cause of acquired blindness in the working-age population worldwide. WHO estimated that DR accounts for ≈ 15-17% of all cases of total blindness in the US and Europe, 7% of all cases in China and Mongolia. In Brazil, according to the Ministry of Health, the disease affects 7.6% of the population. A cost saving intervention includes screening and treatment for retinopathy. Detecting the different lesions related to DR plays an important role towards the stage detection, prediction, and prevention. Our challenge here is to design a deep learning neural network able to fully detect such lesions in digital retinal fundus image to help building robust and scaled solutions to tackle this urgent diabetes scenario. These results show that the Diavision Portable device had a better performance using GLCM, LBP and SVM, presenting 100% for both evaluation metrics considered. Using Messidor dataset were obtained better performance with VGG16 and SVM, archiving 100% for all metrics. In terms of feature extraction time, the GLCM and VGG16 presented acceptable times, respectively, 17.63ms and 37.87ms. © 2020 IEEE.",Color fundus photographs; Computer aided diagnosis; Deep features; Diabetic; Machine learning; Retinopathy
Article,"Atwany M.Z., Sahyoun A.H., Yaqub M.",Deep Learning Techniques for Diabetic Retinopathy Classification: A Survey,IEEE Access,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85126314552&doi=10.1109%2fACCESS.2022.3157632&partnerID=40&md5=4f1f196319b3544f59b98f0120631034,"Diabetic Retinopathy (DR) is a degenerative disease that impacts the eyes and is a consequence of Diabetes mellitus, where high blood glucose levels induce lesions on the eye retina. Diabetic Retinopathy is regarded as the leading cause of blindness for diabetic patients, especially the working-age population in developing nations. Treatment involves sustaining the patient's current grade of vision since the disease is irreversible. Early detection of Diabetic Retinopathy is crucial in order to sustain the patient's vision effectively. The main issue involved with DR detection is that the manual diagnosis process is very time, money, and effort consuming and involves an ophthalmologist's examination of eye retinal fundus images. The latter also proves to be more difficult, particularly in the early stages of the disease when disease features are less prominent in the images. Machine learning-based medical image analysis has proven competency in assessing retinal fundus images, and the utilization of deep learning algorithms has aided the early diagnosis of Diabetic Retinopathy (DR). This paper reviews and analyzes state-of-the-art deep learning methods in supervised, self-supervised, and Vision Transformer setups, proposing retinal fundus image classification and detection. For instance, referable, non-referable, and proliferative classifications of Diabetic Retinopathy are reviewed and summarized. Moreover, the paper discusses the available retinal fundus datasets for Diabetic Retinopathy that are used for tasks such as detection, classification, and segmentation. The paper also assesses research gaps in the area of DR detection/classification and addresses various challenges that need further study and investigation. © 2013 IEEE.",classification; diabetes mellitus; diabetic macular edema; Diabetic retinopathy; exudates; haemorrhages; lesion; microaneurysms; self-supervised learning; supervised learning; transformers
Article,"Cao W., Czarnek N., Shan J., Li L.",Microaneurysm detection using principal component analysis and machine learning methods,IEEE Transactions on Nanobioscience,2018,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85047616112&doi=10.1109%2fTNB.2018.2840084&partnerID=40&md5=28450d1e42d01a0af8cf7e4cbee1f7cf,"Diabetic retinopathy (DR) is an eye abnormality caused by long-term diabetes and it is the most common cause of blindness before the age of 50. Microaneurysms (MAs), resulting from leakage from retinal blood vessels, are early indicators of DR. In this paper, we analyzed MA detectability using small 25 by 25 pixel patches extracted from fundus images in the DIAbetic RETinopathy DataBase - Calibration Level 1 (DIARETDB1). Raw pixel intensities of extracted patches served directly as inputs into the following classifiers: random forest (RF), neural network, and support vector machine. We also explored the use of two techniques (principal component analysis and RF feature importance) for reducing input dimensionality. With traditional machine learning methods and leave-10-patients-out cross validation, our method outperformed a deep learning-based MA detection method, with AUC performance improved from 0.962 to 0.985 and F-measure improved from 0.913 to 0.926, using the same DIARETDB1 database. Furthermore, we validated our method on a different dataset - retinopathy online challenge (ROC) data set. The performance of the three classifiers and the pattern with different percentage of principal components are consistent on the two data sets. Especially, we trained the RF on DIARETDB1 and applied it to ROC; the performance is very similar to that of the RF trained and tested using cross validation on ROC data set. This result indicates that our method has the potential to generalize to different datasets. © 2002-2011 IEEE.",automated microaneurysm detection; diabetic retinopathy; Feature representation; neural network; random forest; support vector machine
Article,"Zhang Q.-M., Luo J., Cengiz K.",An optimized deep learning based technique for grading and extraction of diabetic retinopathy severities,Informatica (Slovenia),2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85112317262&doi=10.31449%2finf.v45i5.3561&partnerID=40&md5=951acf50dad320cce157185a2a846283,"The prognosis of Diabetic Retinopathy (DR) requires regular eye examinations, as ophthalmologists depends on fundus segmentation to treat DR pathologies. Automated approaches for detection, segmentation and classification have developed as an imperative area of research for the effective diagnosis of DR for the treatment of serious eye conditions that prevent visual impairment. Diagnosis of various DR lesions, as well as different severities, helping the ophthalmologists to analyze variations in fundus images and take the necessary measures before the disease progresses. Deep learning techniques have evolved as a recent advent to combat the issues of conventional machine leaning based methods. An optimized deep learning framework is proposed in this article for grading and extraction of diabetic retinopathy severities. This involves various steps like background segmentation, feature set extraction, feature optimization using Cuckoo search and Convolutional Neural Network (CNN) severity grade classification. The method was validated on two standard datasets MESSIDOR and IDRiD. The proposed method yields an accuracy value of 97.55%, cross entropy loss of 0.367 and time intricacy of 20 mins and 15 secs for MESSIDOR and 98.02% cross entropy loss of 0.345 and time intricacy of 22 mins and 21 secs for IDRiD dataset; respectively. The state-of-the-art comparison depicts that the proposed CNN based method provides a maximum accuracy improvement of 10.46% comparative to the existing methodology. The proposed framework yields better accuracy by procurement of the investigative outcomes acquired exhibits proficient DR determination. © 2021 Slovene Society Informatika. All rights reserved.",Convolution neural network; Deep learning; Diabetic retinopathy; Machine learning; Severity grading
Conference Paper,"Pamadi A.M., Ravishankar A., Anu Nithya P., Jahnavi G., Kathavate S.",Diabetic Retinopathy Detection using MobileNetV2 Architecture,"1st IEEE International Conference on Smart Technologies and Systems for Next Generation Computing, ICSTSN 2022",2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85130065323&doi=10.1109%2fICSTSN53084.2022.9761289&partnerID=40&md5=eb2fa984cfc62723ec8969c63afc420d,"The disease Diabetic Retinopathy (DR) is a microvascular diabetic condition that affects the eyes. It is attributed to the impairment of the retinal blood vessels. The later it is detected, the greater the likelihood that the patient will lose sight. This paper proposes two Convolutional Neural Network (CNN) models, one of them a binary classification to detect retinopathy and another multinomial classification model to further classify retinopathy into five distinct and widely used stages - None, Mild, Moderate, Severe and Proliferative DR. Using Gaussian filtered fundus images enhances the recognition of subtle features such as edges or spots used for diagnosis. Transfer learning on a pre-trained MobileNetV2 model further enhances the accuracy to 78% for a multinomial classification and up to 97% for binomial classification. © 2022 IEEE.",Convolutional Neural Networks (CNN); Dataset; Deep Learning; Diabetic Retinopathy (DR); Gaussian; MobileNetV2 Architecture
Article,Yadav N.,A deep data-driven approach for enhanced segmentation of blood vessel for diabetic retinopathy,International Journal of Imaging Systems and Technology,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85126294491&doi=10.1002%2fima.22720&partnerID=40&md5=a155291ca0f40880369a88f1eec60b98,"The segmentation step of retinal blood vessel helps to diagnosis the diseases including diabetic retinopathy, glaucoma, etc. The automatic image segmentation process helps experts to speed up the diagnosis of DR, since analytic methods are time consuming and error prone. The neural network (NN) based methods like U-Net uses leap bonding that extract fine information from the training dataset. However automatic segmentation of image using neural network is a challenging process because of uneven and irregular geometry of organ. In this article, we proposed a U-Net based approach for segmentation of retinal vessels. Before applying segmentation step, the affected area of image is enhanced with some preprocessing techniques. Then a dual tree discrete Ridgelet transform (DT-DRT) is apply on the dataset to extract the features from the region of interest. The features accumulation with DT-DRT ensures better feature representation of vessel for segmentation task. The proposed segmentation is implemented on different publicly available dataset and achieve accuracy of 96.01% in CHASE DB1, 97.65% in DRIVE and 98.61% in STARE dataset. The performance of this algorithm is also compared with some other deep learning models, and results demonstrate that this proposed algorithm performed better than them. © 2022 Wiley Periodicals LLC.",deep learning model; neural networks; radon transform; wavelet transform
Conference Paper,"Islam M.R., Hasan M.A.M., Sayeed A.",Transfer Learning based Diabetic Retinopathy Detection with a Novel Preprocessed Layer,"2020 IEEE Region 10 Symposium, TENSYMP 2020",2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85096413827&doi=10.1109%2fTENSYMP50017.2020.9230648&partnerID=40&md5=0fcdaaaf2be0cc0a059fb7e46096eb10,"one of the major reasons for impaired vision in the world nowadays is diabetic retinopathy (DR). Many people could be saved from permanent blindness with early detection. The manual diagnosis is erroneous and tedious. Hence, numerous computerized vision methods for the automatic detection of diabetic retinopathy and its distinctive stages from retinal images were proposed. Various image processing techniques have been developed besides deep learning methods. In image processing techniques, complex features are manually identified. Most of the earlier works used very small dataset which has a great chance to be over-fitting and worked with grayscale image after transforming color fundus images. In our paper, we developed a deep learning model with transfer learning from VGG16 model followed by a novel color version preprocessing technique. It reduced the training time and provided an average accuracy of 0.9132683 implemented to new Kaggle dataset 'APTOS 2019 Blindness Detection'. Moreover, to avoid the over-fitting problem for long run we used Stratified K-fold cross validation. © 2020 IEEE.",Convolution neural Network; deep learning; diabetic retinopathy; transfer learning
Conference Paper,"Sharma K., Nagappan P.",Machine Learning/Deep Learning Algorithms & Variability in Grading Improves Early Detection of DR,"2022 IEEE International Conference on Electronics, Computing and Communication Technologies, CONECCT 2022",2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85138286424&doi=10.1109%2fCONECCT55679.2022.9865837&partnerID=40&md5=09f34fa39471563a3e1db9e08374367c,"Health condition which mainly influence human retina i.e. cognate by Diabetic Mellitus (DM) is a main thread of Diabetic Retinopathy (DR). As a result of the damage of the retina, it causes vision loss. In accordance with census diabetic individuals who had suffered from diabetics in a long time also have DR issues. As a result, DR has become a critical issue that needs a primary stage screening and assessment in order to prevent vision loss and blindness. Physical diagnosis of the condition is time-consuming and prone to inaccuracy. Furthermore, it is not possible to find an ophthalmologist regardless of location or time. As a result, the need for a highly advanced and computerized intelligent system arises, which can be used to diagnose DR in its early stages. Researchers have proposed a number of Machine Learning (ML) algorithms for the diagnosis of DR for decapods. For determining retinal lesion significantly and for initial stage DR diagnosis various feature extraction and analyzing approaches are recommended. Traditional Machine Learning models, on the other hand, suffer from poor generalization during feature extraction due to limited datasets. Using Deep Learning models, more datasets and high computer processing unit weak generalization problem can be reduced. This study intends to provide a DR overview as well as a brief explanation of previous efforts and current automated methods and improvements, in order to the staring exposure of DR. This paper also discusses the most up-to-date DR lesions as well as the causes and symptoms of DR and focus on how AI/ML approaches helpful in early diagnosis of DR and we have to study more on variability in grading to evaluate the best possible result for screening and improving eye disease mainly caused by diabetics. © 2022 IEEE.",Deep Learning; Diabetic Retinopathy; Machine Learning; Non-proliferative DR and proliferative DR
Conference Paper,"Gulati S., Singh V.P., Shukla S.",Comparative Analysis of Deep Learning Approaches for the Diagnosis of Diabetic Retinopathy,"2022 IEEE Students Conference on Engineering and Systems, SCES 2022",2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85140842290&doi=10.1109%2fSCES55490.2022.9887778&partnerID=40&md5=79ca06d1d62c2d6ec60fd42df8dd4d65,"High levels of blood sugar causes diabetes. Diabetes on the other hand leads to various other health issues like heart diseases, kidney damage, nerves damage and eye damage. Diabetic retinopathy is one such disease that is being caused by diabetes and without early treatment or diagnosis it might lead to vision loss as well. Various Computer aided systems have been used and developed for the diagnostics of diabetic retinopathy in the past where it uses the traditional techniques to get low level features such as shape, colors or textures which are handcrafted features. With the advancement in AI and deep learning methodologies especially in the field of medical image analysis, efficient and accurate results are produced as it performs automatic extraction of features. These features can include high level features or some of the low-level features as well. Most commonly used deep learning method for image detection is convolutional neural network. In this paper, three different CNN architectures such as ResNet50, DenseNet121 and VGG16 are used as transfer learning models to carry out a comparative analysis of deep learning approaches for the diagnosis of Diabetic Retinopathy (DR). These models are used to classify diabetic retinopathy into multi-class (5 class based) classification on the basis of severity level and further into binary (2 class based) classification as 0-No DR and 1-DR. The accuracy so obtained on validation set for multi-class classification for the models ResNet50, DenseNet121 and VGG16 is 94.11%,94.64% and 91.52% respectively and that on test set as 94%, 92% and 86% respectively. Whereas the accuracy for binary classification on validation set for the models ResNet50, DenseNet121 and VGG16 is 98.35%, 98.48% and 95.86% respectively. © 2022 IEEE.",Convolutional Neural Network; Deep Learning; Diabetic Retinopathy; Transfer learning
Article,"Kumar G., Chatterjee S., Chattopadhyay C.",DRISTI: a hybrid deep neural network for diabetic retinopathy diagnosis,"Signal, Image and Video Processing",2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85104715097&doi=10.1007%2fs11760-021-01904-7&partnerID=40&md5=2fd8cdbe582e29331482a10131ef366c,"Diabetic retinopathy (DR) is a significant reason for the global increase in visual loss. Studies show that timely treatment can significantly bring down such incidents. Hence, it is essential to distinguish the stages and severity of DR to recommend needed medical attention. In this view, this paper presents DRISTI (Diabetic Retinopathy classIfication by analySing reTinal Images), where a hybrid deep learning model composed of VGG16 and capsule network is proposed, which yields statistically significant performance improvement over the state of the art. To validate our claim, we have reported detailed experimental and ablation studies. We have also created an augmented dataset to increase the APTOS dataset’s size and check how robust the model is. The five-class training and validation accuracy for the expanded dataset is 99.21 % and 75.50 %. The two-class training and validation accuracy on augmented APTOS is 99.96 % and 97.05 %. Extending the two-class model for the mixed dataset, we get a training and validation accuracy of 99.92 % and 91.43 % , respectively. We have also performed cross-dataset and mixed dataset testing to demonstrate the efficiency of DRISTI. © 2021, The Author(s), under exclusive licence to Springer-Verlag London Ltd., part of Springer Nature.",Capsule network; Deep learning; Diabetic retinopathy; Image classification; VGG16
Conference Paper,"Sengupta S., Singh A., Zelek J., Lakshminarayanan V.",Cross-domain diabetic retinopathy detection using deep learning,Proceedings of SPIE - The International Society for Optical Engineering,2019,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85075727932&doi=10.1117%2f12.2529450&partnerID=40&md5=9c784268b38a4126334d1bd0316bc7be,"Globally Diabetic retinopathy (DR) is one of the leading causes of blindness. But due to low patient to doctor ratio performing clinical retinal screening processes for all such patients is not always possible. In this paper a deep learning based automated diabetic retinopathy detection method is presented. Though different frameworks exist for classifying different retinal diseases with both shallow machine learning algorithms and deep learning algorithms, there is very little literature on the problem of variation of sources between training and test data. Kaggle EYEPACS data was used in this study for training the dataset and the Messidor dataset was used for testing the efficiency of the model. With proper data sampling, augmentation and pre-processing techniques it was possible to achieve state-of-The-Art accuracy of classification using Messidor dataset (which had a different camera settings and resolutions of images). The model achieved significant performance with a sensitivity of almost 90% and specificity of 91. 94% with an average accuracy of 90. 4 © COPYRIGHT SPIE. Downloading of the abstract is permitted for personal use only.",Convolutional Neural Network; Data Augmentation; Deep Learning; Diabetic Retinopathy; Fundus Images; Oph-Thalmology; Retina
Conference Paper,"Aditi S.W., Kabir F., Shill P.C.",Diagnosis of Diabetic Retinopathy Using Deep Learning Techniques,"2021 5th International Conference on Electrical Information and Communication Technology, EICT 2021",2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85127711069&doi=10.1109%2fEICT54103.2021.9733545&partnerID=40&md5=f19f543ccb447354f54dbbbd272baf13,"Diabetic retinopathy (DR) is a critical eye malady and a severe cause of visual deficiency in diabetic patients. Diabetic retinopathy is the root cause of more than 1% of the visual deficiency around the world. DR affects blood vessels of retina which may lead to diabetic macular edema, neovascular glaucoma and retinal detachment. To prevent DR from progressing and causing severe damage, an early detection of diabetic retinopathy is crucial. The analysis of diabetic retinopathy (DR) through color fundus images needs skilled clinicians to discover the presence of DR. The grading system is also very hard. Overall the process is less optimal and very time consuming. In this paper, we propose different deep learning approaches to diagnose DR from digital retinal fundus images and precisely classify its severity. In order to build the best classification, simulate the various deep learning models such as ResNet50, ResNet152V2, VGG16 and VGG19. Different benchmark datasets with different characterizations and complexities have been used for training and testing the models. The simulation results illustrate that the proposed method gives better performance while comparing with other methods. © 2021 IEEE.",Diabetic Retinopathy; Image classification; Pretrained models; ResNet152V2; ResNet50; Transfer learning; VGG16; VGG19
Conference Paper,"Kaushik M.K., Mani Teja D., Naga Mahendra Reddy V., Pravallika S.",Computer aided diagnosis system for diabetic retinopathy using deep learning-based CNN method,"10th International Conference on Advances in Computing, Control, and Telecommunication Technologies, ACT 2019",2019,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85078265276&partnerID=40&md5=ddaa9b6f2c5c919e7ec13d61106f8159,"—Diabetic Retinopathy (DR) is one of the major causes of blindness in the world. Regular screening of diabetic patients for DR has been shown to be a cost-e□ective and important aspect of their care. The accuracy and timing of this care is of significant importance to both the cost and e□ectiveness of treatment. The diagnosis of diabetic retinopathy through colour fundus images requires experienced clinicians to identify the presence and significance of many small features which, along with a complex grading system, makes this a di□cult and time-consuming task. The main objective of this paper is deep learning-based CNN method is introduced for the problem of classifying DR in fundus imagery. This is a medical imaging task with increasing diagnostic relevance .With the help of Convolutional Neural Networks (CNN) approach to diagnosing DR from digital fundus images and accurately classifying its severity. A network is developed with CNN architecture which can identify the intricate features involved in the classification task such as micro-aneurysms, exudate and haemorrhages on the retina and consequently provide a diagnosis automatically and without user input. This network is trained on the publicly available Kaggle dataset and demonstrate impressive results, particularly for a high-level classification task. © Grenze Scientific Society, 2019.",Classification (of information); Computer aided diagnosis; Computer aided instruction; Eye protection; Grading; Image classification; Medical imaging; Neural networks; Classification tasks; Computer aided diagnosis systems; Convolutional neural network; Diabetic patient; Diabetic retinopathy; Digital fundus images; Small features; Time-consuming tasks; Deep learning
Conference Paper,"Giraddi S., Chickerur S., Patil M.S., Kanakaraddi S., Giraddi V.",Lightweight Convolution Neural Network for Diabetic Retinopathy Grading,MysuruCon 2022 - 2022 IEEE 2nd Mysore Sub Section International Conference,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85145351925&doi=10.1109%2fMysuruCon55714.2022.9972448&partnerID=40&md5=b0c0e419389b914329a1aa6deaab3d47,"Prevalence of Diabetic Retinopathy is very high in India. Regular screening is necessary for early detection and disease management. Screening programs generate large number of images and manual examination is time consuming and tedious. Traditional classification methods based on segmentation/handcrafted features methods present high false positive rate at pixel level. Deep learning models have been trained with massive datasets. The use of pretrained models on another task has limitations unless initial and target problem are similar enough. Medical images like digital fundus images have limited similarity with the imagenet database. In this study, authors propose to build and optimize lightweight CNN for grading of diabetic retinopathy into one of five classes. The model thus developed, is compared with pre-trained deep learning architecture Resnet. An accuracy of 83.51% is obtained with CNN and accuracy of 76.17% obtained with Resnet. Results demonstrate CNN can obtain better performance than pretrained models. © 2022 IEEE.",convolution neural network; Deep learning; Diabetic retinopathy; medical image processing; Resnet
Conference Paper,"Paradisa R.H., Sarwinda D., Bustamam A., Argyadiva T.",Classification of Diabetic Retinopathy through Deep Feature Extraction and Classic Machine Learning Approach,"2020 3rd International Conference on Information and Communications Technology, ICOIACT 2020",2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85100907188&doi=10.1109%2fICOIACT50329.2020.9332082&partnerID=40&md5=43322d8b8b719780334247959dd45772,"Diabetic Retinopathy (DR) is a complication of diabetes, the leading cause of vision loss in working-age adults. An ophthalmologist can carry out the diagnosis of DR by examining color fundus images. However, the fundus image analysis process takes a long time. Automatic detection of DR is achallenging task. One of the deep learning approaches, Convolutional Neural Networks (CNN), is efficient in image classification tasks. In this research, a CNN architecture is used, namely ResNet-50, as feature extraction and classification. The ResNet-50 feature output at the feature extraction stage is also used as input for machine learning classifiers such as Support Vector Machine (SVM), Random Forest (RF), k-Nearest Neighbor (k-NN), and Extreme Gradient Boosting (XGBoost). The model works by using fundus images from the DIARETDBI dataset. Data augmentation and preprocessing are proposed in this study to facilitate the model in recognizing images. The performance of each classifier is evaluated based on accuracy, sensitivity, and specificity. The SVM classifier achieved 99% for accuracy and sensitivity in the 80:20 dataset composition. The k-NN classifier obtains the highest specificity for the same dataset's design by 100%. © 2020 IEEE.",Convolutional Neural Network; Diabetic Retinopathy; Feature Extraction; Machine Learning Classifier; ResNet-50
Article,"Miao Y., Tang S.",Classification of Diabetic Retinopathy Based on Multiscale Hybrid Attention Mechanism and Residual Algorithm,Wireless Communications and Mobile Computing,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85132321581&doi=10.1155%2f2022%2f5441366&partnerID=40&md5=4611bc4af990a91e0e525a9a633c6fd6,"The key of classification diagnosis of diabetic retinopathy lies in the recognition of the features of small lesions, and it is difficult to extract the features of too small lesions by general extraction methods. In order to solve the problem that it is difficult to extract small focus, a hybrid attention mechanism combined with residual convolutional neural network model algorithm is proposed to improve the classification accuracy of diabetic retinopathy. Firstly, a multiscale deep learning network model with hybrid attention is designed, and then, the high-level features of images are extracted by using the network model; finally, after balancing different types of samples by sampling algorithm, the spatial attention and channel attention of the extracted features are enhanced; small-step learning strategy, loss function, and initial parameters are used to optimize the performance of the network model. The classifier based on multiscale hybrid attention network is used to judge the five classifications. Experimental results show that the proposed algorithm can learn more features of small targets and can effectively improve the classification performance of diabetic retina. An experimental test was performed on Kaggle's publicly available dataset of diabetic retinas, and the classification accuracy was 93.8%, compared to some existing classification models; the method proposed in this paper can achieve better classification results for diabetic retinopathy. © 2022 Yue Miao and Siyuan Tang.",Computer aided diagnosis; Convolutional neural networks; Deep learning; Eye protection; Image enhancement; Learning systems; Neural network models; Statistical tests; Transfer learning; Attention mechanisms; Classification accuracy; Convolutional neural network; Diabetic retinopathy; Extraction method; Learning network; Model algorithms; Network models; Neural network model; Small lesions; Classification (of information)
Article,"Al-Moosawi N.M., Khudeyer R.S.",ResNet-34/DR: A Residual Convolutional Neural Network for the Diagnosis of Diabetic Retinopathy,Informatica (Slovenia),2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85122583677&doi=10.31449%2finf.v45i7.3774&partnerID=40&md5=9e1e95d60405ffe6bba35487d623a531,"Diabetic retinopathy (DR) is an eye complication associated with diabetes, resulting in blurred vision or blindness. The early diagnosis and treatment of DR can decrease the risk of vision loss dramatically. However, such diagnosis is a tedious and complicated task due to the variability of retinal changes across the stages of the diseases, and due to the high number of undiagnosed and untreated DR cases. In this paper, we develop a computationally efficient and scalable deep learning model using convolutional neural networks (CNN), for diagnosing DR automatically. Various preprocessing algorithms are utilized to improve accuracy, and a transfer learning strategy is adopted to speed up the process. Our experiment used the fundus image set available on online Kaggle datasets. As an ultimate conclusion of applicable performance metrics, our computational simulation achieved a relatively-high F1 score of 93.2% for stage-based DR classification. © 2021 Slovene Society Informatika. All rights reserved.",Convolutional neural networks (CNN); Deep learning (DL); Diabetic retinopathy (DR); ResNet-34; Transfer learning (TL)
Conference Paper,"Ramchandre S., Patil B., Pharande S., Javali K., Pande H.",A Deep Learning Approach for Diabetic Retinopathy detection using Transfer Learning,"2020 IEEE International Conference for Innovation in Technology, INOCON 2020",2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099555004&doi=10.1109%2fINOCON50539.2020.9298201&partnerID=40&md5=5e283280b19223c04aa3a23a293aae52,"Diabetic Retinopathy is a primary complication of diabetes which more often than not, affects both eyes and anyone with type-1 or type-2 diabetes can develop it. A Diabetic patient should undergo eye tests periodically as the pace of development of this condition is slow. A Dataset of Fundus Photographs of retina is considered. Thus, there is a notable value in automatically categorizing the Fundus Photographs. Therefore, to get a consolidated and objective medical diagnosis, this paper proposes a transfer learning based approach for Diabetic Retinopathy categorization. The resizing of the dataset is performed, which converts the varied images into 224x224 format. The images are augmented using AUGMIX and pooled using GeM. Then, we have used pretrained models, namely SEResNeXt32x4d and EfficientNetb3. The pretraining of the aforementioned neural networks has been done on the ImageNet dataset. Then, the Diabetic Retinopathy images are migrated to these models. Based on the dataset already available, the output is ultimately split up into 5 levels according to the seriousness of the degree of DR. The experimental results show that the training accuracy of this method can reach as high as 0.91. Hence, the retina images of the Diabetic and Healthy patients can be easily classified using our proposed methodology, consequently reducing the number of reviews by medical professionals. © 2020 IEEE.",deep learning; diabetic retinopathy; transfer learning
Conference Paper,"Karki S.S., Kulkarni P.",Diabetic retinopathy classification using a combination of EfficientNets,"2021 International Conference on Emerging Smart Computing and Informatics, ESCI 2021",2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85104630631&doi=10.1109%2fESCI50559.2021.9397035&partnerID=40&md5=6333d6471cbed89ec2c24440ca7980b7,"Diabetic Retinopathy (DR) is a diabetes complication that affects vision. It is caused by damage to the blood vessels of retina. Early and accurate detection of DR is crucial to reduce likelihood of progression to proliferative retinopathy and blindness. This paper proposes a method for classifying the severity of DR using deep learning. Experiments were conducted by blending the members of EfficientNet for classification of the diabetic retinopathy image as no DR, mild, moderate, severe, or proliferative DR. The models have been trained using different datasets and best model achieved a quadratic kappa score of 0.924377 on the APTOS test dataset. The results are promising and warrant further investigation. The presented model has the potential aid in fast diagnosis for better early detection of DR. © 2021 IEEE.",APTOS; BCE loss; CNN; EfficientNet; Retinopathy
Article,"Burlina P., Paul W., Liu T.Y.A., Bressler N.M.","Detecting Anomalies in Retinal Diseases Using Generative, Discriminative, and Self-supervised Deep Learning",JAMA Ophthalmology,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85122361372&doi=10.1001%2fjamaophthalmol.2021.5557&partnerID=40&md5=dde604eabb1d2f9c7b68cbbccc3e59b5,"Importance: Anomaly detectors could be pursued for retinal diagnoses based on artificial intelligence systems that may not have access to training examples for all retinal diseases in all phenotypic presentations. Possible applications could include screening of population for any retinal disease rather than a specific disease such as diabetic retinopathy, detection of novel retinal diseases or novel presentations of common retinal diseases, and detection of rare diseases with little or no data available for training. Objective: To study the application of anomaly detection to retinal diseases. Design, Setting, and Participants: High-resolution retinal images from the publicly available EyePACS data set with fundus images with a corresponding label ranging from 0 to 4 for representing different severities of diabetic retinopathy. Sixteen variants of anomaly detectors were designed. For evaluation, a surrogate problem was constructed, using diabetic retinopathy images, in which only retinas with nonreferable diabetic retinopathy, ie, no diabetic macular edema, and no diabetic retinopathy or mild to moderate nonproliferative diabetic retinopathy were used for training an artificial intelligence system, but both nonreferable and referable diabetic retinopathy (including diabetic macular edema or proliferative diabetic retinopathy) were used to test the system for detecting retinal disease. Main Outcomes and Measures: Anomaly detectors were evaluated by commonly accepted performance metrics, including area under the receiver operating characteristic curve, F1 score, and accuracy. Results: A total of 88692 high-resolution retinal images of 44346 individuals with varying severity of diabetic retinopathy were analyzed. The best performing across all anomaly detectors had an area under the receiver operating characteristic of 0.808 (95% CI, 0.789-0.827) and was obtained using an embedding method that involved a self-supervised network. Conclusions and Relevance: This study suggests when abnormal (diseased) data, ie, referable diabetic retinopathy in this study, were not available for training of retinal diagnostic systems wherein only nonreferable diabetic retinopathy was used for training, anomaly detection techniques were useful in identifying images with and without referable diabetic retinopathy. This suggests that anomaly detectors may be used to detect retinal diseases in more generalized settings and potentially could play a role in screening of populations for retinal diseases or identifying novel diseases and phenotyping or detecting unusual presentations of common retinal diseases.. © 2022 American Medical Association. All rights reserved.",Article; artificial intelligence; deep learning; diabetic macular edema; diabetic retinopathy; disease severity; human; image quality; nonproliferative diabetic retinopathy; outlier detection; retina disease; retina image; diabetic retinopathy; eye fundus; macular edema; Artificial Intelligence; Deep Learning; Diabetic Retinopathy; Fundus Oculi; Humans; Macular Edema
Conference Paper,"Juyal A., Negi P.",Severity of Diabetic Retinopathy Detection for Early Prevention using Lightweight Deep Learning Model,MysuruCon 2022 - 2022 IEEE 2nd Mysore Sub Section International Conference,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85145350966&doi=10.1109%2fMysuruCon55714.2022.9972693&partnerID=40&md5=f79bfb82a7c9fb7e7290f03687aa2dfd,"There were 2.6 million visually impaired and blind people worldwide in 2015, and it is predicted that number would increase to 3.2 million by 2020. Although it is anticipated that diabetic retinopathy would become less common in high-income nations, low- and middle-income nations must prioritise the early diagnosis and treatment of the condition. Recent developments in deep learning technology have allowed researchers to demonstrate that automated diabetic retinopathy screening and grading are effective in reducing labour costs. Although ultra-wide-field fundus imaging may capture up to 82 percent of the retinal surface, traditional fundus imaging is still used by the majority of automated processes. In this article, we describe a deep learning- and ultra-wide-field fundus photography-based method for detecting diabetic retinopathy. In studies, we demonstrate that the utilisation of a 7-standard field imaging from ultra-wide-field fundus images, taken from initial treatment diabetic retinopathy research, surpasses the optic disc as well as macula-centered image in a statistical sense. © 2022 IEEE.",and Performance DR Evaluation; Diabetic Retinopathy; Lightweight Deep Learning Model; Severity Disease Classification
Conference Paper,"Cao J., Chen J.",Comparison of Deep Learning Models on Detection and Classification of Diabetic Retinopathy,ICSAI 2021 - 7th International Conference on Systems and Informatics,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85124955343&doi=10.1109%2fICSAI53574.2021.9664179&partnerID=40&md5=c61fbda47f700d451e9292da5dd5d317,"Diabetic retinopathy is a common complication to diabetes, also is the main cause of the current diabetic blindness. Traditional methods of manually classifying retinal pathological images have difficulty in feature extraction, and differences in the level of medical personnel also result in low classification efficiency. In this paper, four deep learning network models based on LeNet, AlexNet, GoogLeNet and Res-Net 50 are used to compare and study the automatic classification of diabetic retinopathy images. The experimental data set comes from the data modeling and data analysis competition platform (Kaggle). The experimental results show that RES-NET 50 can accurately classify the degree of retinopathy with an accuracy of 89.71%, but the convergence rate is slow, while AlexNet can quickly converge with a low accuracy of 63.21%. This research can provide a good research foundation for the diagnosis and treatment of retinal diseases and the classification of disease severity in the future. © 2021 IEEE.",Deep Learning; Diabetic retinopathy; Image Augment; Image classification; Image recognition
Conference Paper,"Gu Y., Wang X., Pan J., Zhou Z.",Diabetic Retinopathy Grading Base on Contrastive Learning and Semi-supervised Learning,Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85120630893&doi=10.1007%2f978-3-030-91415-8_7&partnerID=40&md5=6bed3c1bfb3d7d955f3f8c59ab632726,"The diabetic retinopathy (DR) detection based on deep learning is a powerful tool for early screening of DR. Although several automatic DR grading algorithms have been proposed, their performance is still limited by the characteristics of DR lesions and grading criteria, and coarse-grained image-level label. In this paper, we propose a novel approach based on contrastive learning and semi-supervised learning to break through these limitations. We first employ contrastive learning to solve the problem of inter-class and intra-class differences in DR grading. This method enables the model to identify the unique lesion features on each DR fundus color image and strengthen the feature expression for different kinds of lesions. Then we use a small amount of open-source pixel-level annotation dataset to train the lesion segmentation model, in order to provide fine-grained pseudo-label for image-level fundus images. Meanwhile, we design a pseudo-label attention structure and deep supervision method, to increase the attention of the model to lesion features and improve the grading performance. Experiments on the open-source DR grading datasets EyePACS, Messidior, IDRiD, and FGADR can prove the effectiveness of our proposed method and show the results superior to the previous methods. © 2021, Springer Nature Switzerland AG.",Deep learning; Diabetic retinopathy; Disease grading; Lesion segmentation
Article,"Quellec G., Al Hajj H., Lamard M., Conze P.-H., Massin P., Cochener B.",ExplAIn: Explanatory artificial intelligence for diabetic retinopathy diagnosis,Medical Image Analysis,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85107806204&doi=10.1016%2fj.media.2021.102118&partnerID=40&md5=149c6d32b50f035d0bd036185747d58a,"In recent years, Artificial Intelligence (AI) has proven its relevance for medical decision support. However, the “black-box” nature of successful AI algorithms still holds back their wide-spread deployment. In this paper, we describe an eXplanatory Artificial Intelligence (XAI) that reaches the same level of performance as black-box AI, for the task of classifying Diabetic Retinopathy (DR) severity using Color Fundus Photography (CFP). This algorithm, called ExplAIn, learns to segment and categorize lesions in images; the final image-level classification directly derives from these multivariate lesion segmentations. The novelty of this explanatory framework is that it is trained from end to end, with image supervision only, just like black-box AI algorithms: the concepts of lesions and lesion categories emerge by themselves. For improved lesion localization, foreground/background separation is trained through self-supervision, in such a way that occluding foreground pixels transforms the input image into a healthy-looking image. The advantage of such an architecture is that automatic diagnoses can be explained simply by an image and/or a few sentences. ExplAIn is evaluated at the image level and at the pixel level on various CFP image datasets. We expect this new framework, which jointly offers high classification performance and explainability, to facilitate AI deployment. © 2021 Elsevier B.V.",Diabetic retinopathy diagnosis; Explanatory artificial intelligence; Self-supervised learning
Conference Paper,"Muddamsetty S.M., Moeslund T.B.",Multi-level quality assessment of retinal fundus images using deep convolution neural networks,"VISIGRAPP 2021 - Proceedings of the 16th International Joint Conference on Computer Vision, Imaging and Computer Graphics Theory and Applications",2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85101692551&partnerID=40&md5=96ad9bf7a339b8b69d233d660430d7e2,"Retinal fundus image quality assessment is one of the major steps in screening for retinal diseases, since the poor-quality retinal images do not allow an accurate medical diagnosis. In this paper, we first introduce a large multi-level Retinal Fundus Image Quality Assessment (RFIQA) dataset. It has six levels of quality grades, which are based on important regions to consider for diagnosing diabetic retinopathy (DR), Aged Macular Degeneration (AMD) and Glaucoma by ophthalmologists. Second, we propose a Convolution Neural Network (CNN) model to assess the quality of the retinal images with much fewer parameters than existing deep CNN models and finally we propose to combine deep and generic texture features, and using Random Forest classifier. Experiments show that combing both deep and generic features outperforms using any of the two feature types in isolation. This is confirmed on our new dataset as well as on other public datasets. Copyright © 2021 by SCITEPRESS - Science and Technology Publications, Lda. All rights reserved.",CNN; Deep-learning; Generic Features; Multi-level Grading; Quality Assessment; Retinal Fundus Image
Article,"Patil M.S., Chickerur S., Kumar Y.V.S., Bakale V.A., Giraddi S., Roodagi V.C., Kulkarni Y.N.",Deep hyperparameter transfer learning for diabetic retinopathy classification,Turkish Journal of Electrical Engineering and Computer Sciences,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85117197139&doi=10.3906%2felk-2105-36&partnerID=40&md5=391a228e069f596e876fb4a4421697de,"The detection of diabetic retinopathy (DR) in millions of diabetic patients across the globe is a challenging problem. Diagnosis of retinopathy is a lengthy and tedious process, requiring a medical professional to assess the individual fundus images of a patient’s retina. This process can be automated by applying deep learning (DL) technology given a huge dataset. The problems associated with DL are the unavailability of a large dataset and their higher training time. The DL model’s best performance is achieved using set of optimal hyperparameters (OHPs) obtained by performing costly iterations of hyperparameter optimization (HPO). These problems can be addressed by using transfer learning (TL) technique in both DL model training and HPO. TL in HP tuning is the focus of this work. The authors study the applicability of EyePACS DR dataset’s OHPs to other DR datasets, forming the basis of the research question addressed in this work. The DR classification is performed using a ResNet model trained on the EyePACS (kaggle) and Indian diabetic retinopathy image dataset (IDRiD) datasets. Various HPs tuned in this work are data augmentation configuration, number of layers, optimizers, data samplers, learning rate, and momentum. The authors demonstrate that EyePACS dataset’s OHPs are suitable for training with IDRiD dataset without needing to tune HPs for IDRiD dataset from scratch. The OHPs for a task and their reusability is poorly reported in the literature. Therefore, the EyePACS DR dataset’s OHPs reported here can be used by other researchers. Moreover, the researchers working on other DR datasets can also apply the same OHPs since they are reusable and no iterations of HPO are required. The OHPs are provided for both EyePAC and IDRiD datasets after being tuned from scratch, which can be used as starting point for HPO by others. © TÜBİTAK.",Augmentation; Bayesian optimization; Diabetic retinopathy; Hyperparameter optimization; ResNet; Transfer learning
Article,"Jagan Mohan N., Murugan R., Goel T., Mirjalili S., Roy P.",A novel four-step feature selection technique for diabetic retinopathy grading,Physical and Engineering Sciences in Medicine,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85118679671&doi=10.1007%2fs13246-021-01073-4&partnerID=40&md5=45b7d13987d8558e5938badbda4e9b3e,"Diabetic retinopathy is a microvascular complication of diabetes mellitus that develops over time. Diabetic retinopathy is one of the retinal disorders. Early detection of diabetic retinopathy reduces the chances of permanent vision loss. However, the identification and regular diagnosis of diabetic retinopathy is a time-consuming task and requires expert ophthalmologists and radiologists. In addition, an automatic diabetic retinopathy detection technique is necessary for real-time applications to facilitate and minimize potential human errors. Therefore, we propose an ensemble deep neural network and a novel four-step feature selection technique in this paper. In the first step, the preprocessed entropy images improve the quality of the retinal features. Second, the features are extracted using a deep ensemble model include InceptionV3, ResNet101, and Vgg19 from the retinal fundus images. Then, these features are combined to create an ample feature space. To reduce the feature space, we propose four-step feature selection techniques: minimum redundancy, maximum relevance, Chi-Square, ReliefF, and F test for selecting efficient features. Further, appropriate features are chosen from the majority voting techniques to reduce the computational complexity. Finally, the standard machine learning classifier, support vector machines, is used in diabetic retinopathy classification. The proposed method is tested on Kaggle, MESSIDOR-2, and IDRiD databases, available publicly. The proposed algorithm provided an accuracy of 97.78%, a sensitivity of 97.6%, and a specificity of 99.3%, using top 300 features, which are better than other state-of-the-art methods. © 2021, Australasian College of Physical Scientists and Engineers in Medicine.",Deep networks; Diabetic retinopathy; Feature extraction; Feature selection; Fundus images; Retina; Support vector machine
Conference Paper,"Das S., Das D., Biswas S.K., Purkayastha B.",Deep Diabetic Retinopathy Detection System (DDRDS) using Convolutional Neural Network: A Comparative Study,"2021 International Conference on Intelligent Technologies, CONIT 2021",2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85114894509&doi=10.1109%2fCONIT51480.2021.9498420&partnerID=40&md5=836eb98dd376c7fa1094298e0acefe55,"Diabetic Retinopathy (DR) is a medical condition in the retina of human eye, triggered due to diabetes mellitus which causes formation of lesions in the retina and leads to blurred vision and even blindness. The statistical data estimations show 80% of diabetic patients, suffering from protracted diabetes, also suffers from DR. Hence, early DR evaluation and assessment can reduce susceptibility to severe blindness, especially amongst the working generation. The process of physical diagnosis is laborious, inefficient and liable to cause error, and the lack of resources and expert opinions, makes early detection and treatment infeasible. Thus, advanced intelligent systems using innovative Machine Learning (ML) techniques such as Deep Learning (DL) are proposed by researchers. This paper proposes an intelligent system named Deep Diabetic Retinopathy Detection System (DDRDS) which employs four Deep Convolutional Neural Networks (DCNNs), for fundus image classification, for early detection of DR. © 2021 IEEE.",DCNN; DR; Generalization; Image Classification; Overfitting
Article,"Ogunyemi O.I., Gandhi M., Lee M., Teklehaimanot S., Daskivich L.P., Hindman D., Lopez K., Taira R.K.","Detecting diabetic retinopathy through machine learning on electronic health record data from an urban, safety net healthcare system",JAMIA Open,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85118129414&doi=10.1093%2fjamiaopen%2fooab066&partnerID=40&md5=7ceb9f50e4651fb2f54c024343be3baf,"Objective: Clinical guidelines recommend annual eye examinations to detect diabetic retinopathy (DR) in patients with diabetes. However, timely DR detection remains a problem in medically underserved and under-resourced settings in the United States. Machine learning that identifies patients with latent/undiagnosed DR could help to address this problem. Materials and Methods: Using electronic health record data from 40 631 unique diabetic patients seen at Los Angeles County Department of Health Services healthcare facilities between January 1, 2015 and December 31, 2017, we compared ten machine learning environments, including five classifier models, for assessing the presence or absence of DR. We also used data from a distinct set of 9300 diabetic patients seen between January 1, 2018 and December 31, 2018 as an external validation set. Results: Following feature subset selection, the classifier with the best AUC on the external validation set was a deep neural network using majority class undersampling, with an AUC of 0.8, the sensitivity of 72.17%, and specificity of 74.2%. Discussion: A deep neural network produced the best AUCs and sensitivity results on the test set and external validation set. Models are intended to be used to screen guideline noncompliant diabetic patients in an urban safety-net setting. Conclusion: Machine learning on diabetic patients' routinely collected clinical data could help clinicians in safety-net settings to identify and target unscreened diabetic patients who potentially have undiagnosed DR. © 2021 The Author(s) 2021. Published by Oxford University Press on behalf of the American Medical Informatics Association.",artificial intelligence; diabetic retinopathy; diabetic retinopathy diagnosis; machine learning; safety net providers
Conference Paper,"Zhang Z., Shou W., Ma W., Xing D., Xu Q., Xu L.-Q., Fan Q., Xu L.",An Automated Method of Identifying Incorrectly Labelled Images Based on the Sequences of Loss Functions of Deep Learning Networks,"Lecture Notes of the Institute for Computer Sciences, Social-Informatics and Telecommunications Engineering, LNICST",2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85101317501&doi=10.1007%2f978-3-030-67514-1_21&partnerID=40&md5=00be743c6e38dd48fc0ca7b8b01965fc,"Deep learning has been widely applied to medical image analysis tasks. Since the labelled medical images are the foundation of the training, validation, and test of deep learning classification models, the quality of labelling process could directly affect the performance of the models. However, it was estimated that up to ten percent of manually labelled medical images may be incorrectly labelled. In this paper, by utilizing the sequences of loss functions of deep learning classification networks through multiple training epochs, an automated method of identifying incorrectly labelled medical images was proposed. For those identified images, their labels could be further reviewed and updated by senior and experienced physicians, ultimately improving the quality of labelled medical image datasets, as well as the performance of the deep learning models. Two experiments were carried out to validate the effectiveness of the proposed method, based on a specific fundus image dataset for referable diabetic retinopathy screening. a) In the first experiment, the effectiveness of the method to accurately identify the incorrectly labelled samples from the whole labelled dataset was verified. For a fundus image dataset comprising 10788 samples with gold-standard labels (5394 non-referable diabetic retinopathy samples and 5384 referable diabetic retinopathy samples), the labels of a small part (6%, 648) of the images were intentionally changed to the opposite, in order to simulate the real-world situation. By utilizing the proposed method, 75.31% (488) of the incorrectly labelled samples were successfully identified, and only 4.85% (492) of the correctly labelled samples were wrongly identified as the incorrectly labelled ones. b) In the second experiment, by further reviewing those 980 samples (only 9.1% of the whole dataset) that were identified as incorrectly labelled from the dataset and updating their labels to the correct ones, the deep learning classification model for referable diabetic retinopathy screening was retrained. Tested on an independent test dataset with completely correct labels (700 non-referable diabetic retinopathy samples and 700 referable diabetic retinopathy samples), the best accuracy of the model was increased from 95.93% (trained on the dataset with 6% incorrectly labelled samples) to 96.50% (trained on the revised dataset with 1.5% incorrectly labelled samples), approaching the ideal value 96.57% (trained on the original dataset with 0% incorrectly labelled samples), demonstrating the effectiveness of the proposed method to improve the performance of the deep learning models. © 2021, ICST Institute for Computer Sciences, Social Informatics and Telecommunications Engineering.",Deep learning; Incorrectly labelled sample identification; Medical image classification
Conference Paper,"Valarmathi S., Vijayabhanu R.",A Survey on Diabetic Retinopathy Disease Detection and Classification using Deep Learning Techniques,"Proceedings of 2021 IEEE 7th International Conference on Bio Signals, Images and Instrumentation, ICBSII 2021",2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85107974076&doi=10.1109%2fICBSII51839.2021.9445163&partnerID=40&md5=f518ce891e9524dea225058a6c2843fe,"Diabetes is the most commonly found chronic disease seen in many people of different age groups with poor insulin production, which causes high blood sugar. Diabetes, when left untreated, can lead to the development of several diseases across the body. Diabetic Retinopathy (DR) is an asymptomatic eye disease induced by diabetes that results in damaged retinal vessels. Many automatic diagnostic systems have been developed in the literature in which conventional handcrafted features were used. With the development of Deep Learning (DL), particularly in medical imaging, more accurate and potential results are produced, as it performs automatic feature extraction. Convolutional Neural Networks (CNNs) are the most widely used deep learning method in medical image analysis. In this paper, several Deep Learning-based diabetic retinopathy disease detection and classification techniques are analyzed and reviewed for better understanding. © 2021 IEEE.",Convolutional Neural Network (CNN); Deep Learning; Diabetes; Diabetic Retinopathy; Medical image analysis
Article,"Zhou Y., Wang B., Huang L., Cui S., Shao L.","A Benchmark for Studying Diabetic Retinopathy: Segmentation, Grading, and Transferability",IEEE Transactions on Medical Imaging,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102241270&doi=10.1109%2fTMI.2020.3037771&partnerID=40&md5=067a3eda89638c172aee2291b3ec9892,"People with diabetes are at risk of developing an eye disease called diabetic retinopathy (DR). This disease occurs when high blood glucose levels cause damage to blood vessels in the retina. Computer-Aided DR diagnosis has become a promising tool for the early detection and severity grading of DR, due to the great success of deep learning. However, most current DR diagnosis systems do not achieve satisfactory performance or interpretability for ophthalmologists, due to the lack of training data with consistent and fine-grained annotations. To address this problem, we construct a large fine-grained annotated DR dataset containing 2,842 images (FGADR). Specifically, this dataset has 1,842 images with pixel-level DR-related lesion annotations, and 1,000 images with image-level labels graded by six board-certified ophthalmologists with intra-rater consistency. The proposed dataset will enable extensive studies on DR diagnosis. Further, we establish three benchmark tasks for evaluation: 1. DR lesion segmentation; 2. DR grading by joint classification and segmentation; 3. Transfer learning for ocular multi-disease identification. Moreover, a novel inductive transfer learning method is introduced for the third task. Extensive experiments using different state-of-The-Art methods are conducted on our FGADR dataset, which can serve as baselines for future research. Our dataset will be released in https://csyizhou.github.io/FGADR/. © 1982-2012 IEEE.",Diabetic retinopathy; grading; lesion segmentation; transfer learning
Article,"Skouta A., Elmoufidi A., Jai-Andaloussi S., Ouchetto O.",Hemorrhage semantic segmentation in fundus images for the diagnosis of diabetic retinopathy by using a convolutional neural network,Journal of Big Data,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85131790627&doi=10.1186%2fs40537-022-00632-0&partnerID=40&md5=7417a3b027317952cc7685d7f0d48b6c,"Because retinal hemorrhage is one of the earliest symptoms of diabetic retinopathy, its accurate identification is essential for early diagnosis. One of the major obstacles ophthalmologists face in making a quick and effective diagnosis is viewing too many images to manually identify lesions of different shapes and sizes. To this end, researchers are working to develop an automated method for screening for diabetic retinopathy. This paper presents a modified CNN UNet architecture for identifying retinal hemorrhages in fundus images. Using the graphics processing unit (GPU) and the IDRiD dataset, the proposed UNet was trained to segment and detect potential areas that may harbor retinal hemorrhages. The experiment was also tested using the IDRiD and DIARETDB1 datasets, both freely available on the Internet. We applied preprocessing to improve the image quality and increase the data, which play an important role in defining the complex features involved in the segmentation task. A significant improvement was then observed in the learning neural network that was able to effectively segment the bleeding and achieve sensitivity, specificity and accuracy of 80.49%, 99.68%, and 98.68%, respectively. The experimental results also yielded an IoU of 76.61% and a Dice value of 86.51%, showing that the predictions obtained by the network are effective and can significantly reduce the efforts of ophthalmologists. The results revealed a significant increase in the diagnostic performance of one of the most important retinal disorders caused by diabetes. © 2022, The Author(s).",Artificial intelligence; CAD system; Convolutional neural networks; Deep learning; Detection; Diabetic retinopathy; Fundus images; Segmentation
Conference Paper,"Kumar A.V., Babu A.S.",Diabetic Retinopathy Detection using Deep Learning Methodology,"2022 IEEE 3rd Global Conference for Advancement in Technology, GCAT 2022",2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85145433989&doi=10.1109%2fGCAT55367.2022.9971891&partnerID=40&md5=ca533812ce3296addcbef0b30dbe4c70,"Diabetic retinopathy is a human retinal sickness that makes harm the veins in the retina. Individuals with diabetics have high glucose level that harm the veins. These blood vessels can swell and leak, sometimes it can even block the blood flow. Eventually, this leads to partial or complete vision loss. Early diagnosis helps in timely treatment but it requires an efficient screening system. This work suggests detection of diabetic retinopathy using three deep learning techniques such as Densenet-169,ConvLSTM (proposed model) and Dense-LSTM (proposed hybrid model) and compare these models, which is required for early location and grouping as per the severity of diabetic retinopathy. The database for this work is publicly available MESSIDOR dataset. From the results obtained 94 percentage accuracy for Densenet-169 model, 99 percentage accuracy for ConvLSTM (proposed model)and 83 percentage accuracy for Dense-LSTM (proposed hybrid model). It is evident that Diabetic Retinopathy detection using proposed model, ConvLSTM outperformed the Densenet-169 and Dense-LSTM model. © 2022 IEEE.",ConvLSTM; Deep Learning; Densenet-169; Diabetic Retinopathy; Fundus images
Conference Paper,"Errattahi R., Zahra S.F., Hannani A.E., Abdelhak A., Ouahmane H., Mohamed S., Yassin E.H.",Investigating generalization in automatic COVID-19 detection using deep learning,"11th International Symposium on Signal, Image, Video and Communications, ISIVC 2022 - Conference Proceedings",2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85134051830&doi=10.1109%2fISIVC54825.2022.9800745&partnerID=40&md5=96cb7f7c6dedb7f5bd6e024a9b898dec,"Computer Vision and Deep Learning have been widely used to automatically detect and analyze many diseases in various fields. Some of these include tumor detection, diabetic retinopathy classification, automatic prostate segmentation, nodules classification, etc. In this work, we are investigating the application of computer vision and deep learning techniques in COVID-19 detection from X-ray images. The general purpose was to offer an aided diagnosis system to assist radiologists in COVID-19 detection or to present a preliminary assessment when a radiologist is not immediately available. To address the problem of dependence on training data, and given the nature of the task, we opted for a double evaluation of the developed models. The proposed system appears promising for the diagnosis of COVID19, showing potential results in two different datasets. © 2022 IEEE.",Computer Vision; COVID-19; Deep Learning; Transfer Learning; X-ray
Article,"Zhang W.-F., Li D.-H., Wei Q.-J., Ding D.-Y., Meng L.-H., Wang Y.-L., Zhao X.-Y., Chen Y.-X.",The Validation of Deep Learning-Based Grading Model for Diabetic Retinopathy,Frontiers in Medicine,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85131508271&doi=10.3389%2ffmed.2022.839088&partnerID=40&md5=a5e9fb7284af72b34e78255b3360fc5c,"Purpose: To evaluate the performance of a deep learning (DL)-based artificial intelligence (AI) hierarchical diagnosis software, EyeWisdom V1 for diabetic retinopathy (DR). Materials and Methods: The prospective study was a multicenter, double-blind, and self-controlled clinical trial. Non-dilated posterior pole fundus images were evaluated by ophthalmologists and EyeWisdom V1, respectively. The diagnosis of manual grading was considered as the gold standard. Primary evaluation index (sensitivity and specificity) and secondary evaluation index like positive predictive values (PPV), negative predictive values (NPV), etc., were calculated to evaluate the performance of EyeWisdom V1. Results: A total of 1,089 fundus images from 630 patients were included, with a mean age of (56.52 ± 11.13) years. For any DR, the sensitivity, specificity, PPV, and NPV were 98.23% (95% CI 96.93–99.08%), 74.45% (95% CI 69.95-78.60%), 86.38% (95% CI 83.76-88.72%), and 96.23% (95% CI 93.50-98.04%), respectively; For sight-threatening DR (STDR, severe non-proliferative DR or worse), the above indicators were 80.47% (95% CI 75.07-85.14%), 97.96% (95% CI 96.75-98.81%), 92.38% (95% CI 88.07-95.50%), and 94.23% (95% CI 92.46-95.68%); For referral DR (moderate non-proliferative DR or worse), the sensitivity and specificity were 92.96% (95% CI 90.66-94.84%) and 93.32% (95% CI 90.65-95.42%), with the PPV of 94.93% (95% CI 92.89-96.53%) and the NPV of 90.78% (95% CI 87.81-93.22%). The kappa score of EyeWisdom V1 was 0.860 (0.827-0.890) with the AUC of 0.958 for referral DR. Conclusion: The EyeWisdom V1 could provide reliable DR grading and referral recommendation based on the fundus images of diabetics. Copyright © 2022 Zhang, Li, Wei, Ding, Meng, Wang, Zhao and Chen.",artificial intelligence; diabetic retinopathy; eye wisdom V1; sensitivity; specificity; validation
Conference Paper,"Lazuardi R.N., Abiwinanda N., Suryawan T.H., Hanif M., Handayani A.",Automatic diabetic retinopathy classification with efficientnet,"IEEE Region 10 Annual International Conference, Proceedings/TENCON",2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85098978516&doi=10.1109%2fTENCON50793.2020.9293941&partnerID=40&md5=1c905080722fe25b284baf37aa43de0f,"Using the recent known EfficientNet architecture of deep convolutional neural network (CNN), we present an automatic detection of diabetic retinopathy (DR) from given retinal images. We experiment with subsets of the Kaggle diabetic retinopathy dataset consisting of retinal images with varied diagnostic quality. To address the quality variation, we incorporate two preprocessing steps, i.e. contrast limited adaptive histogram equalization (CLAHE) and image central cropping. We trained EfficientNet-B4 and EfficientNet-B5 model on two Kaggle subsets with different class proportions. In this paper, we propose an automatic early diagnosis of diabetic retinopathy which gained 0.7922 / 83.87% and 0.7931 / 83.89% of quadratic weight kappa and accuracy score on EfficientNet-B4 and EfficientNet-B5 respectively. © 2020 IEEE.",Classification Task; Deep Learning; Diabetic Retinopathy; Progressive Resizing
Article,"Tang M.C.S., Teoh S.S., Ibrahim H., Embong Z.",Neovascularization detection and localization in fundus images using deep learning,Sensors,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85112641391&doi=10.3390%2fs21165327&partnerID=40&md5=3dcd82b9526abb17a3a7fec1c44c0e13,"Proliferative Diabetic Retinopathy (PDR) is a severe retinal disease that threatens diabetic patients. It is characterized by neovascularization in the retina and the optic disk. PDR clinical features contain highly intense retinal neovascularization and fibrous spreads, leading to visual distortion if not controlled. Different image processing techniques have been proposed to detect and diagnose neovascularization from fundus images. Recently, deep learning methods are getting popular in neovascularization detection due to artificial intelligence advancement in biomedical image processing. This paper presents a semantic segmentation convolutional neural network architecture for neovascularization detection. First, image pre-processing steps were applied to enhance the fundus images. Then, the images were divided into small patches, forming a training set, a validation set, and a testing set. A semantic segmentation convolutional neural network was designed and trained to detect the neovascularization regions on the images. Finally, the network was tested using the testing set for performance evaluation. The proposed model is entirely automated in detecting and localizing neovascularization lesions, which is not possible with previously published methods. Evaluation results showed that the model could achieve accuracy, sensitivity, specificity, precision, Jaccard similarity, and Dice similarity of 0.9948, 0.8772, 0.9976, 0.8696, 0.7643, and 0.8466, respectively. We demonstrated that this model could outperform other convolutional neural network models in neovascularization detection. © 2021 by the authors. Licensee MDPI, Basel, Switzerland.",Computer-aided diagnosis; Convolutional neural network; Deep learning; Diabetic retinopathy; Neovascularization detection
Article,"Qiao L., Zhu Y., Zhou H.",Diabetic Retinopathy Detection Using Prognosis of Microaneurysm and Early Diagnosis System for Non-Proliferative Diabetic Retinopathy Based on Deep Learning Algorithms,IEEE Access,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85086803440&doi=10.1109%2fACCESS.2020.2993937&partnerID=40&md5=d4eefa54dd1446be3ce37d0568a997b5,"Predicting the presence of Microaneurysms in the fundus images and the identification of diabetic retinopathy in early-stage has always been a major challenge for decades. Diabetic Retinopathy (DR) is affected by prolonged high blood glucose level which leads to microvascular complications and irreversible vision loss. Microaneurysms formation and macular edema in the retinal is the initial sign of DR and diagnosis at the right time can reduce the risk of non proliferated diabetic retinopathy. The rapid improvement of deep learning makes it gradually become an efficient technique to provide an interesting solution for medical image analysis problems. The proposed system analysis the presence of microaneurysm in fundus image using convolutional neural network algorithms that embeds deep learning as a core component accelerated with GPU(Graphics Processing Unit) which will perform medical image detection and segmentation with high-performance and low-latency inference. The semantic segmentation algorithm is utilized to classify the fundus picture as normal or infected. Semantic segmentation divides the image pixels based on their common semantic to identify the feature of microaneurysm. This provides an automated system that will assist ophthalmologists to grade the fundus images as early NPDR, moderate NPDR, and severe NPDR. The Prognosis of Microaneurysm and early diagnosis system for non-proliferative diabetic retinopathy system has been proposed that is capable to train effectively a deep convolution neural network for semantic segmentation of fundus images which can increase the efficiency and accuracy of NPDR (non proliferated diabetic retinopathy) prediction. © 2020 IEEE.",deep convolution neural network; diabetic retinopathy; Microaneurysm; non proliferated diabetic retinopathy; semantic segmentation
Conference Paper,"Kwasigroch A., Jarzembinski B., Grochowski M.",Deep CNN based decision support system for detection and assessing the stage of diabetic retinopathy,"2018 International Interdisciplinary PhD Workshop, IIPhDW 2018",2018,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050030542&doi=10.1109%2fIIPHDW.2018.8388337&partnerID=40&md5=fc3fe8a1f5e906c27726812d64e2e010,"The diabetic retinopathy is a disease caused by long-standing diabetes. Lack of effective treatment can lead to vision impairment and even irreversible blindness. The disease can be diagnosed by examining digital color fundus photographs of retina. In this paper we propose deep learning approach to automated diabetic retinopathy screening. Deep convolutional neural networks (CNN) - the most popular kind of deep learning algorithms - enjoyed great success in the field of image analysis and recognition. Therefore, we leverage CNN networks to diagnose the diabetic retinopathy and its current stage, based on analysis of the photographs of retina. The utilized models were trained using dataset containing over 88000 retina photographs, labeled by specialist clinicians. To enhance the performance of the system, we proposed a special class coding technique that enabled to include the information about value of difference between predicted score and target score into the objective function being minimized during the neural networks training. To evaluate classification ability of employed models we used standard accuracy metrics and quadratic weighted Kappa score that is calculated between the predicted scores and scores provided in the dataset. The best tested model achieved an accuracy of about 82% in detecting the retinopathy and 51% in assessing its stage. Moreover, system obtained decent Kappa score equal 0.776. Achieved results showed that deep learning algorithms can be successfully employed to solve this very hard to analyze problem. © 2018 IEEE.",convolutional neural networks; deep learning; diabetic retinopathy; machine learning
Article,"Zhang G., Li K., Chen Z., Sun L., Zhang J., Pan X.",Augmentation-Consistent Clustering Network for Diabetic Retinopathy Grading with Fewer Annotations,Journal of Healthcare Engineering,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85127723322&doi=10.1155%2f2022%2f4246239&partnerID=40&md5=2cac2cb3b588bf24d27a9b91dd144118,"Diabetic retinopathy (DR) is currently one of the severe complications leading to blindness, and computer-aided, diagnosis technology-assisted DR grading has become a popular research trend especially for the development of deep learning methods. However, most deep learning-based DR grading models require a large number of annotations to provide data guidance, and it is laborious for experts to find subtle lesion areas from fundus images, making accurate annotation more expensive than other vision tasks. In contrast, large-scale unlabeled data are easily accessible, becoming a potential solution to reduce the annotating workload in DR grading. Thus, this paper explores the internal correlations from unknown fundus images assisted by limited labeled fundus images to solve the semisupervised DR grading problem and proposes an augmentation-consistent clustering network (ACCN) to address the above-mentioned challenges. Specifically, the augmentation provides an efficient cue for the similarity information of unlabeled fundus images, assisting the supervision from the labeled data. By mining the consistent correlations from augmentation and raw images, the ACCN can discover subtle lesion features by clustering with fewer annotations. Experiments on Messidor and APTOS 2019 datasets show that the ACCN surpasses many state-of-the-art methods in a semisupervised manner. © 2022 Guanghua Zhang et al.","Computer aided diagnosis; Computer aided instruction; Deep learning; Grading; Clustering networks; Diabetic retinopathy; Diabetic retinopathy grading; Diagnosis technology; Fundus image; Grading model; Large-scales; Learning methods; Research trends; Semi-supervised; Eye protection; Article; augmentation consistent clustering network; classification algorithm; clustering algorithm; computer assisted diagnosis; convolutional neural network; deep learning; diabetic retinopathy; diagnostic accuracy; diagnostic test accuracy study; eye fundus; false positive result; human; image analysis; intermethod comparison; nonproliferative diabetic retinopathy; proliferative diabetic retinopathy; receiver operating characteristic; residual neural network; retina image; semi supervised machine learning; sensitivity and specificity; cluster analysis; computer assisted diagnosis; diabetes mellitus; diabetic retinopathy; diagnostic imaging; workload; Cluster Analysis; Diabetes Mellitus; Diabetic Retinopathy; Diagnosis, Computer-Assisted; Fundus Oculi; Humans; Workload"
Conference Paper,"Shen Y., Fang R., Sheng B., Dai L., Li H., Qin J., Wu Q., Jia W.",Multi-task fundus image quality assessment via transfer learning and landmarks detection,Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),2018,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85054520055&doi=10.1007%2f978-3-030-00919-9_4&partnerID=40&md5=3f9c59a77dd87b03b769aa719e3d818e,"The quality of fundus images is critical for diabetic retinopathy diagnosis. The evaluation of fundus image quality can be affected by several factors, including image artifact, clarity, and field definition. In this paper, we propose a multi-task deep learning framework for automated assessment of fundus image quality. The network can classify whether an image is gradable, together with interpretable information about quality factors. The proposed method uses images in both rectangular and polar coordinates, and fine-tunes the network from trained model grading of diabetic retinopathy. The detection of optic disk and fovea assists learning the field definition task through coarse-to-fine feature encoding. The experimental results demonstrate that our framework outperform single-task convolutional neural networks and reject ungradable images in automated diabetic retinopathy diagnostic systems. © Springer Nature Switzerland AG 2018.",Fovea detection; Fundus image quality assessment; Multi-task learning; Optic disk detection
Conference Paper,"Di Giammarco M., Iadarola G., Martinelli F., Mercaldo F., Santone A.",Explainable Retinopathy Diagnosis and Localisation by means of Class Activation Mapping,Proceedings of the International Joint Conference on Neural Networks,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85140801375&doi=10.1109%2fIJCNN55064.2022.9891978&partnerID=40&md5=6bf3369e4cd101e10267336c21fbe2e2,"Diabetic retinopathy is a disease afflicting the retina and currently is manually diagnosed by specialists through eye tomography inspection. In order to assist the clinician in this time-consuming task, in this paper, we propose a method aimed to automatically diagnose the (proliferative and non-proliferative) diabetic retinopathy by exploiting deep learning. Furthermore, we investigate the possibility to automatically localise the areas related to the disease by exploiting class activation maps. We evaluate different deep learning models from a quantitative point of view (i.e, using metrics like accuracy, precision and recall) and a qualitative point of view (by exploiting class activation maps and image similarity metrics) with the aim to understand the quality of predictions performed by a model in retinopathy diagnosis, reducing the amount of knowledge required to assess the model performance. From the experimental analysis is emerging that deep learning shows an interesting diagnostic potential in the retinopathy disease localisation and can effectively help the clinician in retinopathy diagnosis. Moreover, the adoption of the class activation maps and its comparison evaluation can help the developers to debug the training step of the model without medical expertise. © 2022 IEEE.",classification; deep learning; diagnosis; retinopathy; transfer learning
Conference Paper,"Jiwani N., Gupta K., Afreen N.",A Convolutional Neural Network Approach for Diabetic Retinopathy Classification,"Proceedings - 2022 IEEE 11th International Conference on Communication Systems and Network Technologies, CSNT 2022",2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85133124960&doi=10.1109%2fCSNT54456.2022.9787577&partnerID=40&md5=8e9602b0723dde00541ea1c3aa146e50,"Diabetic Retinopathy (DR) is a kind of problem which affects diabetic patients, particularly those at their age of working, and can result in vision impairment and possibly irreversible blindness. For diagnosis and to prevent blindness or degeneration, early detection is critical. When ophthalmologists execute the diagnosis step of DR manually, it takes more time, effort, and money, and there are more possibility of misdiagnosis. The scientific community is focusing on developing a computer-aided recognition system for early identification and grading of DR severity. Ongoing AI research has highlighted the growth of the deep learning technique, which is better technique for doing medical image analysis and classification. © 2022 IEEE.",Convolutional Neural Network; Deep Learning; Diabetic Retinopathy; IDRiD dataset
Article,"Toledo-Cortés S., Useche D.H., Müller H., González F.A.",Grading diabetic retinopathy and prostate cancer diagnostic images with deep quantum ordinal regression,Computers in Biology and Medicine,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85128165660&doi=10.1016%2fj.compbiomed.2022.105472&partnerID=40&md5=c5d6006248ef0fc3951892e3e53a231f,"Although for many diseases there is a progressive diagnosis scale, automatic analysis of grade-based medical images is quite often addressed as a binary classification problem, missing the finer distinction and intrinsic relation between the different possible stages or grades. Ordinal regression (or classification) considers the order of the values of the categorical labels and thus takes into account the order of grading scales used to assess the severity of different medical conditions. This paper presents a quantum-inspired deep probabilistic learning ordinal regression model for medical image diagnosis that takes advantage of the representational power of deep learning and the intrinsic ordinal information of disease stages. The method is evaluated on two different medical image analysis tasks: prostate cancer diagnosis and diabetic retinopathy grade estimation on eye fundus images. The experimental results show that the proposed method not only improves the diagnosis performance on the two tasks but also the interpretability of the results by quantifying the uncertainty of the predictions in comparison to conventional deep classification and regression architectures. The code and datasets are available at https://github.com/stoledoc/DQOR. © 2022",Deep probabilistic learning; Density matrices; Diabetic retinopathy; Eye fundus images; Histopathology images; Ordinal regression; Prostate cancer; Quantum measurement; Uncertainty quantification
Article,"Thomas G.A.S., Robinson Y.H., Julie E.G., Shanmuganathan V., Rho S., Nam Y.",Intelligent prediction approach for diabetic retinopathy using deep learning based convolutional neural networks algorithm by means of retina photographs,"Computers, Materials and Continua",2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097150092&doi=10.32604%2fcmc.2020.013443&partnerID=40&md5=04835909089563670783d3b6e594789c,"Retinopathy is a human eye disease that causes changes in retinal blood vessels that leads to bleed, leak fluid and vision impairment. Symptoms of retinopathy are blurred vision, changes in color perception, red spots, and eye pain and it cannot be detected with a naked eye. In this paper, a new methodology based on Convolutional Neural Networks (CNN) is developed and proposed to intelligent retinopathy prediction and give a decision about the presence of retinopathy with automatic diabetic retinopathy screening with accurate diagnoses. The CNN model is trained by different images of eyes that have retinopathy and those which do not have retinopathy. The fully connected layers perform the classification process of the images from the dataset with the pooling layers minimize the coherence among the adjacent layers. The feature loss factor increases the label value to identify the patterns with the kernel-based matching. The performance of the proposed model is compared with the related methods of DREAM, KNN, GD-CNN and SVM. Experimental results show that the proposed CNN performs better. © 2021 Tech Science Press. All rights reserved.",Convolutional neural networks; Dental diagnosis; Diabetic retinopathy detection; Image recognition
Article,"Haggag S., Elnakib A., Sharafeldeen A., Elsharkawy M., Khalifa F., Farag R.K., Mohamed M.A., Sandhu H.S., Mansoor W., Sewelam A., El-Baz A.",A Computer-Aided Diagnostic System for Diabetic Retinopathy Based on Local and Global Extracted Features,Applied Sciences (Switzerland),2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137329778&doi=10.3390%2fapp12168326&partnerID=40&md5=7b80613f12990a93db62ab9f1c7c8132,"Featured Application: This paper presents a novel deep learning system for the detection and diagnosis of diabetic retinopathy using optical coherence tomography images. Diabetic retinopathy (DR) is a major public health problem and the leading cause of vision loss in the working age population. This paper presents a novel deep learning system for the detection and diagnosis of DR using optical coherence tomography (OCT) images. The input for this system is three-channel local and global information from OCT images. The local high-level information is represented by the thickness channel and the reflectivity channel. The global low-level information is represented by the grey-level OCT original image. The deep learning system processes the three-channel input to produce the final DR diagnoses. Experimental results on 200 OCT images, augmented to 800 images, which are collected by the University of Louisville, show high system performance related to other competing methods. Moreover, 10-fold and leave-one-subject-out (LOSO) experiments are performed to confirm how significant using the fused images is in improving the performance of the diagnoses, by investigating four different CNN architectures. All of the four architectures achieve acceptable performance and confirm a significant performance improvement using the fused images. Using LOSO, the best network performance has improved from 90.1 ± 2% using only the grey level dataset to 97.7 ± 0.5% using the proposed fused dataset. These results confirm the promise of using the proposed system for the detection of DR using OCT images. © 2022 by the authors.",deep learning; diabetic retinopathy; high level information; low level information
Article,"Shaik N.S., Cherukuri T.K.",Lesion-aware attention with neural support vector machine for retinopathy diagnosis,Machine Vision and Applications,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85117318617&doi=10.1007%2fs00138-021-01253-y&partnerID=40&md5=ed85f86473a36f12037335741e5a7d8b,"Diabetic retinopathy (DR) is a severe eye disease which can lead to permanent blindness. Identifying DR in early stages by using computer-aided diagnosis (CAD) systems can help the ophthalmologists to give proper treatment rationally, there by preventing many people from going blind. Due to intra-class variations and imbalanced data distribution, it is highly difficult to design a CAD system for DR severity diagnosis with greater generalizability. In this article, we propose a multi-stage deep learning pipeline, lesion-aware attention with neural support vector machine, for diabetic retinopathy diagnosis. Proposed pipeline consists of a pre-trained convolution base for learning retinal image spatial representations, lesion-aware attention for weighting lesion specific features, convolution autoencoder for learning latent attention representations and a neural support vector machine for discrimination. Convolutional autoencoder and neural support vector machine are jointly trained in end-to-end fashion to obtain category based lesion specific latent attention features by complementing each other in re-constructor and discriminator paths. Proposed approach is validated using two benchmark retinal scan image datasets, Kaggle APTOS 2019 and ISBI 2018 IDRiD, for DR type and severity grade classification tasks. Our experimental studies expose that using lesion-aware attention along with the joint training of autoencoder and neural support vector machine boosted the performance of models used for DR diagnosis, thereby outperforming existing works presented in the literature for DR severity grading. Proposed model achieved the highest accuracy of 90.45%, 84.31% on APTOS dataset and an accuracy of 79.85%, 63.24% on IDRiD dataset for DR type and severity grade classification tasks, respectively. © 2021, The Author(s), under exclusive licence to Springer-Verlag GmbH Germany, part of Springer Nature.",Convolutional autoencoder; Diabetic retinopathy (DR); Extreme inception (Xception); Lesion-aware attention; Neural support vector machine; Pre-trained convolution neural networks (CNNs); Transfer learning
Conference Paper,"Si J., Zhang Y., Hu S., Sun L., Li S., Yang H., Li X., Wang Y.",Comparison of LVQ and BP neural network in the diagnosis of diabetes and retinopathy,Communications in Computer and Information Science,2018,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053994890&doi=10.1007%2f978-981-13-2206-8_37&partnerID=40&md5=c244a8f687c869b2023d2a90bc26baba,"Diabetes Mellitus is a chronic, non-infectious disease that affects people’s health, which has a rapid onset trend with the continuous improvement of China’s economy and material life. At present, there is no practical solution to this condition. Diabetic retinopathy (DR) is the most important manifestation of diabetic microangiopathy, which can be divided into proliferative lesion and non-proliferative lesion. The traditional artificial diagnosis method has strong subjectivity and low accuracy. Because disease diagnosis can be regarded as a two-classification pattern recognition problem, the application of neural network method can provide the possibility for the application of artificial intelligence (AI) in disease-assisted diagnosis and treatment. Furthermore, it has significant meanings to find which kind of neural network has a better efficiency. In this paper, learning vector quantization (LVQ) neural network and back propagation (BP) neural network were used to diagnose diabetes and diabetic retinopathy with MATLAB and their recognition rate were compared. The datasets of diabetes and diabetic retinopathy were available in the UCI database. The experiment results were analyzed to evaluate the efficiency of each neural network classifier. The results demonstrate that both LVQ neural network and BP neural network can classify the two datasets effectively. However, compared with the LVQ neural network, the average accuracy rate and sensitivity of the BP neural network is higher. © Springer Nature Singapore Pte Ltd. 2018.",Artificial intelligence; BP neural networks; Diabetes; LVQ neural network; Non-Proliferative diabetic retinopathy; Proliferative diabetic retinopathy; UCI database
Article,"Wang D., Wang L.",On OCT image classification via deep learning,IEEE Photonics Journal,2019,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85107027601&doi=10.1109%2fJPHOT.2019.2934484&partnerID=40&md5=8be8132686c146f7e38f8282b42bc2cb,"Computer-aided diagnosis of retinopathy is a research hotspot in the field of medical image classification. Diabetic macular edema (DME) and age-related macular degeneration (AMD) are two common ocular diseases that can result in partial or complete loss of vision. Optical coherence tomography imaging (OCT) is widely applied to the diagnosis of ocular diseases including DME and AMD. In this paper, an automatic method based on deep learning is proposed to detect AME and AMD lesions, in which two publicly available OCT datasets of retina were adopted and a network model with effective feature of reuse feature was applied to solve the problem of small datasets and enhance the adaptation to the difference of different datasets of the approach. Several network models with effective feature of reusable feature were compared and the transfer learning on networks with pre-trained models was realized. CliqueNet achieves better, classification results compared with other network models with a more than 0.98 accuracy and 0.99 of area under the curve (AUC) value finally. © 2019 Institute of Electrical and Electronics Engineers Inc.. All rights reserved.",Age-related macular degeneration automated diagnosis; Computer-aided diagnosis; Deep learning; Diabetic macular edema; Optical coherence tomography
Article,"Lalithadevi B., Krishnaveni S.",Detection of diabetic retinopathy and related retinal disorders using fundus images based on deep learning and image processing techniques: A comprehensive review,Concurrency and Computation: Practice and Experience,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85132615141&doi=10.1002%2fcpe.7032&partnerID=40&md5=0963afaa77be8c06de8d304f8ca2fc68,"Diabetes mellitus is a chronic disorder disease in which a person's body fails to adhere insulin produced by their pancreas or unable to segregate enough insulin due to harmonic imbalance. Diabetic people are suffering from eye disorders like diabetic retinopathy (DR), glaucoma and various diseases such as neuropathy, nephropathy, cardiomyopathy over long intervals. One of the most prevalent diabetic consequence is DR. Detecting the morphological variations in retina is difficult and requires an effective automated detection system. DR can be predicted in earlier stage using tremendous development of deep learning models and image processing techniques. Recently, many research articles have been published in DR diagnosis system. This article shows a comprehensive review of automated diagnostic methods for DR detection and other related eye disorders from several points: Causes for DR, publicly available datasets, image preprocessing, segmentation of various DR lesions, feature optimization, various deep learning models, and open research challenges. The study offers a thorough overview of DR detection techniques, which delivers valuable information for researchers, medical professionals, and DR affected patients. © 2022 John Wiley & Sons, Ltd.",deep learning; diabetes; diabetic retinopathy; fundus images; image processing; lesions
Article,"Jaiswal A.K., Tiwari P., Kumar S., Al-Rakhami M.S., Alrashoud M., Ghoneim A.",Deep Learning-Based Smart IoT Health System for Blindness Detection Using Retina Images,IEEE Access,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85105865857&doi=10.1109%2fACCESS.2021.3078241&partnerID=40&md5=4e13e39ea148910f8f29900736677583,"Deep Learning-based Smart Healthcare is getting so much attention due to real-time applicability in everyone life's, and It has obtained more attention with the convergence of IoT. Diabetic eye disease is the primary cause of blindness between working aged peoples. The major populated Asian countries such as India and China presently account for millions of people and at the verge of an eruption of diabetic inhabitants. These growing number of diabetic patients posed a major challenge among trained doctors to provide medical screening and diagnosis. Our goal is to leverage the deep learning techniques to automate the detection of blind spot in an eye and identify how severe the stage may be. In this paper, we propose an optimized technique on top of recently released pre-trained EfficientNet models for blindness identification in retinal images along with a comparative analysis among various other neural network models. Our fine-tuned EfficientNet-B5 based model evaluation follows the benchmark dataset of retina images captured using fundus photography during varied imaging stages and outperforms CNN and ResNet50 models. © 2013 IEEE.",CNN; Diabetic retinopathy; IoT; medical diagnosis; retina images
Conference Paper,"Spoorthi K.V., Rekha B.S.",Diabetic Retinopathy Prediction using Deep learning,"CSITSS 2021 - 2021 5th International Conference on Computational Systems and Information Technology for Sustainable Solutions, Proceedings",2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85125768955&doi=10.1109%2fCSITSS54238.2021.9683553&partnerID=40&md5=12931659827ccdadcee812f0a535f663,"Diabetic retinopathy(DR) is a problem in diabetic patients and one of the leading cause of blindness affecting the majority of people around the world. It can cause blindness if not diagnosed early. Due to the diversity and complexity of DR, identifying DR through tedious manual diagnosis is extremely difficult. Therefore, this paper focuses on classifying a certain set of fundus images into 4 stages using deep learning approach as a combination of Deep Convolutional Neural Networks (DCNN) and RNN-LSTM (RNN=Recurrent Neural Network, LSTM = Long Short-Term Memory). This approach automatically detects all the stages of DR. This combination extracts many features of fundus image. In total, approximately 2000 fundus images were used to form the combined model. This study demonstrates that the extraction of those features from fundus images using DCNN and RNN-LSTM has significantly improved the accuracy predicting the DR stages. © 2021 IEEE.",DCNN; DR; LSTM; NPDR; PDR; RNN
Conference Paper,"Chelaramani S., Gupta M., Agarwal V., Gupta P., Habash R.",Multi-task Learning for Fine-Grained Eye Disease Prediction,Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85081561199&doi=10.1007%2f978-3-030-41299-9_57&partnerID=40&md5=8d3bf4aa1811ccd7de21c0b7a87c3251,"Recently, deep learning techniques have been widely used for medical image analysis. While there exists some work on deep learning for ophthalmology, there is little work on multi-disease predictions from retinal fundus images. Also, most of the work is based on small datasets. In this work, given a fundus image, we focus on three tasks related to eye disease prediction: (1) predicting one of the four broad disease categories – diabetic retinopathy, age-related macular degeneration, glaucoma, and melanoma, (2) predicting one of the 320 fine disease sub-categories, (3) generating a textual diagnosis. We model these three tasks under a multi-task learning setup using ResNet, a popular deep convolutional neural network architecture. Our experiments on a large dataset of 40658 images across 3502 patients provides ∼86% accuracy for task 1, ∼67% top-5 accuracy for task 2, and ∼32 BLEU for the diagnosis captioning task. © 2020, Springer Nature Switzerland AG.",Convolutional Neural Networks; Deep learning; Diagnosis caption generation; Multi-task learning; Ophthalmology; Retinal imaging
Article,"Yang B., Li T., Xie H., Liao Y., Chen Y.-P.P.",Classification of Diabetic Retinopathy Severity Based on GCA Attention Mechanism,IEEE Access,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85122303145&doi=10.1109%2fACCESS.2021.3139129&partnerID=40&md5=2425bdf6e4d28ec96b7fb0a201d7a0d0,"Diabetic retinopathy (DR) is one of the major complications caused by diabetes and can lead to severe vision loss or even complete blindness if not diagnosed and treated in a timely manner. In this paper, a new feature map global channel attention mechanism (GCA) is proposed to solve the problem of the early detection of DR. In the GCA module, an adaptive one-dimensional convolution kernel size algorithm based on the dimension of the feature map is proposed and a deep convolutional neural network model for DR color medical image severity diagnosis named GCA-EfficientNet (GENet) is designed. The training process uses transfer learning techniques with a cosine annealing learning rate adjustment strategy. The image regions of interest of GENet are visualized using a heat map. The final accuracy, precision, sensitivity and specificity of the DR dataset of the Kaggle competition reached 0.956, 0.956, 0.956, and 0.989, respectively. A large number of experiment results show that GENet based on the GCA attention mechanism can more effectively extract lesion features and classify the severity of DR. © 2013 IEEE.",Attention mechanism; convolutional neural network; deep learning; diabetic retinopathy; medical images
Article,"Martinez-Murcia F.J., Ortiz A., Ramírez J., Górriz J.M., Cruz R.",Deep residual transfer learning for automatic diagnosis and grading of diabetic retinopathy,Neurocomputing,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85096187478&doi=10.1016%2fj.neucom.2020.04.148&partnerID=40&md5=8cfcdf0bd655a62a6f773a0c0fb92788,"Evaluation and diagnosis of retina pathology is usually made via the analysis of different image modalities that allow to explore its structure. The most popular retina image method is retinography, a technique that displays the fundus of the eye, including the retina and other structures. Retinography is the most common imaging method to diagnose retina diseases such as Diabetic Retinopathy (DB) or Macular Edema (ME). However, retinography evaluation to score the image according to the disease grade presents difficulties due to differences in contrast, brightness and the presence of artifacts. Therefore, it is mainly done via manual analysis; a time consuming task that requires a trained clinician to examine and evaluate the images. In this paper, we present a computer aided diagnosis tool that takes advantage of the performance provided by deep learning architectures for image analysis. Our proposal is based on a deep residual convolutional neural network for extracting discriminatory features with no prior complex image transformations to enhance the image quality or to highlight specific structures. Moreover, we used the transfer learning paradigm to reuse layers from deep neural networks previously trained on the ImageNet dataset, under the hypothesis that first layers capture abstract features than can be reused for different problems. Experiments using different convolutional architectures have been carried out and their performance has been evaluated on the MESSIDOR database using cross-validation. Best results were found using a ResNet50-based architecture, showing an AUC of 0.93 for grades 0 + 1, AUC of 0.81 for grade 2 and AUC of 0.92 for grade 3 labelling, as well as AUCs higher than 0.97 when considering a binary classification problem (grades 0 vs 3). © 2020",Convolutional neural network; Deep learning; Diabetic retinopathy; Residual learning; Retinography; Transfer learning
Article,"Hassan D., Gill H.M., Happe M., Bhatwadekar A.D., Hajrasouliha A.R., Janga S.C.",Combining transfer learning with retinal lesion features for accurate detection of diabetic retinopathy,Frontiers in Medicine,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85142213205&doi=10.3389%2ffmed.2022.1050436&partnerID=40&md5=4df2f0cd185793ecad0764e04f966845,"Diabetic retinopathy (DR) is a late microvascular complication of Diabetes Mellitus (DM) that could lead to permanent blindness in patients, without early detection. Although adequate management of DM via regular eye examination can preserve vision in in 98% of the DR cases, DR screening and diagnoses based on clinical lesion features devised by expert clinicians; are costly, time-consuming and not sufficiently accurate. This raises the requirements for Artificial Intelligent (AI) systems which can accurately detect DR automatically and thus preventing DR before affecting vision. Hence, such systems can help clinician experts in certain cases and aid ophthalmologists in rapid diagnoses. To address such requirements, several approaches have been proposed in the literature that use Machine Learning (ML) and Deep Learning (DL) techniques to develop such systems. However, these approaches ignore the highly valuable clinical lesion features that could contribute significantly to the accurate detection of DR. Therefore, in this study we introduce a framework called DR-detector that employs the Extreme Gradient Boosting (XGBoost) ML model trained via the combination of the features extracted by the pretrained convolutional neural networks commonly known as transfer learning (TL) models and the clinical retinal lesion features for accurate detection of DR. The retinal lesion features are extracted via image segmentation technique using the UNET DL model and captures exudates (EXs), microaneurysms (MAs), and hemorrhages (HEMs) that are relevant lesions for DR detection. The feature combination approach implemented in DR-detector has been applied to two common TL models in the literature namely VGG-16 and ResNet-50. We trained the DR-detector model using a training dataset comprising of 1,840 color fundus images collected from e-ophtha, retinal lesions and APTOS 2019 Kaggle datasets of which 920 images are healthy. To validate the DR-detector model, we test the model on external dataset that consists of 81 healthy images collected from High-Resolution Fundus (HRF) dataset and MESSIDOR-2 datasets and 81 images with DR signs collected from Indian Diabetic Retinopathy Image Dataset (IDRID) dataset annotated for DR by expert. The experimental results show that the DR-detector model achieves a testing accuracy of 100% in detecting DR after training it with the combination of ResNet-50 and lesion features and 99.38% accuracy after training it with the combination of VGG-16 and lesion features. More importantly, the results also show a higher contribution of specific lesion features toward the performance of the DR-detector model. For instance, using only the hemorrhages feature to train the model, our model achieves an accuracy of 99.38 in detecting DR, which is higher than the accuracy when training the model with the combination of all lesion features (89%) and equal to the accuracy when training the model with the combination of all lesions and VGG-16 features together. This highlights the possibility of using only the clinical features, such as lesions that are clinically interpretable, to build the next generation of robust artificial intelligence (AI) systems with great clinical interpretability for DR detection. The code of the DR-detector framework is available on GitHub at https://github.com/Janga-Lab/DR-detector and can be readily employed for detecting DR from retinal image datasets. Copyright © 2022 Hassan, Gill, Happe, Bhatwadekar, Hajrasouliha and Janga.",deep learning; Diabetic Retinopathy; lesion features; retinal image; transfer learning
Conference Paper,"Nasir N., Oswald P., Alshaltone O., Barneih F., Al Shabi M., Al-Shammaa A.",Deep DR: Detection of Diabetic Retinopathy using a Convolutional Neural Network,"2022 Advances in Science and Engineering Technology International Conferences, ASET 2022",2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85128433643&doi=10.1109%2fASET53988.2022.9734314&partnerID=40&md5=7c78c2800d04c7838e954c106b15d216,"Diabetic retinopathy (DR) is a consequence of diabetes that affects the back of the eye due to excessive blood sugar levels. If left misdiagnosed and untreated, it might result in blindness. Retinal screening aids in the early detection and treatment of DR. We created a deep learning model that can detect DR in its early to late stages to make the screening procedure easier. The proposed Convolutional Neural Network (CNN) model classifies between two classes i.e. the presence of DR or otherwise via an image-based dataset. Accuracy of up to 96% has been achieved. © 2022 IEEE.",AI; Convolutional Neural Network; Deep Learning; Diabetic Retinopathy; Python
Article,"Mathews M.R., Anzar S.M.",A comprehensive review on automated systems for severity grading of diabetic retinopathy and macular edema,International Journal of Imaging Systems and Technology,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85103419863&doi=10.1002%2fima.22574&partnerID=40&md5=f3067a08041511d6cc4de1493f604f0c,"Diabetes mellitus is a major medical concern worldwide. Long-term diabetes can affect the retina of the eye and lead to diabetic retinopathy (DR) and diabetic macular edema (DME). Proper screening and consultation with an ophthalmologist are necessary to prevent avoidable vision loss. As DR and DME have become more prevalent, automated screening is essential to provide cost-effective and rapid solutions with reduced human resources requirements. This paper aims to provide a comprehensive review of the literature on computer-aided diagnosis of DR and DME. We identified the studies on automated five-class grading of DR according to International Clinical Diabetic Retinopathy severity scale and three class grading of diabetic maculopathy, using fundus images. A systematic search on research repositories was conducted, and relevant studies were scrutinized and included in the review. The studies were reported in nearly 100 different journals. We have reviewed the studies in all aspects including datasets, preprocessing, non-deep learning, and deep learning-based algorithms, and evaluation metrics. Significant contributions in developing automated tools for DR/DME grading are highlighted. We have identified and discussed research gaps and challenges. This will help researchers to get an updated summary of work done in the area. Deep learning-based algorithms have outperformed the traditional algorithms in the domain. Despite their promising performance, these algorithms reveal the potential for significant improvements to become a reliable tool in clinical settings. © 2021 Wiley Periodicals LLC.",computer aided diagnosis; convolutional neural networks; deep learning; diabetic macular edema; diabetic retinopathy; image processing; retinal fundus imaging
Conference Paper,"Roychowdhury A., Banerjee S.",Random forests in the classification of diabetic retinopathy retinal images,Lecture Notes in Electrical Engineering,2018,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85048612281&doi=10.1007%2f978-981-10-8240-5_19&partnerID=40&md5=81adb5948e697e5c382f6950b5e81f6f,"This paper presents a machine learning classifier, namely, Random Forest to detect abnormalities in retina arising from Diabetic Retinopathy. This is an effort to obtain a computer-aided diagnosis procedure to substitute manual detection. Fundus images from public datasets are used for this purpose. A set of statistical and geometric features were extracted from images in the database which contains the different physical manifestations of the disease. Classification through machine learning can help a physician by giving an indication of the level of the disease. The experimental results show 99.275% of accuracy in prediction of the disease, which is promising. © Springer Nature Singapore Pte Ltd. 2018.",Cotton wool spots; Diabetic retinopathy; Hard exudates; Hemorrhages; Microaneurysm; Random forest classifier
Conference Paper,"Adriman R., Muchtar K., Maulina N.",Performance Evaluation of Binary Classification of Diabetic Retinopathy through Deep Learning Techniques using Texture Feature,Procedia Computer Science,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85101742038&doi=10.1016%2fj.procs.2020.12.012&partnerID=40&md5=977bf6c485adf9312081fde3b0f45898,"One of the main causes of loss of vision in diabetic patients is Diabetic retinopathy (DR). Automated methods are important medical applications for detecting and classifying the disease type into normal or abnormal ones. Fundus images are obtained from the retina using a retinal camera, one of a non-invasive diagnostic technique that offers a way of examining the retina in diabetes patients. We present in this paper a system for the detection and classification of DRs. Our approach is divided into two main steps: in the first step, we use local binary patterns (LBP) to extract texture features, while in the second stage, we analyze extensively the state-of-the-art deep learning techniques for the detection and classification tasks. ResNet, DenseNet, and DetNet are used as deep learning techniques. Preliminary results show that ResNet, DenseNet and DetNet can obtain 0,9635%, 0,8405% and 0,9399% of accuracy, respectively. In addition, we also evaluate the performance of each detection configuration. © 2021 Elsevier B.V.. All rights reserved.",Binary Classification; Deep Learning; Diabetic retinopathy; LBP
Conference Paper,"Siebert M., Tesmer N., Rostalski P.",Stochastic variational deep kernel learning based diabetic retinopathy severity grading,Current Directions in Biomedical Engineering,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137899793&doi=10.1515%2fcdbme-2022-1104&partnerID=40&md5=832150525203bb24dbd2573108aabc29,"The retinal disease Diabetic retinopathy (DR) is one of the most probable causes of blindness. Automatic detection of DR is mostly done using convolutional neural networks (CNNs) on colour retinal images. This work in contrast uses stochastic variational deep kernel learning (SVDKL) for DR grading, combining a deep CNN with Gaussian processes (GPs) into a single end-to-end trainable model, which promises to provide predictions with a reliable uncertainty estimate exploiting approximate Bayesian inference. Evaluating the performance and uncertainty calibration of SVDKL on DR grading compared to a plain CNN, the EfficientNet-B0, preliminary results on a subset of the Kaggle DR dataset show a naturally enhanced uncertainty calibration for SVDKL over the plain CNN as well as a good diagnostic performance. Despite SVDKL achieving a slightly reduced accuracy, incorrect predictions were in closer proximity to the target stages, which is beneficial for clinical diagnosis due to minimizing the cost related to severe misclassifications. © 2022 The Author(s), published by De Gruyter.",Deep kernel learning; Deep learning; Diabetic retinopathy; Medical image processing; Uncertainty quantification
Conference Paper,"Li Y., El Habib Daho M., Conze P.-H., Al Hajj H., Bonnin S., Ren H., Manivannan N., Magazzeni S., Tadayoni R., Cochener B., Lamard M., Quellec G.",Multimodal Information Fusion for Glaucoma and Diabetic Retinopathy Classification,Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85138757295&doi=10.1007%2f978-3-031-16525-2_6&partnerID=40&md5=31133f8445ca511240adcd3cbbf8cb4b,"Multimodal information is frequently available in medical tasks. By combining information from multiple sources, clinicians are able to make more accurate judgments. In recent years, multiple imaging techniques have been used in clinical practice for retinal analysis: 2D fundus photographs, 3D optical coherence tomography (OCT) and 3D OCT angiography, etc. Our paper investigates three multimodal information fusion strategies based on deep learning to solve retinal analysis tasks: early fusion, intermediate fusion, and hierarchical fusion. The commonly used early and intermediate fusion are simple but do not fully exploit the complementary information between modalities. We developed a hierarchical fusion approach that focuses on combining features across multiple dimensions of the network, as well as exploring the correlation between modalities. These approaches were applied to glaucoma and diabetic retinopathy classification, using the public GAMMA dataset (fundus photographs and OCT) and a private dataset of PLEX®Elite 9000 (Carl Zeis Meditec Inc.) OCT angiography acquisitions, respectively. Our hierarchical fusion method performed the best in both cases and paved the way for better clinical diagnosis. © 2022, The Author(s), under exclusive license to Springer Nature Switzerland AG.",Computer-aided diagnosis; Deep learning; Diabetic retinopathy classification; Glaucoma classification; Multimodal information fusion
Article,"Lahmar C., Idri A.",On the value of deep learning for diagnosing diabetic retinopathy,Health and Technology,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85116986540&doi=10.1007%2fs12553-021-00606-x&partnerID=40&md5=0a388e86c6b6b49bc1f026a6defbfa2d,"Diabetic retinopathy (DR) is one of the main causes of vision loss around the world. The early diagnosis of this disease can help in treating it efficiently. Deep learning (DL) is rapidly becoming the state of the art, leading to enhanced performance in various medical applications such as diabetic retinopathy and breast cancer. In this paper, we conduct an empirical evaluation of seven convolutional neural networks (CNN) architectures for an automatic binary classification of the referable diabetic retinopathy; the DL architectures (Inception_ResNet_V2, Inception_V3, ResNet50, VGG16, VGG19, MobileNet_V2 and DenseNet201) were evaluated and compared in terms of accuracy, sensitivity, specificity, precision and F1-score using the Scott Knott test and the Borda count voting method. All the empirical evaluations were over three datasets: APTOS, Kaggle DR and the Messidor-2, using a k-fold cross validation method. Experiments showed the importance of using deep learning in the classification of DR since the seven models gave a high accuracy values. Furthermore, DenseNet201 and mobileNet_V2 were the top two performing techniques respectively. DenseNet201 provided the best performance for the Kaggle and Messidor-2 datasets with an accuracy equal to 84.74% and 85.79% respectively. MobileNet_V2 provided the best performance in the APTOS dataset with an accuracy equal to 93.09%. As for the ResNet50, Inception_V3 and Inception_ResNet_V2, they were the worst performing compared to the other DL techniques. Therefore, we recommend the use of DenseNet201 and MobileNet_V2 for the detection of the referable DR since they provided the best performances on the three datasets. © 2021, IUPESM and Springer-Verlag GmbH Germany, part of Springer Nature.",Convolutional Neural Networks; Deep Learning; Diabetic Retinopathy; Medical Images
Article,"Zhang C., Lei T., Chen P.",Diabetic Retinopathy Grading by a Source-Free Transfer Learning Approach,Biomedical Signal Processing and Control,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85121307375&doi=10.1016%2fj.bspc.2021.103423&partnerID=40&md5=aad3e87688f301c05aa82a8b86b6ac3f,"Diabetic retinopathy (DR) gives rise to blindness in young adults around the world. By early detection, patients with DR can be properly treated in time, and the deterioration of DR can be prevented. Thus, early and accurate DR screening is critical for disease prognosis. However, traditional manual detection work is intensive and easy to cause misdiagnosis for large amounts of patients. In recent years, deep learning methods have achieved remarkable improvements in medical image analysis, making DR detection more reliable and efficient. Nevertheless, existing supervised learning and transfer learning methods require a great deal of labeled data, which is always not available in DR screening due to the challenges of medical annotating and privacy issues. To solve this problem, we design a Source-Free Transfer Learning (SFTL) method for referable DR detection, which utilizes unannotated retinal images and only employs source model throughout the training process. In this paper, we propose two major modules, namely, the target generation module and the collaborative consistency module. For the target generation module, it can produce target-style retinal images, trained by the inputting target data and source model. For the collaborative consistency module, the classification model is further optimized by the generated target-style images, which guides the generator to produce images with more accurate expression. Furthermore, a target reconstruction loss is attached on the generator to enhance the performance, and a feature consistency loss is introduced to make the target model not drift far away from the source model. To evaluate the effectiveness of the SFTL model, we have carried out extensive experiments on APTOS 2019 dataset with a source model from EyePACS dataset, and obtained an accuracy of 91.2%, a sensitivity of 0.951 and a specificity of 0.858, demonstrating that our proposed SFTL model is more competitive than other state-of-the-art supervised learning methods. © 2021 Elsevier Ltd",Diabetic Retinopathy Grading; Source Free; Target Generation; Transfer Learning
Article,"Rajkumar R.S., Grace Selvarani A.",Diabetic Retinopathy Diagnosis Using ResNet with Fuzzy Rough C-Means Clustering,Computer Systems Science and Engineering,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85122979434&doi=10.32604%2fCSSE.2022.021909&partnerID=40&md5=264db0f992798cf59b27b6dc93476bcc,"Diabetic Retinopathy (DR) is a vision disease due to the long-term prevalence of Diabetes Mellitus. It affects the retina of the eye and causes severe damage to the vision. If not treated on time it may lead to permanent vision loss in diabetic patients. Today’s development in science has no medication to cure Diabetic Retinopathy. However, if diagnosed at an early stage it can be controlled and permanent vision loss can be avoided. Compared to the diabetic population, experts to diagnose Diabetic Retinopathy are very less in particular to local areas. Hence an automatic computer-aided diagnosis for DR detection is necessary. In this paper, we propose an unsupervised clustering technique to automatically cluster the DR into one of its five development stages. The deep learning based unsupervised clustering is made to improve itself with the help of fuzzy rough c-means clustering where cluster centers are updated by fuzzy rough c-means clustering algorithm during the forward pass and the deep learning model representations are updated by Stochastic Gradient Descent during the backward pass of training. The proposed method was implemented using python and the results were taken on DGX server with Tesla V100 GPU cards. An experimental result on the publically available Kaggle dataset shows an overall accuracy of 88.7%. The proposed model improves the accuracy of DR diagnosis compared to the existing unsupervised algorithms like k-means, FCM, auto-encoder, and FRCM with alexnet. © 2021 CRL Publishing. All rights reserved.",Clustering; Diabetic retinopathy detection; Diabetic retinopathy diagnosis; Fuzzy rough c-means clustering; Unsupervised CNN
Conference Paper,"Rupashini P.R., Poonkodi R., Shadrach F.D., Anitha R., Esther Mary J., Nirmalan R.",Diabetic Retinopathy Detection Using Retinal Fundus Picture and Image Enhancement Using Fuzzy Clustering,"Proceedings of the 2022 International Conference on Innovative Computing, Intelligent Communication and Smart Electrical Systems, ICSES 2022",2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85141546470&doi=10.1109%2fICSES55317.2022.9914296&partnerID=40&md5=7810dfc8a2564e84dd0f28cfb5a3216c,"Patients with diabetes are more susceptible to developing diabetic retinopathy. Blindness can be caused by a disease and can be saved if early diabetic retinopathy detection is made. Retinal exudates and haemorrhages associated with diabetic retinopathy can be easily detected in fundus images due to their sensitivity to vascular disorders. Exudates and haemorrhages in retinal fundus images can now be easily and affordably detected, and diabetic retinopathy can be appropriately classified. The fundus image is clustered into different areas of interest using a k-means colour compression technique, which reduces the colour dimension. The region properties attributes were used to separate and categories the various components of the diabetic fundus. Finally, experiment and trial were used to identify diabetic retinopathy using the knowledge-based fuzzy inference system (FIS). FIS recognize diabetic retinopathy by utilizing the above-mentioned effective attributes and knowledge-based fuzzy inference system (FIS). A deep learning-based Efficient Net-based feature extractor is used to produce feature vectors from pre-processed photos. The MESSIDOR dataset is used for all trials, and the outcomes are evaluated using a range of criteria. The K-Means Clustering with Fuzzy Technique approach outperformed the competition in rapports of diagnostic accurateness. © 2022 IEEE.",diabetic; eye; Fundus image; fuzzy; k-means
Conference Paper,"Bajwa M.N., Taniguchi Y., Malik M.I., Neumeier W., Dengel A., Ahmed S.",Combining Fine- and Coarse-Grained Classifiers for Diabetic Retinopathy Detection,Communications in Computer and Information Science,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85079089071&doi=10.1007%2f978-3-030-39343-4_21&partnerID=40&md5=4f11afef37b39b7a66b594a06ece7b9c,"Visual artefacts of early diabetic retinopathy in retinal fundus images are usually small in size, inconspicuous, and scattered all over retina. Detecting diabetic retinopathy requires physicians to look at the whole image and fixate on some specific regions to locate potential biomarkers of the disease. Therefore, getting inspiration from ophthalmologist, we propose to combine coarse-grained classifiers that detect discriminating features from the whole images, with a recent breed of fine-grained classifiers that discover and pay particular attention to pathologically significant regions. To evaluate the performance of this proposed ensemble, we used publicly available EyePACS and Messidor datasets. Extensive experimentation for binary, ternary and quaternary classification shows that this ensemble largely outperforms individual image classifiers as well as most of the published works in most training setups for diabetic retinopathy detection. Furthermore, the performance of fine-grained classifiers is found notably superior than coarse-grained image classifiers encouraging the development of task-oriented fine-grained classifiers modelled after specialist ophthalmologists. © 2020, Springer Nature Switzerland AG.",Automated diabetic retinopathy detection; Computer-aided diagnosis; Convolutional neural network; Deep learning in ophthalmology; Medical image analysis
Article,"Li T., Gao Y., Wang K., Guo S., Liu H., Kang H.",Diagnostic assessment of deep learning algorithms for diabetic retinopathy screening,Information Sciences,2019,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85068496728&doi=10.1016%2fj.ins.2019.06.011&partnerID=40&md5=89f1fae17764714ca442fc28d23c6819,"Diabetic retinopathy (DR), the leading cause of blindness for working-age adults, is generally intervened by early screening to reduce vision loss. A series of automated deep-learning-based algorithms for DR screening have been proposed and achieved high sensitivity and specificity (> 90%). However, these deep learning models do not perform well in clinical applications due to the limitations of the existing publicly available fundus image datasets. In order to evaluate these methods in clinical situations, we collected 13,673 fundus images from 9598 patients. These images were divided into six classes by seven graders according to image quality and DR level. Moreover, 757 images with DR were selected to annotate four types of DR-related lesions. Finally, we evaluated state-of-the-art deep learning algorithms on collected images, including image classification, semantic segmentation and object detection. Although we obtain an accuracy of 0.8284 for DR classification, these algorithms perform poorly on lesion segmentation and detection, indicating that lesion segmentation and detection are quite challenging. In summary, we are providing a new dataset named DDR for assessing deep learning models and further exploring the clinical applications, particularly for lesion recognition. © 2019 Elsevier Inc.",Deep learning; Diabetic retinopathy; Fundus image; Image classification; Semantic segmentation
Article,Alahmadi M.D.,Texture Attention Network for Diabetic Retinopathy Classification,IEEE Access,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85130797226&doi=10.1109%2fACCESS.2022.3177651&partnerID=40&md5=5e22cb584d3330d27863f1a1e24faed3,"Diabetic Retinopathy (DR) is a disease caused by a high level of glucose in retina vessels. This malicious disease put millions of people around the world at risk for vision loss each year. Being a life-threatening disease, early diagnosis can be an effective step in the treatment and prevention of vision loss. To automate the early diagnosis process, computer-aided diagnosis methods are not only useful in detecting the diabetic signatures but also provide information regarding the diabetic grade for the optometrist to determine an appropriate treatment. Several deep classification models are proposed in the literature to solve the diabetic retinopathy classification task, however, these methods usually lack incorporate an attention mechanism to better encode the semantic dependency and highlight the most important region for boosting the model performance. To overcome these limitations, we propose to incorporate a style and content recalibration mechanism inside the deep neural network to adaptively scale the informative regions for diabetic retinopathy classification. In our proposed method, the input image passes through the encoder module to encode both high-level and semantic features. Next, by utilizing a content and style separation mechanism, we decompose the representational space into a style (e.g., texture features) and content (e.g., semantic and contextual features) representation. The texture attention module takes the style representation and applies a high-pass filter to highlight the texture information while the spatial normalization module uses a convolutional operation to determine the more informative region inside the retinopathy image to detect diabetic signs. Once the attention modules are applied to the representational features, the fusion module combines both features to form a normalized representation for the decoding path. The decoder module in our model performs both diabetic grading and healthy, non-healthy classification tasks. Our experiment on APTOS Kaggle dataset (accuracy 0.85) demonstrates a significant improvement compared to the literature work. This fact reveals the applicability of our method in a real-world scenario. © 2013 IEEE.",Attention; Classification; Deep learning; Diabetic retinopathy
Article,"Shankar K., Perumal E., Elhoseny M., Nguyen P.T.",An IoT-cloud based intelligent computer-aided diagnosis of diabetic retinopathy stage classification using deep learning approach,"Computers, Materials and Continua",2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097204164&doi=10.32604%2fcmc.2020.013251&partnerID=40&md5=c5f185fd0bc61dfca4df9a6d77144b85,"Diabetic retinopathy (DR) is a disease with an increasing prevalence and the major reason for blindness among working-age population. The possibility of severe vision loss can be extensively reduced by timely diagnosis and treatment. An automated screening for DR has been identified as an effective method for early DR detection, which can decrease the workload associated to manual grading as well as save diagnosis costs and time. Several studies have been carried out to develop automated detection and classification models for DR. This paper presents a new IoT and cloud-based deep learning for healthcare diagnosis of Diabetic Retinopathy (DR). The proposed model incorporates different processes namely data collection, preprocessing, segmentation, feature extraction and classification. At first, the IoT-based data collection process takes place where the patient wears a head mounted camera to capture the retinal fundus image and send to cloud server. Then, the contrast level of the input DR image gets increased in the preprocessing stage using Contrast Limited Adaptive Histogram Equalization (CLAHE) model. Next, the preprocessed image is segmented using Adaptive Spatial Kernel distance measure-based Fuzzy C-Means clustering (ASKFCM) model. Afterwards, deep Convolution Neural Network (CNN) based Inception v4 model is applied as a feature extractor and the resulting feature vectors undergo classification in line with the Gaussian Naive Bayes (GNB) model. The proposed model was tested using a benchmark DR MESSIDOR image dataset and the obtained results showcased superior performance of the proposed model over other such models compared in the study. © 2021 Tech Science Press. All rights reserved.",Classification; Deep learning; Diabetic retinopathy; Feature extraction; GaussianNaive Bayes
Conference Paper,"Chen S., Wang Z., Yao B., Liu T.",Prediction of Diabetic Retinopathy Using Longitudinal Electronic Health Records,IEEE International Conference on Automation Science and Engineering,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85141692465&doi=10.1109%2fCASE49997.2022.9926605&partnerID=40&md5=b9a5ffad8480b028f8e7bcc54d4bdacb,"Diabetic retinopathy (DR) is a microvascular complication of diabetes and is a leading cause of vision loss and blindness. Screening and early detection of DR is critical but current screening methods rely on eye care experts and expensive medical equipment, which are not available in medically underserved communities. The non-image-based, machine-learning approach in this study aims to detect DR in the early stage using demographics, comorbidities, and routine lab results data, which are widely available for diabetic patients. We develop different temporal deep learning models to analyze a real-world, large-scale dataset and compare performances of these models. Experimental results show that temporal models outperform baseline random forest models in metrics of AUPRC and recall. © 2022 IEEE.",diabetic retinopathy prediction; longitudinal EHR data; LSTM; temporal convolutional network
Conference Paper,"Jiwane V., DattaGupta A., Chauhan A., Patil V.",Detecting Diabetic Retinopathy Using Deep Learning Technique with Resnet-50,Lecture Notes in Electrical Engineering,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85119893510&doi=10.1007%2f978-981-16-3690-5_5&partnerID=40&md5=1e2f407dc50625650ee2e65d51b1d6b6,"Diabetes mellitus, also known as diabetes, is a metabolic disease which may cause high blood sugar, blurred vision and several other complications. Patients already suffering from diabetes have a greater probability to develop Diabetic Retinopathy. Most prominently in the blood vessels of the tissue residing in the rear portion of the eye gets damaged causing vision problems. This disease is especially prevalent in India. Test for Diabetic Retinopathy involves a dilated eye exam, which is time consuming and requires specialized doctors and distinct equipment which may not be easily accessible to the people especially in rural areas. Predicting the possibility of Diabetic Retinopathy utilizing fundus image is considered an effectual analysis subject by many. In this paper a method is explored to diagnose Diabetic Retinopathy using fundus images and deep learning to accurately tell the patient whether he has a Diabetic Retinopathy. Features used from the eye fundus images are soft exudate and hard exudate along with optic disc. A website is also made to deploy the model and promote mass diagnosis at a faster pace. © 2022, The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd.",Deep learning; Fundus images; Image processing; ResNet
Conference Paper,"Madala S., Suvarna V.K., Jalapally P.",Framework for Diabetic Retinopathy Classification,"Smart Innovation, Systems and Technologies",2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85128945286&doi=10.1007%2f978-981-16-9669-5_4&partnerID=40&md5=803bcf8c12fe54bd90f5109274cd85d2,"Diabetic retinopathy (DR) is a severe complication of eyes found in the diabetic patients. It is the main cause of loss of vision among them, and it progresses with the duration of the disease. Commonly, the diagnosis will be done by an ophthalmologist. But, the huge number of patients especially in the rural areas has a limited number of ophthalmologists that need to screen and review the images to properly diagnose the disease. If the number of out-patients are high, the doctor will be inclined to spend less amount of time for each patient. Automatic detection of diabetic retinopathy from the astronomically immense scale of retinal images avails the ophthalmologist to treat the affected patient and reduce chances of vision loss, developing an automated diagnosis software based on latest deep learning techniques. We have developed a framework for classification of features in the fundus images for the data sets IDRiD, Messidor, Diaret_db0 based on disease criticality. The GUI takes the retina images data set as the input. It pre-processes the images and does the features extraction. The extracted retinal features are helpful for the accurate diagnosis of DR. Based on these features, we can classify the criticality level of the disease of each image. © 2022, The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd.",Classification; Diabetic retinopathy; Morphological operations
Conference Paper,"Mahadevaswamy U.B., Harshitha T.",Adaptive Prediction and Classification of Diabetic Retinopathy Using Machine Learning,MysuruCon 2022 - 2022 IEEE 2nd Mysore Sub Section International Conference,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85145355371&doi=10.1109%2fMysuruCon55714.2022.9972593&partnerID=40&md5=74ac3e882606aac13a05dfb3693e7bed,"Diabetic Retinopathy (DR) is a eye deformity causes due to chronic diabetes, and it is the root cause condition. Diabetic retinopathy does not display the early symptoms because internal bleeding may occur in the retina triggered by microaneurysms (MA) leading to the major reason for blindness earlier the age of 50. The medical images obtained using the diagnostic machines helps in accurate diagnosis and precise delivery of the treatment. Image Processing has a significance disease detection on medical images. The disease recognizing and classifying approaches are specific in human organs and image type. One of such a disease classes includes detecting of retinal disease such as diabetic detection. The objective of proposed project is to develop an algorithm which analyses the disease pattern and accurate diagnosis of disease. The convolution neural network is exploited for deep learning and retina images are classified into few categories using SVM. The algorithm used a total of 35,925 images obtained from Iweid. The proposed model achieves Accuracy of 97% which are better compared to existing work. © 2022 IEEE.",classification; Diabetic retinopathy; feature selection; Image Processing; machine learning
Conference Paper,"Beede E., Baylor E., Hersch F., Iurchenko A., Wilcox L., Ruamviboonsuk P., Vardoulakis L.M.",A Human-Centered Evaluation of a Deep Learning System Deployed in Clinics for the Detection of Diabetic Retinopathy,Conference on Human Factors in Computing Systems - Proceedings,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85088537429&doi=10.1145%2f3313831.3376718&partnerID=40&md5=377546d227e7db3c0b571f904b579213,"Deep learning algorithms promise to improve clinician workflows and patient outcomes. However, these gains have yet to be fully demonstrated in real world clinical settings. In this paper, we describe a human-centered study of a deep learning system used in clinics for the detection of diabetic eye disease. From interviews and observation across eleven clinics in Thailand, we characterize current eye-screening workflows, user expectations for an AI-assisted screening process, and post-deployment experiences. Our findings indicate that several socio-environmental factors impact model performance, nursing workflows, and the patient experience. We draw on these findings to reflect on the value of conducting human-centered evaluative research alongside prospective evaluations of model accuracy. © 2020 Owner/Author.",deep learning; diabetes; health; human-centered ai
Conference Paper,"Roshan S.M., Karsaz A., Vejdani A.H., Roshan Y.M.",Fine-tuning of pre-trained convolutional neural networks for diabetic retinopathy screening: A clinical study,International Journal of Computational Science and Engineering,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85084282964&doi=10.1504%2fIJCSE.2020.106869&partnerID=40&md5=80517d93ff91a80eb465e453f3c6fd50,"Diabetic retinopathy is a serious complication of diabetes, and if not controlled, may cause blindness. Automated screening of diabetic retinopathy helps physicians to diagnose and control the disease in early stages. In this paper, two case studies are proposed, each on a different dataset. Firstly, automatic screening of diabetic retinopathy utilising pre-trained convolutional neural networks was employed on the Kaggle dataset. The reason for using pre-trained networks is to save time and resources during training compared to fully training a convolutional neural network. The proposed networks were fine-tuned for the pre-processed dataset, and the selectable parameters of the fine-tuning approach were optimised. At the end, the performance of the fine-tuned network was evaluated using a clinical dataset comprising 101 images. The clinical dataset is completely independent from the fine-tuning dataset and is taken by a different device with different image quality and size. Copyright © 2020 Inderscience Enterprises Ltd.",Clinical study; Convolutional neural network; Deep learning; Diabetic retinopathy; Inception model
Conference Paper,"Madala S., Suvarna Vani K., Jalapally P., Srujan Raju K., Soma Shekar G.",Framework for Diabetic Retinopathy Classification,"Smart Innovation, Systems and Technologies",2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137596351&doi=10.1007%2f978-981-16-9705-0_58&partnerID=40&md5=4c22f5199bc5bd484c3f98f7074ec048,"Diabetic retinopathy (DR) is a severe complication of eyes found in the diabetic patients. It is the main cause of sightlessness among them, and it progresses with the duration of the disease. Commonly, the diagnosis will be done by an ophthalmologist. But, the huge number of patients especially in the rural areas has a limited number of ophthalmologists that need to screen and review the images to properly diagnose the disease. If the number of out-patients are high, the doctor will be inclined to spend less amount of time for each patient. Automatic detection of diabetic retinopathy from the astronomically immense scale of retinal images avails the ophthalmologist to treat the affected patient and reduce chances of vision loss. Developing an automated diagnosis software based on latest deep learning techniques. The project aims to develop a framework for classification of features of fundus images based on disease criticality. The GUI takes the retina images dataset as the input. It pre-processes the images and does the features extraction. Extracting the retinal features that are helpful for the accurate diagnosis of DR. Based on these features, we can classify the criticality level of the disease of each image. © 2022, The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd.",Classification; Diabetic retinopathy; Morphological operations
Article,"Suguna G., Lavanya R.",Performance Assessment of EyeNet Model in Glaucoma Diagnosis,Pattern Recognition and Image Analysis,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85109024279&doi=10.1134%2fS1054661821020164&partnerID=40&md5=31cf03f09b6cfdb67c577357697d67e9,"Abstract: Deep learning (DL) has recently gained increasing attention in biomedical data analytics, demonstrating robust performance and promising results. A deep network requires massive amount of data to learn meaningful patterns useful in solving complex problems. Data scarcity in medical field is a bottleneck for applying deep learning in this area. This has led to the popularity of pre-trained models, trained on huge source data to achieve reasonable accuracy in medical diagnosis even with less data in target domain. A wise choice of models trained with data similar to target data would ensure that relevant features are captured. In this work, the significance of choosing appropriate pre-trained models is demonstrated. The EyeNet model, originally trained for diagnosis of diabetic retinopathy (DR) using fundus image dataset, is used as a pre-trained model for building a convolutional neural network (CNN) – based DL architecture for glaucoma diagnosis using images from the same modality. The results are compared with glaucoma diagnosis using different pre-trained models that are less relevant to the problem considered. Different experiments including fine-tuning and transfer learning were performed. Results were validated using the benchmark Rim-one dataset. The EyeNet model outperformed all other models, achieving a maximum accuracy of 89% with transfer learning using support vector machines (SVM) combined with principal component analysis (PCA) for dimensionality reduction. © 2021, Pleiades Publishing, Ltd.",Convolutional neural network; deep-learning; glaucoma; pre-trained models; transfer leaning
Conference Paper,"Ameri N., Shoeibi N., Abrishami M.",Segmentation of Hard Exudates in Retina Fundus Images Using BCDU-Net,"2022 12th International Conference on Computer and Knowledge Engineering, ICCKE 2022",2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85143756423&doi=10.1109%2fICCKE57176.2022.9960101&partnerID=40&md5=24ec4f1884427857e0819cdf2d2387b2,"The importance of Diabetic Retinopathy (DR) screening requires attention to the development of computer-aided diagnostic tools. Computer-Aided Diagnosis (CAD) of retinal detachment imaging can reduce mass screening of the diabetic population. For this purpose, the deep learning technique and the developed U-Net canonization network have been used. Using this network, it receives retinal images and shows the segmentation of the hard exudate lesion as a binary image. The result of this research has been evaluated on the IDRID dataset with three important indicators of dice coefficient, sensitivity, and accuracy achieve at 76.81%, 72.24%, and 99.30%, respectively, and the effectiveness of the approach was confirmed. © 2022 IEEE.",Deep learning; Diabetic retinopathy; Fundus image; Hard exudate; Hard exudate segmentation; Lesion segmentation; U-Net extended cannulation network
Article,"Qummar S., Khan F.G., Shah S., Khan A., Shamshirband S., Rehman Z.U., Khan I.A., Jadoon W.",A Deep Learning Ensemble Approach for Diabetic Retinopathy Detection,IEEE Access,2019,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85078339776&doi=10.1109%2fACCESS.2019.2947484&partnerID=40&md5=8b546c6f55f3e02a12c2a6ee667143b0,"Diabetic Retinopathy (DR) is an ophthalmic disease that damages retinal blood vessels. DR causes impaired vision and may even lead to blindness if it is not diagnosed in early stages. DR has five stages or classes, namely normal, mild, moderate, severe and PDR (Proliferative Diabetic Retinopathy). Normally, highly trained experts examine the colored fundus images to diagnose this fatal disease. This manual diagnosis of this condition (by clinicians) is tedious and error-prone. Therefore, various computer vision-based techniques have been proposed to automatically detect DR and its different stages from retina images. However, these methods are unable to encode the underlying complicated features and can only classify DR's different stages with very low accuracy particularly, for the early stages. In this research, we used the publicly available Kaggle dataset of retina images to train an ensemble of five deep Convolution Neural Network (CNN) models (Resnet50, Inceptionv3, Xception, Dense121, Dense169) to encode the rich features and improve the classification for different stages of DR. The experimental results show that the proposed model detects all the stages of DR unlike the current methods and performs better compared to state-of-the-art methods on the same Kaggle dataset. © 2013 IEEE.",CNN; deep learning; diabetic retinopathy; ensemble model; fundus images; medical image analysis
Article,"Stolte S., Fang R.",A survey on medical image analysis in diabetic retinopathy,Medical Image Analysis,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85086502053&doi=10.1016%2fj.media.2020.101742&partnerID=40&md5=d31abd2d51a89722e23a1c41dff8d3da,"Diabetic Retinopathy (DR) represents a highly-prevalent complication of diabetes in which individuals suffer from damage to the blood vessels in the retina. The disease manifests itself through lesion presence, starting with microaneurysms, at the nonproliferative stage before being characterized by neovascularization in the proliferative stage. Retinal specialists strive to detect DR early so that the disease can be treated before substantial, irreversible vision loss occurs. The level of DR severity indicates the extent of treatment necessary - vision loss may be preventable by effective diabetes management in mild (early) stages, rather than subjecting the patient to invasive laser surgery. Using artificial intelligence (AI), highly accurate and efficient systems can be developed to help assist medical professionals in screening and diagnosing DR earlier and without the full resources that are available in specialty clinics. In particular, deep learning facilitates diagnosis earlier and with higher sensitivity and specificity. Such systems make decisions based on minimally handcrafted features and pave the way for personalized therapies. Thus, this survey provides a comprehensive description of the current technology used in each step of DR diagnosis. First, it begins with an introduction to the disease and the current technologies and resources available in this space. It proceeds to discuss the frameworks that different teams have used to detect and classify DR. Ultimately, we conclude that deep learning systems offer revolutionary potential to DR identification and prevention of vision loss. © 2020 Elsevier B.V.",Deep learning; Diabetic retinopathy; Image mining; Lesion detection
Article,"Nguyen P.T., Bich Huynh V.D., Vo K.D., Phan P.T., Yang E., Joshi G.P.",An optimal deep learning based computer-aided diagnosis system for diabetic retinopathy,"Computers, Materials and Continua",2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85098771461&doi=10.32604%2fcmc.2021.012315&partnerID=40&md5=957d4f1532dc454225db202be3ad9668,"Diabetic Retinopathy (DR) is a significant blinding disease that poses serious threat to human vision rapidly. Classification and severity grading of DR are difficult processes to accomplish. Traditionally, it depends on ophthalmoscopically-visible symptoms of growing severity, which is then ranked in a stepwise scale from no retinopathy to various levels of DR severity. This paper presents an ensemble of Orthogonal Learning Particle Swarm Optimization (OPSO) algorithm-based Convolutional Neural Network (CNN) Model EOP-SO-CNN in order to perform DR detection and grading. The proposed EOP-SO-CNN model involves three main processes such as preprocessing, feature extraction, and classification. The proposed model initially involves preprocessing stage which removes the presence of noise in the input image. Then, the watershed algorithm is applied to segment the preprocessed images. Followed by, feature extraction takes place by leveraging EOPSO-CNN model. Finally, the extracted feature vectors are provided to a Decision Tree (DT) classifier to classify the DR images. The study experiments were carried out using Messidor DR Dataset and the results showed an extraordinary performance by the proposed method over compared methods in a considerable way. The simulation outcome offered the maximum classification with accuracy, sensitivity, and specificity values being 98.47%, 96.43%, and 99.02% respectively. © 2021 Tech Science Press. All rights reserved.",Classification; Computer-aided diagnosis; Convolutional neural network; Diabetic retinopathy; Image processing
Conference Paper,"Srivastava S., Prabhu S., Ramesh S., Pratapneni S., Abraham A., V Bhandary S.",Visualizing the Indicators of Diabetic Retinopathy Learnt by Convolutional Neural Networks,"2017 IEEE International Conference on Computational Intelligence and Computing Research, ICCIC 2017",2018,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85057964991&doi=10.1109%2fICCIC.2017.8524578&partnerID=40&md5=0240d400b20706daf4b33a0fe1ef8e3d,"This study proposes a novel application of visualizing features learnt by convolutional neural networks with the aim to further the understanding of Diabetic Retinopathy. A convolutional neural network is first trained to recognize and classify fundus images of diabetic and non-diabetic patients. The network is then visualized, using a technique of pixel optimization, to discover the features that the trained network looks for to classify the image. Through this novel application of network visualization, we show that critical features for diabetic retinopathy can be re-discovered, leaving great scope for its application in scarcely explored diseases using minimal resources. © 2017 IEEE.",automated diagnosis; convolutional networks; deep learning; diabetic retinopathy; disease classification; inceptionism; medical image analysis; neural networks
Conference Paper,"Elloumi Y., Abroug N., Bedoui M.H.",End-to-End Mobile System for Diabetic Retinopathy Screening Based on Lightweight Deep Neural Network,Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85128761134&doi=10.1007%2f978-3-031-01333-1_6&partnerID=40&md5=f9cbdca3f7c541e0ab2607ca4685e95d,"Diabetic Retinopathy (DR) is the leading cause of visual impairment among working-aged adults. Screening and early diagnosis of DR is essential to avoid visual acuity reduction and blindness. However, a worldwide limited access to ophthalmologists may prevent an early diagnosis of this blinding condition. In this paper, we propose a novel method for screening DR from smartphone-captured fundus images. The main challenges are to perform higher accurate detection even with reduced quality of handheld captured fundus images and to provide the result into the smartphone used for acquisition. For such a need, we apply transfer learning to the lightweight deep neural network “NasnetMobile” which is used as a feature descriptor, while configuring a multi-layer perceptron classifier to deduce the DR disease, in order to take benefit from their lower complexity. A dataset composed of 440 fundus images is structured, where the acquisition and statement are performed by expert ophthalmologists. A cross-validation process is conducted where 95.91% accuracy, 94.44% sensitivity, 96.92% specificity and 95.71% precision in average are achieved. In addition, the whole processing flowchart is implemented into a mobile device, where the execution time is under one second whatever the fundus image is. Those performances allow deploying the proposed system in a clinical context. © 2022, The Author(s), under exclusive license to Springer Nature Switzerland AG.",Deep learning; Diabetic retinopathy; Mobile-health; Transfer Learning
Conference Paper,"Sandhya S.G., Suhasini A., Kumar M.D.",Detection and Scrutiny of Diabetic Retinopathy Using Machine Learning Modus,"2020 International Conference on System, Computation, Automation and Networking, ICSCAN 2020",2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85098269521&doi=10.1109%2fICSCAN49426.2020.9262296&partnerID=40&md5=4d441b87b822193068f0c6cddb232703,"Diabetic retinopathy is a bypassed infection and a diabetes confusion that influences eyes. It's brought about by harm to the veins of the light-Touchy tissue at the rear of the eye (retina). The tremendous populace of diabetic patients and their huge screening necessities have brought forth enthusiasm for PC supported and totally programmed discovery of DR. Early detection of DR is critical for diagnosis and treatment of DR, which has led to a great deal of research towards the research of abnormal features related to DR that can be microneurysms, haemorrhages, hard exudates, etc. Most of the currently used classification techniques increases screening time, human error, complexity and reduce the accuracy. The proposed method involves feature extraction, augmentation and calculation of accuracy using CNN. The proposed model is implemented using Conda, along with Tensorflow and Keras Framework utilizing the Messidor dataset. © 2020 IEEE.",Augmentation; CNN; Deep learning; DR detection framework; Messidor dataset
Article,"Hu J., Wang H., Wang L., Lu Y.",Graph Adversarial Transfer Learning for Diabetic Retinopathy Classification,IEEE Access,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85141604922&doi=10.1109%2fACCESS.2022.3220776&partnerID=40&md5=c98d1bfb3ec36ea21d34679de36b3e6f,"Diabetic retinopathy (DR) is an essential factor that has caused vision loss and even blindness in middle-aged and older adults. A system that can automatically perform DR diagnosis can help ophthalmologists save a lot of tedious work, such as DR grading or lesion detection. At the same time, patients can find their diseases earlier and perform the correct treatment. However, most of the existing methods require many DR annotations to train the model, and the DR data will vary to different degrees due to various shooting tools. The above problems lead to the inefficient use of existing data in the experiment, limiting actual deployment. To alleviate this problem, we propose a novel Graph Adversarial Transfer Learning (GATL) for DR diagnosis in a deep model through transfer learning, including intra-domain alignment and inter-domain alignment. The proposed GATL enjoys several merits. First, our GATL adopts the self-supervised training to save the annotating cost in the target domain thus this domain adaptation method can significantly reduce annotation cost compared to the supervised approaches. Second, we introduce the graph neural network to extract potential features between unknown samples. Third, to enhance the robustness of the model, we use adversarial training to perform both inter-domain and intra-domain alignment to further improve the model's classification accuracy. GATL achieved 94.3%, 97.5%, and 91.1% in accuracy, sensitivity, and specificity in the APTOS dataset and 92.7%, 95.7%, and 89.7% in the EyePACS dataset, respectively. Extensive experimental results on two challenging benchmarks, including APTOS 2019 and EyePACS, demonstrate that the proposed GATL performs favorably against baseline DR classification methods. © 2013 IEEE.",Diabetic retinopathy classification; graph adversarial network; inter-domain; intra-domain; transfer learning
Conference Paper,"Abdelmaksoud E., Barakat S., Elmogy M.",Diabetic Retinopathy Grading Based on a Hybrid Deep Learning Model,"2020 International Conference on Data Analytics for Business and Industry: Way Towards a Sustainable Economy, ICDABI 2020",2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85100481995&doi=10.1109%2fICDABI51230.2020.9325672&partnerID=40&md5=d13899b2e6aacaca91fbf92f54fa92a9,"Diabetic retinopathy (DR) is a dangerous disease that may cause blindness suddenly without any indications. Therefore, it is necessary to continuously screen and audit the disease progress from the early to severe stages. By nature, the color fundus image may facilitate many lesion types that lead to diagnosing different DR grade. In this respect, deep learning achieved great success in medical image analysis, especially in multi-label (ML) classification. In this paper, we present a novel hybrid, deep learning technique for diagnosing different DR grades, which is called the E-DenseNet model. The proposed technique is a hybrid model of the EyeNet and DenseNet using transfer learning. We got benefits from combining the two models as we customized the EyeNet and embedded dense blocks. The proposed computer-aided diagnosis (CAD) system with E-DenseNet can diagnose different DR grades (normal, mild, moderate, severe, and proliferative DR (PDR)) from various ML color fundus images accurately with minimal training time and memory space. The proposed CAD system gives promising results in diagnosing different DR grades from two benchmark datasets. The proposed system achieved an average accuracy (ACC) equals 91.6%, the Dice similarity coefficient (DSC) equals 92.45%, and the Kappa score equals 0.883. © 2020 IEEE.",Computer aided diagnosis; Eye protection; Grading; Industrial economics; Learning systems; Medical imaging; Transfer learning; Benchmark datasets; Computer Aided Diagnosis(CAD); Diabetic retinopathy; Hybrid model; Learning models; Learning techniques; Minimal training; Similarity coefficients; Deep learning
Conference Paper,"Fu H., Wang B., Shen J., Cui S., Xu Y., Liu J., Shao L.",Evaluation of retinal image quality assessment networks in different color-spaces,Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),2019,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85075640913&doi=10.1007%2f978-3-030-32239-7_6&partnerID=40&md5=c7bc56390473e46464f775d16d248c86,"Retinal image quality assessment (RIQA) is essential for controlling the quality of retinal imaging and guaranteeing the reliability of diagnoses by ophthalmologists or automated analysis systems. Existing RIQA methods focus on the RGB color-space and are developed based on small datasets with binary quality labels (i.e., ‘Accept’ and ‘Reject’). In this paper, we first re-annotate an Eye-Quality (EyeQ) dataset with 28,792 retinal images from the EyePACS dataset, based on a three-level quality grading system (i.e., ‘Good’, ‘Usable’ and ‘Reject’) for evaluating RIQA methods. Our RIQA dataset is characterized by its large-scale size, multi-level grading, and multi-modality. Then, we analyze the influences on RIQA of different color-spaces, and propose a simple yet efficient deep network, named Multiple Color-space Fusion Network (MCF-Net), which integrates the different color-space representations at both a feature-level and prediction-level to predict image quality grades. Experiments on our EyeQ dataset show that our MCF-Net obtains a state-of-the-art performance, outperforming the other deep learning methods. Furthermore, we also evaluate diabetic retinopathy (DR) detection methods on images of different quality, and demonstrate that the performances of automated diagnostic systems are highly dependent on image quality. © 2019, Springer Nature Switzerland AG.",Deep learning; Quality assessment; Retinal image
Article,"Yang W.-H., Zheng B., Wu M.-N., Zhu S.-J., Fei F.-Q., Weng M., Zhang X., Lu P.-R.",An Evaluation System of Fundus Photograph-Based Intelligent Diagnostic Technology for Diabetic Retinopathy and Applicability for Research,Diabetes Therapy,2019,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85068911979&doi=10.1007%2fs13300-019-0652-0&partnerID=40&md5=6f55e11afec49fb1920e126aaabfc017,"Introduction: In April 2018, the US Food and Drug Administration (FDA) approved the world’s first artificial intelligence (AI) medical device for detecting diabetic retinopathy (DR), the IDx-DR. However, there is a lack of evaluation systems for DR intelligent diagnostic technology. Methods: Five hundred color fundus photographs of diabetic patients were selected. DR severity varied from grade 0 to 4, with 100 photographs for each grade. Following that, these were diagnosed by both ophthalmologists and the intelligent technology, the results of which were compared by applying the evaluation system. The system includes primary, intermediate, and advanced evaluations, of which the intermediate evaluation incorporated two methods. Main evaluation indicators were sensitivity, specificity, and kappa value. Results: The AI technology diagnosed 93 photographs with no DR, 107 with mild non-proliferative DR (NPDR), 107 with moderate NPDR, 108 with severe NPDR, and 85 with proliferative DR (PDR). The sensitivity, specificity, and kappa value of the AI diagnoses in the primary evaluation were 98.8%, 88.0%, and 0.89, respectively. According to method 1 of the intermediate evaluation, the sensitivity of AI diagnosis was 98.0%, specificity 97.0%, and the kappa value 0.95. In method 2 of the intermediate evaluation, the sensitivity of AI diagnosis was 95.5%, the specificity 99.3%, and kappa value 0.95. In the advanced evaluation, the kappa value of the intelligent diagnosis was 0.86. Conclusions: This article proposes an evaluation system for color fundus photograph-based intelligent diagnostic technology of DR and demonstrates an application of this system in a clinical setting. The results from this evaluation system serve as the basis for the selection of scenarios in which DR intelligent diagnostic technology can be applied. © 2019, The Author(s).",Deep learning; Diabetic retinopathy; Evaluation studies; Ophthalmological diagnostic techniques
Conference Paper,"Saxena S., Lal K., Joshi S.",Retinal Vessel Segmentation Using Blending-Based Conditional Generative Adversarial Networks,Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85119356588&doi=10.1007%2f978-3-030-89128-2_13&partnerID=40&md5=5e6c5772f8c29a5db1a18fe5fa11fa1d,"With a critical need for faster and more accurate diagnosis in medical image analysis, artificial intelligence plays a critical role. Precise artery segmentation and faster diagnosis in retinal blood vessel segmentation can be beneficial for the early detection of acute diseases such as diabetic retinopathy and glaucoma. Recent advancements in deep learning have led to some exciting improvements in the field of medical image segmentation. However, one common problem faced by such methods is the limited availability of labelled data to train a suitable deep learning model. The publicly available dataset for retinal vessel segmentation contains less than 50 images. On the other hand, deep learning is a data-hungry process. We propose a method to generate synthetic images to augment the training needs of the deep learning model. Specifically, we propose a blending and enhancement-based strategy to learn a conditional generative adversarial model. The network synthesizes high-quality fundus images used along with the real images to learn a convolutional neural network-based segmentation model. Experimental evaluation shows that the proposed synthetic generation method improves segmentation performance on the real test images of the vascular extraction (DRIVE) dataset achieving 97.01% segmentation accuracy. © 2021, Springer Nature Switzerland AG.",Convolutional neural network; Generative adversarial networks; Image synthesis; Medical image segmentation; Retinal vessel segmentation
Article,Mansour R.F.,Deep-learning-based automatic computer-aided diagnosis system for diabetic retinopathy,Biomedical Engineering Letters,2018,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85042694325&doi=10.1007%2fs13534-017-0047-y&partnerID=40&md5=cdaba8e546a89aa18c383f804092726c,"The high-pace rise in advanced computing and imaging systems has given rise to a new research dimension called computer-aided diagnosis (CAD) system for various biomedical purposes. CAD-based diabetic retinopathy (DR) can be of paramount significance to enable early disease detection and diagnosis decision. Considering the robustness of deep neural networks (DNNs) to solve highly intricate classification problems, in this paper, AlexNet DNN, which functions on the basis of convolutional neural network (CNN), has been applied to enable an optimal DR CAD solution. The DR model applies a multilevel optimization measure that incorporates pre-processing, adaptive-learning-based Gaussian mixture model (GMM)-based concept region segmentation, connected component-analysis-based region of interest (ROI) localization, AlexNet DNN-based highly dimensional feature extraction, principle component analysis (PCA)- and linear discriminant analysis (LDA)-based feature selection, and support-vector-machine-based classification to ensure optimal five-class DR classification. The simulation results with standard KAGGLE fundus datasets reveal that the proposed AlexNet DNN-based DR exhibits a better performance with LDA feature selection, where it exhibits a DR classification accuracy of 97.93% with FC7 features, whereas with PCA, it shows 95.26% accuracy. Comparative analysis with spatial invariant feature transform (SIFT) technique (accuracy—94.40%) based DR feature extraction also confirms that AlexNet DNN-based DR outperforms SIFT-based DR. © 2017, Korean Society of Medical and Biological Engineering and Springer-Verlag GmbH Germany.",AlexNet DNN; Computer-aided diagnosis; Convolutional neural network; Deep neural network; Diabetic retinopathy; Gaussian mixture model; Linear discriminant analysis; SVM
Article,"Fatima, Imran M., Ullah A., Arif M., Noor R.",A unified technique for entropy enhancement based diabetic retinopathy detection using hybrid neural network,Computers in Biology and Medicine,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85127018483&doi=10.1016%2fj.compbiomed.2022.105424&partnerID=40&md5=54beeaf8d7a4b4f222e170f67e3c4b46,"In this paper, a unified technique for entropy enhancement-based diabetic retinopathy detection using a hybrid neural network is proposed for diagnosing diabetic retinopathy. Medical images play crucial roles in the diagnosis, but two images representing two different stages of a disease look alike. It, consequently, make the process of diagnosis extraneous and error-prone. Therefore, in this paper, a technique is proposed to address these issues. Firstly, a novel entropy enhancement technique is devised exploiting the discrete wavelet transforms to improve the visibility of the medical images by making the subtle features more prominent. Later, we designed a computationally efficient hybrid neural network that efficiently classifies diabetic retinopathy images. To examine the effectiveness of our technique, we have chosen three datasets: Ultra-Wide Filed (UWF) dataset, Asia Pacific Tele Ophthalmology Society (APTOS) dataset, and MESSIDOR-2 dataset. In the end, we performed extensive experiments to validate the performance of our technique. In addition, the comparison of the proposed scheme – in terms of accuracy, specificity, sensitivity, precision and recall curve, and area under the curve – with some of the best contemporary schemes shows the significant improvement of our techniques in terms of diabetic retinopathy classification. © 2022 Elsevier Ltd",Classification; Diabetic retinopathy; Discrete wavelet transform; Histogram; Medical data; Neural network
Conference Paper,"Tian L., Ma L., Wen Z., Xie S., Xu Y.",Learning Discriminative Representations for Fine-Grained Diabetic Retinopathy Grading,Proceedings of the International Joint Conference on Neural Networks,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85116508979&doi=10.1109%2fIJCNN52387.2021.9533344&partnerID=40&md5=b12f7a64c48ec4421bf2b5721702cd6a,"Diabetic retinopathy is one of the leading causes of blindness. However, no specific symptoms of early DR lead to a delayed diagnosis, which results in disease progression in patients. To determine the disease severity levels, ophthalmologists need to focus on the discriminative parts of the retinal images. In recent years, deep learning has achieved great success in medical image analysis. However, most works directly employ algorithms based on convolutional neural networks (CNNs), which ignore the fact that the difference among classes is subtle and gradual. Hence, we consider automatic image grading of DR as a fine-grained classification task, and construct a bilinear model to identify the pathologically discriminative areas. In order to leverage the ordinal information among classes, we put the soft labels with ordinal information among classes into the loss function rather than the most commonly used one-hot labels for the diabetic retinopathy classification. In addition, other than only using a categorical loss to train our network, we also introduce the metric loss to learn a more discriminative feature space which is beneficial to locate the finer discriminative lesion parts. Experimental results demonstrate the superior performance of the proposed method on publicly available IDRiD, DeepDRiD and FGADR datasets. © 2021 IEEE.",Diabetic retinopathy; fine-grained classification; metric learning; ordinal regression
Article,"Bilal A., Zhu L., Deng A., Lu H., Wu N.",AI-Based Automatic Detection and Classification of Diabetic Retinopathy Using U-Net and Deep Learning,Symmetry,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137372574&doi=10.3390%2fsym14071427&partnerID=40&md5=3a5a47cace3c55d60018f2437429d92c,"Artificial intelligence is widely applied to automate Diabetic retinopathy diagnosis. Diabetes-related retinal vascular disease is one of the world’s most common leading causes of blindness and vision impairment. Therefore, automated DR detection systems would greatly benefit the early screening and treatment of DR and prevent vision loss caused by it. Researchers have proposed several systems to detect abnormalities in retinal images in the past few years. However, Diabetic Retinopathy automatic detection methods have traditionally been based on hand-crafted feature extraction from the retinal images and using a classifier to obtain the final classification. DNN (Deep neural networks) have made several changes in the previous few years to assist overcome the problem mentioned above. We suggested a two-stage novel approach for automated DR classification in this research. Due to the low fraction of positive instances in the asymmetric Optic Disk (OD) and blood vessels (BV) detection system, preprocessing and data augmentation techniques are used to enhance the image quality and quantity. The first step uses two independent U-Net models for OD (optic disc) and BV (blood vessel) segmentation. In the second stage, the symmetric hybrid CNN-SVD model was created after preprocessing to extract and choose the most discriminant features following OD and BV extraction using Inception-V3 based on transfer learning, and detects DR by recognizing retinal biomarkers such as MA (microaneurysms), HM (hemorrhages), and exudates (EX). On EyePACS-1, Messidor-2, and DIARETDB0, the proposed methodology demonstrated state-of-the-art performance, with an average accuracy of 97.92%, 94.59%, and 93.52%, respectively. Extensive testing and comparisons with baseline approaches indicate the efficacy of the suggested methodology. © 2022 by the authors.",automatic diagnosis; diabetic retinopathy (DR); DR detection and classification; feature extraction; fundus images (FIs); multi-class segmentation and classification; transfer learning
Article,"Bhardwaj C., Jain S., Sood M.",Transfer learning based robust automatic detection system for diabetic retinopathy grading,Neural Computing and Applications,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85105490668&doi=10.1007%2fs00521-021-06042-2&partnerID=40&md5=442c234ea4a76ec476b46397c75ea6f0,"Diabetic retinopathy (DR) can be categorized on the basis of prolonged complication in the retinal blood vessels which may lead to severe blindness. Early stage prediction and diagnosis of DR requires regular eye examination to reduce the complications causing vision loss. Indicative significance of DR forecast and evaluation to help the ophthalmologists in standard screening has prompted the improvement of computerized DR recognition frameworks. This work focuses on automatic DR disease identification and its grading by the means of transfer learning approach using dynamic investigation. Our proposed approach utilizes deep neural network for feature extraction from fundus images and these features are further ensembled with supervised machine learning technique for DR grading. An optimized classification is achieved by applying an ensemble of convolution neural networks (CNNs) with statistical feature selection module and SVM classifier. The learning of classifier is achieved by the feature information transferred from CNN model to the SVM classifier, which results in remarkable performance of the learned models. Statistically optimized feature set utilized for transfer learning technique yields in the classification accuracy of 90.51% with proposed Prominent Feature-based Transfer Learning (PFTL) method employing Inception V3 model. The cost analysis of the proposed model provides a minimum cross-entropy loss of 0.295 consuming the time of 38 min 53 s, thus, maintaining a trade-off. The generalization ability of the proposed model is established by the performance assessment using latest IDRiD dataset that yields accuracy of 90.01% for Inception V3 network providing uniform outcomes for all the evaluation parameters. The diagnosis ability of the proposed transfer learning-based model is justified by comparing the proposed methods with the state-of-the-art methods. The optimized PFTL model (CNN + Statistical Analysis + SVM) outperforms other classification algorithms and provides the maximum accuracy improvement of 16.01% over the state-of-the-art techniques. © 2021, The Author(s), under exclusive licence to Springer-Verlag London Ltd., part of Springer Nature.",Convolution neural network; Deep neural network; Diabetic retinopathy; Statistical analysis; Supervised machine learning
Conference Paper,"Mane D., Londhe N., Patil N., Patil O., Vidhate P.",A Survey on Diabetic Retinopathy Detection Using Deep Learning,Lecture Notes in Networks and Systems,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85119894152&doi=10.1007%2f978-981-16-2641-8_59&partnerID=40&md5=9956862bb515fdd424d5eaee5bf02ed6,"Diabetic retinopathy happens when there are high blood pressure and high sugar level in the body that damages the blood vessels and veins in retina. These arteries can become swollen and leaky, or they may close, block the flow of blood. Sometimes new, unusual blood arteries grow in the retina part. These unconditional changes can steal your eyesight. Manual examination and analysis of fundus images to detect morphological changes in the eyes are very sluggish and tedious. In the current scenario, deep learning has been set up as the most popular approach with superior performance in various areas and over traditional machine learning methods, especially in image analysis and treatment. In this paper, we adhere to traditional strategies mainly containing input Data acquisition, pre-data processing, segmentation and data preparation, feature measurement, feature extraction, model creation, model training, model testing on testing data, and outcome and analysis of the model. We have reviewed various algorithms and their challenges that help in the diagnosis of methods used in the detection of diabetic retinopathy. © 2022, The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd.",Deep convolutional neural network; Deep learning; Diabetic retinopathy; Image classification; K-nearest neighbor; Retinal abnormalities; Support vector machine
Conference Paper,"Toledo-Cortés S., de la Pava M., Perdomo O., González F.A.",Hybrid Deep Learning Gaussian Process for Diabetic Retinopathy Diagnosis and Uncertainty Quantification,Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097434243&doi=10.1007%2f978-3-030-63419-3_21&partnerID=40&md5=e161fbdf059736a56604e9f8df36d22b,"Diabetic Retinopathy (DR) is one of the microvascular complications of Diabetes Mellitus, which remains as one of the leading causes of blindness worldwide. Computational models based on Convolutional Neural Networks represent the state of the art for the automatic detection of DR using eye fundus images. Most of the current work address this problem as a binary classification task. However, including the grade estimation and quantification of predictions uncertainty can potentially increase the robustness of the model. In this paper, a hybrid Deep Learning-Gaussian process method for DR diagnosis and uncertainty quantification is presented. This method combines the representational power of deep learning, with the ability to generalize from small datasets of Gaussian process models. The results show that uncertainty quantification in the predictions improves the interpretability of the method as a diagnostic support tool. The source code to replicate the experiments is publicly available at https://github.com/stoledoc/DLGP-DR-Diagnosis. © 2020, Springer Nature Switzerland AG.",Deep Learning; Diabetic Retinopathy; Gaussian Process; Uncertainty quantification
Conference Paper,"Bai Y., Hao J., Fu H., Hu Y., Ge X., Liu J., Zhao Y., Zhang J.",Unsupervised Lesion-Aware Transfer Learning for Diabetic Retinopathy Grading in Ultra-Wide-Field Fundus Photography,Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85139043607&doi=10.1007%2f978-3-031-16434-7_54&partnerID=40&md5=6957889598d8af4324eacfef4b9f62cc,"Ultra-wide-field (UWF) fundus photography is a new imaging technique with providing a broader field of view images, and it has become a popular and effective tool for the screening and diagnosis for many eye diseases, such as diabetic retinopathy (DR). However, it is practically challenging to train a robust deep learning model for DR grading in UWF images, due to the limited scale of data and manual annotations. By contrast, we may find large-scale high-quality regular color fundus photography datasets in the research community, with either image-level or pixel-level annotation. In consequence, we propose an Unsupervised Lesion-aware TRAnsfer learning framework (ULTRA) for DR grading in UWF images, by leveraging a large amount of publicly well-annotated regular color fundus images. Inspired by the clinical identification of DR severity, i.e., the decision making process of ophthalmologists based on the type and number of associated lesions, we design an adversarial lesion map generator to provide the auxiliary lesion information for DR grading. A Lesion External Attention Module (LEAM) is introduced to integrate the lesion feature into the model, allowing a relative explainable DR grading. Extensive experimental results show the proposed method is superior to the state-of-the-art methods. © 2022, The Author(s), under exclusive license to Springer Nature Switzerland AG.",Diabetic retinopathy; Unsupervised; UWF imaging
Conference Paper,"Saranya P., Kiruthika Devi S., Bharanidharan B.",Detection of Diabetic Retinopathy in Retinal Fundus Images using DenseNet based Deep Learning Model,"2022 International Mobile and Embedded Technology Conference, MECON 2022",2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85129170751&doi=10.1109%2fMECON53876.2022.9752065&partnerID=40&md5=37a9d056f6b575c68d650775de30eba9,"Diabetic Mellitus is one of the world's most common diseases. Diabetes is quite prevalent, and it produces a variety of health issues such as Diabetic Retinopathy, nephropathy, diabetic foot, and so on. Diabetic Retinopathy is the most prominent problem (DR). DR starts with no symptoms or minor vision problems and escalates to the point when vision loss is a possibility. Since diagnosis takes time and ophthalmologists are scarce, patients endure vision loss even before they are diagnosed. So, an early detection of DR may help to mitigate the problem. To diagnose DR, however, numerous physical tests are required and in the early phases of the disease, it is difficult to diagnose by exams. As a result, a new diagnostic technique must be devised to detect the disease before it manifests itself in a test, allowing it to be treated sooner. The objective of the proposed model is to provide an automated diagnosis model for DR detection utilizing DenseNet-based deep learning models. As an input, the classification model was given a pre-processed retinal image that had not been enhanced with features. Only a few preprocessing steps are done on the noisy images to increase DR detection accuracy and achieved the maximum accuracy and precision of 0.83 and 0.99 respectively. © 2022 IEEE.",deep learning models; DenseNet; Diabetic Retinopathy; fundus images
Conference Paper,"Saranya Rubini S., Saai Nithil R., Kunthavai A., Sharma A.",Deep convolutional neural network-based diabetic retinopathy detection in digital fundus images,Advances in Intelligent Systems and Computing,2019,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85061097085&doi=10.1007%2f978-981-13-3600-3_19&partnerID=40&md5=424ed9b7e9ece9bf76ed87a570ca7d5e,"Diabetic Retinopathy (DR) is a common medical disorder damaging the retinal blood vessels of diabetic patients. Regular screening of fundus images and timely detection of the initial symptoms of DR, namely microaneurysms and hemorrhages, are important to reduce the possibility of vision impairment. The proposed work explores the power of Convolutional Neural Network (CNN) in the analysis and detection of retinal disorders. An automated deep learning model named Deep Convolutional Neural Network-based Diabetic Retinopathy Detection (DCNN-DRD) has been proposed to analyze the retinal images and classify them as healthy or defective based on DR symptoms. A retinal image is fed into the DCNN-DRD model which consists of five convolution and five pooling layers followed by a dropout layer and three fully connected layers. The linear output data produced in every layer represents the weighted value based on DR symptoms and is fed into a gradient descent graph for refinement to improve the learning accuracy through several iterations. Thus, the DCNN-DRD model does not require any preprocessing and learns high-level discriminative features of DR symptoms from the pixel intensities to categorize the retinal image as either healthy or defective. The DCNN-DRD model has been trained with a subset of images from the MESSIDOR dataset and the ROC dataset. Experimental results show that the DCNN-DRD model successfully predicts the retinal image as either healthy or defective with 97% accuracy. © Springer Nature Singapore Pte Ltd. 2019.",Convolutional neural network; Deep learning; Diabetic retinopathy; Hemorrhages; Microaneurysms
Conference Paper,"Khan M.Z., Lee Y.",Retinal image analysis to detect neovascularization using deep segmentation,"Proceedings - 2021 4th International Conference on Information and Computer Technologies, ICICT 2021",2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85111384324&doi=10.1109%2fICICT52872.2021.00026&partnerID=40&md5=0aca877b4f84eee3f179ae30f6b7054f,"The retina has a significant role in early detection of sight-threatening disease symptoms. Most of the ocular complications manifest themselves in retina. The extraction of useful information from this vital resource is a critical task. The recent advancement in artificial intelligence has opened ways to provide rapid assistance in detecting ocular disorders through retinal images. In this article, we have proposed a vessels segmentation model for the early detection of neovascularization. It is a common symptom for patients facing chronic diabetic retinopathy. In neovascularization, the tiny vessels are produced that gets block over time with an extensive amount of sugar content in human blood. The detection of newly formatted tiny blood vessels needs a precise vessels extraction system. Our model has shown promising results on a publicly available retinal image dataset. It has achieved the highest accuracy of 0.9554 with 0.9780 AUC. The underlying research is an effort to produce automated disease detection system. The core function of the proposed system is to analyze the structural variation in vessels of subjects experiencing ocular disease symptoms and to reduce the risk of blindness through early diagnosis. © 2021 IEEE.",Deep learning; Diabetic retinopathy; Image segmentation; Neovascularization; Vessels extraction
Conference Paper,"Gupta S., Panwar A., Goel S., Mittal A., Nijhawan R., Singh A.K.",Classification of lesions in retinal fundus images for diabetic retinopathy using transfer learning,"Proceedings - 2019 International Conference on Information Technology, ICIT 2019",2019,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85082865937&doi=10.1109%2fICIT48102.2019.00067&partnerID=40&md5=27038acaf0f3cd45d470dd425bd70694,"Diabetic Retinopathy (DR) is an eye disorder that affects the small blood vessels in the retina and is featured by the presence of different types of lesions in the affected area. If an early prognostication of DR is not done, then it may lead to loss of vision. Some of the diagnosing tools for detection of DR are Indirect Ophthalmoscope, Slit Lamp Examination, Color Photograph, and Optical Coherence Tomography (OCT). The DR dataset contains 5 types of lesions ranging from mild to severe. These lesions are hard to distinguish from each other. The manual diagnosis of DR involves the proper classification of these lesions into their appropriate classes that is quite tedious and error-prone process marred with low level of accuracies. Researchers therefore rely on automatic detection and prognosis of DR based on Machine Learning (ML) methods. In this work, we propose a Deep Learning (DL) framework to classify these lesions with high level of accuracy. To accomplish the task, we train a DL model Visual Geometry Group (VGG19) on Indian Diabetic Retinopathy Image Dataset (IDRID) dataset to extract the features from the color fundus eye photography provided in the dataset. The extracted features are then fed into different classifiers such as Logistic Regression (LR), Support Vector Machine (SVM), K-Nearest Neighbors (KNN) etc. to classify the lesions properly. We thus show, that using DL along with Transfer Learning (TL) can classify the affected areas such as Microaneurysms (MA), Soft Exudates (SE), Hard Exudates (EX), and Hemorrhage (HE) of a DR eye with high accuracy. © 2019 IEEE.",Deep learning; Inception v3; KNN; Logistic regression; Random forest; SVM; VGG16; VGG19
Conference Paper,"Qian Z., Wu C., Chen H., Chen M.",Diabetic Retinopathy Grading Using Attention based Convolution Neural Network,"IEEE Advanced Information Technology, Electronic and Automation Control Conference (IAEAC)",2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85104593211&doi=10.1109%2fIAEAC50856.2021.9390963&partnerID=40&md5=2dcd6be174765a7c0e10ed25363b4c9c,"In this paper, an automatic diagnosis method based on deep learning algorithm is proposed, which will speed up the diagnosis of diabetic retinopathy and improve the efficiency of treatment. We built a convolutional neural network model called as ""AD2Net"". The network combines the advantages of Res2Net and DenseNet, which can not only learn multi-scale features, but also alleviate the vanishing-gradient problem and strengthen feature reuse. At the same time, this paper also uses attention mechanism method to encourage the network to focus on learning useful information in images, which can improve classification effect of the network to a certain extent. The results show that the method proposed in this paper can divide the fundus images into five stages of disease based on severity. The accuracy and Kappa values that the model has achieved are 83.2% and 0.8 respectively on testing set. Compared with the existing method, the method proposed in this paper has certain advantages. © 2021 IEEE.",CNN; deep learning; diabetic retinopathy; Kaggle
Conference Paper,"Vinayaki V.D., Kalaiselvi R.",An Improved Ensemble Extreme Learning Machine Classifier for Detecting Diabetic Retinopathy in Fundus Images,IFIP Advances in Information and Communication Technology,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85140433213&doi=10.1007%2f978-3-031-16364-7_26&partnerID=40&md5=6caa9c49fff44b6350ebbbaa022c0fcb,"This paper presents an automatic diabetes Retinopathy (DR) detection system using fundus images. The proposed automatic DR screening model saves the time of the ophthalmologist in disease diagnosis. In this approach, the segmentation is conducted using an improved watershed algorithm and Gray Level Co-occurrence Matrix (GLCM) is used for feature extraction. An improved Ensemble Extreme Learning Machine (EELM) is used for classification and its weights are tuned using the Crystal Structure Algorithm (CRYSTAL) algorithm which also optimizes the loss function of the EELM classifier. The experiments are conducted using two datasets namely DRIVE and MESSIDOR by comparing the proposed approach against different state-of-art techniques such as Support Vector Machine, VGG19, Ensemble classifier, and Synergic Deep Learning model. When compared to existing methodologies, the proposed approach has sensitivity, specificity, and accuracy scores of 97%, 97.3%, and 98%, respectively. © 2022, IFIP International Federation for Information Processing.",CRYSTAL algorithm; Diabetic retinopathy; DRIVE; Ensemble Extreme Learning Machine; Fundus image; Improved watershed algorithm
Article,"Babenko B., Mitani A., Traynis I., Kitade N., Singh P., Maa A.Y., Cuadros J., Corrado G.S., Peng L., Webster D.R., Varadarajan A., Hammel N., Liu Y.",Detection of signs of disease in external photographs of the eyes via deep learning,Nature Biomedical Engineering,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85127335620&doi=10.1038%2fs41551-022-00867-5&partnerID=40&md5=0e0759cbc1068aa969b4a465d0ff33b8,"Retinal fundus photographs can be used to detect a range of retinal conditions. Here we show that deep-learning models trained instead on external photographs of the eyes can be used to detect diabetic retinopathy (DR), diabetic macular oedema and poor blood glucose control. We developed the models using eye photographs from 145,832 patients with diabetes from 301 DR screening sites and evaluated the models on four tasks and four validation datasets with a total of 48,644 patients from 198 additional screening sites. For all four tasks, the predictive performance of the deep-learning models was significantly higher than the performance of logistic regression models using self-reported demographic and medical history data, and the predictions generalized to patients with dilated pupils, to patients from a different DR screening programme and to a general eye care programme that included diabetics and non-diabetics. We also explored the use of the deep-learning models for the detection of elevated lipid levels. The utility of external eye photographs for the diagnosis and management of diseases should be further validated with images from different cameras and patient populations. © 2022, The Author(s), under exclusive licence to Springer Nature Limited.",Diagnosis; Eye protection; Learning systems; Ophthalmology; Photography; Blood glucose; Condition; Diabetic retinopathy; Diabetic retinopathy screening; Fundus photographs; Glucose control; Learning models; Macular edema; Predictive performance; Deep learning; diabetic retinopathy; diagnostic imaging; eye fundus; human; retina disease; sensitivity and specificity; Deep Learning; Diabetic Retinopathy; Fundus Oculi; Humans; Retinal Diseases; Sensitivity and Specificity
Article,"Ai Z., Huang X., Feng J., Wang H., Tao Y., Zeng F., Lu Y.",FN-OCT: Disease Detection Algorithm for Retinal Optical Coherence Tomography Based on a Fusion Network,Frontiers in Neuroinformatics,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85133552519&doi=10.3389%2ffninf.2022.876927&partnerID=40&md5=ada233c618fa98b954d795e175a805e9,"Optical coherence tomography (OCT) is a new type of tomography that has experienced rapid development and potential in recent years. It is playing an increasingly important role in retinopathy diagnoses. At present, due to the uneven distributions of medical resources in various regions, the uneven proficiency levels of doctors in grassroots and remote areas, and the development needs of rare disease diagnosis and precision medicine, artificial intelligence technology based on deep learning can provide fast, accurate, and effective solutions for the recognition and diagnosis of retinal OCT images. To prevent vision damage and blindness caused by the delayed discovery of retinopathy, a fusion network (FN)-based retinal OCT classification algorithm (FN-OCT) is proposed in this paper to improve upon the adaptability and accuracy of traditional classification algorithms. The InceptionV3, Inception-ResNet, and Xception deep learning algorithms are used as base classifiers, a convolutional block attention mechanism (CBAM) is added after each base classifier, and three different fusion strategies are used to merge the prediction results of the base classifiers to output the final prediction results (choroidal neovascularization (CNV), diabetic macular oedema (DME), drusen, normal). The results show that in a classification problem involving the UCSD common retinal OCT dataset (108,312 OCT images from 4,686 patients), compared with that of the InceptionV3 network model, the prediction accuracy of FN-OCT is improved by 5.3% (accuracy = 98.7%, area under the curve (AUC) = 99.1%). The predictive accuracy and AUC achieved on an external dataset for the classification of retinal OCT diseases are 92 and 94.5%, respectively, and gradient-weighted class activation mapping (Grad-CAM) is used as a visualization tool to verify the effectiveness of the proposed FNs. This finding indicates that the developed fusion algorithm can significantly improve the performance of classifiers while providing a powerful tool and theoretical support for assisting with the diagnosis of retinal OCT. Copyright © 2022 Ai, Huang, Feng, Wang, Tao, Zeng and Lu.",attention mechanism; fusion network; model interpretability; optical coherence tomography; retinal disease
Article,"Das S., Kharbanda K., M S., Raman R., D E.D.",Deep learning architecture based on segmented fundus image features for classification of diabetic retinopathy,Biomedical Signal Processing and Control,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85104084811&doi=10.1016%2fj.bspc.2021.102600&partnerID=40&md5=efd40be9468d9293efa1d4b2ebf4049a,"Diabetic retinopathy is ophthalmological distress, diabetic patients suffer due to clots, lesions, or haemorrhage formation in the light-sensitive region of the retina. Blocking of vessels leads, due to the increase of blood sugar leads to the formation of new vessel growth, which gives rise to mesh-like structures. Assessing the branching retinal vasculature is an important aspect for ophthalmologists for efficient diagnosis. The fundus scans of the eye are first subjected to pre-processing, followed by segmentation. To extract the branching blood vessels, the technique of maximal principal curvature has been applied, which utilizes the maximum Eigenvalues of the Hessian matrix. Adaptive histogram equalization and the morphological opening, are performed post to that, to enhance and eliminate falsely segmented regions. The proliferation of optical nerves was observed much greater in diabetic or affected patients than in healthy ones. We have used a convolution neural network (CNN) to train the classifier for performing classification. The CNN, constructed for classification, comprises a combination of squeeze and excitation and bottleneck layers, one for each class, and a convolution and pooling layer architecture for classification between the two classes. For the performance evaluation of the proposed algorithm, we use the dataset DIARETDB1 (standard Diabetic Retinopathy Dataset) and the dataset provided by a medical institution, comprised of fundus scans of both affected and normal retinas. Experimental results show that the proposed algorithm provides improved results, when compared to traditional schemes. The model yielded an accuracy of 98.7 % and a precision of 97.2 % while evaluated on the DIARETDB1 dataset. © 2021",Bottleneck; Convolutional neural network; Diabetic retinopathy; Hessian matrix; Maximum principal curvature; Squeeze-excitation
Conference Paper,"Gandhi H., Agrawal K., Oza U., Kumar P.",Diabetic Retinopathy Classification Using Pixel-Level Lesion Segmentation,Lecture Notes in Electrical Engineering,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85142748485&doi=10.1007%2f978-981-19-5037-7_29&partnerID=40&md5=9bde0c2b05e6de27cc69070c4bb12cb2,"Diabetic patients are at a high risk of developing Diabetic Retinopathy (DR). Due to the great success of deep learning, automated DR diagnosis has become a promising technique for the early detection and severity grading of Diabetic Retinopathy. DR classification is the process of classifying fundus image into five risk levels on the basis of severity of diabetes. In this paper, we propose a novel approach to classify DR severity levels. This is done by first segmenting each pixel into six different lesion types and then using different lesion regions present in the fundus images to classify the image into five severity levels of DR. Further, the model is optimized using unique pre-processing techniques like downsampling and image augmentation. We are working on the seg set of the FGADR dataset. Working on the seg set of the FGADR dataset, we report results of the proposed approach which outperforms the previous state-of-the-art methods. Diagnosis of DR can improve significantly by using these automated techniques in detecting lesion regions as well as detecting DR severity levels. © 2022, The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd.",Classification; Deep learning; Diabetic retinopathy; Segmentation
Conference Paper,"Lim Z.W., Lee M.L., Hsu W., Wong T.Y.",Building trust in deep learning system towards automated disease detection,"33rd AAAI Conference on Artificial Intelligence, AAAI 2019, 31st Innovative Applications of Artificial Intelligence Conference, IAAI 2019 and the 9th AAAI Symposium on Educational Advances in Artificial Intelligence, EAAI 2019",2019,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090808159&partnerID=40&md5=aa4a0d9234dbdade2c6ff11a31ccd565,"Though deep learning systems have achieved high accuracy in detecting diseases from medical images, few such systems have been deployed in highly automated disease screening settings due to lack of trust in how well these systems can generalize to out-of-datasets. We propose to use uncertainty estimates of the deep learning system's prediction to know when to accept or to disregard its prediction. We evaluate the effectiveness of using such estimates in a real-life application for the screening of diabetic retinopathy. We also generate visual explanation of the deep learning system to convey the pixels in the image that influences its decision. Together, these reveal the deep learning system's competency and limits to the human, and in turn the human can know when to trust the deep learning system. © 2019, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved.",Diagnosis; Eye protection; Learning systems; Medical imaging; Uncertainty analysis; Diabetic retinopathy; Disease detection; Disease screening; High-accuracy; Real-life applications; Uncertainty estimates; Deep learning
Conference Paper,"Ni J., Chen Q., Liu C., Wang H., Cao Y., Liu B.",An effective CNN approach for diabetic retinopathy stage classification with dual inputs and selective data sampling,"Proceedings - 18th IEEE International Conference on Machine Learning and Applications, ICMLA 2019",2019,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85080971226&doi=10.1109%2fICMLA.2019.00260&partnerID=40&md5=e9e47e81fe4d4d520ea50ca412dd6877,"Diabetic retinopathy (DR) is a vision-threatening complication among the diabetic population and a leading cause of blindness for working-age adults. Early detection and timely treatment can reduce the occurrence of blindness due to DR. Computer-aided diagnosis have great potential to significantly improve the accuracy and speed in DR detection over the traditional manual diagnosis process. In this paper, we present a deep convolutional neural network for DR stage classification, trained and evaluated on a large dataset. Our model uses high-resolution retinal fundus images of both the left and right eyes as inputs to take advantage of more detailed retinal lesion information in images and strong correlation between both eyes. Selective data sampling (SeS) is applied in the training process to mitigate the data imbalance problem. Experiments show that our model outperforms the fine-tuned Inception-v3 model by every measure, achieving an accuracy of 87.2% and a Kappa score of 0.806 on the Kaggle dataset. © 2019 IEEE.",Convolutional neural networks; Deep learning; Image classification
Article,"Pareja-Ríos A., Ceruso S., Romero-Aroca P., Bonaque-González S.",A New Deep Learning Algorithm with Activation Mapping for Diabetic Retinopathy: Backtesting after 10 Years of Tele-Ophthalmology,Journal of Clinical Medicine,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137807863&doi=10.3390%2fjcm11174945&partnerID=40&md5=0e64fb8d2b3f77e1cfac0df09a2c9701,"We report the development of a deep learning algorithm (AI) to detect signs of diabetic retinopathy (DR) from fundus images. For this, we use a ResNet-50 neural network with a double resolution, the addition of Squeeze–Excitation blocks, pre-trained in ImageNet, and trained for 50 epochs using the Adam optimizer. The AI-based algorithm not only classifies an image as pathological or not but also detects and highlights those signs that allow DR to be identified. For development, we have used a database of about half a million images classified in a real clinical environment by family doctors (FDs), ophthalmologists, or both. The AI was able to detect more than 95% of cases worse than mild DR and had 70% fewer misclassifications of healthy cases than FDs. In addition, the AI was able to detect DR signs in 1258 patients before they were detected by FDs, representing 7.9% of the total number of DR patients detected by the FDs. These results suggest that AI is at least comparable to the evaluation of FDs. We suggest that it may be useful to use signaling tools such as an aid to diagnosis rather than an AI as a stand-alone tool. © 2022 by the authors.",artificial intelligence; deep learning; diabetic retinopathy; tele-ophthalmology
Conference Paper,"Suedumrong C., Leksakul K., Wattana P., Chaopaisarn P.",Application of Deep Convolutional Neural Networks VGG-16 and GoogLeNet for Level Diabetic Retinopathy Detection,Lecture Notes in Networks and Systems,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85119833478&doi=10.1007%2f978-3-030-89880-9_5&partnerID=40&md5=0ab18762df5b342a6232b35c228ba1d7,"Diabetic retinopathy (DR) is a diabetes complication that damages the retina. This type of medical condition affects up to 80% of patients with diabetes for 10 or more years. The expertise and equipment required are often lacking in areas where diabetic retinopathy detection is most needed. Most of the work in the field of diabetic retinopathy has been based on disease detection or manual extraction of features. Thus, this research aims at automatic diagnosis of the disease in its different stages using deep learning neural network approach. This paper presents the design and implementation of Graphic Processing Unit (hereby GPU) accelerated deep convolutional neural networks to automatically diagnose and thereby classify high-resolution retinal images into five stages of the disease based on its severity. The accuracy of the single model convolutional neural networks presented in this paper is 71.65% from VGG-16. © 2022, The Author(s), under exclusive license to Springer Nature Switzerland AG.",Convolutional neural networks; Deep learning; Diabetic retinopathy; GoogLeNet; VGG-16
Conference Paper,"Yadav M., Goel R., Rajeswari D.",A Deep Learning Based Diabetic Retinopathy Detection from Retinal Images,"2021 International Conference on Intelligent Technologies, CONIT 2021",2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85114890151&doi=10.1109%2fCONIT51480.2021.9498502&partnerID=40&md5=97fa96fa38ddf5d5e0bf0d20ec7c2d3b,"Diabetes is increased tremendously due to metabolism. Lack of early detection, prolonged diabetics might lead to medical complications such as heart problems, eye vision problems, skin issues etc. Diabetic retinopathy (DR) is a frequent abnormality of diabetics. In this paper, we propose computer vision based technique to analyze and predict diabetes from the retinal input images. This helps in an early stage detection of DR. In this image processing steps such as pre-processing, segmentation, feature extraction steps are applied. After the image processing steps, machine learning based classification step is performed. For experimental results, we used python programming language for better results. For experimental results platform, we use jupyter for developing the coding. The framework developed was evaluated on open access public repository datasets, achieving an accuracy of 98.50% using CNN as compared to the accuracy of 87.40% achieved by SVM. These results perform better than several advanced unsupervised ML techniques. It results in decrease of procedural complexity and improved assessment metrics, hence making it suitable to be used in the diagnosis of DR using retinal image analysis. © 2021 IEEE.",Diabetic retinopathy; feature extraction; machine learning algorithm; pre-processing; segmentation
Article,"Luo Y., Pan J., Fan S., Du Z., Zhang G.",Retinal Image Classification by Self-Supervised Fuzzy Clustering Network,IEEE Access,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85085640812&doi=10.1109%2fACCESS.2020.2994047&partnerID=40&md5=0f0fb2dbaef2e60e27f7293d6179a719,"Diabetic retinal image classification aims to conduct diabetic retinopathy automatically diagnosing, which has achieved considerable improvement by deep learning models. However, these methods all rely on sufficient network training by large scale annotated data, which is very labor-expensive in medical image labeling. Aiming to overcome these drawbacks, this paper focuses on embedding self-supervised framework into unsupervised deep learning architecture. Specifically, we propose a Self-supervised Fuzzy Clustering Network (SFCN) by a feature learning module, reconstruction module, and a fuzzy self-supervision module. The feature learning and reconstruction modules ensure the representative ability of the network, and fuzzy self-supervision module is in charge of further providing the training direction for the whole network. Furthermore, three losses of reconstruction, self-supervision, and fuzzy supervision jointly optimize the SFCN under an unsupervised manner. To evaluate the effectiveness of the proposed method, we implement the network on three widely used retinal image datasets, which results demonstrate the satisfied performance on unsupervised retinal image classification task. © 2013 IEEE.",fuzzy clustering; Retinal image classification; self-supervised; unsupervised learning
Article,"Dutta S., Manideep B.C.S., Basha S.M., Caytiles R.D., Iyengar N.C.S.N.",Classification of diabetic retinopathy images by using deep learning models,International Journal of Grid and Distributed Computing,2018,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85041836448&doi=10.14257%2fijgdc.2018.11.1.09&partnerID=40&md5=b03258d9452b4458d4e3708151d1d07f,"Diabetes or more precisely Diabetes Mellitus (DM) is a metabolic disorder happens because of high blood sugar level in the body. Over the time, diabetes creates eye deficiency also called as Diabetic Retinopathy (DR) causes major loss of vision. The symptoms can originate in the retinal area are augmented blood vessels, fluid drip, exudates, hemorrhages, and micro aneurysms. In modern medical science, images are the indispensable tool for precise diagnosis of patients. In the meantime evaluation of contemporary medical imageries remains complex. In recent times computer vision with Deep Neural Networks can train a model perfectly and level of accuracy also will be higher than other neural network models. In this study fundus images containing diabetic retinopathy has been taken into consideration. The idea behind this paper is to propose an automated knowledge model to identify the key antecedents of DR. Proposed Model have been trained with three types, back propagation NN, Deep Neural Network (DNN) and Convolutional Neural Network (CNN) after testing models with CPU trained Neural network gives lowest accuracy because of one hidden layers whereas the deep learning models are out performing NN. The Deep Learning models are capable of quantifying the features as blood vessels, fluid drip, exudates, hemorrhages and micro aneurysms into different classes. Model will calculate the weights which gives severity level of the patient’s eye. The foremost challenge of this study is the accurate verdict of each feature class thresholds. To identify the target class thresholds weighted Fuzzy C-means algorithm has been used. The model will be helpful to identify the proper class of severity of diabetic retinopathy images. © 2018 SERSC Australia.",Classification; Convolutional Neural Network (CNN); Deep Learning (DL); Deep Neural Network (DNN); Diabetic Retinopathy (DR); Retina; Threshold
Conference Paper,"Harshitha C., Asha A., Pushkala J.L.S., Anogini R.N.S., Karthikeyan C.",Predicting the Stages of Diabetic Retinopathy using Deep Learning,"Proceedings of the 6th International Conference on Inventive Computation Technologies, ICICT 2021",2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102553635&doi=10.1109%2fICICT50816.2021.9358801&partnerID=40&md5=a14df9848934d1a4de42f7e48523bf0d,"Diabetic Retinopathy (DR) is a very ordinary problem among diabetic patients, which in turn results in the constructive loss of vision in those patients. If this abnormality is not detected in the early stages, then there is no treatment to restore the eyesight. Hence, the only remedy from this irreversible situation is to detect this disease at an early stage and undergo treatment. To sustain the vision in the patients, the ophthalmologists use the 'fundus images' of their eyes, which the retinal images of the patients. But this detection of an abnormality in a human eye by another human naked eye is time taking, cost-consuming and it sometimes also leads to misjudgment, due to the subjective difference and considerations among the ophthalmologists. Therefore, the 'Deep Learning' methodology is used to detect Diabetic retinopathy by using the fundus images. Hence, leading to the reduction of misdiagnoses, a computer-based diagnosing system is introduced. Recently, the techniques of deep learning have become the most common method to achieve accuracy among image recognition or feature detection systems for both classification and regression. In this research, the 'Convolutional Neural Networks (CNN)' is used for image recognition, using the retinal images to train the neural network architecture and produce high accuracies. The challenges among other techniques used and problems with existing methods were also discussed in this article. © 2021 IEEE.",Convolutional Neural Networks (CNN); Deep Learning (DL); Diabetic Retinopathy (DR); Machine Learning (ML)
Conference Paper,"Shi B., Zhang X., Wang Z., Song J., Han J., Zhang Z., Toe T.T.",GoogLeNet-based Diabetic-retinopathy-detection,"2022 14th International Conference on Advanced Computational Intelligence, ICACI 2022",2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85136112069&doi=10.1109%2fICACI55529.2022.9837677&partnerID=40&md5=f359e49cce5a846f8945845fb0eed70e,"This paper is about a research in applying different neural networks for diabetic-retinopathy-detection. Respectively using basic CNNs, VGG16 and GoogLeNet trained on datasets from Aravind Eye Hospital in India including 8929 photos and validated on other 1114 photos. Experiment showed that GoogLeNet model could better identify diabetic retinopathy with a higher train accuracy around 97%, compared to the CNN model's performance of 84% and VGG16's 94%. Meanwhile, the test accuracy of GoogLeNet is 85%, relatively higher than other proposed models. The excellent performance of the GoogLeNet model shows its great potential and promises to be extended to replace ophthalmologists in the screening of patients in the future. © 2022 IEEE.",deep learning; Diabetic-Retinopathy-Detection; GoogleNet; image classification
Article,"Ragab M., Aljedaibi W.H., Nahhas A.F., Alzahrani I.R.",Computer aided diagnosis of diabetic retinopathy grading using spiking neural network,Computers and Electrical Engineering,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85129303468&doi=10.1016%2fj.compeleceng.2022.108014&partnerID=40&md5=1a09ae85543b79c04b1cab7384638178,"The recently developed deep learning models can be employed to design computer aided diagnosis (CAD) models for diabetic retinopathy (DR). Though several DR classification approaches are available in the survey, but still there is need to improve the overall DR detection performance. With this motivation, this paper design a novel metaheuristic with deep learning enabled computer aided diagnosis model for DR (MDL-CADDR) detection and grading. The proposed MDL-CADDR technique involves pre-processing stage to boost the quality of fundus images. In addition, Archimedes Optimization Algorithm (AOA) with Kapur's Entropy (AOA-KE) based image segmentation technique is applied. Moreover, Chimp Optimization Algorithm with DenseNet (COA-DN) based Feature Extraction and Spiking Neural Network (SNN) based classification processes are performed to classify distinct stages of DR. The performance validation of the MDL-CADDR technique on benchmark MESSIDOR data set pointed out the supremacy of the MDL-CADDR technique with maximum accuracy of 99.73%. © 2022 Elsevier Ltd",Computer aided diagnosis; Deep learning; Deep transfer learning; DenseNet; Diabetic retinopathy; Metaheuristics; Spiking neural network
Article,Yadav N.,Retinal blood vessels detection for diabetic retinopathy with Ridgelet transform and convolution neural network,"International Journal of Wavelets, Multiresolution and Information Processing",2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85095442138&doi=10.1142%2fS0219691320500484&partnerID=40&md5=2a8ceeccda7b24461820c6af3fb89af1,"Applying machine learning in life sciences, especially diagnostics, has become a key area of focus for researchers. Combining machine learning with traditional algorithms provides a unique opportunity of providing better solutions for the patients. In this paper, we present study results of applying the Ridgelet Transform method on retina images to enhance the blood vessels, then using machine learning algorithms to identify cases of Diabetic Retinopathy (DR). The Ridgelet transform provides better results for line singularity of image function and, thus, helps to reduce artefacts along the edges of the image. The Ridgelet Transform method, when compared with earlier known methods of image enhancement, such as Wavelet Transform and Contourlet Transform, provided satisfactory results. The transformed image using the Ridgelet Transform method with pre-processing quantifies the amount of information in the dataset. It efficiently enhances the generation of features vectors in the convolution neural network (CNN). In this study, a sample of fundus photographs was processed, which was obtained from a publicly available dataset. In pre-processing, first, CLAHE was applied, followed by filtering and application of Ridgelet transform on the patches to improve the quality of the image. Then, this processed image was used for statistical feature detection and classified by deep learning method to detect DR images from the dataset. The successful classification ratio was 98.61%. This result concludes that the transformed image of fundus using the Ridgelet Transform enables better detection by leveraging a transform-based algorithm and the deep learning. © 2020 World Scientific Publishing Company.",convolution neural network; filtering; Fundus image; histogram; Ridgelet transform
Article,"Tariq H., Rashid M., Javed A., Zafar E., Alotaibi S.S., Zia M.Y.I.",Performance analysis of deep-neural-network-based automatic diagnosis of diabetic retinopathy,Sensors,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85121765273&doi=10.3390%2fs22010205&partnerID=40&md5=91fb173c2b5f7a7fe94fdf09392ee5ae,"Diabetic retinopathy (DR) is a human eye disease that affects people who are suffering from diabetes. It causes damage to their eyes, including vision loss. It is treatable; however, it takes a long time to diagnose and may require many eye exams. Early detection of DR may prevent or delay the vision loss. Therefore, a robust, automatic and computer-based diagnosis of DR is essential. Currently, deep neural networks are being utilized in numerous medical areas to diagnose various diseases. Consequently, deep transfer learning is utilized in this article. We employ five convolutional-neural-network-based designs (AlexNet, GoogleNet, Inception V4, Inception ResNet V2 and ResNeXt-50). A collection of DR pictures is created. Subsequently, the created collections are labeled with an appropriate treatment approach. This automates the diagnosis and assists patients through subsequent therapies. Furthermore, in order to identify the severity of DR retina pictures, we use our own dataset to train deep convolutional neural networks (CNNs). Experimental results reveal that the pre-trained model Se-ResNeXt-50 obtains the best classification accuracy of 97.53% for our dataset out of all pre-trained models. Moreover, we perform five different experiments on each CNN architecture. As a result, a minimum accuracy of 84.01% is achieved for a five-degree classification. © 2021 by the authors. Licensee MDPI, Basel, Switzerland.",Automatic detection; Convolutional neural network; Deep learning; Deep transfer learning; Diabetic retinopathy
Conference Paper,"Latha R.S., Sreekanth G.R., Suganthe R.C., Bizu B., Suvalakshmi K., Venkatachalam K.",Diagnosis of Diabetic Retinopathy and Glaucoma from Retinal Images Using Deep Convolution Neural Network,"2022 International Conference on Computer Communication and Informatics, ICCCI 2022",2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85128741309&doi=10.1109%2fICCCI54379.2022.9740851&partnerID=40&md5=f3553ed2ecbbf5b4cbdd6717956f39f5,"Diabetic retinopathy and Glaucoma are major retinal diseases that are the primary sources of sightlessness in working-age people all over the universe. The diagnosis of Diabetic Retinopathy (DR) and Glaucoma through color retinal images necessitates trained professionals identifying the existence and importance of numerous small abnormalities, which is a challenging and time-consuming task due to a complex grading scale. Here we suggest a CNN approach for diagnosing Diabetic Retinopathy and Glaucoma and if provided any High - resolution fundus Image of the Retina and appropriately defining its severity, not having the same. Developed a network with Convolutional Neural Network architecture and done data augmenting that can determine the complex aspects that are implicated in the classification, such as micro aneurysms, retinal haemorrhages, and exudates. For DR, the Kaggle dataset is used, and for Glaucoma, the RIGA dataset is used. Kaggle dataset is used as an input for DR which consists of 3658 images that are classified into 5 different classes and RIGA dataset is used as an input for Glaucoma containing 2-class labels of Glaucoma with 1103 images are analyzed. Obtained good predictive accuracy of 98%, the precision of 97.6%, recall of 96%, and an F-measure of 97% an automated system, for instance, can quickly distinguish between healthy and infected retinal images, minimizing the number of clinician reviews. © 2022 IEEE.",Convolutional Neural Network; Deep learning; Diabetic retinopathy classification; Glaucoma classification; Retinal images
Conference Paper,"Lekshmi K.R., Ashok A.",Machine Learning Approach for Automated Recognition of Non-Proliferative Diabetic Retinopathy,"Proceedings - 2022 6th International Conference on Intelligent Computing and Control Systems, ICICCS 2022",2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85133162869&doi=10.1109%2fICICCS53718.2022.9788306&partnerID=40&md5=ddfea997fd254aee8e14e33ed5379307,"Diabetic Retinopathy (DR) is one of the most rampant ophthalmic disease found in diabetic patients. The damage of blood venule in the light-sensitive cell at the back of the eye causes DR. Vision impairment and vision loss are the results due to DR. Vision degradation can be prevented if diagnosed early and treated promptly. Normally clinical diagnosis is done by the visual examination of the fundus manually by an ophthalmologist. This technique is time-consuming and costly. Today emerging technologies in health care aims to reduce the cost of treatment and early diagnosis. For solving this problem, a computerized detection method is proposed for the early prediction of DR, i.e., non-proliferative diabetic retinopathy (NPDR). Many studies are being conducted to help in the early detection of DR. Any computer-assisted detection technique include segmentation, extraction of features, and classification. These approaches, on the other hand, are unable to capture the deep complex features and can only classify DR's prediction with a poor degree of accuracy. In this work, forty-nine features of each candidate object are extracted and classify them as normal verse abnormal using machine learning algorithms. MESSIDOR dataset having 1200 fundus images are used for the classification of DR. The experimental findings reveal that this technique outperforms KNN (K- Nearest Neighbour), SVM (Support Vector Machine), and NB (Naive Bayes) in recognising the existence of DR. In this method SVM performs high accuracy of 98% in prediction of DR. © 2022 IEEE.",Diabetic Retinopathy; Fundus image; KNN; Messidor; Naive Bayes; NPDR; SVM
Article,"Shaik N.S., Cherukuri T.K.",Hinge attention network: A joint model for diabetic retinopathy severity grading,Applied Intelligence,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85126101706&doi=10.1007%2fs10489-021-03043-5&partnerID=40&md5=5d0654d5dd61c90919055beb8db79b95,"Diabetic Retinopathy is one of the prominent reasons for permanent blindness in working age, long term diabetic patients. With the prevalence in raise of diabetics, majority of the people are endangered to permanent vision loss. The advancements in medical imaging techniques enabled the research community to focus on developing automated and computerized systems for diagnosing retinopathy in early stages. But, it is a very complex challenge due to the presence of high intra-class variations and imbalanced data distribution for higher grades of severity. In recent years, various deep learning based models have been designed for automating the process of retinopathy severity classification. In this research work, we present a fascinating deep learning model with multiple attention stages called Hinge Attention Network (HA-Net). Proposed model consists of a pre-trained VGG16 base to extract initial spatial representation from retinal scan images, spatial attention autoencoder to learn lesion specific latent representations in spatial dimensions and a channel attention based hinge neural network to grab category based discriminative features in channel dimension and classify the severity grade of retinopathy. In addition to spatial and channel attention mechanism, we use Convolutional LSTM layer to prioritize highly important spatial maps before passing to hinge neural network. All these components of HA-Net, enabled it to make generalised and accurate predictions on unseen data. The effectiveness and acceptability of proposed model is proved by validating it using two benchmark datasets, Kaggle APTOS 2019 and ISBI IDRiD. Extensive experimental studies on these datasets reveal that, proposed HA-Net outstrip several existing models by achieving an accuracy of 85.54% on Kaggle APTOS, and an accuracy of 66.41% on IDRiD datasets. © 2022, The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature.",Attention autoencoder; Channel attention; Convolutional LSTM; Diabetic retinopathy (DR); Hinge neural network; Pre-trained models; Spatial attention; Spatial sequence attention; Transfer learning; Visual geometry group net (VGG16)
Article,Toğaçar M.,Detection of retinopathy disease using morphological gradient and segmentation approaches in fundus images,Computer Methods and Programs in Biomedicine,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85120968775&doi=10.1016%2fj.cmpb.2021.106579&partnerID=40&md5=4fb8a71531693cd6c32c499cc0fdcf8b,"Background and objective: Diabetes-related cases can cause glaucoma, cataracts, optic neuritis, paralysis of the eye muscles, or various retinal damages over time. Diabetic retinopathy is the most common form of blindness that occurs with diabetes. Diabetic retinopathy is a disease that occurs when the blood vessels in the retina of the eye become damaged, leading to loss of vision in advanced stages. This disease can occur in any diabetic patient, and the most important factor in treating the disease is early diagnosis. Nowadays, deep learning models and machine learning methods, which are open to technological developments, are already used in early diagnosis systems. In this study, two publicly available datasets were used. The datasets consist of five types according to the severity of diabetic retinopathy. The objectives of the proposed approach in diabetic retinopathy detection are to positively contribute to the performance of CNN models by processing fundus images through preprocessing steps (morphological gradient and segmentation approaches). The other goal is to detect efficient sets from type-based activation sets obtained from CNN models using Atom Search Optimization method and increase the classification success. Methods: The proposed approach consists of three steps. In the first step, the Morphological Gradient method is used to prevent parasitism in each image, and the ocular vessels in fundus images are extracted using the segmentation method. In the second step, the datasets are trained with transfer learning models and the activations for each class type in the last fully connected layers of these models are extracted. In the last step, the Atom Search optimization method is used, and the most dominant activation class is selected from the extracted activations on a class basis. Results: When classified by the severity of diabetic retinopathy, an overall accuracy of 99.59% was achieved for dataset #1 and 99.81% for dataset #2. Conclusions: In this study, it was found that the overall accuracy achieved with the proposed approach increased. To achieve this increase, the application of preprocessing steps and the selection of the dominant activation sets from the deep learning models were implemented using the Atom Search optimization method. © 2021 Elsevier B.V.",Atom search optimization; Diabetic retinopathy; Morphological gradient and segmentation; Selection of dominant activations
Conference Paper,"Dong C.W., Xia D., Jin J., Yang Z.",Classification of diabetic retinopathy based on DSIRNet,"14th International Conference on Computer Science and Education, ICCSE 2019",2019,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85073254581&doi=10.1109%2fICCSE.2019.8845497&partnerID=40&md5=c76945c902510989fb599b5b4a4506ad,"The rapid development of deep learning in recent years has achieved great success in the fields of speech recognition, image recognition and natural language processing. At present, the automatic diagnosis of medical images is the focus of attention from all walks of life, and deep learning technology has shown good application prospects in this respect. In response to the screening of diabetic retinopathy, this paper proposes a deep supervision of the Inception-Residual network(DSIRNet) to classify DR images end-to-end. The network combines the advantages of Inception module and residual module, which can not only learn multi-scale features, but also ensure the transmission of feature information between network layers. At the same time, this paper also uses deep monitoring method to assist the training network, which can improve thermal classification effect of the network to a certain extent. In terms of data sets, data noise and sample distribution imbalances are also addressed. The effectiveness of the proposed model and method is verified by comparative experiments. © 2019 IEEE.",Convolutional neural network; Deep learning; Diabetic retinopathy; Image processing
Article,"Cao K., Xu J., Zhao W.-Q.",Artificial intelligence on diabetic retinopathy diagnosis: An automatic classification method based on grey level co-occurrence matrix and naive Bayesian model,International Journal of Ophthalmology,2019,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85074081112&doi=10.18240%2fijo.2019.07.17&partnerID=40&md5=ac90ba72a3852195e4ce978c745647a1,"• AIM: To develop an automatic tool on screening diabetic retinopathy (DR) from diabetic patients. • METHODS: We extracted textures from eye fundus images of each diabetes subject using grey level co-occurrence matrix method and trained a Bayesian model based on these textures. The receiver operating characteristic (ROC) curve was used to estimate the sensitivity and specificity of the Bayesian model. • RESULTS: A total of 1000 eyes fundus images from diabetic patients in which 298 eyes were diagnosed as DR by two ophthalmologists. The Bayesian model was trained using four extracted textures including contrast, entropy, angular second moment and correlation using a training dataset. The Bayesian model achieved a sensitivity of 0.949 and a specificity of 0.928 in the validation dataset. The area under the ROC curve was 0.938, and the 10-fold cross validation method showed that the average accuracy rate is 93.5%. • CONCLUSION: Textures extracted by grey level cooccurrence can be useful information for DR diagnosis, and a trained Bayesian model based on these textures can be an effective tool for DR screening among diabetic patients. © 2019 International Journal of Ophthalmology (c/o Editorial Office). All rights reserved.",Artificial intelligence; Bayesian; Diabetic retinopathy; Grey level co-occurrence matrix; Receiver operating characteristic curve; Textures
Article,"Santos C., Aguiar M., Welfer D., Belloni B.",A New Approach for Detecting Fundus Lesions Using Image Processing and Deep Neural Network Architecture Based on YOLO Model,Sensors,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137544033&doi=10.3390%2fs22176441&partnerID=40&md5=7fe6b0116ec2c7b2e89e4230ef74ebbe,"Diabetic Retinopathy is one of the main causes of vision loss, and in its initial stages, it presents with fundus lesions, such as microaneurysms, hard exudates, hemorrhages, and soft exudates. Computational models capable of detecting these lesions can help in the early diagnosis of the disease and prevent the manifestation of more severe forms of lesions, helping in screening and defining the best form of treatment. However, the detection of these lesions through computerized systems is a challenge due to numerous factors, such as the characteristics of size and shape of the lesions, noise and the contrast of images available in the public datasets of Diabetic Retinopathy, the number of labeled examples of these lesions available in the datasets and the difficulty of deep learning algorithms in detecting very small objects in digital images. Thus, to overcome these problems, this work proposes a new approach based on image processing techniques, data augmentation, transfer learning, and deep neural networks to assist in the medical diagnosis of fundus lesions. The proposed approach was trained, adjusted, and tested using the public DDR and IDRiD Diabetic Retinopathy datasets and implemented in the PyTorch framework based on the YOLOv5 model. The proposed approach reached in the DDR dataset an mAP of 0.2630 for the IoU limit of 0.5 and F1-score of 0.3485 in the validation stage, and an mAP of 0.1540 for the IoU limit of 0.5 and F1-score of 0.2521, in the test stage. The results obtained in the experiments demonstrate that the proposed approach presented superior results to works with the same purpose found in the literature. © 2022 by the authors.",deep learning; Diabetic Retinopathy; fundus images; lesions detection; YOLO
Conference Paper,"Niu Y., Gu L., Lu F., Lv F., Wang Z., Sato I., Zhang Z., Xiao Y., Dai X., Cheng T.",Pathological evidence exploration in deep retinal image diagnosis,"33rd AAAI Conference on Artificial Intelligence, AAAI 2019, 31st Innovative Applications of Artificial Intelligence Conference, IAAI 2019 and the 9th AAAI Symposium on Educational Advances in Artificial Intelligence, EAAI 2019",2019,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85070664293&partnerID=40&md5=3ebabb6de38636800c346153e7a27e40,"Though deep learning has shown successful performance in classifying the label and severity stage of certain disease, most of them give few evidence on how to make prediction. Here, we propose to exploit the interpretability of deep learning application in medical diagnosis. Inspired by Koch's Postulates, a well-known strategy in medical research to identify the property of pathogen, we define a pathological descriptor that can be extracted from the activated neurons of a diabetic retinopathy detector. To visualize the symptom and feature encoded in this descriptor, we propose a GAN based method to synthesize pathological retinal image given the descriptor and a binary vessel segmentation. Besides, with this descriptor, we can arbitrarily manipulate the position and quantity of lesions. As verified by a panel of 5 licensed ophthalmologists, our synthesized images carry the symptoms that are directly related to diabetic retinopathy diagnosis. The panel survey also shows that our generated images is both qualitatively and quantitatively superior to existing methods. © 2019, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved.",Computer aided instruction; Diagnosis; Eye protection; Image segmentation; Ophthalmology; Descriptors; Diabetic retinopathy; Interpretability; Medical research; Pathological retinal images; Retinal image; Synthesized images; Vessel segmentation; Deep learning
Conference Paper,"Arumugam S.R., Devi E.A., Rajeshram V., Balakrishna R., Karuppasamy S.G., Kumar S.V.",A Robust Approach based on CNN-LSTM Network for the identification of diabetic retinopathy from Fundus Images,"Proceedings of the 2022 International Conference on Electronic Systems and Intelligent Computing, ICESIC 2022",2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85133264640&doi=10.1109%2fICESIC53714.2022.9783570&partnerID=40&md5=2d1ed10d4c58dce0a26519893ee253b3,"Diabetic retinopathy (DR) is a condition that infects the eyes that involve people with diabetes losing their vision. It influences the blood vessels of the eye. Sometimes people complain about eyesight problems, such as difficulties reading or seeing too far away. The retina's blood vessels begin to bleed in the later disease later stages. Highly trained experts typically examine coloured fundus images to detect this fatal condition. This condition's manual diagnosis is time-consuming and error-prone. As a result, many computers vision-based algorithms for automatically detecting DR and its various stages from retina images have been presented. We used the Kaggle retina image dataset for this study, which is openly accessible. We introduced a convolutional neural network (CNN), and long short-term memory (LSTM) based deep learning technique for diagnosing diabetic retinopathy. The system attains better performance than the existing systems. © 2022 IEEE.",CNN; deep learning; Diabetic retinopathy; fundus images; Kaggle; LSTM
Conference Paper,"Panwar A., Semwal G., Goel S., Gupta S.",Stratification of the Lesions in Color Fundus Images of Diabetic Retinopathy Patients Using Deep Learning Models and Machine Learning Classifiers,Lecture Notes in Electrical Engineering,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85128491824&doi=10.1007%2f978-981-19-0019-8_49&partnerID=40&md5=7d46ff30dfab5363eedb3307168a478b,"Diabetic Retinopathy (DR) is a frequently occurring eye disease that is diagnosed in people suffering from diabetes for a long period of time. Patients who live with diabetes for a long duration of time exhibit mild to severe symptoms of DR. This pathos flourishes gradually and leads to complete blindness over time. The diagnosis of DR is a time-consuming and error-prone process for ophthalmologists due to the pictorial complexities of the images. Therefore, a method based on Machine Learning (ML) and Deep Learning (DL) is proposed to classify the retinal fundus images of the patients into classes based on the severity level of the disease. We employ a CNN architecture armed with the power of deep learning and pre-trained with Transfer Learning to accomplish the task. Outsmarting the already existing approaches, the proposed model functions via extracting a feature vector from the test set of the images which on feeding to classifier models can classify the new images with high accuracy. In our work, we apply various CNN models to extract the features from several diabetic fundus images. The extracted features are provided as the input to various classifiers which as a result classify several lesions accurately. The results show that using deep learning along with transfer learning can accurately classify the fundus images into the right category of lesions. © 2022, The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd.",Diabetic retinopathy; Image classification; Transfer learning
Article,"Straňák Z., Penčák M., Veith M.",VYU&#381;ITÍ UM&#282;LÉ INTELIGENCE V ZÁCHYTU DIABETICKÉ RETINOPATIE. P&#344;EHLED [ARTIFICIAL INTELLIGENCE IN DIABETIC RETINOPATHY SCREENING. A REVIEW],Ceska a slovenska oftalmologie : casopis Ceske oftalmologicke spolecnosti a Slovenske oftalmologicke spolecnosti,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85107998346&partnerID=40&md5=8fbe1a741590bba03a63b943360c3432,"OBJECTIVE: The aim of this comprehensive paper is to acquaint the readers with evaluation of the retinal images using the arteficial intelligence (AI). Main focus of the paper is diabetic retinophaty (DR) screening. The basic principles of the artificial intelligence and algorithms that are already used in clinical practice or are shortly before approval will be described. METHODOLOGY: Describing the basic characteristics and mechanisms of different approaches to the use of AI and subsequently literary minireview clarifying the current state of knowledge in the area. RESULTS: Modern systems for screening diabetic retinopathy using deep neural networks achieve a sensitivity and specificity of over 80 % in most published studies. The results of specific studies vary depending on the definition of the gold standard, number of images tested and on the evaluated parameters. CONCLUSION: Evaluation of images using AI will speed up and streamline the diagnosis of DR. The use of AI will allow to keep the quality of the eye care at least on the same level despite the raising number of the patients with diabetes.",artificial intelligence; diabetic retinopathy; Diabetic retinopathy; mass screening; screening
Article,"Alqudah A.M., Alquran H., Abu-Qasmieh I., Al-Badarneh A.",Employing image processing techniques and artificial intelligence for automated eye diagnosis using digital eye fundus images,"Journal of Biomimetics, Biomaterials and Biomedical Engineering",2018,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85063079251&doi=10.4028%2fwww.scientific.net%2fJBBBE.39.40&partnerID=40&md5=2b589cfd3456def4856eecc32889815e,"Blindness usually comes from two main causes, glaucoma and diabetes. Robust mass screening is performed for diagnosing, such as screening that requires a cost-effective method for glaucoma and diabetic retinopathy and integrates well with digital medical imaging, image processing, and administrative processes. For addressing all these issues, we propose a novel low-cost automated glaucoma and diabetic retinopathy diagnosis system, based on features extraction from digital eye fundus images. This paper proposes a diagnosis system for automated identification of healthy, glaucoma, and diabetic retinopathy. Using a combination of local binary pattern features, Gabor filter features, statistical features, and color features which are then fed to an artificial neural network and support vector machine classifiers. In this work, the classifier identifies healthy, glaucoma, and diabetic retinopathy images with an accuracy of 91.1%,92.9%, 92.9%, and 92.3% and sensitivity of 91.06%, 92.6%, 92.66%, and 91.73% and specificity of 89.83%, 91.26%, 91.96%, and 89.16% for ANN, and an accuracy of 90.0%,92.94%, 95.43%, and 97.92% and sensitivity of 89.34%, 93.26%, 95.72%, and 97.93% and specificity of 95.13%, 96.68%, 97.88%, and 99.05% for SVM, based on 5, 10, 15, and 31 number of selected features. The proposed system can detect glaucoma, diabetic retinopathy and normal cases with high accuracy and sensitivity using selected features, the performance of the system is high due to using of a huge fundus database. © 2018 Trans Tech Publications, Switzerland",Classification; Diabetic Retinopathy; Diagnosis; Eye Fundus; Glaucoma
Conference Paper,"Zhao Z., Chopra K., Zeng Z., Li X.",Sea-Net: Squeeze-And-Excitation Attention Net for Diabetic Retinopathy Grading,"Proceedings - International Conference on Image Processing, ICIP",2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85098637817&doi=10.1109%2fICIP40778.2020.9191345&partnerID=40&md5=d7c59da4744a90b532e6b338121ee080,"Diabetes is one of the most common disease in individuals. Diabetic retinopathy (DR) is a complication of diabetes, which could lead to blindness. Automatic DR grading based on retinal images provides a great diagnostic and prognostic value for treatment planning. However, the subtle differences among severity levels make it difficult to capture important features using conventional methods. To alleviate the problems, a new deep learning architecture for robust DR grading is proposed, referred to as SEA-Net, in which, spatial attention and channel attention are alternatively carried out and boosted with each other, improving the classification performance. In addition, a hybrid loss function is proposed to further maximize the inter-class distance and reduce the intraclass variability. Experimental results have shown the effectiveness of the proposed architecture. © 2020 IEEE.",Attention mechanism; Convolutional neural network; Diabetic retinopathy grading; Squeeze-and-Excitation net
Article,"Ravala L., Rajini G.K.",Automatic Diagnosis of Diabetic Retinopathy from Retinal Abnormalities: Improved Jaya-Based Feature Selection and Recurrent Neural Network,Computer Journal,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85134880419&doi=10.1093%2fcomjnl%2fbxab068&partnerID=40&md5=cd6aefefd7636cd1186f67de93584b58,"Accurate diagnosis of lesions bears the highest significance in the early detection of diabetic retinopathy (DR). In this paper, the combination of intelligent methods is developed for segmenting the abnormalities like ‘hard exudates, hemorrhages, microaneurysm and soft exudates’ to detect the DR. The proposed model involves seven main steps: (a) image pre-processing, (b) optic disk removal (c) blood vessel removal, (d) segmentation of abnormalities, (e) feature extraction, (f) optimal feature selection and (f) classification. The pre-processing of the input retinal fundus image is performed by two operations like contrast enhancement by histogram equalization and filtering by average filtering. For the segmentation of abnormalities, the same Circular Hough Transform followed by Top-hat filtering and Gabor filtering is used. Next, the entropy-scale-invariant feature transform (SIFT), grey level co-occurrence matrices and color morphological features are extracted in feature extraction. The optimally selected features are subjected to the classification part, which uses a modified deep learning algorithm called optimized recurrent neural network (RNN). As the main novelty, the optimal feature selection and optimized RNN depends on an improved meta-heuristic algorithm called fitness oriented improved Jaya algorithm. Hence, the beneficial part of the optimization algorithm improves the feature selection and classification. © The British Computer Society 2021. All rights reserved.",diagnosis of diabetic retinopathy; feature extraction; fitness oriented improved Jaya algorithm; novel blood vessel segmentation algorithm; optimal feature selection; recurrent neural network
Article,"Bengani S., Angel Arul Jothi J., Vadivel S.",Automatic segmentation of optic disc in retinal fundus images using semi-supervised deep learning,Multimedia Tools and Applications,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85091266818&doi=10.1007%2fs11042-020-09778-6&partnerID=40&md5=54bad217839a0795dd5e5afaf9e529fa,"Diseases of the eye require manual segmentation and examination of the optic disc by ophthalmologists. Though, image segmentation using deep learning techniques is achieving remarkable results, it leverages on large-scale labeled datasets. But, in the field of medical imaging, it is challenging to acquire large labeled datasets. Hence, this article proposes a novel deep learning model to automatically segment the optic disc in retinal fundus images by using the concepts of semi-supervised learning and transfer learning. Initially, a convolutional autoencoder (CAE) is trained to automatically learn features from a large number of unlabeled fundus images available from the Kaggle’s diabetic retinopathy (DR) dataset. The autoencoder (AE) learns the features from the unlabeled images by reconstructing the input images and becomes a pre-trained network (model). After this, the pre-trained autoencoder network is converted into a segmentation network. Later, using transfer learning, the segmentation network is trained with retinal fundus images along with their corresponding optic disc ground truth images from the DRISHTI GS1 and RIM-ONE datasets. The trained segmentation network is then tested on retinal fundus images from the test set of DRISHTI GS1 and RIM-ONE datasets. The experimental results show that the proposed method performs on par with the state-of-the-art methods achieving a 0.967 and 0.902 dice score coefficient on the test set of the DRISHTI GS1 and RIM-ONE datasets respectively. The proposed method also shows that transfer learning and semi-supervised learning overcomes the barrier imposed by the large labeled dataset. The proposed segmentation model can be used in automatic retinal image processing systems for diagnosing diseases of the eye. © 2020, Springer Science+Business Media, LLC, part of Springer Nature.",Autoencoder; Convolutional neural network; Deep learning; Optic disc; Segmentation; Semi-supervised learning; Transfer learning
Article,"Bhardwaj C., Jain S., Sood M.",Deep Learning–Based Diabetic Retinopathy Severity Grading System Employing Quadrant Ensemble Model,Journal of Digital Imaging,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102240822&doi=10.1007%2fs10278-021-00418-5&partnerID=40&md5=1d0992a6ca32d6046d764c554100a891,"The diabetic retinopathy accounts in the deterioration of retinal blood vessels leading to a serious compilation affecting the eyes. The automated DR diagnosis frameworks are critically important for the early identification and detection of these eye-related problems, helping the ophthalmic experts in providing the second opinion for effectual treatment. The deep learning techniques have evolved as an improvement over the conventional approaches, which are dependent on the handcrafted feature extraction. To address the issue of proficient DR discrimination, the authors have proposed a quadrant ensemble automated DR grading approach by implementing InceptionResnet-V2 deep neural network framework. The presented model incorporates histogram equalization, optical disc localization, and quadrant cropping along with the data augmentation step for improving the network performance. A superior accuracy performance of 93.33% is observed for the proposed framework, and a significant reduction of 0.325 is noticed in the cross-entropy loss function for MESSIDOR benchmark dataset; however, its validation utilizing the latest IDRiD dataset establishes its generalization ability. The accuracy improvement of 13.58% is observed when the proposed QEIRV-2 model is compared with the classical Inception-V3 CNN model. To justify the viability of the proposed framework, its performance is compared with the existing state-of-the-art approaches and 25.23% of accuracy improvement is observed. © 2021, Society for Imaging Informatics in Medicine.",Convolution neural network; Data augmentation; Deep neural network; Diabetic retinopathy; Hand-crafted features; InceptionResnet-V2
Article,"Serener A., Serte S.",Geographic variation and ethnicity in diabetic retinopathy detection via deep learning,Turkish Journal of Electrical Engineering and Computer Sciences,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85085010842&doi=10.3906%2felk-1902-131&partnerID=40&md5=b86d0463c9daa0e7927771862a06833b,"The prevalence of diabetes is on the rise steadily around the globe. Diabetic retinopathy (DR) is a result of damage to the blood vessels in the retina due to diabetes and its fast treatment is crucial for preventing possible blindness. The diagnosis of DR is done mostly using a comprehensive eye exam, where the eye is dilated for better inspection. Analysis by an ophthalmologist is prone to human error and thus automatic and highly accurate detection of DR is preferred for an earlier and better diagnosis. It is important, however, that automatic detection be accurate for all data collected from patients of different geographic and ethnic backgrounds. In this paper, the automatic detection of DR with a deep learning algorithm is analyzed when geographic and ethnic information of the patients is also integrated into the architecture. It is shown that robust and generalizable DR detection performance is linearly related to the correlation of geographic and ethnic patient information between the training and the testing datasets. The deep learning model created eliminates geographic variation in the detection and works for patients of all ethnicities. © 2020 Turkiye Klinikleri. All rights reserved.",Deep learning; Diabetic retinopathy; Ethnicity; Fundus images; Geographic variation
Conference Paper,"Adarsh R., Amarnageswarao G., Pandeeswari R., Deivalakshmi S.",Dense Residual Convolutional Auto Encoder for Retinal Blood Vessels Segmentation,"2020 6th International Conference on Advanced Computing and Communication Systems, ICACCS 2020",2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85084666104&doi=10.1109%2fICACCS48705.2020.9074172&partnerID=40&md5=88a19ed72bed7b691fb8bde354300e6c,"In order to overcome the difficulties in retinal blood vessel segmentation and aid ophthalmologists in diagnosis of diabetic retinopathy and glaucoma, there is a need for effective segmentation techniques. One such efficient technique is to use a model for segmentation using deep learning. In this paper, an auto encoder deep learning network model based on residual path and U-net has been implemented to effectively segment the retinal blood vessels. Our network model has been implemented and tested on DRIVE dataset. This proposed model is reporting an increase in efficiency and Area under ROC compared to previous methods. © 2020 IEEE.",medical image segmentation; Residual Network; Retinal vessels; U-net
Article,"Derwin D.J., Shan B.P., Singh O.J.",Hybrid multi-kernel SVM algorithm for detection of microaneurysm in color fundus images,Medical and Biological Engineering and Computing,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85127468635&doi=10.1007%2fs11517-022-02534-y&partnerID=40&md5=a71d92fc1ed6ec3f4ae722c1d03008ef,"Diabetic retinopathy (DR) is a chronic disease that may cause vision loss in diabetic patients. Microaneurysms which are characterized by small red spots on the retina due to fluid or blood leakage from the weak capillary wall often occur during the early stage of DR, making screening at this stage is essential. In this paper, an automatic screening system for early detection of DR in retinal images is developed using a combined shape and texture features. Due to minimum number of hand-crafted features, the computational burden is much reduced. The proposed hybrid multi-kernel support vector machine classifier is constructed by learning a kernel model formed as a combination of the base kernels. This approach outperforms the recent deep learning techniques in terms of the evaluation metrics. The efficiency of the proposed scheme is experimentally validated on three public datasets — Retinopathy Online Challenge, DIARETdB1, MESSIDOR, and AGAR300 (developed for this study). Studies reveal that the proposed model produced the best results of 0.503 in ROC dataset, 0.481 in DIARETdB1, and 0.464 in the MESSIDOR dataset in terms of FROC score. The AGAR300 database outperforms the existing MA detection algorithm in terms of FROC, AUC, F1 score, precision, sensitivity, and specificity which guarantees the robustness of this system. Graphical abstract: [Figure not available: see fulltext.] © 2022, International Federation for Medical and Biological Engineering.",Diabetic retinopathy; Fundus image; Gradient weighting; Hybrid multi-kernel support vector machine; Microaneurysm
Article,"Abdelmaksoud E., El-Sappagh S., Barakat S., Abuhmed T., Elmogy M.",Automatic Diabetic Retinopathy Grading System Based on Detecting Multiple Retinal Lesions,IEEE Access,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099725193&doi=10.1109%2fACCESS.2021.3052870&partnerID=40&md5=464c50804f5e3777b9d0e5642db2d6c7,"Multi-label classification (MLC) is considered an essential research subject in the computer vision field, principally in medical image analysis. For this merit, we derive benefits from MLC to diagnose multiple grades of diabetic retinopathy (DR) from various colored fundus images, especially from multi-label (ML) datasets. Therefore, ophthalmologists can detect early signs of DR as well as various grades to initiate appropriate treatment and avoid DR complications. In this paper, we propose a comprehensive ML computer-aided diagnosis (CAD) system based on deep learning technique. The proposed system's main contribution is to detect and analyze various pathological changes accompanying DR development in the retina without injecting the patient with dye or making expensive scans. The proposed ML-CAD system visualizes the different pathological changes and diagnoses the DR grades for the ophthalmologists. First, we eliminate noise, enhance quality, and standardize the sizes of the retinal images. Second, we differentiated between the healthy and DR cases by calculating the gray level run length matrix average in four different directions. The system automatically extracts the four changes: exudates, microaneurysms, hemorrhages, and blood vessels by utilizing a deep learning technique (U-Net). Next, we extract six features, which are the gray level co-occurrence matrix, areas of the four segmenting pathology variations, and the bifurcation points count of the blood vessels. Finally, the resulting features were afforded to an ML support vector machine (SVM) based on a classifier chain to differentiate the various DR grades. We utilized eight benchmark datasets (four of them are considered ML) and six different performance evaluation metrics to evaluate the proposed system's performance. It achieved 95.1%, 91.9%, 86.1%, 86.8%, 84.7%, 86.2% for accuracy, area under the curve, sensitivity, specificity, positive predictive value, and dice similarity coefficient, respectively. The experiments show encouraging results as compared with other systems. © 2013 IEEE.",deep learning (DL); diabetic retinopathy (DR); multi-label classification (MLC); Multi-label computer-aided diagnosis (ML-CAD); U-Net
Article,"Huang C., Zong Y., Ding Y., Luo X., Clawson K., Peng Y.",A new deep learning approach for the retinal hard exudates detection based on superpixel multi-feature extraction and patch-based CNN,Neurocomputing,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099607549&doi=10.1016%2fj.neucom.2020.07.145&partnerID=40&md5=33b00914e612050412c1156259097390,"Diabetic Retinopathy (DR) is a severe complication of chronic diabetes causing significant visual deterioration and may lead to blindness with delay of being treated. Exudative diabetic maculopathy, a form of macular edema where hard exudates (HE) develop, is a frequent cause of visual deterioration in DR. The detection of HE comprises a significant role in the DR diagnosis. In this paper, an automatic exudates detection method based on superpixel multi-feature extraction and patch-based deep convolutional neural network is proposed. Firstly, superpixels, regarded as candidates, are generated on each resized image using the superpixel segmentation algorithm called Simple Linear Iterative Clustering (SLIC). Then, 25 features extracted from resized images and patches are generated on each feature. Patches are subsequently used to train a deep convolutional neural network, which distinguishes the hard exudates from the background. Experiments conducted on three publicly available datasets (DiaretDB1, e-ophtha EX and IDRiD) demonstrate that our proposed methodology achieved superior HE detection when compared with current state-of-art algorithms. © 2020 Elsevier B.V.",Automatic diagnosis; Deep learning; Feature extraction; Retinal hard exudates; Superpixel
Article,"Dayana A.M., Emmanuel W.R.S.",Deep learning enabled optimized feature selection and classification for grading diabetic retinopathy severity in the fundus image,Neural Computing and Applications,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85132348206&doi=10.1007%2fs00521-022-07471-3&partnerID=40&md5=c3fb9681ff25fd5a2d806758ec33dd44,"Diabetic Retinopathy (DR), one of the most progressive sight-threatening diseases caused by the long-term diabetic condition, can lead to vision impairment and blindness later. Early diagnosis and timely treatment help control and avert DR from its progression. However, manual grading is exceptionally challenging and arduous due to the complex anatomical features in the retina. Therefore, developing an automated diagnostic method for screening DR is obligatory. This paper proposes a deep learning-enabled optimized feature selection approach to classify the stage of DR severity in the fundus image. At first, a pre-processing phase eradicates the noise and improves the contrast in the retinal fundus image. Then, blood vessel segmentation is performed using the Coherence Enhancing Energy Based Regularized Level Set Evolution method in the green channel fundus image. Subsequently, the optic disk is segmented with Canny Anisotropic Diffusion filter and morphological transformations. Next, the candidate lesion region is detected using an Attention-based Fusion Network (AFU-Net). Then, shape and texture features are extracted, and then, the optimal subset of features is selected using the Improved Harris Hawk Optimization algorithm. Finally, a deep Convolutional Neural Network classifies the DR stages, and the model weight is updated using the same algorithm. The proposed method achieved superior performance in two benchmark public datasets compared with the existing state-of-the-art methods using F1-score, accuracy, sensitivity, and specificity measures. © 2022, The Author(s), under exclusive licence to Springer-Verlag London Ltd., part of Springer Nature.",Anisotropic diffusion filter; Convolutional neural network; Diabetic retinopathy; Fusion network; Harris hawk optimization
Article,"Hemanth D.J., Deperlioglu O., Kose U.",An enhanced diabetic retinopathy detection and classification approach using deep convolutional neural network,Neural Computing and Applications,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85059473749&doi=10.1007%2fs00521-018-03974-0&partnerID=40&md5=5e6f1a2aca4b8b1679fa97b3b112ed99,"The objective of this study is to propose an alternative, hybrid solution method for diagnosing diabetic retinopathy from retinal fundus images. In detail, the hybrid method is based on using both image processing and deep learning for improved results. In medical image processing, reliable diabetic retinopathy detection from digital fundus images is known as an open problem and needs alternative solutions to be developed. In this context, manual interpretation of retinal fundus images requires the magnitude of work, expertise, and over-processing time. So, doctors need support from imaging and computer vision systems and the next step is widely associated with use of intelligent diagnosis systems. The solution method proposed in this study includes employment of image processing with histogram equalization, and the contrast limited adaptive histogram equalization techniques. Next, the diagnosis is performed by the classification of a convolutional neural network. The method was validated using 400 retinal fundus images within the MESSIDOR database, and average values for different performance evaluation parameters were obtained as accuracy 97%, sensitivity (recall) 94%, specificity 98%, precision 94%, FScore 94%, and GMean 95%. In addition to those results, a general comparison of with some previously carried out studies has also shown that the introduced method is efficient and successful enough at diagnosing diabetic retinopathy from retinal fundus images. By employing the related image processing techniques and deep learning for diagnosing diabetic retinopathy, the proposed method and the research results are valuable contributions to the associated literature. © 2019, Springer-Verlag London Ltd., part of Springer Nature.",Convolutional neural network; Deep learning; Diabetic retinopathy; Image processing
Conference Paper,"Zeng M., Fang J., Miao H., Zhang T., Liu J.",A Multi-Scale Self-Attention Network for Diabetic Retinopathy Retrieval,ACM International Conference Proceeding Series,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85120532249&doi=10.1145%2f3484274.3484290&partnerID=40&md5=3482d56614a8331565d2a81b3000180d,"Diabetic retinopathy (DR), a complication due to diabetes, is a common cause of progressive damage to the retina. The mass screening of populations for DR is time-consuming. Therefore, computerized diagnosis is of great significance in the clinical practice, which providing evidence to assist clinicians in decision making. Specifically, hemorrhages, microaneurysms, hard exudates, soft exudates, and other lesions are verified to be closely associated with DR. These lesions, however, are scattered in different positions and sizes in fundus images, the internal relation of which are hard to be reserved in the ultimate features due to a large number of convolution layers that reduce the detail characteristics. In this paper, we present a deep-learning network with a multi-scale self-attention module to aggregate the global context to learned features for DR image retrieval. The multi-scale fusion enhances, in terms of scale, the efficacious latent relation of different positions in features explored by the self-attention. For the experiment, the proposed network is validated on the Kaggle DR dataset, and the result shows that it achieves state-of-the-art performance. © 2021 ACM.",Deep learning; Diabetic retinopathy; Image retrieval; Self-attention
Conference Paper,"Wang K., Zhang X., Huang S., Wang Q., Chen F.",CTF-Net: Retinal Vessel Segmentation via Deep Coarse-To-Fine Supervision Network,Proceedings - International Symposium on Biomedical Imaging,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85085865115&doi=10.1109%2fISBI45749.2020.9098742&partnerID=40&md5=1aa891461f582dad4adde79af2faeb5e,"Retinal blood vessels structure plays an important role in the early diagnosis of diabetic retinopathy, which is a cause of blindness globally. However, the precise segmentation of retinal vessels is often extremely challenging due to the low contrast and noise of the capillaries. In this paper, we propose a novel model of deep coarse-to-fine supervision network (CTF-Net) to solve this problem. This model consists of two U-shaped architecture(coarse and fine segNet). The coarse segNet, which learns to predict probability retina map from input patchs, while the fine segNet refines the predicted map. To gain more paths to preserve the multi-scale and rich deep features information, we design an end-to-end training network instead of multi-stage learning framework to segment the retina vessel from coarse to fine. Furthermore, in order to improve feature representation and reduce the number of parameters of model, we introduce a novel feature augmentation module (FAM-residual block). Experiment results confirm that our method achieves the state-of-the-art performances on the popular datasets DRIVE, CHASE-DB1 and STARE. © 2020 IEEE.",coarse-to-fine segNet; computer aided-diagnosis; deep learning; Retinal vessel segmentation
Article,"Rodrigues E.O., Conci A., Liatsis P.",ELEMENT: Multi-Modal Retinal Vessel Segmentation Based on a Coupled Region Growing and Machine Learning Approach,IEEE Journal of Biomedical and Health Informatics,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097571304&doi=10.1109%2fJBHI.2020.2999257&partnerID=40&md5=43990b830e688491b595d5872b26240a,"Vascular structures in the retina contain important information for the detection and analysis of ocular diseases, including age-related macular degeneration, diabetic retinopathy and glaucoma. Commonly used modalities in diagnosis of these diseases are fundus photography, scanning laser ophthalmoscope (SLO) and fluorescein angiography (FA). Typically, retinal vessel segmentation is carried out either manually or interactively, which makes it time consuming and prone to human errors. In this research, we propose a new multi-modal framework for vessel segmentation called ELEMENT (vEsseL sEgmentation using Machine lEarning and coNnecTivity). This framework consists of feature extraction and pixel-based classification using region growing and machine learning. The proposed features capture complementary evidence based on grey level and vessel connectivity properties. The latter information is seamlessly propagated through the pixels at the classification phase. ELEMENT reduces inconsistencies and speeds up the segmentation throughput. We analyze and compare the performance of the proposed approach against state-of-the-art vessel segmentation algorithms in three major groups of experiments, for each of the ocular modalities. Our method produced higher overall performance, with an overall accuracy of 97.40%, compared to 25 of the 26 state-of-the-art approaches, including six works based on deep learning, evaluated on the widely known DRIVE fundus image dataset. In the case of the STARE, CHASE-DB, VAMPIRE FA, IOSTAR SLO and RC-SLO datasets, the proposed framework outperformed all of the state-of-the-art methods with accuracies of 98.27%, 97.78%, 98.34%, 98.04% and 98.35%, respectively. © 2013 IEEE.",Machine learning; pixel connectivity; pixel-based classi-fication; region growing; retinal vessel segmentation
Article,"Straňák Z., Penčák M., Veith M.",VYU&#381;ITÍ UM&#282;LÉ INTELIGENCE V ZÁCHYTU DIABETICKÉ RETINOPATIE. P&#344;EHLED [ARTEFICIAL INTELLIGENCE IN DIABETIC RETINOPATHY SCREENING. A REVIEW],Ceska a slovenska oftalmologie : casopis Ceske oftalmologicke spolecnosti a Slovenske oftalmologicke spolecnosti,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85119491352&doi=10.31348%2f2021%2f6&partnerID=40&md5=0f482f505d19061fd474788ef978f3a1,"OBJECTIVE: The aim of this comprehensive paper is to acquaint the readers with evaluation of the retinal images using the arteficial intelligence (AI). Main focus of the paper is diabetic retinophaty (DR) screening. The basic principles of the artificial intelligence and algorithms that are already used in clinical practice or are shortly before approval will be described. METHODOLOGY: Describing the basic characteristics and mechanisms of different approaches to the use of AI and subsequently literary minireview clarifying the current state of knowledge in the area. RESULTS: Modern systems for screening diabetic retinopathy using deep neural networks achieve a sensitivity and specificity of over 80 % in most published studies. The results of specific studies vary depending on the definition of the gold standard, number of images tested and on the evaluated parameters. CONCLUSION: Evaluation of images using AI will speed up and streamline the diagnosis of DR. The use of AI will allow to keep the quality of the eye care at least on the same level despite the raising number of the patients with diabetes.",artificial intelligence; diabetic retinopathy; Diabetic retinopathy; mass screening; screening
Conference Paper,"Sanjana S., Shadin N.S., Farzana M.",Automated Diabetic Retinopathy Detection Using Transfer Learning Models,"2021 5th International Conference on Electrical Engineering and Information and Communication Technology, ICEEICT 2021",2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85128498493&doi=10.1109%2fICEEICT53905.2021.9667793&partnerID=40&md5=66065a44edc4ddfe705c8d9c2e5e16c8,"Diabetic retinopathy (DR) is one of the most leading symptoms of vision-loss globally. Early detection and screening can halt its progression. Until date, ophthalmologists have manually screened DR, however, DR detection can be difficult in low-resource areas when there are few ophthalmologists available. Deep learning has recently been one of the most popular strategies for improving performance in a variety of fields, particularly medical image analysis and classification. It can be used to more effectively detect DR and so maintain vision. Transfer learning models are becoming increasingly commonly employed as a deep learning method, and they are quite effective. Two public datasets which contain 1115 retinal fundus images are used in this research. Our research proposed a binary classification of DR, which is done with five Transfer learning models Xception, InceptionResNetV2, MobileNetV2, DenseNet121, and NASNetMobile which achieved the highest validation accuracy of 86.25%, 96.25%, 93.75%, 81.25%, and 80.00% respectively. © 2021 IEEE.",DenseNet121; Diabetic Retinopathy; InceptionResNetV2; MobileNetV2; NASNetMobile; Xception
Article,"Alyoubi W.L., Abulkhair M.F., Shalash W.M.",Diabetic retinopathy fundus image classification and lesions localization system using deep learning,Sensors,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85106438519&doi=10.3390%2fs21113704&partnerID=40&md5=a946ccef40d4eb06f39a149033ae8d95,"Diabetic retinopathy (DR) is a disease resulting from diabetes complications, causing non-reversible damage to retina blood vessels. DR is a leading cause of blindness if not detected early. The currently available DR treatments are limited to stopping or delaying the deterioration of sight, highlighting the importance of regular scanning using high-efficiency computer-based systems to diagnose cases early. The current work presented fully automatic diagnosis systems that exceed manual techniques to avoid misdiagnosis, reducing time, effort and cost. The proposed system classifies DR images into five stages—no-DR, mild, moderate, severe and proliferative DR—as well as localizing the affected lesions on retain surface. The system comprises two deep learning-based models. The first model (CNN512) used the whole image as an input to the CNN model to classify it into one of the five DR stages. It achieved an accuracy of 88.6% and 84.1% on the DDR and the APTOS Kaggle 2019 public datasets, respectively, compared to the state-of-the-art results. Simultaneously, the second model used an adopted YOLOv3 model to detect and localize the DR lesions, achieving a 0.216 mAP in lesion localization on the DDR dataset, which improves the current state-of-the-art results. Finally, both of the proposed structures, CNN512 and YOLOv3, were fused to classify DR images and localize DR lesions, obtaining an accuracy of 89% with 89% sensitivity, 97.3 specificity and that exceeds the current state-of-the-art results. © 2021 by the authors. Licensee MDPI, Basel, Switzerland.",Computer-aided diagnosis; Convolutional neural networks; Deep learning; Diabetic retinopathy; Diabetic retinopathy classification; Diabetic retinopathy lesions localization; YOLO
Conference Paper,"Vinoth Kumar B., Swedhaasri M., Parekh T., Sharma A.",A Multi-Stage Deep Transfer Learning Method for Classification of Diabetic Retinopathy in Retinal images,"Proceedings of the 2nd International Conference on Electronics and Sustainable Communication Systems, ICESC 2021",2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85116654812&doi=10.1109%2fICESC51422.2021.9532991&partnerID=40&md5=9b9f94a3a346cbe8c0163507735699b3,"Diabetic Retinopathy (DR) is one among the most dangerous complications of polygenic disease, and if it is untreated, it can result in permanent disability. Early detection is critical for clinical progress and it is one of the most difficult challenges. Unfortunately, determining the stage of DR is prominently difficult as well as this calls for skillful rendition from humans on the structural images of body. The significance in simplifying this process of detecting cannot be overstated. Convolutional neural networks have been effectually used in a various fields, as well as in the detection of D R. However, the increasing expense of huge labelled datasets and also variability among physicians, who are completely different block the effectiveness of these strategies. In this perspective, this research work has proposed a deep learning-based automated technique for DR stage classification and detection by utilizing sole photography of the fundus in human retina. Further, the proposed research work has suggested a multi-stage deep transfer learning technique that uses equivalent datasets for including labeling, which is completely different. The methodology suggested by this research work can be utilized as a screening method employed for early diagnosis of DR with a sensitivity and specificity of 0.99 as well as a quadratic weighted kappa grade at 0.925466 of blindness detection dataset. © 2021 IEEE.",classification; convolutional neural network; Deep learning; DR; multi-target learning; ordinal regression; quadratic weighted kappa(QWK); test-time augmentation(TTA)
Article,"Liao Y., Xia H., Song S., Li H.",Microaneurysm detection in fundus images based on a novel end-to-end convolutional neural network,Biocybernetics and Biomedical Engineering,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85106275840&doi=10.1016%2fj.bbe.2021.04.005&partnerID=40&md5=c427a12619670bd8a57cf78ffccd1d7c,"Microaneurysms are the earliest symptom of diabetic retinopathy and play an important role in the screening of diabetic retinopathy. However, because of the complex background, automatic detection microaneurysm in fundus images is a challenging task. Firstly, motivated by the characteristics of microaneurysm, a novel deep convolutional encoder-decoder network for microaneurysm detection is designed to locate the MAs by the differences between the skip connection in the network. Then, a weighted dice loss, termed the smooth dice loss, is presented to put more focus on misclassified microaneurysms. Finally, an activation function with a long tail is used to produce an accurate probability map for MA detection. Plenty of experiments, conducted on the Retinopathy Online Challenge dataset and the e-ophtha-MA dataset, demonstrate that the proposed model achieves the comparable performance to the existing state-of-the-art methods on microaneurysm detection with only one-hundredth the running time compared with its counterparts. The proposed method is simple and effective, guarantees the performance while shortening the test time. It indicates the potential application in the auxiliary diagnosis of diabetic retinopathy screening. © 2021 Nalecz Institute of Biocybernetics and Biomedical Engineering of the Polish Academy of Sciences",Computer-aided diagnosis; Deep learning; Diabetic retinopathy screening; Encoder-decoder; Microaneurysm detection
Conference Paper,"Wang L., Chen Z., Wang M., Wang T., Zhu W., Chen X.",Cycle adaptive multi-target weighting network for automated diabetic retinopathy segmentation,Proceedings - International Symposium on Biomedical Imaging,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85107216935&doi=10.1109%2fISBI48211.2021.9433917&partnerID=40&md5=d653354ac841ce8c149c5da76f38657d,"Diabetic retinopathy (DR) is one of the most common microvascular complications of diabetes. Early and accurate screening of DR from fundus images is crucial for the ophthalmologist to make treatment plans. In recent years, many deep learning-based methods have been proposed for medical image segmentation. However, the DR lesions segmentation still meets great challenges. In this work, we propose a novel cycle adaptive multi-target weighting network (CAMWNet) that mimics the biological vision system of the human brain. The network consists of two major parts: a novel adaptive multi-target weighting network (AMWNet) for DR lesions segmentation and a reverse data recovery network (RRN) to simulate the cycle perception in visual hierarchy. In addition, a novel joint loss function is designed to optimize the CAMWNet. Comprehensive experiments on Indian Diabetic Retinopathy Image Dataset (IDRiD) show that, CAMWNet achieves better performance than other state-of-the-art methods with accuracy, Dice similarity coefficients, sensitivity and specificity of 98.33%, 53.84%, 48.54% and 99.88%, respectively. © 2021 IEEE.",Diabetic retinopathy; Multi-target segmentation; Neural network; Retinal fundus images
Conference Paper,"Aruna Kumari A., Henge S.K.",A Hybrid Model on Deep Learning for the Diagnosis of Diabetic Retinopathy Using Image Cropping,Lecture Notes in Networks and Systems,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123302065&doi=10.1007%2f978-981-16-6309-3_49&partnerID=40&md5=cc16b66d5139a4efcf9b7af11b00f28f,"The Diabetic Retinopathy is one of the eye condition that may cause vision loss, blindness to the eyes quickly if not treated at the earliest in the patients having Diabetes Milletus type-1 and Type-2. This can be treated when diagnosed at the early stages of the disease with screen monitoring and treatment like laser etc. If not diagnosed in early stages can cause the impaired vision and may also lead to blindness. To avoid blindness, vision loss, the “Early Treatment Diabetic Retinopathy Study (ETDRS)” helps to detect eye disease at the earliest and prevent the consequences of the disease. As a progressive disease, The Diabetic retinopathy divided into two stages one is “non proliferative diabetic retinopathy” (NPDR) and “proliferative diabetic retinopathy” (PDR). Non-proliferative diabetic retinopathy has four stages, those are normal, mild, moderate, severe which has the threshold as 0, 1, 2, 3 respectively for No Diabetic Retinopathy, mild, moderate, severe, but if the threshold value is 4 it is a proliferative diabetic retinopathy is last stage of the DR. Unlike the available methods, the proposed work aims at diagnosis of all the stages of Diabetic Retinopathy where the retinal image preprocessing followed by the analysis using Convolutional Neural Network Classifier which classifies into different stages of the disease based on the threshold. RESTNET is used for the image tuning and the Hyper parameter tuning is done for detailed analysis. The Kaggle public dataset is used to build the model and would give the higher performance when compared to the existing ones. © 2022, The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd.",Convolutional neural networks; Deep learning; Diabetic retinopathy; Eye disease; Fund images; Medical retinal images
Article,"Li Y., Song Z., Kang S., Jung S., Kang W.",Semi-Supervised Auto-Encoder Graph Network for Diabetic Retinopathy Grading,IEEE Access,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85117270153&doi=10.1109%2fACCESS.2021.3119434&partnerID=40&md5=a4afa6bccc66448b2dbb7b2835e79ca3,"Diabetic Retinopathy (DR) causes quite a few blindness worldwide, which can be refrained by the timely diagnosis on retinal images. Recently, researches on deep learning-based retinal image classification have accelerated outstanding improvements in DR grading task. However, existing DR grading works are mostly limited to a supervised manner. They require accurately annotated data labeled by professional experts, and the annotating work is very laborious and time-consuming. We propose a Semi-supervised Auto-encoder Graph Network (SAGN) for the challenging DR diagnosis to relax this constraint. Precisely, SAGN consists of three major modules: Auto-encoder feature learning, neighbor correlation mining, and graph representation. Firstly, our model learns to extract representations from retinal images and reconstruct them as close to original inputs as possible. Then neighbor correlations among labeled and unlabeled samples are established by their similarities, calculated by the radial basis function. Finally, we operate Graph Convolutional Neural Network (GCN) to grade retinal samples from extracted features and their correlations. To evaluate the performance of SAGN, we conduct sufficient comparative experiments on APTOS 2019 dataset, trained from EyePACS. Results demonstrate that our SAGN model can achieve comparable performance with limited labeled retinal images with the help of large amounts of unlabeled data. © 2013 IEEE.",auto-encoder; Diabetic retinopathy grading; graph convolutional network; semi-supervised learning
Article,"Sun Y., Zhang D.",Diagnosis and Analysis of Diabetic Retinopathy Based on Electronic Health Records,IEEE Access,2019,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85068940066&doi=10.1109%2fACCESS.2019.2918625&partnerID=40&md5=5be17d7d218f2fae972f04f38d221e76,"Diabetic retinopathy (DR) is an important disease leading to blindness in humans, attracting a lot of research interests. Previous breakthrough research findings rely on deep learning techniques to diagnose diabetic retinopathy in patients with medical imaging. Although the medical imaging achieves reasonable recognition accuracy, the application of mass, easy-To-obtain and free electronic health records (EHR) data in life can make an early diagnosis of the DR more convenient and quick. In this paper, we used a set of five machine learning models to diagnose the DR in patients with the EHR data and formed a set of treatment methods. Our experimental data set is formed by processing the data provided by 301 hospitals. The experimental results show that random forest (RF) in the machine learning model can get 92% accuracy with good performance. Subsequently, the input features were analyzed and their importance graded to find that the predisposing factors triggering the human DR disease were associated with renal and liver function. In addition, disease diagnosis methods based on readily available the EHR data will become an integral part of smart healthcare and mobile healthcare. © 2013 IEEE.",Diabetic retinopathy; disease diagnosis; electronic medical records; machine learning; mobile medical
Article,"AbdelMaksoud E., Barakat S., Elmogy M.",A computer-aided diagnosis system for detecting various diabetic retinopathy grades based on a hybrid deep learning technique,Medical and Biological Engineering and Computing,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85129794568&doi=10.1007%2fs11517-022-02564-6&partnerID=40&md5=ffcb8793a2109f8470836ef245ea800a,"Abstract: Diabetic retinopathy (DR) is a serious disease that may cause vision loss unawares without any alarm. Therefore, it is essential to scan and audit the DR progress continuously. In this respect, deep learning techniques achieved great success in medical image analysis. Deep convolution neural network (CNN) architectures are widely used in multi-label (ML) classification. It helps in diagnosing normal and various DR grades: mild, moderate, and severe non-proliferative DR (NPDR) and proliferative DR (PDR). DR grades are formulated by appearing multiple DR lesions simultaneously on the color retinal fundus images. Many lesion types have various features that are difficult to segment and distinguished by utilizing conventional and hand-crafted methods. Therefore, the practical solution is to utilize an effective CNN model. In this paper, we present a novel hybrid, deep learning technique, which is called E-DenseNet. We integrated EyeNet and DenseNet models based on transfer learning. We customized the traditional EyeNet by inserting the dense blocks and optimized the resulting hybrid E-DensNet model’s hyperparameters. The proposed system based on the E-DenseNet model can accurately diagnose healthy and different DR grades from various small and large ML color fundus images. We trained and tested our model on four different datasets that were published from 2006 to 2019. The proposed system achieved an average accuracy (ACC), sensitivity (SEN), specificity (SPE), Dice similarity coefficient (DSC), the quadratic Kappa score (QKS), and the calculation time (T) in minutes (m) equal 91.2 % , 96 % , 69 % , 92.45 % , 0.883, and 3.5m respectively. The experiments show promising results as compared with other systems. Graphical abstract: [Figure not available: see fulltext.]. © 2022, The Author(s).",Convolution neural network (CNN); DenseNet; Diabetic retinopathy (DR); E-DenseNet; EyeNet; Transfer learning
Conference Paper,"Sridhar S., Sanagavarapu S.",Detection and Prognosis Evaluation of Diabetic Retinopathy using Ensemble Deep Convolutional Neural Networks,IES 2020 - International Electronics Symposium: The Role of Autonomous and Intelligent Systems for Human Life and Comfort,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85096766963&doi=10.1109%2fIES50839.2020.9231789&partnerID=40&md5=9fa405eeb251c79940923563c324b1ec,"Diabetic Retinopathy is a condition that occurs in the eye as a result of diabetes in patients. Due to uncontrolled blood sugar levels in patients, there would be a lack of blood flow and oxygen to the retina. This causes strain on blood vessels some extent without invasive treatment and when detected in its early stages. When the strain in the blood vessels increases, it may cause leakage of fluids from blood vessels and loss of proper vision in the eye. This system implements a deep learning model using ResNet to determine the performance for the detection of the various stages of the condition in individuals. Individual submodels are built using ResNet to detect the presence of Diabetic Retinopathy and are ensembled together using the AdaBoost Classifier. Multiclass classification ResNet models are built and stacked together to detect the prognosis of Diabetic Retinopathy. The implemented models showed a performance accuracy of 78.88% to detect the presence and 61.9% to evaluate the prognosis of Diabetic Retinopathy. The performance of the trained models is visualised with a Grad-CAM and the results are analysed. © 2020 IEEE.",Deep Convolutional Neural Network; Diabetic Retinopathy; Ensemble; ResNet; Stacked Generalization
Conference Paper,"Vyas A.H., Khanduja V.",A Survey on Automated Eye Disease Detection using Computer Vision Based Techniques,"2021 IEEE Pune Section International Conference, PuneCon 2021",2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85125952507&doi=10.1109%2fPuneCon52575.2021.9686479&partnerID=40&md5=c5bb6727466d5dc96ee3ccc8478973a2,"Due to recent advancements in the field of Artificial Intelligence (AI), many recent techniques have been developed to objectively identify diseases using images or videos. Eye-related diseases are one of the commonly occurring diseases in the human body. Many diseases can manifest in the eye such as Diabetic Retinopathy (DR), glaucoma, dry eye, Age Related Macular Degeneration (ARMD), cataract, keratoconus and so on. These diseases can cause severe discomfort in patients eye leading to vision loss, blurred vision or photophobia, highly impacting the quality of life of patients. Various AI and image processing techniques have been developed to assist ophthalmologists to diagnose the disease precisely as well as reducing healthcare cost. This paper reviews techniques utilizing machine learning and deep learning to detect eye diseases namely ARMD, cataract, DR and glaucoma. It is observed that the accuracy of AI based techniques outperforms manual feature extraction and classification techniques in all four disease detection areas. © 2021 IEEE.",computer aided diagnosis; deep learning; Eye disease detection; machine learning; medical image processing
Conference Paper,"Levenkova A., Sowmya A., Kalloniatis M., Ly A., Ho A.",Lesion detection in ultra-wide field retinal images for diabetic retinopathy diagnosis,Progress in Biomedical Optics and Imaging - Proceedings of SPIE,2018,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85046285608&doi=10.1117%2f12.2293434&partnerID=40&md5=1bca82d1102e83a6c9f0bd1e20e59d8f,"Diabetic retinopathy (DR) leads to irreversible vision loss. Diagnosis and staging of DR is usually based on the presence, number, location and type of retinal lesions. Ultra-wide field (UWF) digital scanning laser technology provides an opportunity for computer-aided DR lesion detection. High-resolution UWF images (3078×2702 pixels) may allow detection of more clinically relevant retinopathy in comparison with conventional retinal images as UWF imaging covers a 200° retinal area, versus 45° by conventional cameras. Current approaches to DR diagnosis that analyze 7-field Early Treatment Diabetic Retinopathy Study (ETDRS) retinal images provide similar results to UWF imaging. However, in 40% of cases, more retinopathy was found outside the 7-field ETDRS fields by UWF and in 10% of cases, retinopathy was reclassified as more severe. The reason is that UWF images examine both the central retina and more peripheral regions. We propose an algorithm for automatic detection and classification of DR lesions such as cotton wool spots, exudates, microaneurysms and haemorrhages in UWF images. The algorithm uses convolutional neural network (CNN) as a feature extractor and classifies the feature vectors extracted from colour-composite UWF images using a support vector machine (SVM). The main contribution includes detection of four types of DR lesions in the peripheral retina for diagnostic purposes. The evaluation dataset contains 146 UWF images. The proposed method for detection of DR lesion subtypes in UWF images using two scenarios for transfer learning achieved AUC â‰ 80%. Data was split at the patient level to validate the proposed algorithm. © 2018 SPIE.",Computer-aided diagnosis; convolutional neural network; deep learning; diabetic retinopathy; ultra-wide field retinal imaging
Article,"Araújo T., Aresta G., Mendonça L., Penas S., Maia C., Carneiro Â., Mendonça A.M., Campilho A.",DR|GRADUATE: Uncertainty-aware deep learning-based diabetic retinopathy grading in eye fundus images,Medical Image Analysis,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85084682948&doi=10.1016%2fj.media.2020.101715&partnerID=40&md5=34b2f44dc6eb206f86fbc081c7c6d16f,"Diabetic retinopathy (DR) grading is crucial in determining the adequate treatment and follow up of patient, but the screening process can be tiresome and prone to errors. Deep learning approaches have shown promising performance as computer-aided diagnosis (CAD) systems, but their black-box behaviour hinders clinical application. We propose DR|GRADUATE, a novel deep learning-based DR grading CAD system that supports its decision by providing a medically interpretable explanation and an estimation of how uncertain that prediction is, allowing the ophthalmologist to measure how much that decision should be trusted. We designed DR|GRADUATE taking into account the ordinal nature of the DR grading problem. A novel Gaussian-sampling approach built upon a Multiple Instance Learning framework allow DR|GRADUATE to infer an image grade associated with an explanation map and a prediction uncertainty while being trained only with image-wise labels. DR|GRADUATE was trained on the Kaggle DR detection training set and evaluated across multiple datasets. In DR grading, a quadratic-weighted Cohen's kappa (κ) between 0.71 and 0.84 was achieved in five different datasets. We show that high κ values occur for images with low prediction uncertainty, thus indicating that this uncertainty is a valid measure of the predictions’ quality. Further, bad quality images are generally associated with higher uncertainties, showing that images not suitable for diagnosis indeed lead to less trustworthy predictions. Additionally, tests on unfamiliar medical image data types suggest that DR|GRADUATE allows outlier detection. The attention maps generally highlight regions of interest for diagnosis. These results show the great potential of DR|GRADUATE as a second-opinion system in DR severity grading. © 2020 Elsevier B.V.",Deep learning; Diabetic retinopathy grading; Explainability; Uncertainty
Conference Paper,"Kim D.E., Hacisoftaoglu R.E., Karakaya M.",Optic disc localization in retinal images using deep learning frameworks,Proceedings of SPIE - The International Society for Optical Engineering,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85086140709&doi=10.1117%2f12.2558601&partnerID=40&md5=2da9c2cddbff582c26d66f2269894788,"Diabetic Retinopathy (DR) is one of the most common eye diseases related to diabetics. If the diagnosis and treatment are conducted too late, it may result in various degrees of vision loss, even blindness. Therefore, individuals with diabetes should have a regular annual eye exam. Studies showed that early detection can prevent vision loss in earlier stages. However, in places such as undeveloped or developing countries, and even sometimes rural areas in developed countries, may not have enough resources for DR screening. Furthermore, even though these places may have adequate equipment, the diagnosis may take a few days to obtain results for the analysis of the ophthalmologists. Developing an automated detection algorithm is an emerging research area to diagnose DR remotely using a retina image. Localizing the optic disc and fovea is an essential task in these DR detection algorithms. After locating the optic disc, finding other components of the retina is easier. Technological developments in recent years enable the acceleration of diagnosis of such diseases including DR. Deep learning techniques are becoming an essential part of the medical field. In the last years, there have been many attempts to automatize the analysis of medical disorders such as breast cancer, glaucoma, diabetic macular edema, and diabetic retinopathy. In this paper, we presented the utilization of a pre-trained deep learning framework to localize the optic disc in the retina images. Using the transfer learning approach for AlexNet with a linear regression output, we localized the optic disc center. Retina images with labeled ground truth values of optic disc center were used to retrain the AlexNet. We tested our proposed deep learning-based optic disc localization approach with three different publicly available datasets including EyePACS, Messidor, and IDRID. Based on the results, the deep learning-based optic disc localization method shows high detection accuracy. The best results for optic disc detection were observed with cross dataset images as the accuracy of 88.35%, while a 97.66% testing accuracy was observed for the merged dataset using transfer learning approach for the pretrained AlexNet. © 2020 SPIE.",AlexNet; Classification; Convolutional Neural Networks; Deep Learning; Diabetic retinopathy; EyePACS; IDRiD; Localization; Messidor; Optic disc; Regression; Retinal imaging; Transfer learning
Conference Paper,"Zaylaa A.J., Wehbe G.I., Ouahabi A.M.",Bringing AI to Automatic Diagnosis of Diabetic Retinopathy from Optical Coherence Tomography Angiography,"International Conference on Advances in Biomedical Engineering, ICABME",2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85122870693&doi=10.1109%2fICABME53305.2021.9604812&partnerID=40&md5=c1fb5551f131cc1615f7084872c39a7b,"Artificial Intelligence (AI) is significantly gaining interest in the field of Diagnostic and Functional Optical Imaging. As cutting-edge algorithms for decision-making are vast and medical imaging machines are diverse, the choice of the ultimate algorithm remains challenging. As a breakthrough in the field, our aim is to explore the adequate machine and deep learning algorithms that improve the classification of Optical Coherence Tomography Angiography (OCTA) Images, between normal and Diabetic Retinopathy (DR) images. The target was to provide an automatic paradigm for the medical staff to detect the presence of DR Lesions from OCTA images for diagnostic and monitoring purposes. Data were collected prospectively over a year from a comprehensive medical center in Lebanon. The mixed Convolution Neural Network (CNN)-Support Vector Machine Network (CNN, SVM) algorithm was utilized in the new paradigm and compared to the feed forward backpropagation NN, to the SVM and to the modified SVM. Results were evaluated independently for the presence or absence of DR using statistical metrics. Experimental results showcased promising association of deep learning to the early diagnosis of DR. Results manifested the high performance of the new paradigm, where the mixed algorithm applied to the functional OCTA surpassed the performance of the feed forward backpropagation NN. The sensitivity of the mixed (CNN, SVM) algorithm was 22.22% higher than that obtained by the feed forward backpropagation NN. Moreover, the specificity of classification of DR from OCTA images using mixed (CNN, SVM) algorithm was 24.44% higher than that obtained by the feed forward backpropagation NN. The precision was 25.47% higher in the new paradigm than that obtained by the feed forward backpropagation network, and the accuracy was 23.35% higher in the mixed (CNN, SVM) than that obtained by the feed forward backpropagation NN. This high performance plays a massive role in improving the diagnosis of DR, and thus Healthcare system and processing of information. As a future prospect, we aim to consider more algorithms and variables in the diagnosis of DR from OCTA images. © 2021 IEEE.",Artificial Intelligence; Diabetic Retinopathy; Functional Medical Imaging; Machine and Deep Learning; Optical Coherence Tomography Angiography; Statistical Evaluation
Article,"Pedrosa M., Silva J.M., Silva J.F., Matos S., Costa C.",SCREEN-DR: Collaborative platform for diabetic retinopathy,International Journal of Medical Informatics,2018,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85055449567&doi=10.1016%2fj.ijmedinf.2018.10.005&partnerID=40&md5=0bb168c06b298f9bfc734a0bbe0e225c,"Background and objective: Diabetic retinopathy (DR) is the most prevalent microvascular complication of diabetes mellitus and can lead to irreversible visual loss. Screening programs, based on retinal imaging techniques, are fundamental to detect the disease since the initial stages are asymptomatic. Most of these examinations reflect negative cases and many have poor image quality, representing an important inefficiency factor. The SCREEN-DR project aims to tackle this limitation, by researching and developing computer-aided methods for diabetic retinopathy detection. This article presents a multidisciplinary collaborative platform that was created to meet the needs of physicians and researchers, aiming at the creation of machine learning algorithms to facilitate the screening process. Methods: Our proposal is a collaborative platform for textual and visual annotation of image datasets. The architecture and layout were optimized for annotating DR images by gathering feedback from several physicians during the design and conceptualization of the platform. It allows the aggregation and indexing of imagiology studies from diverse sources, and supports the creation and annotation of phenotype-specific datasets to feed artificial intelligence algorithms. The platform makes use of an anonymization pipeline and role-based access control for securing personal data. Results: The SCREEN-DR platform has been deployed in the production environment of the SCREEN-DR project at http://demo.dicoogle.com/screen-dr, and the source code of the project is publicly available. We provide a description of the platform's interface and use cases it supports. At the time of publication, four physicians have created a total of 1826 annotations for 701 distinct images, and the annotated data has been used for training classification models. © 2018 Elsevier B.V.",Collaborative PACS; Computer-aided diagnosis; Diabetic retinopathy screening; Image annotation; Telemedicine
Article,"Hervella Á.S., Rouco J., Novo J., Ortega M.",Multimodal image encoding pre-training for diabetic retinopathy grading,Computers in Biology and Medicine,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85125007894&doi=10.1016%2fj.compbiomed.2022.105302&partnerID=40&md5=9d0b2379b2a5e1f11a612278ca68adb3,"Diabetic retinopathy is an increasingly prevalent eye disorder that can lead to severe vision impairment. The severity grading of the disease using retinal images is key to provide an adequate treatment. However, in order to learn the diverse patterns and complex relations that are required for the grading, deep neural networks require very large annotated datasets that are not always available. This has been typically addressed by reusing networks that were pre-trained for natural image classification, hence relying on additional annotated data from a different domain. In contrast, we propose a novel pre-training approach that takes advantage of unlabeled multimodal visual data commonly available in ophthalmology. The use of multimodal visual data for pre-training purposes has been previously explored by training a network in the prediction of one image modality from another. However, that approach does not ensure a broad understanding of the retinal images, given that the network may exclusively focus on the similarities between modalities while ignoring the differences. Thus, we propose a novel self-supervised pre-training that explicitly teaches the networks to learn the common characteristics between modalities as well as the characteristics that are exclusive to the input modality. This provides a complete comprehension of the input domain and facilitates the training of downstream tasks that require a broad understanding of the retinal images, such as the grading of diabetic retinopathy. To validate and analyze the proposed approach, we performed an exhaustive experimentation on different public datasets. The transfer learning performance for the grading of diabetic retinopathy is evaluated under different settings while also comparing against previous state-of-the-art pre-training approaches. Additionally, a comparison against relevant state-of-the-art works for the detection and grading of diabetic retinopathy is also provided. The results show a satisfactory performance of the proposed approach, which outperforms previous pre-training alternatives in the grading of diabetic retinopathy. © 2022 The Authors",Computer-aided diagnosis; Deep learning; Diabetic retinopathy; Eye fundus; Medical imaging; Self-supervised learning
Article,"Farooq M.S., Arooj A., Alroobaea R., Baqasah A.M., Jabarulla M.Y., Singh D., Sardar R.",Untangling Computer-Aided Diagnostic System for Screening Diabetic Retinopathy Based on Deep Learning Techniques,Sensors,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85125063034&doi=10.3390%2fs22051803&partnerID=40&md5=545205c88665250363d6e523d056862b,"Diabetic Retinopathy (DR) is a predominant cause of visual impairment and loss. Approximately 285 million worldwide population is affected with diabetes, and one-third of these patients have symptoms of DR. Specifically, it tends to affect the patients with 20 years or more with diabetes, but it can be reduced by early detection and proper treatment. Diagnosis of DR by using manual methods is a time-consuming and expensive task which involves trained ophthalmologists to observe and evaluate DR using digital fundus images of the retina. This study aims to systematically find and analyze high-quality research work for the diagnosis of DR using deep learning approaches. This research comprehends the DR grading, staging protocols and also presents the DR taxonomy. Furthermore, identifies, compares, and investigates the deep learning-based algorithms, techniques, and, methods for classifying DR stages. Various publicly available dataset used for deep learning have also been analyzed and dispensed for descriptive and empirical understanding for real-time DR applications. Our in-depth study shows that in the last few years there has been an increasing inclination towards deep learning approaches. 35% of the studies have used Convolutional Neural Networks (CNNs), 26% implemented the Ensemble CNN (ECNN) and, 13% Deep Neural Networks (DNN) are amongst the most used algorithms for the DR classification. Thus using the deep learning algorithms for DR diagnostics have future research potential for DR early detection and prevention based solution. © 2022 by the authors. Licensee MDPI, Basel, Switzerland.",Automated detection; Deep learning; Deep neural network; Diabetic retinopathy
Article,"Geetha S., Parashar M., Abhishek J.S., Turaga R.V., Lawal I.A., Kadry S.",Diabetic Retinopathy Grading with Deep Visual Attention Network,International journal of online and biomedical engineering,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85135008671&doi=10.3991%2fijoe.v18i09.30075&partnerID=40&md5=b717866fa712004ee832c229549e6af9,"Diabetic Retinopathy is a serious complication arising in diabetes afflicted patients. Its effective treatment depends on early detection, and the course of action varies decisively with the intensity of the affliction. Computeraided diagnosis helps to detect not only the presence or absence of the disease, but also the severity, making it easier for ophthalmologists to construct a treatment plan. Diabetic retinopathy grading is the task of classifying images of the eye’s fundus of diabetic patients into 5 different grades ranging from 0–4 based on the severity of the disease. In this work, we propose a deep neural network architecture to address the grading problem. The method utilizes additional attention layer in the neural network model to capture the spatial relationship between the region of interests in the images during the training process to better discriminate between the different severity stage of the disease. Also, we analyze the impact of different image processing techniques on the classification results. We assessed the performance of our proposed method using a dataset of eye fundus images and obtained classification accuracy of 89.20% on average. This performance surpass that reported for other state-of-the-art methods on the same dataset. The effectiveness of the proposed method will facilitate the procedural workflow of identifying severe cases of diabetic retinopathy. © 2022. International journal of online and biomedical engineering. All Rights Reserved.",Attention net; Clahe; Deep learning; Diabetic retinopathy; Diabetic retinopathy grading; Gaussian blur
Conference Paper,Furtado P.,Segmentation of diabetic retinopathy lesions by deep learning: Achievements and limitations,"BIOIMAGING 2020 - 7th International Conference on Bioimaging, Proceedings; Part of 13th International Joint Conference on Biomedical Engineering Systems and Technologies, BIOSTEC 2020",2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85083728781&partnerID=40&md5=54edd84d38b3f99a19d32db7f43354e2,"Analysis of Eye Fundus Images (EFI) allows early diagnosis and grading of Diabetic Retinopathy (DR), detecting micro-aneurisms, exudates, haemorrhages, neo-vascularizations and other signs. Automated detection of individual lesions helps visualizing, characterizing and determining degree of DR. Today modified deep convolution neural networks (DCNNs) are state-of-the-art in most segmentation tasks. But the task of segmenting lesions in EFI is challenging due to sizes, varying shapes, similarity and lack of contrast with other parts of the EFI, so that the results are ambiguous. In this paper we test two DCNNs to do a preliminary evaluation of the strengths and limitations using publicly available data. We already conclude that the accuracies are good but the segmentations still have relevant deficiencies. Based on this, we identify the need for further assessment and suggest future work to improve segmentation approaches. Copyright © 2020 by SCITEPRESS - Science and Technology Publications, Lda. All rights reserved.",Deep learning; EFI; Medical imaging; Segmentation
Conference Paper,"Dekhil O., Naglah A., Shaban M., Ghazal M., Taher F., Elbaz A.",Deep Learning Based Method for Computer Aided Diagnosis of Diabetic Retinopathy,"IST 2019 - IEEE International Conference on Imaging Systems and Techniques, Proceedings",2019,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85081992641&doi=10.1109%2fIST48021.2019.9010333&partnerID=40&md5=c4f38a49b1fd20ae754f73eb132a207d,"Diabetic retinopathy (DR) is a retinal disease caused by the high blood sugar levels that may damage and block the blood vessels feeding the retina. In the early stages of DR, the disease is asymptomatic; however, as the disease advances, a possible sudden loss of vision and blindness may occur. Therefore, an early diagnosis and staging of the disease is required to possibly slow down the progression of the disease and improve control of the symptoms. In response to the previous challenge, we introduce a computer aided diagnosis tool based on convolutional neural networks (CNN) to classify fundus images into one of the five stages of DR. The proposed CNN consists of a preprocessing stage, five stage convolutional, rectified linear and pooling layers followed by three fully connected layers. Transfer learning was adopted to minimize overfitting by training the model on a larger dataset of 3.2 million images (i.e. ImageNet) prior to the use of the model on the APTOS 2019 Kaggle DR dataset. The proposed approach has achieved a testing accuracy of 77% and a quadratic weighted kappa score of 78%, offering a promising solution for a successful early diagnose and staging of DR in an automated fashion. © 2019 IEEE.",Convolutional neural network; Image classification; Ophthalmoscopy
Article,"Pao S.-I., Lin H.-Z., Chien K.-H., Tai M.-C., Chen J.-T., Lin G.-M.",Detection of Diabetic Retinopathy Using Bichannel Convolutional Neural Network,Journal of Ophthalmology,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85087705383&doi=10.1155%2f2020%2f9139713&partnerID=40&md5=6dfcfacfc355e8ecab9cef34c53d2182,"Deep learning of fundus photograph has emerged as a practical and cost-effective technique for automatic screening and diagnosis of severer diabetic retinopathy (DR). The entropy image of luminance of fundus photograph has been demonstrated to increase the detection performance for referable DR using a convolutional neural network- (CNN-) based system. In this paper, the entropy image computed by using the green component of fundus photograph is proposed. In addition, image enhancement by unsharp masking (UM) is utilized for preprocessing before calculating the entropy images. The bichannel CNN incorporating the features of both the entropy images of the gray level and the green component preprocessed by UM is also proposed to improve the detection performance of referable DR by deep learning. © 2020 Shu-I Pao et al.",Article; bichannel convolutional neural network; controlled study; convolutional neural network; deep learning; diabetic retinopathy; diagnostic accuracy; entropy; eye photography; human; image enhancement; receiver operating characteristic; retina image; sensitivity and specificity; unsharp masking; visual masking
Conference Paper,"Mohammadian S., Karsaz A., Roshan Y.M.",Comparative Study of Fine-Tuning of Pre-Trained Convolutional Neural Networks for Diabetic Retinopathy Screening,"2017 24th Iranian Conference on Biomedical Engineering and 2017 2nd International Iranian Conference on Biomedical Engineering, ICBME 2017",2018,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85052464573&doi=10.1109%2fICBME.2017.8430269&partnerID=40&md5=c833e5130ee4953e544b56622be67989,"Diabetic retinopathy is the leading cause of blindness, engaging people in different ages. Early detection of the disease, although significantly important to control and cure it, is usually being overlooked due to the need for experienced examination. To this end, automatic diabetic retinopathy diagnostic methods are proposed to facilitate the examination process and act as the physician's helper. In this paper, automatic diagnosis of diabetic retinopathy using pre-trained convolutional neural networks is studied. Pre-trained networks are chosen to avoid the time-and resource-consuming training algorithms for designing a convolutional neural network from scratch. Each neural network is fine-tuned with the pre-processed dataset, and the fine-tuning parameters as well as the pre-trained neural networks are compared together. The result of this paper, introduces a fast approach to fine-tune pre-trained networks, by studying different tuning parameters and their effect on the overall system performance due to the specific application of diabetic retinopathy screening. © 2017 IEEE.",convolutional neural network; deep learning; Diabetic retinopathy; Inception model
Conference Paper,"Choudhury A.R., Bhattacharya D., Debnath A., Biswas A.",An integrated image processing and deep learning approach for diabetic retinopathy classification,Communications in Computer and Information Science,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85082391557&doi=10.1007%2f978-981-15-3666-3_1&partnerID=40&md5=66c51f67806552db9851771184fb5089,"Diabetic retinopathy is referred to as eye sight damage and permanent blindness because of diabetic condition in humans. Diabetic patients are growing up in numbers every year around the globe. Because of modern day life style with elevated stress and tension the risk is even higher. Hence it is crucial for diabetic patients to look for its effect on other body parts as diabetic condition hit eye more likely and if left unchecked, may lead to serious eye related issues. But it can be easily monitored by regular checkups and proper health care and prevented from further degradation, while an automatic screening system to identify whether an individual need follow up or referral for supplementary action to avoid blindness can ease the task of detection at early stages to a great extent. In this paper a model for automatic detection of diabetic retinopathy is proposed using low complexity image processing technique and modified Convolutional Neural Network (CNN) with better accuracy and precision to help an ophthalmologist through detection of change in retina features. The proposed model is used to classify the fundus images into two categories, viz. healthy and infected and tested on EyePACS dataset which obtained classification accuracy of 82% shows the robustness of the system. © Springer Nature Singapore Pte Ltd 2020.",Convolutional Neural Network; Deep learning; Diabetic retinopathy; Fundus image; Image processing
Article,"Bhardwaj C., Jain S., Sood M.",Diabetic retinopathy severity grading employing quadrant-based Inception-V3 convolution neural network architecture,International Journal of Imaging Systems and Technology,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85092921054&doi=10.1002%2fima.22510&partnerID=40&md5=6b2a9394e1e224ea5dcf9b0bc13a3df3,Diabetic retinopathy (DR) accounts in eye-related disorders due to accumulated damage to small retinal blood vessels. Automated diagnostic systems are effective in early detection and diagnosis of severe eye complications by assisting the ophthalmologists. Deep learning-based techniques have emerged as an advancement over conventional techniques based on hand-crafted features. The authors have proposed a Quadrant-based automated DR grading system in this work using Inception-V3 deep neural network to extract small lesions present in retinal fundus images. The grading efficiency of the proposed architecture is improved utilizing image enhancement and optical disc removal pipeline along with data augmentation stage. The proposed system yields accuracy of 93.33% with minimized cross-entropy loss of 0.291. Capability of proposed system is demonstrated experimentally to provide efficient DR diagnosis. The diagnosis ability of the proposed architecture is demonstrated by state-of-the-art comparison with other mainstream convolution neural network models and a maximum improvement of 14.33% is observed. © 2020 Wiley Periodicals LLC,convolution neural network; data augmentation; deep neural network; diabetic retinopathy; hand-crafted features
Conference Paper,"Qian P., Zhao Z., Chen C., Zeng Z., Li X.",Two Eyes Are Better Than One: Exploiting Binocular Correlation for Diabetic Retinopathy Severity Grading,"Proceedings of the Annual International Conference of the IEEE Engineering in Medicine and Biology Society, EMBS",2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85122530571&doi=10.1109%2fEMBC46164.2021.9630812&partnerID=40&md5=a6b6993dd9a9794044a242df8d6929ff,"Diabetic retinopathy (DR) is one of the most common eye conditions among diabetic patients. However, vision loss occurs primarily in the late stages of DR, and the symptoms of visual impairment, ranging from mild to severe, can vary greatly, adding to the burden of diagnosis and treatment in clinical practice. Deep learning methods based on retinal images have achieved remarkable success in automatic DR grading, but most of them neglect that the presence of diabetes usually affects both eyes, and ophthalmologists usually compare both eyes concurrently for DR diagnosis, leaving correlations between left and right eyes unexploited. In this study, simulating the diagnostic process, we propose a two-stream binocular network to capture the subtle correlations between left and right eyes, in which, paired images of eyes are fed into two identical subnetworks separately during training. We design a contrastive grading loss to learn binocular correlation for five-class DR detection, which maximizes inter-class dissimilarity while minimizing the intra-class difference. Experimental results on the EyePACS dataset show the superiority of the proposed binocular model, outperforming monocular methods by a large margin.Clinical relevance - Compared to conventional DR grading methods based on monocular images, our approach can provide more accurate predictions and extract graphical patterns from retinal images of both eyes for clinical reference. © 2021 IEEE.",Binoculars; Deep learning; Diagnosis; Grading; Large dataset; Ophthalmology; Clinical practices; Diabetic retinopathy; Diabetic retinopathy grading; Diabetics patients; Eye conditions; Late stage; Learning methods; Retinal image; Vision loss; Visual impairment; Eye protection; diabetes mellitus; diabetic retinopathy; eye fundus; human; Diabetes Mellitus; Diabetic Retinopathy; Fundus Oculi; Humans
Article,"Gu Y., Wang X., Pan J., Yong Z., Guo S., Pan T., Jiao Y., Zhou Z.",Effective methods of diabetic retinopathy detection based on deep convolutional neural networks,International Journal of Computer Assisted Radiology and Surgery,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85116350310&doi=10.1007%2fs11548-021-02498-8&partnerID=40&md5=ec4e9c722b8c2ea39c7f4c5cb07ed47d,"Purpose: Diabetic retinopathy (DR) has become the leading cause of blindness worldwide. In clinical practice, the detection of DR often takes a lot of time and effort for ophthalmologist. It is necessary to develop an automatic assistant diagnosis method based on medical image analysis techniques. Methods: Firstly, we design a feature enhanced attention module to capture focus lesions and regions. Secondly, we propose a stage sampling strategy to solve the problem of data imbalance on datasets and avoid the CNN ignoring the focus features of samples that account for small parts. Finally, we treat DR detection as a regression task to keep the gradual change characteristics of lesions and output the final classification results through the optimization method on the validation set. Results: Extensive experiments are conducted on open-source datasets. Our methods achieve 0.851 quadratic weighted kappa which outperforms first place in the Kaggle DR detection competition based on the EyePACS dataset and get the accuracy of 0.914 in the referable/non-referable task and 0.913 in the normal/abnormal task based on the Messidor dataset. Conclusion: In this paper, we propose three novel automatic DR detection methods based on deep convolutional neural networks. The results illustrate that our methods can obtain comparable performance compared with previous methods and generate visualization pictures with potential lesions for doctors and patients. © 2021, CARS.",Convolutional neural networks; Deep learning; Diabetic retinopathy; Fundus image analysis
Conference Paper,"AlSaad R., Al-Maadeed S., Al Mamun M.A., Boughorbel S.",A Deep Learning Based Automatic Severity Detector for Diabetic Retinopathy,Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),2018,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050563641&doi=10.1007%2f978-3-319-96136-1_6&partnerID=40&md5=f4fa600dc30339e3a9b8e784b32f386b,"Automated Diabetic Retinopathy (DR) screening methods with high accuracy have the strong potential to assist doctors in evaluating more patients and quickly routing those who need help to a specialist. In this work, we used Deep Convolutional Neural Network architecture to diagnosing DR from digital fundus images and accurately classifying its severity. We train this network using a graphics processor unit (GPU) on the publicly available Kaggle dataset. We used Theano, Lasagne, and cuDNN libraries on two Amazon EC2 p2.xlarge instances and demonstrated impressive results, particularly for a high-level classification task. On the dataset of 30,262 training images and 4864 testing images, our model achieves an accuracy of 72%. Our experimental results showed that increasing the batch size does not necessarily speed up the convergence of the gradient computations. Also, it demonstrated that the number and size of fully connected layers do not have a significant impact on the performance of the model. © 2018, Springer International Publishing AG, part of Springer Nature.",Convolutional Neural Networks; Deep learning; Diabetic retinopathy; Medical imaging
Article,"Asif S., Amjad K., Qurrat-ul-Ain",Deep Residual Network for Diagnosis of Retinal Diseases Using Optical Coherence Tomography Images,Interdisciplinary Sciences – Computational Life Sciences,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85133194136&doi=10.1007%2fs12539-022-00533-z&partnerID=40&md5=e1c2cab7efca8d22711cd8dd59b89fa6,"Diabetic retinopathy occurs due to damage to the blood vessels in the retina, and it is a major health problem in recent years that progresses slowly without recognizable symptoms. Optical coherence tomography (OCT) is a popular and widely used noninvasive imaging modality for the diagnosis of diabetic retinopathy. Accurate and early diagnosis of this disease using OCT images is crucial for the prevention of blindness. In recent years, several deep learning methods have been very successful in automating the process of detecting retinal diseases from OCT images. However, most methods face reliability and interpretability issues. In this study, we propose a deep residual network for the classification of four classes of retinal diseases, namely diabetic macular edema (DME), choroidal neovascularization (CNV), DRUSEN and NORMAL in OCT images. The proposed model is based on the popular architecture called ResNet50, which eliminates the vanishing gradient problem and is pre-trained on large dataset such as ImageNet and trained end-to-end on the publicly available OCT image dataset. We removed the fully connected layer of ResNet50 and placed our new fully connected block on top to improve the classification accuracy and avoid overfitting in the proposed model. The proposed model was trained and evaluated using different performance metrics, including receiver operating characteristic (ROC) curve on a dataset of 84,452 OCT images with expert disease grading as DRUSEN, CNV, DME and NORMAL. The proposed model provides an improved overall classification accuracy of 99.48% with only 5 misclassifications out of 968 test samples and outperforms existing methods on the same dataset. The results show that the proposed model is well suited for the diagnosis of retinal diseases in ophthalmology clinics. Graphical abstract: [Figure not available: see fulltext.] © 2022, International Association of Scientists in the Interdisciplinary Areas.",Computer-aided detection and diagnosis; Deep learning; Optical coherence tomography; Residual network; Transfer learning
Article,"Arcadu F., Benmansour F., Maunz A., Willis J., Haskova Z., Prunotto M.",Deep learning algorithm predicts diabetic retinopathy progression in individual patients,npj Digital Medicine,2019,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097310832&doi=10.1038%2fs41746-019-0172-3&partnerID=40&md5=5755488849242a61e0a87d31a5e74c1b,"The global burden of diabetic retinopathy (DR) continues to worsen and DR remains a leading cause of vision loss worldwide. Here, we describe an algorithm to predict DR progression by means of deep learning (DL), using as input color fundus photographs (CFPs) acquired at a single visit from a patient with DR. The proposed DL models were designed to predict future DR progression, defined as 2-step worsening on the Early Treatment Diabetic Retinopathy Diabetic Retinopathy Severity Scale, and were trained against DR severity scores assessed after 6, 12, and 24 months from the baseline visit by masked, well-trained, human reading center graders. The performance of one of these models (prediction at month 12) resulted in an area under the curve equal to 0.79. Interestingly, our results highlight the importance of the predictive signal located in the peripheral retinal fields, not routinely collected for DR assessments, and the importance of microvascular abnormalities. Our findings show the feasibility of predicting future DR progression by leveraging CFPs of a patient acquired at a single visit. Upon further development on larger and more diverse datasets, such an algorithm could enable early diagnosis and referral to a retina specialist for more frequent monitoring and even consideration of early intervention. Moreover, it could also improve patient recruitment for clinical trials targeting DR. © 2019, The Author(s).",Deep learning; Diagnosis; Eye protection; Forecasting; Areas under the curves; Color fundus photograph; Diabetic retinopathy; Further development; Learning models; Microvascular; Model prediction; Performance; Predictive signals; Vision loss; Learning algorithms; algorithm; Article; deep learning; diabetic macular edema; diabetic retinopathy; disease exacerbation; disease severity; human; major clinical study; microaneurysm; ophthalmoscopy; optic nerve; outcome variable; priority journal; retrospective study; transfer of learning; visual field
Article,"Astorga J.E.O., Wang L., Yamada S., Fujiwara Y., Du W., Peng Y.",Automatic Detection of Microaneurysms in Fundus Images,International Journal of Software Innovation,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85146238469&doi=10.4018%2fIJSI.315658&partnerID=40&md5=7c9bb76d46046260bcfae66f37a80e03,"Early detection and treatment of diabetic retinopathy can delay blindness and improve quality of life for diabetic patients. It is difficult to detect early symptoms of diabetic retinopathy, which is presented by few microaneurysms in fundus images. This study proposes an algorithm to detect microaneurysms in fundus images automatically. The proposal includes microaneurysms segmentation by U-Net model and their false positives removal by ResNet model. The effectiveness of the proposal is evaluated with the public database IDRiD and E-ophtha by the area under precision recall curve (AUPR). 90% of microaneurysms can be detected at early stages of diabetic retinopathy. This proposal outperforms previous methods based in AUPR evaluation. © 2022 Taru Publications. All rights reserved.",Computer Aided Diagnosis; Deep Learning; Diabetic Retinopathy; Retinal Disease
Article,"Bodapati J.D., Shaik N.S., Naralasetti V.",Composite deep neural network with gated-attention mechanism for diabetic retinopathy severity classification,Journal of Ambient Intelligence and Humanized Computing,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85098794888&doi=10.1007%2fs12652-020-02727-z&partnerID=40&md5=53cdfebd76463ea1da741ce7a5a016ca,"Diabetic Retinopathy (DR) is a micro vascular complication caused by long-term diabetes mellitus. Unidentified diabetic retinopathy leads to permanent blindness. Early identification of this disease requires frequent complex diagnostic procedure which is expensive and time consuming. In this article, we propose a composite deep neural network architecture with gated-attention mechanism for automated diagnosis of diabetic retinopathy. The feature descriptors obtained from multiple pre-trained deep Convolutional Neural Networks (CNNs) are used to represent color fundus retinal images. Spatial pooling methods are introduced to get the reduced versions of these representations without loosing much information. The proposed composite DNN learns independently from each of these reduced representations through different channels and contributes to improving the model generalization. In addition, model also includes gated attention blocks which allows the model to emphasize more on lesion portions of the retinal images while reduced attention to the non-lesion regions. Our experiments on APTOS-2019 Kaggle blindness detection challenge reveal that, the proposed approach leads to improved performance when compared to the existing best models. Our empirical studies also reveal that, the proposed approach leads to more generalised predictions with multi-modal representations when compared to those of uni-modal representations. The proposed composite deep neural network model recorded an accuracy of 82.54% (↑ 2%), and a Kappa score of 79 (↑ 9 points) for diabetic retinopathy severity level prediction. © 2021, Springer-Verlag GmbH Germany, part of Springer Nature.",Composite deep Neural network; Diabetic retinopathy (DR); Gated-attention; Multi-modal features; Pre-trained convolutional neural network; Retinal fundus images; Spatial pooling; Transfer learning
Conference Paper,"Khan M.Z., Lee Y.",Screening fundus images to extract multiple ocular features: A unified modeling approach,"BHI 2021 - 2021 IEEE EMBS International Conference on Biomedical and Health Informatics, Proceedings",2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85125169245&doi=10.1109%2fBHI50953.2021.9508593&partnerID=40&md5=0184ddab17bcf00baa33bb7d77fa0e91,"The retina is a thin layered tissue located close to the optic nerve, considered an extension of the human brain. It captures the incoming light and transforms it into neural signals. Most ocular and systemic disorders such as diabetic retinopathy, glaucoma, hypertension, and cardiovascular diseases manifest themselves in this central hub. The extraction of useful information from the retina is critical. Different imaging techniques, including fundus photography and optical coherence tomography, helped practitioners find useful details; however, the risk of diagnosis error advanced by human intervention is relatively high. The underlying article has designed a fully automated screening system based on a unified modeling approach of diagnosis. The system can extract multiple ocular features with a novel semantic segmentation network to early detect the symptoms of retinal disease. The proposed method has used a separate, publicly available benchmark dataset for each feature evaluation. It has shown promising results in vessels, optic cup, and optic disc segmentation by achieving the highest accuracy, an area under the roc curve, and dice scores. The method is an effort to reduce vision impairment risks in patients facing diabetic retinopathy and glaucoma by providing an automated screening system that can visualize the changes that appear in retinal features caused by vision-threatening disorders. © 2021 IEEE",Deep learning; Fundus images; Ocular disorder; Retinal features; Segmentation
Article,"Zhang G., Sun B., Zhang Z., Pan J., Yang W., Liu Y.",Multi-Model Domain Adaptation for Diabetic Retinopathy Classification,Frontiers in Physiology,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85134200475&doi=10.3389%2ffphys.2022.918929&partnerID=40&md5=d046ca9e248538d5f807615927ca0edf,"Diabetic retinopathy (DR) is one of the most threatening complications in diabetic patients, leading to permanent blindness without timely treatment. However, DR screening is not only a time-consuming task that requires experienced ophthalmologists but also easy to produce misdiagnosis. In recent years, deep learning techniques based on convolutional neural networks have attracted increasing research attention in medical image analysis, especially for DR diagnosis. However, dataset labeling is expensive work and it is necessary for existing deep-learning-based DR detection models. For this study, a novel domain adaptation method (multi-model domain adaptation) is developed for unsupervised DR classification in unlabeled retinal images. At the same time, it only exploits discriminative information from multiple source models without access to any data. In detail, we integrate a weight mechanism into the multi-model-based domain adaptation by measuring the importance of each source domain in a novel way, and a weighted pseudo-labeling strategy is attached to the source feature extractors for training the target DR classification model. Extensive experiments are performed on four source datasets (DDR, IDRiD, Messidor, and Messidor-2) to a target domain APTOS 2019, showing that MMDA produces competitive performance for present state-of-the-art methods for DR classification. As a novel DR detection approach, this article presents a new domain adaptation solution for medical image analysis when the source data is unavailable. Copyright © 2022 Zhang, Sun, Zhang, Pan, Yang and Liu.",convolutional neural network; deep learning; diabetic retinopathy classification; domain adaptation; multi-model
Article,"Imran A., Li J., Pei Y., Yang J.-J., Wang Q.",Comparative Analysis of Vessel Segmentation Techniques in Retinal Images,IEEE Access,2019,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85092025174&doi=10.1109%2fACCESS.2019.2935912&partnerID=40&md5=e39c8ed5408a8ecd0b934a1ba414abd0,"The blood vessels are the primary anatomical structure that can be visible in retinal images. The segmentation of retinal blood vessels has been accepted worldwide for the diagnosis of both cardiovascular (CVD) and retinal diseases. Thus, it requires an appropriate vessel segmentation method for automatic detection of retinal diseases such as diabetic retinopathy and cataract. The detection of retinal diseases using computer-aided diagnosis (CAD) can help people to avoid the risks of visual impairment and save medical resources. This survey presents a comparative analysis of various machine learning and deep learning-based methods for automated blood vessel segmentation in retinal images. This paper briefly describes fundus photography, publicly available retinal databases, pre-processing and post-processing techniques for retinal vessels segmentation. A comprehensive review of the state of the art supervised and unsupervised blood vessel segmentation methodologies are presented in this paper. The objective of this study is to establish a professional structure to familiarize an individual with up-to-date vessel segmentation techniques. Moreover, we compared these approaches to the dataset, evaluation metrics, pre-processing and post-processing steps, feature extraction, segmentation methods, and induced results. © 2013 IEEE.",image segmentation; medical imaging; retinal diseases; retinal fundus images; Vessel segmentation
Article,"Hemamalini S., Kumar V.D.A.",Outlier Based Skimpy Regularization Fuzzy Clustering Algorithm for Diabetic Retinopathy Image Segmentation,Symmetry,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85144877067&doi=10.3390%2fsym14122512&partnerID=40&md5=ab317be741db321d00d338d4c9bfe603,"Blood vessels are harmed in diabetic retinopathy (DR), a condition that impairs vision. Using modern healthcare research and technology, artificial intelligence and processing units are used to aid in the diagnosis of this syndrome and the study of diagnostic procedures. The correct assessment of DR severity requires the segmentation of lesions from fundus pictures. The manual grading method becomes highly difficult and time-consuming due to the wide range of the morphologies, number, and sizes of lesions. For image segmentation, traditional fuzzy clustering techniques have two major drawbacks. First, fuzzy memberships based clustering are more susceptible to outliers. Second, because of the lack of local spatial information, these techniques often result in oversegmentation of images. In order to address these issues, this research study proposes an outlier-based skimpy regularization fuzzy clustering technique (OSR-FCA) for image segmentation. Clustering methods that use fuzzy membership with sparseness can be improved by incorporating a Gaussian metric regularisation into the objective function. The proposed study used the symmetry information contained in the image data to conduct the image segmentation using the fuzzy clustering technique while avoiding over segmenting relevant data. This resulted in a reduced proportion of noisy data and better clustering results. The classification was carried out by a deep learning technique called convolutional neural network (CNN). Two publicly available datasets were used for the validation process by using different metrics. The experimental results showed that the proposed segmentation technique achieved 97.16% and classification technique achieved 97.26% of accuracy on the MESSIDOR dataset. © 2022 by the authors.",deep learning technique; diabetic retinopathy; fuzzy clustering algorithm; outliers; oversegmentation; skimpy regularization; spatial information
Article,"Zhang G., Sun B., Chen Z., Gao Y., Zhang Z., Li K., Yang W.",Diabetic Retinopathy Grading by Deep Graph Correlation Network on Retinal Images Without Manual Annotations,Frontiers in Medicine,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85128883031&doi=10.3389%2ffmed.2022.872214&partnerID=40&md5=433569ecaaaa35060d22a16a2160a212,"Background: Diabetic retinopathy, as a severe public health problem associated with vision loss, should be diagnosed early using an accurate screening tool. While many previous deep learning models have been proposed for this disease, they need sufficient professional annotation data to train the model, requiring more expensive and time-consuming screening skills. Method: This study aims to economize manual power and proposes a deep graph correlation network (DGCN) to develop automated diabetic retinopathy grading without any professional annotations. DGCN involves the novel deep learning algorithm of a graph convolutional network to exploit inherent correlations from independent retinal image features learned by a convolutional neural network. Three designed loss functions of graph-center, pseudo-contrastive, and transformation-invariant constrain the optimisation and application of the DGCN model in an automated diabetic retinopathy grading task. Results: To evaluate the DGCN model, this study employed EyePACS-1 and Messidor-2 sets to perform grading results. It achieved an accuracy of 89.9% (91.8%), sensitivity of 88.2% (90.2%), and specificity of 91.3% (93.0%) on EyePACS-1 (Messidor-2) data set with a confidence index of 95% and commendable effectiveness on receiver operating characteristic (ROC) curve and t-SNE plots. Conclusion: The grading capability of this study is close to that of retina specialists, but superior to that of trained graders, which demonstrates that the proposed DGCN provides an innovative route for automated diabetic retinopathy grading and other computer-aided diagnostic systems. Copyright © 2022 Zhang, Sun, Chen, Gao, Zhang, Li and Yang.",automated diagnosis; diabetic retinopathy; graph correlation network; retinal image classification; unsupervised learning
Conference Paper,"Ramesh R., Sathiamoorthy S.",Teaching and Learning based Optimization with Deep learning Model for Diabetic Retinopathy Grading and Classification,"4th International Conference on Inventive Research in Computing Applications, ICIRCA 2022 - Proceedings",2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85146495388&doi=10.1109%2fICIRCA54612.2022.9985707&partnerID=40&md5=f87f98245f52ffd95407fd9c7f107d2a,"Diabetic retinopathy (DR) refers to a disease that leads to diabetes complications, causing non-reversible damage to retina blood vessels. DR becomes an important reason for impaired vision if not identified initially. The manual analysis procedure of DR retina fundus image with ophthalmologists consumes more time and is expensive and also has the chance of misdiagnosis different computer-aided diagnosis (CAD) techniques. In recent times, deep learning (DL) turns out to be most common method that has reached superior performance in several regions, particularly in clinical image analysis and classification. This study has presented the fully automatic analysis models which surpass manual approaches for avoiding misdiagnosis, minimizes time, cost, and effort. A novel Teaching and Learning based Optimization with Deep learning for Diabetic Retinopathy Grading and Classification (TLBODL-DRGC) model is introduced. The presented TLBODL-DRGC model inspects the retinal fundus image for the recognition and classification of different DR stages. In the TLBODL-DRGC model, the Gabor filtering (GF) system was applied for preprocessing the retinal image, and Otsu thersholding is employed to segment them. Next, the features are developed in them by the use of EfficientNetB0 method, and TLBO based hyperparameter optimizer is presented to enhance the classifier results. Finally, extra-tree classifier (ETC) model is exploited to properly determine the different stages of DR. The presented TLBODL-DRGC model is evaluated using benchmark retinal image database and the results demonstrate the promising performance over other DL models. © 2022 IEEE.",Computer vision; Deep learning; Diabetic retinopathy; Image processing; Retinal screening
Conference Paper,"Singh A., Sengupta S., Rasheed M.A., Jayakumar V., Lakshminarayanan V.",Uncertainty aware and explainable diagnosis of retinal disease,Progress in Biomedical Optics and Imaging - Proceedings of SPIE,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85100946906&doi=10.1117%2f12.2581362&partnerID=40&md5=813d5397135d1cf65c61f3c6960faadb,"Deep learning methods for ophthalmic diagnosis have shown considerable success in tasks like segmentation and classification. However, their widespread application is limited due to the models being opaque and vulnerable to making a wrong decision in complicated cases. Explainability methods show the features that a system used to make prediction while uncertainty awareness is the ability of a system to highlight when it is not sure about the decision. This is one of the first studies using uncertainty and explanations for informed clinical decision making. We perform uncertainty analysis of a deep learning model for diagnosis of four retinal diseases-age-related macular degeneration (AMD), central serous retinopathy (CSR), diabetic retinopathy (DR), and macular hole (MH) using images from a publicly available (OCTID) dataset. Monte Carlo (MC) dropout is used at the test time to generate a distribution of parameters and the predictions approximate the predictive posterior of a Bayesian model. A threshold is computed using the distribution and uncertain cases can be referred to the ophthalmologist thus avoiding an erroneous diagnosis. The features learned by the model are visualized using a proven attribution method from a previous study. The effects of uncertainty on model performance and the relationship between uncertainty and explainability are discussed in terms of clinical significance. The uncertainty information along with the heatmaps make the system more trustworthy for use in clinical settings. © COPYRIGHT SPIE. Downloading of the abstract is permitted for personal use only.",attributions; Bayesian; deep learning; explainability; retina; retinal disease; retinal imaging; Uncertainty
Article,"Heisler M., Karst S., Lo J., Mammo Z., Yu T., Warner S., Maberley D., Beg M.F., Navajas E.V., Sarunic M.V.",Ensemble deep learning for diabetic retinopathy detection using optical coherence tomography angiography,Translational Vision Science and Technology,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090631326&doi=10.1167%2ftvst.9.2.20&partnerID=40&md5=e33e7732d04f8ac9c0efcfb99d0026ec,"Purpose: To evaluate the role of ensemble learning techniques with deep learning in classifying diabetic retinopathy (DR) in optical coherence tomography angiography (OCTA) images and their corresponding co-registered structural images. Methods: A total of 463 volumes from 380 eyes were acquired using the 3 × 3-mm OCTA protocol on the Zeiss Plex Elite system. Enface images of the superficial and deep capillary plexus were exported from both the optical coherence tomography and OCTA data. Component neural networks were constructed using single data-types and fine-tuned using VGG19, ResNet50, and DenseNet architectures pretrained on ImageNet weights. These networks were then ensembled using majority soft voting and stacking techniques. Results were compared with a classifier using manually engineered features. Class activation maps (CAMs) were created using the original CAM algorithm and Grad-CAM. Results: ThenetworkstrainedwiththeVGG19architectureoutperformedthenetworks trained on deeper architectures. Ensemble networks constructed using the four finetuned VGG19 architectures achieved accuracies of 0.92 and 0.90 for the majority soft voting and stacking methods respectively. Both ensemble methods outperformed the highest single data-type network and the network trained on hand-crafted features. Grad-CAM was shown to more accurately highlight areas of disease. Conclusions: Ensemble learning increases the predictive accuracy of CNNs for classifying referable DR on OCTA datasets. Translational Relevance: Because the diagnostic accuracy of OCTA images is shown to be greater than the manually extracted features currently used in the literature, the proposed methods may be beneficial toward developing clinically valuable solutions for DR diagnoses. © 2020 The Authors.",Deep learning; Diabetic retinopathy; Machine learning; Optical coherence tomography; Optical coherence tomography angiography
Conference Paper,"Filippini C., Chiarelli A.M., Cardone D., Perpetuini D., Lorenza B., Agnifili L., Mastropasqua L., Merla A.",Age-related ocular surface modifications assessment combining thermal infrared and deep learning approach.,Proceedings of SPIE - The International Society for Optical Engineering,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85113905678&doi=10.1117%2f12.2594554&partnerID=40&md5=63685d95df81d14bafb947729636e93c,"Age-related diseases such as glaucoma, diabetic retinopathy, and macular degeneration remain the leading causes of low, vision in developed countries. Early detection of such diseases can prevent the risk of progression to blindness. To this end, regular check-ups are encouraged to favor timely eye disease diagnosis. Yet, conducting routine large-scale eye screening can be difficult and time-consuming. In this study, a novel, fast and automatic approach for age-related ocular surface modifications (AR-OSM) assessment is proposed. Indeed, accurate AR-OSM detection in the healthy population may allow to establish age-matched normal ranges, valuable for the preliminary identification of age-related diseases. The task was performed combining thermal infrared (IR) imaging of the eye with artificial intelligence techniques. Thermal IR imaging enables non-invasive real-time imaging of the ocular surface temperature (OST). OST is influenced by ocular factors like the tear film, blood flow perfusion, heat conduction, and convection of the aqueous humor, thus providing significant information on eye health. Ninety-two healthy subjects participated in the experiment (age: 20-90 years-old). A Deep convolutional neural network (DCNN) model was implemented to predict the subjects' age based on their eye IR-image. The DCNN was able to predict the participants' age with a good level of accuracy, reporting a correlation between real and predicted age of r=0.82 and RMSE=9.9years. In conclusion, this method allows an accurate AR-OSM evaluation usable for early recognition of eyes at risk for age-related disease. © 2021 SPIE. All rights reserved.",Artificial intelligence; Deep learning; Eye aging; IR imaging
Conference Paper,"Chudzik P., Majumdar S., Caliva F., Al-DIri B., Hunter A.",Exudate segmentation using fully convolutional neural networks and inception modules,Progress in Biomedical Optics and Imaging - Proceedings of SPIE,2018,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85047362279&doi=10.1117%2f12.2293549&partnerID=40&md5=c02a8067a9a10de5e47e01dc9fa8c318,"Diabetic retinopathy is an eye disease associated with diabetes mellitus and also it is the leading cause of preventable blindness in working-age population. Early detection and treatment of DR is essential to prevent vision loss. Exudates are one of the earliest signs of diabetic retinopathy. This paper proposes an automatic method for the detection and segmentation of exudates in fundus photographies. A novel fully convolutional neural network architecture with Inception modules is proposed. Compared to other methods it does not require the removal of other anatomical structures. Furthermore, a transfer learning approach is applied between small datasets of different modalities from the same domain. To the best of authors' knowledge, it is the first time that such approach has been used in the exudate segmentation domain. The proposed method was evaluated using publicly available E-Ophtha datasets. It achieved better results than the state-of-the-art methods in terms of sensitivity and specificity metrics. The proposed algorithm accomplished better results using a diseased/not diseased evaluation scenario which indicates its applicability for screening purposes. Simplicity, performance, efficiency and robustness of the proposed method demonstrate its suitability for diabetic retinopathy screening applications. © COPYRIGHT SPIE. Downloading of the abstract is permitted for personal use only.",Convolutional Neural Networks; Deep Learning; Diabetic Retinopathy; Exudate Segmentation; Fundus Photography
Conference Paper,"Ananda S., Kitahara D., Hirabayashi A., Udaya Kumar Reddy K.R.",Automatic fundus image segmentation for diabetic retinopathy diagnosis by multiple modified U-nets and segnets,"2019 Asia-Pacific Signal and Information Processing Association Annual Summit and Conference, APSIPA ASC 2019",2019,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85082386466&doi=10.1109%2fAPSIPAASC47483.2019.9023290&partnerID=40&md5=9d8b6ffe9cff36228573d7c6595ca19d,"Diabetes mellitus leads to damage of the retina by a high blood sugar level. This disease is called diabetic retinopathy (DR), and it is one major cause of blindness among working-aged people. DR affects about 80% of patients who have had diabetes for twenty years or more. The longer a period of diabetes is, the higher the risk of developing DR is. In order to prevent the blindness caused by DR, accurate DR diagnosis from a retinal fundus image is important. Recently, deep learning techniques play significant role in the field of computer vision. When we apply deep learning to segmentation of abnormal parts in fundus images, two major problems arise. One is that the number of available data is insufficient to train a deep neural network. The other is that the sizes of the abnormal parts are quite different depending on the type of the disease, which leads to low segmentation accuracy of small diseases. These two problems make the fundus image segmentation challenging. In this paper, we propose a segmentation method using multiple deep neural networks. To train the deep neural networks from a small number of data, we use data augmentation as preprocessing and adopt the Dice coefficient with the binary cross entropy as a loss function. Moreover, to improve the segmentation accuracy of small diseases, e.g., microaneurysms, we construct one individual network for each type of the disease. In experiments, the networks are trained from IDRiD dataset and tested for MESSIDOR dataset. We compare and discuss the accuracy of the proposed method with modified U-Nets and SegNets. © 2019 IEEE.",Deep learning; Deep neural networks; Diagnosis; Eye protection; Blood sugar levels; Diabetes mellitus; Diabetic retinopathy; Individual network; Learning techniques; Retinal fundus images; Segmentation accuracy; Segmentation methods; Image segmentation
Conference Paper,"Yan Y., Conze P.-H., Quellec G., Massin P., Lamard M., Coatrieux G., Cochener B.",Longitudinal Detection of Diabetic Retinopathy Early Severity Grade Changes Using Deep Learning,Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85115851196&doi=10.1007%2f978-3-030-87000-3_2&partnerID=40&md5=f05978e96e7cc6b768c4d22ad55eff93,"Longitudinal medical image analysis is crucial for identifying the unobvious emergence and evolution of early lesions, towards earlier and better patient-specific pathology management. However, traditional computer-aided diagnosis (CAD) systems for diabetic retinopathy (DR) rarely make use of longitudinal information to improve DR analysis. In this work, we present a deep information fusion framework that exploits two consecutive longitudinal studies for the assessment of early DR severity changes. In particular, three fusion schemes are investigated: (1) early fusion of inputs, (2) intermediate fusion of feature vectors incorporating Spatial Transformer Networks (STN) and (3) late fusion of feature vectors. Exhaustive experiments compared with respect to no-fusion baselines validate that incorporating prior DR studies can improve the referable DR severity classification performance through the late fusion scheme whose AUC reaches 0.9296. Advantages and limitations of the different fusion methods are discussed in depth. We also propose different pre-training strategies which are employed to bring considerable performance gains for DR severity grade change detection purposes. © 2021, Springer Nature Switzerland AG.",Computer-aided diagnosis; Deep learning; Diabetic retinopathy; Information fusion; Longitudinal analysis
Conference Paper,"Atul, Dhingra S.",Classification of Diabetic Retinopathy Disease with Improved Transfer Learning Techniques using EfficientNets,"2022 10th International Conference on Reliability, Infocom Technologies and Optimization (Trends and Future Directions), ICRITO 2022",2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85144590448&doi=10.1109%2fICRITO56286.2022.9965087&partnerID=40&md5=acf4dda630077d7fb19d2e2fd2fd9bfd,"One complication of diabetes is diabetic retinopathy (DR) and is a very common eye disease. It is one of the primary causes of blindness worldwide. Traditionally, a physician identifies the presence of vitals manually when diagnosing the image of the retina of the eye of the people suffering from Diabetic Retinopathy. It is a difficult, time-taking, manual, and skill-oriented task. This paper's aim is to create a system that can automatically analyze the images of the retina and tells about the severity of the disease. This has been achieved by modelling an improved Convolutional Neural Network based model using the transfer learning techniques and various efficientNet models like efficientNet-B1, efficientNet-B2, efficientNet-B3, efficientNet-B4 and efficientNet-B5. This research work uses the dataset provided by Kaggle Community. The efficientNet-B5 model results show an accuracy of 98.91% and a validation kappa score of 0.9308. © 2022 IEEE.",Blindness Detection; Deep Learning; Diabetic Retinopathy; EfficientNets; fundus images; Kaggle; Transfer Learning
Article,"Ming S., Xie K., Lei X., Yang Y., Zhao Z., Li S., Jin X., Lei B.",Evaluation of a novel artificial intelligence-based screening system for diabetic retinopathy in community of China: a real-world study,International Ophthalmology,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85098666378&doi=10.1007%2fs10792-020-01685-x&partnerID=40&md5=e5f07db43dfaa8ba5b792973efdea7ea,"Purpose: To evaluate the performance of an AI-based diabetic retinopathy (DR) grading model in real-world community clinical setting. Methods: Participants with diabetes on record in the chosen community were recruited by health care staffs in a primary clinic of Zhengzhou city, China. Retinal images were prospectively collected during December 2018 and April 2019 based on intent-to-screen principle. A pre-validated AI system based on deep learning algorithm was deployed to screen DR graded according to the International Clinical Diabetic Retinopathy scale. Kappa value of DR severity, the sensitivity, specificity of detecting referable DR (RDR) and any DR were generated based on the standard of the majority manual grading decision of a retina specialist panel. Results: Of the 193 eligible participants, 173 (89.6%) were readable with at least one eye image. Mean [SD] age was 69.3 (9.0) years old. Total of 321 eyes (83.2%) were graded both by AI and the specialist panel. The κ value in eye image grading was 0.715. The sensitivity, specificity and area under curve for detection of RDR were 84.6% (95% CI: 54.6– 98.1%), 98.0% (95% CI: 94.3–99.6%) and 0.913 (95% CI: 0.797–1.000), respectively. For detection of any DR, the upper indicators were 90.0% (95% CI: 68.3–98.8), 96.6% (95% CI: 92.1–98.9) and 0.933 (95% CI: 0.933–1.000), respectively. Conclusion: The AI system showed relatively good consistency with ophthalmologist diagnosis in DR grading, high specificity and acceptable sensitivity for identifying RDR and any DR. Translational relevance: It is feasible to apply AI-based DR screening in community. Precis: Deployed in community real-world clinic setting, AI-based DR screening system showed high specificity and acceptable sensitivity in identifying RDR and any DR. Good DR diagnostic consistency was found between AI and manual grading. These prospective evidences were essential for regulatory approval. © 2021, The Author(s), under exclusive licence to Springer Nature B.V. part of Springer Nature.",Artificial intelligence; Deep neural network; Diabetic retinopathy; Fundus photography; Rreal-world study
Article,"Liang N., Yuan L., Wen X., Xu H., Wang J.",End-To-End Retina Image Synthesis Based on CGAN Using Class Feature Loss and Improved Retinal Detail Loss,IEEE Access,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85135735667&doi=10.1109%2fACCESS.2022.3196377&partnerID=40&md5=9bd4e57c83c408f8c91a035382541095,"Retinal images are the most direct and effective basis for Diabetic Retinopathy (DR) diagnosis. With the rapid development of deep learning, the technology of retinal image-assisted diagnosis based on deep learning is widely used in the field of DR intelligent diagnosis. However, the training of deep neural network usually requires a large number of annotated samples, but retinal images annotated by professional doctors are cost-expensive and difficult to obtain, which limits the application of deep learning technology in DR intelligent diagnosis. In order to alleviate the scarcity of labelled retinal images, we propose an end-to-end conditional generative adversarial network with class feature loss and improved retinal detail loss. The network combines the above two losses with the adversarial loss, and jointly constrains the generator to generate high-quality retinal images. The proposed retinal detail loss is summed over physiological detail loss which is meant to preserve high-level semantic features of the physiological details contained in the fundus images and pixel loss which ensures the low-level features in synthesized image will not deviate from the real image. In addition, the class feature loss constrains the synthesized images to be consistent with the real images in class features representation, which further makes the synthesized images have pathological features of the corresponding grade. The generated images by the proposed network are evaluated from three objective metrics including the subjective effect and the FID, SWD, which are used to evaluate the quality and diversity of generated images, and the effect of retinal vessel segmentation, respectively. Experimental results demonstrate that our synthesized images have superior performance on both the quality and quantity. © 2013 IEEE.",conditional generative adversarial network; deep learning; Diabetic retinopathy; DR~grading; retinal image synthesis
Conference Paper,"Xia X., Zhan K., Li Y., Xiao G., Yan J., Huang Z., Huang G., Fang Y.",Eye Disease Diagnosis and Fundus Synthesis: A Large-Scale Dataset and Benchmark,"2022 IEEE 24th International Workshop on Multimedia Signal Processing, MMSP 2022",2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85143613021&doi=10.1109%2fMMSP55362.2022.9949547&partnerID=40&md5=6d7332b2e883585c36234d81f6e943f7,"As one of the most common imaging modalities, retinal fundus imaging offers images of interior surface of eyes for initial examination of disorders. Data-driven machine learning methods, especially deep learning models in recent years, provide automatic ophthalmological disease diagnosis techniques from color fundus images. Data with high quality, diversity and balanced distribution supports deep model-based eye disease diagnosis. However, many existing datasets focus on a specific kind of eye disease, and some suffer from label noise or quality degeneration, which hinders automatic screening algorithms from dealing with multiple eye diseases. To solve this, we propose a high-quality dataset containing 28877 color fundus images for deep learning-based diagnosis. Except for 15000 healthy samples, the dataset consists of 8 eye disorders including diabetic retinopathy, agerelated macular degeneration, glaucoma, pathological myopia, hypertension, retinal vein occlusion, LASIK spot and others. Based on this, we propose a co-attention network for disease diagnosis, establish benchmark on screening and grading tasks, and demonstrate that the proposed dataset supports generative adversarial network-based image synthesis. The dataset will be made publicly available. © 2022 IEEE.",dataset; eye disease diagnosis; fundus sythesis
Article,"Porwal P., Pachade S., Kokare M., Deshmukh G., Son J., Bae W., Liu L., Wang J., Liu X., Gao L., Wu T., Xiao J., Wang F., Yin B., Wang Y., Danala G., He L., Choi Y.H., Lee Y.C., Jung S.-H., Li Z., Sui X., Wu J., Li X., Zhou T., Toth J., Baran A., Kori A., Chennamsetty S.S., Safwan M., Alex V., Lyu X., Cheng L., Chu Q., Li P., Ji X., Zhang S., Shen Y., Dai L., Saha O., Sathish R., Melo T., Araújo T., Harangi B., Sheng B., Fang R., Sheet D., Hajdu A., Zheng Y., Mendonça A.M., Zhang S., Campilho A., Zheng B., Shen D., Giancardo L., Quellec G., Mériaudeau F.",IDRiD: Diabetic Retinopathy – Segmentation and Grading Challenge,Medical Image Analysis,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85074152892&doi=10.1016%2fj.media.2019.101561&partnerID=40&md5=f325251c527232a54b57a535314b7dbd,"Diabetic Retinopathy (DR) is the most common cause of avoidable vision loss, predominantly affecting the working-age population across the globe. Screening for DR, coupled with timely consultation and treatment, is a globally trusted policy to avoid vision loss. However, implementation of DR screening programs is challenging due to the scarcity of medical professionals able to screen a growing global diabetic population at risk for DR. Computer-aided disease diagnosis in retinal image analysis could provide a sustainable approach for such large-scale screening effort. The recent scientific advances in computing capacity and machine learning approaches provide an avenue for biomedical scientists to reach this goal. Aiming to advance the state-of-the-art in automatic DR diagnosis, a grand challenge on “Diabetic Retinopathy – Segmentation and Grading” was organized in conjunction with the IEEE International Symposium on Biomedical Imaging (ISBI - 2018). In this paper, we report the set-up and results of this challenge that is primarily based on Indian Diabetic Retinopathy Image Dataset (IDRiD). There were three principal sub-challenges: lesion segmentation, disease severity grading, and localization of retinal landmarks and segmentation. These multiple tasks in this challenge allow to test the generalizability of algorithms, and this is what makes it different from existing ones. It received a positive response from the scientific community with 148 submissions from 495 registrations effectively entered in this challenge. This paper outlines the challenge, its organization, the dataset used, evaluation methods and results of top-performing participating solutions. The top-performing approaches utilized a blend of clinical information, data augmentation, and an ensemble of models. These findings have the potential to enable new developments in retinal image analysis and image-based DR screening in particular. © 2019 Elsevier B.V.",Challenge; Deep learning; Diabetic Retinopathy; Retinal image analysis
Article,"Gayathri S., Gopi V.P., Palanisamy P.",A lightweight CNN for Diabetic Retinopathy classification from fundus images,Biomedical Signal Processing and Control,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85089221799&doi=10.1016%2fj.bspc.2020.102115&partnerID=40&md5=04cbb7b6e6279e82e536253bf8bc741f,"Diabetic Retinopathy (DR) is a complication of diabetes mellitus that damages blood vessel networks in the retina. This is a serious vision-threatening issue in most diabetic subjects. The DR diagnosis by color fundus images involves skilled clinicians to recognize the presence of lesions in the image that can be used to detect the disease properly, making it a time-consuming process. Effective automated detection of DR is a challenging task. The feature extraction plays an excellent role in effective automated disease detection. Convolutional Neural Networks (CNN) have superior image classification efficiency in the present scenario compared to earlier handcrafted feature-based image classification techniques. This work presents a novel CNN model to extract features from retinal fundus images for better classification performance. The CNN output features are used as input for different machine learning classifiers in the suggested system. The model is evaluated through various classifiers (Support Vector Machine, AdaBoost, Naive Bayes, Random Forest, and J48) by using images from generic IDRiD, MESSIDOR, and KAGGLE datasets. The efficacy of the classifier is evaluated by comparing the specificity, precision, recall, False Positive Rate (FPR), Kappa-score, and accuracy values for each classifier. The evaluation results indicate that the proposed feature extraction technique along with the J48 classifier outperforms all the other classifiers for MESSIDOR, IDRiD, and KAGGLE datasets with an average accuracy of 99.89% for binary classification and 99.59% for multiclass classification. Furthermore, for the J48 classifier, the average Kappa-score (K-score) is 0.994 for binary classification and 0.994 for multi-class classification. © 2020 Elsevier Ltd",10-fold cross-validation; Classifiers; CNN feature extraction; DR binary and multi class classification; Retinal fundus images
Article,"Yi S.-L., Yang X.-L., Wang T.-W., She F.-R., Xiong X., He J.-F.",Diabetic retinopathy diagnosis based on RA-efficientnet,Applied Sciences (Switzerland),2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85119931923&doi=10.3390%2fapp112211035&partnerID=40&md5=e1cf87f49d0745fcbec0a4bf6cd7ec7a,"The early detection and grade diagnosis of diabetic retinopathy (DR) are very important for the avoidance of blindness, and using deep learning methods to automatically diagnose DR has attracted great attention. However, the small amount of DR data limits its application. To automatically learn the disease’s features and detect DR more accurately, we constructed a DR grade diagnostic model. To realize the model, the authors performed the following steps: firstly, we preprocess the DR images to solve the existing problems in an APTOS 2019 dataset, such as size difference, information redundancy and the data imbalance. Secondly, to extract more valid image features, a new network named RA-EfficientNet is proposed, in which a residual attention (RA) block is added to EfficientNet to extract more features and to solve the problem of small differences between lesions. EfficientNet has been previously trained on the ImageNet dataset, based on transfer learning technology, to overcome the small sample size problem of DR. Lastly, based on the extracted features, two classifiers are designed, one is a 2-grade classifier and the other a 5-grade classifier. The 2-grade classifier can diagnose DR, and the 5-grade classifier provides 5 grades of diagnosis for DR, as follows: 0 for No DR, 1 for mild DR, 2 for moderate, 3 for severe and 4 for proliferative DR. Experiments show that our proposed RA-EfficientNet can achieve better performance, with an accuracy value of 98.36% and a kappa score of 96.72% in a 2-grade classification and an accuracy value of 93.55% and a kappa score of 91.93% in a 5-grade classification. The results indicate that the proposed model effectively improves DR detection efficiency and resolves the existing limitation of manual feature extraction. © 2021 by the authors. Licensee MDPI, Basel, Switzerland.",Diabetic retinopathy; EfficientNet; Residual attention block; Retinal image; Transfer learning
Conference Paper,"Xiao Z., Zhang Y., Wu J., Zhang X.",SE-MIDNet Based on Deep Learning for Diabetic Retinopathy Classification,ACM International Conference Proceeding Series,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85116241083&doi=10.1145%2f3467707.3467720&partnerID=40&md5=bdc0857b3671e2c48e7424ae3f7fac8c,"Diabetic Retinopathy (DR) is one of the most serious complications of diabetes. At present, DR detection mainly relies on detailed analysis by ophthalmologists. However, manual diagnosis is time-consuming and low efficiency. Aiming at the task of DR automatic classification, this paper proposes a classification method of DR based on deep learning. In view of the different sizes of the lesion area, firstly, an improved Inception module is proposed, which enables the network to efficiently extract multi-scale features of DR images. Then, the dense connection method is used to splice the output feature maps of the improved Inception module and send them to the subsequent layers to realize the multi-scale feature reuse of DR images and enhance the feature representation of small targets. Finally, the Squeeze-and-Excitation (SE) module is used to obtain the global information of the feature map on each channel, and the dynamic nonlinear modeling of each channel is carried out to improve the generalization ability of the network. The experimental results show that the network structure designed in this paper has good generalization ability, and the accuracy of DR automatic classification reaches 88.24%, the sensitivity reaches 99.43%, and the specificity reaches 97.6%, which can meet the needs of hospitals for DR classification. © 2021 ACM.",Deep learning; DR classification; Inception; SE module
Conference Paper,"Zabihollahy F., Lochbihler A., Ukwatta E.",Deep learning based approach for fully automated detection and segmentation of hard exudate from retinal images,Progress in Biomedical Optics and Imaging - Proceedings of SPIE,2019,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85066461492&doi=10.1117%2f12.2513034&partnerID=40&md5=9c39c6ca3b9039fd6b27ff402b66004e,"Diabetic retinopathy (DR), which is a major cause of blindness in the world is characterized by hard exudate lesions in the eyes as these lesions are one of the most prevalent and earliest symptoms of DR. In this paper, a fully automated method for hard exudate delineation is described that could assist ophthalmologists for timely diagnosis of DR before disease progress to a level beyond treatment. We used a dataset consist of 107 images to develop a U-Net-based method for hard exudate detection and segmentation. This network consists of shrinking and expansive streams in which shrinking path has the same structure as conventional convolutional networks. In expansive path, obtained features are merged with those from shrinking path with the proper resolution to generate multi-scale features and accomplish distinction between hard exudate and normal tissue in retinal images. The training images were augmented artificially to increase the number of samples in the dataset and avoid overfitting issues. Experimental results showed that our proposed method reported sensitivity, specificity, accuracy, and Dice similarity coefficient of 96.15%, 80.77%, 88.46%, and 67.23 ± 13.60% on 52 test images, respectively. © 2019 SPIE.",Diabetic retinopathy; hard exudate; U-Net convolutional neural network (CNN)-based
Article,"Kumar A., Tewari A.S., Singh J.P.",Classification of diabetic macular edema severity using deep learning technique,Research on Biomedical Engineering,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85135306852&doi=10.1007%2fs42600-022-00233-z&partnerID=40&md5=a0ae7bf4a65dc65eefd37c8dc6194849,"Purpose: Diabetic macular edema (DME) is a kind of hard exudates lesion seen near the diabetic macular region of the retina. DME causes visual loss and may result in complete blindness; early identification and treatment may be able to cure this. Identification of DME at an early stage is a challenging and error-prone task. To address this issue, the article presents a methodology that uses the notion of transfer learning to identify cases of DME from retinal fundus images. Methods: A pre-trained DenseNet121 is used in this technique to extract the useful set of feature vectors from the fundus images, which are then fed into a few additional fully connected layers and then into the classification layer to classify DME instances. A total of 577 fundus training images from 3 DME classes were used to train the proposed model, and 103 fundus testing images were used to verify the proposed model for classifying them into one of the three DME cases. Results: The suggested model is trained and tested on the Indian Diabetic Retinopathy Image Dataset (IDRiD). With the test images, the results demonstrate that the proposed model outperformed the state-of-the-art models presented in “Diabetic Retinopathy – Segmentation and Grading Challenge” held at ISBI-2018 with an accuracy of 86.4%. Conclusion: The proposed model diagnoses DME at an early stage for timely treatment and helps to reduce the workload of ophthalmologists. © 2022, The Author(s), under exclusive licence to The Brazilian Society of Biomedical Engineering.",Deep learning; Diabetic macular edema; Diabetic retinopathy; Medical image processing; Transfer learning
Article,Alghamdi H.S.,Towards Explainable Deep Neural Networks for the Automatic Detection of Diabetic Retinopathy,Applied Sciences (Switzerland),2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85139952075&doi=10.3390%2fapp12199435&partnerID=40&md5=50db8a8968b86bd20a7049ee0de3456c,"Featured Application: The proposed approach can be applied to any of the Convolutional Neural Networks-based architecture to explain, evaluate and validate the model’s decisions. Diabetic Retinopathy (DR) is a common complication associated with diabetes, causing irreversible vision loss. Early detection of DR can be very helpful for clinical treatment. Ophthalmologists’ manual approach to DR diagnoses is expensive and time-consuming; thus, automatic detection of DR is becoming vital, especially with the increasing number of diabetes patients worldwide. Deep learning methods for analyzing medical images have recently become prevalent, achieving state-of-the-art results. Consequently, the need for interpretable deep learning has increased. Although it was demonstrated that the representation depth is beneficial for classification accuracy for DR diagnoses, model explainability is rarely analyzed. In this paper, we evaluated three state-of-the-art deep learning models to accelerate DR detection using the fundus images dataset. We have also proposed a novel explainability metric to leverage domain-based knowledge and validate the reasoning of a deep learning model’s decisions. We conducted two experiments to classify fundus images into normal and abnormal cases and to categorize the images according to the DR severity. The results show the superiority of the VGG-16 model in terms of accuracy, precision, and recall for both binary and DR five-stage classification. Although the achieved accuracy of all evaluated models demonstrates their capability to capture some lesion patterns in the relevant DR cases, the evaluation of the models in terms of their explainability using the Grad-CAM-based color visualization approach shows that the models are not necessarily able to detect DR related lesions to make the classification decision. Thus, more investigations are needed to improve the deep learning model’s explainability for medical diagnosis. © 2022 by the author.",convolutional neural networks; deep learning; DenseNet; diabetic retinopathy; explainable deep networks; Grad-CAM; ResNet
Article,Lahmiri S.,Hybrid deep learning convolutional neural networks and optimal nonlinear support vector machine to detect presence of hemorrhage in retina,Biomedical Signal Processing and Control,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85083510927&doi=10.1016%2fj.bspc.2020.101978&partnerID=40&md5=8edfaa038b6945a2747d589bd5970579,"Diabetic retinopathy is a disorder that occurs in retina and it is caused by diabetes mellitus. Millions of people with diabetic retinopathy are expected to experience a loss of vision across the globe. Therefore, accurate automated-diagnosis systems are highly needed to help physicians in clinical milieu. Though many factors are effective in the diagnosis of diabetic retinopathy, presence of hemorrhage in retina remains one of the most significant factors. We present a three-stage hybrid system for classification of normal and abnormal digital retina images with hemorrhage. First, deep learning convolutional neural networks (CNN) is used for automatic features extraction. Second, the Student t-test is applied to the high dimensional features set extracted by CNN to select the best ten features. Third, the selected CNN-based features are fed to a nonlinear support vector machine (SVM) tuned by Bayes optimization to perform classification task. Three additional popular classifiers are also trained with features extracted by CNN and their performances are compared to that of the optimal nonlinear SVM including linear discriminant analysis (LDA), naïve Bayes (NB), and k nearest neighbor (kNN). Each automated-diagnosis system is validated on a database composed of healthy and unhealthy digital retina images affected with various grades of hemorrhage. Experimental results from ten-fold cross-validation methodology show that CNN-SVM outperforms all other three reference systems; namely, CNN-LDA, CNN-NB, and CNN-kNN. Indeed, CNN-SVM system achieved 99.11%±0.0101 accuracy, 99.14%±0.0143 sensitivity, 99.08%±0.0083 specificity, and 0.97.31%± 0.0381 area under curve (AUC) of the receiver operating characteristic. The proposed system is fast and accurate. © 2020 Elsevier Ltd",Bayes optimization; Classification; Deep learning convolutional neural networks; Diabetic retinopathy; Nonlinear support vector machine; Retina hemorrhage
Article,"Li X., Shen L., Shen M., Tan F., Qiu C.S.",Deep learning based early stage diabetic retinopathy detection using optical coherence tomography,Neurocomputing,2019,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85071587672&doi=10.1016%2fj.neucom.2019.08.079&partnerID=40&md5=80899679fa6bbeb78da52d04bb0a73e3,"Diabetic retinopathy (DR) is one of the leading causes of preventable blindness globally. Performing retinal examinations on all diabetic patients is an unmet need, and detection at an early stage can provide better control of the disease. The objective of this study is to provide an optical coherence tomography (OCT) image based diagnostic technology for automated early DR diagnosis, including at both grades 0 and 1. This work can help ophthalmologists with evaluation and treatment, reducing the rate of vision loss, and enabling timely and accurate diagnosis. In this work, we developed and evaluated a novel deep network – OCTD_Net, for early-stage DR detection. While one of the networks extracted features from the original OCT image, the other extracted retinal layer information. The accuracy, sensitivity and specificity was 0.92, 0.90 and 0.95, respectively. Our analysis of retinal layers and the features learned by the proposed network suggests that grade 1 DR patients present with significant changes in the thickness and reflection of certain retinal layers. However, grade 0 DR patients do not have such significant changes. The heatmaps of the trained network also suggest that patients with early DR showed different textures around the myoid and ellipsoid zones, inner nuclear layers, and photoreceptor outer segments, which should all receive dedicated attention for early DR diagnosis. © 2019 Elsevier B.V.",Computer-aided diagnosis; Deep learning; Diabetic retinopathy; Optical coherence tomography
Article,"Pugal Priya R., Saradadevi Sivarani T., Gnana Saravanan A.",Deep long and short term memory based Red Fox optimization algorithm for diabetic retinopathy detection and classification,International Journal for Numerical Methods in Biomedical Engineering,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85121367485&doi=10.1002%2fcnm.3560&partnerID=40&md5=80a7e5eb02cc2319706f6d4a0e7b6404,"Because of retina abnormalities of diabetic patients, the most common vision-threatening disease is diabetic retinopathy (DR). The DR diagnosis and prevention are challenging tasks as they may lead to vision loss. According to the literature analysis, the shortcomings in existing studies, such as failed to reduce the feature dimension, higher execution time, and higher computational cost, unable to tune the hyper-parameters, such as a number of hidden layers and learning rate, more computational complexities, higher cost, and so forth, during DR classification. To tackle these problems, we proposed a deep long- and short-term memory (LSTM) in a neural network with Red Fox optimization (deep LSTM-RFO) algorithm for DR classification. The four major components involved in the proposed methods are image preprocessing, segmentation, feature extraction, and classification. At first, an adaptive histogram equalization and histogram equalization model performs the fundus image preprocessing, thereby neglecting the noise and improving the contrast level of an image. Next, an adaptive watershed segmentation model effectively segments the lesion region based on the optic disc color and size of hemorrhages. At the third stage, we have extracted statistical, intensity, color, and shape features. Finally, the single normal class with three abnormal classes such as mild non-proliferative diabetic retinopathy, moderate NPDR, and severe NPDR are accurately classified using the deep LSTM-RFO algorithm. Experimentally, the MESSIDOR, STARE, and DRIVE datasets are used for both training and validation. MATLAB software performs the implementation process with respect to various evaluation criteria used. However, the proposed method accomplished superior performance, such as 98.45% specificity, 96.78% sensitivity, 97.92% precision, 96.89% recall, and 97.93% F-score results in terms of DR classification than previous methods. © 2021 John Wiley & Sons Ltd.",deep LSTM in neural network; diabetic retinopathy; feature extraction; Red Fox optimization algorithm; watershed segmentation model
Conference Paper,"Chudzik P., Majumdar S., Caliva F., Al-DIri B., Hunter A.",Microaneurysm detection using deep learning and interleaved freezing,Progress in Biomedical Optics and Imaging - Proceedings of SPIE,2018,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85047331216&doi=10.1117%2f12.2293520&partnerID=40&md5=e461ddf28d64a015ea2819f7110d274e,"Diabetes affects one in eleven adults. Diabetic retinopathy is a microvascular complication of diabetes and the leading cause of blindness in the working-age population. Microaneurysms are the earliest clinical signs of diabetic retinopathy. This paper proposes an automatic method for detecting microaneurysms in fundus photographies. A novel patch-based fully convolutional neural network for detection of microaneurysms is proposed. Compared to other methods that require five processing stages, it requires only two. Furthermore, a novel network fine-tuning scheme called Interleaved Freezing is presented. This procedure significantly reduces the amount of time needed to re-train a network and produces competitive results. The proposed method was evaluated using publicly available and widely used datasets: E-Ophtha and ROC. It outperforms the state-of-the-art methods in terms of free-response receiver operatic characteristic (FROC) metric. Simplicity, performance, efficiency and robustness of the proposed method demonstrate its suitability for diabetic retinopathy screening applications. © COPYRIGHT SPIE. Downloading of the abstract is permitted for personal use only.",Convolutional Neural Networks; Deep Learning; Diabetic Retinopathy; Fundus Photography; Microaneurysm Detection
Conference Paper,"Rao S., Tang J., Huang Y., Cui K., Wang S.",Grouping and Decoupling Mechanism for Diabetic Retinopathy Image Grading,ACM International Conference Proceeding Series,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85122055170&doi=10.1145%2f3500931.3501002&partnerID=40&md5=8dcec4d5d84b55a44e17644964650ff4,"Automatic detection of diabetic retinopathy (DR) by fundus images can help a lot of patients to get diagnosis. However, many excellent deep learning models for image classification do not equally achieve good results on DR detection since fundus image classification is different from typical image classification problem. The lesions are usually small and reflected in the part rather than the whole image. In this paper, we investigate the effect of network depth and the relationship between different DR grades. Then we propose a novel attention network to group and classify DR. Our contributions are mainly in three aspects: 1. Find a suitable network depth for DR detection by experiments. 2.Propose a grouping and decoupling mechanism for DR grading. 3. Design a novel deep convolutional neural network to classify DR, which also generates attention map indicating the location of lesions. Experiments show that our network outperforms other methods on the Messidor dataset. We reach the AUC of 96.9% and the accuracy of 92.7% on binary classification and the accuracy of 81.7% on 4-class grading. © 2021 ACM.",Attention mechanism; Convolutional neural network; Diabetic retinopathy; Network depth
Conference Paper,"Hasan D.A., Zeebaree S.R.M., Sadeeq M.A.M., Shukur H.M., Zebari R.R., Alkhayyat A.H.",Machine Learning-based Diabetic Retinopathy Early Detection and Classification Systems - A Survey,"1st Babylon International Conference on Information Technology and Science 2021, BICITS 2021",2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85118453872&doi=10.1109%2fBICITS51482.2021.9509920&partnerID=40&md5=800c0cea51d8eeb810561bd6b84f8dae,"Diabetes Mellitus is a chronic disease that spreads quickly worldwide. It results from increasing the blood glucose level and causes complications in the heart, kidney, and eyes. Diabetic Retinopathy (DR) is an eye disease that refers to the bursting of blood vessels in the retina as Diabetes exacerbates. It is considered the main reason for blindness because it appears without showing any symptoms in the primitive stages. Earlier detection and classification of DR cases is a crucial step toward providing the necessary medical treatment. Recently, machine learning plays an efficient role in medical applications and computer-aided diagnosis due to the accelerated development in its algorithms. In this paper, we aim to study the performance of various machine learning algorithms-based DR detection and classification systems. These systems are trained and tested using massive amounts of retina fundus and thermal images from various publicly available datasets. These systems proved their success in tracking down the warning signs and identifying the DR severity level. The reviewed systems' results indicate that ResNet50 deep convolutional neural network was the most effective algorithm for performance metrics. The Resnet50 contains a set of feature extraction kernels that can analyze retina images to extract wealth information. We conclude that machine learning algorithms can support the physician in adopting appropriate diagnoses and treating DR cases. © 2021 IEEE",CAD; Classification; Clustering; Diabetic retinopathy; Machine learning; Regression
Conference Paper,"Santos C., Aguiar M., Welfer D., Belloni B.",A New Method Based on Deep Learning to Detect Lesions in Retinal Images using YOLOv5,"Proceedings - 2021 IEEE International Conference on Bioinformatics and Biomedicine, BIBM 2021",2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85125204099&doi=10.1109%2fBIBM52615.2021.9669581&partnerID=40&md5=a7aa3cf6b2f3110a3519d2405b3f4164,"Diabetic Retinopathy is one of the leading causes of vision loss and presents in its initial phase retinal lesions, such as microaneurysms, hemorrhages, and hard and soft exudates. Therefore, computational models capable of detecting these lesions can help in the early diagnosis of the disease and prevent the manifestation of more severe forms of lesions, helping define the best form of treatment. This work proposes a method based on deep neural network models that perform one-stage object detection, using state-of-the-art data augmentation and transfer learning techniques to present a model that aids in the medical diagnosis of fundus lesions. The model was trained, adjusted, and evaluated using the DDR Diabetic Retinopathy Dataset, and implemented based on the YOLOv5 architecture and the PyTorch framework, achieving values for mAP of 0.1040 and 0.0283 for IoU threshold of 0.5 and 0.5:0.95 respectively, in the validation set. The results obtained in the experiments demonstrate that the proposed method presented superior results to equivalent works found in the literature. © 2021 IEEE.",diabetic retinopathy; fundus image; lesion detection; you only look once
Article,"Mezni I., Ben Slama A., Mbarki Z., Seddik H., Trabelsi H.",Automated identification of SD-optical coherence tomography derived macular diseases by combining 3D-block-matching and deep learning techniques,Computer Methods in Biomechanics and Biomedical Engineering: Imaging and Visualization,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85107801216&doi=10.1080%2f21681163.2021.1926329&partnerID=40&md5=65f8ff2ecf6c25123a844d2d966deb1f,"This paper reveals an automatic approach for macular diagnostic by the use of Optical Coherence Tomography (OCT) in the evaluation process. At preliminary behaviour levels, the evaluation of macular zone in OCT scan is characterised by an error prone task, related to the experience and the attention of ophthalmologists. Thus, different techniques of OCT-image analysis help the option of obtaining a consistent and independent diagnosis to identify macular degeneration behaviour. In this work, we report an automated approach based on a combined filtering and classification strategy. The presented method is validated on a real integrated diabetic oedema macular (DME) and age related to macular degeneration (AMD). The experimental results illustrate the high accuracy of the results of the proposed method compared to the ground truth. Furthermore, a comparative study with existing techniques is presented in order to demonstrate the efficiency and the superiority of the proposed technique. © 2021 Informa UK Limited, trading as Taylor & Francis Group.",block-matching and 3D filtering (BM3D); OCT image filtering; Optical coherence tomography; recurrent neural networks and deep belief networks
Article,"Wang X., Xu M., Zhang J., Jiang L., Li L., He M., Wang N., Liu H., Wang Z.",Joint Learning of Multi-Level Tasks for Diabetic Retinopathy Grading on Low-Resolution Fundus Images,IEEE Journal of Biomedical and Health Informatics,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85117855823&doi=10.1109%2fJBHI.2021.3119519&partnerID=40&md5=cf55e455e8aff46bfcfced0887ca3610,"Diabetic retinopathy (DR) is a leading cause of permanent blindness among the working-age people. Automatic DR grading can help ophthalmologists make timely treatment for patients. However, the existing grading methods are usually trained with high resolution (HR) fundus images, such that the grading performance decreases a lot given low resolution (LR) images, which are common in clinic. In this paper, we mainly focus on DR grading with LR fundus images. According to our analysis on the DR task, we find that: 1) image super-resolution (ISR) can boost the performance of both DR grading and lesion segmentation; 2) the lesion segmentation regions of fundus images are highly consistent with pathological regions for DR grading. Based on our findings, we propose a convolutional neural network (CNN)-based method for joint learning of multi-level tasks for DR grading, called DeepMT-DR, which can simultaneously handle the low-level task of ISR, the mid-level task of lesion segmentation and the high-level task of disease severity classification on LR fundus images. Moreover, a novel task-aware loss is developed to encourage ISR to focus on the pathological regions for its subsequent tasks: lesion segmentation and DR grading. Extensive experimental results show that our DeepMT-DR method significantly outperforms other state-of-the-art methods for DR grading over three datasets. In addition, our method achieves comparable performance in two auxiliary tasks of ISR and lesion segmentation. © 2013 IEEE.",Deep neural networks; diabetic retinopathy; multi-task learning; retinal fundus images
Conference Paper,"Bygari R., Naik R., Uday Kumar P.",Blindness (Diabetic Retinopathy) Severity Scale Detection,"Proceedings - 2021 8th Swiss Conference on Data Science, SDS 2021",2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85112869014&doi=10.1109%2fSDS51136.2021.00009&partnerID=40&md5=70325a0e9446cbf84469f147ab406325,"Diabetic retinopathy (DR) is a severe complication of diabetes that can cause permanent blindness. Timely diagnosis and treatment of DR are critical to avoid total loss of vision. Manual diagnosis is time consuming and error-prone. In this paper, we propose a novel deep learning based method for automatic screening of retinal fundus images to detect and classify DR based on the severity. The method uses a dual-path configuration of deep neural networks to achieve the objective. In the first step, a modified UNet++ based retinal vessel segmentation is used to create a fundus image that emphasises elements like haemorrhages, cotton wool spots, and exudates that are vital to identify the DR stages. Subsequently, two convolutional neural networks (CNN) classifiers take the original image and the newly created fundus image respectively as inputs and identify the severity of DR on a scale of 0 to 4. These two scores are then passed through a shallow neural network classifier (ANN) to predict the final DR stage. The public datasets STARE, DRIVE, CHASE DB1, and APTOS are used for training and evaluation. Our method achieves an accuracy of 94.80% and Quadratic Weighted Kappa (QWK) score of 0.9254, and outperform many state-of-the-art methods. © 2021 IEEE.",convolutional neural network; deep learning; Diabetic retinopathy; fundus image
Article,"Wang S., Wang X., Hu Y., Shen Y., Yang Z., Gan M., Lei B.",Diabetic Retinopathy Diagnosis Using Multichannel Generative Adversarial Network with Semisupervision,IEEE Transactions on Automation Science and Engineering,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85083426796&doi=10.1109%2fTASE.2020.2981637&partnerID=40&md5=62db19bb0a74274386daecedb5b3f481,"Diabetic retinopathy (DR) is one of the major causes of blindness. It is of great significance to apply deep-learning techniques for DR recognition. However, deep-learning algorithms often depend on large amounts of labeled data, which is expensive and time-consuming to obtain in the medical imaging area. In addition, the DR features are inconspicuous and spread out over high-resolution fundus images. Therefore, it is a big challenge to learn the distribution of such DR features. This article proposes a multichannel-based generative adversarial network (MGAN) with semisupervision to grade DR. The multichannel generative model is developed to generate a series of subfundus images corresponding to the scattering DR features. By minimizing the dependence on labeled data, the proposed semisupervised MGAN can identify the inconspicuous lesion features by using high-resolution fundus images without compression. Experimental results on the public Messidor data set show that the proposed model can grade DR effectively. Note to Practitioners-This article is motivated by the challenging problem due to the inadequacy of labeled data in medical image analysis and the dispersion of efficient features in high-resolution medical images. As for the inadequacy of labeled data in medical image analysis, the reasons mainly include the followings: 1) the high-quality annotation of medical imaging sample depends heavily on scarce medical expertise which is very expensive and 2) comparing with natural issues, it is more difficult to collect medical images because of privacy issues. It is of great significance to apply deep-learning techniques for diabetic retinopathy (DR) recognition. In this article, the multichannel generative adversarial network (GAN) with semisupervision is developed for DR-Aided diagnosis. The proposed model can deal with DR classification problem with inadequacy of labeled data in the following ways: 1) the multichannel generative scheme is proposed to generate a series of subfundus images corresponding to the scattering DR features and 2) the proposed multichannel-based GAN (MGAN) model with semisupervision can make full use of both labeled data and unlabeled data. The experimental results demonstrate that the proposed model outperforms the other representative models in terms of accuracy, area under ROC curve (AUC), sensitivity, and specificity. © 2004-2012 IEEE.",Computer-Aided diagnosis (CAD); diabetic retinopathy (DR); generative adversarial network (GAN); multichannel; semisupervised learning
Conference Paper,"DelaPava M., Ríos H., Rodríguez F.J., Perdomo O.J., González F.A.",A deep learning model for classification of diabetic retinopathy in eye fundus images based on retinal lesion detection,Proceedings of SPIE - The International Society for Optical Engineering,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123046023&doi=10.1117%2f12.2606319&partnerID=40&md5=f7a1dfde723f0dd6fadd8fafcac0b109,"Diabetic retinopathy (DR) is the result of a complication of diabetes affecting the retina. It can cause blindness, if left undiagnosed and untreated. An ophthalmologist performs the diagnosis by screening each patient and analyzing the retinal lesions via ocular imaging. In practice, such analysis is time-consuming and cumbersome to perform. This paper presents a model for automatic DR classification on eye fundus images. The approach identifies the main ocular lesions related to DR and subsequently diagnoses the illness. The proposed method follows the same workflow as the clinicians, providing information that can be interpreted clinically to support the prediction. A subset of the kaggle EyePACS and the Messidor-2 datasets, labeled with ocular lesions, is made publicly available. The kaggle EyePACS subset is used as training set and the Messidor-2 as a test set for lesions and DR classification models. For DR diagnosis, our model has an area-under-the-curve, sensitivity, and specificity of 0:948, 0:886, and 0:875, respectively, which competes with state-of-the-art approaches. © 2021 SPIE.",Diabetic retinopathy; Machine learning; Ocular screening; Retinal lesions
Article,"Pappu G.P., Krishna T., Biswal B., Karn P.K., Biswal P.K., Hasan S., Nayak D.",A deeply supervised maximum response texton based SegNet for simultaneous multi retinal lesion segmentation,International Journal of Imaging Systems and Technology,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85125879134&doi=10.1002%2fima.22723&partnerID=40&md5=a1d895ccb4283979383c58a5fe0c512f,"Diabetic Retinopathy (DR) is a diabetic mellitus complication that causes vision impairment and may lead to permanent blindness. The early signs of DR that appear on the retinal surface are microaneurysms, hemorrhages, hard exudates, and soft exudates. Hence the automatic detection of these retinal lesions assists in the early diagnosis of DR. This paper presents a novel deep learning model, MRT-SegNet (Maximum Response Texton – Segmentation Network) for the automatic segmentation of different retinal lesions simultaneously along with the optic disc. In the proposed MRT-SegNet, each encoder block consists of an MRT filter bank that extracts the textural feature maps of the retinal images and then fuses them with the local feature maps that are extracted from the traditional encoder block of the network. This fusion enables the network to segment the minute lesions from the retinal surface. The proposed model is evaluated on the IDRiD dataset and achieves a mean Area Under the Precision & Recall Curve (mAUC_PR) of 0.698 and AUC_PR scores of 0.495, 0.706, 0.823, 0.769 for microaneurysms, hemorrhages, hard exudates, and soft exudates respectively. The experimental results demonstrate that the MRT-SegNet outperformed other multi retinal lesion segmentation models by achieving superior performance. © 2022 Wiley Periodicals LLC.",diabetic retinopathy; IDRiD dataset; maximum response texton filter bank; multi retinal lesion segmentation
Article,"Prahs P., Radeck V., Mayer C., Cvetkov Y., Cvetkova N., Helbig H., Märker D.",OCT-based deep learning algorithm for the evaluation of treatment indication with anti-vascular endothelial growth factor medications,Graefe's Archive for Clinical and Experimental Ophthalmology,2018,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85033462485&doi=10.1007%2fs00417-017-3839-y&partnerID=40&md5=0bf4b01907faaa7e70f33def8c6118c9,"Purpose: Intravitreal injections with anti-vascular endothelial growth factor (anti-VEGF) medications have become the standard of care for their respective indications. Optical coherence tomography (OCT) scans of the central retina provide detailed anatomical data and are widely used by clinicians in the decision-making process of anti-VEGF indication. In recent years, significant progress has been made in artificial intelligence and computer vision research. We trained a deep convolutional artificial neural network to predict treatment indication based on central retinal OCT scans without human intervention. Method: A total of 183,402 retinal OCT B-scans acquired between 2008 and 2016 were exported from the institutional image archive of a university hospital. OCT images were cross-referenced with the electronic institutional intravitreal injection records. OCT images with a following intravitreal injection during the first 21 days after image acquisition were assigned into the ‘injection’ group, while the same amount of random OCT images without intravitreal injections was labeled as ‘no injection’. After image preprocessing, OCT images were split in a 9:1 ratio to training and test datasets. We trained a GoogLeNet inception deep convolutional neural network and assessed its performance on the validation dataset. We calculated prediction accuracy, sensitivity, specificity, and receiver operating characteristics. Results: The deep convolutional neural network was successfully trained on the extracted clinical data. The trained neural network classifier reached a prediction accuracy of 95.5% on the images in the validation dataset. For single retinal B-scans in the validation dataset, a sensitivity of 90.1% and a specificity of 96.2% were achieved. The area under the receiver operating characteristic curve was 0.968 on a per B-scan image basis, and 0.988 by averaging over six B-scans per examination on the validation dataset. Conclusion: Deep artificial neural networks show impressive performance on classification of retinal OCT scans. After training on historical clinical data, machine learning methods can offer the clinician support in the decision-making process. Care should be taken not to mistake neural network output as treatment recommendation and to ensure a final thorough evaluation by the treating physician. © 2017, Springer-Verlag GmbH Germany.",Age-related macular degeneration; Artificial intelligence; Computer vision; Computer-aided diagnosis; Deep learning; Diabetic retinopathy; Optical coherence tomography
Article,"Cao P., Hou Q., Song R., Wang H., Zaiane O.",Collaborative learning of weakly-supervised domain adaptation for diabetic retinopathy grading on retinal images,Computers in Biology and Medicine,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85126120654&doi=10.1016%2fj.compbiomed.2022.105341&partnerID=40&md5=fdf3d6254ca3b261c75feab231f3f260,"Early detection and treatment of diabetic retinopathy (DR) can significantly reduce the risk of vision loss in patients. In essence, we are faced with two challenges: (i) how to simultaneously achieve domain adaptation from the different domains and (ii) how to build an interpretable multi-instance learning (MIL) on the target domain in an end-to-end framework. In this paper, we address these issues and propose a unified weakly-supervised domain adaptation framework, which consists of three components: domain adaptation, instance progressive discriminator and multi-instance learning with attention. The method models the relationship between the patches and images in the target domain with a multi-instance learning scheme and an attention mechanism. Meanwhile, it incorporates all available information from both source and target domains for a jointly learning strategy. We validate the performance of the proposed framework for DR grading on the Messidor dataset and the large-scale Eyepacs dataset. The experimental results demonstrate that it achieves an average accuracy of 0.949 (95% CI 0.931–0.958)/0.764 (95% CI 0.755–0.772) and an average AUC value of 0.958 (95% CI 0.945–0.962)/0.749 (95% CI 0.732–0.761) for binary-class/multi-class classification tasks on the Messidor dataset. Moreover, the proposed method achieves an accuracy of 0.887 and a quadratic weighted kappa score value of 0.860 on the Eyepacs dataset, outperforming the state-of-the-art approaches. Comprehensive experiments confirm the effectiveness of the approach in terms of both grading performance and interpretability. The source code is available at https://github.com/HouQingshan/WAD-Net. © 2022 Elsevier Ltd",Computer-aided diagnosis; Diabetic retinopathy; Domain adaption; Interpretability; Multi-instance learning
Conference Paper,"Wu L., Wan C., Wu Y., Liu J.",Generative caption for diabetic retinopathy images,"2017 International Conference on Security, Pattern Analysis, and Cybernetics, SPAC 2017",2018,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050596508&doi=10.1109%2fSPAC.2017.8304332&partnerID=40&md5=f51bd636c7ec54503477e1937ec4d12a,"For a long time, the detection of diabetic retinopathy has always been a great challenge. People want to find a fast and effective computer-aided treatment to diagnose the disease. In recent years, the rapid development of the deep learning makes it gradually become an effective technique for the analysis of medical images. In this paper, we propose a method to deal with diabetic retinopathy images with generative caption technique of images to generate a simple sequence to explain the abnormal contents in fundus images. The generative technique of images is a generative model based on a deep recurrent architecture that combines convolution neural network (CNN) which is currently state-of-the-art for object recognition and detection with long-short-term-memory (LSTM) which is applied with great success to machine translation and sequence generation, and that can be used to generate natural sentences describing an image. The target of the model in training is to maximize the likelihood of the target description sentence given from the training images. The model built on dataset DIARETDB0, DIARETDB1 and Messidor can achieve good performance and generate fluent sequences. In addition, the experimental results show that the accuracy of diagnosis for individual abnormal discoveries is up to 88.53% and the diagnosis accuracy is more than 90%. © 2017 IEEE.",Deep Learning; Diabetic Retinopathy; Image Caption; Retinopathy Lesions
Article,"Liu R., Li Q., Xu F., Wang S., He J., Cao Y., Shi F., Chen X., Chen J.",Application of artificial intelligence-based dual-modality analysis combining fundus photography and optical coherence tomography in diabetic retinopathy screening in a community hospital,BioMedical Engineering Online,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85134510913&doi=10.1186%2fs12938-022-01018-2&partnerID=40&md5=50431272a8ccbc659ea814f276765d1f,"Background: To assess the feasibility and clinical utility of artificial intelligence (AI)-based screening for diabetic retinopathy (DR) and macular edema (ME) by combining fundus photos and optical coherence tomography (OCT) images in a community hospital. Methods: Fundus photos and OCT images were taken for 600 diabetic patients in a community hospital. Ophthalmologists graded these fundus photos according to the International Clinical Diabetic Retinopathy (ICDR) Severity Scale as the ground truth. Two existing trained AI models were used to automatically classify the fundus images into DR grades according to ICDR, and to detect concomitant ME from OCT images, respectively. The criteria for referral were DR grades 2–4 and/or the presence of ME. The sensitivity and specificity of AI grading were evaluated. The number of referable DR cases confirmed by ophthalmologists and AI was calculated, respectively. Results: DR was detected in 81 (13.5%) participants by ophthalmologists and in 94 (15.6%) by AI, and 45 (7.5%) and 53 (8.8%) participants were diagnosed with referable DR by ophthalmologists and by AI, respectively. The sensitivity, specificity and area under the curve (AUC) of AI for detecting DR were 91.67%, 96.92% and 0.944, respectively. For detecting referable DR, the sensitivity, specificity and AUC of AI were 97.78%, 98.38% and 0.981, respectively. ME was detected from OCT images in 49 (8.2%) participants by ophthalmologists and in 57 (9.5%) by AI, and the sensitivity, specificity and AUC of AI were 91.30%, 97.46% and 0.944, respectively. When combining fundus photos and OCT images, the number of referrals identified by ophthalmologists increased from 45 to 75 and from 53 to 85 by AI. Conclusion: AI-based DR screening has high sensitivity and specificity and may feasibly improve the referral rate of community DR. © 2022, The Author(s).",Artificial intelligence; Deep learning; Diabetic retinopathy; Optical coherence tomography
Article,"Li Y., Zhu M., Sun G., Chen J., Zhu X., Yang J.",Weakly supervised training for eye fundus lesion segmentation in patients with diabetic retinopathy,Mathematical Biosciences and Engineering,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85127931645&doi=10.3934%2fmbe.2022248&partnerID=40&md5=6166b90abb2631fe383e61a45ee51365,"Objective: Diabetic retinopathy is the leading cause of vision loss in working-age adults. Early screening and diagnosis can help to facilitate subsequent treatment and prevent vision loss. Deep learning has been applied in various fields of medical identification. However, current deep learningbased lesion segmentation techniques rely on a large amount of pixel-level labeled ground truth data, which limits their performance and application. In this work, we present a weakly supervised deep learning framework for eye fundus lesion segmentation in patients with diabetic retinopathy. Methods: First, an efficient segmentation algorithm based on grayscale and morphological features is proposed for rapid coarse segmentation of lesions. Then, a deep learning model named Residual-Attention Unet (RAUNet) is proposed for eye fundus lesion segmentation. Finally, a data sample of fundus images with labeled lesions and unlabeled images with coarse segmentation results is jointly used to train RAUNet to broaden the diversity of lesion samples and increase the robustness of the segmentation model. Results: A dataset containing 582 fundus images with labels verified by doctors, including hemorrhage (HE), microaneurysm (MA), hard exudate (EX) and soft exudate (SE), and 903 images without labels was used to evaluate the model. In ablation test, the proposed RAUNet achieved the highest intersection over union (IOU) on the labeled dataset, and the proposed attention and residual modules both improved the IOU of the UNet benchmark. Using both the images labeled by doctors and the proposed coarse segmentation method, the weakly supervised framework based on RAUNet architecture significantly improved the mean segmentation accuracy by over 7% on the lesions. Significance: This study demonstrates that combining unlabeled medical images with coarse segmentation results can effectively improve the robustness of the lesion segmentation model and proposes a practical framework for improving the performance of medical image segmentation given limited labeled data samples. © 2022 the Author(s).",deep learning; diabetic retinopathy; fundus image; lesion segmentation; weak supervision
Article,"Huang S., Li J., Xiao Y., Shen N., Xu T.",RTNet: Relation Transformer Network for Diabetic Retinopathy Multi-Lesion Segmentation,IEEE Transactions on Medical Imaging,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123348337&doi=10.1109%2fTMI.2022.3143833&partnerID=40&md5=42dbb8c9e9376a577a026cfa5e2a5095,"Automatic diabetic retinopathy (DR) lesions segmentation makes great sense of assisting ophthalmologists in diagnosis. Although many researches have been conducted on this task, most prior works paid too much attention to the designs of networks instead of considering the pathological association for lesions. Through investigating the pathogenic causes of DR lesions in advance, we found that certain lesions are closed to specific vessels and present relative patterns to each other. Motivated by the observation, we propose a relation transformer block (RTB) to incorporate attention mechanisms at two main levels: A self-Attention transformer exploits global dependencies among lesion features, while a cross-Attention transformer allows interactions between lesion and vessel features by integrating valuable vascular information to alleviate ambiguity in lesion detection caused by complex fundus structures. In addition, to capture the small lesion patterns first, we propose a global transformer block (GTB) which preserves detailed information in deep network. By integrating the above blocks of dual-branches, our network segments the four kinds of lesions simultaneously. Comprehensive experiments on IDRiD and DDR datasets well demonstrate the superiority of our approach, which achieves competitive performance compared to state-of-The-Arts. © 1982-2012 IEEE.",deep learning; Diabetic retinopathy; fundus image; semantic segmentation; transformer
Conference Paper,"Rahimzadeh M., Mohammadi M.R.",ROCT-Net: A new ensemble deep convolutional model with improved spatial resolution learning for detecting common diseases from retinal OCT images,ICCKE 2021 - 11th International Conference on Computer Engineering and Knowledge,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85127490645&doi=10.1109%2fICCKE54056.2021.9721471&partnerID=40&md5=0b239f90056834ab469656c899b5fdd1,"Optical coherence tomography (OCT) imaging is a well-known technology for visualizing retinal layers and helps ophthalmologists to detect possible diseases. Accurate and early diagnosis of common retinal diseases can prevent the patients from suffering critical damages to their vision. Computer-aided diagnosis (CAD) systems can significantly assist ophthalmologists in improving their examinations. This paper presents a new enhanced deep ensemble convolutional neural network for detecting retinal diseases from OCT images. Our model generates rich and multi-resolution features by employing the learning architectures of two robust convolutional models. Spatial resolution is a critical factor in medical images, especially the OCT images that contain tiny essential points. To empower our model, we apply a new post-architecture model to our ensemble model for enhancing spatial resolution learning without increasing computational costs. The introduced post-architecture model can be deployed to any feature extraction model to improve the utilization of the feature map's spatial values. We have collected two open-source datasets for our experiments to make our models capable of detecting six crucial retinal diseases: Age-related Macular Degeneration (AMD), Central Serous Retinopathy (CSR), Diabetic Retinopathy (DR), Choroidal Neovascularization (CNV), Diabetic Macular Edema (DME), and Drusen alongside the normal cases. Our experiments on two datasets and comparing our model with some other well-known deep convolutional neural networks have proven that our architecture can increase the classification accuracy up to 5%. We hope that our proposed methods create the next step of CAD systems development and help future researches. © 2021 IEEE.",CAD System; Capsule Network; Convolutional Neural Network; Ensemble Learning; OCT Image Classification; Optical Coherence Tomography; Retinal Disease; Spatial Resolution Learning
Conference Paper,"Sadhukhan S., Ghorai G.K., Maiti S., Sarkar G., Dhara A.K.",Optic Disc Localization in Retinal Fundus Images using Faster R-CNN,"Proceedings of 5th International Conference on Emerging Applications of Information Technology, EAIT 2018",2018,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85055512452&doi=10.1109%2fEAIT.2018.8470435&partnerID=40&md5=ab11870af8fc11f63f5a0360dcdd13ce,"Now a days lot of people are suffering from Diabetic Retinopathy throughout the world. This is one kind of eye disease which affects people having diabetes for long time. If this is undiagnosed and not treated for long time, it can lead to blindness. Several studies have shown that an early detection and timely treatment is the only way to reduce the sufferings from diabetic retinopathy. The development of an automated screening system is the right approach for screening of diabetic retinopathy. Automated detection of several anatomical regions such as optic disc, retinal vasculature and macula is important to design a tool for the screening purpose. In our work we have presented a novel and fast optic disc detection method using Faster R-CNN. The proposed method is validated on 1200 fundus images from the MESSIDOR database which is widely accepted publicly available dataset for research purpose. We propose a supervised detection technique that uses a deep learning network trained on 6, 992 retinal fundus images augmented using geometrical transformations from MESSIDOR-II database. The proposed method shows satisfactory robustness on both normal and images affected by diabetic retinopathy. It outperforms many previous methods in terms of speed with satisfactory accuracy of optic disc localization. © 2018 IEEE.",Computer aided diagnosis of diabetic retinopathy; Convolution neural network; Faster R-CNN; MESSIDOR database.; Regression; Softmax classifier
Conference Paper,"Kanakatte A., Gubbi J., Ghose A., Purushothaman B.",A Decision Support System for Retinal Image Defect Detection,"ISBI Workshops 2020 - International Symposium on Biomedical Imaging Workshops, Proceedings",2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090403546&doi=10.1109%2fISBIWorkshops50223.2020.9153446&partnerID=40&md5=b4f46b5e0d773861bde945c8863bffe0,"Deep learning has become the de facto method for image classification. In this work, a common framework for decision support system is presented that can be reused for diagnosing multiple retinal clinical conditions. Retinal fundus images provide a non-invasive way to diagnose eye-related diseases like glaucoma and diabetic retinopathy (DR). State-of-the-art deep learning methods focus on the detection of key regions of the retina including fundus, optic disc and retinal vessels individually. In order to achieve acceptable precision and recall for a clinically deployable system, a decision support system that combines state-of-the-art deep learning system and relevant explainable features are built. The proposed method is tested on two retinal pathology use cases - glaucoma and for the detection of hard exudates that is critical in diagnosing DR. The proposed model is validated using DRIVE dataset with average Jaccard index of more than 96% for fundus, around 98% for OD and around 90% in identifying retinal vessels using a five-fold cross-validation. For disease detection, the above key regions are combined and validated using standard datasets with good outcomes. © 2020 IEEE.",Decision Support System; Diabetic Retinopathy; Glaucoma; Retinal imaging
Article,"Hacisoftaoglu R.E., Karakaya M., Sallam A.B.",Deep learning frameworks for diabetic retinopathy detection with smartphone-based retinal imaging systems,Pattern Recognition Letters,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85085268695&doi=10.1016%2fj.patrec.2020.04.009&partnerID=40&md5=d3f633239829c0ec429e34703d3ddc5c,"Diabetic Retinopathy (DR) may result in various degrees of vision loss and even blindness if not diagnosed in a timely manner. Therefore, having an annual eye exam helps early detection to prevent vision loss in earlier stages, especially for diabetic patients. Recent technological advances made smartphone-based retinal imaging systems available on the market to perform small-sized, low-powered, and affordable DR screening in diverse environments. However, the accuracy of DR detection depends on the field of view and image quality. Since smartphone-based retinal imaging systems have much more compact designs than a traditional fundus camera, captured images are likely to be the low quality with a smaller field of view. Our motivation in this paper is to develop an automatic DR detection model for smartphone-based retinal images using the deep learning approach with the ResNet50 network. This study first utilized the well-known AlexNet, GoogLeNet, and ResNet50 architectures, using the transfer learning approach. Second, these frameworks were retrained with retina images from several datasets including EyePACS, Messidor, IDRiD, and Messidor-2 to investigate the effect of using images from the single, cross, and multiple datasets. Third, the proposed ResNet50 model is applied to smartphone-based synthetic images to explore the DR detection accuracy of smartphone-based retinal imaging systems. Based on the vision-threatening diabetic retinopathy detection results, the proposed approach achieved a high classification accuracy of 98.6%, with a 98.2% sensitivity and a 99.1% specificity while its AUC was 0.9978 on the independent test dataset. As the main contributions, DR detection accuracy was improved using the transfer learning approach for the ResNet50 network with publicly available datasets and the effect of the field of view in smartphone-based retinal imaging was studied. Although a smaller number of images were used in the training set compared with the existing studies, considerably acceptable high accuracies for validation and testing data were obtained. © 2020 Elsevier B.V.",AlexNet; Deep learning; Diabetic retinopathy; GoogLeNet; ResNet50; Smartphone-based retinal imaging
Article,"Li X., Jiang Y., Zhang J., Li M., Luo H., Yin S.",Lesion-attention pyramid network for diabetic retinopathy grading,Artificial Intelligence in Medicine,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85125463429&doi=10.1016%2fj.artmed.2022.102259&partnerID=40&md5=64cc496222bdba46ef5d8504416fe3b3,"As one of the most common diabetic complications, diabetic retinopathy (DR) can cause retinal damage, vision loss and even blindness. Automated DR grading technology has important clinical significance, which can help ophthalmologists achieve rapid and early diagnosis. With the popularity of deep learning, DR grading based on the convolutional neural networks (CNNs) has become the mainstream method. Unfortunately, although the CNN-based method can achieve satisfactory diagnostic accuracy, it lacks significant clinical information. In this paper, a lesion-attention pyramid network (LAPN) is presented. The pyramid network integrates the subnetworks with different resolutions to get multi-scale features. In order to take the lesion regions in the high-resolution image as the diagnostic evidence, the low-resolution network calculates the lesion activation map (using the weakly-supervised localization method) and guides the high-resolution network to concentrate on the lesion regions. Furthermore, a lesion attention module (LAM) is designed to capture the complementary relationship between the high-resolution features and the low-resolution features, and to fuse the lesion activation map. Experiment results show that the proposed scheme outperforms other existing approaches, and the proposed method can provide lesion activation map with lesion consistency as an additional evidence for clinical diagnosis. © 2022",Attention mechanism; Convolutional neural network; Diabetic retinopathy; Pyramid network
Conference Paper,"Bulut B., Kalin V., Gunes B.B., Khazhin R.",Deep Learning Approach for Detection of Retinal Abnormalities Based on Color Fundus Images,"Proceedings - 2020 Innovations in Intelligent Systems and Applications Conference, ASYU 2020",2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097951607&doi=10.1109%2fASYU50717.2020.9259870&partnerID=40&md5=8338ac3a5020b4f448a08d09096b93bd,"In cases where people cannot access regular controls, treatment and care, delaying the diagnosis and treatment of eye diseases such as glaucoma, cataracts, diabetic retinopathy or leaving them to deteriorate unconsciously, may make daily life difficult and even cause blindness. Therefore, automatic examination of fundus photographs is important in terms of providing early diagnosis with fast, objective and consistent image evaluation and helping the application of large-scale scanning programs. This research uses Xception model with transfer learning method to classify images obtained from Akdeniz University Hospital Eye Diseases Department. During the analysis, the Xception model containing 50 different parameter combinations was trained by scanning the appropriate hyper-parameter space for the model. Comparisons were made for the top 9 models with the highest performance. The 4th model reached the highest accuracy rate with 91.39% for the training set, and as for the validation set, the 0th model showed 82.5% of accuracy. In addition, in order to test the performance of the model with an independent data set, open access fundus images were used for test analysis and binary classification AUC (Area Under Curve) values were calculated for 21 different diseases. © 2020 IEEE.",artificial intelligence; computer vision; convolutional neural network; decision support system; deep learning; eye disease; fundus images; hyper-parameter optimization; image classification; transfer learning; Xception
Article,"Somasundaram K., Sivakumar P., Suresh D.",Classification of Diabetic Retinopathy Diseas with Transfer Learning using Deep Convolutional Neural Networks,Advances in Electrical and Computer Engineering,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85114777184&doi=10.4316%2fAECE.2021.03006&partnerID=40&md5=1410e5297d137c50d18846eaa8edf0ff,"Diabetic Retinopathy (DR) stays a main source of vision deterioration around world and it is getting exacerbated day by day. Almost no warning signs for detecting DR which will be greater challenge with us today. So, it is extremely preferred that DR has to be discovered on time. Adversely, the existing result involves an ophthalmologist to manually check and identify DR by positioning the exudates related with vascular irregularity due to diabetes from fundus image. In this work, we are able to classify images based on different severity levels through an automatic DR classification system. To extract specific features of image without any loss in spatial information, a Convolutional Neural Network (CNN) models which possesses an image with a distinct weight matrix is used. In the beginning, we estimate various CNN models to conclude the best performing CNN for DR classification with an objective to obtain much better accuracy. In the classification of DR disease with transfer learning using deep CNN models, 97.72% of accuracy is provided by the proposed CNN model for Kaggle dataset. The proposed CNN model provides a classification accuracy of 97.58% for MESSIDOR dataset. The proposed technique provides better results than other state-of-art methods. © 2021. All Rights Reserved.",computer aided diagnosis; image classification; learning; neural networks; retinopathy
Conference Paper,"Gwetu M.V., Tapamo J.-R., Viriri S.",Retinal Image Segmentation Through Valley Emphasis Thresholding of the Gabor Filter Response,Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097549882&doi=10.1007%2f978-3-030-63007-2_40&partnerID=40&md5=5dc8445592b1aca8bb10d26c241bee53,"The quest for automated diagnosis of diabetic retinopathy continues due to increasing prevalence coupled with scarcity of skilled medical experts, especially in the third world. Due to the significant role that retinal image analysis plays in such diagnosis, there is a need for effective segmentation methods that accurately isolate the various retinal components, whose attributes have diagnostic relevance. Previous work has mainly focused on improving accuracy rates without much regard for algorithm efficiency. This study explores the use of Gabor features and Valley Emphasis (VE) thresholding for efficient and effective retinal image segmentation. Pre-processing is optimized through the squared magnitude Gabor response, prior to enrolling a selective VE thresholding approach. Experiments on the DRIVE and STARE datasets demonstrate significant reduction in computational overhead coupled with a minor improvement in segmentation accuracy. © 2020, Springer Nature Switzerland AG.",Gabor filter; Retinal image segmentation; Selective; Squared magnitude; Valley emphasis thresholding
Article,"Chetoui M., Akhloufi M.A.",Explainable end-to-end deep learning for diabetic retinopathy detection across multiple datasets,Journal of Medical Imaging,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85091486578&doi=10.1117%2f1.JMI.7.4.044503&partnerID=40&md5=f52cca21611a435817fed6ce33831fc4,"Purpose: Diabetic retinopathy (DR) is characterized by retinal lesions affecting people having diabetes for several years. It is one of the leading causes of visual impairment worldwide. To diagnose this disease, ophthalmologists need to manually analyze retinal fundus images. Computer-aided diagnosis systems can help alleviate this burden by automatically detecting DR on retinal images, thus saving physicians' precious time and reducing costs. The objective of this study is to develop a deep learning algorithm capable of detecting DR on retinal fundus images. Nine public datasets and more than 90,000 images are used to assess the efficiency of the proposed technique. In addition, an explainability algorithm is developed to visually show the DR signs detected by the deep model. Approach: The proposed deep learning algorithm fine-tunes a pretrained deep convolutional neural network for DR detection. The model is trained on a subset of EyePACS dataset using a cosine annealing strategy for decaying the learning rate with warm up, thus improving the training accuracy. Tests are conducted on the nine datasets. An explainability algorithm based on gradient-weighted class activation mapping is developed to visually show the signs selected by the model to classify the retina images as DR. Result: The proposed network leads to higher classification rates with an area under curve (AUC) of 0.986, sensitivity = 0.958, and specificity = 0.971 for EyePACS. For MESSIDOR, MESSIDOR-2, DIARETDB0, DIARETDB1, STARE, IDRID, E-ophtha, and UoA-DR, the AUC is 0.963, 0.979, 0.986, 0.988, 0.964, 0.957, 0.984, and 0.990, respectively. Conclusions: The obtained results achieve state-of-the-art performance and outperform past published works relying on training using only publicly available datasets. The proposed approach can robustly classify fundus images and detect DR. An explainability model was developed and showed that our model was able to efficiently identify different signs of DR and detect this health issue. © 2020 Society of Photo-Optical Instrumentation Engineers (SPIE).",convolutional neural networks; diabetic retinopathy; exudates and hemorrhage; inception; microaneurysms; residual networks
Article,"Du J., Zou B., Ouyang P., Zhao R.",Retinal microaneurysm detection based on transformation splicing and multi-context ensemble learning,Biomedical Signal Processing and Control,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123844477&doi=10.1016%2fj.bspc.2022.103536&partnerID=40&md5=c818e98d3ead5a4930135b091068849a,"Retinal microaneurysm (MA) detection is essential for diagnosis of diabetic retinopathy (DR) by providing the earliest clinical sign of DR. However, automatically detecting MA has always been a challenge due to the extremely small proportion of MA, the susceptibility to interference from blood vessels, and the obvious contrast difference between MAs. This paper proposed a novel deep learning method to achieve accurate MA detection based on transformation splicing (TS) and multi-context ensemble learning. TS rebalances the proportion of MA and reduces interference from blood vessels by transforming the pixel distribution of each candidate image and reinforcing the features of difficult samples, which enables the subsequent model to better learn the enhanced image features. At the same time, a multi-context ensemble learning combining dual deep learning models and attention mechanism is designed to adaptively learn different spliced image contexts, which improves detection performance for weak MAs. The final scores of the proposed method in e-ophatha-MA, DiaretDB1 and ROC three public datasets are 0.518, 0.429 and 0.306 respectively, which demonstrates the state-of-the-art performance for MA detection. © 2022 Elsevier Ltd",Data Enhancement; Image Splicing; Local Cross-section Transformation; Microaneurysm Detection; Multi-context ensemble learning
Conference Paper,"Hassan R., Rahman M.A., Ullah I., Hamdan Alenezi A., Rassem T.H.",Identifying the Level of Diabetic Retinopathy Using Deep Convolution Neural Network,"ETCCE 2020 - International Conference on Emerging Technology in Computing, Communication and Electronics",2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102021984&doi=10.1109%2fETCCE51779.2020.9350905&partnerID=40&md5=9865b41b5564627cd81fe650b0b1be0c,"Diabetic Retinopathy is the leading cause of blindness in the last 100 years. The traditional screening process for DR and its stages takes a lot of time, and it is not practical. Using machine learning techniques and image processing, we can automate detecting diabetic retinal disease and disease stage with acceptable performance. In this work, we have used multiple deep convolution neural networks (CNN) with the same architecture of InceptionV3. Each of the pre-trained Inception V3 architecture is retrained with 2200 preprocessed and leveled images. The dataset is preprocessed using multiple high performing and effective image processing techniques. Then the newly trained models are used for identifying the level of DR. In the final stage, we use a voting scheme for classifying the level of DR from the output of each model. We have achieved 90.5% accuracy in binary classification (Normal/DR) and 81.1% accuracy in 5-class classification. © 2020 IEEE.",Contrast Limited Adaptive Histogram Equalization (CLAHE); Convolution Neural Network (CNN); Diabetic Retinopathy; InceptionV3
Article,"Kou C., Li W., Liang W., Yu Z., Hao J.",Microaneurysms segmentation with a U-Net based on recurrent residual convolutional neural network,Journal of Medical Imaging,2019,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85069511587&doi=10.1117%2f1.JMI.6.2.025008&partnerID=40&md5=c137b65c7ce9d47087e14799b7d636c1,"Microaneurysms (MAs) play an important role in the diagnosis of clinical diabetic retinopathy at the early stage. Annotation of MAs manually by experts is laborious and so it is essential to develop automatic segmentation methods. Automatic MA segmentation remains a challenging task mainly due to the low local contrast of the image and the small size of MAs. A deep learning-based method called U-Net has become one of the most popular methods for the medical image segmentation task. We propose an architecture for U-Net, named deep recurrent U-Net (DRU-Net), obtained by combining the deep residual model and recurrent convolutional operations into U-Net. In the MA segmentation task, DRU-Net can accumulate effective features much better than the typical U-Net. The proposed method is evaluated on two publicly available datasets: E-Ophtha and IDRiD. Our results show that the proposed DRU-Net achieves the best performance with 0.9999 accuracy value and 0.9943 area under curve (AUC) value on the E-Ophtha dataset. And on the IDRiD dataset, it has achieved 0.987 AUC value (to our knowledge, this is the first result of segmenting MAs on this dataset). Compared with other methods, such as U-Net, FCNN, and ResU-Net, our architecture (DRU-Net) achieves state-of-the-art performance. © 2019 Society of Photo-Optical Instrumentation Engineers (SPIE).",deep recurrent U-Net; microaneurysms; segmentation; U-Net
Article,"Liu Z., Wang C., Cai X., Jiang H., Wang J.",Discrimination of Diabetic Retinopathy from Optical Coherence Tomography Angiography Images Using Machine Learning Methods,IEEE Access,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85100793792&doi=10.1109%2fACCESS.2021.3056430&partnerID=40&md5=72c3b61fdbcc0ec4e968b5f48e03d4fd,"The goal was to discriminate between diabetic retinopathy (DR) and healthy controls (HC) by evaluating Optical coherence tomography angiography (OCTA) images from $3\times 3$ mm scans with the assistance of different machine learning models. The OCTA angiography dataset of superficial vascular plexus (SVP), deep vascular plexus (DVP), and retinal vascular network (RVN) were acquired from 19 DR (38 eyes) patients and 25 HC (44 eyes). A discrete wavelet transform was applied to extract texture features from each image. Four machine learning models, including logistic regression (LR), logistic regression regularized with the elastic net penalty (LR-EN), support vector machine (SVM), and the gradient boosting tree named XGBoost, were used to classify wavelet features between groups. The area under the receiver operating characteristics curve (AUC), sensitivity, specificity, and diagnostic accuracy of the classifiers were obtained. The OCTA image dataset included 114 and 132 images from DR and HC subjects, respectively. LR-EN and LR using all three images, SVP, DVP, and RVN, provided the highest sensitivity of 0.84 and specificity of 0.80, the best diagnostic accuracy of 0.82, and an AUC of 0.83 and 0.84, respectively, which were slightly lower than that of LR using one image SVP (0.85) or two images DVP and SVP (0.85). The LR-EN and LR classification algorithms had the high sensitivity, specificity, and diagnostic accuracy in identifying DR, which may be promising in facilitating the early diagnosis of DR. © 2013 IEEE.",Diabetic retinopathy; logistic regression; logistic regression regularized with the elastic net penalty; machine learning; support vector machine
Article,"Maji D., Sekh A.A.",Automatic Grading of Retinal Blood Vessel in Deep Retinal Image Diagnosis,Journal of Medical Systems,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090029973&doi=10.1007%2fs10916-020-01635-1&partnerID=40&md5=cf482dbc905f6ff21cb9f50ab7809b9e,"Automatic grading of retinal blood vessels from fundus image can be a useful tool for diagnosis, planning and treatment of eye. Automatic diagnosis of retinal images for early detection of glaucoma, stroke, and blindness is emerging in intelligent health care system. The method primarily depends on various abnormal signs, such as area of hard exudates, area of blood vessels, bifurcation points, texture, and entropies. The development of an automated screening system based on vessel width, tortuosity, and vessel branching are also used for grading. However, the automated method that directly can come to a decision by taking the fundus images got less attention. Detecting eye problems based on the tortuosity of the vessel from fundus images is a complicated task for opthalmologists. So automated grading algorithm using deep learning can be most valuable for grading retinal health. The aim of this work is to develop an automatic computer aided diagnosis system to solve the problem. This work approaches to achieve an automatic grading method that is opted using Convolutional Neural Network (CNN) model. In this work we have studied the state-of-the-art machine learning algorithms and proposed an attention network which can grade retinal images. The proposed method is validated on a public dataset EIARG1, which is only publicly available dataset for such task as per our knowledge. © 2020, The Author(s).",Diabetic retinopathy (DR); Retinopathy of prematurity (ROP); Tortuosity-based grading
Article,"Arsalan M., Haider A., Won Lee Y., Ryoung Park K.",Detecting retinal vasculature as a key biomarker for deep Learning-based intelligent screening and analysis of diabetic and hypertensive retinopathy,Expert Systems with Applications,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85127574304&doi=10.1016%2fj.eswa.2022.117009&partnerID=40&md5=5a00c79c4ca4f7dcea1d343c6132bd10,"Retinal vessels are considered important biomarkers for the detection of retinal diseases, like diabetic retinopathy (caused by diabetes) and hypertensive retinopathy (caused by hypertension). The manual finding from this retinal vasculature is time-consuming and costly. The image quality of the fundus image directly affects the accurate segmentation of these vessels in the automatic methods. With such inferior quality images, deep-learning-based methods are better for dealing with segmentation. Conventional deep-learning-based vessel segmentation methods deal the segmentation task with deeper convolutional neural networks and many trainable parameters. Minor changes in the retinal vasculature, such as those that result from the creation of new smaller vessels, is crucial for the keen analysis of diseases (e.g., diabetic retinopathy). The small vessels are crucial to segment, owing to continuous max-pooling operations and deeper networks. We herein present a pool-less residual segmentation network that is capable of segmenting even smaller vessels using a shallower network with a low number of trainable parameters. Our proposed pool-less residual segmentation network (PLRS-Net) is a vessel segmentation network that provides the pooling effect with strided convolution for better segmentation sensitivity. The final PLRS-Net is an advanced form of a pool-less segmentation network (PLS-Net) wherein semantic segmentation was performed with a few layers, and the residual connection fulfilled the feature enhancement strategy to construct PLRS-Net. PLS-Net and PLRS-Net are two separate networks that can perform vessel segmentation without prior preprocessing and postprocessing. To evaluate our proposed method, the experiments include three publicly available datasets: Digital retinal images for vessel extraction (DRIVE), child heart health study in England database (CHASE-DB1), and structured analysis of retina (STARE). The results demonstrate that our proposed method provides a high segmentation performance, achieving an average sensitivity (Sen) of 82.69, specificity (Spe) of 98.17, accuracy (Acc) 96.82, and area under the curve (AUC) of 98.35 for the DRIVE dataset, Sen of 83.01, Spe of 98.39, Acc of 97.31, and AUC of 98.63 for the CHASE-DB1 dataset, and a Sen of 86.35, Spe of 98.03, Acc of 97.15, and AUC of 98.99 for the STARE dataset. These accuracies show exceptional segmentation performance of the proposed method compared to state-of-the-art approaches for automatic vessel detection for diagnosis purposes. © 2022 Elsevier Ltd",Deep learning; Diabetic and hypertensive retinopathy; PLRS-Net; PLS-Net; Retinal vessels
Article,"Wang X., Tang F., Chen H., Luo L., Tang Z., Ran A.-R., Cheung C.Y., Heng P.-A.",UD-MIL: Uncertainty-Driven Deep Multiple Instance Learning for OCT Image Classification,IEEE Journal of Biomedical and Health Informatics,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85092207318&doi=10.1109%2fJBHI.2020.2983730&partnerID=40&md5=4cbc0ced485547769f13ed77eddd1e1d,"Deep learning has achieved remarkable success in the optical coherence tomography (OCT) image classification task with substantial labelled B-scan images available. However, obtaining such fine-grained expert annotations is usually quite difficult and expensive. How to leverage the volume-level labels to develop a robust classifier is very appealing. In this paper, we propose a weakly supervised deep learning framework with uncertainty estimation to address the macula-related disease classification problem from OCT images with the only volume-level label being available. First, a convolutional neural network (CNN) based instance-level classifier is iteratively refined by using the proposed uncertainty-driven deep multiple instance learning scheme. To our best knowledge, we are the first to incorporate the uncertainty evaluation mechanism into multiple instance learning (MIL) for training a robust instance classifier. The classifier is able to detect suspicious abnormal instances and abstract the corresponding deep embedding with high representation capability simultaneously. Second, a recurrent neural network (RNN) takes instance features from the same bag as input and generates the final bag-level prediction by considering the individually local instance information and globally aggregated bag-level representation. For more comprehensive validation, we built two large diabetic macular edema (DME) OCT datasets from different devices and imaging protocols to evaluate the efficacy of our method, which are composed of 30,151 B-scans in 1,396 volumes from 274 patients (Heidelberg-DME dataset) and 38,976 B-scans in 3,248 volumes from 490 patients (Triton-DME dataset), respectively. We compare the proposed method with the state-of-the-art approaches, and experimentally demonstrate that our method is superior to alternative methods, achieving volume-level accuracy, F1-score and area under the receiver operating characteristic curve (AUC) of 95.1%, 0.939 and 0.990 on Heidelberg-DME and those of 95.1%, 0.935 and 0.986 on Triton-DME, respectively. Furthermore, the proposed method also yields competitive results on another public age-related macular degeneration OCT dataset, indicating the high potential as an effective screening tool in the clinical practice. © 2013 IEEE.",classification; multiple instance learning; Optical coherence tomography; uncertainty estimation
Article,"Vives-Boix V., Ruiz-Fernández D.",Diabetic retinopathy detection through convolutional neural networks with synaptic metaplasticity,Computer Methods and Programs in Biomedicine,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85106311342&doi=10.1016%2fj.cmpb.2021.106094&partnerID=40&md5=2f68bdfe8152e5145c8772727117a945,"Background and objectives: Diabetic retinopathy is a type of diabetes that causes vascular changes that can lead to blindness. The ravages of this disease cannot be reversed, so early detection is essential. This work presents an automated method for early detection of this disease using fundus colored images. Methods: A bio-inspired approach is proposed on synaptic metaplasticity in convolutional neural networks. This biological phenomenon is known to directly interfere in both learning and memory by reinforcing less common occurrences during the learning process. Synaptic metaplasticity has been included in the backpropagation stage of a convolution operation for every convolutional layer. Results: The proposed method has been evaluated by using a public small diabetic retinopathy dataset from Kaggle with four award-winning convolutional neural network architectures. Results show that convolutional neural network architectures including synaptic metaplasticity improve both learning rate and accuracy. Furthermore, obtained results outperform other methods in current literature, even using smaller datasets for training. Best results have been obtained for the InceptionV3 architecture with synaptic metaplasticity with a 95.56% accuracy, 94.24% F1-score, 98.9% precision and 90% recall, using 3662 images for training. Conclusions: Convolutional neural networks with synaptic metaplasticity are suitable for early detection of diabetic retinopathy due to their fast convergence rate, training simplicity and high performance. © 2021 Elsevier B.V.",Convolutional neural networks; Deep learning; Diabetic retinopathy; Image processing; Metaplasticity
Conference Paper,Mishra R.K.,Deep Learning Model for Multiclass Classification of Diabetic Retinal Fundus Images Using Gradient Descent Optimization,Lecture Notes in Electrical Engineering,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85144186651&doi=10.1007%2f978-981-19-5550-1_3&partnerID=40&md5=80c266833ad1259a319ef3883b7b0cb5,"Multiclass classification of diabetic retinal fundus images is a challenging task for classical methods due to presence of non-linear patterns in the images. Non-linearity in the shape and structure of blood vessels causes loss of crucial information used in accurate diagnosis of the disease. Hence, machine learning models became more prominent with high accuracy and speed of disease diagnosis. However, the efficacy of these methods largely depends on the feature extraction models. Convolutional neural networks (CNNs) provide solution to these difficulties by incorporating both feature extraction and classification in a single architecture. This work presents a gradient-descent (GD)-based optimization in CNN classifier that improves both speed and accuracy of classification. Experiments conducted on Kaggle, DRIVE, and STARE datasets, and the results are compared to the existing methods. The proposed approach shows a false positive rate (FPR) of 0.00075, specificity of 100%, precision of 99.9%, recall rate of 99.75%, and -score of 99.99%. © 2022, The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd.",Convolutional neural networks; Diabetic retinopathy; Gradient descent; Medical image classification; Optimization
Conference Paper,"Zabihollahy F., Ukwatta E.",Fully-automated segmentation of optic disk from retinal images using deep learning techniques,Progress in Biomedical Optics and Imaging - Proceedings of SPIE,2019,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85068105531&doi=10.1117%2f12.2512239&partnerID=40&md5=7579e22d4ce1d0e86fb0843ef5fd30e3,"Segmentation of optic disk (OD) from retinal images is a crucial task for early detection of many eye diseases, including glaucoma and diabetic retinopathy. The main goal of this research is to facilitate early diagnosis of certain pathologies via fully automated segmentation of the OD from retinal images. We propose a deep learning-based technique to delineate the boundary of OD from retinal images of patients with diabetic retinopathy and diabetic macular edema. In our method, we first localized OD within a region of interest (ROI) using random forest (RF). The RF is an ensemble algorithm, which trains and combines multiple decision trees to produce a highly accurate classifier. We then used a convolutional neural network (CNN) based model to segment OD from chosen ROIs in the retinal images. The developed algorithm has been validated on 480,249 image patches extracted from 49 images of public Indian diabetic retinopathy image dataset (IDRiD). This dataset includes images with large variability in terms of the spatial location of OD and presence of other eye lesions that resemble the contrast of OD. Validation metrics including average of Dice and Jaccard indexes (DI and JI), Hausdorff distance (HD), and absolute surface difference (ASD) were reported as 82.62 ± 11.07%, 71.78 ± 14.87%, 13.19 ± 10.90 mm, and 22.74 ± 19.78%, respectively. As compared to other alternative methods, such as K-nearest neighbors (KNN), deformable models, graph-cuts, and image thresholding, our method yielded higher accuracy for OD segmentation in comparison to manual expert delineation. The algorithm-generated results demonstrate the usefulness of our proposed method for automated segmentation of OD from retinal images. © 2019 SPIE.",Convolutional neural network; Diabetic retinopathy; Glaucoma; Optic disk; Random forest
Article,"Abbood S.H., Hamed H.N.A., Rahim M.S.M., Rehman A., Saba T., Bahaj S.A.",Hybrid Retinal Image Enhancement Algorithm for Diabetic Retinopathy Diagnostic Using Deep Learning Model,IEEE Access,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85134247277&doi=10.1109%2fACCESS.2022.3189374&partnerID=40&md5=6e5117df43190840a5f97cfdda9dc098,"Diabetic Retinopathy (DR) is a prevalent acute stage of diabetes mellitus that causes vision-effecting abnormalities on the retina. This will cause blindness if not identified early. Because DR not an irreversible procedure, and only vision is preserved via care. Consequently, Early diagnosis and care with DR will significantly minimize the chance of vision loss. In modern ophthalmology, retinal image analysis has become a popular approach to disease diagnosis. The ophthalmologists and computerized systems extensively employ fundus angiography to detect DR-based clinical signs for early detection of DR. fundus photographs are commonly prone to low contrast, noise, and irregular illumination issues due to the complexity of imaging environments such as imaging variety of angles and light conditions. This research presents an Algorithm for improving the quality of images to strengthen the standard of color fundus images by reducing the noise and improving the contrast. The approach includes two main stages: cropping the images to remove insignificant content, then applying the shape crop and gaussian blurring for noise reduction and contrast improvement. The experimental results are evaluated using two standard datasets EyePACS and MESSIDOR. It's clearly shown that the outcomes of feature extraction and classification of enhanced images is outperform the results without applying the enhancement approach. The improved algorithm is also tested in smart hospitals as an IoMT application. © 2013 IEEE.",deep learning; diabetic retinopathy; fundus image; health risks; healthcare; Image enhancement; retina
Article,"Sambyal N., Saini P., Syal R., Gupta V.",Modified U-Net architecture for semantic segmentation of diabetic retinopathy images,Biocybernetics and Biomedical Engineering,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85086934779&doi=10.1016%2fj.bbe.2020.05.006&partnerID=40&md5=c725a1796ab8e4d0ab961ba776f4a6cb,"Segmentation of lesions from fundus images is an essential prerequisite for accurate severity assessment of diabetic retinopathy. Due to variation in morphologies, number and size of lesions, the manual grading process becomes extremely challenging and time-consuming. This necessitates the need of an automatic segmentation system that can precisely define the region of interest boundaries and assist ophthalmologists in speedy diagnosis along with diabetic retinopathy severity grading. The paper presents a modified U-Net architecture based on residual network and employs periodic shuffling with sub-pixel convolution initialized to convolution nearest neighbour resize. The proposed architecture has been trained and validated for microaneurysm and hard exudate segmentation on two publicly available datasets namely IDRiD and e-ophtha. For IDRiD dataset, the network obtains 99.88% accuracy, 99.85% sensitivity, 99.95% specificity and dice score of 0.9998 for both microaneurysm and exudate segmentation. Further, when trained on e-ophtha and validated on IDRiD dataset, the network shows 99.98% accuracy, 99.88% sensitivity, 99.89% specificity and dice score of 0.9998 for microaneurysm segmentation. For exudates segmentation, the model obtained 99.98% accuracy, 99.88% sensitivity, 99.89% specificity and dice score of 0.9999, when trained on e-ophtha and validated on IDRiD dataset. In comparison to existing literature, the proposed model provides state-of-the-art results for retinal lesion segmentation. © 2020 Nalecz Institute of Biocybernetics and Biomedical Engineering of the Polish Academy of Sciences",Diabetic retinopathy; Fundus image; Hard exudates; Microaneurysm; Modified U-Net; Semantic segmentation
Conference Paper,"Le D., Alam M., Son T., Lim J.I., Yao X.",Deep learning artery-vein classification in OCT angiography,Progress in Biomedical Optics and Imaging - Proceedings of SPIE,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85108782870&doi=10.1117%2f12.2577304&partnerID=40&md5=a70205333feb9249a9f8c38757d2aedc,"Early disease diagnosis and effective treatment assessment are crucial to prevent vision loss. Retinal arteries and veins can be affected differently by different eye diseases, e.g., arterial narrowing and venous beading in diabetic retinopathy (DR). Therefore, differential artery-vein (AV) analysis can provide valuable information for early disease detection and better stage classification. However, manual, or semi-automated methods for AV identification are inefficient in a clinical setting. This study is to demonstrate the use of deep learning for automated AV classification in optical coherence tomography angiography (OCTA). We present ‘AV-Net’, a fully convolutional network (CNN) based on a modified U-shaped architecture. The input to AV-Net is a 2-channel system that combines grayscale enface OCT and OCTA. The enface OCT is a near infrared image, equivalent to a fundus image, which provides the vessel intensity profiles. In contrast, the OCTA contains the information of the blood flow strength, and vessel geometric features. The output of AV-Net is an RGB (red-green-blue) image, with R and B corresponding to arteries and veins, respectively, and the G channel represents the background. The dataset in this study is comprised of images from 50 individuals (20 controls and 30 DR patients). Transfer learning and regularization techniques, such as data augmentation and cross validation, were employed during training to prevent overfitting. The results reveal robust vessel segmentation and AV classification. A fully automated platform is essential for fostering efficient clinical deployment of AI-based screening, diagnosis, and treatment evaluation. © 2021 SPIE.",Deep learning; Diabetic retinopathy; Machine learning; Medical imaging; Ophthalmology; Optical coherence tomography; Optical diagnostics for medicine
Article,"Zhang X., li F., Li D., Wei Q., Han X., Zhang B., Chen H., Zhang Y., Mo B., Hu B., Ding D., Li X., Yu W., Chen Y.",Automated detection of severe diabetic retinopathy using deep learning method,Graefe's Archive for Clinical and Experimental Ophthalmology,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85116102199&doi=10.1007%2fs00417-021-05402-x&partnerID=40&md5=e900c71dce48746adea74e63f4f13e35,"Purpose: The purpose of this study is to develop and validate the intelligent diagnosis of severe DR with lesion recognition based on color fundus photography. Methods: The Kaggle public dataset for DR grading is used in the project, including 53,576 fundus photos in the test set, 28,101 in the training set, and 7,025 in the validation set. We randomly select 4,192 images for lesion annotation. Inception V3 structure is adopted as the classification algorithm. Both 299 × 299 pixel images and 896 × 896 pixel images are used as the input size. ROC curve, AUC, sensitivity, specificity, and their harmonic mean are used to evaluate the performance of the models. Results: The harmonic mean and AUC of the model of 896 × 896 input are higher than those of the 299 × 299 input model. The sensitivity, specificity, harmonic mean, and AUC of the method with 896 × 896 resolution images as input for severe DR are 0.925, 0.907, 0.916, and 0.968, respectively. The prediction error mainly occurs in moderate NPDR, and cases with more hard exudates and cotton wool spots are easily predicted as severe cases. Cases with preretinal hemorrhage and vitreous hemorrhage are easily identified as severe cases, and IRMA is the most difficult lesion to recognize. Conclusions: We have studied the intelligent diagnosis of severe DR based on color fundus photography. This artificial intelligence–based technology offers a possibility to increase the accessibility and efficiency of severe DR screening. © 2021, The Author(s), under exclusive licence to Springer-Verlag GmbH Germany, part of Springer Nature.",Color fundus photography; Deep learning; Intraretinal microvascular abnormality; Severe diabetic retinopathy
Article,"Tehrani A.A., Nickfarjam A.M., Ebrahimpour-komleh H., Aghadoost D.",Multi-input 2-dimensional deep belief network: diabetic retinopathy grading as case study,Multimedia Tools and Applications,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85092491681&doi=10.1007%2fs11042-020-10025-1&partnerID=40&md5=a72ae3adce41fd6d1877fb88f3d7ea59,"The most important action in treating diabetic retinopathy is early diagnosis and its progression degree. This paper presents a two-dimensional Deep Belief Network based on Mixed-restricted Boltzmann Machine capable of receiving multiple two-dimensional inputs. Using multiple inputs provides more appropriate prior information for learning. In this proposed method, the image is transferred to the HSV color space and then the 3D color image is converted to a 2D matrix using a weighted mean. This weighted mean is calculated based on the entropy criterion. The resulting two-dimensional matrix is not in pixel and is merely a raw description of the image. The local, regional and global descriptions are extracted from this matrix and provided for the network. The proposed deep network automatically extracts the appropriate features to determine the progression degree of diabetic retinopathy by the network. Window by window image processing can overcome one of the basic problems of image classification, i.e. the small number of labeled data. Experiments showed that the proposed method is superior when compared to other methods. © 2020, Springer Science+Business Media, LLC, part of Springer Nature.",Deep networks; Diabetic retinopathy; Mixed-restricted Boltzmann machine; Multi-input 2-dimensional deep belief network; Retinal image
Article,"Qian X., Jingying H., Xian S., Yuqing Z., Lili W., Baorui C., Wei G., Yefeng Z., Qiang Z., Chunyan C., Cheng B., Kai M., Yi Q.",The effectiveness of artificial intelligence-based automated grading and training system in education of manual detection of diabetic retinopathy,Frontiers in Public Health,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85142298710&doi=10.3389%2ffpubh.2022.1025271&partnerID=40&md5=0bb3033245c0083e6984db9a612b15ab,"Background: The purpose of this study is to develop an artificial intelligence (AI)-based automated diabetic retinopathy (DR) grading and training system from a real-world diabetic dataset of China, and in particular, to investigate its effectiveness as a learning tool of DR manual grading for medical students. Methods: We developed an automated DR grading and training system equipped with an AI-driven diagnosis algorithm to highlight highly prognostic related regions in the input image. Less experienced prospective physicians received pre- and post-training tests by the AI diagnosis platform. Then, changes in the diagnostic accuracy of the participants were evaluated. Results: We randomly selected 8,063 cases diagnosed with DR and 7,925 with non-DR fundus images from type 2 diabetes patients. The automated DR grading system we developed achieved accuracy, sensitivity/specificity, and AUC values of 0.965, 0.965/0.966, and 0.980 for moderate or worse DR (95 percent CI: 0.976–0.984). When the graders received assistance from the output of the AI system, the metrics were enhanced in varying degrees. The automated DR grading system helped to improve the accuracy of human graders, i.e., junior residents and medical students, from 0.947 and 0.915 to 0.978 and 0.954, respectively. Conclusion: The AI-based systemdemonstrated high diagnostic accuracy for the detection of DR on fundus images from real-world diabetics, and could be utilized as a training aid system for trainees lacking formal instruction on DR management. Copyright © 2022 Qian, Jingying, Xian, Yuqing, Lili, Baorui, Wei, Yefeng, Qiang, Chunyan, Cheng, Kai and Yi.",artificial intelligence; diabetic retinopathy; diagnosis; medical image education; medical students
Conference Paper,"Canche M., Dalmau O., Garcia M.",Automatic detection of hard exudates in retinal images with diabetic retinopathy,"Proceedings of a Special Session - 16th Mexican International Conference on Artificial Intelligence: Advances in Artificial Intelligence, MICAI 2017",2018,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85060684356&doi=10.1109%2fMICAI-2017.2017.00017&partnerID=40&md5=99ce1c6d7216ddeb07c0aafa2d427a31,"The Diabetic Retinopathy (DR) is a visual complication of diabetes and one of the principal cause of lost vision not recoverable in industrialized countries. It can be treated, if detected, in its first stages. This is not an easy task because the patients with DR do not perceive any symptoms until the visual loss develops in advanced stages when the treatment is less efficient. Hard exudates are the most common lesions in the early stages. In this work, we developed an automatic method for hard exudates detection in Diabetic Retinopathy images with an acceptable level of confidence that can help specialists in the diagnosis and screening of this disease. We also propose an exhaustive study of feature selection first by individual analysis and then by combining several features. This strategy is efficient, comparable and competitive with results of methods of the state of the art. © 2017 IEEE.",Adaboost; blood vessel detection; classification; diabetic retinopathy; Hard exudates detection; image processing
Article,"Javidi M., Harati A., Pourreza H.",Retinal image assessment using bi-level adaptive morphological component analysis,Artificial Intelligence in Medicine,2019,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85070616284&doi=10.1016%2fj.artmed.2019.07.010&partnerID=40&md5=0057386eb8a1a12839a5e4b133e8c07c,"The automated analysis of retinal images is a widely researched area which can help to diagnose several diseases like diabetic retinopathy in early stages of the disease. More specifically, separation of vessels and lesions is very critical as features of these structures are directly related to the diagnosis and treatment process of diabetic retinopathy. The complexity of the retinal image contents especially in images with severe diabetic retinopathy makes detection of vascular structure and lesions difficult. In this paper, a novel framework based on morphological component analysis (MCA) is presented which benefits from the adaptive representations obtained via dictionary learning. In the proposed Bi-level Adaptive MCA (BAMCA), MCA is extended to locally deal with sparse representation of the retinal images at patch level whereas the decomposition process occurs globally at the image level. BAMCA method with appropriately offline learnt dictionaries is adopted to work on retinal images with severe diabetic retinopathy in order to simultaneously separate vessels and exudate lesions as diagnostically useful morphological components. To obtain the appropriate dictionaries, K-SVD dictionary learning algorithm is modified to use a gated error which guides the process toward learning the main structures of the retinal images using vessel or lesion maps. Computational efficiency of the proposed framework is also increased significantly through some improvement leading to noticeable reduction in run time. We experimentally show how effective dictionaries can be learnt which help BAMCA to successfully separate exudate and vessel components from retinal images even in severe cases of diabetic retinopathy. In this paper, in addition to visual qualitative assessment, the performance of the proposed method is quantitatively measured in the framework of vessel and exudate segmentation. The reported experimental results on public datasets demonstrate that the obtained components can be used to achieve competitive results with regard to the state-of-the-art vessel and exudate segmentation methods. © 2019 Elsevier B.V.",Bi-level adaptive morphological component analysis; Diabetic retinopathy image assessment; Dictionary learning
Article,"Chen P.-N., Lee C.-C., Liang C.-M., Pao S.-I., Huang K.-H., Lin K.-F.",General deep learning model for detecting diabetic retinopathy,BMC Bioinformatics,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85118745411&doi=10.1186%2fs12859-021-04005-x&partnerID=40&md5=a07689ec1e9c97430787ec2a92e71d70,"Background: Doctors can detect symptoms of diabetic retinopathy (DR) early by using retinal ophthalmoscopy, and they can improve diagnostic efficiency with the assistance of deep learning to select treatments and support personnel workflow. Conventionally, most deep learning methods for DR diagnosis categorize retinal ophthalmoscopy images into training and validation data sets according to the 80/20 rule, and they use the synthetic minority oversampling technique (SMOTE) in data processing (e.g., rotating, scaling, and translating training images) to increase the number of training samples. Oversampling training may lead to overfitting of the training model. Therefore, untrained or unverified images can yield erroneous predictions. Although the accuracy of prediction results is 90%–99%, this overfitting of training data may distort training module variables. Results: This study uses a 2-stage training method to solve the overfitting problem. In the training phase, to build the model, the Learning module 1 used to identify the DR and no-DR. The Learning module 2 on SMOTE synthetic datasets to identify the mild-NPDR, moderate NPDR, severe NPDR and proliferative DR classification. These two modules also used early stopping and data dividing methods to reduce overfitting by oversampling. In the test phase, we use the DIARETDB0, DIARETDB1, eOphtha, MESSIDOR, and DRIVE datasets to evaluate the performance of the training network. The prediction accuracy achieved to 85.38%, 84.27%, 85.75%, 86.73%, and 92.5%. Conclusions: Based on the experiment, a general deep learning model for detecting DR was developed, and it could be used with all DR databases. We provided a simple method of addressing the imbalance of DR databases, and this method can be used with other medical images. © 2021, The Author(s).",Decision tree; Nasnet-large; Overfitting; SMOTE; Transfer learning
Article,"Farag M.M., Fouad M., Abdel-Hamid A.T.",Automatic Severity Classification of Diabetic Retinopathy Based on DenseNet and Convolutional Block Attention Module,IEEE Access,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85127810826&doi=10.1109%2fACCESS.2022.3165193&partnerID=40&md5=525df75d28bdea3b3791c1804afe41e5,"Diabetic Retinopathy (DR) - a complication developed due to heightened blood glucose levels- is deemed one of the most sight-threatening diseases. Unfortunately, DR screening is manually acquired by an ophthalmologist, a process that can be considered erroneous and time-consuming. Accordingly, automated DR diagnostics have become a focus of research in recent years due to the tremendous increase in diabetic patients. Moreover, the recent accomplishments demonstrated by Convolutional Neural Networks (CNN) settle them as state-of-the-art for DR stage identification. This paper proposes a new automatic deep-learning-based approach for severity detection by utilizing a single Color Fundus photograph (CFP). The proposed technique employs DenseNet169's encoder to construct a visual embedding. Furthermore, Convolutional Block Attention Module (CBAM) is introduced on top of the encoder to reinforce its discriminative power. Finally, the model is trained using cross-entropy loss on the Kaggle Asia Pacific Tele-Ophthalmology Society's (APTOS) dataset. On the binary classification task, we accomplished (97% accuracy - 97% sensitivity - 98.3% specificity - 0.9455, Quadratic Weighted Kappa score (QWK)) compared to the state-of-the-art. Moreover, Our network showed high competency (82% accuracy - 0.888 (QWK)) for severity grading. The significant contribution of the proposed framework is that it efficiently grades the severity level of diabetic retinopathy while reducing the time and space complexity required, which demonstrates it as a promising candidate for autonomous diagnosis. © 2013 IEEE.",attention mechanism; convolutional neural networks (CNN); deep learning; Diabetic retinopathy
Article,"Nazir T., Irtaza A., Shabbir Z., Javed A., Akram U., Mahmood M.T.",Diabetic retinopathy detection through novel tetragonal local octa patterns and extreme learning machines,Artificial Intelligence in Medicine,2019,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85070591769&doi=10.1016%2fj.artmed.2019.07.003&partnerID=40&md5=79e7ce1dd761e66b79c3693d03a482a6,"Diabetic retinopathy (DR) is an eye disease that victimize the people suffering from diabetes from many years. The severe form of DR results in form of the blindness that can initially be controlled by the DR-screening oriented treatment. The effective screening programs require the trained human resource that manually grade the fundus images to understand the severity of the disease. But due to the complexity of this process, and the insufficient number of the trained workers, the precise manual grading is an expensive process. The CAD-based solutions try to address these limitations but most of the existing DR detection systems are as evaluated over small sets and become ineffective when applied in real scenarios. Therefore, in this paper we proposed a novel technique to precisely detect the various stages of the DR by extending the research of the content-based image retrieval domain. To achieve the human-level performance over the large-scale DR-datasets (i.e. Kaggle-DR), the fundus images are represented by the novel tetragonal local octa pattern (T-LOP) features, that are then classified through the extreme learning machine (ELM). To justify the significance of the method, the proposed scheme is compared against several state-of-the-art methods including the deep learning-based methods over four DR-datasets of variational lengths (i.e. Kaggle-DR, DRIVE, Review-DB, STARE). The experimental results confirm the significance of the DR-detection scheme to serve as a stand-alone solution for providing the precise information of the severity of the DR in an efficient manner. © 2019 Elsevier B.V.",Content based image retrieval; Diabetic retinopathy; Extreme learning machines; Tetragonal local octa patterns
Article,"Priya Henry A.G., Jude A.",Convolutional neural-network-based classification of retinal images with different combinations of filtering techniques,Open Computer Science,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85113756248&doi=10.1515%2fcomp-2020-0177&partnerID=40&md5=4a7b2d8b465007192618b10996c58b5c,"Retinal image analysis is one of the important diagnosis methods in modern ophthalmology because eye information is present in the retina. The image acquisition process may have some effects and can affect the quality of the image. This can be improved by better image enhancement techniques combined with the computer-aided diagnosis system. Deep learning is one of the important computational application techniques used for a medical imaging application. The main aim of this article is to find the best enhancement techniques for the identification of diabetic retinopathy (DR) and are tested with the commonly used deep learning techniques, and the performances are measured. In this article, the input image is taken from the Indian-based database named as Indian Diabetic Retinopathy Image Dataset, and 13 filters are used including smoothing and sharpening filters for enhancing the images. Then, the quality of the enhancement techniques is compared using performance metrics and better results are obtained for Median, Gaussian, Bilateral, Wiener, and partial differential equation filters and are combined for improving the enhancement of images. The output images from all the enhanced filters are given as the convolutional neural network input and the results are compared to find the better enhancement method. © 2021 Asha Gnana Priya Henry and Anitha Jude, published by De Gruyter.",CNN; DR; filters; performance metrics; retinal image enhancement
Article,"Anil Kumar K.R., Noushira K.I., Meenakshy K.",Classification of diabetic retinopathy features using bag of feature model,International Journal of Innovative Technology and Exploring Engineering,2019,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85075137760&doi=10.35940%2fijitee.A4145.119119&partnerID=40&md5=2714941d19b6805281541c822aff52b7,"Deep learning (DL) as well as feature learning by unsupervised methods have made tremendous consideration in the past decades because of its great and dynamic capacity to change input data into high level depictions by means of various machine learning (ML) methods and approaches. Therefore these interests have also showed a fast and steady growth in the arena of medical image analysis, especially in Diabetic Retinopathy (DR) classification. On contradiction, manual interpretation involves excessive processing time, large amount of expertise and work. Sternness of the DR is analyzed relative to the existence of Microaneurysms (MAs), Exudates (EXs) and Hemorrhages(HEs). Spotting of DR in its early stage is crucial and important to avoid blindness. This paper proposes an algorithm to build an automated system to extract the above mentioned DR features which are the elemental and initial signs of diabetic retinopathy. Initial step in this algorithm is preprocessing of the original image. The next step in this features extraction algorithms is elimination of optic disc (OD) and blood vessels which have similar characteristic with these features. Blood vessels are segmented using Multi-Level Adaptive Thresholding. OD is segmented using morphological operations. Feature extraction and classification is achieved by using deep Bag of Feature (BoF) model which uses Speeded Up Robust Features Our method achieved 100% acuuracy in DRIVE database and over 90% accuracy for e-OPTHA database. Thus, the proposed methodology represents a track towards precise and highly automated DR diagnosis on a large substantial scale along with better sensitivity and specificity. © BEIESP.",Diabetic Retinopathy; Haemorrhages and exudates; Index Terms: Bag of Feature model; Microaneurysms
Conference Paper,"Deshmukh P., Gaikwad A.N.",Deep Learning Based DR Medical Image Classification,Communications in Computer and Information Science,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85135073456&doi=10.1007%2f978-3-031-11349-9_41&partnerID=40&md5=8f080eb16395c905b34ee4af047f0811,"Diabetic retinopathy (DR) is a prevailing disease that causes blindness among diabetic patients. The timely intervention with the regular fundus photography screening is the efficient way to cope with this disease. Screening of a large number of diabetic patients urges to the computer-aided and fully automatic DR diagnosis. Deep neural networks are gaining more attention due to their effectiveness in various tasks. The diagnosis of the can be made automatic and accurate suggestions can be provided to DR patients. The classification of DR images is challenging and important step. Therefore, in this paper, we have proposed a learning-based DR image reconstruction followed by a classification approach for DR image classification. Initially, the learning-based image reconstruction approach is proposed with a multi-encoder decoder network and residual inception block to delve into the features of input medical image and convert it into a set of abstract features followed by the reconstruction of the input medical image. The features from encoder are the abstract version of actual image representation which can be used for robust reconstruction for the input image. Therefore, these encoded features are used for DR image classification. The results analysis of the proposed framework with existing SOTA feature extraction algorithms is conducted on the MESSIDOR database for DR image classification. From the results’ analysis, it is evident that the proposed reconstruction-based classification framework outperforms the existing SOTA feature extraction algorithms. © 2022, The Author(s), under exclusive license to Springer Nature Switzerland AG.",Classification; Diabetic retinopathy; Image reconstruction; Residual inception block
Conference Paper,"Niranjana R., Narayanan K.L., Francy Irudaya Rani E., Agalya A., Chandraleka C., Indhumathi K.",Resourceful Retinal Vessel segmentation for Early Exposure of Vision Threatening Diseases,"2022 International Conference on Advanced Computing Technologies and Applications, ICACTA 2022",2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85129196581&doi=10.1109%2fICACTA54488.2022.9752931&partnerID=40&md5=7d399ed5d9cee64015b34aed09dc78bd,"Blood Vessels play a major role in our vision process. Likewise, the segmentation of theses vascular structure of blood vessels segmentation projects as a critical part in diagnosis of the various vision threatening diseases including Glaucoma and Diabetic Retinopathy (DR). The accurate way of doing the segmentation of retinal blood vessel is a critical part of analysis of retinal images pertaining to the fundus. Image Processing play a vital role in the medical field. Medical image processing provides very appropriate to diagnoses the various vision threatening diseases like Glaucoma and Diabetic Retinopathy (DR). Nowadays, it is a very growing and challenging field. We proposed a simple supervised approach by using deep learning Convolutional Neural Network. The steps that include in our proposed system are Preprocessing, Segmentation, Feature Extraction, and Classification. Wiener filter is used to de-noise the retinal image. OTSU for segmentation, which separate the foreground and the background and ACO for optimization which enhance the filtered image from Wiener filter. GLCM for feature extraction of the segmented image. For classification, we used a deep learning convolution neural network which provides more iterations. So it will give an appropriate classification for vision threatening diseases. After that a MATLAB software core is implemented. © 2022 IEEE.",Ant Colony Optimization; Diabetic Retinopathy; Grey Level Occurrence Matrix; MATLAB; Otsu
Article,"Gurcan O.F., Beyca O.F., Dogan O.",A comprehensive study of machine learning methods on diabetic retinopathy classification,International Journal of Computational Intelligence Systems,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85104639972&doi=10.2991%2fIJCIS.D.210316.001&partnerID=40&md5=df7d2f4cf832412685c9b5bb67c4abae,"Diabetes is one of the emerging threats to public health all over the world. According to projections by the World Health Organization, diabetes will be the seventh foremost cause of death in 2030 (WHO, Diabetes, 2020. https://www.afro.who.int/healthtopics/diabetes). Diabetic retinopathy (DR) results from long-lasting diabetes and is the fifth leading cause of visual impairment, worldwide. Early diagnosis and treatment processes are critical to overcoming this disease. The diagnostic procedure is challenging, especially in low-resource settings, or time-consuming, depending on the ophthalmologist’s experience. Recently, automated systems now address DR classification tasks. This study proposes an automated DR classification system based on preprocessing, feature extraction, and classification steps using deep convolutional neural network (CNN) and machine learning methods. Features are extracted from a pretrained model by the transfer learning approach. DR images are classified by several machine learning methods. XGBoost outperforms other methods. Dimensionality reduction algorithms are applied to obtain a lowerdimensional representation of extracted features. The proposed model is trained and evaluated on a publicly available dataset. Grid search and calibration are used in the analysis. This study provides researchers with performance comparisons of different machine learning methods. The proposed model offers a robust solution for detecting DR with a small number of images. We used a transfer learning approach, which differs from other studies in the literature, during the feature extraction. It provides a data-driven, cost-effective solution, which includes comprehensive preprocessing and fine-tuning processes. © 2021 The Authors. Published by Atlantis Press B.V.",Ensemble learning; Machine learning; PCA; SVD; Transfer learning; XGBoost
Article,"Yu C., Xie S., Niu S., Ji Z., Fan W., Yuan S., Liu Q., Chen Q.",Hyper-reflective foci segmentation in SD-OCT retinal images with diabetic retinopathy using deep convolutional neural networks,Medical Physics,2019,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85070985852&doi=10.1002%2fmp.13728&partnerID=40&md5=bc31753ea67f101b4c3ded7316e6394b,"Purpose: The purpose of this study was to automatically and accurately segment hyper-reflective foci (HRF) in spectral domain optical coherence tomography (SD-OCT) images with diabetic retinopathy (DR) using deep convolutional neural networks. Methods: An automatic HRF segmentation model for SD-OCT images based on deep networks was constructed. The model segmented small lesions through pixel-wise predictions based on small image patches. We used an approach for discriminative features extraction for small patches by introducing small kernels and strides in convolutional and pooling layers, which was applied on the state-of-the-art deep classification networks (GoogLeNet and ResNet). The features extracted by the adapted deep networks were fed into a softmax layer to produce the probabilities of HRF. We trained different models on a dataset with 16 HRF eyes by using different sizes of patches, and then, we fused these models to generate optimal results. Results: Experimental results on 18 eyes demonstrated that our method is effective for the HRF segmentation. The dice similarity coefficient (DSC) for the foci area in B-scan, projection images, and foci amount in B-scan images reaches 67.81%, 74.09%, and 72.45%, respectively. Conclusions: The proposed segmentation model can accurately segment HRF in SD-OCT images with DR and outperforms traditional methods. Our model may provide reliable segmentations for small lesions in SD-OCT images and may be helpful in the clinical diagnosis of diseases. © 2019 American Association of Physicists in Medicine",deep convolutional neural network; diabetic retinopathy; hyper-reflective foci; image segmentation; spectral domain optical coherence tomography
Conference Paper,"Ahmad M., Kasukurthi N., Pande H.",Deep learning for weak supervision of diabetic retinopathy abnormalities,Proceedings - International Symposium on Biomedical Imaging,2019,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85073907004&doi=10.1109%2fISBI.2019.8759417&partnerID=40&md5=6c4d6cddd9e27d39ca144ab16d5b4768,"Deep learning-based grading of the fundus images of the retina is an active area of research. Various existing studies use different deep learning architectures on different datasets. Results of some of the studies could not be replicated in other studies. Thus a benchmarking study across multiple architectures spanning both classification and localization is needed. We present a comparative study of different state-of-the-art architectures trained on a proprietary dataset and tested on the publicly available Messidor-2 dataset. Although evidence is of utmost importance in AI-based medical diagnosis, most studies limit themselves to the classification performance and do not report the quantification of the performance of the abnormalities localization. To alleviate this, using class activation maps, we also report a comparison of localization scores for different architectures. For classification, we found that as the number of parameters increase, the models perform better, with NASNet yielding highest accuracy and average precision, recall, and F1-scores of around 95%. For localization, VGG19 outperformed all the models with a mean Intersection over Minimum of 0.45. We also found that there is a trade-off between classification performance and localization performance. As the models get deeper, their receptive field increases, causing them to perform well on classification but underperform on the localization of fine-grained abnormalities. © 2019 IEEE.",Abnormality localization; Class activation maps; Diabetic retinopathy; Messidor-2
Article,"Purna Chandra Reddy V., Gurrala K.K.",Joint DR-DME classification using deep learning-CNN based modified grey-wolf optimizer with variable weights,Biomedical Signal Processing and Control,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85120698000&doi=10.1016%2fj.bspc.2021.103439&partnerID=40&md5=7440bf0ac2ca851ce35302fd37044f74,"This paper aims to develop a computer-based diagnostic system to assist ophthalmologists in screening for diabetic retinopathy and diabetic macular edema by identifying the early signs of DR in retinal fundus images. The main objective of this work is to detect and grade DR by the severity of its classes using a hybrid deep-learning convolutional neural network-based modified grey-wolf optimizer with variable weights, which is termed as DLCNN-MGWO-VW. Initially, ResNet50 is used to extract the combined features of DR and DME diseases. Then, a disease-specific attention module is used to extract the disease-specific features, which differentiates the basic features of two considered diseases. These data are later fed to the MGWO-VW for the optimal selection of individual disease-specific features from DR and DME, respectively. Finally, the disease-dependent attention module is used to identify the exact internal relationship between the two diseases with the aid of disease-dependent features that are also used for joint detection and classification of DR and DME, respectively. The simulations are performed on a publicly available IDRiD dataset, according to the ISBI-2018 challenge on DR segmentation and grading sub-challenge-2, where proposed hybrid DLCNN-MGWO-VW architecture maximizes the overall performance jointly for grading DR and DME, as compared to the state-of-art approaches from the literature. The proposed DLCNN-MGWO-VW method outperforms all the ISBI-2018 subchallenge-2 teams, with accuracy rates of 96.0%, 93.2%, and 92.23% for the detection and classification of DR, DME, and joint DR-DME, respectively. © 2021 Elsevier Ltd",Convolutional neural networks; Deep learning; Diabetic macular edema; Diabetic retinopathy; Grey-wolf optimization; IDRiD dataset
Article,"Li J., Wang Y., Wang S., Wang J., Liu J., Jin Q., Sun L.",Multiscale Attention Guided Network for COVID-19 Diagnosis Using Chest X-Ray Images,IEEE Journal of Biomedical and Health Informatics,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85101463413&doi=10.1109%2fJBHI.2021.3058293&partnerID=40&md5=7aa9227e226409ccd3b0e7b1c5877daa,"Coronavirus disease 2019 (COVID-19) is one of the most destructive pandemic after millennium, forcing the world to tackle a health crisis. Automated lung infections classification using chest X-ray (CXR) images could strengthen diagnostic capability when handling COVID-19. However, classifying COVID-19 from pneumonia cases using CXR image is a difficult task because of shared spatial characteristics, high feature variation and contrast diversity between cases. Moreover, massive data collection is impractical for a newly emerged disease, which limited the performance of data thirsty deep learning models. To address these challenges, Multiscale Attention Guided deep network with Soft Distance regularization (MAG-SD) is proposed to automatically classify COVID-19 from pneumonia CXR images. In MAG-SD, MA-Net is used to produce prediction vector and attention from multiscale feature maps. To improve the robustness of trained model and relieve the shortage of training data, attention guided augmentations along with a soft distance regularization are posed, which aims at generating meaningful augmentations and reduce noise. Our multiscale attention model achieves better classification performance on our pneumonia CXR image dataset. Plentiful experiments are proposed for MAG-SD which demonstrates its unique advantage in pneumonia classification over cutting-edge models. The code is available at https://github.com/JasonLeeGHub/MAG-SD. © 2013 IEEE.",convolutional neural network; COVID-19; multiscale attention; x-ray radiology
Conference Paper,"Abbas W., Shakeel M.H., Khurshid N., Taj M.",Patch-based generative adversarial network towards retinal vessel segmentation,Communications in Computer and Information Science,2019,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85083649195&doi=10.1007%2f978-3-030-36808-1_6&partnerID=40&md5=632a0d69eeaf97e6cdf9543fae9242aa,"Retinal blood vessels are considered to be the reliable diagnostic biomarkers of ophthalmologic and diabetic retinopathy. Monitoring and diagnosis totally depends on expert analysis of both thin and thick retinal vessels which has recently been carried out by various artificial intelligent techniques. Existing deep learning methods attempt to segment retinal vessels using a unified loss function optimized for both thin and thick vessels with equal importance. Due to variable thickness, biased distribution, and difference in spatial features of thin and thick vessels, unified loss function are more influential towards identification of thick vessels resulting in weak segmentation. To address this problem, a conditional patch-based generative adversarial network is proposed which utilizes a generator network and a patch-based discriminator network conditioned on the sample data with an additional loss function to learn both thin and thick vessels. Experiments are conducted on publicly available STARE and DRIVE datasets which show that the proposed model outperforms the state-of-the-art methods. © Springer Nature Switzerland AG 2019.",Deep Learning; Generative Adversarial Network; Retinal Vessels; Segmentation
Article,"Abbasi-Sureshjani S., Dashtbozorg B., ter Haar Romeny B.M., Fleuret F.",Exploratory study on direct prediction of diabetes using deep residual networks,Lecture Notes in Computational Vision and Biomechanics,2018,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032348384&doi=10.1007%2f978-3-319-68195-5_86&partnerID=40&md5=48ec9abd60e42ea3d551a7cc658ab085,"Diabetes is threatening the health of many people in the world. People may be diagnosed with diabetes only when symptoms or complications such as diabetic retinopathy start to appear. Retinal images reflect the health of the circulatory system and they are considered as a cheap and patient-friendly source of information for diagnosis purposes. Convolutional neural networks have enhanced the performance of conventional image processing techniques significantly by neglecting inconsistent feature extraction pipelines and learning informative features automatically from data. In this work we explore the possibility of using the deep residual networks as one of the state-of-the-art convolutional networks to diagnose diabetes directly from retinal images, without using any blood glucose information. The results indicate that convolutional networks are able to capture informative differences between healthy and diabetic patients and it is possible to differentiate between these two groups using only the retinal images. The performance of the proposed method is significantly higher than human experts. © 2018, Springer International Publishing AG.",Deep learning; Diabetes; Diabetic retinopathy; ResNet; Retinal images
Conference Paper,"Zhou K., Gu Z., Li A., Cheng J., Gao S., Liu J.",Fundus Image Quality-Guided Diabetic Retinopathy Grading,Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),2018,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053922387&doi=10.1007%2f978-3-030-00949-6_29&partnerID=40&md5=b2454131aadca67eff3e6f86a4158f79,"With the increasing use of fundus cameras, we can get a large number of retinal images. However there are quite a number of images in poor quality because of uneven illumination, occlusion and so on. The quality of images significantly affects the performance of automated diabetic retinopathy (DR) screening systems. Unlike the previous methods that did not face the unbalanced distribution, we propose weighted softmax with center loss to solve the unbalanced data distribution in medical images. Furthermore, we propose Fundus Image Quality (FIQ)-guided DR grading method based on multi-task deep learning, which is the first work using fundus image quality to help grade DR. Experimental results on the Kaggle dataset show that fundus image quality greatly impact DR grading. By considering the influence of quality, the experimental results validate the effectiveness of our propose method. All codes and fundus image quality label on Kaggle DR dataset are released in https://github.com/ClancyZhou/kaggle_DR_image_quality_miccai2018_workshop. © 2018, Springer Nature Switzerland AG.",Deep learning; DR screening; Fundus image quality classification; Multi-task
Article,"Wang R., Li P., Yang Z.",Analysis and Recognition of Clinical Features of Diabetes Based on Convolutional Neural Network,Computational and Mathematical Methods in Medicine,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85135550955&doi=10.1155%2f2022%2f7902786&partnerID=40&md5=6a78e80f8500125309d2d63c81de4fd7,"Diabetes mellitus is a common chronic noncommunicable disease, the main manifestation of which is the long-term high blood sugar level in patients due to metabolic disorders. However, due to excessive reliance on the clinical experience of ophthalmologists, our diagnosis takes a long time, and it is prone to missed diagnosis and misdiagnosis. In recent years, with the development of deep learning, its application in the auxiliary diagnosis of diabetic retinopathy has become possible. How to use the powerful feature extraction ability of deep learning algorithm to realize the mining of massive medical data is of great significance. Therefore, under the action of computer-aided technology, this paper processes and analyzes the retinal images of the fundus through traditional image processing and convolutional neural network-related methods, so as to achieve the role of assisting clinical treatment. Based on the admission records of diabetic patients after data analysis and feature processing, this paper uses an improved convolutional neural network algorithm to establish a model for predicting changes in diabetic conditions. The model can assist doctors to judge the patient's treatment effect by using it based on the case records of inpatient diagnosis and treatment and to predict the risk of readmission of inpatients after discharge. It also can help to judge the effectiveness of the treatment plan. The results of the study show that the model proposed in this paper has a lower probability of misjudging patients with poor recovery as good recovery, and the prediction is more accurate. © 2022 Rui Wang et al.","Convolution; Convolutional neural networks; Deep learning; Eye protection; Forecasting; Image processing; Learning algorithms; Medical computing; Ophthalmology; Patient rehabilitation; Patient treatment; Blood sugar levels; Clinical experience; Clinical features; Convolutional neural network; Diabetes mellitus; Diabetic retinopathy; Features extraction; ITS applications; Metabolic disorders; Non-communicable disease; Diagnosis; Article; clinical feature; convolutional neural network; diabetes mellitus; diabetic patient; diabetic retinopathy; eye fundus; hospital patient; hospital readmission; human; image processing; retina image; algorithm; diabetes mellitus; diabetic retinopathy; diagnostic imaging; procedures; Algorithms; Diabetes Mellitus; Diabetic Retinopathy; Fundus Oculi; Humans; Image Processing, Computer-Assisted; Neural Networks, Computer"
Article,"Saeed F., Hussain M., Aboalsamh H.A.",Automatic Diabetic Retinopathy Diagnosis Using Adaptive Fine-Tuned Convolutional Neural Network,IEEE Access,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102639343&doi=10.1109%2fACCESS.2021.3065273&partnerID=40&md5=a3c7846857d2db40374f8e9b99e8e9db,"Diabetic retinopathy (DR) is a complication of diabetes that leads to blindness. The manual screening of color fundus images to detect DR at early stages is expensive and time consuming. Deep learning (DL) techniques have been employed for automatic DR screening on fundus images due to their outstanding performance in many applications. However, training a DL model needs a huge amount of data, which are usually unavailable in the case of DR, and overfitting is unavoidable. Employing a two-stage transfer learning method, we developed herein an intelligent computer-aided system using a pre-trained convolutional neural network (CNN) for automatic DR screening on fundus images. A CNN model learns the domain-specific hierarchy of low-to high-level features. Given this, using the regions of interest (ROIs) of lesions extracted from the annotated fundus images, the first layer of a pre-trained CNN model is re-initialized. The model is then fine-tuned, such that the low-level layers learn the local structures of the lesion and normal regions. As the fully connected layer (FC) layers encode high-level features, which are global in nature and domain specific, we replace them with a new FC layer based on the principal component analysis PCA and use it in an unsupervised manner to extract discriminate features from the fundus images. This step reduces the model complexity, significantly avoiding the overfitting problem. This step also lets the model adopt the fundus image structures, making it suitable for DR feature detection. Finally, we add a gradient boosting-based classification layer. The evaluation of the proposed system using a 10-fold cross-validation on two challenging datasets (i.e., EyePACS and Messidor) indicates that it outperforms state-of-the-art methods. It will be useful for the initial screening of DR patients and will help graders in deciding quickly as regards patient referral to an ophthalmologist for further diagnosis and treatment. © 2013 IEEE.",classification; CNN; diabetic retinopathy; Fundus images
Conference Paper,"Santos C., De Aguiar M.S., Welfer D., Belloni B.",Deep Neural Network Model based on One-Stage Detector for Identifying Fundus Lesions,Proceedings of the International Joint Conference on Neural Networks,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85116486743&doi=10.1109%2fIJCNN52387.2021.9534354&partnerID=40&md5=9d3863cd61672544fd61db5e9f8f34f9,"Diabetic Retinopathy is a major cause of vision loss caused by retina lesions, including hard and soft exudates, microaneurysms, and hemorrhages. The development of a computational tool capable of detecting these lesions can assist in the early diagnosis of the most severe forms of the lesions and assist in the screening process and definition of the best treatment form. However, the detection of tiny objects of very different sizes and shapes makes the detection process more complicated. This paper proposes a computational model based on pre-trained convolutional neural networks capable of detecting fundus lesions to promote medical diagnosis support. We trained, adjusted, and evaluated the model using the DDR diabetic retinopathy dataset and implemented it based on a YOLOv4 architecture and Darknet framework, achieving an mAP of 7.26% and a mloU of 11.64%. The experimental results show that the proposed model presented results superior to those obtained in related works found in the literature. © 2021 IEEE.",deep learning; diabetic retinopathy; fundus image; lesion detection
Article,"A’bas N.N., Rahim S.S., Dolhalit M.L., Saifudin W.S.N., Abdullasim N., Parumo S., Omar R.N.R., Khair S.Z.M., Kalaichelvam K., Izhar S.I.N.",Development and Usability Testing of a Consultation System for Diabetic Retinopathy Screening,International Journal of Advanced Computer Science and Applications,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85107762973&doi=10.14569%2fIJACSA.2021.0120522&partnerID=40&md5=a53fd4f630ab4402eb17dcc0e8794290,"This study aims to develop a novel web-based decision support system for diabetic retinopathy screening and classification of eye fundus images for medical officers. The research delivers diabetic retinopathy information with a web-based environment according to the needs of the users. The proposed research also intends to evaluate the developed system usability to the target users. The complex characteristics of diabetic retinopathy signs contribute to the difficulty in detecting diabetic retinopathy. Therefore, professional and skilled retinal screeners are required to produce accurate diabetic retinopathy detection and diagnosis. The proposed system assists the communication and consultation among the medical experts in the hospital and the primary health cares located at the health clinics. The agile software development model is the methodology used for the development of this research project. The project collaborates with the Department of Ophthalmology, Hospital Melaka, Malaysia for the medical content expertise and testing. Representative medical officers from Hospital Melaka and all the public health clinics in Melaka were involved in the preliminary study and system testing. This research study consists of a web development producing an interactive web-based application of diabetic retinopathy consultation which comprises image processing and editing features as a core of the system. It is envisaged that this research project will contribute to the management of diabetic retinopathy screening among medical officers. © 2021. All Rights Reserved.",Consultation; diabetic retinopathy; eye screening; image editing; image processing; testing; web development
Article,Abdelsalam M.M.,Effective blood vessels reconstruction methodology for early detection and classification of diabetic retinopathy using OCTA images by artificial neural network,Informatics in Medicine Unlocked,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85088016584&doi=10.1016%2fj.imu.2020.100390&partnerID=40&md5=8da50a8335a630ceb8c9675db24389a2,"Background: Diabetic retinopathy (DR) refers to the ocular effect of diabetes. It is one of the retinal vascular diseases that can cause loss of vision. DR leads to alterations in vascular networks, including angiogenesis and capillary regression. Objective: The objective of this research is to provide an effective robust and accurate automatic methodology for the early detection of DR subjects. The methodology depends on two steps: 1) Blood vessel reconstruction, enhancement, and re-continuity using written custom programs, and 2) An Artificial Neural Network (ANN) as an automatic classifier between the diabetic without diabetic retinopathy (DR) and the Mild to Moderate Non-Proliferative Diabetic Retinopathy (NPDR) subjects. Methods: This approach depends on extracting the seven features, which are the most changeable features according to the morphological retinal vascular network changes. These features are the mean of the intercapillary areas as regions of interest for the largest 10 and 20 selected regions, either including or excluding the Foveal Avascular Zone (FAZ) region, FAZ perimeter, circularity index, and vascular density. The OCTA images were obtained and approved by the Ophthalmology Center in Mansoura University-Egypt. Results: One hundred images were processed, distributed as follows: 40 eyes were normal, 30 eyes were diabetic without DR, and 30 eyes were NPDR subjects. The total system accuracy reached 97%. The performance parameters of the classification system for normal versus diabetic were 97.5% for sensitivity, 96.67% for specificity, and 95.2% for precision. While, the measures for a diabetic without DR versus non-proliferative DR (mild to moderate) were 96.67% for sensitivity, 96.67% for specificity, and 96.67% for precision. The maximum misclassification error was 3.33%. Conclusion: The proposed methodology is capable of accurate classification of the diabetic without DR and Non-proliferative diabetic retinopathy subjects. This methodology depends on using written custom programs and a plugin for MATLAB and Fiji based Image-J software with a supervised artificial neural network. This technique achieves high accuracy, resolution, specificity, and precision with only a short time needed for diagnosis. © 2020 The Author",And artificial neural network classifier; Artificial intelligence; Diabetic retinopathy; Optical coherence tomography angiography
Conference Paper,"Wu Q., Cheddad A.",Segmentation-based Deep Learning Fundus Image Analysis,"2019 9th International Conference on Image Processing Theory, Tools and Applications, IPTA 2019",2019,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85077954037&doi=10.1109%2fIPTA.2019.8936078&partnerID=40&md5=491fc605b220d3e9650b70b6e2d038d8,"Diabetic retinopathy is the most common cause of new cases of blindness in people of working age. Early diagnosis is the key to slowing the progression of the disease, thus preventing blindness. Retinal fundus images form an important basis for judging these retinal diseases. To the best of our knowledge, no prior studies have scrutinized the predictive power of the different compositions of retinal images using deep learning. This paper is to investigate whether there exists specific region that could assist in better prediction of the retinopathy disease, meaning to find the best region in fundus images that can boost the prediction power of models for retinopathy classification. To this end, with image segmentation techniques, the fundus image is divided into three different segments, namely, the optic disc, the blood vessels, and the other regions (regions other than blood vessels and optic disk). These regions are then contrasted against the performance of original fundus images. The convolutional neural network as well as transfer deep learning with the state-of-the-art pre-trained models (i.e., AlexNet, GoogleNet, Resnet50, VGG19) are deployed. We report the average of ten runs for each model. Different machine learning evaluation metrics are used. The other regions' segment reveals more predictive power than the original fundus image especially when using AlexNet/Resnet50. © 2019 IEEE.",AlexNet; Deep Learning; Fundus Image; Image Segmentation; Retinopathy
Article,"Dong X., Du S., Zheng W., Cai C., Liu H., Zou J.",Evaluation of an Artificial Intelligence System for the Detection of Diabetic Retinopathy in Chinese Community Healthcare Centers,Frontiers in Medicine,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85128819951&doi=10.3389%2ffmed.2022.883462&partnerID=40&md5=eb75341b06ab0cdc360d5ec8c5a1f884,"Objective: To evaluate the sensitivity and specificity of a Comprehensive Artificial Intelligence Retinal Expert (CARE) system for detecting diabetic retinopathy (DR) in a Chinese community population. Methods: This was a cross-sectional, diagnostic study. Participants with a previous diagnosis of diabetes from three Chinese community healthcare centers were enrolled in the study. Single-field color fundus photography was obtained and analyzed by the AI system and two ophthalmologists. Primary outcome measures included the sensitivity, specificity, positive predictive value, and negative predictive value with their 95% confidence intervals (CIs) of the AI system in detecting DR and diabetic macular edema (DME). Results: In this study, 443 subjects (848 eyes) were enrolled, and 283 (63.88%) were men. The mean age was 52.09 (11.51) years (range 18–82 years); 266 eyes were diagnosed with any DR, 233 with more-than-mild diabetic retinopathy (mtmDR), 112 with vision-threatening diabetic retinopathy (vtDR), and 57 with DME. The image ability of the AI system was as high as 99.06%, whereas its sensitivity and specificity varied significantly in detecting DR with different severities. The sensitivity/specificity to detect any DR was 75.19% (95%CI 69.47–80.17)/93.99% (95%CI 91.65–95.71), mtmDR 78.97% (95%CI 73.06–83.90)/92.52% (95%CI 90.07–94.41), vtDR 33.93% (95%CI 25.41–43.56)/97.69% (95%CI 96.25–98.61), and DME 47.37% (95%CI 34.18–60.91)/93.99% (95%CI 91.65–95.71). Conclusions: This multicenter cross-sectional diagnostic study noted the safety and reliability of the CARE system for DR (especially mtmDR) detection in Chinese community healthcare centers. The system may effectively solve the dilemma faced by Chinese community healthcare centers: due to the lack of ophthalmic expertise of primary physicians, DR diagnosis and referral are not timely. Copyright © 2022 Dong, Du, Zheng, Cai, Liu and Zou.",artificial intelligence; color fundus photography; community healthcare; diabetic retinopathy; sensitivity; specificity
Article,"Nazir T., Nawaz M., Rashid J., Mahum R., Masood M., Mehmood A., Ali F., Kim J., Kwon H.-Y., Hussain A.",Detection of diabetic eye disease from retinal images using a deep learning based centernet model,Sensors,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85112130428&doi=10.3390%2fs21165283&partnerID=40&md5=c55fc3807624dd4add4bb0a9bc388e8c,"Diabetic retinopathy (DR) is an eye disease that alters the blood vessels of a person suffering from diabetes. Diabetic macular edema (DME) occurs when DR affects the macula, which causes fluid accumulation in the macula. Efficient screening systems require experts to manually analyze images to recognize diseases. However, due to the challenging nature of the screening method and lack of trained human resources, devising effective screening-oriented treatment is an expensive task. Automated systems are trying to cope with these challenges; however, these methods do not generalize well to multiple diseases and real-world scenarios. To solve the aforementioned issues, we propose a new method comprising two main steps. The first involves dataset preparation and feature extraction and the other relates to improving a custom deep learning based CenterNet model trained for eye disease classification. Initially, we generate annotations for suspected samples to locate the precise region of interest, while the other part of the proposed solution trains the Center Net model over annotated images. Specifically, we use DenseNet-100 as a feature extraction method on which the one-stage detector, CenterNet, is employed to localize and classify the disease lesions. We evaluated our method over challenging datasets, namely, APTOS-2019 and IDRiD, and attained average accuracy of 97.93% and 98.10%, respectively. We also performed cross-dataset validation with benchmark EYEPACS and Diaretdb1 datasets. Both qualitative and quantitative results demonstrate that our proposed approach outperforms state-of-the-art methods due to more effective localization power of CenterNet, as it can easily recognize small lesions and deal with over-fitted training data. Our proposed framework is proficient in correctly locating and classifying disease lesions. In comparison to existing DR and DME classification approaches, our method can extract representative key points from low-intensity and noisy images and accurately classify them. Hence our approach can play an important role in automated detection and recognition of DR and DME lesions. © 2021 by the authors.",Deep learning; Diabetic macular edema; Diabetic retinopathy; Medical imaging; Retinal images
Article,"Khojasteh P., Aliahmad B., Kumar D.K.","Fundus images analysis using deep features for detection of exudates, hemorrhages and microaneurysms 08 Information and Computing Sciences 0801 Artificial Intelligence and Image Processing",BMC Ophthalmology,2018,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85056140263&doi=10.1186%2fs12886-018-0954-4&partnerID=40&md5=428ec65020fd484201d8086dac02add6,"Background: Convolution neural networks have been considered for automatic analysis of fundus images to detect signs of diabetic retinopathy but suffer from low sensitivity. Methods: This study has proposed an alternate method using probabilistic output from Convolution neural network to automatically and simultaneously detect exudates, hemorrhages and microaneurysms. The method was evaluated using two approaches: patch and image-based analysis of the fundus images on two public databases: DIARETDB1 and e-Ophtha. The novelty of the proposed method is that the images were analyzed using probability maps generated by score values of the softmax layer instead of the use of the binary output. Results: The sensitivity of the proposed approach was 0.96, 0.84 and 0.85 for detection of exudates, hemorrhages and microaneurysms, respectively when considering patch-based analysis. The results show overall accuracy for DIARETDB1 was 97.3% and 86.6% for e-Ophtha. The error rate for image-based analysis was also significantly reduced when compared with other works. Conclusion: The proposed method provides the framework for convolution neural network-based analysis of fundus images to identify exudates, hemorrhages, and microaneurysms. It obtained accuracy and sensitivity which were significantly better than the reported studies and makes it suitable for automatic diabetic retinopathy signs detection. © 2018 The Author(s).",Convolutional neural networks; Deep learning; Diabetic retinopathy; Fundus image analysis; Image processing
Article,"Hemalakshmi G.R., Santhi D., Mani V.R.S., Geetha A., Prakash N.B.",Deep Residual Network Based on Image Priors for Single Image Super Resolution in FFA Images,CMES - Computer Modeling in Engineering and Sciences,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85091401875&doi=10.32604%2fcmes.2020.011331&partnerID=40&md5=26adcf15954b885897ac37749c610e9f,"Diabetic retinopathy, aged macular degeneration, glaucoma etc. are widely prevalent ocular pathologies which are irreversible at advanced stages. Machine learning based automated detection of these pathologies facilitate timely clinical interventions, preventing adverse outcomes. Ophthalmologists screen these pathologies with fundus Fluorescein Angiography Images (FFA) which capture retinal components featuring diverse morphologies such as retinal vasculature, macula, optical disk etc. However, these images have low resolutions, hindering the accurate detection of ocular disorders. Construction of high resolution images from these images, by super resolution approaches expedites the diagnosis of pathologies with better accuracy. This paper presents a deep learning network for Single Image Super Resolution (SISR) of fundus fluorescein angiography images, modeled on residual learning, gridded interpolation and Swish activation functions. The image prior for this network is constructed by gridded interpolation which provides better image fidelity compared to other priors. Evaluation of the performance of this network and comparative analysis with benchmark architectures, on a standard dataset shows that the proposed network is superior with respect to performance metrics and computational time. © 2020 Tech Science Press. All rights reserved.",FFA; Gridded interpolation; Residual network; SIS; Swish function
Conference Paper,"Yaroshchak S., Smaida M., El Barg Y.",Medical image enhancement based on convolutional denoising autoencoders and GMD model,CEUR Workshop Proceedings,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85111868993&partnerID=40&md5=36188d98b5fa5b54bbe39cbf30c35c7b,"Eye diseases include Glaucoma, Myopia and Diabetic retinopathy are very serious health problems in the life of people. Timely, early diagnosis of these diseases is very important to avoid blindness. There are many methods have been developed for this purpose. In this paper, we demonstrate the using of Convolutional Denoising Autoencoders (CDAE) to enhance the images we obtained from DCGAN (which we obtained from previous paper). In addition, using GMD model (Glaucoma, Myopia and Diabetic retinopathy) to compare the accuracy of the model using, original data only, original data with synthetic data which we obtained from DCGAN (obtained from pervious paper) and original data with high resolution data which we obtained from (CDAE). Our dataset consists of four types of eye diseases, Glaucoma, Myopia, Diabetic retinopathy and Normal. All these data were collected from Kaggle and proved from ophthalmologist. Firstly, we exploit CDAE to enhance the medical images (make it high-resolution). Then we utilize GMD method for eye diseases classification. finally, training our method using different types of dataset and comparative results in terms of accuracy are presented. The accuracy of the model had improved significantly from 89.84 % in training set and 89.94% in validation set, to 92.82% in training set and 93.32% in validation set based on this work. © 2021 Copyright for this paper by its authors. Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0). CEUR Workshop Proceedings (CEUR-WS.org)",Deep learning; Denoising autoencoders; Eye diseases; GMD model
Conference Paper,"Zeghlache R., Conze P.-H., Daho M.E.H., Tadayoni R., Massin P., Cochener B., Quellec G., Lamard M.",Detection of Diabetic Retinopathy Using Longitudinal,Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85138795430&doi=10.1007%2f978-3-031-16525-2_5&partnerID=40&md5=e8e4c87d1861171a792ae62a483fc029,"Longitudinal imaging is able to capture both static anatomical structures and dynamic changes in disease progression towards earlier and better patient-specific pathology management. However, conventional approaches for detecting diabetic retinopathy (DR) rarely take advantage of longitudinal information to improve DR analysis. In this work, we investigate the benefit of exploiting self-supervised learning with a longitudinal nature for DR diagnosis purposes. We compare different longitudinal self-supervised learning (LSSL) methods to model the disease progression from longitudinal retinal color fundus photographs (CFP) to detect early DR severity changes using a pair of consecutive exams. The experiments were conducted on a longitudinal DR screening dataset with or without those trained encoders (LSSL) acting as a longitudinal pretext task. Results achieve an AUC of 0.875 for the baseline (model trained from scratch) and an AUC of 0.96 (95% CI: 0.9593-0.9655 DeLong test) with a p-value &lt;2.2e–16 on early fusion using a simple ResNet alike architecture with frozen LSSL weights, suggesting that the LSSL latent space enables to encode the dynamic of DR progression. © 2022, The Author(s), under exclusive license to Springer Nature Switzerland AG.",Computer-aided diagnosis; Deep learning; Diabetic retinopathy; Longitudinal analysis; Self-supervised learning
Article,"Zhang G., Pan J., Zhang Z., Zhang H., Xing C., Sun B., Li M.",Hybrid graph convolutional network for semi-supervised retinal image classification,IEEE Access,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85101786513&doi=10.1109%2fACCESS.2021.3061690&partnerID=40&md5=0678d9e0c80934fe5cbd14bed3ad6d3a,"Diabetic Retinopathy (DR) causes a significant health threat to the patient's vision with diabetic disease, which may result in blindness in severe situations. Various automatic DR diagnosis models have been proposed along with the development of deep learning, while there always relies on a large scale annotated data to train the network. However, annotating medical fundus images is cost-expensive and requires well-trained professional doctors to identity the DR grades. To overcome this drawback, this paper focuses on utilizing the easily-obtained unlabeled data with the help of limited annotated data to identify DR grades accurately. Hence we proposes a semi-supervised retinal image classification method by a Hybrid Graph Convolutional Network (HGCN). This HGCN network designs a modularity-based graph learning module and integrates Convolutional Neural Network (CNN) features into the graph representation by graph convolutional network. The synthesized hybrid features are optimized by a semi-supervised classification task which is assisted by a similarity-based pseudo label estimator. Through the proposed HGCN method, the retinal image classification model can be trained efficiently by partially labeled samples and the complicated annotating work is not required for the most retinal images. The experimental results on MESSIDOR dataset demonstrate the favorable performance of HGCN on semi-supervised retinal image classification, and the fully labeled data training also achieves an obvious superiority to the state-of-the-art supervised learning methods. © 2013 IEEE.",graph convolutional network; modularity-based graph learning; Retinal image classification; semi-supervised
Conference Paper,"Wargnier-Dauchelle V., Simon-Chane C., Histace A.",Retinal blood vessels segmentation: Improving state-of-the-art deep methods,Communications in Computer and Information Science,2019,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85072836222&doi=10.1007%2f978-3-030-29930-9_1&partnerID=40&md5=f481491bf32a89a591118fb343f42693,"Retinal blood vessels segmentation is an important step for computer-aided early diagnosis of several retinal vascular diseases, in particular diabetic retinopathy. This segmentation is necessary to evaluate the state of the vascular network and to detect abnormalities (aneurysms, hemorrhages, etc). Many image processing and machine learning methods have been developed in recent years in order to achieve this segmentation. These methods are difficult to compare with one another since the evaluation conditions vary greatly. Moreover, public databases often provide multiple ground truths. In this paper, we implement a competitive state-of-the art method and evaluate it on the DRIVE (Digital Retinal Images for Vessel Extraction) public database. Based on this method, we test and present several improvements which are evaluated using a dedicated performance evaluation protocol. This protocol uses five criteria and three different evaluations in order to assess the robustness of the methods’ performances. © Springer Nature Switzerland AG 2019.",Convolutional neural network; Deep learning; DRIVE; Retinal blood vessels segmentation; U-Net
Conference Paper,"Khan T.M., Robles-Kelly A., Naqvi S.S.",A Semantically Flexible Feature Fusion Network for Retinal Vessel Segmentation,Communications in Computer and Information Science,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097292920&doi=10.1007%2f978-3-030-63820-7_18&partnerID=40&md5=95de5c7e106358ccc7f5f97101ea1658,"The automatic detection of retinal blood vessels by computer aided techniques plays an important role in the diagnosis of diabetic retinopathy, glaucoma, and macular degeneration. In this paper we present a semantically flexible feature fusion network that employs residual skip connections between adjacent neurons to improve retinal vessel detection. This yields a method that can be trained employing residual learning. To illustrate the utility of our method for retinal blood vessel detection, we show results on two publicly available data sets, i.e. DRIVE and STARE. In our experimental evaluation we include widely used evaluation metrics and compare our results with those yielded by alternatives elsewhere in the literature. In our experiments, our method is quite competitive, delivering a margin of sensitivity and accuracy improvement as compared to the alternatives under consideration. © 2020, Springer Nature Switzerland AG.",Deep neural networks; Image segmentation; Medical image analysis; Retinal vessels
Article,"Schuman J.S., De Los Angeles Ramos Cadena M., McGee R., Al-Aswad L.A., Medeiros F.A., Abramoff M., Blumenkranz M., Chew E., Chiang M., Eydelman M., Myung D., Shields C., Antony B.J., Aung T., Boland M., Brunner T., Chang R.T., Chauhan B., Cherwek D.H., Garway-Heath D., Graves A., Goldberg J.L., He M., Hammel N., Hood D., Ishikawa H., Leung C., Pasquale L., Quigley H.A., Roberts C.W., Robin A.L., Sturman E., Susanna R., Vianna J., Zangwill L., Collaborative Community on Ophthalmic Imaging Executive Committee and Glaucoma Workgroup",A Case for the Use of Artificial Intelligence in Glaucoma Assessment,Ophthalmology Glaucoma,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85124939357&doi=10.1016%2fj.ogla.2021.12.003&partnerID=40&md5=a247fee1920e57d7becfa08dfc21237a,"We hypothesize that artificial intelligence (AI) applied to relevant clinical testing in glaucoma has the potential to enhance the ability to detect glaucoma. This premise was discussed at the recent Collaborative Community on Ophthalmic Imaging meeting, “The Future of Artificial Intelligence–Enabled Ophthalmic Image Interpretation: Accelerating Innovation and Implementation Pathways,” held virtually September 3–4, 2020. The Collaborative Community on Ophthalmic Imaging (CCOI) is an independent self-governing consortium of stakeholders with broad international representation from academic institutions, government agencies, and the private sector whose mission is to act as a forum for the purpose of helping speed innovation in healthcare technology. It was 1 of the first 2 such organizations officially designated by the Food and Drug Administration in September 2019 in response to their announcement of the collaborative community program as a strategic priority for 2018–2020. Further information on the CCOI can be found online at their website (https://www.cc-oi.org/about). Artificial intelligence for glaucoma diagnosis would have high utility globally, because access to care is limited in many parts of the world and half of all people with glaucoma are unaware of their illness. The application of AI technology to glaucoma diagnosis has the potential to broadly increase access to care worldwide, in essence flattening the Earth by providing expert-level evaluation to individuals even in the most remote regions of the planet. © 2022 American Academy of Ophthalmology",Artificial intelligence; Deep learning; Glaucoma; Neural networks; OCT
Conference Paper,"Ye L., Zhu W., Feng S., Chen X.",GaNet: Group attention network for diabetic retinopathy image segmentation,Progress in Biomedical Optics and Imaging - Proceedings of SPIE,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85092603875&doi=10.1117%2f12.2548310&partnerID=40&md5=44aa07cb1d9b9c00c7e0119c18020679,"The assistance of deep learning techniques for clinic doctors in disease analysis, diagnosis and treatment is becoming popular and popular. In this paper, we propose a U-shape architecture based Group Attention network (named as GANet) for symptom segmentation in fundus images with diabetic retinopathy, in which Channel Group Attention(CGA) module and Spatial Group Attention Upsampling (SGAU) module are designed. The CGA module can adaptively allocate resources based on the importance of the feature channels, which can enhance the flexibility of the network to handle different types of information. The original U-Net directly merges the high-level features and low-level features in decoder stage for semantic segmentation, and achieves good results. To increase the nonlinearity of the U-shape network and pay more attention to the lesion area, we propose a Spatial Group Attention Upsampling (SGAU) module. In summary, our main contributions include two aspects: (1) Based on the U-shape network, the CGA module and SGAU module are designed and applied, which can adaptively allocate the weight of channels and pay more attention to the lesion area, respectively. (2) Compared with the original U-Net, the Dice coefficients of the proposed network improves by nearly 2.96% for hard exudates segmentation and 2.89% for hemorrhage segmentation, respectively. © 2020 SPIE. All rights reserved.",Deep Learning; Diabetic Retinopathy; Group Attention Network; Segmentation
Conference Paper,"Zhang Y., Zhou H., Xie Z., He Y.",Improving cross-domain diabetic retinopathy lesions segmentation based on CycleGAN augmentation,Proceedings of SPIE - The International Society for Optical Engineering,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137367539&doi=10.1117%2f12.2636505&partnerID=40&md5=09f9890c54eb82e7f5a40595b882deb1,"Diabetic retinopathy (DR) severity grade depends on lesion types. Automatic lesion segmentation of DR on fundus image plays a key role in the diagnosis of DR. It is increasingly common that a model is trained by the images from different sources. While a model trained on the source domain is transferred to another (target domain), the performance of the model generally decreases. In this paper, a novel method was proposed for cross-domain segmentation of DR lesions by applying cycle-consistent adversarial networks (CycleGAN) and an improved Xception-based UNet named AttXUNet. To enhance the generalization ability of AttXUNet, the AttXUNet was trained on transformed dataset generated by CycleGAN for reducing the distribution difference between source domain and the target domain. We tested the proposed model on three datasets of fundus images, and the results demonstrated that our model could accurately segment DR lesions on fundus images and alleviate the degradation of segmentation performance on multiple target domains. © 2022 SPIE. Downloading of the abstract is permitted for personal use only.",Deep Learning; Diabetic Retinopathy; Domain Adaptation; Sematic Segmentation
Article,"Son J., Shin J.Y., Kim H.D., Jung K.-H., Park K.H., Park S.J.",Development and Validation of Deep Learning Models for Screening Multiple Abnormal Findings in Retinal Fundus Images,Ophthalmology,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85068260505&doi=10.1016%2fj.ophtha.2019.05.029&partnerID=40&md5=9e6f9eda95816a3eec42ae173e9bf643,"Purpose: To develop and evaluate deep learning models that screen multiple abnormal findings in retinal fundus images. Design: Cross-sectional study. Participants: For the development and testing of deep learning models, 309 786 readings from 103 262 images were used. Two additional external datasets (the Indian Diabetic Retinopathy Image Dataset and e-ophtha) were used for testing. A third external dataset (Messidor) was used for comparison of the models with human experts. Methods: Macula-centered retinal fundus images from the Seoul National University Bundang Hospital Retina Image Archive, obtained at the health screening center and ophthalmology outpatient clinic at Seoul National University Bundang Hospital, were assessed for 12 major findings (hemorrhage, hard exudate, cotton-wool patch, drusen, membrane, macular hole, myelinated nerve fiber, chorioretinal atrophy or scar, any vascular abnormality, retinal nerve fiber layer defect, glaucomatous disc change, and nonglaucomatous disc change) with their regional information using deep learning algorithms. Main Outcome Measures: Area under the receiver operating characteristic curve and sensitivity and specificity of the deep learning algorithms at the highest harmonic mean were evaluated and compared with the performance of retina specialists, and visualization of the lesions was qualitatively analyzed. Results: Areas under the receiver operating characteristic curves for all findings were high at 96.2% to 99.9% when tested in the in-house dataset. Lesion heatmaps highlight salient regions effectively in various findings. Areas under the receiver operating characteristic curves for diabetic retinopathy-related findings tested in the Indian Diabetic Retinopathy Image Dataset and e-ophtha dataset were 94.7% to 98.0%. The model demonstrated a performance that rivaled that of human experts, especially in the detection of hemorrhage, hard exudate, membrane, macular hole, myelinated nerve fiber, and glaucomatous disc change. Conclusions: Our deep learning algorithms with region guidance showed reliable performance for detection of multiple findings in macula-centered retinal fundus images. These interpretable, as well as reliable, classification outputs open the possibility for clinical use as an automated screening system for retinal fundus images. © 2019 American Academy of Ophthalmology","adult; algorithm; Article; chorioretinopathy; cross-sectional study; deep learning; drusen; eye fundus; female; human; major clinical study; male; middle aged; myelinated nerve; nerve fiber; priority journal; retina disease; retina exudate; retina hemorrhage; retina image; retina macula hole; retrospective study; sensitivity and specificity; aged; algorithm; area under the curve; computer assisted diagnosis; diagnostic imaging; eye fundus; information processing; machine learning; procedures; receiver operating characteristic; retina disease; very elderly; Adult; Aged; Aged, 80 and over; Algorithms; Area Under Curve; Cross-Sectional Studies; Datasets as Topic; Deep Learning; Female; Fundus Oculi; Humans; Image Interpretation, Computer-Assisted; Machine Learning; Male; Middle Aged; Neural Networks, Computer; Retinal Diseases; ROC Curve; Sensitivity and Specificity"
Article,"Xie R., Liu J., Cao R., Qiu C.S., Duan J., Garibaldi J., Qiu G.",End-to-End Fovea Localisation in Colour Fundus Images with a Hierarchical Deep Regression Network,IEEE Transactions on Medical Imaging,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85098884299&doi=10.1109%2fTMI.2020.3023254&partnerID=40&md5=303e55f83bc861f81a13265553d7f8c6,"Accurately locating the fovea is a prerequisite for developing computer aided diagnosis (CAD) of retinal diseases. In colour fundus images of the retina, the fovea is a fuzzy region lacking prominent visual features and this makes it difficult to directly locate the fovea. While traditional methods rely on explicitly extracting image features from the surrounding structures such as the optic disc and various vessels to infer the position of the fovea, deep learning based regression technique can implicitly model the relation between the fovea and other nearby anatomical structures to determine the location of the fovea in an end-to-end fashion. Although promising, using deep learning for fovea localisation also has many unsolved challenges. In this paper, we present a new end-to-end fovea localisation method based on a hierarchical coarse-to-fine deep regression neural network. The innovative features of the new method include a multi-scale feature fusion technique and a self-attention technique to exploit location, semantic, and contextual information in an integrated framework, a multi-field-of-view (multi-FOV) feature fusion technique for context-aware feature learning and a Gaussian-shift-cropping method for augmenting effective training data. We present extensive experimental results on two public databases and show that our new method achieved state-of-the-art performances. We also present a comprehensive ablation study and analysis to demonstrate the technical soundness and effectiveness of the overall framework and its various constituent components. © 1982-2012 IEEE.",coarse-to-fine framework; data augmentation; data fusion; deep learning; Fovea localisation; three-stage network
Article,"Guo S., Li T., Kang H., Li N., Zhang Y., Wang K.",L-Seg: An end-to-end unified framework for multi-lesion segmentation of fundus images,Neurocomputing,2019,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85064178050&doi=10.1016%2fj.neucom.2019.04.019&partnerID=40&md5=ac8a3658295de8e66a6f31f830be4a20,"Diabetic retinopathy and diabetic macular edema are the two leading causes for blindness in working-age people, and the quantitative and qualitative diagnosis of these two diseases usually depends on the presence and areas of lesions in fundus images. The main related lesions include soft exudates, hard exudates, microaneurysms, and haemorrhages. However, segmentation of these four kinds of lesions is difficult due to their uncertainty in size, contrast, and high interclass similarity. Therefore, we aim to design a multi-lesion segmentation model. We have designed the first small object segmentation network (L-Seg) that can segment the four kinds of lesions simultaneously. Taking into account that small lesion regions could not response at high level of network, we propose a multi-scale feature fusion method to handle this problem. In addition, when considering the cases of both class-imbalance and loss-imbalance problems, we propose a multi-channel bin loss. We have evaluated L-Seg on three fundus datasets including two publicly available datasets - IDRiD and e-ophtha and one private dataset - DDR. Extensive experiments have demonstrated that L-Seg achieves better performance in small lesion segmentation than other deep learning models and traditional methods. Specially, the mAUC score of L-Seg is over 16.8%, 1.51% and 3.11% higher than that of DeepLab v3+ on IDRiD, e-ophtha and DDR datasets, respectively. Moreover, our framework shows competitive performance compared with top-3 teams in IDRiD challenge. The source code of L-Seg is available at: https://github.com/guomugong/L-Seg. © 2019 Elsevier B.V.",Class-imbalance; Diabetic retinopathy; Fundus image; Multi-lesion segmentation
Article,"Dai L., Fang R., Li H., Hou X., Sheng B., Wu Q., Jia W.",Clinical report guided retinal microaneurysm detection with multi-sieving deep learning,IEEE Transactions on Medical Imaging,2018,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85040931169&doi=10.1109%2fTMI.2018.2794988&partnerID=40&md5=af81f485e3e3346b8c2036c296bd437f,"Timely detection and treatment of microaneurysms is a critical step to prevent the development of vision-threatening eye diseases such as diabetic retinopathy. However, detecting microaneurysms in fundus images is a highly challenging task due to the low image contrast, misleading cues of other red lesions, and the large variation of imaging conditions. Existing methods tend to fail in face of the large intra-class variation and small inter-class variations for microaneurysm detection in fundus images. Recently, hybrid text/image mining computer-aided diagnosis systems have emerged to offer a promise of bridging the semantic gap between images and diagnostic information. In this paper, we focus on developing an interleaved deep mining technique to cope intelligently with the unbalanced microaneurysm detection problem. Specifically, we present a clinical report guided multi-sieving convolutional neural network, which leverages a small amount of supervised information in clinical reports to identify the potential microaneurysm regions via the image-to-text mapping in the feature space. These potential microaneurysm regions are then interleaved with fundus image information for multi-sieving deep mining in a highly unbalanced classification problem. Critically, the clinical reports are employed to bridge the semantic gap between low-level image features and high-level diagnostic information. We build an efficient microaneurysm detection framework based on the hybrid text/image interleaving and validate its performance on challenging clinical data sets acquired from diabetic retinopathy patients. Extensive evaluations are carried out in terms of fundus detection and classification. Experimental results show that our framework achieves 99.7% precision and 87.8% recall, comparing favorably with the state-of-the-art algorithms. Integration of expert domain knowledge and image information demonstrates the feasibility of reducing the difficulty of training classifiers under extremely unbalanced data distributions. © 1982-2012 IEEE.",clinical reports; deep learning; Diabetic retinopathy; fundus image analysis; microaneurysm detection; multi-sieving CNN
Article,"Rêgo S., Dutra-Medeiros M., Soares F., Monteiro-Soares M.",Screening for Diabetic Retinopathy Using an Automated Diagnostic System Based on Deep Learning: Diagnostic Accuracy Assessment,Ophthalmologica,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85109456051&doi=10.1159%2f000512638&partnerID=40&md5=c5f6a3339f57d12377e4ea1b18c55f25,"Purpose: To evaluate the diagnostic accuracy of a diagnostic system software for the automated screening of diabetic retinopathy (DR) on digital colour fundus photographs, the 2019 Convolutional Neural Network (CNN) model with Inception-V3. Methods: In this cross-sectional study, 295 fundus images were analysed by the CNN model and compared to a panel of ophthalmologists. Images were obtained from a dataset acquired within a screening programme. Diagnostic accuracy measures and respective 95% CI were calculated. Results: The sensitivity and specificity of the CNN model in diagnosing referable DR was 81% (95% CI 66-90%) and 97% (95% CI 95-99%), respectively. Positive predictive value was 86% (95% CI 72-94%) and negative predictive value 96% (95% CI 93-98%). The positive likelihood ratio was 33 (95% CI 15-75) and the negative was 0.20 (95% CI 0.11-0.35). Its clinical impact is demonstrated by the change observed in the pre-test probability of referable DR (assuming a prevalence of 16%) to a post-test probability for a positive test result of 86% and for a negative test result of 4%. Conclusion: A CNN model negative test result safely excludes DR, and its use may significantly reduce the burden of ophthalmologists at reading centres. © 2020 S. Karger AG, Basel. All rights reserved.",Artificial intelligence; Automated diagnosis; Diabetic retinopathy; Screening
Article,"Asia A.-O., Zhu C.-Z., Althubiti S.A., Al-Alimi D., Xiao Y.-L., Ouyang P.-B., Al-Qaness M.A.A.",Detection of Diabetic Retinopathy in Retinal Fundus Images Using CNN Classification Models,Electronics (Switzerland),2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137808738&doi=10.3390%2felectronics11172740&partnerID=40&md5=3d3a3fdab84d64503b15bbd7b7c540f1,"Diabetes is a widespread disease in the world and can lead to diabetic retinopathy, macular edema, and other obvious microvascular complications in the retina of the human eye. This study attempts to detect diabetic retinopathy (DR), which has been the main reason behind the blindness of people in the last decade. Timely or early treatment is necessary to prevent some DR complications and control blood glucose. DR is very difficult to detect in time-consuming manual diagnosis because of its diversity and complexity. This work utilizes a deep learning application, a convolutional neural network (CNN), in fundus photography to distinguish the stages of DR. The images dataset in this study is obtained from Xiangya No. 2 Hospital Ophthalmology (XHO), Changsha, China, which is very large, little and the labels are unbalanced. Thus, this study first solves the problem of the existing dataset by proposing a method that uses preprocessing, regularization, and augmentation steps to increase and prepare the image dataset of XHO for training and improve performance. Then, it takes the advantages of the power of CNN with different residual neural network (ResNet) structures, namely, ResNet-101, ResNet-50, and VggNet-16, to detect DR on XHO datasets. ResNet-101 achieved the maximum level of accuracy, 0.9888, with a training loss of 0.3499 and a testing loss of 0.9882. ResNet-101 is then assessed on 1787 photos from the HRF, STARE, DIARETDB0, and XHO databases, achieving an average accuracy of 0.97, which is greater than prior efforts. Results prove that the CNN model (ResNet-101) has better accuracy than ResNet-50 and VggNet-16 in DR image classification. © 2022 by the authors.",classification; CNN; deep learning; diabetic retinopathy; ResNet; VggNet
Article,"Macsik P., Pavlovicova J., Goga J., Kajan S.",Local Binary CNN for Diabetic Retinopathy Classification on Fundus Images,Acta Polytechnica Hungarica,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85134760810&partnerID=40&md5=16b6b67bde91211b4b5459743271190d,"Diabetic retinopathy (DR), is currently one of the major causes of preventable blindness, worldwide. With an early diagnosis and proper treatment of this eye disease, we can prevent the spread of diabetic retinopathy. In this paper, we propose a new alternative of local binary convolutional neural network (LBCNN) deterministic filter generation which can approximate the performance of the standard convolutional neural network (CNN) with less learnable parameters and also with less memory use, which can be helpful in systems with low-memory or low computational capacity, like smart-phones. We compare our scheme with standard CNN and LBCNN that uses stochastic filter generation strategy on retinal fundus image datasets in case of binary classification into healthy and damaged classes. These experiments are also evaluated according to the standard criteria used in medical applications, such as, overall accuracy, specificity, sensitivity and predictive values. On the small dataset (Aptos), one of our proposed LBCNN architectures outperformed all of the other deep learning models examined. © 2022, Budapest Tech Polytechnical Institution. All rights reserved.",Binary classification; CAD (Computer-aided diagnostics); Learnable parameters; Memory reduction
Conference Paper,"Mathew G., Sindhu Ramachandran S., Suchithra V.",EdgeAI: Diabetic Retinopathy Detection in Intel Architecture,"2020 IEEE / ITU International Conference on Artificial Intelligence for Good, AI4G 2020",2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85100357620&doi=10.1109%2fAI4G50087.2020.9311036&partnerID=40&md5=bbf3c61c202562d8fd124ab907510451,"Diabetic retinopathy is a leading cause of blindness among working-age adults. Millions of people suffer from Diabetic Retinopathy in India. More dreaded situation is faced by the population in rural India where access to quality healthcare is limited. AI comes to the rescue in those situations where initial diagnosis can be performed without much manual intervention. Early detection of this condition is critical for good prognosis. In this paper we propose a solution using UP2 board (Edge device based on x86 architecture) where AI diagnosis can be performed on the local premise itself. We used PyTorch framework for training the model using EfficientNet-B4 network architecture. Trained model was optimized using Intel Distribution of Open-VINO, and hence there is no much compromise in execution time. Inference time for execution of single image in UP2 board is 0.2 sec. Our model achieved test metric performance comparable to baseline literature results, with sensitivity of 91.5% and specificity of 97.86%. For proof of concept we used open dataset from Kaggle 2019 competition hosted by Aravind Hospital, India. © 2020 IEEE.",Diabetic Retinopathy; Edge Computing; Intel Distribution of OpenVINO; PyTorch; UP2 board
Article,"Paradisa R.H., Bustamam A., Mangunwardoyo W., Victor A.A., Yudantha A.R., Anki P.",Deep feature vectors concatenation for eye disease detection using fundus image,Electronics (Switzerland),2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85121433184&doi=10.3390%2felectronics11010023&partnerID=40&md5=fb1f7acfd66d3f812f90d363e1fb5cd8,"Fundus image is an image that captures the back of the eye (retina), which plays an important role in the detection of a disease, including diabetic retinopathy (DR). It is the most common complication in diabetics that remains an important cause of visual impairment, especially in the young and economically active age group. In patients with DR, early diagnosis can effectively help prevent the risk of vision loss. DR screening was performed by an ophthalmologist by analysing the lesions on the fundus image. However, the increasing prevalence of DR is not proportional to the availability of ophthalmologists who can read fundus images. It can lead to delayed prevention and management of DR. Therefore, there is a need for an automated diagnostic system as it can help ophthalmologists increase the efficiency of the diagnostic process. This paper provides a deep learning approach with the concatenate model for fundus image classification with three classes: no DR, non‐proliferative diabetic retinopathy (NPDR), and proliferative diabetic retinopathy (PDR). The model architecture used is DenseNet121 and Inception‐ResNetV2. The feature extraction results from the two models are combined and classified using the multilayer perceptron (MLP) method. The method that we propose gives an improvement compared to a single model with the results of accuracy, and average precision and recall of 91% and 90% for the F1‐score, respectively. This experiment demonstrates that our proposed deep‐learning approach is effective for the automatic DR classification using fundus photo data. © 2021 by the authors. Licensee MDPI, Basel, Switzerland.",Concatenate; Densenet121; Diabetic retinopathy; Inception‐resnetv2
Conference Paper,"Gong L., Ma K., Zheng Y.",Distractor-Aware Neuron Intrinsic Learning for Generic 2D Medical Image Classifications,Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85092731645&doi=10.1007%2f978-3-030-59713-9_57&partnerID=40&md5=1e6d14cf2458477294d3cb3531ff412d,"Medical image analysis benefits Computer Aided Diagnosis (CADx). A fundamental analyzing approach is the classification of medical images, which serves for skin lesion diagnosis, diabetic retinopathy grading, and cancer classification on histological images. When learning these discriminative classifiers, we observe that the convolutional neural networks (CNNs) are vulnerable to distractor interference. This is due to the similar sample appearances from different categories (i.e., small inter-class distance). Existing attempts select distractors from input images by empirically estimating their potential effects to the classifier. The essences of how these distractors affect CNN classification are not known. In this paper, we explore distractors from the CNN feature space via proposing a neuron intrinsic learning method. We formulate a novel distractor-aware loss that encourages large distance between the original image and its distractor in the feature space. The novel loss is combined with the original classification loss to update network parameters by back-propagation. Neuron intrinsic learning first explores distractors crucial to the deep classifier and then uses them to robustify CNN inherently. Extensive experiments on medical image benchmark datasets indicate that the proposed method performs favorably against the state-of-the-art approaches. © 2020, Springer Nature Switzerland AG.",Distractor-awareness; Medical Image Classification; Neuron Intrinsic Learning
Article,"Wang Y., Shi D., Tan Z., Niu Y., Jiang Y., Xiong R., Peng G., He M.",Screening Referable Diabetic Retinopathy Using a Semi-automated Deep Learning Algorithm Assisted Approach,Frontiers in Medicine,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85120856322&doi=10.3389%2ffmed.2021.740987&partnerID=40&md5=c3ce64e4a2c0579b672d8172393d7ac8,"Purpose: To assess the accuracy and efficacy of a semi-automated deep learning algorithm (DLA) assisted approach to detect vision-threatening diabetic retinopathy (DR). Methods: We developed a two-step semi-automated DLA-assisted approach to grade fundus photographs for vision-threatening referable DR. Study images were obtained from the Lingtou Cohort Study, and captured at participant enrollment in 2009–2010 (“baseline images”) and annual follow-up between 2011 and 2017. To begin, a validated DLA automatically graded baseline images for referable DR and classified them as positive, negative, or ungradable. Following, each positive image, all other available images from patients who had a positive image, and a 5% random sample of all negative images were selected and regraded by trained human graders. A reference standard diagnosis was assigned once all graders achieved consistent grading outcomes or with a senior ophthalmologist's final diagnosis. The semi-automated DLA assisted approach combined initial DLA screening and subsequent human grading for images identified as high-risk. This approach was further validated within the follow-up image datasets and its time and economic costs evaluated against fully human grading. Results: For evaluation of baseline images, a total of 33,115 images were included and automatically graded by the DLA. 2,604 images (480 positive results, 624 available other images from participants with a positive result, and 1500 random negative samples) were selected and regraded by graders. The DLA achieved an area under the receiver operating characteristic curve (AUC), sensitivity, specificity, and accuracy of 0.953, 0.970, 0.879, and 88.6%, respectively. In further validation within the follow-up image datasets, a total of 88,363 images were graded using this semi-automated approach and human grading was performed on 8975 selected images. The DLA achieved an AUC, sensitivity, and specificity of 0.914, 0.852, 0.853, respectively. Compared against fully human grading, the semi-automated DLA-assisted approach achieved an estimated 75.6% time and 90.1% economic cost saving. Conclusions: The DLA described in this study was able to achieve high accuracy, sensitivity, and specificity in grading fundus images for referable DR. Validated against long-term follow-up datasets, a semi-automated DLA-assisted approach was able to accurately identify suspect cases, and minimize misdiagnosis whilst balancing safety, time, and economic cost. Copyright © 2021 Wang, Shi, Tan, Niu, Jiang, Xiong, Peng and He.",artificial intelligence; cost-saving analysis; deep learning; diabetic retinopathy; screening
Conference Paper,"Shrivastava U., Joshi M.V.",Automated Multiclass Diagnosis of Diabetic Retinopathy using Hierarchical Learning,ACM International Conference Proceeding Series,2018,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85098215000&doi=10.1145%2f3293353.3293412&partnerID=40&md5=89008bb643adf042c2b96da092f8f7b7,"Diabetic Retinopathy (DR) is the leading cause of blindness in the modern world. Diagnosis of DR requires an experienced ophthalmologist and it is a tedious and time-consuming process. In this paper, we propose a Convolutional Neural Network (CNN) based automated diagnosis system that can classify various stages of DR accurately. A hierarchical approach is adopted for classification in which we break down our classification task into two stages. In the first stage we perform binary classification obtaining the true positive and negative samples and in the second stage, five class classification is performed on those images classified as true positive, false positive and false negative in the first stage of classification. Our approach of classifying hierarchically takes care of the class imbalance in the data by removing the most dominant class 0 (No-DR) from the dataset at the binary classification stage. The proposed method uses the Inception-v3 CNN for feature extraction in which we use the features from second last layer of both main and auxiliary classifiers. The extracted features are concatenated into a single feature vector to train a Support Vector Machine (SVM). We use SVM with Radial Basis Function (RBF) kernel for both binary and multiclass classifications. Experiments are conducted on ""Kaggle""dataset and our approach attains an accuracy of 87.7% on validation data for binary classification and 81.8% for multiclass classification. Our results are better than the recently proposed approach using CNN indicating that the hierarchical classification performs better for multiclass classification. © 2018 ACM.",Computer vision; Convolutional neural networks; Deep learning; Eye protection; Support vector machines; Automated diagnosis system; Binary classification; False positive and false negatives; Hierarchical approach; Hierarchical classification; Hierarchical learning; Multi-class classification; Radial Basis Function(RBF); Classification (of information)
Article,"Bustamam A., Sarwinda D., Paradisa R.H., Victor A.A., Yudantha A.R., Siswantining T.",Evaluation of convolutional neural network variants for diagnosis of diabetic retinopathy,Communications in Mathematical Biology and Neuroscience,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85108354325&doi=10.28919%2fcmbn%2f5660&partnerID=40&md5=46f614ba3ad44a65354d6ec3e2b41ab1,"Diabetic Retinopathy (DR) is a long-term complication of Diabetes Mellitus (DM) that impairs vision. This stage occurs in visual impairment and blindness if treated late. DR identified through scanning fundus images. A technique on classifying DR in fundus images is the deep learning approach, one of the methods of implementing machine learning. In this study, the Convolutional Neural Networks (CNN) method applied with the ResNet-50 and DenseNet-121 architectures. The data adopted in this analysis was generated from DIARETDB1, an online database containing fundus images. Then, the pre-processing stage is carried out on the fundus image to improve model performance, such as selected the green channel from the images and inverted it, converted the images into grayscale images, and applied Contrast Limited Adaptive Histogram Equalization (CLAHE) for uniform contrast in the images. The outcome of this research indicates that the ResNet-50 model is better than DenseNet-121 in detecting DR. The most reliable results from the ResNet-50 model's case testing are accuracy, precision, and recall of 95%, 98%, and 96% respectively. © 2021, SCIK Publishing Corporation. All rights reserved.",Deep learning; Densenet; Diabetic retinopathy; Fundus image; Resnet
Conference Paper,"Zhao M., Hamarneh G.",Retinal image classification via vasculature-guided sequential attention,"Proceedings - 2019 International Conference on Computer Vision Workshop, ICCVW 2019",2019,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85082436774&doi=10.1109%2fICCVW.2019.00049&partnerID=40&md5=a4e268760ec33e83f5bff4973720f38a,"Age-related macular degeneration and diabetic retinopathy are diseases of increasing prevalence globally in recent years. Traditionally, diagnosing these diseases relied on manual visual inspection by experts, which was costly, time-consuming and laborious as it required closely examining high-resolution color fundus images. More recently, deep learning networks have shown great potential in predicting diseases from retinal images. However, being purely data-driven, these networks are susceptible to overfitting and their training requires large annotated data. In this paper, we propose to enrich deep learning-based fundus image classifiers with prior knowledge on special structures in the retina implicated with the disease. In particular, we leverage vessel priors to guide the attention mechanism of deep learning architectures. In addition, we leverage a bi-directional dual-layer LSTM module to learn the inter-dependencies between a sequence of prior-guided attention maps deployed across the depth of the disease classification network. Results on the clinical datasets show the proposed method could bring performance improvement by as much as 8%? © 2019 IEEE.",Attention; Deep learning; Lstm; Retinal image
Conference Paper,"Kho S.H., Mashohor S., Hanafi M.",Deep Learning for Diabetic Retinopathy (DR) Classifier,Lecture Notes in Electrical Engineering,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85125280453&doi=10.1007%2f978-981-16-8129-5_28&partnerID=40&md5=1e38933fa5e779e72d2018863d8a0ab6,"High prevalence in diabetes contributed to the rising of the complications such as diabetic retinopathy (DR) which cause the patient to suffer from vision loss and this vision loss may become permanent if it is not well manage and treat. Including other medication non-adherence factor, this rising trend has been made more challenging for physician in keep apace with demand using manual method of retina screening to diagnose DR. Therefore, this project aimed to develop a classifier of deep learning for DR in 5 different level of severity which are normal (no DR), mild, moderate, severe and proliferative DR, to speed up the clinical assessment for early DR detection or DR monitoring progression of disease. The classification was applied using Scottish grading with consider three categories for fundus abnormalities which are hemorrhage, lipid exudates and microaneurysms for a training from scratch model and a pre-trained model using Inception V3. Verified and trustable dataset of retina screening or fundus image available online such as kaggle.com used to train and test of the system. Besides, the execution of this project was completed via on cloud training using Google Cloud Platform (GCP). The obtained results are measuring the classifier performance tested in term of accuracy, sensitivity, and specificity. Transfer learning using Inception V3 has been shown a better performance compare to own training model with accuracy 81.2% using transfer learning Inception V3 and 74.7% for own training model. © 2022, The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd.",Convolution neural network; Diabetic retinopathy classifier; Pre-Trained model inception V3
Conference Paper,"Han J., Jiang W., Dai C., Ma H.",The Design of Diabetic Retinopathy Classifier Based on Parameter Optimization SVM,"2018 International Conference on Intelligent Informatics and Biomedical Sciences, ICIIBMS 2018",2018,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85060024638&doi=10.1109%2fICIIBMS.2018.8549947&partnerID=40&md5=ed0cf02fe3629af7e39e06aff393b65d,"Diabetic retinopathy is a kind of disease which can seriously damage eyesight. Early diagnosis and regular treatment can effectively reduce visual deterioration. Artificial judgment of fundus images is time-consuming and easy to misdiagnose. Machine learning is an algorithm which automatically analyzes rules from data and uses rules to predict unknown data. Support Vector Machine (SVM) is one of the most important methods of machine learning. SVM is a classifier with learning ability. It is broadly applied to image recognition and image processing. Based on machine learning, a parametric optimized SVM classifier for diabetic retinopathy is proposed. Firstly, the classifier uses PCA and KPCA method to extract the prominent features of the image without artificial recognizing the features of the image, eliminates the specific feature extraction method, reduces the algorithm complexity, increases the generalization ability of the algorithm, and greatly improves the image processing speed. Secondly, grid search and genetic algorithm are used to optimize the parameters, avoid the problem of slow operation speed and low classification accuracy due to the large amount of data or the unsuitable selection of kernel parameters. Finally, a combinatorial optimization algorithm of KPCA and grid search is created. Meanwhile, the designed experiments verify that this combination optimization algorithm can make the classifier achieve the best classification state. The experimental results show that the classification accuracy of this combinatorial optimization algorithm reaches 98.33%, which can realize the automatic classification of diabetic retinopathy more accurately and rapidly. © 2018 IEEE.",classification accuracy; Genetic Algorithm; grid search; Kernel Principal Component Analysis; parameter optimization; Support Vector Machine
Conference Paper,"Kumari C.U., Hemanth A., Anand V., Kumar D.S., Naga Sanjeev R., Sri Harshitha T.S.",Deep Learning Based Detection of Diabetic Retinopathy using Retinal Fundus Images,"Proceedings of the 2022 3rd International Conference on Intelligent Computing, Instrumentation and Control Technologies: Computational Intelligence for Smart Systems, ICICICT 2022",2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85141371849&doi=10.1109%2fICICICT54557.2022.9917709&partnerID=40&md5=bc2613c3c7d2d2836eeef39f7a6d3321,"Diabetic retinopathy is a type of diabetes which affects the eye by causing damage to retinal blood vessels. It may have no symptoms at first or cause diminished vision problems. As the condition deteriorates, it affects both eyes, leading to partial or complete loss of vision. This is especially so when blood sugar levels are uncontrollable. As a result, the diabetic patient is at greater risk for developing this condition. The risk of complete and permanent blindness can be avoided if an early detection is made. As a result, effective screening method is required. In this paper the four salient features microaneurysms, blood vessels, hemorrhages and exudates are drawn out from the unprocessed images using image-processing techniques and convolutional neural network is used for automatic identification and it implements fundus images classification of Diabetic Retinopathy. The pre-trained CNNs use DenseNet-169. The transferred CNNs are then fine-tuned using the fundus images. Pre-trained CNN models were considered as feature extractors for fundus pictures. As features, the outputs of the final fully connected layers are used. By using DenseNet-16 the highest accuracy is obtained compared to remaining models. The ensuing result displays visual examples as well as images of the corresponding DRIVE database basic facts. The model is further trained with a Conv2 layer with 128 filters to improve accuracy, and greater integration is used to obtain an accuracy of 80%. © 2022 IEEE.",CNN; medical image analysis; Non-Proliferative Retinopathy; Retina Fundus Images
Article,"Khojasteh P., Passos Júnior L.A., Carvalho T., Rezende E., Aliahmad B., Papa J.P., Kumar D.K.",Exudate detection in fundus images using deeply-learnable features,Computers in Biology and Medicine,2019,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85056215478&doi=10.1016%2fj.compbiomed.2018.10.031&partnerID=40&md5=750ee82401ae99d6227e8349938a56e3,"Presence of exudates on a retina is an early sign of diabetic retinopathy, and automatic detection of these can improve the diagnosis of the disease. Convolutional Neural Networks (CNNs) have been used for automatic exudate detection, but with poor performance. This study has investigated different deep learning techniques to maximize the sensitivity and specificity. We have compared multiple deep learning methods, and both supervised and unsupervised classifiers for improving the performance of automatic exudate detection, i.e., CNNs, pre-trained Residual Networks (ResNet-50) and Discriminative Restricted Boltzmann Machines. The experiments were conducted on two publicly available databases: (i) DIARETDB1 and (ii) e-Ophtha. The results show that ResNet-50 with Support Vector Machines outperformed other networks with an accuracy and sensitivity of 98% and 0.99, respectively. This shows that ResNet-50 can be used for the analysis of the fundus images to detect exudates. © 2018",Convolutional neural networks; Deep learning; Deep residual networks; Diabetic retinopathy; Discriminative restricted Boltzmann machines; Exudate detection
Conference Paper,"Lin Z., Guo R., Wang Y., Wu B., Chen T., Wang W., Chen D.Z., Wu J.",A framework for identifying diabetic retinopathy based on anti-noise detection and attention-based fusion,Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),2018,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85054076986&doi=10.1007%2f978-3-030-00934-2_9&partnerID=40&md5=c1bdfd1b8c0582a0ed58c63a45d9c9fd,"Automatic diagnosis of diabetic retinopathy (DR) using retinal fundus images is a challenging problem because images of low grade DR may contain only a few tiny lesions which are difficult to perceive even to human experts. Using annotations in the form of lesion bounding boxes may help solve the problem by deep learning models, but fully annotated samples of this type are usually expensive to obtain. Missing annotated samples (i.e., true lesions but not included in annotations) are noise and can affect learning models negatively. Besides, how to utilize lesion information for identifying DR should be considered carefully because different types of lesions may be used to distinguish different DR grades. In this paper, we propose a new framework for unifying lesion detection and DR identification. Our lesion detection model first determines the missing annotated samples to reduce their impact on the model, and extracts lesion information. Our attention-based network then fuses original images and lesion information to identify DR. Experimental results show that our detection model can considerably reduce the impact of missing annotation and our attention-based network can learn weights between the original images and lesion information for distinguishing different DR grades. Our approach outperforms state-of-the-art methods on two grand challenge retina datasets, EyePACS and Messidor. © Springer Nature Switzerland AG 2018.",Deep learning; Diagnosis; Eye protection; Medical computing; Automatic diagnosis; Detection models; Diabetic retinopathy; Grand Challenge; Learning models; Lesion detection; Retinal fundus images; State-of-the-art methods; Medical imaging
Article,"Chen J.S., Coyner A.S., Ostmo S., Sonmez K., Bajimaya S., Pradhan E., Valikodath N., Cole E.D., Al-Khaled T., Chan R.V.P., Singh P., Kalpathy-Cramer J., Chiang M.F., Campbell J.P.",Deep Learning for the Diagnosis of Stage in Retinopathy of Prematurity: Accuracy and Generalizability across Populations and Cameras,Ophthalmology Retina,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85105274067&doi=10.1016%2fj.oret.2020.12.013&partnerID=40&md5=2cacf607346fc79f67b959184f358e26,"Purpose: Stage is an important feature to identify in retinal images of infants at risk of retinopathy of prematurity (ROP). The purpose of this study was to implement a convolutional neural network (CNN) for binary detection of stages 1, 2, and 3 in ROP and to evaluate its generalizability across different populations and camera systems. Design: Diagnostic validation study of CNN for stage detection. Participants: Retinal fundus images obtained from preterm infants during routine ROP screenings. Methods: Two datasets were used: 5943 fundus images obtained by RetCam camera (Natus Medical, Pleasanton, CA) from 9 North American institutions and 5049 images obtained by 3nethra camera (Forus Health Incorporated, Bengaluru, India) from 4 hospitals in Nepal. Images were labeled based on the presence of stage by 1 to 3 expert graders. Three CNN models were trained using 5-fold cross-validation on datasets from North America alone, Nepal alone, and a combined dataset and were evaluated on 2 held-out test sets consisting of 708 and 247 images from the Nepali and North American datasets, respectively. Main Outcome Measures: Convolutional neural network performance was evaluated using area under the receiver operating characteristic curve (AUROC), area under the precision-recall curve (AUPRC), sensitivity, and specificity. Results: Both the North American– and Nepali-trained models demonstrated high performance on a test set from the same population: AUROC, 0.99; AUPRC, 0.98; sensitivity, 94%; and AUROC, 0.97; AUPRC, 0.91; and sensitivity, 73%; respectively. However, the performance of each model decreased to AUROC of 0.96 and AUPRC of 0.88 (sensitivity, 52%) and AUROC of 0.62 and AUPRC of 0.36 (sensitivity, 44%) when evaluated on a test set from the other population. Compared with the models trained on individual datasets, the model trained on a combined dataset achieved improved performance on each respective test set: sensitivity improved from 94% to 98% on the North American test set and from 73% to 82% on the Nepali test set. Conclusions: A CNN can identify accurately the presence of ROP stage in retinal images, but performance depends on the similarity between training and testing populations. We demonstrated that internal and external performance can be improved by increasing the heterogeneity of the training dataset features of the training dataset, in this case by combining images from different populations and cameras. © 2020 American Academy of Ophthalmology",Artificial intelligence; Generalizability; Neural networks; Retinopathy of prematurity; Stage
Article,"Ali R., Hardie R.C., Narayanan B.N., Kebede T.M.",IMNets: Deep Learning Using an Incremental Modular Network Synthesis Approach for Medical Imaging Applications,Applied Sciences (Switzerland),2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85131511236&doi=10.3390%2fapp12115500&partnerID=40&md5=0f09c43cc4ee9448408eb46de0f43639,"Deep learning approaches play a crucial role in computer-aided diagnosis systems to support clinical decision-making. However, developing such automated solutions is challenging due to the limited availability of annotated medical data. In this study, we proposed a novel and computationally efficient deep learning approach to leverage small data for learning generalizable and domain invariant representations in different medical imaging applications such as malaria, diabetic retinopathy, and tuberculosis. We refer to our approach as Incremental Modular Network Synthesis (IMNS), and the resulting CNNs as Incremental Modular Networks (IMNets). Our IMNS approach is to use small network modules that we call SubNets which are capable of generating salient features for a particular problem. Then, we build up ever larger and more powerful networks by combining these SubNets in different configurations. At each stage, only one new SubNet module undergoes learning updates. This reduces the computational resource requirements for training and aids in network optimization. We compare IMNets against classic and state-of-the-art deep learning architectures such as AlexNet, ResNet-50, Inception v3, DenseNet-201, and NasNet for the various experiments conducted in this study. Our proposed IMNS design leads to high average classification accuracies of 97.0%, 97.9%, and 88.6% for malaria, diabetic retinopathy, and tuberculosis, respectively. Our modular design for deep learning achieves the state-of-the-art performance in the scenarios tested. The IMNets produced here have a relatively low computational complexity compared to traditional deep learning architectures. The largest IMNet tested here has 0.95 M of the learnable parameters and 0.08 G of the floating-point multiply–add (MAdd) operations. The simpler IMNets train faster, have lower memory requirements, and process images faster than the benchmark methods tested. © 2022 by the authors. Licensee MDPI, Basel, Switzerland.",deep learning; diabetic retinopathy; malaria detection; medical imaging; modular networks; tuberculosis detection
Article,"Ihnaini B., Khan M.A., Khan T.A., Abbas S., Daoud M.S., Ahmad M., Khan M.A.",A Smart Healthcare Recommendation System for Multidisciplinary Diabetes Patients with Data Fusion Based on Deep Ensemble Learning,Computational Intelligence and Neuroscience,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85116295228&doi=10.1155%2f2021%2f4243700&partnerID=40&md5=853c150ef44e9d7a50f15e596e583919,"The prediction of human diseases precisely is still an uphill battle task for better and timely treatment. A multidisciplinary diabetic disease is a life-threatening disease all over the world. It attacks different vital parts of the human body, like Neuropathy, Retinopathy, Nephropathy, and ultimately Heart. A smart healthcare recommendation system predicts and recommends the diabetic disease accurately using optimal machine learning models with the data fusion technique on healthcare datasets. Various machine learning models and methods have been proposed in the recent past to predict diabetes disease. Still, these systems cannot handle the massive number of multifeatures datasets on diabetes disease properly. A smart healthcare recommendation system is proposed for diabetes disease based on deep machine learning and data fusion perspectives. Using data fusion, we can eliminate the irrelevant burden of system computational capabilities and increase the proposed system's performance to predict and recommend this life-threatening disease more accurately. Finally, the ensemble machine learning model is trained for diabetes prediction. This intelligent recommendation system is evaluated based on a well-known diabetes dataset, and its performance is compared with the most recent developments from the literature. The proposed system achieved 99.6% accuracy, which is higher compared to the existing deep machine learning methods. Therefore, our proposed system is better for multidisciplinary diabetes disease prediction and recommendation. Our proposed system's improved disease diagnosis performance advocates for its employment in the automated diagnostic and recommendation systems for diabetic patients. © 2021 Baha Ihnaini et al.",Data fusion; Deep learning; Diagnosis; Forecasting; Recommender systems; Data fusion technique; Diabetes patients; Ensemble learning; Human bodies; Human disease; Machine data; Machine learning methods; Machine learning models; Multifeatures; Nephropathy; Health care; diabetes mellitus; health care delivery; human; machine learning; Delivery of Health Care; Diabetes Mellitus; Humans; Machine Learning
Conference Paper,"Zhang S., Wu H., Murthy V., Wang X., Cao L., Schwartz J., Hernandez J., Rodriguez G., Liu B.J.",The application of deep learning for diabetic retinopathy prescreening in research eye-PACS,Progress in Biomedical Optics and Imaging - Proceedings of SPIE,2018,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85047754661&doi=10.1117%2f12.2296673&partnerID=40&md5=f1ddbb9624ebbbc87330583c9205213b,"The increasing incidence of diabetes mellitus (DM) in modern society has become a serious issue. DM can also lead to several secondary clinical complications. One of these complications is diabetic retinopathy (DR), which is the leading cause of new cases of blindness for adults in the United States. While DR can be treated if screened and caught early in progression, the only currently effective method to detect symptoms of DR in the eyes of DM patients is through the manual analysis of fundus images. Manual analysis of fundus images is time-consuming for ophthalmologists and can reduce access to DR screening in rural areas. Therefore, effective automatic prescreening tools on a cloud-based platform might be a potential solution to that problem. Recently, deep learning (DL) approaches have been shown to have state-of-The-Art performance in image analysis tasks. In this study, we established a research PACS for fundus images to view DICOMized and anonymized fundus images. We prototyped a deep learning engine in the PACS server to perform prescreening classification of uploaded fundus images into DR grade. We fine-Tuned a deep convolutional neural network (CNN) model pretrained on the ImageNet dataset by using over 30,000 labeled image samples from the public Kaggle Diabetic Retinopathy Detection fundus image dataset6. We linked the PACS repository with the DL engine and demonstrated the output predicted result of DR into the PACS worklist. The initial prescreened result was promising and such applications could have potential as a ""second reader"" with future CAD development for nextgeneration PACS. © 2018 SPIE.",Deep learning; Diabetic retinopathy; Fundus image; PACS; ResNet
Article,"Pekala M., Joshi N., Liu T.Y.A., Bressler N.M., DeBuc D.C., Burlina P.",Deep learning based retinal OCT segmentation,Computers in Biology and Medicine,2019,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85072536710&doi=10.1016%2fj.compbiomed.2019.103445&partnerID=40&md5=96b43aa46a496501a0a3427aa1018d45,"We look at the recent application of deep learning (DL) methods in automated fine-grained segmentation of spectral domain optical coherence tomography (OCT) images of the retina. We describe a new method combining fully convolutional networks (FCN) with Gaussian Processes for post processing. We report performance comparisons between the proposed approach, human clinicians, and other machine learning (ML) such as graph based approaches. The approach is demonstrated on an OCT dataset consisting of mild non-proliferative diabetic retinopathy from the University of Miami. The method is shown to have performance on par with humans, also compares favorably with the other ML methods, and appears to have as small or smaller mean unsigned error (equal to 1.06), versus errors ranging from 1.17 to 1.81 for other methods, and compared with human error of 1.10. © 2019 Elsevier Ltd",Fully convolutional networks; Gaussian process regression; Neurodegenerative; OCT segmentation; Retinal and vascular diseases
Article,"Sugeno A., Ishikawa Y., Ohshima T., Muramatsu R.",Simple methods for the lesion detection and severity grading of diabetic retinopathy by image processing and transfer learning,Computers in Biology and Medicine,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85114128850&doi=10.1016%2fj.compbiomed.2021.104795&partnerID=40&md5=4272d39ec32996ce06a3f6dea276ee63,"Diabetic retinopathy (DR) has become one of the major causes of blindness. Due to the increased prevalence of diabetes worldwide, diabetic patients exhibit high probabilities of developing DR. There is a need to develop a labor-less computer-aided diagnosis system to support the clinical diagnosis. Here, we attempted to develop simple methods for severity grading and lesion detection from retinal fundus images. We developed a severity grading system for DR by transfer learning with a recent convolutional neural network called EfficientNet-B3 and the publicly available Kaggle Asia Pacific Tele-Ophthalmology Society (APTOS) 2019 training dataset, which includes artificial noise. After removing the blurred and duplicated images from the dataset using a numerical threshold, the trained model achieved specificity and sensitivity values ≳ 0.98 in the identification of DR retinas. For severity grading, the classification accuracy values of 0.84, 0.95, and 0.98 were recorded for the 1st, 2nd, and 3rd predicted labels, respectively. The utility of EfficientNets-B3 for the severity grading of DR as well as the detailed retinal areas referred were confirmed via visual explanation methods of convolutional neural networks. Lesion extraction was performed by applying an empirically defined threshold value to the enhanced retinal images. Although the extraction of blood vessels and detection of red lesions occurred simultaneously, the red and white lesions, including both soft and hard exudates, were clearly extracted. The detected lesion areas were further confirmed with ground truth using the DIARETDB1 database images with general accuracy. The simple and easily applicable methods proposed in this study will aid in the detection and severity grading of DR, which might help in the selection of appropriate treatment strategies for DR. © 2021 Elsevier Ltd",Computer-aided diagnosis; Convolutional neural network (CNN); Deep learning; Diabetic retinopathy (DR); Image processing; Lesion detection; Severity grading
Article,"Sandhu H.S., Eltanboly A., Shalaby A., Keynton R.S., Schaal S., El-Baz A.",Automated diagnosis and grading of diabetic retinopathy using optical coherence tomography,Investigative Ophthalmology and Visual Science,2018,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85060644276&doi=10.1167%2fiovs.17-23677&partnerID=40&md5=8fce8e4363cab96a5d7dfddb2da5ac2e,"PURPOSE. We determine the feasibility and accuracy of a computer-assisted diagnostic (CAD) system to diagnose and grade nonproliferative diabetic retinopathy (NPDR) from optical coherence tomography (OCT) images. METHODS. A cross-sectional, single-center study was done of type II diabetics who presented for routine screening and/or monitoring exams. Inclusion criteria were age 18 or older, diagnosis of diabetes mellitus type II, and clear media allowing for OCT imaging. Exclusion criteria were inability to image the macula, posterior staphylomas, proliferative diabetic retinopathy, and concurrent retinovascular disease. All patients underwent a full dilated eye exam and spectral-domain OCT of a 6 x 6 mm area of the macula in both eyes. These images then were analyzed by a novel CAD system that segments the retina into 12 layers; quantifies the reflectivity, curvature, and thickness of each layer; and ultimately uses this information to train a neural network that classifies images as either normal or having NPDR, and then further grades the level of retinopathy. A first dataset was tested by ‘‘leave-one-subject-out’’ (LOSO) methods and by 2-and 4-fold cross-validation. The system then was tested on a second, independent dataset. RESULTS. Using LOSO experiments on a dataset of images from 80 patients, the proposed CAD system distinguished normal from NPDR subjects with 93.8% accuracy (sensitivity = 92.5%, specificity = 95%) and achieved 97.4% correct classification between subclinical and mild/ moderate DR. When tested on an independent dataset of 40 patients, the proposed system distinguished between normal and NPDR subjects with 92.5% accuracy and between subclinical and mild/moderate NPDR with 95% accuracy. CONCLUSIONS. A CAD system for automated diagnosis of NPDR based on macular OCT images from type II diabetics is feasible, reliable, and accurate. Â© 2018 The Authors.",Deep fusion classification networks; DFCN; Diabetic retinopathy; Machine learning; Neural networks; NPDR; OCT; SNCAE
Article,"Yu M., Wang Y.",Intelligent detection and applied research on diabetic retinopathy based on the residual attention network,International Journal of Imaging Systems and Technology,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85128280199&doi=10.1002%2fima.22734&partnerID=40&md5=1ef2f64b174c3616e270c6673c77a144,"This study proposes a high-accuracy (ACC) algorithm to automatically detect diabetic retinopathy (DR) and diabetic macular edema (DME) in retinal fundus images. Three DR datasets were obtained for use in this study: EyePACS, Messidor, and IDRid. In the EyePACS dataset, two DR classifications and five classifications experiments were conducted. The Messidor and IDRid dataset were graded DR and DME. After preprocessing, enhancement, and normalizing, common convolutional neural networks (CNN) were used to obtain the classification results. Afterward, an optimization method residual attention network (RAN) was introduced that was based on the residual attention module, and incorporated dilated convolution, so as to optimize the experimental results. The focal loss was then added to solve the imbalance problem. Next, a five-fold cross-validation strategy was introduced so as to assess and optimize the proposed model, after which the prediction ACC, sensitivity, specificity, area under receiver operating curve, and Kappa score were assessed. The proposed method RAN was shown to achieve 89.2% ACC (95% confidence interval [CI], 0.8782–0.9123) for two DR classifications (normal and abnormal) on the EyePACS dataset, 89.8% ACC (95% CI, 0.8751–0.9275) for two DR classifications on the Messidor dataset. The IDRid dataset achieved an ACC of 71.5% (95% CI, 0.6941–0.7423) for the two DR classifications. RAN mainly improves the results of commonly used CNN methods on the same dataset. Therefore, the classification and diagnosis of DR may be improved by adopting the proposed method. © 2022 Wiley Periodicals LLC.",artificial intelligence; attention mechanism; CNN; diabetic retinopathy; dilated convolution; fundus image
Article,"Gupta S., Thakur S., Gupta A.",Optimized hybrid machine learning approach for smartphone based diabetic retinopathy detection,Multimedia Tools and Applications,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85125237921&doi=10.1007%2fs11042-022-12103-y&partnerID=40&md5=6cd7e0d46838ab2f73c2ae7478de6454,"Diabetic Retinopathy (DR) is defined as the Diabetes Mellitus difficulty that harms the blood vessels in the retina. It is also known as a silent disease and cause mild vision issues or no symptoms. In order to enhance the chances of effective treatment, yearly eye tests are vital for premature discovery. Hence, it uses fundus cameras for capturing retinal images, but due to its size and cost, it is a troublesome for extensive screening. Therefore, the smartphones are utilized for scheming low-power, small-sized, and reasonable retinal imaging schemes to activate automated DR detection and DR screening. In this article, the new DIY (do it yourself) smartphone enabled camera is used for smartphone based DR detection. Initially, the preprocessing like green channel transformation and CLAHE (Contrast Limited Adaptive Histogram Equalization) are performed. Further, the segmentation process starts with optic disc segmentation by WT (watershed transform) and abnormality segmentation (Exudates, microaneurysms, haemorrhages, and IRMA) by Triplet half band filter bank (THFB). Then the different features are extracted by Haralick and ADTCWT (Anisotropic Dual Tree Complex Wavelet Transform) methods. Using life choice-based optimizer (LCBO) algorithm, the optimal features are chosen from the mined features. Then the selected features are applied to the optimized hybrid ML (machine learning) classifier with the combination of NN and DCNN (Deep Convolutional Neural Network) in which the SSD (Social Ski-Driver) is utilized for the best weight values of hybrid classifier to categorize the severity level as mild DR, severe DR, normal, moderate DR, and Proliferative DR. The proposed work is simulated in python environment and to test the efficiency of the proposed scheme the datasets like APTOS-2019-Blindness-Detection, and EyePacs are used. The model has been evaluated using different performance metrics. The simulation results verified that the suggested scheme is provides well accuracy for each dataset than other current approaches. © 2022, The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature.",And DIY smartphone enabled camera; Diabetic retinopathy; Machine learning; Optimization; Segmentation; Smartphone
Article,"Li Y.-H., Yeh N.-N., Chen S.-J., Chung Y.-C.",Computer-Assisted Diagnosis for Diabetic Retinopathy Based on Fundus Images Using Deep Convolutional Neural Network,Mobile Information Systems,2019,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85060106388&doi=10.1155%2f2019%2f6142839&partnerID=40&md5=da3a4d4c6b7d9643f6131976b6c6b612,"Diabetic retinopathy (DR) is a complication of long-standing diabetes, which is hard to detect in its early stage because it only shows a few symptoms. Nowadays, the diagnosis of DR usually requires taking digital fundus images, as well as images using optical coherence tomography (OCT). Since OCT equipment is very expensive, it will benefit both the patients and the ophthalmologists if an accurate diagnosis can be made, based solely on reading digital fundus images. In the paper, we present a novel algorithm based on deep convolutional neural network (DCNN). Unlike the traditional DCNN approach, we replace the commonly used max-pooling layers with fractional max-pooling. Two of these DCNNs with a different number of layers are trained to derive more discriminative features for classification. After combining features from metadata of the image and DCNNs, we train a support vector machine (SVM) classifier to learn the underlying boundary of distributions of each class. For the experiments, we used the publicly available DR detection database provided by Kaggle. We used 34,124 training images and 1,000 validation images to build our model and tested with 53,572 testing images. The proposed DR classifier classifies the stages of DR into five categories, labeled with an integer ranging between zero and four. The experimental results show that the proposed method can achieve a recognition rate up to 86.17%, which is higher than previously reported in the literature. In addition to designing a machine learning algorithm, we also develop an app called ""Deep Retina."" Equipped with a handheld ophthalmoscope, the average person can take fundus images by themselves and obtain an immediate result, calculated by our algorithm. It is beneficial for home care, remote medical care, and self-examination. © 2019 Yung-Hui Li et al.",Computer aided diagnosis; Convolution; Eye protection; Learning algorithms; Neural networks; Optical tomography; Support vector machines; Computer assisted diagnosis; Deep convolutional neural networks; Diabetic retinopathy; Digital fundus images; Discriminative features; Number of layers; Recognition rates; Remote medical care; Deep neural networks
Conference Paper,"Ali Mazumder M.S., Hossain T., Mehedi Shamrat F.M.J., Jahan N., Tasnim Z., Khater A.",Deep Learning Approaches for Diabetic Retinopathy Detection by Image Classification,"3rd International Conference on Smart Electronics and Communication, ICOSEC 2022 - Proceedings",2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85143669561&doi=10.1109%2fICOSEC54921.2022.9952159&partnerID=40&md5=fa228ef13bd4277b55bfa5b41e4dc882,"Diabetic retinopathy (DR) is among the most prevalent eye diseases that can result in blindness and vision loss if left untreated. Early detection of vision impairment might slow or stop its progression. Manual diagnosis using retinal fundus images, such as visual acuity testing, pupil dilation, and optical consistency tomography, calls for highly skilled clinicians to identify and assess the significance of numerous smallest details, making this a rigorous, time-consuming, and error-prone task. Consequently, a computer-aided automated process is definitely required. This study proposes an automated strategy for binary classification of DR versus normal retina using gaussian filtered color fundus retinal photos as input. The study employs the Diabetic Retinopathy dataset from Kaggle that includes 3,662 original retinal images with labelling for non-DR and DR. Using Convolutional Neural Network (CNN) architectures, the process can distinguish exudates, microaneurysms, and hemorrhages in retinal imaging by training with labelled data. The study trained and tested five models, InceptionV3, MobileNetV2, ResNet50, VGG16, and VGG19. It is observed that MobileNetV2 stands out as the most effective at detecting DR and Non-DR with and accuracy of 96.04% and Cohen Kappa Score of 92.08%. In the study, the models Resnet50, VGG16 and VGG19 have the same compilation time of 62 seconds for each epoch compared to which MobileNetv2 takes more time with 90 seconds, followed by InceptionV3 with 85 seconds. © 2022 IEEE.",Convolutional Neural Network; Deep Learning; Diabetic Retinopathy; Disease Detection; Fundus Image
Conference Paper,"Lee A., Khushi M., Hao P., Uddin S., Poon S.K.",Grading Diabetic Retinopathy Severity Using Modern Convolution Neural Networks (CNN),"Proceedings - 2021 IEEE International Conference on Digital Health, ICDH 2021",2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85119521556&doi=10.1109%2fICDH52753.2021.00014&partnerID=40&md5=81a75dd1bce7a56247f74870736b33ac,"Diabetic Retinopathy is an ophthalmic complication eventuating with impaired vision or even blindness if left unmanaged. In modern society, ophthalmologists are responsible for diagnosing diabetic retinopathy to prevent such outcomes. However, medical costs and the availability of clinicians are just some of the barriers of entry to these services. Portable and more automated solutions could find immediate effectiveness in remote areas and developing countries lacking necessary medical infrastructure. Over time, various computer vision-based techniques have been proposed to automatically diagnose diabetic retinopathy. However, grading diabetic retinopathy in its different stages is still yet to reach the required clinical precision. In this paper, we developed a solution to this problem by image processing followed by ensembling state of the art Convolution Neural Networks (CNNs). We demonstrate the effectiveness of the developed method on publicly available datasets and show that the method outperforms previous studies in multi-classification metrics, achieving accuracies for 5-classes of up to 88.71 % and quadratic weighted kappa scores of up to 0.9256. These outcomes provide promising validation for the clinical relevance and applicability of modern CNN architectures as automated, portable and accurate solutions for the grading of diabetic retinopathy severity. © 2021 IEEE.",CNN; Convolution Neural Networks; Deep Learning; Diabetic Retinopathy; EfficientNet; Fundus Camera Imaging
Article,"Lee T., Hu M., Gao Q., Amason J., Borkar D., D'Alessio D., Canos M., Shariff A., Pajic M., Hadziahmetovic M.",Evaluation of a deep learning supported remote diagnosis model for identification of diabetic retinopathy using wide-field Optomap,Annals of Eye Science,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85132434953&doi=10.21037%2faes-21-53&partnerID=40&md5=b032b3a64512a2570598290df83e6f0f,"Background: We test a deep learning (DL) supported remote diagnosis approach to detect diabetic retinopathy (DR) and other referable retinal pathologies using ultra-wide-field (UWF) Optomap. Methods: Prospective, non-randomized study involving diabetic patients seen at endocrinology clinics. Non-expert imagers were trained to obtain non-dilated images using UWF Primary. Images were graded by two retina specialists and classified as DR or incidental retinal findings. Cohen's kappa was used to test the agreement between the remote diagnosis and the gold standard exam. A novel DL model was trained to identify the presence or absence of referable pathology, and sensitivity, specificity and area under the receiver operator characteristics curve (AUROC) were used to assess its performance. Results: A total of 265 patients were enrolled, of which 241 patients were imaged (433 eyes). The mean age was 50±17 years, 45% of patients were female, 34% had a diagnosis of diabetes mellitus type 1, and 66% of type 2. The average Hemoglobin A1c was 8.8±2.3%, and 81% were on Insulin. Of the 433 images, 404 (93%) were gradable, 64 patients (27%) were referred to a retina specialist, and 46 (19%) were referred to comprehensive ophthalmologist for a referable retinal pathology on remote diagnosis. Cohen's kappa was 0.58, indicating moderate agreement. Our DL algorithm achieved an accuracy of 82.8% (95% CI: 80.3-85.2%), a sensitivity of 81.0% (95% CI: 78.5-83.6%), specificity of 73.5% (95% CI: 70.6-76.3%), and AUROC of 81.0% (95% CI: 78.5-83.6%). Conclusions: UWF Primary can be used in the non-ophthalmology setting to screen for referable retinal pathology and can be successfully supported by an automated algorithm for image classification. © 2022 AME Publishing Company. All rights reserved.",deep learning (DL); diabetic retinopathy (DR); imaging; Retina; screening
Article,"Alam M., Le D., Lim J.I., Chan R.V.P., Yao X.",Supervised machine learning based multi-task artificial intelligence classification of retinopathies,Journal of Clinical Medicine,2019,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85077722152&doi=10.3390%2fjcm8060872&partnerID=40&md5=7b81756b8ead2cd19dd010136969e364,"Artificial intelligence (AI) classification holds promise as a novel and affordable screening tool for clinical management of ocular diseases. Rural and underserved areas, which suffer from lack of access to experienced ophthalmologists may particularly benefit from this technology. Quantitative optical coherence tomography angiography (OCTA) imaging provides excellent capability to identify subtle vascular distortions, which are useful for classifying retinovascular diseases. However, application of AI for differentiation and classification of multiple eye diseases is not yet established. In this study, we demonstrate supervised machine learning based multi-task OCTA classification. We sought 1) to differentiate normal from diseased ocular conditions, 2) to differentiate different ocular disease conditions from each other, and 3) to stage the severity of each ocular condition. Quantitative OCTA features, including blood vessel tortuosity (BVT), blood vascular caliber (BVC), vessel perimeter index (VPI), blood vessel density (BVD), foveal avascular zone (FAZ) area (FAZ-A), and FAZ contour irregularity (FAZ-CI) were fully automatically extracted from the OCTA images. A stepwise backward elimination approach was employed to identify sensitive OCTA features and optimal-feature-combinations for the multi-task classification. For proof-of-concept demonstration, diabetic retinopathy (DR) and sickle cell retinopathy (SCR) were used to validate the supervised machine leaning classifier. The presented AI classification methodology is applicable and can be readily extended to other ocular diseases, holding promise to enable a mass-screening platform for clinical deployment and telemedicine. © 2019 by the authors. Licensee MDPI, Basel, Switzerland.",Artificial intelligence; Computer aided diagnosis; Diabetic retinopathy; Ophthalmology; Optical coherence tomography angiography; Quantitative analysis; Sickle cell retinopathy; Support vector machine
Article,"Purna Chandra Reddy V., Gurrala K.K.",OHGCNet: Optimal feature selection-based hybrid graph convolutional network model for joint DR-DME classification,Biomedical Signal Processing and Control,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85134680959&doi=10.1016%2fj.bspc.2022.103952&partnerID=40&md5=1020f17b34161b3baefb6f50cd14e5af,"Diabetic retinopathy (DR) is the crucial eye disease, which effects the blood vessels of the patient suffering with diabetes. The Diabetic macular edema (DME) is another crucial disease, that arises when DR reaches and damages the macula, resulting in fluid buildup in the retina. Individual, and joint screening methods of these DME, and DR require experts to manually analyze color eye fundus images. However, developing an efficient screening-oriented therapy is a time-consuming and costly endeavor because of the difficult nature of the screening approach and a scarcity of qualified human resources. In addition, automated systems are attempting to deal with these issues, and standard machine learning and deep learning processes have failed to fulfil the required criterion of performance and accuracy. Thus, this article focuses on the implementation of graph learning-based graph convolutional network (GCN) for the classification of joint DR-DME with enhanced accuracy. Initially, hybrid GCN (HGCN) with relation aware channel-spatial attention (RACSA) model is developed for extracting the deep features of individual DME, DR, and joint DR-DME. Further, a novel bio-optimization approach named modified deer hunting optimization algorithm (MDHOA) is employed as an optimal feature selection technique for the extraction of salient features. Finally, HGCN is utilized as a classifier for the classification of individual DME, DR, and joint DR-DME diseases. The extensive simulations conducted on IDRiD dataset shows that proposed OHGCNet performed superior as compared to the conventional methods with the improvement in classification accuracy as 5.11%, 3.88%, and 5.47% for DME, DR, and joint DR-DME. Furthermore, the performance of proposed OHGCNet also compared with the ISBI-sub challenge 2 and resulted in superior position as compared with leadership contenders. © 2022 Elsevier Ltd",Convolutional neural network; Deer hunting optimization; Diabetic macular edema; Diabetic retinopathy; Graph convolutional network; Graph learning
Article,"Ashraf M.N., Hussain M., Habib Z.",Deep Red Lesion Classification for Early Screening of Diabetic Retinopathy,Mathematics,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85125461573&doi=10.3390%2fmath10050686&partnerID=40&md5=27e9ec1150e5ee62450ac3b32e47da9e,"Diabetic retinopathy (DR) is an asymptotic and vision-threatening complication among working-age adults. To prevent blindness, a deep convolutional neural network (CNN) based diagnosis can help to classify less-discriminative and small-sized red lesions in early screening of DR patients. However, training deep models with minimal data is a challenging task. Fine-tuning through transfer learning is a useful alternative, but performance degradation, overfitting, and domain adaptation issues further demand architectural amendments to effectively train deep models. Various pre-trained CNNs are fine-tuned on an augmented set of image patches. The best-performing ResNet50 model is modified by introducing reinforced skip connections, a global max-pooling layer, and the sum-of-squared-error loss function. The performance of the modified model (DR-ResNet50) on five public datasets is found to be better than state-of-the-art methods in terms of well-known metrics. The highest scores (0.9851, 0.991, 0.991, 0.991, 0.991, 0.9939, 0.0029, 0.9879, and 0.9879) for sensitivity, specificity, AUC, accuracy, precision, F1-score, false-positive rate, Matthews’s correlation coefficient, and kappa coefficient are obtained within a 95% confidence interval for unseen test instances from e-Ophtha_MA. This high sensitivity and low false-positive rate demonstrate the worth of a proposed framework. It is suitable for early screening due to its performance, simplicity, and robustness. © 2022 by the authors. Licensee MDPI, Basel, Switzerland.",Computer-aided diagnosis; Convolutional neural networks; Deep residual networks; Diabetic retinopathy; Red lesions; Skip connections
Article,"Zong Y., Chen J., Yang L., Tao S., Aoma C., Zhao J., Wang S.",U-net based method for automatic hard exudates segmentation in fundus images using inception module and residual connection,IEEE Access,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102875528&doi=10.1109%2fACCESS.2020.3023273&partnerID=40&md5=49a078c7d760ca3a428fe495630c5370,"Diabetic retinopathy (DR) is an eye abnormality caused by chronic diabetes that affected patients worldwide. Hard exudate is an important and observable sign of DR and can be used for early diagnosis. In this paper, an automatic hard exudates segmentation method is proposed in order to aid ophthalmologists to diagnose DR in the early stage. We utilized the SLIC superpixel algorithm to generate sample patches, thus overcoming the difficulty of the limited and imbalanced dataset. Furthermore, a U-net based network architecture with inception modules and residual connections is proposed to conduct end-to-end hard exudate segmentation, and focal loss is utilized as the loss function. Extensive experiments have been conducted on the IDRiD dataset to evaluate the performance of the proposed method. The reported sensitivity, specificity, and accuracy achieve 96.38%, 97.14%, and 97.95% respectively, which demonstrates the effectiveness and superiority of our method. The achieved segmentation results prove the potential of the method for clinical diagnosis. © 2020 Institute of Electrical and Electronics Engineers Inc.. All rights reserved.",Deep learning; Diabetic retinopathy; Exudates segmentation; Superpixel; U-net
Article,"Wang H., Yuan G., Zhao X., Peng L., Wang Z., He Y., Qu C., Peng Z.",Hard exudate detection based on deep model learned information and multi-feature joint representation for diabetic retinopathy screening,Computer Methods and Programs in Biomedicine,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85079847260&doi=10.1016%2fj.cmpb.2020.105398&partnerID=40&md5=da7b0425e2b61d9e8adc8e30f01c8844,"Background and objective: Diabetic retinopathy (DR), which is generally diagnosed by the presence of hemorrhages and hard exudates, is one of the most prevalent causes of visual impairment and blindness. Early detection of hard exudates (HEs) in color fundus photographs can help in preventing such destructive damage. However, this is a challenging task due to high intra-class diversity and high similarity with other structures in the fundus images. Most of the existing methods for detecting HEs are based on characterizing HEs using hand crafted features (HCFs) only, which can not characterize HEs accurately. Deep learning methods are scarce in this domain because they require large-scale sample sets for training which are not generally available for most routine medical imaging research. Methods: To address these challenges, we propose a novel methodology for HE detection using deep convolutional neural network (DCNN) and multi-feature joint representation. Specifically, we present a new optimized mathematical morphological approach that first segments HE candidates accurately. Then, each candidate is characterized using combined features based on deep features with HCFs incorporated, which is implemented by a ridge regression-based feature fusion. This method employs multi-space-based intensity features, geometric features, a gray-level co-occurrence matrix (GLCM)-based texture descriptor, a gray-level size zone matrix (GLSZM)-based texture descriptor to construct HCFs, and a DCNN to automatically learn the deep information of HE. Finally, a random forest is employed to identify the true HEs among candidates. Results: The proposed method is evaluated on two benchmark databases. It obtains an F-score of 0.8929 with an area under curve (AUC) of 0.9644 on the e-optha database and an F-score of 0.9326 with an AUC of 0.9323 on the HEI-MED database. These results demonstrate that our approach outperforms state-of-the-art methods. Our model also proves to be suitable for clinical applications based on private clinical images from a local hospital. Conclusions: This newly proposed method integrates the traditional HCFs and deep features learned from DCNN for detecting HEs. It achieves a new state-of-the-art in both detecting HEs and DR screening. Furthermore, the proposed feature selection and fusion strategy reduces feature dimension and improves HE detection performance. © 2020",Convolutional neural network; Fundus images; Hard exudate detection; Multi-feature joint representation
Conference Paper,"Patel S., Lohakare M., Prajapati S., Singh S., Patel N.",DiaRet: A Browser-Based Application for the Grading of Diabetic Retinopathy with Integrated Gradients,"2021 IEEE International Conference on Robotics, Automation and Artificial Intelligence, RAAI 2021",2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85124885468&doi=10.1109%2fRAAI52226.2021.9507938&partnerID=40&md5=a3f1fda2ae3716a1ef6e6fc5cd46c5be,"Patients with long-standing diabetes often fall prey to Diabetic Retinopathy (DR) resulting in changes in the retina of the human eye, which may lead to loss of vision in extreme cases. The aim of this study is two-fold: (a) create deep learning models that were trained to grade degraded retinal fundus images and (b) to create a browser-based application that will aid in diagnostic procedures by highlighting the key features of the fundus image. In this research work, we have emulated the images plagued by distortions by degrading the images based on multiple different combinations of Light Transmission Disturbance, Image Blurring and insertion of Retinal Artifacts. InceptionV3, ResNet-50 and InceptionResNetV2 were trained and used to classify retinal fundus images based on their severity level and then further used in the creation of a browser-based application, which implements the Integration Gradient (IG) Attribution Mask on the input image and demonstrates the predictions made by the model and the probability associated with each class. ©2021 IEEE",Attention Mechanism; Computer-aided Diagnosis; Deep Learning; Diabetic Retinopathy; Explainable AI; Integrated Gradients
Article,"Abbood S.H., Hamed H.N.A., Rahim M.S.M., Alaidi A.H.M., ALRikabi H.T.S.",DR-LL Gan: Diabetic Retinopathy Lesions Synthesis using Generative Adversarial Network,International journal of online and biomedical engineering,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85126703872&doi=10.3991%2fijoe.v18i03.28005&partnerID=40&md5=528bed018832c15979b02487b77dac81,"Diabetic Retinopathy (DR) is a serious consequence of diabetes that seriously impact on the eyes and is a leading cause of blindness. If the lesions in DR arise in the central portion of the fundus, they may result in significant vision loss, which we refer to as Diabetic Macular Edema (DME). Deep learning (DL) techniques are commonly used utilized in ophthalmology for discriminative tasks such as diabetic retinopathy or age-related macular degeneration (AMD) diagnosis. Deep learning techniques typically need huge picture data sets for deep convolutional neural networks (DCNNs) training, it should be graded by human specialists. According to international protocol, it is classified into five severity categories. However, improving a grading model for high generality needs a significant quantity of balanced training data, which is challenging to obtain, especially at high levels of severity. Typical techniques for data augmentation, in many applications of deep learning in the retinal image processing domain, the difficulty of access to huge annotated datasets and legal concerns about patient privacy are limiting issues. As a result, the concept of creating synthetic retinal pictures that are indistinguishable from actual data has garnered more attention. GANs have been certain to be an effective framework for creating synthetic databases of anatomically accurate retinal fundus pictures. GANs, in particular, have garnered increasing attention in ophthalmology. in this article, we present a lossless generative adversarial network (DR-LL GAN) to generate good resolution fundus pictures that May be adjusted to include random grading and information about the lesion. As a result, large-scale generated data may be used to train a DR grading and lesion segmentation model with more appropriate augmentation. Our model experiments evaluated on IDRID and MESSIDOR datasets, it’s obtained a discrimination loss of 0.69374 and a generation loss of 1.10438, as well as a segmentation accuracy of 0.9840 in our tests. This might support in the optimization techniques of the neural network design and in computer-aided screening of medical picture, thus increasing diagnostic reliability for clinical assessment in the future of sophisticated technological healthcare © 2022,International journal of online and biomedical engineering.All Rights Reserved",Dcnn; Diabetic macular edema; Diabetic retinopathy; Dl; Gan
Conference Paper,"Bibi N., Nida N., Irtaza A., Anwar S.M.",Automatic Detection of Exudates for Daignosis of Non-proliferative Diabetic Retinopathy using Region-based Convolutional Neural Networks,"Proceedings - 2021 International Conference on Frontiers of Information Technology, FIT 2021",2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85126991295&doi=10.1109%2fFIT53504.2021.00048&partnerID=40&md5=604e3000668a17d995ae3edebb1fa059,"Diabetic Retinopathy (DR) is a severe visual impairment that grows from mild non-proliferative DR to proliferative DR. Exudates are the earliest sign of NPDR and therefore, an earlier detection of exudates would help in the diagnosis of DR. Towards this, a deep region-based convolutional neural network (RCNN) is adopted in this study to achieve pixel-wise exudate detection using MobileNet as feature extractor from fundus images. In particular, preprocessing of the retinal images is performed, including data augmentation and bounding boxes generation. The goal is to achieve pixel-level accuracy and reduce computational time. The region proposal are generated which are potential exudate candidate points within the training fundus images. Further, the local region surrounding the candidate points is forwarded to the deep RCNN for model learning and exudate detection. The proposed model is evaluated using two publicly available datasets including DIARETDB1 and e-Ophtha. Our method achieves sensitivity and specificity values of 0.98 and 0.94, respectively for DIARETDB1 data, while for e-Ophtha sensitivity and specificity is 0.96 and 0.99, respectively. © 2021 IEEE.",DCNN; EXUDATE DETECTION; NPDR; RCNN; REGION PROPOSAL
Article,"Luo L., Xue D., Feng X.",Automatic diabetic retinopathy grading via self-knowledge distillation,Electronics (Switzerland),2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85089662581&doi=10.3390%2felectronics9091337&partnerID=40&md5=28feac9fa928f20bacb83381c088d120,"Diabetic retinopathy (DR) is a common fundus disease that leads to irreversible blindness, which plagues the working-age population. Automatic medical imaging diagnosis provides a non-invasive method to assist ophthalmologists in timely screening of suspected DR cases, which prevents its further deterioration. However, the state-of-the-art deep-learning-based methods generally have a large amount of model parameters, which makes large-scale clinical deployment a time-consuming task. Moreover, the severity of DR is associated with lesions, and it is difficult for the model to focus on these regions. In this paper, we propose a novel deep-learning technique for grading DR with only image-level supervision. Specifically, we first customize the model with the help of self-knowledge distillation to achieve a trade-off between model performance and time complexity. Secondly, CAM-Attention is used to allow the network to focus on discriminative zone, e.g., microaneurysms, soft/hard exudates, etc.. Considering that directly attaching a classifier after the Side branch will disrupt the hierarchical nature of convolutional neural networks, a Mimicking Module is employed that allows the Side branch to actively mimic the main branch structure. Extensive experiments are conducted on two benchmark datasets, with an AUC of 0.965 and an accuracy of 92.9% for the Messidor dataset and 67.96% accuracy achieved for the challenging IDRID dataset, which demonstrates the superior performance of our proposed method. © 2020 by the authors. Licensee MDPI, Basel, Switzerland.",Attention mechanism; Convolutional neural network (CNN); Diabetic retinopathy (DR); Image classification; Self-knowledge distillation (SKD)
Article,"Elmoufidi A., Skouta A., Jai-andaloussi S., Ouchetto O.",Deep multiple instance learning for automatic glaucoma prevention and auto-annotation using color fundus photography,Progress in Artificial Intelligence,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85138383809&doi=10.1007%2fs13748-022-00292-4&partnerID=40&md5=bd2a3565d644dd8217ab950b493fabab,"In the area of ophthalmology, glaucoma affects an increasing number of people. It is a major cause of blindness. Early detection prevents severe ocular complications such as glaucoma, cystoid macular edema, or diabetic proliferative retinopathy. Intelligent systems are proven to be beneficial for the assessment of glaucoma. In this paper, we describe an approach to automate the diagnosis of glaucoma disease, based on color funds photography using deep learning. The setup of the proposed framework is ordered as follows: The bidimensional empirical mode decomposition (BEMD) algorithm is applied to decompose the ROI to components (BIMFs + residue). CNN architecture VGG19 is implemented to extract features from decomposed BEMD components. The features obtained are the input parameters of the implemented classifier based on full connect layers and softmax. To train the built model, we have used the public dataset RIM-ONE DL. To test our models, we have used a part of RIM-ONE DL and REFUGE. The average obtained sensitivity, specificity, accuracy and AUC rates are, respectively, 99.14%, 99.19%, 99.13%, 99.09% and 99.17%, 99.24%, 99.20%, 99.18% in RIM-ONE DL and REFUGE dataset. The experimental results obtained from different datasets demonstrate the efficiency and robustness of the proposed approach. A comparison with some recent previous work in the literature has shown a significant advancement in our proposal. © 2022, Springer-Verlag GmbH Germany, part of Springer Nature.",Computer-aided diagnosis; Convolutional neural networks (CNNs); Deep learning; Glaucoma; Machine learning; Medical imaging; Ophthalmology
Conference Paper,"Wang X., Ju L., Zhao X., Ge Z.",Retinal abnormalities recognition using regional multitask learning,Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),2019,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85075640409&doi=10.1007%2f978-3-030-32239-7_4&partnerID=40&md5=813b2a0672b55fe630a49b6f0686826b,"The number of people suffering from retinal diseases increases with population aging and the popularity of electronic screens. Previous studies on deep learning based automatic screening generally focused on specific types of retinal diseases, such as diabetic retinopathy and glaucoma. Since patients may suffer from various types of retinal diseases simultaneously, these solutions are not clinically practical. To address this issue, we propose a novel deep learning based method that can recognise 36 different retinal diseases with a single model. More specifically, the proposed method uses a region-specific multi-task recognition model by learning diseases affecting different regions of the retina with three sub-networks. The three sub-networks are semantically trained to recognise diseases affecting optic-disc, macula and entire retina. Our contribution is two-fold. First, we use multitask learning for retinal disease classification and achieve significant improvements for recognising three main groups of retinal diseases in general, macular and optic-disc regions. Second, we collect a multi-label retinal dataset to the community as standard benchmark and release it for further research opportunities. © 2019, Springer Nature Switzerland AG.",Deep learning; Diagnosis; Eye protection; Medical computing; Medical imaging; Multi-task learning; Ophthalmology; Automatic screening; Diabetic retinopathy; Learning-based methods; Number of peoples; Population aging; Research opportunities; Retinal disease; Single models; Learning systems
Article,"Banupriya V., Anusuya S.",Improving Classification of Retinal Fundus Image Using Flow Dynamics Optimized Deep Learning Methods,SSRG International Journal of Electrical and Electronics Engineering,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85145374981&doi=10.14445%2f23488379%2fIJEEE-V9I12P104&partnerID=40&md5=503c16cb1c51487923ebb760ae132418,"Diabetic Retinopathy (DR) refers to a barrier that takes place in diabetes mellitus damaging the blood vessel network present in the retina. This may endanger the subjects' vision if they have diabetes. It can take some time to perform a DR diagnosis using color fundus pictures because experienced clinicians are required to identify the tumors in the imagery used to identify the illness. Automated detection of the DR can be an extremely challenging task. Convolutional Neural Networks (CNN) are also highly effective at classifying images when applied in the present situation, particularly compared to the handmade and functionality methods employed. In order to guarantee high results, the researchers also suggested a cutting-edge CNN model that might determine the characteristics of the fundus images. The features of the CNN output were employed in various classifiers of machine learning for the proposed system. This model was later evaluated using different forms of deep learning methods and Visual Geometry Group (VGG) networks). It was done by employing the images from a generic KAGGLE dataset. Here, the River Formation Dynamics (RFD) algorithm proposed along with the FUNDNET to detect retinal fundus images has been employed. The investigation's findings demonstrated that the approach performed better than alternative approaches. © 2022 Seventh Sense Research Group®.",Deep Learning (DL); Diabetic Retinopathy (DR); Residual Networks (ResNet); Retinal Fundus Images; River Formation Dynamics (RFD); Visual Geometry Group (VGG) Network
Conference Paper,"Poh C.Y., Teoh S.S.","Performance Evaluation of Optic Disc Detection Using Faster RCNN with Alexnet, Resnet50 and Vgg19 Convolutional Neural Networks",Lecture Notes in Electrical Engineering,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85125249033&doi=10.1007%2f978-981-16-8129-5_115&partnerID=40&md5=5672dd1ba619df0c160f431fc5ba311a,"Automatic detection of optic disc (OD) from retinal images is essential in the diagnosis of diabetic retinopathy (DR) and other eye diseases. For example, it is used in the detection of glaucoma and neovascularization on the optic disc. In this paper, the application of deep learning for automatic detection of OD from fundus images is investigated. The methods investigated are Faster Region Convolutional Neural Network (Faster RCNN) using three different pre-trained networks: Alexnet, Resnet50 and Vgg19. The effect of using input images in RGB and CIEXYZ formats on the detection performance is also evaluated. The performance is compared using four metrics: precision, sensitivity, miss rate and processing time. Fundus image dataset from DIABETDB0 is used in the evaluation. The experiment results show that using Faster RCNN and a pre-trained network with deeper convolutional layers gives better results for OD detection. Faster RCNN with Restnet50 network produced the best overall results with the highest precision and sensitivity (1.0000 and 0.9474 respectively), and the lowest miss rate (0.0526). It was also found that using input image in CIEXYZ format can give better results compared to RGB image. © 2022, The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd.",Deep learning; Diabetic retinopathy; Faster RCNN; Fundus image analysis; Optic disc detection
Article,"Liu Y.-P., Li Z., Xu C., Li J., Liang R.",Referable diabetic retinopathy identification from eye fundus images with weighted path for convolutional neural network,Artificial Intelligence in Medicine,2019,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85070416651&doi=10.1016%2fj.artmed.2019.07.002&partnerID=40&md5=9f18ede0d2c626a84f5608e85c20e74f,"Diabetic retinopathy (DR) is the most common cause of blindness in middle-age subjects and low DR screening rates demonstrates the need for an automated image assessment system, which can benefit from the development of deep learning techniques. Therefore, the effective classification performance is significant in favor of the referable DR identification task. In this paper, we propose a new strategy, which applies multiple weighted paths into convolutional neural network, called the WP-CNN, motivated by the ensemble learning. In WP-CNN, multiple path weight coefficients are optimized by back propagation, and the output features are averaged for redundancy reduction and fast convergence. The experiment results show that with the efficient training convergence rate WP-CNN achieves an accuracy of 94.23% with sensitivity of 90.94%, specificity of 95.74%, an area under the receiver operating curve of 0.9823 and F1-score of 0.9087. By taking full advantage of the multipath mechanism, the proposed WP-CNN is shown to be accurate and effective for referable DR identification compared to the state-of-art algorithms. © 2019",Convolutional neural network; Deep learning; Diabetic retinopathy; Eye fundus images
Article,"Mohammedhasan M., Uğuz H.",A new early stage diabetic retinopathy diagnosis model using deep convolutional neural networks and principal component analysis,Traitement du Signal,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097652938&doi=10.18280%2fts.370503&partnerID=40&md5=58f1d40e98dbba28984e4d92dc7bbf21,"Diabetic retinopathy (DR) is a disease of the retina, which leads over time to vision problems such retinal detachment, vitreous hemorrhage, glaucoma, and in worse cases leads to blindness, which can initially be controlled by periodic DR-screening. Early diagnosis will lead to greater control of the disease, whereas performing retinal examinations on all diabetic patients is an unattainable need, as diabetes is a chronic disease and its global prevalence has been steadily increasing over the past few decades. According to recent World Health Organization statistics, about 422 million people worldwide have diabetes, the majority living in low-and middle-income countries. This paper proposes a new strategy that brings the strength of convolutional neural networks (CNNs) to the diagnosis of DR. Coupled with using principal component analysis (PCA) that performs dimension reduction to improve the diagnostic accuracy, the proposed model exploiting edge-preserving guided image filtering (E-GIF) that performs as a contrast enhancement mechanism, and in addition to smoothing low gradient areas, it also accentuates strong edges. Diabetic retinopathy causes progressive damage to the blood vessels in the retina to the extent that it leaves traces and lesions in the tissues of the retina. These lesions appear in the form of edges and when processing retinal images, we seek to accentuate these edges to enable better diagnosis of diabetic retinopathy symptoms. A new CNN architecture with residual connections is used, which performs very well in diagnosing DR. The proposed model is named with RUnet-PCA: Residual U-net Deep CNN with Principal Component Analysis. The well-known AlexNet, VggNet-s, VggNet-16, VggNet-19, GoogleNet, and ResNet models were adopted for comparison with the proposed model. Publicly available Kaggle dataset was employed for training exploring the DR diagnosis accuracy. Experimental results show that the proposed RUnet-PCA model achieved a diagnosis accuracy of 98.44% and it was extremely robust and promising in comparison to other diagnosis methods. © 2020 Lavoisier. All rights reserved.",Convolutional neural network; Data augmentation; Deep learning; Diabetic retinopathy; Edge-preserving guided image filtering; Principal component analysis; U-network
Conference Paper,"Auccahuasi W., Flores E., Sernaque F., Cueva J., Diaz M., Oré E.",Recognition of hard exudates using Deep Learning,Procedia Computer Science,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85084467173&doi=10.1016%2fj.procs.2020.03.287&partnerID=40&md5=0d544c66c153595687383234dac5056b,"Diabetes Mellitus is a metabolic disease characterized by the presence of elevated blood glucose levels. Diabetes itself causes other chronic complications, including an eye disease known as diabetic retinopathy. Nowadays, diabetic retinopathy is the most frequent cause of blindness among the active population of developed countries. The principles that produce this disease are not completely known and can not yet be prevented. However, there are effective treatments that delay their evolution as long as it is diagnosed with sufficient anticipation. The problem of diabetic retinopathy is that it is an asymptomatic disease and only defects appear in the vision at an advanced stage of the disease. So in the early stages of diabetic retinopathy is usually imperceptible, diabetic patients do not realize that they have the disease and do not undergo an eye examination. Sometimes the patient is examined when it is too late for proper treatment, due to the presence of severe damage to the retina, occurring only the diagnosis of Diabetes. Currently, technology is becoming more important in the field of health, due to this, a series of systems have been designed to help decision making that helps in the early detection of diabetic retinopathy through the images of Eye, in the present work we present a methodology to be able to recognize the hard exudates that is the first manifestation of diabetic retinopathy, by presenting coloration similar to the other anatomical forms of the eye, its automatic recognition is complicated, the methodology that is presented consists of the use of a database of fundus images with positive and negative symptoms of diabetic retinopathy, from this database a set of images is created that correspond to the hard exudates and images that do not correspond to the hard exudates, with this set of images creates a convolutional network, in order to improve the recognition, obtaining sultados that can satisfy in the clinical practice. © 2020 The Authors. Published by Elsevier B.V.",Diabetes Mellitus; features; images; processing; retinography; segmentation
Conference Paper,"Wang L., Huang Y., Lin B., Wu W., Chen H., Pu J.",Automatic classification of exudates in color fundus images using an augmented deep learning procedure,ACM International Conference Proceeding Series,2019,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85077613413&doi=10.1145%2f3364836.3364843&partnerID=40&md5=34b18ab314387222c0a37a033a305c52,"Automatic classification of hard and soft exudates in color fundus images is very helpful for computer-aided diagnosis of retina related diseases, such as diabetic retinopathy (DR). In this study, we developed a novel method for this purpose based on the emerging deep learning technology known as convolutional neural networks (CNNs) by leveraging its strength of explicitly extracting the underlying image textures. We specifically investigate whether the emphasis of the image characteristic within an exudate spot could improve the classification performance. To verify this, we collected a database of fundus image that contains soft and hard exudates. The exudate regions were cropped from fundus images. There are a total of 550 cropped image patches (275 hard and 275 soft) with a fixed dimension of 128×128 pixels. These patches were further thresholded to exclude image background, resulting in another version of image patches merely containing exudate regions. Each version of image patches was randomly divided into 440 for training and 110 for testing, and then fed into the developed deep learning network in a separate or combinatorial way. Experimental results showed that the classification accuracy of this method was 93.41% when the thresholded version of the dataset was used as an augmented learning procedure, as compared to 90.80% and 87.41% when the original and background excluded datasets were used for training, respectively. This suggests that the augmented CNN can provide more accurate classification performance when the region-of-interest (ROI) and the original images were integrated. © 2019 Association for Computing Machinery.",Color fundus images; Convolutional neural networks; Diabetic retinopathy; Exudate classification
Article,"Suganthi S.R.L., Sneha U.K., Shwetha S.",Diabetic retinopathy classification using machine learning techniques,International Journal of Engineering Trends and Technology,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85086658332&doi=10.14445%2f22315381%2fIJETT-V68I1P207&partnerID=40&md5=6fec20a5ce9cfc9c8d5a1184445fdf60,"Diabetic Retinopathy is an eye disease which is caused due to long term diabetes. It is one of the major complications of diabetes that affects the blood vessels by causing damage to the light-sensitive tissue. The working age population is largely affected by this disease. At first diabetic retinopathy may cause no symptoms at all. But eventually, it can result in blindness. Ophthalmology is a branch of medicine and surgery that deals with the diagnosis and treatment of eye disorders. The Ophthalmologists use the eye images of the patients to detect and advise preventive care for eye disorders. Using fundus camera the patient's eye image is acquired as these Eye images are the primary data source for the classification. The images in its original form may not reveal the necessary features that are used for the purpose of classification. Thus, to apply machine learning algorithms, various attributes from the eye image are extracted using the domain knowledge to reveal different characteristics of the disease pattern. Automatic classification using machine learning techniques are generally rigid. Deep learning technique has been used for automatic classification and prediction with high accuracy. The pre-processed eye image data set is used to train the classifier for binary classification to infer the patient's eye as an infected eye or a normal eye. The model has been evaluated using various measures namely, Precision, Recall, and F-Score. The severity of the disease is measured and classified into different categories using machine learning algorithms. © 2020 Seventh Sense Research Group. All rights reserved.",CNN; Decision Tree classifier; Deep Learning; Diabetic Retinopathy; Machine Learning; Random Forest; ROI; Support Vector Machine
Conference Paper,"Mary Dayana A., Sam Emmanuel W.R.",Attention-Based Deep Fusion Network for Retinal Lesion Segmentation in Fundus Image,Communications in Computer and Information Science,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85118982894&doi=10.1007%2f978-3-030-81462-5_36&partnerID=40&md5=1baf97219ee462d7b3f6b06a8099ae97,"Segmentation of subtle lesions in fundus images has become a vital part of diagnosing ocular diseases such as Diabetic Retinopathy (DR). Diabetic eye disease is characterized by the scattered lesions in the retina. Detection of these lesions at the early stage is important as its progression leads to vision loss if proper treatment is not taken. The main objective of the work is to assist ophthalmologist in the effective diagnosis of eye disease providing timely treatment. This paper focuses on developing a deep learning-based Fusion Network (Fu-Net) with an attention mechanism for lesion segmentation in color fundus images. The network was developed based on the baseline U-Net model with trivial modification in the encoder and decoder part of the model. A multi-feature fusion block (MFuse) is integrated with the encoder of the network to extract the lesion features and a channel attention module is integrated with the decoder part to fuse the feature information effectively. Besides, a modified weighted focal loss function is introduced to mitigate the problem of class imbalance in the fundus image. The computational results obtained signifies the superior performance of the proposed method in the lesion segmentation task. © 2021, Springer Nature Switzerland AG.",Channel attention module; Diabetic Retinopathy; Fusion network; Segmentation
Article,"Sudha V., Ganeshbabu T.R.",A convolutional neural network classifier VGG-19 architecture for lesion detection and grading in diabetic retinopathy based on deep learning,"Computers, Materials and Continua",2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85096461675&doi=10.32604%2fcmc.2020.012008&partnerID=40&md5=10f4b9e351acf62eb1be891805468068,"Diabetic Retinopathy (DR) is a type of disease in eyes as a result of a diabetic condition that ends up damaging the retina, leading to blindness or loss of vision. Morphological and physiological retinal variations involving slowdown of blood flow in the retina, elevation of leukocyte cohesion, basement membrane dystrophy, and decline of pericyte cells, develop. As DR in its initial stage has no symptoms, early detection and automated diagnosis can prevent further visual damage. In this research, using a Deep Neural Network (DNN), segmentation methods are proposed to detect the retinal defects such as exudates, hemorrhages, microaneurysms from digital fundus images and then the conditions are classified accurately to identify the grades as mild, moderate, severe, no PDR, PDR in DR. Initially, saliency detection is applied on color images to detect maximum salient foreground objects from the background. Next, structure tensor is applied powerfully to enhance the local patterns of edge elements and intensity changes that occur on edges of the object. Finally, active contours approximation is performed using gradient descent to segment the lesions from the images. Afterwards, the output images from the proposed segmentation process are subjected to evaluate the ratio between the total contour area and the total true contour arc length to label the classes as mild, moderate, severe, No PDR and PDR. Based on the computed ratio obtained from segmented images, the severity levels were identified. Meanwhile, statistical parameters like the mean and the standard deviation of pixel intensities, mean of hue, saturation and deviation clustering, are estimated through K-means, which are computed as features from the output images of the proposed segmentation process. Using these derived feature sets as input to the classifier, the classification of DR was performed. Finally, a VGG-19 deep neural network was trained and tested using the derived feature sets from the KAGGLE fundus image dataset containing 35,126 images in total. The VGG-19 is trained with features extracted from 20,000 images and tested with features extracted from 5,000 images to achieve a sensitivity of 82% and an accuracy of 96%. The proposed system was able to label and classify DR grades automatically. © 2020 Tech Science Press. All rights reserved.",Diabetic retinopathy; Exudates; Gradient descent method; Haemorrhages; Microaneurysms; Saliency map; Structure tensor; VGG-19
Article,"Chen Y., Long J., Guo J.",RF-GANs: A Method to Synthesize Retinal Fundus Images Based on Generative Adversarial Network,Computational Intelligence and Neuroscience,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85119991771&doi=10.1155%2f2021%2f3812865&partnerID=40&md5=4be64fac4fd4f70ba7188308f02e3841,"Diabetic retinopathy (DR) is a diabetic complication affecting the eyes, which is the main cause of blindness in young and middle-aged people. In order to speed up the diagnosis of DR, a mass of deep learning methods have been used for the detection of this disease, but they failed to attain excellent results due to unbalanced training data, i.e., the lack of DR fundus images. To address the problem of data imbalance, this paper proposes a method dubbed retinal fundus images generative adversarial networks (RF-GANs), which is based on generative adversarial network, to synthesize retinal fundus images. RF-GANs is composed of two generation models, RF-GAN1 and RF-GAN2. Firstly, RF-GAN1 is employed to translate retinal fundus images from source domain (the domain of semantic segmentation datasets) to target domain (the domain of EyePACS dataset connected to Kaggle (EyePACS)). Then, we train the semantic segmentation models with the translated images, and employ the trained models to extract the structural and lesion masks (hereafter, we refer to it as Masks) of EyePACS. Finally, we employ RF-GAN2 to synthesize retinal fundus images using the Masks and DR grading labels. This paper verifies the effectiveness of the method: RF-GAN1 can narrow down the domain gap between different datasets to improve the performance of the segmentation models. RF-GAN2 can synthesize realistic retinal fundus images. Adopting the synthesized images for data augmentation, the accuracy and quadratic weighted kappa of the state-of-the-art DR grading model on the testing set of EyePACS increase by 1.53% and 1.70%, respectively. © 2021 Yu Chen et al.","Deep learning; Diagnosis; Eye protection; Grading; Ophthalmology; Semantic Segmentation; Semantics; Diabetic retinopathy; Diabetic retinopathy grading; Fundus image; Image-based; Learning methods; Retinal fundus images; Segmentation models; Semantic segmentation; Speed up; Training data; Generative adversarial networks; eye fundus; human; image processing; middle aged; Fundus Oculi; Humans; Image Processing, Computer-Assisted; Middle Aged"
Article,"Pin K., Chang J.H., Nam Y.",Comparative study of transfer learning models for retinal disease diagnosis from fundus images,"Computers, Materials and Continua",2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85117062078&doi=10.32604%2fcmc.2022.021943&partnerID=40&md5=5cd1564b1b8e4ff4e1da6818cac89462,"While the usage of digital ocular fundus image has been widespread in ophthalmology practice, the interpretation of the image has been still on the hands of the ophthalmologists which are quite costly. We explored a robust deep learning system that detects three major ocular diseases: diabetic retinopathy (DR), glaucoma (GLC), and age-related macular degeneration (AMD). The proposed method is composed of two steps. First, an initial quality evaluation in the classification system is proposed to filter out poor-quality images to enhance its performance, a technique that has not been explored previously. Second, the transfer learning technique is used with various convolutional neural networks (CNN) models that automatically learn a thousand features in the digital retinal image, and are based on those features for diagnosing eye diseases. Comparison performance of many models is conducted to find the optimal model which fits with fundus classification. Among the different CNN models, DenseNet-201 outperforms others with an area under the receiver operating characteristic curve of 0.99. Furthermore, the corresponding specificities for healthy, DR, GLC, and AMD patients are found to be 89.52%, 96.69%, 89.58%, and 100%, respectively. These results demonstrate that the proposed method can reduce the time-consumption by automatically diagnosing multiple eye diseases using computer-aided assistance tools. © 2022 Tech Science Press. All rights reserved.",Age-related macular degeneration; Deep neural networks; Diabetic retinopathy; Glaucoma; Multiclass classification; Quality evaluation; Transfer learning
Article,"Kaushik H., Singh D., Kaur M., Alshazly H., Zaguia A., Hamam H.",Diabetic Retinopathy Diagnosis from Fundus Images Using Stacked Generalization of Deep Models,IEEE Access,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85111578483&doi=10.1109%2fACCESS.2021.3101142&partnerID=40&md5=b1983d239437495686f8e3b53fe2fda1,"Diabetic retinopathy (DR) is a diabetes complication that affects the eye and can cause damage from mild vision problems to complete blindness. It has been observed that the eye fundus images show various kinds of color aberrations and irrelevant illuminations, which degrade the diagnostic analysis and may hinder the results. In this research, we present a methodology to eliminate these unnecessary reflectance properties of the images using a novel image processing schema and a stacked deep learning technique for the diagnosis. For the luminosity normalization of the image, the gray world color constancy algorithm is implemented which does image desaturation and improves the overall image quality. The effectiveness of the proposed image enhancement technique is evaluated based on the peak signal to noise ratio (PSNR) and mean squared error (MSE) of the normalized image. To develop a deep learning based computer-aided diagnostic system, we present a novel methodology of stacked generalization of convolution neural networks (CNN). Three custom CNN model weights are fed on the top of a single meta-learner classifier, which combines the most optimum weights of the three sub-neural networks to obtain superior metrics of evaluation and robust prediction results. The proposed stacked model reports an overall test accuracy of 97.92% (binary classification) and 87.45% (multi-class classification). Extensive experimental results in terms of accuracy, F-measure, sensitivity, specificity, recall and precision reveal that the proposed methodology of illumination normalization greatly facilitated the deep learning model and yields better results than various state-of-art techniques. © 2013 IEEE.",Convolutional neural networks; diabetic retinopathy; early diagnosis; ensemble learning; fundus images; gray world algorithm
Conference Paper,"Memari N., Abdollahi S., Ganzagh M.M., Moghbel M.",Computer-assisted diagnosis (CAD) system for Diabetic Retinopathy screening using color fundus images using Deep learning,"2020 IEEE Student Conference on Research and Development, SCOReD 2020",2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097733540&doi=10.1109%2fSCOReD50371.2020.9250986&partnerID=40&md5=e7e9d04c6e2d1cc790b18f9202adf88a,"Diabetes is a serious medical condition and regular screening for diabetes is of great importance as treatment options are most effective in the early stages of diabetes. Digital imaging of retina is considered as a low-cost method for screening and could be used in conjunction with computer-based image processing techniques to automatically detect early signs of diabetes utilizing diabetes-related pathologies visible in retinal fundus images. This research proposes a novel computer-assisted diagnosis (CAD) system for assisting with the screening of the population as up to 50% of the affected population are not aware of having diabetes. Moreover, these screenings are often carried out by an optometrist who receives some training with the patients being referred to an ophthalmologist if they show symptoms. Having a computer-assisted diagnosis system assisting the optometrist during the screening can greatly increase the detection rate for patients with diabetes by providing a second opinion and highlighting any suspicious pathologies. For achieving the highest detection rate possible, a hybrid machine learning approach is proposed in this research by combining Deep Learning with the AdaBoost classifier. The proposed computer-assisted diagnosis system starts with the segmentation of the blood vessels. Then, microaneurysms and exudates are segmentation from the image. Statistical and regional features are then extracted utilizing first, second, and higher-order image features. A Deep Learning framework will be utilized for extracting additional statistical image descriptors as a Deep Learning has superior contextual analysis capabilities compared to other machine learning techniques. Finally, the most informative features are selected by a minimal-redundancy maximal-relevance feature selection approach with an AdaBoost classifier analyzing all the features and informing the operator regarding the patient's condition. Ethereum Swarm blockchain-based decentralized cloud file storage provides the proposed CAD users with a secure storage olution to access the patient information and related images. The sensitivity, specificity, and accuracy of the classification will be measured under clinical conditions. Healthcare, government, and public users would receive the most benefit from this project. © 2020 IEEE.",Deep Learning; Diabetic Retinopathy.; Machine Learning; Retinal vessel segmentation
Article,"Wu Y., Xia Y., Song Y., Zhang Y., Cai W.",NFN＋: A novel network followed network for retinal vessel segmentation,Neural Networks,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85082167721&doi=10.1016%2fj.neunet.2020.02.018&partnerID=40&md5=7926430e71f860dcc277058865c920cf,"In the early diagnosis of diabetic retinopathy, the morphological attributes of blood vessels play an essential role to construct a retinal computer-aided diagnosis system. However, due to the challenges including limited densely annotated data, inter-vessel differences and structured prediction problem, it remains challenging to segment accurately the retinal vessels, particularly the capillaries on color fundus images. To address these issues, in this paper, we propose a novel deep learning-based model called NFN＋ to effectively extract multi-scale information and make full use of deep feature maps. In NFN＋, the front network converts an image patch into a probabilistic retinal vessel map, and the followed network further refines the map to achieve a better post-processing module, which helps represent the vessel structures implicitly. We employ the inter-network skip connections to unite two identical multi-scale backbones, which enables the useful multi-scale features to be directly transferred from shallow layers to deeper layers. The refined probabilistic retinal vessel maps produced from the augmented images are then averaged to construct the segmentation results. We evaluated this model on the digital retinal images for vessel extraction (DRIVE), structured analysis of the retina (STARE), and the child heart and health study (CHASE) databases. Our results indicate that the elaborated cascaded designs can produce performance gain and the proposed NFN＋ model, to our best knowledge, achieved the state-of-the-art retinal vessel segmentation accuracy on color fundus images (AUC: 98.30%, 98.75% and 98.94%, respectively). © 2020 Elsevier Ltd",Cascaded networks; Deep learning; Retinal vessel segmentation; Skip connections
Article,"Abdul Rahman A., Biswal B., P G.P., Hasan S., Sairam M.V.S.",Robust segmentation of vascular network using deeply cascaded AReN-UNet,Biomedical Signal Processing and Control,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85109445515&doi=10.1016%2fj.bspc.2021.102953&partnerID=40&md5=8156241914c5c467016543389ebc862c,"Retinal vessel segmentation is an essential step for non-invasive diagnosis and analysis of ocular pathologies such as diabetic retinopathy, glaucoma, etc. Although several deep learning networks have been implemented for segmenting vascular maps, still further modification can be carried out on the existing deep learning networks for precise segmentation of vascular maps. This paper presents a novel cascaded AReN-UNet (Attention Residual U Network), driven by the integration of attention and residual modules. The proposed network is implemented by cascading two deep learning networks of depth 4. In the second network, each encoder receives the feature maps from the previous convolutional block. In addition to this, the feature maps of a respective convolutional block of the preceding network are also fed as input to the convolutional block of the second network. Furthermore, aggregated residual and attention modules in the cascaded AReN-UNet are used to improve convergence and stability of the network which eventually reduces the vessel breakdowns in the vascular map. The proposed model is trained and evaluated on different datasets such as DRIVE, CHASE_DB1, and one locally collected dataset. The proposed network illustrates the state-of-the-art performance by achieving an accuracy, F1 score, sensitivity, specificity, and Area Under the Curve (AUC) of 96.96%, 82.63%, 83.68%, 98.35%, and 98.67% respectively on the DRIVE dataset and 97.70%, 82.01%, 85.60%, 98.35%, and 99.01% respectively on the CHASE_DB1 dataset. © 2021",Attention module; Cascaded AReN-UNet; Convolutional neural networks; Residual module; Retinal fundus images; Segmentation
Conference Paper,"Dos Passos M.G., Amaral L.L., Garcia D., Vicente R.B., De Abreu L.L.T., De Siqueira Vieira J.K., De Souza Pires M.M., Comunello E., Ceretta L.B., Barra C.M.C.M., Tanaka H., De Carvalho D.R., De Oliveira T.R., Pires P.D.S., Simões P.W.",Meta-analysis of the sensitivity of decision support systems in diagnosing diabetic retinopathy,Studies in Health Technology and Informatics,2019,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85071495394&doi=10.3233%2fSHTI190349&partnerID=40&md5=d9da825d28aa3ecbca50a00adbfe5882,"Diabetic Retinopathy (DR) is one of the most common microvascular complications presenting by patients diagnosticated with diabetic diseases. Uncontrolled hyperglycemia may manifest as visual impairment and blindness. The early detection of DR is essential to minimize the risk and consequence of visual diminishing. The standard gold diagnoses tool relies on different imaging modalities and requires a judgment of expert photographers, which are not available in most of the primary care centers or remote location. In that scenario, an automate or semiautomated DR screening systems can contribute to improving the accuracy of the diagnostic. Thus, we performed a Systematic Review and Meta-Analysis to evaluate the Decision Support Systems (DSS) in diagnosing DR. The overall Diagnostic Odds Ratio was 73.15 (95%CI: 37.54-142.50), sensitivity was 97.70 (95%CI: 97.50-97.90) and specificity was 90.30 (95%CI: 90.00-90.60). Our results corroborate with the concept of usefulness of DSSs in early diagnosis, screening and preliminary evaluation of suspicious images of DR. © 2019 International Medical Informatics Association (IMIA) and IOS Press.",Clinical; Decision Support Systems; Diabetic Retinopathy; Meta-analysis
Article,"Qureshi I., Ma J., Abbas Q.",Diabetic retinopathy detection and stage classification in eye fundus images using active deep learning,Multimedia Tools and Applications,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099033867&doi=10.1007%2fs11042-020-10238-4&partnerID=40&md5=9cacb36cdacffb0d3a905f596d9de77c,"Retinal fundus image analysis (RFIA) for diabetic retinopathy (DR) screening can be used to reduce the risk of blindness among diabetic patients. The RFIA screening programs help the ophthalmologists to cope with this paramount visual impairment problem. In this article, an automatic recognition of the DR stage is proposed based on a new multi-layer architecture of active deep learning (ADL). To develop the ADL system, we used the convolutional neural networks (CNN) model to automatically extract features compare to handcrafted-based features. However, the training of CNN procedure requires an immense size of labeled data that makes it almost difficult in the classification phase. As a result, a label-efficient CNN architecture is presented known as ADL-CNN by using one of the active learning methods known as an expected gradient length (EGL). This ADL-CNN model can be seen as a two-stage process. At first, the proposed ADL-CNN system selects both the most informative patches and images by using some ground truth labels of training samples to learn the simple to complex retinal features. Next, it provides useful masks for prognostication to assist clinical specialists for the important eye sample annotation and segment regions-of-interest within the retinograph image to grade five severity-levels of diabetic retinopathy. To test and evaluate the performance of ADL-CNN model, the EyePACS benchmark is utilized and compared with state-of-the-art methods. The statistical metrics are used such as sensitivity (SE), specificity (SP), F-measure and classification accuracy (ACC) to measure the effectiveness of ADL-CNN system. On 54,000 retinograph images, the ADL-CNN model achieved an average SE of 92.20%, SP of 95.10%, F-measure of 93% and ACC of 98%. Hence, the new ADL-CNN architecture is outperformed for detecting DR-related lesions and recognizing the five levels of severity of DR on a wide range of fundus images. © 2021, The Author(s), under exclusive licence to Springer Science+Business Media, LLC part of Springer Nature.",Active deep learning; Convolutional neural network; Diabetic retinopathy; Diabetic retinopathy; Expected gradient length; Image processing; Severity-level
Conference Paper,"Das D., Das S., Biswas S.K., Purkayastha B.",Deep Diabetic Retinopathy Feature eXtraction and Random Forest based ensemble Classification System (DDRFXRFCS),"2021 Asian Conference on Innovation in Technology, ASIANCON 2021",2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85117570887&doi=10.1109%2fASIANCON51346.2021.9544899&partnerID=40&md5=dfae269c2ac87e552da14aa78d767d97,"Diabetic Retinopathy (DR) is a severe eye disease caused due to diabetes mellitus and is mostly seen amongst patients suffering from prolonged diabetes. It causes vision problem and in the worst case it causes severe blindness due to formation of lesions in the retina triggered by the rupture of retinal blood vessels. It has become important to detect the disease at an early stage to avoid severity and to avoid difficulties in identification of subtle lesions during the progressive stages of the disease. The process of manual analysis is cumbersome for routine treatment. Hence, the importance of implementing intelligent systems using Deep Learning (DL) is realized. Various research works have been performed using DL and Convolutional Neural Networks for image related tasks, and DR is no different as it requires fundus images for diagnosis. Various single-model based feature extraction and classification systems are proposed earlier which have consistently shown a stagnant performance in DR detection with greater bias and variance. In order to reduce bias and variance and avoid overfitting of the model, researchers have proposed ensemble-based models for image classification based on deep features extracted using DL models. Such ensemble models have exhibited much better performance in aggregating diverse perspective for making predictions to obtain the average optimal prediction compared to a single classifier-based model. Thus, this paper proposes three different state-of-the-art DL Convolutional Network (DConvNet) for individual feature extraction and Random Forest (RF) based ensemble classification for obtaining various predictions and compute the average of all predictions, which is the optimal best solution, for the purpose of early DR detection. © 2021 IEEE.",Deep Learning; Diabetic Retinopathy; Ensemble; Feature Importance; Image; Random Forest
Article,"Bogacsovics G., Toth J., Hajdu A., Harangi B.",Enhancing CNNs through the use of hand-crafted features in automated fundus image classification,Biomedical Signal Processing and Control,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85128326328&doi=10.1016%2fj.bspc.2022.103685&partnerID=40&md5=4f4029d4a2108c24a1bdd5ab4b740c48,"Eye diseases such as diabetic retinopathy and diabetic macular edema pose a major threat in today's world as they affect a significant portion of the global population. Therefore, it is of utmost importance to develop robust solutions that can accurately detect these diseases, especially in their early stages. However, current methods, based on hand-crafted features devised by experts, are not sufficiently accurate. Several solutions have been proposed that use deep learning techniques to improve the performance of such systems. However, they ignore the highly valuable hand-crafted features, that could contribute to more accurate prediction, which underlines the significance of our research. In this paper, we revisit the problem of combining these hand-crafted features with the features extracted by neural networks with the objective of delivering more accurate predictions. We systematically study several state-of-the-art neural networks and methods and propose a number of ways to integrate them into our framework. We show that we arrived at the conclusion that it is possible to achieve significantly better results and outperform networks that do not consider hand-crafted features using the proposed methods. © 2022 The Author(s)",Deep learning; Diabetic macular edema; Diabetic retinopathy; Ensemble learning; Hand-crafted features; Screening systems
Article,"Qu L., Balachandar N., Zhang M., Rubin D.",Handling data heterogeneity with generative replay in collaborative learning for medical imaging,Medical Image Analysis,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85127565574&doi=10.1016%2fj.media.2022.102424&partnerID=40&md5=87eacb27b8f46eb8d99b1a8ae0af084c,"Collaborative learning, which enables collaborative and decentralized training of deep neural networks at multiple institutions in a privacy-preserving manner, is rapidly emerging as a valuable technique in healthcare applications. However, its distributed nature often leads to significant heterogeneity in data distributions across institutions. In this paper, we present a novel generative replay strategy to address the challenge of data heterogeneity in collaborative learning methods. Different from traditional methods that directly aggregating the model parameters, we leverage generative adversarial learning to aggregate the knowledge from all the local institutions. Specifically, instead of directly training a model for task performance, we develop a novel dual model architecture: a primary model learns the desired task, and an auxiliary “generative replay model” allows aggregating knowledge from the heterogenous clients. The auxiliary model is then broadcasted to the central sever, to regulate the training of primary model with an unbiased target distribution. Experimental results demonstrate the capability of the proposed method in handling heterogeneous data across institutions. On highly heterogeneous data partitions, our model achieves ∼4.88% improvement in the prediction accuracy on a diabetic retinopathy classification dataset, and ∼49.8% reduction of mean absolution value on a Bone Age prediction dataset, respectively, compared to the state-of-the art collaborative learning methods. © 2022 Elsevier B.V.",Autoencoder; Collaborative learning; Data heterogeneity; Federated learning; Generative adversarial networks (GAN)
Article,"Sikder N., Masud M., Bairagi A.K., Arif A.S.M., Nahid A.-A., Alhumyani H.A.",Severity classification of diabetic retinopathy using an ensemble learning algorithm through analyzing retinal images,Symmetry,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85104122753&doi=10.3390%2fsym13040670&partnerID=40&md5=a70831d0e0ef0c349344cc2f3dfceaaa,"Diabetic Retinopathy (DR) refers to the damages endured by the retina as an effect of diabetes. DR has become a severe health concern worldwide, as the number of diabetes patients is soaring uncountably. Periodic eye examination allows doctors to detect DR in patients at an early stage to initiate proper treatments. Advancements in artificial intelligence and camera technology have allowed us to automate the diagnosis of DR, which can benefit millions of patients indeed. This paper inscribes a novel method for DR diagnosis based on the gray-level intensity and texture features extracted from fundus images using a decision tree-based ensemble learning technique. This study primarily works with the Asia Pacific Tele-Ophthalmology Society 2019 Blindness Detection (APTOS 2019 BD) dataset. We undertook several steps to curate its contents to make them more suitable for machine learning applications. Our approach incorporates several image processing techniques, two feature extraction techniques, and one feature selection technique, which results in a classification accuracy of 94.20% (margin of error: ±0.32%) and an F-measure of 93.51% (margin of error: ±0.5%). Several other parameters regarding the proposed method’s performance have been presented to manifest its robustness and reliability. Details on each employed technique have been included to make the provided results reproducible. This method can be a valuable tool for mass retinal screening to detect DR, thus drastically reducing the rate of vision loss attributed to it. © 2021 by the authors. Licensee MDPI, Basel, Switzerland.",Diabetic retinopathy detection; Ensemble learning; Genetic algorithm; Gray-level co-occurrence matrix; Image histogram; Medical image analysis
Conference Paper,"Hire M., Shinde S.",Ant Colony Optimization Based Exudates Segmentation in Retinal Fundus Images and Classification,"Proceedings - 2018 4th International Conference on Computing, Communication Control and Automation, ICCUBEA 2018",2018,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85065215693&doi=10.1109%2fICCUBEA.2018.8697727&partnerID=40&md5=c5c07dccc4f1cadbb9941a0ba3a5bdfd,"Presently multi day's Diabetic retinopathy is a genuine restorative issue that fundamentally hurt the human retina and finely vision visual deficiency. The examination of the Retinal pictures is done through various determination strategies in current Ophthalmology. There are different methods available for segmentation of the exudates in the fundus retinal images. These methods are used for non-intrusive diagnosis for the eye diseases. Exudates are the manifestations of DR. Exudates are frequently observed with microaneurysms. These methods comes with some issues such as noise presence, low contrast, uneven illumination, and color variation so to overcome those issues some new method is needed, that is computer aided diagnosis for exudates segmentation. The exudates segmentation is perform by following some specific steps. System preprocesses the fundus image of human retina which is followed by image segmentation in which exudates are segmented. Exudates segmentation is done using Ant Colony optimization Algorithm. The algorithm's performance was evaluated with a dataset available online. Classification is performed on segmented image to classifying the image as Normal retina and diabetic retinopathy retina and if classification results is as diabetic retina than image is further classify into class of diabetic. © 2018 IEEE.",Ant Colony Optimization; Exudates Segmentation; Fundus Images; KNN
Article,"Naqvi S.A.G., Zafar H.M.F., Ul Haq I.",Automated system for referral of cotton-wool spots,Current Diabetes Reviews,2018,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85045971745&doi=10.2174%2f1573399812666161201114309&partnerID=40&md5=af20409dd0d73fc6096ccb9fba3ccbb8,"Background: Cotton-wool spots also referred as soft exudates are the early signs of complications in the eye fundus of the patients suffering from diabetic retinopathy. Early detection of exudates helps in the diagnosis of the disease and provides better medical attention. Methods: In this paper, an automated system for the detection of soft exudates has been suggested. The system has been developed by the combination of different techniques like Scale Invariant Feature Transform (SIFT), Visual Dictionaries, K-means clustering and Support Vector Machine (SVM). Results: The performance of the system is evaluated on a publically available dataset and AUC of 94.59% is achieved with the highest accuracy obtained is 94.59%. The experiments are also performed after mixing three datasets and AUC of 92.61% is observed with 91.94% accuracy. Conclusion: The proposed system is easy to implement and can be used by medical experts both online and offline for referral of Cotton-wool spots in large populations. The system shows promising performance. © 2018 Bentham Science Publishers.",Cotton-wool spots; Diabetic retinopathy; Eye fundus; SIFT; SVM; Visual dictionary
Article,"Malerbi F.K., Melo G.B.","Feasibility of screening for diabetic retinopathy using artificial intelligence, Brazil [Possible utilisation de l'intelligence artificielle pour dépister la rétinopathie diabétique au Brésil] [Viabilidad del cribado de la retinopatía diabética mediante la inteligencia artificial en Brasil]",Bulletin of the World Health Organization,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85139110658&doi=10.2471%2fBLT.22.288580&partnerID=40&md5=03504754f20d44d4e1ad38203b4675bb,"Problem There is currently no national strategy or standardized approach to diabetic retinopathy screening in the Brazilian public health system, and multiple socioeconomic barriers prevent access to eye examination in Brazil’s poorest regions. Approach From September 2021 to March 2022 we carried out a pilot project with an artificial intelligence system for diabetic retinopathy screening, embedded in a portable retinal camera. Patients with a diagnosis of diabetes according to the municipality registry were invited to attend nearby clinics for screening on designated days. Trained health-care technicians acquired images which were automatically evaluated by the system, with instant remote evaluation by retinal specialists in selected cases. Local setting Our study was based in Sergipe State, located at a region with high illiteracy rates and no local availability of specialized retina care. The average number of laser treatments performed annually in the last 5 years is 126, for a total State population of 2.3 million. Relevant changes Even though screening was performed free of charge in a convenient location for patients, from a total 2052 eligible individuals, only 1083 attended for screening. Lessons learnt Efforts to raise awareness on the condition screened and to provide health education for patients and local health-care personnel are fundamental for increased attendance. Tailoring screening systems to the local setting, such as determining the trade-off between sensitivity and specificity, is challenging in regions with no current benchmarks. Standards for retinopathy screening based on the strategies adopted by high-income countries may not be realistic in low-and middle-income countries. © 2022, World Health Organization. All rights reserved.",artificial intelligence; detection method; diabetes; feasibility study; health care; health education; public health; trade-off; adult; Article; artificial intelligence; awareness; Brazil; diabetic retinopathy; diagnostic accuracy; eye examination; feasibility study; female; health care cost; health education; high income country; human; human development; laser therapy; low income country; major clinical study; male; middle income country; patient registry; pilot study; quality control; screening; sensitivity and specificity; artificial intelligence; diabetes mellitus; diabetic retinopathy; feasibility study; Brazil; Sergipe; Artificial Intelligence; Brazil; Diabetes Mellitus; Diabetic Retinopathy; Feasibility Studies; Humans; Pilot Projects
Article,"Li Z., Jiang J., Chen K., Zheng Q., Liu X., Weng H., Wu S., Chen W.",Development of a deep learning-based image quality control system to detect and filter out ineligible slit-lamp images: A multicenter study,Computer Methods and Programs in Biomedicine,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102882589&doi=10.1016%2fj.cmpb.2021.106048&partnerID=40&md5=968efbf9daca7c5cae77f94b90fb272b,"Background and objective: Previous studies developed artificial intelligence (AI) diagnostic systems only using eligible slit-lamp images for detecting corneal diseases. However, images of ineligible quality (including poor-field, defocused, and poor-location images), which are inevitable in the real world, can cause diagnostic information loss and thus affect downstream AI-based image analysis. Manual evaluation for the eligibility of slit-lamp images often requires an ophthalmologist, and this procedure can be time-consuming and labor-intensive when applied on a large scale. Here, we aimed to develop a deep learning-based image quality control system (DLIQCS) to automatically detect and filter out ineligible slit-lamp images (poor-field, defocused, and poor-location images). Methods: We developed and externally evaluated the DLIQCS based on 48,530 slit-lamp images (19,890 individuals) that were derived from 4 independent institutions using different types of digital slit lamp cameras. To find the best deep learning model for the DLIQCS, we used 3 algorithms (AlexNet, DenseNet121, and InceptionV3) to train models. The area under the receiver operating characteristic curve (AUC), sensitivity, specificity, and accuracy were leveraged to assess the performance of each algorithm for the classification of poor-field, defocused, poor-location, and eligible images. Results: In an internal test dataset, the best algorithm DenseNet121 had AUCs of 0.999, 1.000, 1.000, and 1.000 in the detection of poor-field, defocused, poor-location, and eligible images, respectively. In external test datasets, the AUCs of the best algorithm DenseNet121 for identifying poor-field, defocused, poor-location, and eligible images were ranged from 0.997 to 0.997, 0.983 to 0.995, 0.995 to 0.998, and 0.999 to 0.999, respectively. Conclusions: Our DLIQCS can accurately detect poor-field, defocused, poor-location, and eligible slit-lamp images in an automated fashion. This system may serve as a prescreening tool to filter out ineligible images and enable that only eligible images would be transferred to the subsequent AI diagnostic systems. © 2021 Elsevier B.V.",Artificial intelligence; Deep learning; Image quality; Slit lamp
Article,"Arsalan M., Haider A., Choi J., Park K.R.",Diabetic and hypertensive retinopathy screening in fundus images using artificially intelligent shallow architectures,Journal of Personalized Medicine,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85121696747&doi=10.3390%2fjpm12010007&partnerID=40&md5=f86c7527b239fd0567598a8e66fd8fe8,"Retinal blood vessels are considered valuable biomarkers for the detection of diabetic retinopathy, hypertensive retinopathy, and other retinal disorders. Ophthalmologists analyze retinal vasculature by manual segmentation, which is a tedious task. Numerous studies have focused on automatic retinal vasculature segmentation using different methods for ophthalmic disease analysis. However, most of these methods are computationally expensive and lack robustness. This paper proposes two new shallow deep learning architectures: dual-stream fusion network (DSF-Net) and dual-stream aggregation network (DSA-Net) to accurately detect retinal vasculature. The proposed method uses semantic segmentation in raw color fundus images for the screening of diabetic and hypertensive retinopathies. The proposed method’s performance is assessed using three publicly available fundus image datasets: Digital Retinal Images for Vessel Extraction (DRIVE), Structured Analysis of Retina (STARE), and Children Heart Health Study in England Database (CHASE-DB1). The experimental results revealed that the proposed method provided superior segmentation performance with accuracy (Acc), sensitivity (SE), specificity (SP), and area under the curve (AUC) of 96.93%, 82.68%, 98.30%, and 98.42% for DRIVE, 97.25%, 82.22%, 98.38%, and 98.15% for CHASE-DB1, and 97.00%, 86.07%, 98.00%, and 98.65% for STARE datasets, respectively. The experimental results also show that the proposed DSA-Net provides higher SE compared to the existing approaches. It means that the proposed method detected the minor vessels and provided the least false negatives, which is extremely important for diagnosis. The proposed method provides an automatic and accurate segmentation mask that can be used to highlight the vessel pixels. This detected vasculature can be utilized to compute the ratio between the vessel and the non-vessel pixels and distinguish between diabetic and hypertensive retinopathies, and morphology can be analyzed for related retinal disorders. © 2021 by the authors. Licensee MDPI, Basel, Switzerland.",Diabetic retinopathy; Fundus images; Hypertensive retinopathy; Ophthalmic diseases; Retinal disease screening; Retinal vasculature
Article,"Ghosh S.K., Ghosh A.",A novel retinal image segmentation using rSVM boosted convolutional neural network for exudates detection,Biomedical Signal Processing and Control,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85106934643&doi=10.1016%2fj.bspc.2021.102785&partnerID=40&md5=bf8600c3bf5eb0671213d271be3028f5,"Retinal image analysis is an emerging research field in ophthalmological disease diagnosis since falsely detected optic disc, fovea, and blood vessels have become essential levels for automated diagnosis practices. In this article, we introduce a novel retinal image segmentation based on ranking support vector machine (rSVM) with convolutional neural network in deep learning field for the detection of diabetic retinopathy. Firstly, the spatial features of the retinal images have been extracted from RGB channel and mapped into a single binary features plane by the computing of pixel by pixel score using rSVM. Thereafter, we have designed a deep convolutional neural network for the retinal image segmentation followed by automatic anomaly detection using morphological operations. The rSVM computes a score function which is more suitable for multi-level classification to binary features classification in order to reduce the overall execution time in the segmentation task. The CNN has been designed with rSVM to define a consistent feature label in the network that reduces the number of channels in the CNN which lead to fast convergence. As a consequence, we have achieved good segmentation accuracy such as 96.4%, 97% and 98.2% for three different databases through post processing steps in comparison with other existing model. © 2021 Elsevier Ltd",Convolutional neural network; Exudates; FROC; Optic disc segmentation; Retinal image; RSVM
Article,"Maqsood S., Damaševičius R., Maskeliūnas R.",Hemorrhage detection based on 3d cnn deep learning framework and feature fusion for evaluating retinal abnormality in diabetic patients,Sensors,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85107124229&doi=10.3390%2fs21113865&partnerID=40&md5=2ef5e4eada92807fdd1b033dfa5fa5bb,"Diabetic retinopathy (DR) is the main cause of blindness in diabetic patients. Early and accurate diagnosis can improve the analysis and prognosis of the disease. One of the earliest symptoms of DR are the hemorrhages in the retina. Therefore, we propose a new method for accurate hemorrhage detection from the retinal fundus images. First, the proposed method uses the modified contrast enhancement method to improve the edge details from the input retinal fundus images. In the second stage, a new convolutional neural network (CNN) architecture is proposed to detect hemorrhages. A modified pre-trained CNN model is used to extract features from the detected hemorrhages. In the third stage, all extracted feature vectors are fused using the convolutional sparse image decomposition method, and finally, the best features are selected by using the multi-logistic regression controlled entropy variance approach. The proposed method is evaluated on 1509 images from HRF, DRIVE, STARE, MESSIDOR, DIARETDB0, and DIARETDB1 databases and achieves the average accuracy of 97.71%, which is superior to the previous works. Moreover, the proposed hemorrhage detection system attains better performance, in terms of visual quality and quantitative analysis with high accuracy, in comparison with the state-of-the-art methods. © 2021 by the authors. Licensee MDPI, Basel, Switzerland.",Deep learning; Diabetic retinopathy; Feature fusion; Hemorrhage detection; Medical image processing; Retinal fundus image
Article,"Yu Z., Yang X., Sweeting G.L., Ma Y., Stolte S.E., Fang R., Wu Y.",Identify diabetic retinopathy-related clinical concepts and their attributes using transformer-based natural language processing methods,BMC Medical Informatics and Decision Making,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85138896942&doi=10.1186%2fs12911-022-01996-2&partnerID=40&md5=2c6f06b1403a20f2728762d4c6b28a62,"Background: Diabetic retinopathy (DR) is a leading cause of blindness in American adults. If detected, DR can be treated to prevent further damage causing blindness. There is an increasing interest in developing artificial intelligence (AI) technologies to help detect DR using electronic health records. The lesion-related information documented in fundus image reports is a valuable resource that could help diagnoses of DR in clinical decision support systems. However, most studies for AI-based DR diagnoses are mainly based on medical images; there is limited studies to explore the lesion-related information captured in the free text image reports. Methods: In this study, we examined two state-of-the-art transformer-based natural language processing (NLP) models, including BERT and RoBERTa, compared them with a recurrent neural network implemented using Long short-term memory (LSTM) to extract DR-related concepts from clinical narratives. We identified four different categories of DR-related clinical concepts including lesions, eye parts, laterality, and severity, developed annotation guidelines, annotated a DR-corpus of 536 image reports, and developed transformer-based NLP models for clinical concept extraction and relation extraction. We also examined the relation extraction under two settings including ‘gold-standard’ setting—where gold-standard concepts were used–and end-to-end setting. Results: For concept extraction, the BERT model pretrained with the MIMIC III dataset achieve the best performance (0.9503 and 0.9645 for strict/lenient evaluation). For relation extraction, BERT model pretrained using general English text achieved the best strict/lenient F1-score of 0.9316. The end-to-end system, BERT_general_e2e, achieved the best strict/lenient F1-score of 0.8578 and 0.8881, respectively. Another end-to-end system based on the RoBERTa architecture, RoBERTa_general_e2e, also achieved the same performance as BERT_general_e2e in strict scores. Conclusions: This study demonstrated the efficiency of transformer-based NLP models for clinical concept extraction and relation extraction. Our results show that it’s necessary to pretrain transformer models using clinical text to optimize the performance for clinical concept extraction. Whereas, for relation extraction, transformers pretrained using general English text perform better. © 2022, The Author(s).",Deep learning; Diabetic retinopathy; Named entity recognition; Natural language processing; Relation extraction
Article,"Saranya P., Prabakaran S., Kumar R., Das E.",Blood vessel segmentation in retinal fundus images for proliferative diabetic retinopathy screening using deep learning,Visual Computer,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099939879&doi=10.1007%2fs00371-021-02062-0&partnerID=40&md5=277b724aeea721909a21750deea29cbf,"Diabetic retinopathy (DR) is also called diabetic eye disease, which causes damage to the retina due to diabetes mellitus and that leads to blindness when the disease reaches an extreme stage. The medical tests take a lot of procedure, time, and money to test for the proliferative stage of diabetic retinopathy (PDR). Hence to resolve this problem, this model is proposed to detect and identify the proliferative stages of diabetic retinopathy which is also identified by its hallmark feature that is neovascularization. In the proposed system, the paper aims to correctly identify the presence of neovascularization using color fundus images. The presence of neovascularization in an eye is an indication that the eye is affected with proliferative PDR. Neovascularization is the development of new abnormal blood vessels in the retina. Since the occurrence of neovascularization may lead to partial or complete vision loss, timely and accurate prediction is important. The aim of the paper is to propose a method to detect the presence of neovascularization which involves image processing methods such as resizing, green channel filtering, Gaussian filter, and morphology techniques such as erosion and dilation. For classification, the different layers of CNN have been used and modeled together in a VGG-16 net architecture. The model was trained and tested on 2200 images all together from the Kaggle database. The proposed model was tested using DRIVE and STARE data sets, and the accuracy, specificity, sensitivity, precision, F1 score achieved are 0.96, 0.99, 0.95, 0.99, and 0.97, respectively, on DRIVE and 0.95, 0.99, 0.9375, 0.96, and 0.95, respectively, on STARE. © 2021, The Author(s), under exclusive licence to Springer-Verlag GmbH, DE part of Springer Nature.",Blood vessels; CNN; Dense-net; Neovascularization; Pathogenic blood vessels; Proliferative diabetic retinopathy; Vision loss
Article,"Garifullin A., Lensu L., Uusitalo H.",Deep Bayesian baseline for segmenting diabetic retinopathy lesions: Advances and challenges,Computers in Biology and Medicine,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85112340185&doi=10.1016%2fj.compbiomed.2021.104725&partnerID=40&md5=2f76a77da3c6380ab9ecf5d6ea0293fb,"Early diagnosis of retinopathy is essential for preventing retinal complications and visual impairment due to diabetes. For the detection of retinopathy lesions from retinal images, several automatic approaches based on deep neural networks have been developed in the recent years. Most of the proposed methods produce point estimates of pixels belonging to the lesion areas and give no or little information on the uncertainty of method predictions. However, the latter can be essential in the examination of the medical condition of the patient when the goal is early detection of abnormalities. This work extends the recent research with a Bayesian framework by considering the parameters of a convolutional neural network as random variables and utilizing stochastic variational dropout based approximation for uncertainty quantification. The framework includes an extended validation procedure and it allows analyzing lesion segmentation distributions, model calibration and prediction uncertainties. Also the challenges related to the deep probabilistic model and uncertainty quantification are presented. The proposed method achieves area under precision-recall curve of 0.84 for hard exudates, 0.641 for soft exudates, 0.593 for haemorrhages, and 0.484 for microaneurysms on IDRiD dataset. © 2021 The Author(s)",Bayesian deep learning; Diabetic retinopathy; Haemorrhage; Hard exudate; Lesion segmentation; Microaneurysm; Soft exudate
Article,"Basha S.S., Ramanaia K.V.",Optimal Feature Selection for Diagnosing Diabetic Retinopathy Using FireFly Migration Operator-Based Monarch Butterfly Optimization,Critical Reviews in Biomedical Engineering,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85138258343&doi=10.1615%2fCritRevBiomedEng.2022041571&partnerID=40&md5=b74f1224ef9f4e8a92d7ce79e068f201,"In recent years, diabetic retinopathy (DR) needs to be focused with the intention of developing accurate and effective approaches by accomplishing the existing challenges in the traditional models. With this objective, this paper aims to introduce an effective diagnosis system by utilizing retinal fundus images. The implementation of this diagnosis model incorporates 4 stages like (i) preprocessing, (ii) blood vessel segmentation, (iii) feature extraction, as well as (iv) classification. Originally, the median filter as well as contrast limited adaptive histogram equalization (CLAHE) help to preprocess the image. Moreover, the Fuzzy C Mean (FCM) thresholding is applied for blood vessel segmentation, which generates stochastic clustering of pixels to obtain enhanced threshold values. Further, feature extraction is accomplished by utilizing gray-level run-length matrix (GLRM), local, and morphological transformation-based features. Furthermore, a deep learning (DL) model known as convolutional neural network (CNN) is employed for the diagnosis or classification purpose. As a main novelty, this paper introduces an optimal feature selection as well as classification model. Further, the feature selection is done optimally by FireFly Migration Operator-based Monarch Butterfly Optimization (FM-MBO) which hybridized of the monarch butterfly optimization (MBO) and fire fly (FF) algorithms as the entire adopted extracted features attain higher feature length. Moreover, the proposed FM-MBO algorithm helps for optimizing the count of CNN’s convolutional neurons to further improve the performance accuracy. At the end, the enhanced outcomes of the adopted diagnostic scheme are validated via a valuable comparative examination in terms of significant performance measures. © 2022 by Begell House, Inc.",convolutional layer optimization; diabetic retinopathy; hybrid algorithm; medical image processing; optimal feature selection
Conference Paper,"Akil M., Elloumi Y., Kachouri R.",Computational aspects of deep learning models for detection of eye retina abnormalities,Proceedings of SPIE - The International Society for Optical Engineering,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85085738670&doi=10.1117%2f12.2557601&partnerID=40&md5=6ae5a9c90ffa860b74535388da606e6b,"Glaucoma, Cataract, Age-related macular degeneration, (AMD) Diabetic retinopathy (DR) are among the leading retinal diseases. Thus, there is an active effort to create and develop methods to automate screening of retinal diseases. Many CAD (Computer Aided Diagnosis) systems have been expanded and are widely used for ocular diseases. Recently, Deep Neural Networks (DNNs) have been adopted in ophthalmology and applied to fundus images, achieving detection of retinal abnormalities using retinal images. There are essentially two approaches, the first one is based on hybrid method that employs image processing for preprocessing, features extraction and post processing and Deep Neural Network (DNN) is only used for classification. The second is the fully method where DNN is used for both feature extraction and classification. Several DNN models and their variants have been proposed such as AlexNet, VGG, GoogleNet, Inception, U-Net, Residual Net (ResNet), DenseNet for detection of eye retina abnormalities. The aim of this work is to provide the background and the methodology to conduct a benchmarking analysis including the computational aspects and analysis of the representative DNNs proposed in the state of the art for detection DR diseases. For each DNN different characteristics and some performance indices (i.e. model complexity, computation complexity, inference time, memory use) and detection disease performance (i.e. accuracy rate), must be taking into account to find the more accurate model. The public domain datasets used for training and testing the DNN models such as Kaggle, MESSIDOR, and EyePACS are outlined and analyzed in particular in DR detection. © COPYRIGHT SPIE. Downloading of the abstract is permitted for personal use only.",Automated screening and detection of DR disease; Computation complexity; Deep Neural Networks; Fundus images; Performance analysis
Article,"Nandy Pal M., Sarkar A., Gupta A., Banerjee M.",Deep CNN based microaneurysm-haemorrhage classification in retinal images considering local neighbourhoods,Computer Methods in Biomechanics and Biomedical Engineering: Imaging and Visualization,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85120082795&doi=10.1080%2f21681163.2021.2002190&partnerID=40&md5=7722b7ec2286d3836a8a832ead0a50dd,"Retinal image characteristics can be utilised for early diagnosis of Diabetic Retinopathy (DR). The earliest symptom of DR is the presence of microaneurysm and haemorrhage in retinal fundus images. A computerised classification system can increase the effectiveness of the large volume screening process of retinal images. In this paper, a deep convolutional neural network-based pixel classification approach has been presented where the models, trained on online public datasets, are used for symptom level classification of the fundus images, collected from patient data of a local state hospital. The method achieves average values of sensitivity of 0.4556, specificity of 0.8395 and accuracy of 0.8341 on the local dataset. The CNN did not require exhaustive training with a large number of images as symptom level training was performed on annotated overlapping patches. The average classification time is 0.7275 sec/image. The results in terms of classification metrics and in terms of execution time requirement are very encouraging when compared with different recently developed classification methods and as per the simplicity of the method is concerned. © 2021 Informa UK Limited, trading as Taylor & Francis Group.",AUC; computational time; convolutional neural network (CNN); haemorrhage (HM); Micro aneurysm (MA); sensitivity
Article,"Sayres R., Taly A., Rahimy E., Blumer K., Coz D., Hammel N., Krause J., Narayanaswamy A., Rastegar Z., Wu D., Xu S., Barb S., Joseph A., Shumski M., Smith J., Sood A.B., Corrado G.S., Peng L., Webster D.R.",Using a Deep Learning Algorithm and Integrated Gradients Explanation to Assist Grading for Diabetic Retinopathy,Ophthalmology,2019,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85062733485&doi=10.1016%2fj.ophtha.2018.11.016&partnerID=40&md5=a1c8809ef9919ad05027c88173f920cf,"Purpose: To understand the impact of deep learning diabetic retinopathy (DR) algorithms on physician readers in computer-assisted settings. Design: Evaluation of diagnostic technology. Participants: One thousand seven hundred ninety-six retinal fundus images from 1612 diabetic patients. Methods: Ten ophthalmologists (5 general ophthalmologists, 4 retina specialists, 1 retina fellow) read images for DR severity based on the International Clinical Diabetic Retinopathy disease severity scale in each of 3 conditions: unassisted, grades only, or grades plus heatmap. Grades-only assistance comprised a histogram of DR predictions (grades) from a trained deep-learning model. For grades plus heatmap, we additionally showed explanatory heatmaps. Main Outcome Measures: For each experiment arm, we computed sensitivity and specificity of each reader and the algorithm for different levels of DR severity against an adjudicated reference standard. We also measured accuracy (exact 5-class level agreement and Cohen's quadratically weighted κ), reader-reported confidence (5-point Likert scale), and grading time. Results: Readers graded more accurately with model assistance than without for the grades-only condition (P < 0.001). Grades plus heatmaps improved accuracy for patients with DR (P < 0.001), but reduced accuracy for patients without DR (P = 0.006). Both forms of assistance increased readers’ sensitivity moderate-or-worse DR: unassisted: mean, 79.4% [95% confidence interval (CI), 72.3%–86.5%]; grades only: mean, 87.5% [95% CI, 85.1%–89.9%]; grades plus heatmap: mean, 88.7% [95% CI, 84.9%–92.5%] without a corresponding drop in specificity (unassisted: mean, 96.6% [95% CI, 95.9%–97.4%]; grades only: mean, 96.1% [95% CI, 95.5%–96.7%]; grades plus heatmap: mean, 95.5% [95% CI, 94.8%–96.1%]). Algorithmic assistance increased the accuracy of retina specialists above that of the unassisted reader or model alone; and increased grading confidence and grading time across all readers. For most cases, grades plus heatmap was only as effective as grades only. Over the course of the experiment, grading time decreased across all conditions, although most sharply for grades plus heatmap. Conclusions: Deep learning algorithms can improve the accuracy of, and confidence in, DR diagnosis in an assisted read setting. They also may increase grading time, although these effects may be ameliorated with experience. © 2018 American Academy of Ophthalmology","algorithm; Article; deep learning; diabetic patient; diabetic retinopathy; disease severity assessment; eye fundus; histogram; human; Likert scale; major clinical study; ophthalmologist; outcome assessment; priority journal; sensitivity and specificity; classification; computer assisted diagnosis; diabetic retinopathy; female; male; photography; procedures; receiver operating characteristic; reproducibility; standard; Algorithms; Deep Learning; Diabetic Retinopathy; Diagnosis, Computer-Assisted; Female; Humans; Male; Ophthalmologists; Photography; Reference Standards; Reproducibility of Results; ROC Curve; Sensitivity and Specificity"
Article,"Vasireddi H.K., K S.D., G N V R.R.",Deep feed forward neural network–based screening system for diabetic retinopathy severity classification using the lion optimization algorithm,Graefe's Archive for Clinical and Experimental Ophthalmology,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85114881899&doi=10.1007%2fs00417-021-05375-x&partnerID=40&md5=802e3ca8d00442655591d6b53377a92e,"Abstract: Diabetic Retinopathy (DR) has become a major cause of blindness in recent years. Diabetic patients should be screened on a regular basis for early detection, which can help them avoid blindness. Furthermore, the number of diabetic patients undergoing these screening procedures is rapidly increasing, resulting in increased workload for ophthalmologists. An efficient screening system that assists ophthalmologists in DR diagnosis saves ophthalmologists a lot of time and effort. To address this issue, an automatic DR detection screening system is required to improve diagnosis speed and detection accuracy. Appropriate treatment can be provided to patients to prevent vision loss if the severity levels of DR are accurately diagnosed in the early stages. A growing number of screening systems for DR diagnosis have been developed in recent years using various deep learning models, and the majority of the published work did not include any optimization algorithm in the neural network for severity classification. The use of an optimization algorithm with the necessary hyper parameter tuning will improve the model’s performance. Considering this as motivation, we proposed a five-phase DFNN-LOA model. The DFNN-LOA algorithm presented here has five phases: (i) pre-processing, (ii) optic disc detection, (iii) segmentation, (iv) feature extraction, and (v) severity classification. The proposed model’s experimental analysis is carried out on the MESSIDOR dataset. The experimental results show that the proposed DFNN-LOA model has superior characteristics, with maximum accuracy, sensitivity, specificity, F1-score, PPV, and NPV of 97.6%, 98.4%, 90.7%, 96.5%, 94.6%, and 97.1%, respectively. © 2021, The Author(s), under exclusive licence to Springer-Verlag GmbH Germany, part of Springer Nature.",Classification; Deep feed forward neural network (DFNN); Diabetic retinopathy; Lion optimization algorithm (LOA); Optic disc (OD) detection; Optimization
Article,"Zhang W., Zhong J., Yang S., Gao Z., Hu J., Chen Y., Yi Z.",Automated identification and grading system of diabetic retinopathy using deep neural networks,Knowledge-Based Systems,2019,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85063720878&doi=10.1016%2fj.knosys.2019.03.016&partnerID=40&md5=d4f4a3148201f20b4a9a5b043907cd9b,"Diabetic retinopathy (DR)is a major cause of human vision loss worldwide. Slowing down the progress of the disease requires early screening. However, the clinical diagnosis of DR presents a considerable challenge in low-resource settings where few ophthalmologists are available to care for all patients with diabetes. In this study, an automated DR identification and grading system called DeepDR is proposed. DeepDR directly detects the presence and severity of DR from fundus images via transfer learning and ensemble learning. It comprises a set of state-of-the-art neural networks based on combinations of popular convolutional neural networks and customised standard deep neural networks. The DeepDR system is developed by constructing a high-quality dataset of DR medical images and then labelled by clinical ophthalmologists. We further explore the relationship between the number of ideal component classifiers and the number of class labels, as well as the effects of different combinations of component classifiers on the best integration performance to construct an optimal model. We evaluate the models on the basis of validity and reliability using nine metrics. Results show that the identification model performs best with a sensitivity of 97.5%, a specificity of 97.7% and an area under the curve of 97.7%. Meanwhile, the grading model achieves a sensitivity of 98.1% and a specificity of 98.9%. On the basis of the methods above, DeepDR can detect DR satisfactorily. Experiment results indicate the importance and effectiveness of the ideal number and combinations of component classifiers in relation to model performance. DeepDR provides reproducible and consistent detection results with high sensitivity and specificity instantaneously. Hence, this work provides ophthalmologists with insights into the diagnostic process. © 2019 Elsevier B.V.",Deep learning; Diabetic retinopathy; Ensemble learning; Fundus images; Image classification; Transfer learning
Article,"Ghazal M., Ali S.S., Mahmoud A.H., Shalaby A.M., El-Baz A.",Accurate Detection of Non-Proliferative Diabetic Retinopathy in Optical Coherence Tomography Images Using Convolutional Neural Networks,IEEE Access,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85080903339&doi=10.1109%2fACCESS.2020.2974158&partnerID=40&md5=84c180ed903f8b2c950e892574c4d539,"Diabetic retinopathy (DR) is a disease that forms as a complication of diabetes. It is particularly dangerous since it often goes unnoticed and can lead to blindness if not detected early. Despite the clear importance and urgency of such an illness, there is no precise system for the early detection of DR so far. Fortunately, such system could be achieved using deep learning including convolutional neural networks (CNNs), which gained momentum in the field of medical imaging due to its capability of being effectively integrated into various systems in a manner that significantly improves the performance. This paper proposes a computer aided diagnostic (CAD) system for the early detection of non-proliferative DR (NPDR) using CNNs. The proposed system is developed for the optical coherence tomography (OCT) imaging modality. Throughout this paper, all aspects of deployment of the proposed system are studied starting from the preprocessing stage required to extract input retina patches to train the CNN without resizing the image, to the use of transfer learning principals and how to effectively combine features in order to optimize performance. This is done through investigating several scenarios for the system setup and then selecting the best one, which from the results revealed to be a two pre-trained CNNs based system, in which one of these CNNs is independently fed by nasal retina patches and the other one by temporal retina patches. The proposed transfer learning based CAD system achieves a promising accuracy of 94%. © 2013 IEEE.",Convolutional neural network (CNN); diabetic retinopathy (DR); optical coherence tomography (OCT)
Conference Paper,"Nagpal D., Panda S.N., Malarvel M.",Hypertensive Retinopathy Screening through Fundus Images-A Review,"Proceedings of the 6th International Conference on Inventive Computation Technologies, ICICT 2021",2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102588373&doi=10.1109%2fICICT50816.2021.9358746&partnerID=40&md5=f0c13e30a664876a5741319ac319e8b9,"Automatic segmentation of fundus images is an important task in computer-aided diagnosis (CAD) for analysis of medical images to diagnose diseases such as Hypertensive retinopathy, diabetic Retinopathy (HR). HR occurs due to hypertension for a prolonged period of time. It may lead to vision loss, if not treated at early stages. It can be observed by the changes in retinal vasculature that are caused by arterial hypertension. There are various features observed in fundus images such as arterial narrowing, bifurcation, tortuosity, etc. Computer-aided diagnosis plays a vital role in screening and grading of retinal images. There is still a need for automatic detection and grading of HR. This article presents the state-of-the-art methodologies used by researchers for predicting hypertensive retinopathy. Features that are present in retinal images have also been discussed for early detection of HR. The probable extraction techniques have been explored and evaluated based on layers used by different models. The classification technique discussed by different researchers has also been explored followed by the conclusion. This review will be beneficial for the researchers who want to focus on medical image analysis and enhancing the diagnosis of the system through CAD. © 2021 IEEE.",Biomedical imaging; Deep learning; fundus imaging; Hypertensive retinopathy; Medical Image analysis; Survey
Conference Paper,"Khan M.Z., Lee Y.",Ocular inspection to prevent vision impairment caused by diabetic retinopathy,"Proceedings - 2021 4th International Conference on Information and Computer Technologies, ICICT 2021",2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85111377958&doi=10.1109%2fICICT52872.2021.00024&partnerID=40&md5=b63def5111736a2efa28bc6cfe8fcd3a,"The retina is a unique tissue, considered an extension of the human brain that transforms the incoming light into neural signals. Many significant ocular diseases exhibit themselves in this central hub. Retinal images, therefore, play a vital part in the early detection of these chronic complications. Besides, the advancement of machine learning and biomedical imaging techniques has opened the doors for modern-day researchers to uncover life-threatening problems, such as diabetic retinopathy. This disease is common in middle-aged adults. It weakens the inner surface of retinal vessels, causing vision impairment. The precise diagnosis of diabetic retinopathy needs a computer-guided tool to automate the vessel extraction process. This article applied sequence block with U-Net architecture to segment ocular vasculature. Our approach efficiently used neighboring pixels to predict retinal vessels and generate a segmentation map with a baseline encoder-decoder structure. The vanishing gradient problem is resolved with long-term skip connections. The proposed approach is compared with state-of-the-art work. It is found that the sequence block boosted the U-Net performance on DRIVE and STARE datasets. The underlying method is an effort to limit the human biasness and error in ocular inspection and reduce the vision impairment rate in masses. © 2021 IEEE.",Deep learning; Diabetic retinopathy; Image segmentation; Retinal vessels; Sequence model
Conference Paper,"Chen Q., Sun X., Zhang N., Cao Y., Liu B.",Mini lesions detection on diabetic retinopathy images via large scale CNN features,"Proceedings - International Conference on Tools with Artificial Intelligence, ICTAI",2019,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85080953333&doi=10.1109%2fICTAI.2019.00056&partnerID=40&md5=c68a7c40085ee45f1dd9e5972b3861fe,"Diabetic retinopathy (DR) is a diabetes complication that affects eyes. DR is a primary cause of blindness in working-age people and it is estimated that 3 to 4 million people with diabetes are blinded by DR every year worldwide. Early diagnosis have been considered an effective way to mitigate such problem. The ultimate goal of our research is to develop novel machine learning techniques to analyze the DR images generated by the fundus camera for automatically DR diagnosis. In this paper, we focus on identifying small lesions on DR fundus images. The results from our analysis, which include the lesion category and their exact locations in the image, can be used to facilitate the determination of DR severity (indicated by DR stages). Different from traditional object detection for natural images, lesion detection for fundus images have unique challenges. Specifically, the size of a lesion instance is usually very small, compared with the original resolution of the fundus images, making them diffcult to be detected. We analyze the lesion-vs-image scale carefully and propose a large-size feature pyramid network (LFPN) to preserve more image details for mini lesion instance detection. Our method includes an effective region proposal strategy to increase the sensitivity. The experimental results show that our proposed method is superior to the original feature pyramid network (FPN) method and Faster RCNN. © 2019 IEEE.",Diabetic retinopathy; FPN; Mini lesion detection
Conference Paper,"Kumari S., Padmakumara N., Palangoda W., Balagalla C., Samarasingha P., Fernando A., Pemadasa N.",Automated diabetic retinopathy screening with montage fundus images,"ICAC 2020 - 2nd International Conference on Advancements in Computing, Proceedings",2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102452194&doi=10.1109%2fICAC51239.2020.9357137&partnerID=40&md5=f3afded67deeeaaa6dfa5bba895cb13f,"Diabetic retinopathy (DR), also known as diabetic eye disease is one of the major causes of blindness in the active population. The longer a person has diabetes, higher the chances of developing DR. This research paper is an attempt towards finding an automatic way to staging DR using montage eye images through artificial intelligence (AI). Convolutional neural networks (CNNs) play a big role in DR detection. Using transfer learning and hyper-parameter tuning DR staging is analyzed through different models. VGG16 gave the highest classification accuracies for the stages Proliferative DR (PDR) & Non-proliferative DR (NPDR). The highest level of NPDR is severe DR which achieved 94.9% classification accuracy (CA) & special features like cotton wool & laser treatment performed at 83.3% CA for each. Moreover, by using patient's history data such as age, right eye & left eye value accuracies & diabetic diagnosed year, system can predict the DR stages. That predictive model has achieved the best CA of 94 % by using Xgboost classifier. Overall, a fully functional app has been developed to detect DR stages with Montage Fundus images using AI. © 2020 IEEE.",Classification accuracy; Convolutional neural network; Diabetic retinopathy; Machine learning; Transfer learning
Conference Paper,"Elsharkawy M., Sharafeldeen A., Soliman A., Khalifa F., Ghazal M., El-Daydamony E., Atwan A., Sandhu H.S., El-Baz A.",Diabetic Retinopathy Diagnostic CAD System Using 3D-Oct Higher Order Spatial Appearance Model,Proceedings - International Symposium on Biomedical Imaging,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85129689645&doi=10.1109%2fISBI52829.2022.9761508&partnerID=40&md5=a81859f2740dbccfa6ff2ed035cdba0d,"Diagnoses of Diabetic Retinopathy (DR) at an early stage are of extreme importance so that the retina can be preserved and the risk of substantial damage to the retina or loss of vision is reduced. A new Computer-Aided Diagnosis (CAD) method based on Optical Coherence Tomography (OCT) scans of the retina is presented here for the detection of DR at an early stage. Utilizing an adaptive appearance-based approach that uses prior shape information, the system segments the retinal layers from the 3D-OCT scans. From the layers segmented from the B-scans volume of the OCT, novel texture features are extracted for DR diagnosis. In particular, a 2nd-order reflectivity value is calculated for each individual layer using the 2D Markov-Gibbs Random Field (2D-MGRF) model. Then, Cumulative Distribution Function (CDF) descriptors are used to represent the extracted image-derived feature using CDF's percentiles. A feed-forward neural network is used for layer-by-layer classification of 3D volume using Gibbs energy features extracted from each individual layer. In the final stage, all twelve layers are fused with a global subject diagnosis based on a majority voting method. We evaluated a 3D-OCT system using 180 subjects using a combination of different k-fold validation techniques. The system performance for this CAD system using 4-, 5-, and 10-fold cross validation achieved accuracies of 89.4%, 91.5%, and 95.7%, respectively. In addition, our system's ability to detect the DR early has been validated by further comparisons with the state-of-the-art deep learning networks. © 2022 IEEE.",2D-MGRF; 3-D OCT; CAD; DR
Conference Paper,Aljehane N.O.,An Intelligent Moth Flame Optimization with Inception Network for Diabetic Retinopathy Detection and Grading,"Proceedings of 2022 2nd International Conference on Computing and Information Technology, ICCIT 2022",2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85126806296&doi=10.1109%2fICCIT52419.2022.9711602&partnerID=40&md5=6ad1f1c6fa7fa26bb97d40c93800904f,"Diabetic Retinopathy (DR) is a widespread illness among diabetic patients that creates lesions on the retina affecting vision. When the DR is not identified in the earlier stage, the vision can be severely affected. Since the manual detection of DR using fundus images by ophthalmologists is time consuming, expensive, and not accurate, deep learning (DL) models have become a popular tool to detect and classify DR at the beginning stages. With this motivation, this paper designs an intelligent moth flame optimization with Inception network-based DR detection and grading (IMFO-INDR) model. The goal of the IMFO-INDR model is to detect the existence of lesions in the fundus image and assign proper class labels to it. The IMFO-INDR model involves histogram-based segmentation to determine the affected lesion areas in the fundus images. In addition, Inception v4 model is applied as feature extraction and the hyperparameters involved in it are optimally tuned by the use of MFO algorithm. At last, softmax classifier is used for the allocation of class labels to the input fundus images based on the extracted feature vectors. The experimental validation of the IMFO-INDR model takes place using the MESSIDOR database and the results are examined in terms of several aspects. The resultant values demonstrate the promising performance of the IMFO-INDR model over the existing DR diagnosis models. © 2022 IEEE.",Computer vision; Deep learning; Diabetic Retinopathy; Image classification; Image processing; MESSIDOR database
Article,"Joshi S., Karule P.T.",Mathematical morphology for microaneurysm detection in fundus images,European Journal of Ophthalmology,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85064952406&doi=10.1177%2f1120672119843021&partnerID=40&md5=5594d5082cf9d6c21d3525e486389cb4,"Aim: Fundus image analysis is the basis for the better understanding of retinal diseases which are found due to diabetes. Detection of earlier markers such as microaneurysms that appear in fundus images combined with treatment proves beneficial to prevent further complications of diabetic retinopathy with an increased risk of sight loss. Methods: The proposed algorithm consists of three modules: (1) image enhancement through morphological processing; (2) the extraction and removal of red structures, such as blood vessels preceded by detection and removal of bright artefacts; (3) finally, the true microaneurysm candidate selection among other structures based on feature extraction set. Results: The proposed strategy is successfully evaluated on two publicly available databases containing both normal and pathological images. The sensitivity of 89.22%, specificity of 91% and accuracy of 92% achieved for the detection of microaneurysms for Diaretdb1 database images. The algorithm evaluation for microaneurysm detection has a sensitivity of 83% and specificity 82% for e-ophtha database. Conclusion: In automated detection system, the successful detection of the number of microaneurysms correlates with the stages of the retinal diseases and its early diagnosis. The results for true microaneurysm detection indicates it as a useful tool for screening colour fundus images, which proves time saving for counting of microaneurysms to follow Diabetic Retinopathy Grading Criteria. © The Author(s) 2019.",diabetic retinopathy; Fundus images; microaneurysms; morphology; red lesions
Article,"Bhuiyan A., Govindaiah A., Alauddin S., Otero-Marquez O., Smith R.T.",Combined automated screening for age-related macular degeneration and diabetic retinopathy in primary care settings,Annals of Eye Science,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85109830861&doi=10.21037%2faes-20-114&partnerID=40&md5=ed723101bc37dbeb012c2389795b743c,"Background: Age-related macular degeneration (AMD) and diabetic retinopathy (DR) are among the leading causes of blindness in the United States and other developed countries. Early detection is the key to prevention and effective treatment. We have built an artificial intelligence-based screening system which utilizes a cloud-based platform for combined large scale screening through primary care settings for early diagnosis of these diseases. Methods: iHealthScreen Inc., an independent medical software company, has developed automated AMD and DR screening systems utilizing a telemedicine platform based on deep machine learning techniques. For both diseases, we prospectively imaged both eyes of 340 unselected non-dilated subjects over 50 years of age. For DR specifically, 152 diabetic patients at New York Eye and Ear faculty retina practices, ophthalmic and primary care clinics in New York city with color fundus cameras. Following the initial review of the images, 308 images with other confounding conditions like high myopia and vascular occlusion, and poor quality were excluded, leaving 676 eligible images for AMD and DR evaluation. Three ophthalmologists evaluated each of the images, and after adjudication, the patients were determined referrable or non-referable for AMD DR. Concerning AMD, 172 were labeled referable (intermediate or late), and 504 were non-referable (no or early). Concurrently, regarding DR, 33 were referable (moderate or worse), and 643 were non-referable (none or mild). All images were uploaded to iHealthScreen's telemedicine platform and analyzed by the automated systems for both diseases. The system performances are tested on per eye basis with sensitivity, specificity, accuracy, and kappa scores with respect to the professional graders. Results: In identifying referable DR, the system achieved a sensitivity of 97.0% and a specificity of 96.3%, and a kappa score of 0.70 on this prospective dataset. For AMD, the sensitivity was 86.6%, the specificity of 92.1%, and a kappa score of 0.76. Conclusions: The AMD and DR screening tools achieved excellent performance operating together to identify two retinal diseases prospectively in mixed datasets, demonstrating the feasibility of such tools in the early diagnosis of eye diseases. These early screening tools will help create an even more comprehensive system capable of being trained on other retinal pathologies, a goal within reach for public health deployment. © Annals of Eye Science. All rights reserved.",Age-related macular degeneration; Diabetic retinopathy; Primary care
Article,"Goel S., Gupta S., Panwar A., Kumar S., Verma M., Bourouis S., Ullah M.A.",Deep Learning Approach for Stages of Severity Classification in Diabetic Retinopathy Using Color Fundus Retinal Images,Mathematical Problems in Engineering,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85120918261&doi=10.1155%2f2021%2f7627566&partnerID=40&md5=44e056f283e80a4367bde2fd7be7601e,"Diabetes is a very fast-growing disease in India, with currently more than 72 million patients. Prolonged diabetes (about almost 20 years) can cause serious loss to the tiny blood vessels and neurons in the patient eyes, called diabetic retinopathy (DR). This first causes occlusion and then rapid vision loss. The symptoms of the disease are not very conspicuous in its early stage. The disease is featured by the formation of bloated structures in the retinal area called microaneurysms. Because of negligence, the condition of the eye worsens into the generation of more severe blots and damage to retinal vessels causing complete loss of vision. Early screening and monitoring of DR can reduce the risk of vision loss in patients with high possibilities. But the diabetic retinopathy detection and its classification by a human, is a challenging and error-prone task, because of the complexity of the image captured by color fundus photography. Machine learning algorithms armed with some feature extraction techniques have been employed earlier to detect and classify the levels of DR. However, these techniques provide below-par accuracy. Now, with the advent of deep learning (DL) techniques in computer vision, it has become possible to achieve very high levels of accuracy. DL models are an abstraction of the human brain coupled with the eyes. To create a model from scratch and train it is a cumbersome task requiring a huge amount of images. This deficiency of the DL techniques can be patched up by employing another technique to a task called transfer learning. In this, a DL model is trained on image metadata, and to learn features it used hundreds of classes from the DR fundus images. This enables professionals to create models capable of classifying unseen images into a proper grade or level with acceptable accuracy. This paper proposed a DL model coupled with different classifiers to classify the fundus image into its correct class of severity. We have trained the model on IDRD images and it has proven to show very high accuracy. © 2021 Silky Goel et al.",Blood vessels; Color photography; Deep learning; Diagnosis; Feature extraction; Image classification; Learning algorithms; Ophthalmology; Vision; Condition; Diabetic retinopathy; Fundus image; Learning approach; Learning models; Learning techniques; Microaneurysms; Retinal image; Retinal vessels; Vision loss; Eye protection
Article,"Chowdhury A.R., Chatterjee T., Banerjee S.",A Random Forest classifier-based approach in the detection of abnormalities in the retina,Medical and Biological Engineering and Computing,2019,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85052155640&doi=10.1007%2fs11517-018-1878-0&partnerID=40&md5=cf11caa59e58b68ef87ef9e37a252bd9,"Classification of abnormalities from medical images using computer-based approaches is of growing interest in medical imaging. Timely detection of abnormalities due to diabetic retinopathy and age-related macular degeneration is required in order to prevent the prognosis of the disease. Computer-aided systems using machine learning are becoming interesting to ophthalmologists and researchers. We present here one such technique, the Random Forest classifier, to aid medical practitioners in accurate diagnosis of the diseases. A computer-aided diagnosis system is proposed for detecting retina abnormalities, which combines K means-based segmentation of the retina image, after due preprocessing, followed by machine learning techniques, using several low level and statistical features. Abnormalities in the retina that are classified are caused by age-related macular degeneration and diabetic retinopathy. Performance measures used in the analysis are accuracy, sensitivity, specificity, F-measure, and Mathew correlation coefficient. A comparison with another machine learning technique, the Naïve Bayes classifier shows that the classification achieved by Random Forest classifier is 93.58% and it outperforms Naïve Bayes classifier which yields an accuracy of 83.63%. [Figure not available: see fulltext.]. © 2018, International Federation for Medical and Biological Engineering.","Age-related macular degeneration, K-means clustering; Diabetic retinopathy images; Naïve Bayes classifier; Random Forest classifier"
Article,"Dou P., Zhang Y., Zheng R.U.I., Ye Y.U., Mao J., Liu L.E.I., Wu M., Sun M.",RETINAL IMAGING and ANALYSIS USING MACHINE LEARNING with INFORMATION FUSION of the FUNCTIONAL and STRUCTURAL FEATURES BASED on A DUAL-MODAL FUNDUS CAMERA,Journal of Mechanics in Medicine and Biology,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85107835967&doi=10.1142%2fS0219519421500305&partnerID=40&md5=672728c636d0d7c5a05c6f1cf70e7649,"Retinal diseases and systemic diseases, such as diabetic retinopathy (DR) and Alzheimer's disease, may manifest themselves in the retina, changing the retinal oxygen saturation (SO2) level or the retinal vascular structures. Recent studies explored the correlation of diseases with either retina vascular structures or SO2 level, but not both due to the lack of proper instrument or methodology. In this study, we applied a dual-modal fundus camera and developed a deep learning-based analysis method to simultaneously acquire and quantify the SO2 and vascular structures. Deep learning was used to automatically locate the optic discs and segment arterioles and venules of the blood vessels. We then sought to apply machine learning methods, such as random forest (RF) and support vector machine (SVM), to fuse the SO2 level and retinal vessel parameters as different features to discriminate against the disease from the healthy controls. We showed that the fusion of the functional (oxygen saturation) and structural (vascular parameters) features offers better performance to classify diseased and healthy subjects. For example, we gained a 13.8% and 2.0% increase in the accuracy with fusion using the RF and SVM to classify the nonproliferative DR and the healthy controls. © 2021 World Scientific Publishing Company.",computer-aided diagnosis system; deep learning; dual-modal fundus camera; information fusion; Retinal oxygen saturation; retinal vessel parameters
Conference Paper,"Beluch W.H., Genewein T., Nürnberger A., Köhler J.M.",The Power of Ensembles for Active Learning in Image Classification,Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition,2018,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85061664748&doi=10.1109%2fCVPR.2018.00976&partnerID=40&md5=850034d1d2f23ac5a4ad7dd384fe5800,"Deep learning methods have become the de-facto standard for challenging image processing tasks such as image classification. One major hurdle of deep learning approaches is that large sets of labeled data are necessary, which can be prohibitively costly to obtain, particularly in medical image diagnosis applications. Active learning techniques can alleviate this labeling effort. In this paper we investigate some recently proposed methods for active learning with high-dimensional data and convolutional neural network classifiers. We compare ensemble-based methods against Monte-Carlo Dropout and geometric approaches. We find that ensembles perform better and lead to more calibrated predictive uncertainties, which are the basis for many active learning algorithms. To investigate why Monte-Carlo Dropout uncertainties perform worse, we explore potential differences in isolation in a series of experiments. We show results for MNIST and CIFAR-10, on which we achieve a test set accuracy of 90% with roughly 12,200 labeled images, and initial results on ImageNet. Additionally, we show results on a large, highly class-imbalanced diabetic retinopathy dataset. We observe that the ensemble-based active learning effectively counteracts this imbalance during acquisition. © 2018 IEEE.",Clustering algorithms; Computer vision; Deep learning; Diagnosis; Eye protection; Large dataset; Learning algorithms; Medical imaging; Monte Carlo methods; Neural networks; Active-learning algorithm; Convolutional neural network; Ensemble-based method; Geometric approaches; High dimensional data; Medical image diagnosis; Potential difference; Predictive uncertainty; Image classification
Article,Karsaz A.,Diabetic retinopathy screening using improved support vector domain description: a clinical study,Soft Computing,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85135210620&doi=10.1007%2fs00500-022-07387-z&partnerID=40&md5=3d8a3d67ef25686e60dc30c6756e7a92,"Diabetic retinopathy (DR) is the major cause of visual impairment among diabetic patients. Significant works have been done to hybrid a modified CNN architecture such as AlexNet with some of classifiers such as support vector machines (SVMs) or fuzzy C-Means (FCM) to improve the DR screening. This new hybrid innovative structure uses more efficient extracting features of a retinal images in both spatial and spectral domains. In spite the advantages of this innovative architecture, the different kernel functions affect the performance of the proposed algorithm. Using the appropriate transformed data into two- or three-dimensional feature maps and using an improved support vector domain description (ISVDD) can obtain more flexible and more accurate image description. To this end, the optimal degree values of different kernel functions can be extracted by using a particle swarm optimization (PSO) algorithm. Also, we compared the performance of our approach (modified-AlexNet-ISVDD) with the results obtained by hybrid modified AlexNet and some of classifiers such as K-Nearest Neighbors (KNN) and FCM clustering. We achieve the proposed CNN architecture using ISVDD on the DIARETDB1 and MESSIDOR datasets, with more than 99% sensitivity. © 2022, The Author(s), under exclusive licence to Springer-Verlag GmbH Germany, part of Springer Nature.",Clinical study; Deep learning; Diabetic retinopathy screening; Improved Support vector domain description (ISVDD); Optimal kernel functions; Particle swarm optimization (PSO)
Conference Paper,"Suriyal S., Druzgalski C., Gautam K.",Mobile assisted diabetic retinopathy detection using deep neural network,"2018 Global Medical Engineering Physics Exchanges/Pan American Health Care Exchanges, GMEPE/PAHCE 2018",2018,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050481398&doi=10.1109%2fGMEPE-PAHCE.2018.8400760&partnerID=40&md5=e5174f9490f9c6e84abd81c12a7f8da1,"Diabetic retinopathy (DR) is a major microvascular complication resulting from diabetes and continues to have a serious impact on global health systems. Globally about 95 million people suffer from DR. This paper focuses on detection aspects of a mobile application developed to perform DR screening in real time. The application is powered by a tensorflow deep neural network architecture that is trained and tested on 16,798 fundus images. These images are preprocessed to remove noise and prepare them to be fed into neural network. Preprocessing steps involve averaging all the images using a 5×5 filter to improve the quality of images and then these images are resized to 256×256 pixels. After preprocessing the input dataset is fed into the neural network. The convolutional neural network model used in this project is MobileNets, which is used for mobile devices. The neural network has 28 convolutional layers and after each layer there is batchnorm and ReLU nonlinear function except at the final layer. The output from last layer is a class label either DR or no DR. The final accuracy of the model is 73.3%. This model is optimized to work on mobile devices and does not require Internet connection to run. © 2018 IEEE.",convolutional neural network; deep learning; Diabetic Retinopathy; tensorflow
Article,"Ursin F., Timmermann C., Orzechowski M., Steger F.",Diagnosing Diabetic Retinopathy With Artificial Intelligence: What Information Should Be Included to Ensure Ethical Informed Consent?,Frontiers in Medicine,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85111931123&doi=10.3389%2ffmed.2021.695217&partnerID=40&md5=0d8edc442017fc345e2215dee92f1c10,"Purpose: The method of diagnosing diabetic retinopathy (DR) through artificial intelligence (AI)-based systems has been commercially available since 2018. This introduces new ethical challenges with regard to obtaining informed consent from patients. The purpose of this work is to develop a checklist of items to be disclosed when diagnosing DR with AI systems in a primary care setting. Methods: Two systematic literature searches were conducted in PubMed and Web of Science databases: a narrow search focusing on DR and a broad search on general issues of AI-based diagnosis. An ethics content analysis was conducted inductively to extract two features of included publications: (1) novel information content for AI-aided diagnosis and (2) the ethical justification for its disclosure. Results: The narrow search yielded n = 537 records of which n = 4 met the inclusion criteria. The information process was scarcely addressed for primary care setting. The broad search yielded n = 60 records of which n = 11 were included. In total, eight novel elements were identified to be included in the information process for ethical reasons, all of which stem from the technical specifics of medical AI. Conclusions: Implications for the general practitioner are two-fold: First, doctors need to be better informed about the ethical implications of novel technologies and must understand them to properly inform patients. Second, patient's overconfidence or fears can be countered by communicating the risks, limitations, and potential benefits of diagnostic AI systems. If patients accept and are aware of the limitations of AI-aided diagnosis, they increase their chances of being diagnosed and treated in time. © Copyright © 2021 Ursin, Timmermann, Orzechowski and Steger.",diabetic retinopathy; ethics; information process; informed consent; machine learning
Conference Paper,"Chen C., Chuah J.H., Ali R.",Retinal Vessel Segmentation in Fundus Images Using Convolutional Neural Network,"2021 International Conference on High Performance Big Data and Intelligent Systems, HPBD and IS 2021",2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85124906854&doi=10.1109%2fHPBDIS53214.2021.9658459&partnerID=40&md5=93b2905c1ebd2d5482ef524896df3cee,"The structure of retinal vessel can reflect health status of patients, and a clear representation of retinal vessel map helps ophthalmologist to make diagnosis of some disease, such as diabetic retinopathy (DR) and hypertension. However most automatic methods for the task cannot produce a good performance, they always misclassify pixels in vessel boundaries and thin vessels. In this paper, we propose a deep learning-based model for automatic accurate retinal vessel segmentation. We cascaded two U-net to construct a multi-model network and then obtain a coarse-To-fine segmentation. We introduced residual learning and added sufficient skip connections to reuse feature maps. We adopted dilated convolution and arranged dilation rates carefully to enable the model to capture more context information. Finally, we conducted intensive experiments on DRIVE, STARE, and CHASE_DB1 databases. Our proposed model can produce an accuracy of 0.9552/0.9699/0.9642, an AUC of 0.9787/0.9852/0.9846, a sensitivity of 0.8211/0.8466/0.8395 on DRIVE, STARE and CHASE_DB1 databases, respectively. © 2021 IEEE.",convolutional neural network; deep learning; fundus image; retinal vessel segmentation
Conference Paper,"Nazir T., Irtaza A., Rashid J., Nawaz M., Mehmood T.",Diabetic Retinopathy Lesions Detection using Faster-RCNN from retinal images,"Proceedings - 2020 1st International Conference of Smart Systems and Emerging Technologies, SMART-TECH 2020",2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099291533&doi=10.1109%2fSMART-TECH49988.2020.00025&partnerID=40&md5=45aaf28f84957cdae03c7f506a9e7fdb,"Diabetic Retinopathy is an eye disease that damages the retina which can cause vision loss. Early detection of DR is needed because the disease shows little signs in its initial stage due to the slow progression of the disease. The screening process of the eye is a time-consuming, costly, and tedious task due to the examination of every single patient. In this work, we deal with the localization of lesions of DR from retinal images. We have presented a novel method based on the Faster Region-based Convolutional Neural Network (RCNN) to overcome the challenges of DR lesions detection methods and precisely detect the early signs as well. Our method constitutes two steps: first is preprocessing and the other is the localization of abnormalities of DR i.e. hard exudates, soft exudates, microaneurysms, and hemorrhages. For performance evaluation, we have used the publicly available datasets i.e. Diaretdbl and Messidor and achieved average values of accuracy as 0.95 and Intersection over union (IOU) as 0.94. The proposed method achieved remarkable results as compared to state-of-the-art techniques. © 2020 IEEE.",Deep learning; Diabetic Retinopathy; Faster RCNN; Fundus imaging
Conference Paper,"Zhang F., Miao J., Wang W., Xiao Z., Xu X.",Automatic Discrimination of Fundus DR Based on Improved Residual Dense Block Network,ACM International Conference Proceeding Series,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85116545018&doi=10.1145%2f3468945.3468954&partnerID=40&md5=a79f9de393788e169a4716dedbe67afc,"Diabetic retinopathy is the most serious complication of diabetes. In hospital treatment or telemedicine, experts analyze and treat patients with Diabetic Retinopathy (DR) based on the retinal images captured by the fundus camera. However, large number of non-pathological fundus images occupy too much time for the ophthalmologist to diagnose, and delay the timely treatment of patients with fundus DR. Therefore, it is a very urgent task to automatically and objectively screen whether the fundus has DR. Based on deep learning, we proposes an improved residual-dense module convolutional neural network structure (Modified Residual Dense Block Convolution Neural Network, MRDB-CNN). DR fundus images and non-DR fundus images are used for model training and the overall accuracy of the network structure is assessed by test set. Experiments have proved that the module can extract the detailed features of the fundus DR. The MRDB-CNN network structure can obtain a better generalization ability and a higher-precision network classification model while avoiding the complex image preprocessing. The accuracy of DR discrimination reached 94.90%, which reaches the needs of initial screening of fundus DR in hospital treatment and telemedicine. © 2021 ACM.",Deep learning; Fundus DR discrimination; MRDB-CNN; Retinal images
Article,"Bhimavarapu U., Battineni G.",Automatic Microaneurysms Detection for Early Diagnosis of Diabetic Retinopathy Using Improved Discrete Particle Swarm Optimization,Journal of Personalized Medicine,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85125293365&doi=10.3390%2fjpm12020317&partnerID=40&md5=0bd9503266af140a9e7cdcfbed2ff502,"Diabetic retinopathy (DR) is one of the most important microvascular complications associated with diabetes mellitus. The early signs of DR are microaneurysms, which can lead to complete vision loss. The detection of DR at an early stage can help to avoid non-reversible blindness. To do this, we incorporated fuzzy logic techniques into digital image processing to conduct effective detection. The digital fundus images were segmented using particle swarm optimization to identify microaneurysms. The particle swarm optimization clustering combined the membership functions by grouping the high similarity data into clusters. Model testing was conducted on the publicly available dataset called DIARETDB0, and image segmentation was done by probability-based (PBPSO) clustering algorithms. Different fuzzy models were applied and the outcomes were compared with our probability discrete particle swarm optimization algorithm. The results revealed that the proposed PSO algorithm achieved an accuracy of 99.9% in the early detection of DR. © 2022 by the authors. Licensee MDPI, Basel, Switzerland.",Diabetic retinopathy; Fuzzy image processing; Microaneurysms; PSO clustering; Swarm intelligence
Article,"Deepa V., Sathish Kumar C., Cherian T.",Automated grading of diabetic retinopathy using CNN with hierarchical clustering of image patches by siamese network,Physical and Engineering Sciences in Medicine,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85130487362&doi=10.1007%2fs13246-022-01129-z&partnerID=40&md5=be31277a01cec4bc698a5f6f2f37e003,"Diabetic retinopathy (DR) is a progressive vascular complication that affects people who have diabetes. This retinal abnormality can cause irreversible vision loss or permanent blindness; therefore, it is crucial to undergo frequent eye screening for early recognition and treatment. This paper proposes a feature extraction algorithm using discriminative multi-sized patches, based on deep learning convolutional neural network (CNN) for DR grading. This comprehensive algorithm extracts local and global features for efficient decision-making. Each input image is divided into small-sized patches to extract local-level features and then split into clusters or subsets. Hierarchical clustering by Siamese network with pre-trained CNN is proposed in this paper to select clusters with more discriminative patches. The fine-tuned Xception model of CNN is used to extract the global-level features of larger image patches. Local and global features are combined to improve the overall image-wise classification accuracy. The final support vector machine classifier exhibits 96% of classification accuracy with tenfold cross-validation in classifying DR images. © 2022, Australasian College of Physical Scientists and Engineers in Medicine.",Diabetic retinopathy; Hierarchical clustering; Multi-sized patches; Pre-trained CNN models; Siamese network
Article,"Tsuji T., Hirose Y., Fujimori K., Hirose T., Oyama A., Saikawa Y., Mimura T., Shiraishi K., Kobayashi T., Mizota A., Kotoku J.",Classification of optical coherence tomography images using a capsule network,BMC Ophthalmology,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85082066708&doi=10.1186%2fs12886-020-01382-4&partnerID=40&md5=aa2813d234c88f9e646ee360ea949974,"Background: Classification of optical coherence tomography (OCT) images can be achieved with high accuracy using classical convolution neural networks (CNN), a commonly used deep learning network for computer-aided diagnosis. Classical CNN has often been criticized for suppressing positional relations in a pooling layer. Therefore, because capsule networks can learn positional information from images, we attempted application of a capsule network to OCT images to overcome that shortcoming. This study is our attempt to improve classification accuracy by replacing CNN with a capsule network. Methods: From an OCT dataset, we produced a training dataset of 83,484 images and a test dataset of 1000 images. For training, the dataset comprises 37,205 images with choroidal neovascularization (CNV), 11,348 with diabetic macular edema (DME), 8616 with drusen, and 26,315 normal images. The test dataset has 250 images from each category. The proposed model was constructed based on a capsule network for improving classification accuracy. It was trained using the training dataset. Subsequently, the test dataset was used to evaluate the trained model. Results: Classification of OCT images using our method achieved accuracy of 99.6%, which is 3.2 percentage points higher than that of other methods described in the literature. Conclusion: The proposed method achieved classification accuracy results equivalent to those reported for other methods for CNV, DME, drusen, and normal images. © 2020 The Author(s).",Capsule network; Choroidal neovascularization; Deep learning; Diabetic macular edema; Drusen; Optical coherence tomography
Conference Paper,"Yu Z., Yang X., Sweeting G.L., Ma Y., Stolte S.E., Fang R., Wu Y.",Identify Diabetic Retinopathy-related Clinical Concepts Using Transformer-based Natural Language Processing Methods,"Proceedings - 2021 IEEE 9th International Conference on Healthcare Informatics, ISCHI 2021",2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85118103728&doi=10.1109%2fICHI52183.2021.00089&partnerID=40&md5=8129d299aeaa65e5d2ef00c362e86781,"Diabetic retinopathy (DR) is a leading cause of blindness in American adults. If detected early, DR can be treated to preventing further damage causing blindness, therefore, early detection is very important for the treatment of DR. There is an increasing interest in developing Al technologies to help early detection of DR using electronic health records (EHR). The detailed diagnoses information documented in image reports is a valuable resource that could help detect lesions from the medical image, thus helping early detection of DR. In this study, we examined two state-of-the-art transformer-based natural language processing models, including BERT and RoBERTa, to extract DR-related concepts from clinical narratives. We identified four different categories of DR-related clinical concepts including lesions, eye parts, laterality, and severity, developed annotation guidelines, annotated a DR-corpus of 536 image reports, and trained four transformer-based NLP models for clinical concept extraction. The experimental results show that the BERT model pretrained with the MIMIC III dataset achieved the best strict/lenient F1-score of 0.9503 and 0.9645, respectively. © 2021 IEEE.",Deep learning; Diabetic retinopathy; Named entity recognition; Natural language processing
Article,"Bernardini M., Romeo L., Mancini A., Frontoni E.",A Clinical Decision Support System to Stratify the Temporal Risk of Diabetic Retinopathy,IEEE Access,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85119418547&doi=10.1109%2fACCESS.2021.3127274&partnerID=40&md5=32fc07d51482b1b0759351fa42238d2f,"Diabetic Retinopathy (DR) is the most common and insidious microvascular complication of diabetes, and can progress asymptomatically until a sudden loss of vision occurs. Although DR is prevalent nowadays, its prevention remains challenging. The multiple aim of this study was to predict the risk of developing DR as diabetic complication (task 1) and, subsequently, temporally stratify the DR risk (task 2) using electronic health records data. To perform these objectives, a novel preprocessing procedure was designed to select both control and pathological patients, and moreover, a novel fully annotated/standardized 120K dataset from multiple diabetologic centers was provided. Globally, although the Extreme Gradient Boosting model offers satisfying predictive performance, the Random Forest model obtained the best predictive performance to solve task 1 and task 2, reaching the best Area Under the Precision-Recall Curve of 72.43 % and 84.38 %, respectively. Also the features importance extracted from the best Machine Learning (ML) models is provided. The proposed Artificial Intelligence-based solution was proven to be capable of generalizing across different diabetologic centers while ensuring high-interpretability. Moreover, the proposed ML solution is currently being adopted as a Clinical Decision Support System in several diabetologic centers for DR screening and follow-up purposes. © 2013 IEEE.",diabetic retinopathy; electronic health records; machine learning; Predictive medicine
Article,"Amin S., Alouffi B., Uddin M.I., Alosaimi W.",Optimizing Convolutional Neural Networks with Transfer Learning for Making Classification Report in COVID-19 Chest X-Rays Scans,Scientific Programming,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85130567591&doi=10.1155%2f2022%2f5145614&partnerID=40&md5=14fa1d6a555d1f65518ba05892861e08,"The coronavirus disease (COVID-19) outbreak, which began in December 2019, has claimed numerous lives and impacted all aspects of human life. COVID-19 was deemed an outbreak by the World Health Organization (WHO) as time passed, putting a tremendous strain on substantially all countries, particularly those with poor health services and delayed reaction times. This recently identified virus is highly contagious. Controlling the rapid spread of this infection requires early detection of infected people through comprehensive screening. For COVID-19 viral diagnosis and follow-up, chest radiography imaging is an excellent tool. Deep learning (DL) has been used for a variety of healthcare purposes, including diabetic retinopathy detection, image classification, and thyroid diagnosis. DL is a useful strategy for combating the COVID-19 outbreak because there are so many streams of medical images (e.g., X-rays, CT, and MRI). In this study, we used the benchmark chest X-ray scan (CXRS) dataset for both COVID-19-infected and noninfected patients. We evaluate the results of DL-based convolutional neural network (CNN) models after preprocessing the scans and using data augmentation. Transfer learning (TL) is used to improve the algorithm's classification performance for chest radiography imaging. Finally, features of the attention and feature interweave modules are combined to create a more accurate feature map. The architecture is trained for COVID-19 CXRS using CNN, and the newly generated feature layer is applied to TL architecture. The experimental results found that training enhances the CNN + TL algorithm's ability to classify CXRS with an overall detection accuracy of 99.3%, precision (0.97), recall (0.98), f-measure (0.98), and receiver operating characteristic (ROC) curve (area = 0.97). The results show that further training improves the classification architecture's performance by 99.3%. © 2022 Samina Amin et al.",Computer aided diagnosis; Computerized tomography; Convolution; Coronavirus; Deep learning; Eye protection; Magnetic resonance imaging; Medical imaging; Network architecture; X ray radiography; Chest radiography; Convolutional neural network; Coronaviruses; Diabetic retinopathy; Follow up; Health services; Human lives; Images classification; Transfer learning; World Health Organization; Convolutional neural networks
Conference Paper,"Fang X., Shen Y., Zheng B., Zhu S., Wu M.",Optic Disc Segmentation Based on Phase-fusion PSPNet,ACM International Conference Proceeding Series,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85122084626&doi=10.1145%2f3500931.3500959&partnerID=40&md5=f276dea6da85c6c3ccb034e9bd298a55,"In the analysis of fundus images, optic disc segmentation is vital to judge eye diseases such as diabetic retinopathy and glaucoma. Improving the accuracy of optic disc segmentation is of great significance to the diagnosis of the above diseases. Based on the PSPNet model, the Phase-Fusion PSPNet network structure is proposed. The network is connected to the phase upsampling module after the pyramid pooling module, which reduces information loss and makes the network suitable for segmentation tasks with fuzzy edges. The principle of phase upsampling module is to upsample the larger size span step by step and combine it with the corresponding size feature map. iChallenge-PM, iChallenge-AMD, and iChallenge-GON as the training and validation datasets in the paper. The IoU and PA of Phase-fusion PSPNet are 89.93% and 94.94%. Compared with PSPNet, the IoU and PA increased by 1.22% and 1.62% respectively. Experiments show that adding the phase upsampling module makes the model have a better segmentation performance. © 2021 ACM.",Deep learning; Intelligent medical; Optic disc segmentation; Phase upsampling; PSPNet
Conference Paper,"Baharlouei Z., Rabbani H., Plonka G.",Detection of Retinal Abnormalities in OCT Images Using Wavelet Scattering Network,"Proceedings of the Annual International Conference of the IEEE Engineering in Medicine and Biology Society, EMBS",2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85138127335&doi=10.1109%2fEMBC48229.2022.9871989&partnerID=40&md5=74c5dddc4667a5c41ae72b2cf4b3b195,"Diagnosis retinal abnormalities in Optical Coherence Tomography (OCT) images assist ophthalmologist in the early detection and treatment of patients. To do this, different Computer Aided Diagnosis (CAD) methods based on machine learning and deep learning algorithms have been proposed. In this paper, wavelet scattering network is used to identify normal retina and four pathologies namely, Central Serous Retinopathy (CSR), Macular Hole (MH), Age-related Macular Degeneration (AMD) and Diabetic Retinopathy (DR). Wavelet scattering network is a particular convolutional network which is formed from cascading wavelet transform with nonlinear modulus and averaging operators. This transform generates sparse, translation invariant and deformation stable representations of signals. Filters in the layers of this network are predefined wavelets and not need to be learned which causes decreasing the processing time and complexity. The extracted features are fed to a Principal Component Analysis (PCA) classifier. The results of this research show the accuracy of 97.4% and 100% in diagnosis abnormal retina and DR from normal ones, respectively. We also achieved the accuracy of 84.2% in classifying OCT images to five classes of normal, CSR, MH, AMD and DR which outperforms other state of the art methods with high computational complexity. Clinical Relevance- Clinically, the manually checking of each OCT B-scan by ophthalmologists is tedious and time consuming and may lead to an erroneous decision specially for multiclass problems. In this study, a low complexity CAD system for retinal OCT image classification based on wavelet scattering network is introduced which can be learned by a small number of data. © 2022 IEEE.","Deep learning; Eye protection; Image classification; Learning algorithms; Network layers; Ophthalmology; Optical tomography; Patient treatment; Principal component analysis; Wavelet transforms; Age-related macular degeneration; Averaging operators; Convolutional networks; Diabetic retinopathy; Diagnosis methods; Machine-learning; Macular hole; On-machines; Scattering networks; Wavelets transform; Computer aided diagnosis; central serous retinopathy; diabetic retinopathy; diagnostic imaging; human; macular degeneration; optical coherence tomography; procedures; retina; retina tear; Central Serous Chorioretinopathy; Diabetic Retinopathy; Humans; Macular Degeneration; Retina; Retinal Perforations; Tomography, Optical Coherence"
Article,"Xiao D., Bhuiyan A., Frost S., Vignarajan J., Tay-Kearney M.-L., Kanagasingam Y.",Major automatic diabetic retinopathy screening systems and related core algorithms: a review,Machine Vision and Applications,2019,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85061040370&doi=10.1007%2fs00138-018-00998-3&partnerID=40&md5=bc4642ffeb57f731898fd33370b21c19,"Diabetic retinopathy (DR), one of the major and long-term microvascular complications of diabetes, is the most common cause of vision loss and blindness in the working population of the world. Even with the management of diabetes, most patients will develop some forms of DR after approximately 20 years. However, DR is a treatable disease throughout the disease progression. To provide appropriate DR management, the USA and European countries have successfully implemented systematic early DR screening programs. At the same time, some computer-aided DR screening systems, which combine advanced DR detection algorithms and telemedicine technology, have also been developed for early-stage DR detection. Some of them have been tested in the DR screening programs. In this paper, we focus on a review of the major automatic DR screening systems which have performed large-scale evaluation rather than give an extensive review of all published DR grading algorithms. We first present the structures of the automatic systems and their supporting algorithms developed by the research groups, as well as the practices of the systems in their screening programs. We further present a more detailed review of the DR lesion detection algorithms in each system and reveal how the DR screening systems successfully practiced in clinical trials or large-scale screening programs. We also review recently new research areas as well as deep learning-based DR screening systems and compare them with the traditional lesion detection-based DR screening systems. The performances of the systems in the trials are summarized by considering the specificity and sensitivity with respect to the scale of testing datasets. At last, we will discuss future challenges. © 2019, Springer-Verlag GmbH Germany, part of Springer Nature.",Automatic DR screening system; Diabetic retinopathy; DR grading algorithm; DR screening program
Article,"Ibrahim M.R., Fathalla K.M., Youssef S.M.",HyCAD-OCT: A hybrid computer-aided diagnosis of retinopathy by optical coherence tomography integrating machine learning and feature maps localization,Applied Sciences (Switzerland),2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85088652312&doi=10.3390%2fapp10144716&partnerID=40&md5=a94de2ceda85df2ec73a2a650cca4f12,"Optical Coherence Tomography (OCT) imaging has major advantages in effectively identifying the presence of various ocular pathologies and detecting a wide range of macular diseases. OCT examinations can aid in the detection of many retina disorders in early stages that could not be detected in traditional retina images. In this paper, a new hybrid computer-aided OCT diagnostic system (HyCAD) is proposed for classification of Diabetic Macular Edema (DME), Choroidal Neovascularization (CNV) and drusen disorders, while separating them from Normal OCT images. The proposed HyCAD hybrid learning system integrates the segmentation of Region of Interest (RoI), based on central serious chorioretinopathy (CSC) in Spectral Domain Optical Coherence Tomography (SD-OCT) images, with deep learning architectures for effective diagnosis of retinal disorders. The proposed system assimilates a range of techniques including RoI localization and feature extraction, followed by classification and diagnosis. An efficient feature fusion phase has been introduced for combining the OCT image features, extracted by Deep Convolutional Neural Network (CNN), with the features extracted from the RoI segmentation phase. This fused feature set is used to predict multiclass OCT retina disorders. The proposed segmentation phase of retinal RoI regions adds substantial contribution as it draws attention to the most significant areas that are candidate for diagnosis. A new modified deep learning architecture (Norm-VGG16) is introduced integrating a kernel regularizer. Norm-VGG16 is trained from scratch on a large benchmark dataset and used in RoI localization and segmentation. Various experiments have been carried out to illustrate the performance of the proposed system. Large Dataset of Labeled Optical Coherence Tomography (OCT) v3 benchmark is used to validate the efficiency of the model compared with others in literature. The experimental results show that the proposed model achieves relatively high-performance in terms of accuracy, sensitivity and specificity. An average accuracy, sensitivity and specificity of 98.8%, 99.4% and 98.2% is achieved, respectively. The remarkable performance achieved reflects that the fusion phase can effectively improve the identification ratio of the urgent patients' diagnostic images and clinical data. In addition, an outstanding performance is achieved compared to others in literature. © 2020 by the authors.",CNN; Deep learning; Feature fusion; Feature generation; OCT; Retina disorders; RoI segmentation
Conference Paper,"Praveena S., Lavanya R.",Superpixel based segmentation for multilesion detection in diabetic retinopathy,"Proceedings of the International Conference on Trends in Electronics and Informatics, ICOEI 2019",2019,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85075872532&doi=10.1109%2ficoei.2019.8862636&partnerID=40&md5=f481720eff79b63f99168ac484805656,"Diabetic Retinopathy (DR) is a progressive chronic vision-threatening disease of retinal microvasculature associated with prolonged hyperglycaemia, hypertension and other conditions associated with diabetes. Indicators of DR include different kinds of lesions appearing on the retinal surface that are visible in a Digital Fundus Photograph (DFP). Localization of lesions and visual perception is essential to aid physicians in understanding the severity of the condition and to plan an appropriate treatment procedure for the patient. Segmentation inaccuracies due to factors like subtle nature of abnormalities and interference of blood vessels reflect in reduced classification accuracy in case of Feature Based Machine Learning (FML). While Pixel Based Machine Learning (PML) can overcome these issues, they require high computational capabilities and are redundant. Non-segmentation approaches like deep learning have been employed as an alternative for DR diagnosis. However, these techniques directly grade the image through classification and do not allow for visual perception. Thus we have used an intermediate approach called Super-pixel based segmentation that can overcome the problems in FML and PML while retaining the advantages of both. They are consistent with human visual perception and also overcome the data insufficiency problem. In this paper, we have compared the results of multilesion detection associated with DR using super-pixels segmented from three different algorithms namely, Compacted Watershed (CWS), Simple Linear Iterative Clustering (SLIC) & Linear Spectral Clustering (LSC) under a single unified framework. Experimental results show that LSC over-performs both SLIC and CWS quantitatively and qualitatively. ©2019 IEEE.",Blood vessels; Clustering algorithms; Deep learning; Diagnosis; Iterative methods; Machine learning; Ophthalmology; Patient treatment; Superpixels; Vision; Classification accuracy; Computational capability; Diabetic retinopathy; Fundus photographs; Human visual perception; Iterative clustering; Localization of lesions; Unified framework; Eye protection
Article,"Zago G.T., Andreão R.V., Dorizzi B., Teatini Salles E.O.",Diabetic retinopathy detection using red lesion localization and convolutional neural networks,Computers in Biology and Medicine,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85074980557&doi=10.1016%2fj.compbiomed.2019.103537&partnerID=40&md5=526b27fbc3560dbd68b93b736ca2093c,"Detecting the early signs of diabetic retinopathy (DR) is essential, as timely treatment might reduce or even prevent vision loss. Moreover, automatically localizing the regions of the retinal image that might contain lesions can favorably assist specialists in the task of detection. In this study, we designed a lesion localization model using a deep network patch-based approach. Our goal was to reduce the complexity of the model while improving its performance. For this purpose, we designed an efficient procedure (including two convolutional neural network models) for selecting the training patches, such that the challenging examples would be given special attention during the training process. Using the labeling of the region, a DR decision can be given to the initial image, without the need for special training. The model is trained on the Standard Diabetic Retinopathy Database, Calibration Level 1 (DIARETDB1) database and is tested on several databases (including Messidor) without any further adaptation. It reaches an area under the receiver operating characteristic curve of 0.912−95%CI(0.897−0.928) for DR screening, and a sensitivity of 0.940−95%CI(0.921−0.959). These values are competitive with other state-of-the-art approaches. © 2019 Elsevier Ltd",Convolutional neural networks; Deep learning; Diabetic retinopathy; Retinal images
Conference Paper,"Gayathri S., Mredhula L.",Extraction of Textural Features from Retinal Fundus Images,"2019 5th International Conference on Advanced Computing and Communication Systems, ICACCS 2019",2019,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85067997485&doi=10.1109%2fICACCS.2019.8728511&partnerID=40&md5=9289550eeee96ceab58b9b142de457fb,Glaucoma and Diabetic retinopathy are the two main diseases that affect the human eye. Irreversible damage and partial loss of vision are caused by these diseases if not treated at the earliest. Glaucoma is a painless neurological disease in which fluid pressure in the eye increases constantly. It damages the optic nerve and thereby affects the sight of the patient. It is considered as the one of important reason for blindness universally. Conventional screening methods enable us to identify these diseases only after it has caused partial damage (25% or more) to the eye. Detection of glaucoma using computational decision support systems at the early stage can help prevent this complication. This paper proposes extraction of textural feature from fundus images of retina which aids in the detection of glaucoma. © 2019 IEEE.,Glaucoma; GLCM; Optic cup; Optic disc; Rim vessels
Article,"Sarhan M.H., Nasseri M.A., Zapp D., Maier M., Lohmann C.P., Navab N., Eslami A.",Machine Learning Techniques for Ophthalmic Data Processing: A Review,IEEE Journal of Biomedical and Health Informatics,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097571435&doi=10.1109%2fJBHI.2020.3012134&partnerID=40&md5=577439697e5bd554ae22660ffaf0f38c,"Machine learning and especially deep learning techniques are dominating medical image and data analysis. This article reviews machine learning approaches proposed for diagnosing ophthalmic diseases during the last four years. Three diseases are addressed in this survey, namely diabetic retinopathy, age-related macular degeneration, and glaucoma. The review covers over 60 publications and 25 public datasets and challenges related to the detection, grading, and lesion segmentation of the three considered diseases. Each section provides a summary of the public datasets and challenges related to each pathology and the current methods that have been applied to the problem. Furthermore, the recent machine learning approaches used for retinal vessels segmentation, and methods of retinal layers and fluid segmentation are reviewed. Two main imaging modalities are considered in this survey, namely color fundus imaging, and optical coherence tomography. Machine learning approaches that use eye measurements and visual field data for glaucoma detection are also included in the survey. Finally, the authors provide their views, expectations and the limitations of the future of these techniques in the clinical practice. © 2013 IEEE.",age-related macular degeneration; deep learning; diabetic retinopathy; glaucoma; Ophthalmic diagnostics
Article,"Yan Z., Yang X., Cheng K.-T.",Joint segment-level and pixel-wise losses for deep learning based retinal vessel segmentation,IEEE Transactions on Biomedical Engineering,2018,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85045728445&doi=10.1109%2fTBME.2018.2828137&partnerID=40&md5=f02666ce52d5aeb6a28030a0d7bda3a0,"Objective: Deep learning based methods for retinal vessel segmentation are usually trained based on pixel-wise losses, which treat all vessel pixels with equal importance in pixel-to-pixel matching between a predicted probability map and the corresponding manually annotated segmentation. However, due to the highly imbalanced pixel ratio between thick and thin vessels in fundus images, a pixel-wise loss would limit deep learning models to learn features for accurate segmentation of thin vessels, which is an important task for clinical diagnosis of eye-related diseases. Methods: In this paper, we propose a new segment-level loss which emphasizes more on the thickness consistency of thin vessels in the training process. By jointly adopting both the segment-level and the pixel-wise losses, the importance between thick and thin vessels in the loss calculation would be more balanced. As a result, more effective features can be learned for vessel segmentation without increasing the overall model complexity. Results: Experimental results on public data sets demonstrate that the model trained by the joint losses outperforms the current state-of-the-art methods in both separate-training and cross-training evaluations. Conclusion: Compared to the pixel-wise loss, utilizing the proposed joint-loss framework is able to learn more distinguishable features for vessel segmentation. In addition, the segment-level loss can bring consistent performance improvement for both deep and shallow network architectures. Significance: The findings from this study of using joint losses can be applied to other deep learning models for performance improvement without significantly changing the network architectures. © 1964-2012 IEEE.",Deep learning; Retinal image analysis; Segment-level loss; Vessel segmentation
Article,Sikkandar M.Y.,Automatic Detection of Genetics and Genomics of Eye Disease Using Deep Assimilation Learning Algorithm,Interdisciplinary Sciences – Computational Life Sciences,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85098753015&doi=10.1007%2fs12539-020-00404-5&partnerID=40&md5=7415f54c29aac3ba90578eb8b61b6429,"Diabetic retinopathy (DR) is one of the most prevalent genetic diseases in human and it is caused by damage to the blood vessels in the eye retina. If it is undetected and untreated at right time, it can lead to vision loss. There are many medical imaging and processing technologies to improve the diagnostic process of DR to overcome the lack of human experts. In the existing image processing methods, there are issues such as lack of noise removal, improper clustering segmentation and less classification accuracy. This can be accomplished by automatic diagnosis of DR using advanced image processing method. The cotton wool spot (CWS), hard exudates (HE) contains a common manifestation of many diseases in retina including DR and acquired immunodeficiency syndrome. In the present work, super iterative clustering algorithm (SICA) is proposed to identify the CWS, HE on retinal image. Feature-based medical image retrieval (FBMIR) datasets are utilized for this purpose. Noises present on the images and histogram-filtering technique is used to convert red, green, and blue (RGB) images into a perfect greyscale image without noise. After pre-processing, SICA is used to identify the CWS, HE detection on retinal images and eliminates unnecessary areas of interest. In the third stage, after detecting CWS and HE, various statistical features are extracted for further classification using deep assimilation learning algorithm (DALA). The performance of DALA technique is examined with various classification parameters like recall, precision, and F-measure. Finally, the false classification ratios are computed to compare the performance of the trained networks. The proposed method produces accurate detection of affected regions with an accuracy ratio of 98.5% and it is higher than the other conventional methods. This method may improve the accuracy of automatic detection and classification of eye diseases. © 2021, International Association of Scientists in the Interdisciplinary Areas.",Cotton wool spot (CES); Deep assimilation learning algorithm (DALA); Hard exudates (HE) detection; Histogram filtering techniques; Super iterative clustering algorithm
Article,"Ghosh S.K., Biswas B., Ghosh A.",SDCA: A novel stack deep convolutional autoencoder – An application on retinal image denoising,IET Image Processing,2019,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85077436152&doi=10.1049%2fiet-ipr.2018.6582&partnerID=40&md5=732fc3f86d98c44d45b2adf9cd297ecf,"Retinal fundus images are used for the diagnosis and treatment of various eye diseases such as diabetic retinopathy, glaucoma, exudates and so on. The retinal vasculature is difficult to investigate retinal conditions due to the presence of various noises in the retinal image during the capture of the image. Removal of noise is an important aspect for better visibility and diagnosis of the noisy fundus in ophthalmology. This study represents a deep learning based approach to denoising images and restoring features using stack denoising convolutional autoencoder. The proposed scheme is implemented to restore the structural details of fundus as well as to decrease the noise level. Furthermore, the proposed model utilises shared layers with the optimal manner to reduce the noise level of the target image with minimal computational cost. To restore an image, the proposed model brings a patched base training on samples to suppress with one to one manner without any loss of information. To access the denoising effect of the proposed scheme, several standard fundus databases such as DRIVE, STARE and DIARETDB1 have been tested in this study. Comparing the efficiency of the suggested model with state-of-art methods, the proposed scheme gives better result in terms of qualitative and quantitative analysis. © The Institution of Engineering and Technology 2019.",Convolution; Deep learning; Diagnosis; Eye protection; Image reconstruction; Ophthalmology; Restoration; Computational costs; Diabetic retinopathy; Learning-based approach; Qualitative and quantitative analysis; Retinal fundus images; Retinal vasculature; State-of-art methods; Structural details; Image denoising
Article,"Lois N., Cook J., Wang A., Aldington S., Mistry H., Maredza M., McAuley D., Aslam T., Bailey C., Chong V., Ghanchi F., Scanlon P., Sivaprasad S., Steel D., Styles C., Azuara-Blanco A., Prior L., Waugh N., Saad A., Azuara-Blanco A., Styles C., Steel D.H., Ghanchi F.D., Eleftheriadis H., Efraimidis S., Acharya N., Waugh N., Maredza M., Sivaprasad S., Aslam T.M., Chong V., Bailey C., McNally C., Menon G., Cook J., Wang A., Sones W., Prior L., Aldington S., Scanlon P.H., Ivanova K., EMERALD Study Group",Multimodal imaging interpreted by graders to detect re-activation of diabetic eye disease in previously treated patients: The emerald diagnostic accuracy study,Health Technology Assessment,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85107412076&doi=10.3310%2fHTA25320&partnerID=40&md5=cd910b5cdfc23971bf8300923a5a7160,"Background: Owing to the increasing prevalence of diabetes, the workload related to diabetic macular oedema and proliferative diabetic retinopathy is rising, making it difficult for hospital eye services to meet demands. Objective: The objective was to evaluate the diagnostic performance, cost-effectiveness and acceptability of a new pathway using multimodal imaging interpreted by ophthalmic graders to detect reactivation of diabetic macular oedema/proliferative diabetic retinopathy in previously treated patients. Design This was a prospective, case-referent, cross-sectional diagnostic study. Setting: The setting was ophthalmic clinics in 13 NHS hospitals. Participants: Adults with type 1 or type 2 diabetes with previously successfully treated diabetic macular oedema/proliferative diabetic retinopathy in one/both eyes in whom, at the time of enrolment, diabetic macular oedema/proliferative diabetic retinopathy could be active or inactive Methods: For the ophthalmic grader pathway, review of the spectral domain optical coherence tomography scans to detect diabetic macular oedema, and seven-field Early Treatment Diabetic Retinopathy Study/ultrawide field fundus images to detect proliferative diabetic retinopathy, by trained ophthalmic graders. For the current standard care pathway (reference standard), ophthalmologists examined patients face to face by slit-lamp biomicroscopy for proliferative diabetic retinopathy and, in addition, spectral domain optical coherence tomography imaging for diabetic macular oedema. Outcome measures: The primary outcome measure was sensitivity of the ophthalmic grader pathway to detect active diabetic macular oedema/proliferative diabetic retinopathy. The secondary outcomes were specificity, agreement between pathways, cost-consequences, acceptability and the proportion of patients requiring subsequent ophthalmologist assessment, unable to undergo imaging and with inadequate quality images/indeterminate findings. It was assumed for the main analysis that all patients in whom graders diagnosed active disease or were ‘unsure’ or images were ‘ungradable’ required examination by an ophthalmologist. Results: Eligible participants with active and inactive diabetic macular oedema (152 and 120 participants, respectively) and active and inactive proliferative diabetic retinopathy (111 and 170 participants, respectively) were recruited. Under the main analysis, graders had a sensitivity of 97% (142/147) (95% confidence interval 92% to 99%) and specificity of 31% (35/113) (95% confidence interval 23% to 40%) to detect diabetic macular oedema. For proliferative diabetic retinopathy, graders had a similar sensitivity and specificity using seven-field Early Treatment Diabetic Retinopathy Study [sensitivity 85% (87/102), 95% confidence interval 77% to 91%; specificity 48% (77/160), 95% confidence interval 41% to 56%] or ultra-wide field imaging [sensitivity 83% (87/105), 95% confidence interval 75% to 89%; specificity 54% (86/160), 95% confidence interval 46% to 61%]. Participants attending focus groups expressed preference for face-to-face evaluations by ophthalmologists. In the ophthalmologists’ absence, patients voiced the need for immediate feedback following grader’s assessments, maintaining periodic evaluations by ophthalmologists. Graders and ophthalmologists were supportive of the new pathway. When compared with the reference standard (current standard pathway), the new grader pathway could save £1390 per 100 patients in the review of people with diabetic macular oedema and, depending on the imaging modality used, between £461 and £1189 per 100 patients in the review of people with proliferative diabetic retinopathy. Conclusions: For people with diabetic macular oedema, the ophthalmic grader pathway appears safe and cost saving. The sensitivity of the new pathway to detect active proliferative diabetic retinopathy was lower, but may still be considered acceptable for patients with proliferative diabetic retinopathy previously treated with laser. Suggestions from focus group discussions should be taken into consideration if the new pathway is introduced to ensure its acceptability to users. Limitations: Lack of fundus fluorescein angiography to confirm diagnosis of active proliferative diabetic retinopathy. Future work: Could refinement of the new pathway increase its sensitivity to detect proliferative diabetic retinopathy? Could artificial intelligence be used for automated reading of images in this previously treated population? Trial registration: Current Controlled Trials ISRCTN10856638 and ClinicalTrials.gov NCT03490318. © Queen’s Printer and Controller of HMSO 2021.","adult; Article; clinical outcome; cost effectiveness analysis; cross-sectional study; diabetic macular edema; diagnostic accuracy; diagnostic test accuracy study; female; human; imaging; major clinical study; male; middle aged; multimodal imaging; non insulin dependent diabetes mellitus; ophthalmologist; outcome assessment; proliferative diabetic retinopathy; prospective study; sensitivity analysis; sensitivity and specificity; slit lamp microscopy; spectral domain optical coherence tomography; ultra wide field fundus image; artificial intelligence; diabetic retinopathy; diagnostic imaging; multimodal imaging; non insulin dependent diabetes mellitus; Adult; Artificial Intelligence; Cross-Sectional Studies; Diabetes Mellitus, Type 2; Diabetic Retinopathy; Humans; Multimodal Imaging; Prospective Studies"
Article,"Jiang Y., Pan J., Yuan M., Shen Y., Zhu J., Wang Y., Li Y., Zhang K., Yu Q., Xie H., Li H., Wang X., Luo Y.",Segmentation of Laser Marks of Diabetic Retinopathy in the Fundus Photographs Using Lightweight U-Net,Journal of Diabetes Research,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85118676119&doi=10.1155%2f2021%2f8766517&partnerID=40&md5=964bf9135199e2a8070e6ebd4fe455f7,"Diabetic retinopathy (DR) is a prevalent vision-threatening disease worldwide. Laser marks are the scars left after panretinal photocoagulation, a treatment to prevent patients with severe DR from losing vision. In this study, we develop a deep learning algorithm based on the lightweight U-Net to segment laser marks from the color fundus photos, which could help indicate a stage or providing valuable auxiliary information for the care of DR patients. We prepared our training and testing data, manually annotated by trained and experienced graders from Image Reading Center, Zhongshan Ophthalmic Center, publicly available to fill the vacancy of public image datasets dedicated to the segmentation of laser marks. The lightweight U-Net, along with two postprocessing procedures, achieved an AUC of 0.9824, an optimal sensitivity of 94.16%, and an optimal specificity of 92.82% on the segmentation of laser marks in fundus photographs. With accurate segmentation and high numeric metrics, the lightweight U-Net method showed its reliable performance in automatically segmenting laser marks in fundus photographs, which could help the AI assist the diagnosis of DR in the severe stage. © 2021 Yukang Jiang et al.","Article; controlled study; cross validation; deep learning; diabetic retinopathy; diagnostic accuracy; diagnostic test accuracy study; eye photography; false negative result; false positive result; human; major clinical study; positivity rate; receiver operating characteristic; segmentation algorithm; sensitivity and specificity; transfer of learning; diabetic retinopathy; eye fundus; image processing; laser coagulation; pathology; photography; scar; severity of illness index; Cicatrix; Deep Learning; Diabetic Retinopathy; Fundus Oculi; Humans; Image Processing, Computer-Assisted; Light Coagulation; Photography; Severity of Illness Index"
Conference Paper,"Zhao Z., Zhang K., Hao X., Tian J., Heng Chua M.C., Chen L., Xu X.",BiRA-Net: Bilinear Attention Net for Diabetic Retinopathy Grading,"Proceedings - International Conference on Image Processing, ICIP",2019,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85076815838&doi=10.1109%2fICIP.2019.8803074&partnerID=40&md5=17f2fdcf216539a027f0adf1fcf5c57a,"Diabetic retinopathy (DR) is a common retinal disease that leads to blindness. For diagnosis purposes, DR image grading aims to provide automatic DR grade classification, which is not addressed in conventional research methods of binary DR image classification. Small objects in the eye images, like lesions and microaneurysms, are essential to DR grading in medical imaging, but they could easily be influenced by other objects. To address these challenges, we propose a new deep learning architecture, called BiRA-Net, which combines the attention model for feature extraction and bilinear model for fine-grained classification. Furthermore, in considering the distance between different grades of different DR categories, we propose a new loss function, called grading loss, which leads to improved training convergence of the proposed approach. Experimental results are provided to demonstrate the superior performance of the proposed approach. © 2019 IEEE.",Not Found
Article,"Vidal-Alaball J., Fibla D.R., Zapata M.A., Marin-Gomez F.X., Fernandez O.S.",Artificial intelligence for the detection of diabetic retinopathy in primary care: Protocol for algorithm development,JMIR Research Protocols,2019,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85066817390&doi=10.2196%2f12539&partnerID=40&md5=7947a8485cf42b922a26470327f2b125,"Background: Diabetic retinopathy (DR) is one of the most important causes of blindness worldwide, especially in developed countries. In diabetic patients, periodic examination of the back of the eye using a nonmydriatic camera has been widely demonstrated to be an effective system to control and prevent the onset of DR. Convolutional neural networks have been used to detect DR, achieving very high sensitivities and specificities. Objective: The objective of this is paper was to develop an artificial intelligence (AI) algorithm for the detection of signs of DR in diabetic patients and to scientifically validate the algorithm to be used as a screening tool in primary care. Methods: Under this project, 2 studies will be conducted in a concomitant way: (1) Development of an algorithm with AI to detect signs of DR in patients with diabetes and (2) A prospective study comparing the diagnostic capacity of the AI algorithm with respect to the actual system of family physicians evaluating the images. The standard reference to compare with will be a blinded double reading conducted by retina specialists. For the development of the AI algorithm, different iterations and workouts will be performed on the same set of data. Before starting each new workout, the strategy of dividing the set date into 2 groups will be used randomly. A group with 80% of the images will be used during the training (training dataset), and the remaining 20% images will be used to validate the results (validation dataset) of each cycle (epoch). During the prospective study, true-positive, true-negative, false-positive, and false-negative values will be calculated again. From here, we will obtain the resulting confusion matrix and other indicators to measure the performance of the algorithm. Results: Cession of the images began at the end of 2018. The development of the AI algorithm is calculated to last about 3 to 4 months. Inclusion of patients in the cohort will start in early 2019 and is expected to last 3 to 4 months. Preliminary results are expected to be published by the end of 2019. Conclusions: The study will allow the development of an algorithm based on AI that can demonstrate an equal or superior performance, and that constitutes a complement or an alternative, to the current screening of DR in diabetic patients. © Josep Vidal-Alaball, Dídac Royo Fibla, Miguel A Zapata, Francesc X Marin-Gomez, Oscar Solans Fernandez.",Artificial intelligence; Computer assisted diagnosis; Diabetes mellitus; Diabetic retinopathy; Fundus oculi; Neural network computer
Article,"Sun Y., Zhang H., Yao X.",Automatic diagnosis of macular diseases from OCT volume based on its two-dimensional feature map and convolutional neural network with attention mechanism,Journal of Biomedical Optics,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85091129320&doi=10.1117%2f1.JBO.25.9.096004&partnerID=40&md5=1ac2cd67c414f26cc225bd54edf56fb1,"Significance: Automatic and accurate classification of three-dimensional (3-D) retinal optical coherence tomography (OCT) images is essential for assisting ophthalmologist in the diagnosis and grading of macular diseases. Therefore, more effective OCT volume classification for automatic recognition of macular diseases is needed. Aim: For OCT volumes in which only OCT volume-level labels are known, OCT volume classifiers based on its global feature and deep learning are designed, validated, and compared with other methods. Approach: We present a general framework to classify OCT volume for automatic recognizing macular diseases. The architecture of the framework consists of three modules: B-scan feature extractor, two-dimensional (2-D) feature map generation, and volume-level classifier. Our architecture could address OCT volume classification using two 2-D image machine learning classification algorithms. Specifically, a convolutional neural network (CNN) model is trained and used as a B-scan feature extractor to construct a 2-D feature map of an OCT volume and volume-level classifiers such as support vector machine and CNN with/without attention mechanism for 2-D feature maps are described. Results: Our proposed methods are validated on the publicly available Duke dataset, which consists of 269 intermediate age-related macular degeneration (AMD) volumes and 115 normal volumes. Fivefold cross-validation was done, and average accuracy, sensitivity, and specificity of 98.17%, 99.26%, and 95.65%, respectively, are achieved. The experiments show that our methods outperform the state-of-the-art methods. Our methods are also validated on our private clinical OCT volume dataset, consisting of 448 AMD volumes and 462 diabetic macular edema volumes. Conclusions: We present a general framework of OCT volume classification based on its 2-D feature map and CNN with attention mechanism and describe its implementation schemes. Our proposed methods could classify OCT volumes automatically and effectively with high accuracy, and they are a potential practical tool for screening of ophthalmic diseases from OCT volume. © The Authors. Published by SPIE under a Creative Commons Attribution 4.0 Unported License. Distribution or reproduction of this work in whole or in part requires full attribution of the original publication, including its DOI.",attention mechanism; convolutional neural network; image classification; optical coherence tomography; transfer learning
Conference Paper,"Siebert M., Rostalski P.",Performance evaluation of lightweight convolutional neural networks on retinal lesion segmentation,Progress in Biomedical Optics and Imaging - Proceedings of SPIE,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85132826714&doi=10.1117%2f12.2611796&partnerID=40&md5=6adbce644d083303511cd745cc3c171c,"In addition to the recent development of deep learning-based, automatic detection systems for diabetic retinopathy (DR), efforts are being made to integrate those systems into mobile detection devices running on the edge requiring lightweight algorithms. Moreover, to enable clinical deployment it is important to enhance the transparency of the deep learning systems usually being black-box models and hence giving no insights into its reasoning. By providing precise segmentation masks for lesions being related to the severity of DR, a good intuition about the decision making of the diagnosing system can be given. Hence, to enable transparent mobile DR detection devices simultaneously segmenting disease-related lesions and running on the edge, lightweight models capable to produce fine-grained segmentation masks are required contradicting the generally high complexity of fully convolutional architectures used for image segmentation. In this paper, we evaluate both the runtime and segmentation performance of several lightweight fully convolutional networks for DR related lesion segmentation and assess its potential to extend mobile DR-grading systems for improved transparency. To this end, the U2-Net is downscaled to reduce the computational load by reducing feature size and applying depthwise separable convolutions and evaluated using deep model ensembling as well as single- and multi-task inference to improve performance and further reduce memory cost. Experimental results using the U2-Net-S† ensemble show good segmentation performance while maintaining a small memory footprint as well as reasonable inference speed and thus indicate a promising first step towards a holistic mobile diagnostic system providing both precise lesion segmentation and DR-grading. © 2022 SPIE.",deep learning; diabetic retinopathy; fundus image; mobile segmentation; multi-lesion segmentation; U-Net
Conference Paper,"Gulati T., Sengupta S., Lakshminarayanan V.",Application of an enhanced deep super-resolution network in retinal image analysis,Progress in Biomedical Optics and Imaging - Proceedings of SPIE,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85094200825&doi=10.1117%2f12.2543791&partnerID=40&md5=c278b0c2024b9982691eab5b9a85acf2,"Fundus imaging is widely used for the diagnosis of retinal diseases. Major ophthalmic diseases like glaucoma, diabetic retinopathy (DR), age-related macular degeneration (AMD) are diagnosed by examining retinal fundus images. Therefore, the efficient and reliable diagnosis largely depends upon the resolution of the images. In different diseased conditions, different pathologies and landmarks (haemorrhages, microaneurysms, exudates, blood vessels, optic disc and optic cup, fovea) of the retina get affected. In clinical situations it is often not possible to obtain good high-resolution images. Here, the techniques of super-resolution can be applied. The objective of super-resolution is to obtain a high-resolution image from a low-resolution input image. In this paper, we present results of the application of enhanced deep residual networks for single image super-resolution (EDSR) on retinal fundus images. This network is based on the SRResNet architecture involving skip connections. Using the public RIGA dataset, which consists of glaucoma and normal fundus images, we have trained the model using 2x, 4x and 8x scaling with three different optimizers each (namely ADAM, Stochastic Gradient Descent and RMSprop) to determine which optimizer is best for the different scales. We have also provided results obtained by varying the residual blocks in the network. © COPYRIGHT SPIE. Downloading of the abstract is permitted for personal use only.",Clinical Ophthamology; Deep Learning; Glaucoma; Image Processing; Retinal Fundus Images; RIGA Dataset; Super resolution
Conference Paper,"Pranava Raman B.M.S., Anusree V., Sreeratcha B., Preeti Krishnaveni R.A., Dunston S.D., Rajam M.A.V.",Analysis of the Effect of Black Box Adversarial Attacks on Medical Image Classification Models,"Proceedings of the 2022 3rd International Conference on Intelligent Computing, Instrumentation and Control Technologies: Computational Intelligence for Smart Systems, ICICICT 2022",2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85141342101&doi=10.1109%2fICICICT54557.2022.9917603&partnerID=40&md5=524b4a64de05e3d8a540855b91f9db16,"In the field of medical science, the reliability of the results produced by deep learning classifiers on disease diagnosis plays a crucial role. The reliability of the classifier substantially reduces by the presence of adversarial examples. The adversarial examples mislead the classifiers to give wrong prediction with equal or more confidence than the actual prediction. The adversarial attacks in the black box type is done by creating a pseudo model that resembles the target model. From the pseudo model, the attack is created and is transferred to the target model. In this work, the Fast Gradient Sign Method and its variants Momentum Iterative Fast Gradient Sign Method, Projected Gradient Descent and Basic Iterative Method are used to create adversarial examples on a target VGG-16 model. The datasets used are Diabetic Retinopathy 2015 Data Colored Resized and SARS-CoV-2 CT Scan Dataset. The experimentation revealed that the transferability of attack is true for the above described attack methods on a VGG-16 model. Also, the Projected Gradient Descent attack provides a higher success in attack in comparison with the other methods experimented in this work. © 2022 IEEE.",adversarial attacks; black box attacks; covid; deep neural networks; diabetic retinopathy
Article,"Ljubic B., Hai A.A., Stanojevic M., Diaz W., Polimac D., Pavlovski M., Obradovic Z.",Predicting complications of diabetes mellitus using advanced machine learning algorithms,Journal of the American Medical Informatics Association,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85091890855&doi=10.1093%2fjamia%2focaa120&partnerID=40&md5=289391e080a1e38bc7b910db461239d9,"Objective: We sought to predict if patients with type 2 diabetes mellitus (DM2) would develop 10 selected complications. Accurate prediction of complications could help with more targeted measures that would prevent or slow down their development. Materials and Methods: Experiments were conducted on the Healthcare Cost and Utilization Project State Inpatient Databases of California for the period of 2003 to 2011. Recurrent neural network (RNN) long short-term memory (LSTM) and RNN gated recurrent unit (GRU) deep learning methods were designed and compared with random forest and multilayer perceptron traditional models. Prediction accuracy of selected complications were compared on 3 settings corresponding to minimum number of hospitalizations between diabetes diagnosis and the diagnosis of complications. Results: The diagnosis domain was used for experiments. The best results were achieved with RNN GRU model, followed by RNN LSTM model. The prediction accuracy achieved with RNN GRU model was between 73% (myocardial infarction) and 83% (chronic ischemic heart disease), while accuracy of traditional models was between 66% – 76%. Discussion: The number of hospitalizations was an important factor for the prediction accuracy. Experiments with 4 hospitalizations achieved significantly better accuracy than with 2 hospitalizations. To achieve improved accuracy deep learning models required training on at least 1000 patients and accuracy significantly dropped if training datasets contained 500 patients. The prediction accuracy of complications decreases over time period. Considering individual complications, the best accuracy was achieved on depressive disorder and chronic ischemic heart disease. Conclusions: The RNN GRU model was the best choice for electronic medical record type of data, based on the achieved results. © The Author(s) 2020.",Deep learning; Diabetes mellitus; Diabetes mellitus complications; Machine learning; RNN models
Article,"Saleh N., Abdel Wahed M., Salaheldin A.M.",Computer-aided diagnosis system for retinal disorder classification using optical coherence tomography images,Biomedizinische Technik,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85130955537&doi=10.1515%2fbmt-2021-0330&partnerID=40&md5=a66f87f838c9e42cdde7d5926a05fdd1,"The incidence of vision impairment is rapidly increasing. Diagnosis and classifying retinal abnormalities in ophthalmological applications is a significant challenge. Using Optical Coherence Tomography (OCT), the study aims to develop a computer aided diagnosis system for detecting and classifying retinal disorders. Choroidal neovascularization, diabetic macular edema, drusen, and normal cases are the investigated groups. Both deep learning and machine learning are combined to build the system. The SqueezeNet neural network was modified to extract features. The Support Vector Machine (SVM), K-Nearest Neighbor (K-NN), Decision Tree (DT), and Ensemble Model (EM) algorithms were used for disorder classification. The Bayesian optimization technique was also used to determine the best hyperparameters for each model. The model' performance was evaluated through nine criteria using 12,000 OCT images. The results have demonstrated accuracies of 97.39, 97.47, 96.98, and 95.25% for the SVM, K-NN, DT, and EM, respectively. When results are compared to relevant studies in terms of accuracy and tested samples, they show superior performance. As a result, a novel computer-aided diagnosis system for detecting and classifying retinal diseases has been developed, reducing human error while also saving time. © 2022 Walter de Gruyter GmbH, Berlin/Boston.",computer-aided diagnosis; optical coherence tomography; retinal disease; SqueezeNet
Conference Paper,"Parthiban K., Kamarasan M.",EfficientNet with Optimal Wavelet Neural Network for DR Detection and Grading,"Proceedings - 4th International Conference on Smart Systems and Inventive Technology, ICSSIT 2022",2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85127352085&doi=10.1109%2fICSSIT53264.2022.9716528&partnerID=40&md5=e6ff463e6318b8f5c3a06488843e7309,"Diabetic retinopathy (DR) is an illness caused by diabetes, affecting irreversible injury to the retina blood vessels. Since the traditional diagnosis process is expensive and time consuming, automated DR detection models are necessary to identify the disease at the early stage. The recently developed deep learning (DL) models make it an effective approach for accomplishing interesting solutions for medical image analysis problems. This study introduces an EfficientNet with Chicken Swarm Optimization based Wavelet Neural Network (EN-CSOWNN) model for DR Detection andGrading. The goal of the EN-CSOWNN technique is to classify the different stages of DR using retinal fundus images. In addition, the EN-CSOWNN technique involves the design of U-Net based segmentation approach to determine the infected regions in the fundus image. Besides, EfficientNet model is used for deriving a set of feature vectors and WNN model is employedto allot distinct class labels. Finally, the CSO algorithm is utilized to properly adjust the initial parameters (connection weights, scaling factor, and translation factor) of the WNN model and thereby improves the classification performance significantly. In order to demonstrate the better performance of the EN-CSOWNN technique, a comprehensive set of simulations take place on benchmark MESSIDOR dataset and the results depict the enhanced classification outcome of the EN-CSOWNN technique with the maximum accuracy of 98.60%. © 2022 IEEE",Deep learning; Diabetic retinopathy; Fundus images; Grading; Parameter optimization; U-Net
Article,"Renith G., Senthilselvi A.",Accuracy improvement in diabetic retinopathy detection using dlia,Journal of Advanced Research in Dynamical and Control Systems,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85085307011&doi=10.5373%2fJARDCS%2fV12I4%2f20201426&partnerID=40&md5=dd4cadc477732e3fab0e72ffc97e9750,"In today’s modern technology, deep learning has become a strong giant technology based on neural network technique which imitates the human brain characteristics. There are many industries using deep learning technology including Health care, Automotive, Retail, Financial, and Oil & Gas and so on. Medical Imaging plays a vital role in Health Care industries. Medical imaging shows the interior structures of human body visually. Using current technology, we could able to diagnose different kind of diseases in the human body. Human Eye is the sensible organ that can receive visual images from outside world. There are many kinds of eye diseases including diabetes, glaucoma, cataract, AMD, hypertension, myopia and other abnormalities. Manual diagnosing process needs the person with good technical knowledge and more time. With deep learning approach, we could able to automatically diagnose the eye diseases with minimal time and effort. We collected some retinal color fundus images of both normal and diabetic images from ODIR 2019 database. Activation function plays a vital role in neural network technique. Activation function decides whether the information learned from the input data is relevant or not. It passes only the correct data information into the series of layers in the network. Hence activation function plays a main role in improving the accuracy in the diagnosis of eye disease. There are many activation functions in neural network including RELU, CELU, ELU, Tanh, SELU, Mish, Swish, Soft sign, Leaky RELU etc and we are going to use some of them. Another important method in improving the accuracy in disease diagnosis is image data augmentation. Augmentation is a technique used to increase the input dataset by modifying or varying little amount of input data from original images. We have increased accuracy by using Deep Learning Network with Image Augmentation (DLIA) technique by 3.3 % by our proposed method. © 2020, Institute of Advanced Scientific Research, Inc.. All rights reserved.",Dense Net; Diabetic Retinopathy; Image Augmentation; Retinal Color Fundus
Article,"Feng R., Xu Z., Zheng X., Hu H., Jin X., Chen D.Z., Yao K., Wu J.",KerNet: A Novel Deep Learning Approach for Keratoconus and Sub-Clinical Keratoconus Detection Based on Raw Data of the Pentacam HR System,IEEE Journal of Biomedical and Health Informatics,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85105858044&doi=10.1109%2fJBHI.2021.3079430&partnerID=40&md5=5e58675f1cbb1ef9e14e6c4b41c75050,"Keratoconus is one of the most severe corneal diseases, which is difficult to detect at the early stage (i.e., sub-clinical keratoconus) and possibly results in vision loss. In this paper, we propose a novel end-to-end deep learning approach, called KerNet, which processes the raw data of the Pentacam HR system (consisting of five numerical matrices) to detect keratoconus and sub-clinical keratoconus. Specifically, we propose a novel convolutional neural network, called KerNet, containing five branches as the backbone with a multi-level fusion architecture. The five branches receive five matrices separately and capture effectively the features of different matrices by several cascaded residual blocks. The multi-level fusion architecture (i.e., low-level fusion and high-level fusion) moderately takes into account the correlation among five slices and fuses the extracted features for better prediction. Experimental results show that: (1) our novel approach outperforms state-of-the-art methods on an in-house dataset, by ~1% for keratoconus detection accuracy and ~4 for sub-clinical keratoconus detection accuracy; (2) the attention maps visualized by Grad-CAM show that our KerNet places more attention on the inferior temporal part for sub-clinical keratoconus, which has been proved as the identifying regions for ophthalmologists to detect sub-clinical keratoconus in previous clinical studies. To our best knowledge, we are the first to propose an end-to-end deep learning approach utilizing raw data obtained by the Pentacam HR system for keratoconus and subclinical keratoconus detection. Further, the prediction performance and the clinical significance of our KerNet are well evaluated and proved by two clinical experts. Our code is available at https://github.com/upzheng/Keratoconus. © 2013 IEEE.",end-to-end deep learning; Keratoconus; Pentacam HR system; raw data; sub-clinical keratoconus
Article,"Kanimozhi N., Singaravel G.",Hybrid artificial fish particle swarm optimizer and kernel extreme learning machine for type-II diabetes predictive model,Medical and Biological Engineering and Computing,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85103000238&doi=10.1007%2fs11517-021-02333-x&partnerID=40&md5=0b5e8c23071371bda61dc9ea75ff9594,"The World Health Organization (WHO) estimated that in 2016, 1.6 million deaths caused were due to diabetes. Precise and on-time diagnosis of type-II diabetes is crucial to reduce the risk of various diseases such as heart disease, stroke, kidney disease, diabetic retinopathy, diabetic neuropathy, and macrovascular problems. The non-invasive methods like machine learning are reliable and efficient in classifying the people subjected to type-II diabetics risk and healthy people into two different categories. This present study aims to develop a stacking-based integrated kernel extreme learning machine (KELM) model for identifying the risk of type-II diabetic patients based on the follow-up time on the diabetes research center dataset. The Pima Indian Diabetic Dataset (PIDD) and a Diabetic Research Center dataset are used in this study. A min-max normalization is used to preprocess the noisy datasets. The Hybrid Particle Swarm Optimization-Artificial Fish Swarm Optimization (HAFPSO) algorithm used satisfies the multi-objective problem by increasing the Classification Accuracy (CA) and decreasing the kernel complexity of the optimal learners (NBC) selected. At last, the model is integrated by utilizing the KELM as a meta-classifier which combines the predictions of the twenty Base Learners as a whole. The proposed classification method helps the clinicians to predict the patients who are at a high risk of type-II diabetes in the future with the highest accuracy of 98.5%. The proposed method is tested with different measures such as accuracy, sensitivity, specificity, Mathews Correlation Coefficient, and Kappa Statistics are calculated. The results obtained show that the KELM-HAFPSO approach is a promising new tool for identifying type-II diabetes. Graphical abstract: [Figure not available: see fulltext.] © 2021, International Federation for Medical and Biological Engineering.",Artificial fish swarm algorithm;; Kernel extreme learning machine;; Meta-classifier;; Particle swarm optimization;; Type-II diabetes classification
Conference Paper,"Liu J., Gibson E., Ramchal S., Shankar V., Piggott K., Sychev Y., Li A.S., Rao P.K., Margolis T.P., Fondahn E., Bhaskaranand M., Solanki K., Rajagopal R.",Diabetic Retinopathy Screening with Automated Retinal Image Analysis in a Primary Care Setting Improves Adherence to Ophthalmic Care,Ophthalmology Retina,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85088789743&doi=10.1016%2fj.oret.2020.06.016&partnerID=40&md5=ddd9a2c2e3995a2c74db0d42b1d47be7,"Purpose: Retinal screening examinations can prevent vision loss resulting from diabetes but are costly and highly underused. We hypothesized that artificial intelligence-assisted nonmydriatic point-of-care screening administered during primary care visits would increase the adherence to recommendations for follow-up eye care in patients with diabetes. Design: Prospective cohort study. Participants: Adults 18 years of age or older with a clinical diagnosis of diabetes being cared for in a metropolitan primary care practice for low-income patients. Methods: All participants underwent nonmydriatic fundus photography followed by automated retinal image analysis with human supervision. Patients with positive or inconclusive screening results were referred for comprehensive ophthalmic evaluation. Adherence to referral recommendations was recorded and compared with the historical adherence rate from the same clinic. Main Outcome Measure: Rate of adherence to eye screening recommendations. Results: By automated screening, 8.3% of the 180 study participants had referable diabetic eye disease, 13.3% had vision-threatening disease, and 29.4% showed inconclusive results. The remaining 48.9% showed negative screening results, confirmed by human overread, and were not referred for follow-up ophthalmic evaluation. Overall, the automated platform showed a sensitivity of 100% (confidence interval, 92.3%–100%) in detecting an abnormal screening results, whereas its specificity was 65.7% (confidence interval, 57.0%–73.7%). Among patients referred for follow-up ophthalmic evaluation, the adherence rate was 55.4% at 1 year compared with the historical adherence rate of 18.7% (P < 0.0001, Fisher exact test). Conclusions: Implementation of an automated diabetic retinopathy screening system in a primary care clinic serving a low-income metropolitan patient population improved adherence to follow-up eye care recommendations while reducing referrals for patients with low-risk features. © 2020 American Academy of Ophthalmology","hemoglobin; adult; clinical assessment; cohort analysis; comparative study; Conference Paper; controlled study; diabetic eye disease; diabetic retinopathy; diagnostic accuracy; diagnostic test accuracy study; disease severity; eye care; eye disease; eye fundus; female; follow up; fundus photography; glaucoma; human; image analysis; lowest income group; machine learning; macular degeneration; major clinical study; male; middle aged; ophthalmic Care; outcome assessment; pars plana vitrectomy; predictive value; prevalence; primary medical care; prospective study; questionnaire; retina detachment; retina image; risk assessment; screening test; sensitivity and specificity; visual acuity; vitrectomy; artificial intelligence; diabetic retinopathy; diagnostic imaging; image processing; mass screening; outpatient department; primary health care; procedures; retina; Ambulatory Care Facilities; Artificial Intelligence; Diabetic Retinopathy; Female; Follow-Up Studies; Humans; Image Processing, Computer-Assisted; Male; Mass Screening; Middle Aged; Primary Health Care; Prospective Studies; Retina"
Article,"Abbas Q., Ibrahim M.E.A., Baig A.R.",Transfer Learning-based Computer-aided Diagnosis System for Predicting Grades of Diabetic Retinopathy,"Computers, Materials and Continua",2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85122743415&doi=10.32604%2fcmc.2022.023670&partnerID=40&md5=c8d0b6a05f496530af99dce385fc38b3,"Diabetic retinopathy (DR) diagnosis through digital fundus images requires clinical experts to recognize the presence and importance of many intricate features. This task is very difficult for ophthalmologists and time-consuming. Therefore, many computer-aided diagnosis (CAD) systems were developed to automate this screening process of DR. In this paper, a CAD-DR system is proposed based on preprocessing and a pre-train transfer learning-based convolutional neural network (PCNN) to recognize the five stages of DR through retinal fundus images. To develop this CAD-DR system, a preprocessing step is performed in a perceptual-oriented color space to enhance the DR-related lesions and then a standard pre-train PCNN model is improved to get high classification results. The architecture of the PCNN model is based on three main phases. Firstly, the training process of the proposed PCNN is accomplished by using the expected gradient length (EGL) to decrease the image labeling efforts during the training of the CNN model. Secondly, the most informative patches and images were automatically selected using a few pieces of training labeled samples. Thirdly, the PCNN method generated useful masks for prognostication and identified regions of interest. Fourthly, the DR-related lesions involved in the classification task such as micro-aneurysms, hemorrhages, and exudates were detected and then used for recognition of DR. The PCNN model is pre-trained using a high-end graphical processor unit (GPU) on the publicly available Kaggle benchmark. The obtained results demonstrate that the CAD-DR system outperforms compared to other state-of-the-art in terms of sensitivity (SE), specificity (SP), and accuracy (ACC). On the test set of 30,000 images, the CAD-DR system achieved an average SE of 93.20%, SP of 96.10%, and ACC of 98%. This result indicates that the proposed CAD-DR system is appropriate for the screening of the severity-level of DR. © 2022 Tech Science Press. All rights reserved.",Computer-aided diagnosis system; Convolutional neural network; Deep learning; Diabetic retinopathy; Retinal fundus images; Transfer learning
Article,"Ho E., Wang E., Youn S., Sivajohan A., Lane K., Chun J., Hutnik C.M.L.",Deep Ensemble Learning for Retinal Image Classification,Translational Vision Science and Technology,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85141003860&doi=10.1167%2ftvst.11.10.39&partnerID=40&md5=b3770b883103d2a97bb93c737c5662a7,"Purpose: Vision impairment affects 2.2 billion people worldwide, half of which is preventable with early detection and treatment. Currently, automatic screening of ocular pathologies using convolutional neural networks (CNNs) on retinal fundus photographs is limited to a few pathologies. Simultaneous detection of multiple ophthalmic pathologies would increase clinical usability and uptake. Methods: Two thousand five hundred sixty images were used from the Retinal Fundus Multi-Disease Image Dataset (RFMiD). Models were trained (n = 1920) and validated (n = 640). Five selected CNN architectures were trained to predict the presence of any pathology and categorize the 28 pathologies. All models were trained to minimize asymmetric loss, a modified form of binary cross-entropy. Individual model predictions were averaged to obtain a final ensembled model and assessed for mean area under the receiver-operator characteristic curve (AUROC) for disease screening (healthy versus pathologic image) and classification (AUROC for each class). Results: The ensemble network achieved a disease screening (healthy versus pathologic) AUROC score of 0.9613. The highest single network score was 0.9586 using the SE-ResNeXt architecture. For individual disease classification, the average AUROC score for each class was 0.9295. Conclusions: Retinal fundus images analyzed by an ensemble of CNNs trained to minimize asymmetric loss were effective in detection and classification of ocular pathologies than individual models. External validation is needed to translate machine learning models to diverse clinical contexts. Translational Relevance: This study demonstrates the potential benefit of ensemblebased deep learning methods on improving automatic screening and diagnosis of multiple ocular pathologies from fundoscopy imaging. © 2022 The Authors.",artificial intelligence (AI); deep learning; disease screening; fundoscopy
Article,"Li Z., Jiang J., Zhou H., Zheng Q., Liu X., Chen K., Weng H., Chen W.",Development of a deep learning-based image eligibility verification system for detecting and filtering out ineligible fundus images: A multicentre study,International Journal of Medical Informatics,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85098560497&doi=10.1016%2fj.ijmedinf.2020.104363&partnerID=40&md5=90db1e9c68fb5b2381b990e32b871526,"Background: Recent advances in artificial intelligence (AI) have shown great promise in detecting some diseases based on medical images. Most studies developed AI diagnostic systems only using eligible images. However, in real-world settings, ineligible images (including poor-quality and poor-location images) that can compromise downstream analysis are inevitable, leading to uncertainty about the performance of these AI systems. This study aims to develop a deep learning-based image eligibility verification system (DLIEVS) for detecting and filtering out ineligible fundus images. Methods: A total of 18,031 fundus images (9,188 subjects) collected from 4 clinical centres were used to develop and evaluate the DLIEVS for detecting eligible, poor-location, and poor-quality fundus images. Four deep learning algorithms (AlexNet, DenseNet121, Inception V3, and ResNet50) were leveraged to train models to obtain the best model for the DLIEVS. The performance of the DLIEVS was evaluated using the area under the receiver operating characteristic curve (AUC), sensitivity, and specificity, as compared with a reference standard determined by retina experts. Results: In the internal test dataset, the best algorithm (DenseNet121) achieved AUCs of 1.000, 0.999, and 1.000 for the classification of eligible, poor-location, and poor-quality images, respectively. In the external test datasets, the AUCs of the best algorithm (DenseNet121) for detecting eligible, poor-location, and poor-quality images were ranged from 0.999–1.000, 0.997–1.000, and 0.997–0.999, respectively. Conclusions: Our DLIEVS can accurately discriminate poor-quality and poor-location images from eligible images. This system has the potential to serve as a pre-screening technique to filter out ineligible images obtained from real-world settings, ensuring only eligible images will be applied in the subsequent image-based AI diagnostic analyses. © 2020 Elsevier B.V.",Artificial intelligence; Deep learning; Eligibility; fundus image
Conference Paper,"Ghosh S.K., Biswas B., Ghosh A.",A Novel Enhancement and Segmentation of Color Retinal Image Based on Fuzzy Measure and Fuzzy Integral,Advances in Intelligent Systems and Computing,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85077121848&doi=10.1007%2f978-981-13-9042-5_2&partnerID=40&md5=a47f5bb49b71714a6e8dfef00fa74654,"Image enhancement and segmentation are predominating methods in image processing and are widely used in ophthalmology for the diagnosis of various eye diseases such as diabetic retinopathy, glaucoma. Especially, retinal image segmentation is vastly required to extract certain features that can facilitate in diagnosis and treatment of eye. Due to the acquisition process, color retinal images can suffer from poor contrast, thus enhancement is essential in ophthalmology. In this work, a novel fuzzy color image enhancement and segmentation technique has been suggested to overcome the problem of low and variation of contrast, and segment in retinal images. This paper provides a special fuzzy computation on retinal image such as fuzzy measure which is used for enhancement and fuzzy integral is applied for segmentation. The proposed algorithm can accomplish excellent contrast and a segment of an image object that endows feasibility in diagnosis from retinal image. © 2020, Springer Nature Singapore Pte Ltd.",Fuzzy integral; Fuzzy measure; Fuzzy partition; Image enhancement; Image segmentation
Conference Paper,Tavakoli M.,Automated Optic Disk Detection in Fundus Images using a Combination of Deep Learning and Local Histogram Matching,Progress in Biomedical Optics and Imaging - Proceedings of SPIE,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85132040826&doi=10.1117%2f12.2611561&partnerID=40&md5=ddb674fd978cd5ea5f7221352713ef79,"Retinal images have been used in the diagnosis of many ocular diseases such as glaucoma and diabetic retinopathy. Here, automatic detection of optic disk (OD) is essential in deriving clinical parameters to assist clinical diagnosis. In fact, detecting OD center and its boundary is the essential step of most vessel segmentation, disease diagnostic, and retinal recognition algorithms. In this study, we proposed a new approach for localizing OD by combining local histogram matching and the concept of deep learning. The algorithm is composed of 4 steps, Image partitioning, Local histogram matching and validation, Convolutional Neural Network (CNN) classification, and OD detection. Here, we used OD of the five reference retinal images in each dataset to extract the histograms of each color channel. Then, we calculated the mean of histograms for each channel as template for creating some OD candidates. An AlexNet-like CNN was applied to classify candidates as ODs or nonODs. The candidates used as an input to feed the CNN for final classification. In this study, we worked on three databases (one rural, MUMS-DB, and two publicly available databases, DRIVE, STARE) including 520 retinal images to evaluate the proposed method. The accuracy of our algorithm was 100%, 90%, and 95% for the DRIVE, STARE, and MUMS-DB respectively. It is shown that this method provides higher detection rates than the existing methods that have reported. © 2022 SPIE",Computer aided diagnosis; Convolutional neural networks; Deep learning; Eye protection; Graphic methods; Medical imaging; Automatic Detection; Convolutional neural network; Diabetic retinopathy; Fundus image; Histogram matching; Local histogram; Ocular disease; Optic disk detections; Optic disks; Retinal image; Ophthalmology
Article,"Pan X., Jin K., Cao J., Liu Z., Wu J., You K., Lu Y., Xu Y., Su Z., Jiang J., Yao K., Ye J.",Multi-label classification of retinal lesions in diabetic retinopathy for automatic analysis of fundus fluorescein angiography based on deep learning,Graefe's Archive for Clinical and Experimental Ophthalmology,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85078049283&doi=10.1007%2fs00417-019-04575-w&partnerID=40&md5=d5f9aad25fd03438e656731e3f9f60b1,"Purpose: To automatically detect and classify the lesions of diabetic retinopathy (DR) in fundus fluorescein angiography (FFA) images using deep learning algorithm through comparing 3 convolutional neural networks (CNNs). Methods: A total of 4067 FFA images from Eye Center at the Second Affiliated Hospital of Zhejiang University School of Medicine were annotated with 4 kinds of lesions of DR, including non-perfusion regions (NP), microaneurysms, leakages, and laser scars. Three CNNs including DenseNet, ResNet50, and VGG16 were trained to achieve multi-label classification, which means the algorithms could identify 4 retinal lesions above at the same time. Results: The area under the curve (AUC) of DenseNet reached 0.8703, 0.9435, 0.9647, and 0.9653 for detecting NP, microaneurysms, leakages, and laser scars, respectively. For ResNet50, AUC was 0.8140 for NP, 0.9097 for microaneurysms, 0.9585 for leakages, and 0.9115 for laser scars. And for VGG16, AUC was 0.7125 for NP, 0.5569 for microaneurysms, 0.9177 for leakages, and 0.8537 for laser scars. Conclusions: Experimental results demonstrate that DenseNet is a suitable model to automatically detect and distinguish retinal lesions in the FFA images with multi-label classification, which lies the foundation of automatic analysis for FFA images and comprehensive diagnosis and treatment decision-making for DR. © 2020, Springer-Verlag GmbH Germany, part of Springer Nature.",Deep learning; Diabetic retinopathy; Fundus fluorescein angiography; Multi-label classification
Conference Paper,"Sheikh S., Qidwai U.",Smartphone-based diabetic retinopathy severity classification using convolution neural networks,Advances in Intelligent Systems and Computing,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090098659&doi=10.1007%2f978-3-030-55190-2_35&partnerID=40&md5=f5ca5676a38ca77e533d013617472f65,"With diabetes growing at an alarming rate, changes in the retina causes a condition called diabetic retinopathy which eventually leads to blindness. Early detection of diabetic retinopathy is the best way to provide good timely treatment and thus prevent blindness. Many developed countries have put forward well-structured screening programs which screens every person diagnosed with diabetes at regular intervals. However, the cost of running these programs is increasing with ever increasing disease burden. These screening programs require well trained opticians or ophthalmologist and the global shortage of health care professionals is putting a pressing need to develop screening tools with POCT (Point-Of-Care-Technology). Using smartphone-based screening tools will help process and generate a plan for the patients thus skipping the health care provider needed to just classify the disease. In this paper, we trained and validated 4 different classifiers using VGG16, Resnet50, InceptionV3 and DenseNet121 algorithms on the Retinal fundus Kaggle dataset to segment the parts of the retina. We experimented with different image preprocessing techniques and employed various hyperparameter tuning to build a good model. We achieved the best model with DenseNet161 with a kappa score of 0.9025, sensitivity 90% and specificity 87% validated on the same dataset and compared the results. We used this model in an android application to predict the severity of retinal fundus images which can later be tested in clinical environments. © Springer Nature Switzerland AG 2021.",Android application; Convolutional neural networks; Deep learning; Diabetic retinopathy
Conference Paper,"Lei G., Xia Y., Zhang W., Chen D., Wang D.",Comparative Analysis of Pre-process Pipelines for Automatic Retinal Vessel Segmentation,"Chinese Control Conference, CCC",2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85091398974&doi=10.23919%2fCCC50068.2020.9189391&partnerID=40&md5=4b58f8506102826c56d4fa7a953fe413,"Retinal vessel structure is an unique individual characteristic and important biology marker of many diseases, like Diabetic Retinopathy (DR), cardiovascular ailment, and so on. Automatic retinal vessel segmentation can be used to assist the early diagnosis of above diseases, but suffers from the poor quality and low contrast of fundus images. To eliminate the noise in the fundus images, many pre-process pipelines are designed to normalize and enhance the fundus images. However, the specific operations in pre-process pipelines of the fundus images haven't been distinguished from operations in normalization of natural images. This paper collects a dozen of pre-process pipelines from published retinal vessel segmentation researches, and proposes five general patterns of these pre-process pipelines. Furthermore, we test the flexibility of five classical pre-process pipelines on public retinal vessel datasets with a Dense-UNet model. Experiments demonstrate that the ""Hiera"" pre-process pipeline and the ""DUNet"" pre-process pipeline outperform the rest pipelines in assisting the Dense-UNet to segment the retinal vessels. © 2020.",deep learning; pre-process pipeline; Retinal vessel segmentation
Article,"Dagliati A., Marini S., Sacchi L., Cogni G., Teliti M., Tibollo V., De Cata P., Chiovato L., Bellazzi R.",Machine Learning Methods to Predict Diabetes Complications,Journal of Diabetes Science and Technology,2018,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85042196404&doi=10.1177%2f1932296817706375&partnerID=40&md5=1bce5db4614d6e725285f2acf22a3f03,"One of the areas where Artificial Intelligence is having more impact is machine learning, which develops algorithms able to learn patterns and decision rules from data. Machine learning algorithms have been embedded into data mining pipelines, which can combine them with classical statistical strategies, to extract knowledge from data. Within the EU-funded MOSAIC project, a data mining pipeline has been used to derive a set of predictive models of type 2 diabetes mellitus (T2DM) complications based on electronic health record data of nearly one thousand patients. Such pipeline comprises clinical center profiling, predictive model targeting, predictive model construction and model validation. After having dealt with missing data by means of random forest (RF) and having applied suitable strategies to handle class imbalance, we have used Logistic Regression with stepwise feature selection to predict the onset of retinopathy, neuropathy, or nephropathy, at different time scenarios, at 3, 5, and 7 years from the first visit at the Hospital Center for Diabetes (not from the diagnosis). Considered variables are gender, age, time from diagnosis, body mass index (BMI), glycated hemoglobin (HbA1c), hypertension, and smoking habit. Final models, tailored in accordance with the complications, provided an accuracy up to 0.838. Different variables were selected for each complication and time scenario, leading to specialized models easy to translate to the clinical practice. © 2017, © 2017 Diabetes Technology Society.",Data Mining; Machine Learning; Microvascular Complications; Risk Predictions; Type 2 Diabetes
Conference Paper,"Smaida M., Yaroshchak S.",Bagging of convolutional neural networks for diagnostic of eye diseases,CEUR Workshop Proceedings,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85085216476&partnerID=40&md5=760bbff549e4fdeae1e98d7396070ba0,"Deep learning is a subset of machine learning where artificial neural networks, algorithms inspired by the structure of the human brain itself, learn from large amounts of data. In this paper, we will introduce the part of the techniques of deep learning to perform multi-class classification, in order to classify eye diseases. One of the biggest issues in image recognition is the classification of medical images, and it aims to classify medical images into different categories to help doctors diagnose the disease. But the most important idea will be addressed in our paper is the evaluation performance model using a bagging ensemble. In this study, we will compare three models of the convolutional neural network, CNN, Vgg16 and InceptionV3 in order to evaluate the performance of the models using bagging ensemble. In our work, a deep learning convolutional network based on Keras and Tensor Flow is deployed using python for image classification. A number of different medical images have been used as a data set to diagnose eye diseases, which contain four types of diseases such as, Diabetic retinopathy, Glaucoma, Myopia and Normal. CNN, VGG16 and InceptionV3 neural network structures are compared singly and together using bagging ensemble, in order to diagnose eye diseases. All experiments were applied and the result was obtained. It has been shown that using a bagging ensemble yields better predictive efficiency than can be obtained using learning algorithms alone. Moreover, the use of the confusion matrix in our experiments shows us where our classifiers are confused when it makes predictions. © 2020 for this paper by its authors.",Bagging; Deep Learning; Diabetic retinopathy; Ensemble learning; Eye diseases; Glaucoma; InceptionV3; Myopia; Vgg16
Article,"Mitra A., Banerjee P.S., Roy S., Roy S., Setua S.K.",The region of interest localization for glaucoma analysis from retinal fundus image using deep learning,Computer Methods and Programs in Biomedicine,2018,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85051471876&doi=10.1016%2fj.cmpb.2018.08.003&partnerID=40&md5=f338f3cfa038e47a88087ed08f6ad455,"Background and objectives: Retinal fundus image analysis without manual intervention has been rising as an imperative analytical approach for early detection of eye-related diseases such as glaucoma and diabetic retinopathy. For analysis and detection of Glaucoma and some other disease from retinal image, there is a significant role of predicting the bounding box coordinates of Optic Disc (OD) that acts as a Region of Interest (ROI). Methods: We reframe ROI detection as a solitary regression predicament, from image pixel values to ROI coordinates including class probabilities. A Convolution Neural Network (CNN) has trained on full images to predict bounding boxes along with their analogous probabilities and confidence scores. The publically available MESSIDOR and Kaggle datasets have been used to train the network. We adopted various data augmentation techniques to amplify our dataset so that our network becomes less sensitive to noise. From a very high-level perspective, every image is divided into a 13 × 13 grid. Every grid cell envisages 5 bounding boxes along with the corresponding class probability and a confidence score. Before training, the network and the bounding box priors or anchors are initialized using k-means clustering on the original dataset using a distance metric based on Intersection of the Union (IOU) over ground-truth bounding boxes. During training in fact, a sum-squared loss function is used as the prediction's error function. Finally, Non-maximum suppression is applied by the proposed methodology to reach the concluding prediction. Results: The following projected method accomplish an accuracy of 99.05% and 98.78% on the Kaggle and MESSIDOR test sets for ROI detection. Results of proposed methodology indicates that proposed network is able to perceive ROI in fundus images in 0.0045 s at 25 ms of latency, which is far better than the recent-time and using no handcrafted features. Conclusions: The network predicts accurate results even on low-quality images without being biased towards any particular type of image. The network prepared to see more summed up depiction rather than past works in the field. Going by the results, our novel method has better diagnosis of eye diseases in the future in a faster and reliable way. © 2018 Elsevier B.V.","Anchor Boxes; Batch Normalization; Convolution Neural Networks; Intersection over Union; K-means clustering; Leaky ReLU, Max Pooling; Non-maximum suppression; Optic Disc Localization"
Conference Paper,"Rebinth A., Mohan Kumar S.",A Deep Learning Approach To Computer Aided Glaucoma Diagnosis,"2019 International Conference on Recent Advances in Energy-Efficient Computing and Communication, ICRAECC 2019",2019,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85080960861&doi=10.1109%2fICRAECC43874.2019.8994988&partnerID=40&md5=76fe07340b6760098881c4dc9b85ad27,"Glaucoma has been listed as a major health deterrent and is one of the top three causes of vision loss which may lead to permanent blindness. Recent global health evaluation on primary health challenges conducted by World Health Organization (WHO) has identified eye related defects as one of the critical few. Survey reports highlight that if not treated, this can become a primary concern by 2020 leading to around 80 million people affected due to eye related defects. Irrespective of geologically being developed or developing country, retinal eye defects have progressing significantly over the earlier part of this century. Progression of eye defects can be reduced by the timely diagnosis of eye defects. Image processing in the recent years has gained traction and growth multiple avenues from facial recognition to computer aided diagnosis of diseases. Cost effective and efficient computer aided diagnosis of fundal abnormalities have been enabled using image processing. This paper discusses the different methodologies adopted for automatic detection and gives insight into the progression of image mining techniques. © 2019 IEEE.",Diabetic retinopathy; Feature detection; Fundus images; Glaucoma; KNN; Naïve-bayes; Optic cup; Optic disc; Retinal abnormalities; Segmentation; SVM
Article,Guo S.,Fundus image segmentation via hierarchical feature learning,Computers in Biology and Medicine,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85117083644&doi=10.1016%2fj.compbiomed.2021.104928&partnerID=40&md5=5648f3e654ea048d87af5ec6d4583380,"Fundus Image Segmentation (FIS) is an essential procedure for the automated diagnosis of ophthalmic diseases. Recently, deep fully convolutional networks have been widely used for FIS with state-of-the-art performance. The representative deep model is the U-Net, which follows an encoder-decoder architecture. I believe it is suboptimal for FIS because consecutive pooling operations in the encoder lead to low-resolution representation and loss of detailed spatial information, which is particularly important for the segmentation of tiny vessels and lesions. Motivated by this, a high-resolution hierarchical network (HHNet) is proposed to learn semantic-rich high-resolution representations and preserve spatial details simultaneously. Specifically, a High-resolution Feature Learning (HFL) module with increasing dilation rates was first designed to learn the high-level high-resolution representations. Then, the HHNet was constructed by incorporating three HFL modules and two feature aggregation modules. The HHNet runs in a coarse-to-fine manner, and fine segmentation maps are output at the last level. Extensive experiments were conducted on fundus lesion segmentation, vessel segmentation, and optic cup segmentation. The experimental results reveal that the proposed method shows highly competitive or even superior performance in terms of segmentation performance and computation cost, indicating its potential advantages in clinical application. © 2021 Elsevier Ltd",Hierarchical network; High-resolution feature; Lesion segmentation; Vessel segmentation
Conference Paper,"Raut R., Sapate V., Rokde A., Pachade S., Porwal P., Kokare M.",Laser Scar Classification in Retinal Fundus Images Using Wavelet Transform and Local Variance,Advances in Intelligent Systems and Computing,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85072826860&doi=10.1007%2f978-981-13-8798-2_9&partnerID=40&md5=b61c13a8ca5c5214ac1a7ee5dff5353d,"Diabetic retinopathy (DR) affects the vision of the person and may eventually lead to blindness. In the initial stage of the disease, patients are treated with a laser to restrict its progression. Such laser treatment leaves behind scars on the retina and patients are advised to undergo screening regularly to track further complications. This paper presents a novel retinal background characterization approach that explores the potential of discrete wavelet transform and rotational-invariant variance features for texture classification of retinal images with and without laser marks. For this experiment, different classifiers, namely, support vector machine, naive Bayes, neural network, and random forest classifiers are tested. We used two publicly available datasets, namely, LMD-DRS and LMD-BAPT. In all cases, the proposed approach obtained the sensitivity, specificity, and accuracy values higher than 68.9%, 70.2%, and 69.4%, respectively. It was found that all performance measures achieve over 87.5, 89.4, and 86.7% for the classification task using random forest classifier. These promising results suggest that the proposed technique can discriminate retinal images having laser marks and without laser marks, and has the potential to be an important constituent in computerized screening solution for retinal images. © Springer Nature Singapore Pte Ltd. 2020",Computer-aided diagnosis; Diabetic retinopathy; Discrete wavelet transform; Feature extraction; Laser scar detection; Retinal image analysis
Article,"Tseng V.S., Chen C.-L., Liang C.-M., Tai M.-C., Liu J.-T., Wu P.-Y., Deng M.-S., Lee Y.-W., Huang T.-Y., Chen Y.-H.",Leveraging multimodal deep learning architecture with retina lesion information to detect diabetic retinopathy,Translational Vision Science and Technology,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85088707280&doi=10.1167%2ftvst.9.2.41&partnerID=40&md5=13bf4f1f9933b266656a642a09efd33d,"Purpose: To improve disease severity classification from fundus images using a hybrid architecture with symptom awareness for diabetic retinopathy (DR). Methods: We used 26,699 fundus images of 17,834 diabetic patients from three Taiwanese hospitals collected in 2007 to 2018 for DR severity classification. Thirty-seven ophthalmologists verified the images using lesion annotation and severity classification as the ground truth. Two deep learning fusion architectures were proposed: late fusion, which combines lesion and severity classification models in parallel using a postprocess-ing procedure, and two-stage early fusion, which combines lesion detection and classification models sequentially and mimics the decision-making process of ophthalmol-ogists. Messidor-2 was used with 1748 images to evaluate and benchmark the performance of the architecture. The primary evaluation metrics were classification accuracy, weighted κ statistic, and area under the receiver operating characteristic curve (AUC). Results: For hospital data, a hybrid architecture achieved a good detection rate, with accuracy and weighted κ of 84.29% and 84.01%, respectively, for five-class DR grading. It also classified the images of early stage DR more accurately than conventional algorithms. The Messidor-2 model achieved an AUC of 97.09% in referral DR detection compared to AUC of 85% to 99% for state-of-the-art algorithms that learned from a larger database. Conclusions: Our hybrid architectures strengthened and extracted characteristics from DR images, while improving the performance of DR grading, thereby increasing the robustness and confidence of the architectures for general use. Translational Relevance: The proposed fusion architectures can enable faster and more accurate diagnosis of various DR pathologies than that obtained in current manual clinical practice. © 2020 The Authors.",Convolutional neural network; Diabetic retinopathy; Fundus image; Fusion architecture; Object detection
Conference Paper,"Liu T., Wu J., Zhang X., Peng Z., Li J.",Blockchain-based access control schemes for medical image analysis system,Communications in Computer and Information Science,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85106227629&doi=10.1007%2f978-981-15-2767-8_32&partnerID=40&md5=19dbf8834d16a1ce74d1ace4f72eebd5,"Medical image analysis systems with machine learning have played an important role in the computer-aided diagnosis and treatment for diseases. However, individual privacy of user data is vulnerable since the training data is exposed to unauthorized user. Therefore, this paper designs an access control scheme to prevent illegal users from accessing medical data while achieving high accuracy of lesion classification. Specifically, in the novel lightweight consortium blockchain-based access control scheme, a chosen consortium node is utilized as key generation center instead of a trusted third party in conventional schemes. Two public retinal datasets are utilized for the classification of diabetic retinopathy (DR). Security analysis shows that the proposed scheme can prevent the user data from leakage and malicious tampering. Experimental results demonstrate that the processing of data cleaning is efficient to increase the accuracy of the classification for early lesions of DR by removing low quality images, and the accuracy is up to 90.2%. © Springer Nature Singapore Pte Ltd. 2020.",Access control; Consortium blockchain; Deep learning; Medical image
Conference Paper,Murugan R.,The Retinal Blood Vessel Segmentation Using Expected Maximization Algorithm,Advances in Intelligent Systems and Computing,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85072833721&doi=10.1007%2f978-981-13-8798-2_6&partnerID=40&md5=4b2c05012766f027234fa5ffacc98e75,"The Retinal Blood Vessel segmentation plays a vital role in automatic retinal disease screening systems. It helps in the screen process of glaucoma, diabetic retinopathy, and other eye- related diseases. The primary objective of this paper is to consequently segment the vessels in fundus retinal pictures, which encourages us in diabetic retinopathy screening. The initial enhancement of image is carried out using Histogram Equalization. After which, the green channel of the image is applied with morphological image processing to remove the optic disc. The image segmentation is then performed to modify the intensity of contrast and little pixels viewed as noise are evacuated. The obtained image would represent the blood vessels of the original image. This paper proposes an expected maximization algorithm to segment the blood vessels in the human retina. The novelty of these method is to perform uniform intensity distribution in retinal images. The proposed method was tested by publicly available datasets such as DRIVE, STARE, MESSIDOR, DIARETDB0, and University of Lincoln. The proposed method has obtained an average area under receiver operating characteristics of 0.9203. Moreover, this shows a better performance than other state-of-the-art methods. © Springer Nature Singapore Pte Ltd. 2020",Blood vessels; Diabetic retinopathy; Histogram equalization; Morphological processing; Optic disc; Retina
Conference Paper,"Ghosh S.K., Biswas B., Ghosh A.",A novel Approach of Retinal Image Enhancement using PSO System and Measure of Fuzziness,Procedia Computer Science,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85084498893&doi=10.1016%2fj.procs.2020.03.446&partnerID=40&md5=ff7d656647d2c10de6c779a9b55897d9,"Retinal image analysis has become a promising research field in the diagnosis of ophthalmological diseases since optic disc, fovea, and blood vessels are essential features based on which the analysis is performed. This paper introduces a novel retinal image enhancement scheme based on particle swarm optimization (PSO) under fuzzy framework as it overcomes the problem of upgrading the imprecise nature of retinal image in traditional PSO system in the field of image enhancement. Firstly, two sub-images such as lower and upper in fuzzy regions of the image are determined by type-2 fuzzy system. Then,an S-shape membership function is utilized on lower and upper sub-images. An objective function such as index of fuzziness is optimized in terms of particle swarm optimization (PSO) system and it also defines the adaptive parameters which are incorporated with the proposed enhancement technique. The suggested model applies low contrast color retinal images to treat different diseases of eye such as diabetic retinopathy, glaucoma, optic disc etc. The proposed algorithm demonstrates excellent result in terms of both subjective and objective evaluation than traditional PSO systems and other baseline methods. © 2020 The Authors. Published by Elsevier B.V.",fuzzy index; Image enhancement; particle swarm optimization; Retinal image; type-2 fuzzy system
Article,"Yasser I., Khalifa F., Abdeltawab H., Ghazal M., Sandhu H.S., El-Baz A.",Automated Diagnosis of Optical Coherence Tomography Angiography (OCTA) Based on Machine Learning Techniques,Sensors,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85126867009&doi=10.3390%2fs22062342&partnerID=40&md5=cad45f142bce1649c898a18ea220f069,"Diabetic retinopathy (DR) refers to the ophthalmological complications of diabetes mellitus. It is primarily a disease of the retinal vasculature that can lead to vision loss. Optical coherence tomography angiography (OCTA) demonstrates the ability to detect the changes in the retinal vascular system, which can help in the early detection of DR. In this paper, we describe a novel framework that can detect DR from OCTA based on capturing the appearance and morphological markers of the retinal vascular system. This new framework consists of the following main steps: (1) extracting retinal vascular system from OCTA images based on using joint Markov-Gibbs Random Field (MGRF) model to model the appearance of OCTA images and (2) estimating the distance map inside the extracted vascular system to be used as imaging markers that describe the morphology of the retinal vascular (RV) system. The OCTA images, extracted vascular system, and the RV-estimated distance map is then composed into a three-dimensional matrix to be used as an input to a convolutional neural network (CNN). The main motivation for using this data representation is that it combines the low-level data as well as high-level processed data to allow the CNN to capture significant features to increase its ability to distinguish DR from the normal retina. This has been applied on multi-scale levels to include the original full dimension images as well as sub-images extracted from the original OCTA images. The proposed approach was tested on in-vivo data using about 91 patients, which were qualitatively graded by retinal experts. In addition, it was quantitatively validated using datasets based on three metrics: sensitivity, specificity, and overall accuracy. Results showed the capability of the proposed approach, outperforming the current deep learning as well as features-based detecting DR approaches. © 2022 by the authors. Licensee MDPI, Basel, Switzerland.",Convolutional neural networks (CNN); Diabetic retinopathy (DR); Image encryption; Optical coherence tomography angiography (OCTA); Security analysis
Article,"Ju L., Wang X., Zhao X., Lu H., Mahapatra D., Bonnington P., Ge Z.",Synergic Adversarial Label Learning for Grading Retinal Diseases via Knowledge Distillation and Multi-Task Learning,IEEE Journal of Biomedical and Health Informatics,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099732775&doi=10.1109%2fJBHI.2021.3052916&partnerID=40&md5=2e8540763794d41b6d0e027afca15d43,"The need for comprehensive and automated screening methods for retinal image classification has long been recognized. Well-qualified doctors annotated images are very expensive and only a limited amount of data is available for various retinal diseases such as diabetic retinopathy (DR) and age-related macular degeneration (AMD). Some studies show that some retinal diseases such as DR and AMD share some common features like haemorrhages and exudation but most classification algorithms only train those disease models independently when the only single label for one image is available. Inspired by multi-task learning where additional monitoring signals from various sources is beneficial to train a robust model. We propose a method called synergic adversarial label learning (SALL) which leverages relevant retinal disease labels in both semantic and feature space as additional signals and train the model in a collaborative manner using knowledge distillation. Our experiments on DR and AMD fundus image classification task demonstrate that the proposed method can significantly improve the accuracy of the model for grading diseases by 5.91% and 3.69% respectively. In addition, we conduct additional experiments to show the effectiveness of SALL from the aspects of reliability and interpretability in the context of medical imaging application. © 2013 IEEE.",Deep convolutional neural networks; knowledge distillation; medical imaging classification; multi-task learning
Article,"Costa P., Smailagic A., Cardoso J.S., Campilho A.",Epistemic and heteroscedastic uncertainty estimation in retinal blood vessel segmentation,U.Porto Journal of Engineering,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85105657708&doi=10.24840%2f2183-6493_007.003_0008&partnerID=40&md5=95d4fdde754bdb9068aadea5c8e5cd52,"Current state-of-the-art medical image segmentation methods require high quality datasets to obtain good performance. However, medical specialists often disagree on diagnosis, hence, datasets contain contradictory annotations. This, in turn, leads to difficulties in the optimization process of Deep Learning models and hinder performance. We propose a method to estimate uncertainty in Convolutional Neural Network (CNN) segmentation models, that makes the training of CNNs more robust to contradictory annotations. In this work, we model two types of uncertainty, heteroscedastic and epistemic, without adding any additional supervisory signal other than the ground-truth segmentation mask. As expected, the uncertainty is higher closer to vessel boundaries, and on top of thinner and less visible vessels where it is more likely for medical specialists to disagree. Therefore, our method is more suitable to learn from datasets created with heterogeneous annotators. We show that there is a correlation between the uncertainty estimated by our method and the disagreement in the segmentation provided by two different medical specialists. Furthermore, by explicitly modeling the uncertainty, the Intersection over Union of the segmentation network improves 5.7 percentage points. © 2021, Universidade do Porto - Faculdade de Engenharia. All rights reserved.",Blood Vessel Segmentation; Convolutional Neural Networks; Deep Learning; Diabetic Retinopathy; Uncertainty Estimation
Article,"Li Q., Fan S., Chen C.",An Intelligent Segmentation and Diagnosis Method for Diabetic Retinopathy Based on Improved U-NET Network,Journal of Medical Systems,2019,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85070676226&doi=10.1007%2fs10916-019-1432-0&partnerID=40&md5=e79f012eb58e53021caa04810d55b799,"Due to insufficient samples, the generalization performance of deep network is insufficient. In order to solve this problem, an improved U-net based image automatic segmentation and diagnosis algorithm was proposed, in which the max-pooling operation in original U-net model was replaced by the convolution operation to keep more feature information. Firstly, the regions of 128×128 were extracted from all slices of the patients as data samples. Secondly, the patient samples were divided into training sample set and testing sample set, and data augmentation was performed on the training samples. Finally, all the training samples were adopted to train the model. Compared with Fully Convolutional Network (FCN) model and max-pooling based U-net model, DSC and CR coefficients of the proposed method achieve the best results, while PM coefficient is 2.55 percentage lower than the maximum value in the two comparison models, and Average Symmetric Surface Distance is slightly higher than the minimum value of the two comparison models by 0.004. The experimental results show that the proposed model can achieve good segmentation and diagnosis results. © 2019, Springer Science+Business Media, LLC, part of Springer Nature.",Deep learning; Diabetic retinopathy; Fully convolutional network; Generalization performance; Intelligent diagnosis; U-net model
Article,"Liu H., Yue K., Cheng S., Pan C., Sun J., Li W.",Hybrid model structure for diabetic retinopathy classification,Journal of Healthcare Engineering,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85094852339&doi=10.1155%2f2020%2f8840174&partnerID=40&md5=f1e75c257afa38efc74db4be6833c07f,"Diabetic retinopathy (DR) is one of the most common complications of diabetes and the main cause of blindness. The progression of the disease can be prevented by early diagnosis of DR. Due to differences in the distribution of medical conditions and low labor efficiency, the best time for diagnosis and treatment was missed, which results in impaired vision. Using neural network models to classify and diagnose DR can improve efficiency and reduce costs. In this work, an improved loss function and three hybrid model structures Hybrid-A, Hybrid-f, and Hybrid-c were proposed to improve the performance of DR classification models. EfficientNetB4, EfficientNetB5, NASNetLarge, Xception, and InceptionResNetV2 CNNs were chosen as the basic models. These basic models were trained using enhance cross-entropy loss and cross-entropy loss, respectively. The output of the basic models was used to train the hybrid model structures. Experiments showed that enhance cross-entropy loss can effectively accelerate the training process of the basic models and improve the performance of the models under various evaluation metrics. The proposed hybrid model structures can also improve DR classification performance. Compared with the best-performing results in the basic models, the accuracy of DR classification was improved from 85.44% to 86.34%, the sensitivity was improved from 98.48% to 98.77%, the specificity was improved from 71.82% to 74.76%, the precision was improved from 90.27% to 91.37%, and the F1 score was improved from 93.62% to 93.9% by using hybrid model structures. © 2020 Hao Liu et al.","Diagnosis; Efficiency; Entropy; Model structures; Classification models; Classification performance; Diabetic retinopathy; Evaluation metrics; Hybrid model structures; Labor efficiency; Medical conditions; Neural network model; Eye protection; Article; classification algorithm; computer assisted diagnosis; controlled study; convolutional neural network; deep learning; diabetic retinopathy; diagnostic accuracy; disease severity; sensitivity and specificity; diabetes mellitus; diabetic retinopathy; human; Diabetes Mellitus; Diabetic Retinopathy; Humans; Neural Networks, Computer"
Conference Paper,"Zahra Belharar F., Zrira N.",DeepRetino: Ophthalmic Disease Classification from Retinal Images using Deep Learning,"2022 IEEE 9th International Conference on Sciences of Electronics, Technologies of Information and Telecommunications, SETIT 2022",2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85138996922&doi=10.1109%2fSETIT54465.2022.9875570&partnerID=40&md5=2f0210f16c5f2adfc36eba6177d3c03a,"Eye diseases are one of the main causes of visual impairment. Their causes are various: they may be related to the aging process or originate from another pathology, such as complications of diabetes. Therefore, early diagnosis is highly recommended to prevent and control eye diseases. Previous approaches focused only on the detection of glaucoma, cataract or diabetic retinopathy. The main purpose of this article is to propose DeepRetino, an automatic multi-classification approach for six eye diseases based on advances in Deep Learning, in particular Convolutional Neural Networks (CNNs). In the preprocessing phase, we first focused on the histogram equalization method called Contrast Limited Adaptive Histogram Equalization (CLAHE) to improve the contrast of the fundus images. On the other hand, in the learning phase, we initialize and update the network weights using Xavier Orthogonal and Adam Optimizer. Finally, we evaluate DeepRetino on the Ocular Disease Intelligent Recognition (ODIR) dataset for deployment. © 2022 IEEE.",Contrast Limited Adaptive Histogram Equalization (CLAHE); Convolution Neural Networks (CNNs); Deep Learning; DeepRetino; Ocular Disease Intelligent Recognition (ODIR); Ophthalmic diseases
Article,"Zhao H., Qiu X., Lu W., Huang H., Jin X.",High-quality retinal vessel segmentation using generative adversarial network with a large receptive field,International Journal of Imaging Systems and Technology,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85083043276&doi=10.1002%2fima.22428&partnerID=40&md5=f02e59878946d32cd15e3dce60b506b7,"Retinal vessel segmentation is of great significance for assisting doctors in diagnosis of ophthalmological diseases such as diabetic retinopathy, macular degeneration and glaucoma. This article proposes a new retinal vessel segmentation algorithm using generative adversarial learning with a large receptive field. A generative network maps an input retinal fundus image to a realistic vessel image while a discriminative network differentiates between images drawn from the database and the generative network. Firstly, the proposed generative network combines shallow features with the upsampled deep features to assemble a more precise vessel image. Secondly, the residual module in the proposed generative and discriminative networks can effectively help deep nets easy to optimize. Moreover, the dilated convolutions in the proposed generative network effectively enlarge the receptive field without increasing the amount of computations. A number of experiments are conducted on two publicly available datasets (DRIVE and STARE) achieving the segmentation accuracy rates of 95.63% and 96.84%, and the average areas under the ROC curve of 98.12% and 98.53%. Performance results show that the proposed automatic retinal vessel segmentation algorithm outperforms state-of-the-art algorithms in many validation metrics. The proposed algorithm can not only detect small tiny blood vessels but also capture large-scale high-level semantic vessel features. © 2020 Wiley Periodicals, Inc.",dilated convolution; generative adversarial network; receptive field; retinal vessel segmentation
Article,"Yang L., Wang H., Zeng Q., Liu Y., Bian G.",A hybrid deep segmentation network for fundus vessels via deep-learning framework,Neurocomputing,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85104361160&doi=10.1016%2fj.neucom.2021.03.085&partnerID=40&md5=a65ad30e03c12f90d710d8a986e84c26,"High-precision segmentation of fundus vessels is a fundamental step in the diagnosis and treatment of fundus diseases, in which both thick and thin vessels are important features for symptom detection. With the rapid development of artificial intelligence, the deep convolutional neural network (DCNN) has been widely applied into image analysis of fundus vessels. Nevertheless, due to the imbalanced ratio between thick and thin vessels, the existing segmentation methods are weak in the task of microvessel extraction from fundus images. To address this problem, this paper proposes a new hybrid deep image segmentation method for fundus vessels that consists of a multitask segmentation network and a fusion network. For the proposed method, a multitask segmentation network is developed to precisely segment both thick vessels and thin vessels from fundus images separately. In addition, an effective loss function is designed to adapt to the two different vessel segmentation tasks and ultimately solve the imbalanced ratio between these two vessels. Furthermore, an improved U-net network model is proposed to serve as the basic segmentation network to ensure the segmentation performance of the multitask segmentation network. Together with these networks, a fusion network is also proposed to fuse these two kinds of blood vessels to obtain the fusion images as the final segmentation results of fundus vessels. The proposed segmentation method is validated on many different public data sets of fundus images, such as DRIVE, STARE and CHASE_DB1. Experimental results show that the proposed method obtains a better segmentation performance on fundus images and acquires a higher recall, F_1 value, and accuracy than other advanced segmentation methods. © 2021 Elsevier B.V.",Fundus vessels; Fusion network; Image segmentation; Multitask segmentation network; U-net network
Conference Paper,"Pampana L.K., Rayudu M.S.",A Review: Prediction of Multiple Adverse Health Conditions from Retinal Images,Proceedings of B-HTC 2020 - 1st IEEE Bangalore Humanitarian Technology Conference,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85101430066&doi=10.1109%2fB-HTC50970.2020.9297936&partnerID=40&md5=103a1caf9e73f7ace5dc8b2b80e523a9,"During the recent years, lifestyle related diseases and disorders such as stress, hypertension and diabetes are increasing at a rapid rate in the middle aged population also These disorders may have greater likelihood of developing multiple adverse health conditions like cardiovascular strokes, cerebrovascular strokes, kidney failures, depression etc. Preventive diagnosis measures are required to diagnose these adverse health hazards in the middle aged group. These days the health care sector is equipped with sophisticated instruments to diagnose the abnormalities in specific organs using different modalities like Computer Tomography(CT), Magnetic Resonance Imaging(MRI), Positron Emission Tomography(PET), Ultrasonography scans, X-Ray, etc. Retinal vascular imaging has its popularity in diagnosing several ocular diseases viz, Diabetic Retinopathy(DR), Age related Macular Degeneration(AMD), Edema, Glaucoma, etc using the latest advancements in Artificial Intelligence with the aid of modalities like Retinal Fundoscopy, Optical Coherence Tomography(OCT), confocal scanning laser ophthalmoscope (cSLO). As per the clinical based studies, the retina shares similar physiological and anatomical features with vital organs hence it is million worthwhile to say that retinal vascular imaging could predict the multiple adverse health conditions like Cardiovascular(CVD), Cerebrovascular(CVS), Chronicle Kidney Diseases(CKD), Breast Cancer and Pulmonary Diseases. The main objective of this review is to study and present the retinal associations related to these life threat adverse diseases., by considering sources from various clinical based studies. The review is concluded by addressing the potential and candidate retinal biomarkers for each of these diseases. © 2020 IEEE.",Biomarkers; Cardiovascular diseases; Cerebrovascular diseases; Health Risk Factors; Retinal Imaging
Conference Paper,"Nugroho H.A., Frannita E.L.",Intelligent Diabetic Retinopathy Detection using Deep Learning,"2021 4th International Seminar on Research of Information Technology and Intelligent Systems, ISRITI 2021",2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85126681427&doi=10.1109%2fISRITI54043.2021.9702859&partnerID=40&md5=57fc44c3d0a2e1027995b90d3eaaeaa5,"Diabetic retinopathy (DR) is the most common illness related to diabetes caused by the increasing of glucose in human blood and has been dramatically increased in the last decade. Practically, DR is examined by conducting manual analysis on retina images resulted from fundus camera modality in which can lead to some problems such as time-consuming, need more thoroughness and properly skill and experience. Due to the insufficient number of ophthalmologists, especially in rural areas, an alternative solution in supporting diagnosis properly is needed. Regarding to those issues, some research communities have proposed intelligent system for detecting DR. Despite some previous intelligent DR detection have been developed, there still remained problem that quality of image was extremely affect the performance. Hence, in this study we proposed an intelligent DR detection completed with image enhancement process for maintaining the model performance. Our proposed solution was performed in 200 retina images consisting of two classes (normal and abnormal or DR). Our proposed solution successfully increased the performance with the highest accuracy, sensitivity, specificity, positive predictive value, and negative predictive value of 0.92, 0.95, 0.81, 0.95, 0.81, respectively. This result has increased by around of 40% in most of evaluation metrics of the model's performance without an image enhancement process. It indicates that conducting image enhancement process before training the model was important to increase the model performance and to prevent the miss-detection. © 2021 IEEE.",deep learning; Diabetes; diabetic retinopathy; image enhancement
Article,"Narhari B.B., Murlidhar B.K., Sayyad A.D., Sable G.S.",Automated diagnosis of diabetic retinopathy enabled by optimized thresholding-based blood vessel segmentation and hybrid classifier,Bio-Algorithms and Med-Systems,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097904060&doi=10.1515%2fbams-2020-0053&partnerID=40&md5=bba4eb5c91be74161fd8f67c0a27eba6,"Objectives: The focus of this paper is to introduce an automated early Diabetic Retinopathy (DR) detection scheme from colour fundus images through enhanced segmentation and classification strategies by analyzing blood vessels. Methods: The occurrence of DR is increasing from the past years, impacting the eyes due to a sudden rise in the glucose level of blood. All over the world, half of the people who are under age 70 are severely suffered from diabetes. The patients who are affected by DR will lose their vision during the absence of early recognition of DR and appropriate treatment. To decrease the growth and occurrence of loss of vision, the early detection and timely treatment of DR are desirable. At present, deep learning models have presented better performance using retinal images for DR detection. In this work, the input retinal fundus images are initially subjected to pre-processing that undergoes contrast enhancement by Contrast Limited Adaptive Histogram Equalization (CLAHE) and average filtering. Further, the optimized binary thresholding-based segmentation is done for blood vessel segmentation. For the segmented image, Tri-level Discrete Level Decomposition (Tri-DWT) is performed to decompose it. In the feature extraction phase, Local Binary Pattern (LBP), and Gray-Level Co-occurrence Matrices (GLCMs) are extracted. Next, the classification of images is done through the combination of two algorithms, one is Neural Network (NN), and the other Convolutional Neural Network (CNN). The extracted features are subjected to NN, and the tri- DWT-based segmented image is subjected to CNN. Both the segmentation and classification phases are enhanced by the improved meta-heuristic algorithm called Fitness Ratebased Crow Search Algorithm (FR-CSA), in which few parameters are optimized for attaining maximum detection accuracy. Results: The proposed DR detection model was implemented in MATLAB 2018a, and the analysis was done using three datasets, HRF, Messidor, and DIARETDB. Conclusions: The developed FR-CSA algorithm has the best detection accuracy in diagnosing DR. © 2021 De Gruyter. All rights reserved.",Average filtering; Contrast limited adaptive histogram equalization; Convolutional neural network; Diabetic retinopathy; Fitness rate-based crow search algorithm; Gray-level co-occurrence matrices; Neural network; Optimized binary thresholding; Tri-level discrete level decomposition
Article,"Maji D., Maiti S., Dhara A.K., Sarkar G.",Automatic grading of retinal blood vessel tortuosity using Modified CNN in deep retinal image diagnosis,Biomedical Signal Processing and Control,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123943280&doi=10.1016%2fj.bspc.2022.103514&partnerID=40&md5=981c1b792cab11d606f7a9c9a30d66a5,"Background: The World Health Organization states that the number of patients suffering from diabetes has shot up by nearly four times from 108 millions in 1980 to 422 millions in 2014. Diabetic Retinopathy (DR) is the long-term effect of diabetes, which if not clinically treated effectively on time might lead to irreversible loss of vision. By examining the retinal fundus images the disease might be diagnosed well by examining the retinal fundus images. However, the fact that these images contain noise and variation due to certain environmental conditions such as light makes it difficult even for experts in the field to access the right grade of the disease. In this paper, we aim to present a robust Convolution Neural Network (CNN) architecture, which can grade the disease irrespective of noise and variation. We have used the publicly available dataset on Kaggle to train our model and we have validated on another publicly available data set, EIARG2. We also provide a comparative study of our model against standard architectures like ResNet50, VGG16 and several others of the domain and thus conclude by virtue of promising results that our architecture is superior for grading diabetic retinopathy than the present-day standard architectures. A CNN network has been proposed which can grade retinal images using the state-of-the-art machine learning algorithms. The method found 0.96 Performance (SCC) accurate for grading the tortuosity-based eye health. © 2022 Elsevier Ltd",Convolutional Neural Network (CNN); Diabetic retinopathy (DR); Fundus image; Retinal Blood Vessel
Article,"A P S., Kar S., S G., Gopi V.P., Palanisamy P.",OctNET: A Lightweight CNN for Retinal Disease Classification from Optical Coherence Tomography Images,Computer Methods and Programs in Biomedicine,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099502979&doi=10.1016%2fj.cmpb.2020.105877&partnerID=40&md5=d981deb2227e71029206ae1cd712124a,"Background and Objective: Retinal diseases are becoming a major health problem in recent years. Their early detection and ensuing treatment are essential to prevent visual damage, as the number of people affected by diabetes is expected to grow exponentially. Retinal diseases progress slowly, without any discernible symptoms. Optical Coherence Tomography (OCT) is a diagnostic tool capable of analyzing and identifying the quantitative discrimination in the disease affected retinal layers with high resolution. This paper proposes a deep neural network-based classifier for the computer-aided classification of Diabetic Macular Edema (DME), drusen, Choroidal NeoVascularization (CNV) from normal OCT images of the retina. Methods: In the proposed method, we demonstrate the feasibility of classifying and detecting severe retinal pathologies from OCT images using a deep convolutional neural network having six convolutional blocks. The classification results are explained using a gradient-based class activation mapping algorithm. Results: Training and validation of the model are performed on a public dataset of 83,484 images with expert-level disease grading of CNV, DME, and drusen, in addition to normal retinal image. We achieved a precision of 99.69%, recall of 99.69%, and accuracy of 99.69% with only three misclassifications out of 968 test cases. Conclusion: In the proposed work, downsampling and weight sharing were introduced to improve the training efficiency and were found to reduce the trainable parameters significantly. The class activation mapping was also performed, and the output image was similar to the retina's actual color OCT images. The proposed network used only 6.9% of learnable parameters compared to the existing ResNet-50 model and yet outperformed it in classification. The proposed work can be potentially employed in real-time applications due to reduced complexity and fewer learnable parameters over other models. © 2020 Elsevier B.V.",Artificial intelligence; Class activation mapping; Computer-aided detection and diagnosis; Eye; Machine learning; Optical coherence tomography
Conference Paper,"Listyalina L., Mustiadi I., Dharmawan D.A.",Joint dice and intersection over union losses for deep optical disc segmentation,IBIOMED 2020 - Proceedings of the 37th International Conference on Biomedical Engineering,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85112654091&doi=10.1109%2fIBIOMED50285.2020.9487620&partnerID=40&md5=ff6f0da3f9fd594a3466f44f58a7183a,"Optic disc segmentation on retinal images is essential for the diagnosis of various eye-related diseases, such as diabetic retinopathy, glaucoma, and macular edema. However, manual segmentation of optic discs from fundus images by ophthalmologists is time-consuming, tedious, and labor-extensive. In the literature, various optic disc segmentation algorithms have been proposed. In general, the existing methods are evaluated in terms of the Dice coefficient and Area of Overlap. These two metrics indicates the capability of the existing methods in preserving the accurate optic disc contour and size. However, most available segmentation methods do not attempt to reduce the two measures directly. In this paper, we present a new deep optical disc framework that can tackle the drawbacks of the methods in the literature. The proposed framework performs segmentation by taking the advantages of the U-shaped convolutional neural network (U-Net); U-Net could be trained using a limited number of data. Unlike most other methods in the literature, we use a joint dice and intersection over union losses for training the deep network. We train and evaluate the proposed framework on retinal images from the DRIVE and DRISHTI-GS datasets. In the experimental parts, the proposed framework is capable of outperforming competing methods in terms of the Dice coefficient and Area of Overlap. Therefore, our framework is suitable for broad applications of automated retinal diseases diagnosis. © 2020 IEEE.",Deep learning; Dice loss; IoU loss; Optical disc; Retinal image; Segmentation
Article,"Jadhav A.S., Patil P.B., Biradar S.",Optimal feature selection-based diabetic retinopathy detection using improved rider optimization algorithm enabled with deep learning,Evolutionary Intelligence,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85083467606&doi=10.1007%2fs12065-020-00400-0&partnerID=40&md5=3940d8b28a17cdf749a248bd55d43465,"This proposal tempts to develop automated DR detection by analyzing the retinal abnormalities like hard exudates, haemorrhages, Microaneurysm, and soft exudates. The main processing phases of the developed DR detection model is Pre-processing, Optic Disk removal, Blood vessel removal, Segmentation of abnormalities, Feature extraction, Optimal feature selection, and Classification. At first, the pre-processing of the input retinal image is done by Contrast Limited Adaptive Histogram Equalization. The next phase performs the optic disc removal, which is carried out by open-close watershed transformation. Further, the Grey Level thresholding is done for segmenting the blood vessels and its removal. Once the optic disk and blood vessels are removed, segmentation of abnormalities is done by Top hat transformation and Gabor filtering. Further, the feature extraction phase is started, which tends to extract four sets of features like Local Binary Pattern, Texture Energy Measurement, Shanon’s and Kapur’s entropy. Since the length of the feature vector seems to be long, the feature selection process is done, which selects the unique features with less correlation. Moreover, the Deep Belief Network (DBN)-based classification algorithm performs the categorization of images into four classes normal, earlier, moderate, or severe stages. The optimal feature selection is done by the improved meta-heuristic algorithm called Modified Gear and Steering-based Rider Optimization Algorithm (MGS-ROA), and the same algorithm updates the weight in DBN. Finally, the effectual performance and comparative analysis prove the stable and reliable performance of the proposed model over existing models. The performance of the proposed model is compared with the existing classifiers, such as, NN, KNN, SVM, DBN and the conventional Heuristic-Based DBNs, such as PSO-DBN, GWO-DBN, WOA-DBN, and ROA-DBN for the evaluation metrics, accuracy, sensitivity, specificity, precision, FPR, FNR, NPV, FDR, F1 score, and MC. From the results, it is exposed that the accuracy of the proposed MGS-ROA-DBN is 30.1% higher than NN, 32.2% higher than KNN, and 17.1% higher than SVM and DBN. Similarly, the accuracy of the developed MGS-ROA-DBN is 13.8% superior to PSO, 5.1% superior to GWO, 10.8% superior to WOA, and 2.5% superior to ROA. © 2020, Springer-Verlag GmbH Germany, part of Springer Nature.",Deep belief network; Diabetic retinopathy diagnosis; Modified gear and steering-based rider optimization algorithm; Optimal feature selection; retinal abnormalities
Article,"Khomri B., Christodoulidis A., Djerou L., Babahenini M.C., Cheriet F.",Particle swarm optimization method for small retinal vessels detection on multiresolution fundus images,Journal of Biomedical Optics,2018,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85047054489&doi=10.1117%2f1.JBO.23.5.056004&partnerID=40&md5=f29c0c7cdf1a165498d022ff945f81f5,"Retinal vessel segmentation plays an important role in the diagnosis of eye diseases and is considered as one of the most challenging tasks in computer-Aided diagnosis (CAD) systems. The main goal of this study was to propose a method for blood-vessel segmentation that could deal with the problem of detecting vessels of varying diameters in high-and low-resolution fundus images. We proposed to use the particle swarm optimization (PSO) algorithm to improve the multiscale line detection (MSLD) method. The PSO algorithm was applied to find the best arrangement of scales in the MSLD method and to handle the problem of multiscale response recombination. The performance of the proposed method was evaluated on two lowresolution (DRIVE and STARE) and one high-resolution fundus (HRF) image datasets. The data include healthy (H) and diabetic retinopathy (DR) cases. The proposed approach improved the sensitivity rate against the MSLD by 4.7% for the DRIVE dataset and by 1.8% for the STARE dataset. For the high-resolution dataset, the proposed approach achieved 87.09% sensitivity rate, whereas the MSLD method achieves 82.58% sensitivity rate at the same specificity level. When only the smallest vessels were considered, the proposed approach improved the sensitivity rate by 11.02% and by 4.42% for the healthy and the diabetic cases, respectively. Integrating the proposed method in a comprehensive CAD system for DR screening would allow the reduction of false positives due to missed small vessels, misclassified as red lesions. © 2018 Society of Photo-Optical Instrumentation Engineers (SPIE).",fundus imaging; image segmentation.; multiobjective optimization; multiscale line detection; particle swarm optimization algorithm; retinal blood vessel segmentation
Conference Paper,"Adeyinka A.A., Adebiyi M.O., Akande N.O., Ogundokun R.O., Kayode A.A., Oladele T.O.",A Deep Convolutional Encoder-Decoder Architecture for Retinal Blood Vessels Segmentation,Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),2019,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85068998039&doi=10.1007%2f978-3-030-24308-1_15&partnerID=40&md5=6a73800decd7e2d34a455f369d87b840,"Over the last decades, various methods have been employed in medical images analysis. Some state-of-the-arts techniques such as deep learning have been recently applied to medical images analysis. This research proposes the application of deep learning technique in performing segmentation of retinal blood vessels. Analyzing and segmentation of retina vessels has assisted in diagnosis and monitoring of some diseases. Diseases such as age-related fovea degeneration, diabetic retinopathy, glaucoma, hypertension, arteriosclerosis and choroidal neovascularization can be effectively managed by the analysis of retinal vessels images. In this work, a Deep Convolutional Encoder-Decoder Architecture for the segmentation of retinal vessels images is proposed. The proposed method is a deep learning system composed of an encoder and decoder mechanism allows a low resolution image set of retinal vessels to be analyzed by set of convolutional layers in the encoder unit before been sent into a decoder unit for final segmented output. The proposed system was evaluated using some evaluation metrics such as dice coefficient, jaccard index and mean of intersection. The review of the existing works was also carried out. It could be shown that the proposed system outperforms many existing methods in the segmentation of retinal vessels images. © 2019, Springer Nature Switzerland AG.",Convolutional layers; Decoder; Deep learning; Encoder; Images; Retinal vessels; Segmentation
Article,"Orlando J.I., Prokofyeva E., del Fresno M., Blaschko M.B.",An ensemble deep learning based approach for red lesion detection in fundus images,Computer Methods and Programs in Biomedicine,2018,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031774716&doi=10.1016%2fj.cmpb.2017.10.017&partnerID=40&md5=e7968151bce8d8d26468e95751395743,"Background and objectives: Diabetic retinopathy (DR) is one of the leading causes of preventable blindness in the world. Its earliest sign are red lesions, a general term that groups both microaneurysms (MAs) and hemorrhages (HEs). In daily clinical practice, these lesions are manually detected by physicians using fundus photographs. However, this task is tedious and time consuming, and requires an intensive effort due to the small size of the lesions and their lack of contrast. Computer-assisted diagnosis of DR based on red lesion detection is being actively explored due to its improvement effects both in clinicians consistency and accuracy. Moreover, it provides comprehensive feedback that is easy to assess by the physicians. Several methods for detecting red lesions have been proposed in the literature, most of them based on characterizing lesion candidates using hand crafted features, and classifying them into true or false positive detections. Deep learning based approaches, by contrast, are scarce in this domain due to the high expense of annotating the lesions manually. Methods: In this paper we propose a novel method for red lesion detection based on combining both deep learned and domain knowledge. Features learned by a convolutional neural network (CNN) are augmented by incorporating hand crafted features. Such ensemble vector of descriptors is used afterwards to identify true lesion candidates using a Random Forest classifier. Results: We empirically observed that combining both sources of information significantly improve results with respect to using each approach separately. Furthermore, our method reported the highest performance on a per-lesion basis on DIARETDB1 and e-ophtha, and for screening and need for referral on MESSIDOR compared to a second human expert. Conclusions: Results highlight the fact that integrating manually engineered approaches with deep learned features is relevant to improve results when the networks are trained from lesion-level annotated data. An open source implementation of our system is publicly available at https://github.com/ignaciorlando/red-lesion-detection. © 2017 Elsevier B.V.",Deep learning; Diabetic retinopathy; Fundus images; Red lesion detection
Article,"Zhang W., Zhao X., Chen Y., Zhong J., Yi Z.",DeepUWF: An Automated Ultra-Wide-Field Fundus Screening System via Deep Learning,IEEE Journal of Biomedical and Health Informatics,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85098797699&doi=10.1109%2fJBHI.2020.3046771&partnerID=40&md5=bca17f05073e425c04d4172ea46ad803,"The emerging ultra-wide field of view (UWF) fundus color imaging is a powerful tool for fundus screening. However, manual screening is labor-intensive and subjective. Based on 2644 UWF images, a set of early fundus abnormal screening system named DeepUWF is developed. DeepUWF includes an abnormal fundus screening subsystem and a disease diagnosis subsystem for three kinds of fundus diseases (retinal tear & retinal detachment, diabetic retinopathy and pathological myopia). The components in the system are composed of a set of excellent convolutional neural networks and two custom classifiers. However, the contrast of UWF images used in the research is low, which seriously limits the extraction of fine features of UWF images by depth model. Therefore, the high specificity and low sensitivity of prediction results have always been difficult problems in research. In order to solve this problem, six kinds of image preprocessing techniques are adopted, and their effects on the prediction performance of fundus abnormal and three kinds of fundus diseases models are studied. A variety of experimental indicators are used to evaluate the algorithms for validity and reliability. The experimental results show that these preprocessing methods are helpful to improve the learning ability of the networks and achieve good sensitivity and specificity. Without ophthalmologists, DeepUWF has potential application value, which is helpful for fundus health screening and workflow improvement. © 2013 IEEE.",Deep learning; fundus screening; image classification; ultra-wide-field
Article,"Sánchez-Morla E.M., Fuentes J.L., Miguel-Jiménez J.M., Boquete L., Ortiz M., Orduna E., Satue M., Garcia-Martin E.",Automatic diagnosis of bipolar disorder using optical coherence tomography data and artificial intelligence,Journal of Personalized Medicine,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85113465713&doi=10.3390%2fjpm11080803&partnerID=40&md5=bdfb4b1ad3e705cc1def8d05e7dbb316,"Background: The aim of this study is to explore an objective approach that aids the diagnosis of bipolar disorder (BD), based on optical coherence tomography (OCT) data which are analyzed using artificial intelligence. Methods: Structural analyses of nine layers of the retina were analyzed in 17 type I BD patients and 42 controls, according to the areas defined by the Early Treatment Diabetic Retinopathy Study (ETDRS) chart. The most discriminating variables made up the feature vector of several automatic classifiers: Gaussian Naive Bayes, K-nearest neighbors and support vector machines. Results: BD patients presented retinal thinning affecting most layers, compared to controls. The retinal thickness of the parafoveolar area showed a high capacity to discriminate BD subjects from healthy individuals, specifically for the ganglion cell (area under the curve (AUC) = 0.82) and internal plexiform (AUC = 0.83) layers. The best classifier showed an accuracy of 0.95 for classifying BD versus controls, using as variables of the feature vector the IPL (inner nasal region) and the INL (outer nasal and inner inferior regions) thickness. Conclusions: Our patients with BD present structural alterations in the retina, and artificial intelligence seem to be a useful tool in BD diagnosis, but larger studies are needed to confirm our findings. © 2021 by the authors. Licensee MDPI, Basel, Switzerland.",Artificial intelligence; Bipolar disorder; Neuroprogression; Optical coherence tomography
Article,"Hatamizadeh A., Hosseini H., Patel N., Choi J., Pole C.C., Hoeferlin C.M., Schwartz S.D., Terzopoulos D.",RAVIR: A Dataset and Methodology for the Semantic Segmentation and Quantitative Analysis of Retinal Arteries and Veins in Infrared Reflectance Imaging,IEEE Journal of Biomedical and Health Informatics,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85127518587&doi=10.1109%2fJBHI.2022.3163352&partnerID=40&md5=2a65bb261721e2b1f29dab9cde698711,"The retinal vasculature provides important clues in the diagnosis and monitoring of systemic diseases including hypertension and diabetes. The microvascular system is of primary involvement in such conditions, and the retina is the only anatomical site where the microvasculature can be directly observed. The objective assessment of retinal vessels has long been considered a surrogate biomarker for systemic vascular diseases, and with recent advancements in retinal imaging and computer vision technologies, this topic has become the subject of renewed attention. In this paper, we present a novel dataset, dubbed RAVIR, for the semantic segmentation of Retinal Arteries and Veins in Infrared Reflectance (IR) imaging. It enables the creation of deep learning-based models that distinguish extracted vessel type without extensive post-processing. We propose a novel deep learning-based methodology, denoted as SegRAVIR, for the semantic segmentation of retinal arteries and veins and the quantitative measurement of the widths of segmented vessels. Our extensive experiments validate the effectiveness of SegRAVIR and demonstrate its superior performance in comparison to state-of-the-art models. Additionally, we propose a knowledge distillation framework for the domain adaptation of RAVIR pretrained networks on color images. We demonstrate that our pretraining procedure yields new state-of-the-art benchmarks on the DRIVE, STARE, and CHASE-DB1 datasets. Dataset link: https://ravirdataset.github.io/data. © 2013 IEEE.",deep learning; ophthalmology; Retinal image analysis; semantic segmentation; vascular width estimation
Article,"Ting D.S.W., Cheung C.Y., Nguyen Q., Sabanayagam C., Lim G., Lim Z.W., Tan G.S.W., Soh Y.Q., Schmetterer L., Wang Y.X., Jonas J.B., Varma R., Lee M.L., Hsu W., Lamoureux E., Cheng C.-Y., Wong T.Y.",Deep learning in estimating prevalence and systemic risk factors for diabetic retinopathy: a multi-ethnic study,npj Digital Medicine,2019,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85089606034&doi=10.1038%2fs41746-019-0097-x&partnerID=40&md5=a2e3f426ebed6a1aac63f493ecdf3cfb,"In any community, the key to understanding the burden of a specific condition is to conduct an epidemiological study. The deep learning system (DLS) recently showed promising diagnostic performance for diabetic retinopathy (DR). This study aims to use DLS as the grading tool, instead of human assessors, to determine the prevalence and the systemic cardiovascular risk factors for DR on fundus photographs, in patients with diabetes. This is a multi-ethnic (5 races), multi-site (8 datasets from Singapore, USA, Hong Kong, China and Australia), cross-sectional study involving 18,912 patients (n = 93,293 images). We compared these results and the time taken for DR assessment by DLS versus 17 human assessors – 10 retinal specialists/ophthalmologists and 7 professional graders). The estimation of DR prevalence between DLS and human assessors is comparable for any DR, referable DR and vision–threatening DR (VTDR) (Human assessors: 15.9, 6.5% and 4.1%; DLS: 16.1%, 6.4%, 3.7%). Both assessment methods identified similar risk factors (with comparable AUCs), including younger age, longer diabetes duration, increased HbA1c and systolic blood pressure, for any DR, referable DR and VTDR (p > 0.05). The total time taken for DLS to evaluate DR from 93,293 fundus photographs was ~1 month compared to 2 years for human assessors. In conclusion, the prevalence and systemic risk factors for DR in multi-ethnic population could be determined accurately using a DLS, in significantly less time than human assessors. This study highlights the potential use of AI for future epidemiology or clinical trials for DR grading in the global communities. © 2019, The Author(s).",Blood pressure; Deep learning; Diagnosis; Eye movements; Eye protection; Eye tracking; Photography; Risk assessment; Risk perception; Cardio-vascular risk factors; Condition; Diabetic retinopathy; Diagnostic performance; Epidemiological studies; Fundus photographs; Human assessors; Multi-site; Risk factors; Systemic risks; Grading; hemoglobin A1c; high density lipoprotein cholesterol; low density lipoprotein cholesterol; triacylglycerol; adult; Article; Australia; cardiovascular risk; China; cholesterol blood level; controlled study; cross-sectional study; deep learning; diabetic retinopathy; electric potential; ethnic difference; female; Hong Kong; human; major clinical study; male; middle aged; ophthalmologist; photography; prevalence; priority journal; retina image; Singapore; systolic blood pressure; United States
Article,"Arsalan M., Baek N.R., Owais M., Mahmood T., Park K.R.",Deep learning-based detection of pigment signs for analysis and diagnosis of retinitis pigmentosa,Sensors (Switzerland),2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85086629440&doi=10.3390%2fs20123454&partnerID=40&md5=74686bb8c0532fd54957fd3e3b2ce9ca,"Ophthalmological analysis plays a vital role in the diagnosis of various eye diseases, such as glaucoma, retinitis pigmentosa (RP), and diabetic and hypertensive retinopathy. RP is a genetic retinal disorder that leads to progressive vision degeneration and initially causes night blindness. Currently, the most commonly applied method for diagnosing retinal diseases is optical coherence tomography (OCT)-based disease analysis. In contrast, fundus imaging-based disease diagnosis is considered a low-cost diagnostic solution for retinal diseases. This study focuses on the detection of RP from the fundus image, which is a crucial task because of the low quality of fundus images and non-cooperative image acquisition conditions. Automatic detection of pigment signs in fundus images can help ophthalmologists and medical practitioners in diagnosing and analyzing RP disorders. To accurately segment pigment signs for diagnostic purposes, we present an automatic RP segmentation network (RPS-Net), which is a specifically designed deep learning-based semantic segmentation network to accurately detect and segment the pigment signs with fewer trainable parameters. Compared with the conventional deep learning methods, the proposed method applies a feature enhancement policy through multiple dense connections between the convolutional layers, which enables the network to discriminate between normal and diseased eyes, and accurately segment the diseased area from the background. Because pigment spots can be very small and consist of very few pixels, the RPS-Net provides fine segmentation, even in the case of degraded images, by importing high-frequency information from the preceding layers through concatenation inside and outside the encoder-decoder. To evaluate the proposed RPS-Net, experiments were performed based on 4-fold cross-validation using the publicly available Retinal Images for Pigment Signs (RIPS) dataset for detection and segmentation of retinal pigments. Experimental results show that RPS-Net achieved superior segmentation performance for RP diagnosis, compared with the state-of-the-art methods. © 2020 by the authors. Licensee MDPI, Basel, Switzerland.",Deep learning; Retinal disease; Retinitis pigmentosa; RPS-Net; Semantic segmentation
Article,"Zheng C., Xie X., Zhou K., Chen B., Chen J., Ye H., Li W., Qiao T., Gao S., Yang J., Liu J.",Assessment of generative adversarial networks model for synthetic optical coherence tomography images of retinal disorders,Translational Vision Science and Technology,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85088699544&doi=10.1167%2ftvst.9.2.29&partnerID=40&md5=8468ecea9866ffb5c996ae1ba75fb506,"Purpose: To assess whether a generative adversarial network (GAN) could synthesize realistic optical coherence tomography (OCT) images that satisfactorily serve as the educational images for retinal specialists, and the training datasets for the classification of various retinal disorders using deep learning (DL). Methods: The GANs architecture was adopted to synthesize high-resolution OCT images trained on a publicly available OCT dataset, including urgent referrals (37,206 OCT images from eyes with choroidal neovascularization, and 11,349 OCT images from eyes with diabetic macular edema) and nonurgent referrals (8617 OCT images from eyes with drusen, and 51,140 OCT images from normal eyes). Four hundred real and synthetic OCT images were evaluated by two retinal specialists (with over 10 years of clinical retinal experience) to assess image quality. We further trained two DL models on either real or synthetic datasets and compared the performance of urgent versus nonurgent referrals diagnosis tested on a local (1000 images from the public dataset) and clinical validation dataset (278 images from Shanghai Shibei Hospital). Results: The image quality of real versus synthetic OCT images was similar as assessed by two retinal specialists. The accuracy of discrimination of real versus synthetic OCT images was 59.50% for retinal specialist 1 and 53.67% for retinal specialist 2. For the local dataset, the DL model trained on real (DL_Model_R) and synthetic OCT images (DL_Model_S) had an area under the curve (AUC) of 0.99, and 0.98, respectively. For the clinical dataset, the AUC was 0.94 for DL_Model_R and 0.90 for DL_Model_S. Conclusions: The GAN synthetic OCT images can be used by clinicians for educational purposes and for developing DL algorithms. Translational Relevance: The medical image synthesis based on GANs is promising in humans and machines to fulfill clinical tasks. © 2020 The Authors.",Deep learning; Generative adversarial networks; Optical coherence tomography; Retinal disorders
Conference Paper,"Wen Y., Chen L., Qiao L., Deng Y., Chen H., Zhang T., Zhou C.",LET'S FIND FLUORESCEIN: CROSS-MODAL DUAL ATTENTION LEARNING FOR FLUORESCEIN LEAKAGE SEGMENTATION IN FUNDUS FLUORESCEIN ANGIOGRAPHY,Proceedings - IEEE International Conference on Multimedia and Expo,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85126468910&doi=10.1109%2fICME51207.2021.9428108&partnerID=40&md5=d08da47466fabc84f76d7fe78fcb4a4e,"Automatic segmentation of fluorescein leakage in fundus fluorescein angiography images is important in the clinical diagnosis of advanced diabetic retinopathy. Despite the recent success of deep-learning-based models in improving medical image segmentation, segmentation of fluorescein leakage has been ignored owing to (1) a lack of publicly available data with sufficient annotations for training a segmentation network and (2) incapability of supervised models to accurately localize fluorescein leakage at different imaging angles. To address these issues, we studied the automatic segmentation of fluorescein leakage in fundus fluorescein angiography images and devised a method involving (1) a cross-modal learning framework for fluorescein leakage segmentation using both image and text data, (2) a dual attention learning module for identifying important linguistic and visual features, and (3) fluorescein-related-keyword classification for identifying meaningful textual expressions pertaining to the location and type of fluorescein leakage. We demonstrate the effectiveness of the proposed method for an in-house fundus fluorescein angiography image data set. © 2021 IEEE",Attention module; Convolutional neural network; Cross-modal; Deep learning; Fluorescein leakage segmentation; Fundus fluorescein angiography
Article,"Abbasi S., Hajabdollahi M., Khadivi P., Karimi N., Roshandel R., Shirani S., Samavi S.",Classification of diabetic retinopathy using unlabeled data and knowledge distillation,Artificial Intelligence in Medicine,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85115891214&doi=10.1016%2fj.artmed.2021.102176&partnerID=40&md5=072f4a84cf66950cb7ab1fb069029010,"Over the last decade, advances in Machine Learning and Artificial Intelligence have highlighted their potential as a diagnostic tool in the healthcare domain. Despite the widespread availability of medical images, their usefulness is severely hampered by a lack of access to labeled data. For example, while Convolutional Neural Networks (CNNs) have emerged as an essential analytical tool in image processing, their impact is curtailed by training limitations due to insufficient labeled data availability. Transfer Learning enables models developed for one task to be reused for a second task. Knowledge distillation enables transferring knowledge from a pre-trained model to another. However, it suffers from limitations, and the two models' constraints need to be architecturally similar. Knowledge distillation addresses some of the shortcomings of transfer learning by generalizing a complex model to a lighter model. However, some parts of the knowledge may not be distilled by knowledge distillation sufficiently. In this paper, a novel knowledge distillation approach using transfer learning is proposed. The proposed approach transfers the complete knowledge of a model to a new smaller one. Unlabeled data are used in an unsupervised manner to transfer the new smaller model's maximum amount of knowledge. The proposed method can be beneficial in medical image analysis, where labeled data are typically scarce. The proposed approach is evaluated in classifying images for diagnosing Diabetic Retinopathy on two publicly available datasets, including Messidor and EyePACS. Simulation results demonstrate that the approach effectively transfers knowledge from a complex model to a lighter one. Furthermore, experimental results illustrate that different small models' performance is improved significantly using unlabeled data and knowledge distillation. © 2021 Elsevier B.V.",Convolutional neural networks (CNN); Diabetic retinopathy; Knowledge distillation; Teacher-student model; Transfer learning; Unlabeled data
Article,"Guo S., Wang K., Kang H., Liu T., Gao Y., Li T.",Bin loss for hard exudates segmentation in fundus images,Neurocomputing,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85065042355&doi=10.1016%2fj.neucom.2018.10.103&partnerID=40&md5=e2cbff45de2801b4d4d5bf74a8dbb1eb,"Diabetic retinopathy is one of the leading reasons that causes blindness. And the segmentation of hard exudates in color fundus images is crucial for early diagnosis of diabetic retinopathy, which is a difficult task due to its uncertainty in size, shape and contrast. Class-balanced cross entropy (CBCE) loss is the most popular objective function for image segmentation task to solve the class-unbalance problem. However, we show that background pixels tend to be misclassified to hard exudates in CBCE since the loss for a misclassified background pixels is much smaller than that for a misclassified hard exudate pixel, which is called loss-unbalance problem here. A top-k loss is proposed in this paper, which considers the cases of both class-unbalance and loss-unbalance by focusing more over the hard-to-classify pixels. Moreover, a fast version of the top-k loss, named bin loss, is implemented for efficiency, which reduces the time complexity from O(nlog n) of top-k loss to O(n), where n is the number of background pixels. We evaluated the proposed bin loss over two public datasets for hard exudates segmentation task, including e-ophtha EX and IDRiD. Furthermore, three popular models for image segmentation, HED, DeepLab v2, and FCRN, were used to evaluate the versatility of bin loss. Extensive experiments show that each model with the proposed bin loss performs better than that with CBCE loss, which demonstrates bin loss is versatile so that it can be applied to different models for performance improvement. Specially, for DeepLab over e-ophtha EX, the F-score increases 5.2 percentage points, and the area under the SE-PPV curve (AUC) increases 10.6 percentage points. Moreover, the AUC increases more than 4 percentage points over IDRiD dataset for both DeepLab and FCRN. The source code of bin loss is available at: https://github.com/guomugong/bin_loss. © 2019 Elsevier B.V.",Bin loss; Deep learning; Diabetic retinopathy; Fundus image; Hard exudates segmentation
Article,"Shen Y., Sheng B., Fang R., Li H., Dai L., Stolte S., Qin J., Jia W., Shen D.",Domain-invariant interpretable fundus image quality assessment,Medical Image Analysis,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85079546595&doi=10.1016%2fj.media.2020.101654&partnerID=40&md5=4d3129c46de3e85c4141e702445fa9a4,"Objective and quantitative assessment of fundus image quality is essential for the diagnosis of retinal diseases. The major factors in fundus image quality assessment are image artifact, clarity, and field definition. Unfortunately, most of existing quality assessment methods focus on the quality of overall image, without interpretable quality feedback for real-time adjustment. Furthermore, these models are often sensitive to the specific imaging devices, and cannot generalize well under different imaging conditions. This paper presents a new multi-task domain adaptation framework to automatically assess fundus image quality. The proposed framework provides interpretable quality assessment with both quantitative scores and quality visualization for potential real-time image recapture with proper adjustment. In particular, the present approach can detect optic disc and fovea structures as landmarks, to assist the assessment through coarse-to-fine feature encoding. The framework also exploit semi-tied adversarial discriminative domain adaptation to make the model generalizable across different data sources. Experimental results demonstrated that the proposed algorithm outperforms different state-of-the-art approaches and achieves an area under the ROC curve of 0.9455 for the overall quality classification. © 2020 Elsevier B.V.",Domain adaptation; Fundus image quality assessment; Interpretability; Multi-task learning
Conference Paper,"Kumar E.S., Bindu C.S.",Segmentation of Retinal Lesions in Fundus Images: A Patch Based Approach Using Encoder-Decoder Neural Network,"2021 7th International Conference on Advanced Computing and Communication Systems, ICACCS 2021",2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85108030157&doi=10.1109%2fICACCS51430.2021.9441964&partnerID=40&md5=0df712cfea7f641b1deaa4c7f9a247ec,"Lesion segmentation is an essential aspect while diagnosing Diabetic Retinopathy (DR) at initial stages. Manual identification becomes exceptionally challenging and time consuming because of the distinction in morphologies and size of lesions. Manual annotation of lesions by professionals is labor intensive and therefore requires the development of automatic segmentation techniques, but still it is also a challenging task because of the low local contrast and small size lesions present in the image. The automatic segmentation of retinal lesions through deep learning approach is of great impact for the initial diagnosis and treatment of DR. This paper proposes a patch based approach using encoder-decoder neural network to perform retinal lesions segmentation in fundus images. The architecture is trained and validated on IDRiD dataset which consists of microaneurysms, hemorrhages and hard exudate segmentations. In this approach for creating image patches a sliding widow technique is used, later the network evaluates the patches of the images and produces a probability map that predicts different types of lesions. An elaborative experiment was accompanied on IDRiD to calculate the performance of the suggested approach. The projected sensitivity, specificity and accuracy are 97.24%, 99.97%, and 99.97% respectively, which validates the effectiveness and dominance of this technique. When compared with other studies on similar tasks, the results obtained by this work indicate substantially improved performance in terms of sensitivity specificity. © 2021 IEEE.",Convolutional Neural Network; Deep Learning; Diabetic Retinopathy; Encoder-Decoder Network; Fundus Images; Lesion Segmentation; Patch Generation
Conference Paper,"Chelaramani S., Gupta M., Agarwal V., Gupta P., Habash R.",Multi-task knowledge distillation for eye disease prediction,"Proceedings - 2021 IEEE Winter Conference on Applications of Computer Vision, WACV 2021",2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85109992041&doi=10.1109%2fWACV48630.2021.00403&partnerID=40&md5=c568ab93ba299bf2b3807451ee2c7896,"While accurate disease prediction from retinal fundus images is critical, collecting large amounts of high quality labeled training data to build such supervised models is difficult. Deep learning classifiers have led to high accuracy results across a wide variety of medical imaging problems, but they need large amounts of labeled data. Given a fundus image, we aim to evaluate various solutions for learning deep neural classifiers using small labeled data for three tasks related to eye disease prediction: (T1) predicting one of the five broad categories - diabetic retinopathy, age-related macular degeneration, glaucoma, melanoma and normal, (T2) predicting one of the 320 fine-grained disease sub-categories, (T3) generating a textual diagnosis. The problem is challenging because of small data size, need for predictions across multiple tasks, handling image variations, and large number of hyper-parameter choices. Modeling the problem under a multi-task learning (MTL) setup, we investigate the contributions of each of the proposed tasks while dealing with a small amount of labeled data. Further, we suggest a novel MTL-based teacher ensemble method for knowledge distillation. On a dataset of 7212 labeled and 35854 unlabeled images across 3502 patients, our technique obtains ~83% accuracy, ~75% top-5 accuracy and ~48 BLEU for tasks T1, T2 and T3 respectively. Even with 15% training data, our method outperforms baselines by 8.1, 3.2 and 11.2 points for the three tasks respectively. © 2021 IEEE.",Classification (of information); Computer vision; Deep learning; Diagnosis; Distillation; Eye protection; Forecasting; Linearization; Medical imaging; Medical problems; Eye disease; High quality; High-accuracy; Labeled data; Labeled training data; Large amounts; Learning classifiers; Multi tasks; Retinal fundus images; Task knowledge; Ophthalmology
Article,"Padilla-Pantoja F.D., Sanchez Y.D., Quijano-Nieto B.A., Perdomo O.J., Gonzalez F.A.",Etiology of Macular Edema Defined by Deep Learning in Optical Coherence Tomography Scans,Translational vision science & technology,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85139375864&doi=10.1167%2ftvst.11.9.29&partnerID=40&md5=fde7ce2bfbd08fc53662263661682eac,"Purpose: To develop an automated method based on deep learning (DL) to classify macular edema (ME) from the evaluation of optical coherence tomography (OCT) scans. Methods: A total of 4230 images were obtained from data repositories of patients attended in an ophthalmology clinic in Colombia and two free open-access databases. They were annotated with four biomarkers (BMs) as intraretinal fluid, subretinal fluid, hyperreflective foci/tissue, and drusen. Then the scans were labeled as control or ocular disease among diabetic macular edema (DME), neovascular age-related macular degeneration (nAMD), and retinal vein occlusion (RVO) by two expert ophthalmologists. Our method was developed by following four consecutive phases: segmentation of BMs, the combination of BMs, feature extraction with convolutional neural networks to achieve binary classification for each disease, and, finally, multiclass classification of diseases and control images. Results: The accuracy of our model for nAMD was 97%, and for DME, RVO, and control were 94%, 93%, and 93%, respectively. Area under curve values were 0.99, 0.98, 0.96, and 0.97, respectively. The mean Cohen's kappa coefficient for the multiclass classification task was 0.84. Conclusions: The proposed DL model may identify OCT scans as normal and ME. In addition, it may classify its cause among three major exudative retinal diseases with high accuracy and reliability. Translational Relevance: Our DL approach can optimize the efficiency and timeliness of appropriate etiological diagnosis of ME, thus improving patient access and clinical decision making. It could be useful in places with a shortage of specialists and for readers that evaluate OCT scans remotely.","diabetic retinopathy; diagnostic imaging; human; macular edema; optical coherence tomography; procedures; reproducibility; retina vein occlusion; Deep Learning; Diabetic Retinopathy; Humans; Macular Edema; Reproducibility of Results; Retinal Vein Occlusion; Tomography, Optical Coherence"
Article,"Joshi A., Sharma K.K.",Graph deep network for optic disc and optic cup segmentation for glaucoma disease using retinal imaging,Physical and Engineering Sciences in Medicine,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85132753878&doi=10.1007%2fs13246-022-01154-y&partnerID=40&md5=49ded25230b81b898e1a1a1f1b501f58,"The fundus imaging method of eye screening detects eye diseases by segmenting the optic disc (OD) and optic cup (OC). OD and OC are still challenging to segment accurately. This work proposes three-layer graph-based deep architecture with an enhanced fusion method for OD and OC segmentation. CNN encoder-decoder architecture, extended graph network, and approximation via fusion-based rule are explored for connecting local and global information. A graph-based model is developed for combining local and overall knowledge. By extending feature masking, regularization of repetitive features with fusion for combining channels has been done. The performance of the proposed network is evaluated through the analysis of different metric parameters such as dice similarity coefficient (DSC), intersection of union (IOU), accuracy, specificity, sensitivity. Experimental verification of this methodology has been done using the four benchmarks publicly available datasets DRISHTI-GS, RIM-ONE for OD, and OC segmentation. In addition, DRIONS-DB and HRF fundus imaging datasets were analyzed for optimizing the model’s performance based on OD segmentation. DSC metric of methodology achieved 0.97 and 0.96 for DRISHTI-GS and RIM-ONE, respectively. Similarly, IOU measures for DRISHTI-GS and RIM-ONE datasets were 0.96 and 0.93, respectively, for OD measurement. For OC segmentation, DSC and IOU were measured as 0.93 and 0.90 respectively for DRISHTI-GS and 0.83 and 0.82 for RIM-ONE data. The proposed technique improved value of metrics with most of the existing methods in terms of DSC and IOU of the results metric of the experiments for OD and OC segmentation. © 2022, Australasian College of Physical Scientists and Engineers in Medicine.",Deep learning; Dice similarity coefficient; Glaucoma; Intersection section of union; Optic disc segmentation; Retinal fundus images
Conference Paper,"Khan M.Z., Lee Y.",Dynamic Inductive Transfer Learning with Decision Support Feedback to Optimize Retina Analysis,"Proceedings - 2021 IEEE 9th International Conference on Healthcare Informatics, ISCHI 2021",2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85118136068&doi=10.1109%2fICHI52183.2021.00025&partnerID=40&md5=d5bb04c7aa9ffa277db5ed12fa3035fc,"The retina is a unique tissue considered an extension of a brain that transforms the incoming light into neural signals. Numerous deep neural networks are developed to segment retinal images precisely for detecting diabetic retinopathy and glaucoma. However, these networks are limited in selecting evaluation metrics and tuning hyperparameters subjectively in the model validation process. Furthermore, the segmentation networks lack a progressive mode of model tuning for active transfer learning. This article proposed a novel technique of dynamic inductive learning with single-point decision criteria, striving to optimize the image segmentation model using multi-criteria decision support feedback. A case study is conducted to reveal the problems related to the conventional approach and establish the significance of a proposed concept with empirical evidence. It is found that dynamic inductive transfer learning reduces the subjectivity of hyperparameter selection in a model validation process. For a given challenge of retinal vessel extraction, stochastic gradient descent is considered an optimal candidate for two variants of dynamic inductive transfer learning with a decision score of 0.9634 and 0.9951, respectively. This effort would serve as a vital step towards an optimal disease diagnosis. © 2021 IEEE.",Decision system; Optimization; Retinal vessels; Segmentation model; Transfer learning
Article,"Gao Q., Amason J., Cousins S., Pajic M., Hadziahmetovic M.",Automated identification of referable retinal pathology in teleophthalmology setting,Translational Vision Science and Technology,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85108378730&doi=10.1167%2fTVST.10.6.30&partnerID=40&md5=762cd0dedd648dc95fe7fcf4673785a0,"Purpose: This study aims to meet a growing need for a fully automated, learning-based interpretation tool for retinal images obtained remotely (e.g. teleophthalmol-ogy) through different imaging modalities that may include imperfect (uninterpretable) images. Methods: A retrospective study of 1148 optical coherence tomography (OCT) and color fundus photography (CFP) retinal images obtained using Topcon’s Maestro care unit on 647 patients with diabetes. To identify retinal pathology, a Convolutional Neural Network (CNN) with dual-modal inputs (i.e. CFP and OCT images) was developed. We developed a novel alternate gradient descent algorithm to train the CNN, which allows for the use of uninterpretable CFP/OCT images (i.e. ungradable images that do not contain sufficient image biomarkers for the reviewer to conclude absence or presence of retinal pathology). Specifically, a 9:1 ratio to split the training and testing dataset was used for training and validating the CNN. Paired CFP/OCT inputs (obtained from a single eye of a patient) were grouped as retinal pathology negative (RPN; 924 images) in the absence of retinal pathology in both imaging modalities, or if one of the imaging modalities was uninterpretable and the other without retinal pathology. If any imaging modality exhibited referable retinal pathology, the corresponding CFP/OCT inputs were deemed retinal pathology positive (RPP; 224 images) if any imaging modality exhibited referable retinal pathology. Results: Our approach achieved 88.60% (95% confidence interval [CI] = 82.76% to 94.43%) accuracy in identifying pathology, along with the false negative rate (FNR) of 12.28% (95% CI = 6.26% to 18.31%), recall (sensitivity) of 87.72% (95% CI = 81.69% to 93.74%), specificity of 89.47% (95% CI = 83.84% to 95.11%), and area under the curve of receiver operating characteristic (AUC-ROC) was 92.74% (95% CI = 87.71% to 97.76%). Conclusions: Our model can be successfully deployed in clinical practice to facilitate automated remote retinal pathology identification. Translational Relevance: A fully automated tool for early diagnosis of retinal pathology might allow for earlier treatment and improved visual outcomes. © 2021 The Authors.",Automated diagnosis; Deep learning; Image analysis; Retinal pathology; Teleophthalmology
Article,"Wang J., Li X., Lv P., Shi C.",SERR-U-Net: Squeeze-and-Excitation Residual and Recurrent Block-Based U-Net for Automatic Vessel Segmentation in Retinal Image,Computational and Mathematical Methods in Medicine,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85113793569&doi=10.1155%2f2021%2f5976097&partnerID=40&md5=d4861458f630f9b5ccc95aa7d536b20c,"Background and Objective. Accurate segmentation of retinal vessels is considered as an important prerequisite for computer-aided diagnosis of ophthalmic diseases, diabetes, glaucoma, and other diseases. Although current learning-based methods have greatly improved the performance of retinal vessel segmentation, the accuracy could not meet the requirements of clinical assistance yet. Methods. A new SERR-U-Net framework for retinal vessel segmentation is proposed, which leverages technologies including Squeeze-and-Excitation (SE), residual module, and recurrent block. First, the convolution layers of encoder and decoder are modified on the basis of U-Net, and the recurrent block is used to increase the network depth. Second, the residual module is utilized to alleviate the vanishing gradient problem. Finally, to derive more specific vascular features, we employed the SE structure to introduce attention mechanism into the U-shaped network. In addition, enhanced super-resolution generative adversarial networks (ESRGANs) are also deployed to remove the noise of retinal image. Results. The effectiveness of this method was tested on two public datasets, DRIVE and STARE. In the experiment of DRIVE dataset, the accuracy and AUC (area under the curve) of our method were 0.9552 and 0.9784, respectively, and for SATRE dataset, 0.9796 and 0.9859 were achieved, respectively, which proved a high accuracy and promising prospect on clinical assistance. Conclusion. An improved U-Net network combining SE, ResNet, and recurrent technologies is developed for automatic vessel segmentation from retinal image. This new model enables an improvement on the accuracy compared to learning-based methods, and its robustness in circumvent challenging cases such as small blood vessels and intersection of vessels is also well demonstrated and validated. © 2021 Jinke Wang et al.","Blood vessels; Computer aided diagnosis; Eye protection; Image enhancement; Learning systems; Ophthalmology; Recurrent neural networks; Adversarial networks; Area under the curves; Attention mechanisms; Learning-based methods; Retinal vessel segmentations; Vanishing gradient; Vascular features; Vessel segmentation; Image segmentation; area under the curve; Article; computer aided design; diabetic retinopathy; enhanced super resolution generative adversarial network; human; image processing; image segmentation; noise reduction; qualitative analysis; quantitative analysis; recurrent neural network; residual neural network; retina blood vessel; retina image; squeeze and excitation residual and recurrent block based unit network; algorithm; anatomy and histology; biology; computer assisted diagnosis; factual database; pathology; procedures; retinoscopy; Algorithms; Computational Biology; Databases, Factual; Deep Learning; Humans; Image Interpretation, Computer-Assisted; Neural Networks, Computer; Retinal Vessels; Retinoscopy"
Conference Paper,"Badar M., Shahzad M., Fraz M.M.",Simultaneous segmentation of multiple retinal pathologies using fully convolutional deep neural network,Communications in Computer and Information Science,2018,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85052869677&doi=10.1007%2f978-3-319-95921-4_29&partnerID=40&md5=4851ee25c80e60d3ccd2283931c56256,"The segmentation of retinal pathologies is the primitive and essential step in the development of automated diagnostic system for various systemic, cardiovascular, and ophthalmic diseases. The existing state-of-the-art machine learning based retinal pathologic segmentation techniques mainly aim at delineating pathology of one kind only. In this context, we have proposed a novel end-to-end technique for simultaneous segmentation of multiple retinal pathologies (i.e., exudates, hemorrhages, and cotton-wool spots) using encoder-decoder based fully convolutional neural network architecture. Moreover, the task of retinal pathology extraction has been modeled as a semantic segmentation framework which enables us to obtain pixel-level class labels. The proposed algorithm has been evaluated on publically available Messidor dataset and achieved state-of-the-art mean accuracies of 99.24% (exudates), 97.86% (hemorrhages), and 88.65% (cotton-wool spots). The developed approach may aid in further optimization of pathology quantification module of the QUARTZ software which has been developed earlier by our research group. © Springer Nature Switzerland AG 2018.",Deep learning; Diabetic retinopathy; Encoder-decoder; Fully convolutional neural networks; Retinal pathology; Semantic segmentation
Article,"Schlegl T., Waldstein S.M., Bogunovic H., Endstraßer F., Sadeghipour A., Philip A.-M., Podkowinski D., Gerendas B.S., Langs G., Schmidt-Erfurth U.",Fully Automated Detection and Quantification of Macular Fluid in OCT Using Deep Learning,Ophthalmology,2018,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85044656432&doi=10.1016%2fj.ophtha.2017.10.031&partnerID=40&md5=165c07aa6023917be0bec2e769856245,"Purpose: Development and validation of a fully automated method to detect and quantify macular fluid in conventional OCT images. Design: Development of a diagnostic modality. Participants: The clinical dataset for fluid detection consisted of 1200 OCT volumes of patients with neovascular age-related macular degeneration (AMD, n = 400), diabetic macular edema (DME, n = 400), or retinal vein occlusion (RVO, n = 400) acquired with Zeiss Cirrus (Carl Zeiss Meditec, Dublin, CA) (n = 600) or Heidelberg Spectralis (Heidelberg Engineering, Heidelberg, Germany) (n = 600) OCT devices. Methods: A method based on deep learning to automatically detect and quantify intraretinal cystoid fluid (IRC) and subretinal fluid (SRF) was developed. The performance of the algorithm in accurately identifying fluid localization and extent was evaluated against a manual consensus reading of 2 masked reading center graders. Main Outcome Measures: Performance of a fully automated method to accurately detect, differentiate, and quantify intraretinal and SRF using area under the receiver operating characteristics curves, precision, and recall. Results: The newly designed, fully automated diagnostic method based on deep learning achieved optimal accuracy for the detection and quantification of IRC for all 3 macular pathologies with a mean accuracy (AUC) of 0.94 (range, 0.91–0.97), a mean precision of 0.91, and a mean recall of 0.84. The detection and measurement of SRF were also highly accurate with an AUC of 0.92 (range, 0.86–0.98), a mean precision of 0.61, and a mean recall of 0.81, with superior performance in neovascular AMD and RVO compared with DME, which was represented rarely in the population studied. High linear correlation was confirmed between automated and manual fluid localization and quantification, yielding an average Pearson's correlation coefficient of 0.90 for IRC and of 0.96 for SRF. Conclusions: Deep learning in retinal image analysis achieves excellent accuracy for the differential detection of retinal fluid types across the most prevalent exudative macular diseases and OCT devices. Furthermore, quantification of fluid achieves a high level of concordance with manual expert assessment. Fully automated analysis of retinal OCT images from clinical routine provides a promising horizon in improving accuracy and reliability of retinal diagnosis for research and clinical practice in ophthalmology. © 2017 American Academy of Ophthalmology","area under the curve; Article; controlled study; deep learning; diabetic macular edema; diagnostic accuracy; diagnostic test accuracy study; human; learning algorithm; machine learning; major clinical study; optical coherence tomography; priority journal; recall; receiver operating characteristic; retina image; retina vein occlusion; subretinal fluid; wet macular degeneration; aged; comparative study; computer assisted diagnosis; diabetic retinopathy; diagnostic imaging; female; macular edema; male; middle aged; optical coherence tomography; procedures; reproducibility; retina vein occlusion; validation study; visual acuity; wet macular degeneration; Aged; Deep Learning; Diabetic Retinopathy; Diagnosis, Computer-Assisted; Female; Humans; Macular Edema; Male; Middle Aged; Reproducibility of Results; Retinal Vein Occlusion; ROC Curve; Subretinal Fluid; Tomography, Optical Coherence; Visual Acuity; Wet Macular Degeneration"
Article,"Guo M., Zhao M., Cheong A.M.Y., Dai H., Lam A.K.C., Zhou Y.",Automatic quantification of superficial foveal avascular zone in optical coherence tomography angiography implemented with deep learning,"Visual Computing for Industry, Biomedicine, and Art",2019,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85087964973&doi=10.1186%2fs42492-019-0031-8&partnerID=40&md5=76184f8d292d61945ac591a2bb2b1cf9,"An accurate segmentation and quantification of the superficial foveal avascular zone (sFAZ) is important to facilitate the diagnosis and treatment of many retinal diseases, such as diabetic retinopathy and retinal vein occlusion. We proposed a method based on deep learning for the automatic segmentation and quantification of the sFAZ in optical coherence tomography angiography (OCTA) images with robustness to brightness and contrast (B/C) variations. A dataset of 405 OCTA images from 45 participants was acquired with Zeiss Cirrus HD-OCT 5000 and the ground truth (GT) was manually segmented subsequently. A deep learning network with an encoder–decoder architecture was created to classify each pixel into an sFAZ or non-sFAZ class. Subsequently, we applied largest-connected-region extraction and hole-filling to fine-tune the automatic segmentation results. A maximum mean dice similarity coefficient (DSC) of 0.976 ± 0.011 was obtained when the automatic segmentation results were compared against the GT. The correlation coefficient between the area calculated from the automatic segmentation results and that calculated from the GT was 0.997. In all nine parameter groups with various brightness/contrast, all the DSCs of the proposed method were higher than 0.96. The proposed method achieved better performance in the sFAZ segmentation and quantification compared to two previously reported methods. In conclusion, we proposed and successfully verified an automatic sFAZ segmentation and quantification method based on deep learning with robustness to B/C variations. For clinical applications, this is an important progress in creating an automated segmentation and quantification applicable to clinical analysis. © 2019, The Author(s).",Automatic segmentation and quantification; Deep learning; Foveal avascular zone; Optical coherence tomography angiography
Article,"Wen Y., Chen L., Qiao L., Deng Y., Chen H., Zhang T., Zhou C.",FLeak-Seg: Automated Fundus Fluorescein Leakage Segmentation via Cross-Modal Attention Learning,IEEE Multimedia,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123361361&doi=10.1109%2fMMUL.2022.3142986&partnerID=40&md5=0a7c4faa84abf88e307da16178e68fed,"Despite the recent success of deep learning-based models for medical image segmentation and the importance of automated fluorescein leakage segmentation for the diagnosis of advanced diabetic retinopathy, segmentation of fluorescein leakage has been neglected because 1) there are no publicly available databases with sufficient annotations to train segmentation models and 2) supervised models struggle to accurately distinguish between different types of fluorescein leakage and localize leakages at different imaging angles. To tackle these challenges, this work presents FLeak-Seg, a cross-modal dual attention learning method to jointly capture visual and language information, for end-to-end fluorescein leakage segmentation in fundus fluorescein angiography. Specifically, both image and text data are used as input, where visual and linguistic features are captured by a cross-modal attention learning module to compensate for the lack of annotations. A keyword classification module is also employed to identify meaningful expressions related to the type and location of fluorescein leakages to further facilitate the segmentation. Experimental results obtained in an in-house fundus fluorescein angiography database demonstrate the superiority of our method. We show how erroneous segmentation masks can be improved using FLeak-Seg, its advantages in the context of limited samples, and its behavior on segmenting different types of fluorescein leakages. © 2022 IEEE.",Attention learning; Cross-modal; Deep learning; Fluorescein leakage segmentation; Fundus fluorescein angiography
Article,"Zheng B., Jiang Q., Lu B., He K., Wu M.-N., Hao X.-L., Zhou H.-X., Zhu S.-J., Yang W.-H.",Five-category intelligent auxiliary diagnosis model of common fundus diseases based on fundus images,Translational Vision Science and Technology,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85109829122&doi=10.1167%2ftvst.10.7.20&partnerID=40&md5=74738457e78785febc6ed00db4bffab0,"Purpose: The discrepancy of the number between ophthalmologists and patients in China is large. Retinal vein occlusion (RVO), high myopia, glaucoma, and diabetic retinopathy (DR) are common fundus diseases. Therefore, in this study, a five-category intelligent auxiliary diagnosis model for common fundus diseases is proposed; the model’s area of focus is marked. Methods: A total of 2000 fundus images were collected; 3 different 5-category intelligent auxiliary diagnosis models for common fundus diseases were trained via different transfer learning and image preprocessing techniques. A total of 1134 fundus images were used for testing. The clinical diagnostic results were compared with the diagnostic results. The main evaluation indicators included sensitivity, specificity, F1-score, area under the concentration-time curve (AUC), 95% confidence interval (CI), kappa, and accuracy. The interpretation methods were used to obtain the model’s area of focus in the fundus image. Results: The accuracy rates of the 3 intelligent auxiliary diagnosis models on the 1134 fundus images were all above 90%, the kappa values were all above 88%, the diagnosis consistency was good, and the AUC approached 0.90. For the 4 common fundus diseases, the best results of sensitivity, specificity, and F1-scores of the 3 models were 88.27%, 97.12%, and 84.02%; 89.94%, 99.52%, and 93.90%; 95.24%, 96.43%, and 85.11%; and 88.24%, 98.21%, and 89.55%, respectively. Conclusions: This study designed a five-category intelligent auxiliary diagnosis model for common fundus diseases. It can be used to obtain the diagnostic category of fundus images and the model’s area of focus. Translational Relevance: This study will help the primary doctors to provide effective services to all ophthalmologic patients. © 2021 The Authors.",Common fundus diseases; Deep learning; Intelligent auxiliary diagnosis model; Model interpretability approach; Ophthalmological diagnostic techniques
Conference Paper,"Subramanian M., Shanmugavadivel K., Naren O.S., Premkumar K., Rankish K.",Classification of Retinal OCT Images Using Deep Learning,"2022 International Conference on Computer Communication and Informatics, ICCCI 2022",2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85128762823&doi=10.1109%2fICCCI54379.2022.9740985&partnerID=40&md5=3f31c25a47427553015a04bd04af328a,"In recent years, retinal disorders have become a serious public health concern. Retinal disorders develop slowly and without obvious signs. Every year, millions of individuals all around the world are diagnosed with retinal illness. Retinal illnesses manifest themselves in a variety of ways, but the majority of them result in visual problems. Retinal illnesses may damage any portion of your retina, causing visual problems, and some can even lead to blindness. Various retinal illnesses include Diabetic retinopathy, Macular pucker, Glaucoma, Macular hole, Age-related macular degeneration, Drusen, Central serous retinopathy, Macular edema, Vitreous traction, and Optic nerve abnormalities. Millions of light-sensitive cells (rods and cones) and other nerve cells make up the retina, which receives and organizes visual information. To avoid vision deterioration, early identification and treatment are critical. Optical Coherence Tomography (OCT) is a high-resolution diagnostic technology that can analyze and determine the quantitative distinction in diseased retinal layers. OCT - Optical coherence tomography which uses light waves is a non-invasive imaging procedure that takes cross-section photographs of your retina. It obtains a large number of detailed images of the retina, which are valuable for diagnosing and tracking changes in the retina and optic nerve over time. It is crucial in both diagnosing and selecting the appropriate treatment options. The accuracy of traditional approaches for classifying retinal disorders has ranged from 80% to 91%. As a result, a deep learning image identification system based on convolutional neural networks is presented to classify retinal illnesses more precisely and ideally in their early stages. The OCT pictures of the retina are classified into 'AMD, CNV, DRUSEN, DMR, DR, MH, CSR, and Normal Eye' using a lightweight Deep neural network. On the Retinal OCT Images dataset, the accuracy achieved in this study with the aid of VGG16 is around 97%. When compared to other methodologies in the literature, it has a high level of accuracy in categorizing the illness. © 2022 IEEE.",Convolutional Neural Network (CNN); DenseNet; Inception; Retinal Diseases; Retinal OCT Images Dataset; VGG16; VGG19
Article,"Lo Castro D., Tegolo D., Valenti C.",A visual framework to create photorealistic retinal vessels for diagnosis purposes,Journal of Biomedical Informatics,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85087492636&doi=10.1016%2fj.jbi.2020.103490&partnerID=40&md5=5d1ce0f466093e73a2cc0d8e6f98eae0,"The methods developed in recent years for synthesising an ocular fundus can be been divided into two main categories. The first category of methods involves the development of an anatomical model of the eye, where artificial images are generated using appropriate parameters for modelling the vascular networks and fundus. The second type of method has been made possible by the development of deep learning techniques and improvements in the performance of hardware (especially graphics cards equipped with a large number of cores). The methodology proposed here to produce high-resolution synthetic fundus images is intended to be an alternative to the increasingly widespread use of generative adversarial networks to overcome the problems that arise in producing slightly modified versions of the same real images. This will allow the simulation of pathologies and the prediction of eye-related diseases. The proposed approach is based on the principle of least action and correctly places the vessels on the simulated eye fundus without using real morphometric information. An a posteriori analysis of the average characteristics such as the size, length, bifurcations, and endpoint positioning confirmed the substantial accuracy of the proposed approach compared to real data. A graphical user interface allows the user to make any changes in real time by controlling the positions of control points. © 2020 Elsevier Inc.",Data augmentation; Fundus image analysis; Predictive evaluation diseases; Statistical features; Synthetic retinal image
Article,"Aurangzeb K., Aslam S., Alhussein M., Naqvi R.A., Arsalan M., Haider S.I.",Contrast Enhancement of Fundus Images by Employing Modified PSO for Improving the Performance of Deep Learning Models,IEEE Access,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85103275349&doi=10.1109%2fACCESS.2021.3068477&partnerID=40&md5=d693a9731b7a2e27e2b1cb868e83bafc,"Computer-Aided diagnosis (CAD) is a widely used technique to detect and diagnose diseases like tumors, cancers, edemas, etc. Several critical retinal diseases like diabetic retinopathy (DR), hypertensive retinopathy (HR), Macular degeneration, retinitis pigmentosa (RP) are mainly analyzed based on the observation of fundus images. The raw fundus images are of inferior quality to represent the minor changes directly. To detect and analyze minor changes in retinal vasculature or to apply advanced disease detection algorithms, the fundus image should be enhanced enough to visibly present vessel touristy. The performance of deep learning models for diagnosing these critical diseases is highly dependent on accurate segmentation of images. Specifically, for retinal vessels segmentation, accurate segmentation of fundus images is highly challenging due to low vessel contrast, varying widths, branching, and the crossing of vessels. For contrast enhancement, various retinal-vessel segmentation methods apply image-contrast enhancement as a pre-processing step, which can introduce noise in an image and affect vessel detection. Recently, numerous studies applied Contrast Limited Adaptive Histogram Equalization (CLAHE) for contrast enhancement, but with the default values for the contextual region and clip limit. In this study, our aim is to improve the performance of both supervised and unsupervised machine learning models for retinal-vessel segmentation by applying modified particle swarm optimization (MPSO) for CLAHE parameter tuning, with a specific focus on optimizing the clip limit and contextual regions. We subsequently assessed the capabilities of the optimized version of CLAHE using standard evaluation metrics. We used the contrast enhanced images achieved using MPSO-based CLAHE for demonstrating its real impact on performance of deep learning model for semantic segmentation of retinal images. The achieved results proved positive impact on sensitivity of supervised machine learning models, which is highly important. By applying the proposed approach on the enhanced retinal images of the publicly available databases of {DRIVE and STARE}, we achieved a sensitivity, specificity and accuracy of {0.8315 and 0.8433}, {0.9750 and 0.9760} and {0.9620 and 0.9645}, respectively. © 2013 IEEE.",CAD tools; CLAHE; contrast enhancement; deep learning; healthcare; modified PSO; PSO; semantic segmentation
Article,"Du G., Zhan Y., Zhang Y., Guo J., Chen X., Liang J., Zhao H.",Automated segmentation of the gastrocnemius and soleus in shank ultrasound images through deep residual neural network,Biomedical Signal Processing and Control,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85122425396&doi=10.1016%2fj.bspc.2021.103447&partnerID=40&md5=4e02b25ce60e2fd4a1533b9f49b4ddb0,"Segmentation of the shank gastrocnemius (Gas) and soleus (Sol) muscles in ultrasound (US) images allows to extract the muscle features, which are important for the early diagnosis of muscle atrophy. The automatic segmentation of the muscles is a challenging task, and deep learning (DL) provides a solution to this problem, which can effectively extract representative features from the muscle regions and background of the images. In this study, we propose ResTU-net, an automatic segmentation method based on improved U-net network, to segment the Gas and Sol muscles in shank US images. This network uses the deep residual neural network (Resnet) as the sublayer unit of each layer of a U-net, and can effectively combine the features of each layer with those of the next layer to meet the challenges of poor US image quality and low contrast. In addition, dilated convolution is used instead of the pooling layer in the network to prevent information loss during training. Experiments were performed on 3350 shank US images from 23 Sprague Dawley (SD) rats, among them, 2650 shank US images were used for network training and 700 for network validation. Compared with state-of-the-art networks, the experimental results show that the method can achieved the best segmentation capability results and a mean Dice similarity coefficient (DSC) of the Gas and Sol muscles of 94.82% and 90.72%, respectively. This work indicates that the proposed fully automatic segmentation method may be accurately and efficiently applied to Gas and Sol muscles segmentation in shank US images. © 2021 Elsevier Ltd",Deep learning; Deep residual neural network; Dilated convolution; Muscle atrophy; Segmentation
Article,"Ara R.K., Matiolański A., Dziech A., Baran R., Domin P., Wieczorkiewicz A.",Fast and Efficient Method for Optical Coherence Tomography Images Classification Using Deep Learning Approach,Sensors,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85132295127&doi=10.3390%2fs22134675&partnerID=40&md5=43a984e8607c4bc775357261ba77960d,"The use of optical coherence tomography (OCT) in medical diagnostics is now common. The growing amount of data leads us to propose an automated support system for medical staff. The key part of the system is a classification algorithm developed with modern machine learning techniques. The main contribution is to present a new approach for the classification of eye diseases using the convolutional neural network model. The research concerns the classification of patients on the basis of OCT B-scans into one of four categories: Diabetic Macular Edema (DME), Choroidal Neovascularization (CNV), Drusen, and Normal. Those categories are available in a publicly available dataset of above 84,000 images utilized for the research. After several tested architectures, our 5-layer neural network gives us a promising result. We compared them to the other available solutions which proves the high quality of our algorithm. Equally important for the application of the algorithm is the computational time, which is reduced by the limited size of the model. In addition, the article presents a detailed method of image data augmentation and its impact on the classification results. The results of the experiments were also presented for several derived models of convolutional network architectures that were tested during the research. Improving processes in medical treatment is important. The algorithm cannot replace a doctor but, for example, can be a valuable tool for speeding up the process of diagnosis during screening tests. © 2022 by the authors. Licensee MDPI, Basel, Switzerland.",artificial neural networks; biomedical imaging; convolutional neural network; image analysis; oct; optical coherence tomog-raphy
Article,Yin X.,Prediction Algorithm of Young Students' Physical Health Risk Factors Based on Deep Learning,Journal of Healthcare Engineering,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85113972100&doi=10.1155%2f2021%2f9049266&partnerID=40&md5=3eefee1cd65c2759fe71ee53378e7fb8,"Young people's physical and mental health is the foundation of society's overall development and the key to improving people's health quality. Middle school students' physical examinations and monitoring work are a surefire way to ensure their healthy development. Poor vision, dental caries, overweight and obesity, and high blood pressure are the most common adverse health outcomes of students caused by adolescent health risk behavior factors. Researchers have been concerned about the retinal fundus vascular system, which is the only internal vascular system that can be observed in a noninvasive state of the human body. Fundus images contain a wealth of disease-related information. Fundus images have been widely used in the field of medical auxiliary diagnosis because many important systemic diseases of the human body cause specific reactions in the fundus. Aiming to solve the problem of inseparable tiny blood vessels, this paper proposes a model of retinal vessel segmentation based on attention mechanisms. In light of the retinal arteriovenous division of discontinuous challenges, the topological structure of the constraint system along with overcoming the network and topology restrictions is monitored. Finally, simulation experiments were conducted on two publicly available datasets. The findings show that the proposed method is reliable, effective, and accurate in predicting physical health risk factors in adolescent students. © 2021 Xianping Yin.","Behavioral research; Blood; Blood pressure; Blood vessels; Diagnosis; Health risks; Medical imaging; Ophthalmology; Students; Topology; Attention mechanisms; Constraint systems; High blood pressures; Middle school students; Prediction algorithms; Retinal vessel segmentations; Systemic disease; Topological structure; Deep learning; adolescent; adolescent health; adult; aged; algorithm; Article; computer simulation; data analysis software; deep learning; diabetic patient; diabetic retinopathy; eye fundus; feature extraction; health hazard; human; image enhancement; image segmentation; major clinical study; prediction; retina blood vessel; retina image; retina vein; retinal arteriole; risk factor; sensitivity and specificity; student; algorithm; dental caries; image processing; procedures; risk factor; student; Adolescent; Algorithms; Deep Learning; Dental Caries; Humans; Image Processing, Computer-Assisted; Neural Networks, Computer; Risk Factors; Students"
Conference Paper,"Khalid S., Abdulwahab S., Rashwan H.A., Cristiano J., Abdel-Nasser M., Puig D.",Efficient Fundus Image Gradeability Approach Based on Deep Reconstruction-Classification Network,Frontiers in Artificial Intelligence and Applications,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85117938923&doi=10.3233%2fFAIA210160&partnerID=40&md5=06e377daab7f418594f1bcddcc486348,"Quality of retinal image is vital for screening of ailments pertaining to eye such as glaucoma, diabetic retinopathy (DR) and age related macular degeneration. Therefore, assessing quality of retinal image prior to any kind of diagnosis has assumed significance in Computer Aided Desgin (CAD) applications. The rationale behind this is that reliability of retinal image is to be guaranteed to have dependable diagnosis. In this paper, we propose a novel retinal fundus image quality assessment (RIQA) method based on autoencoder network to assess retinal images if the image is acceptable for screening or not. The autoencoder network architecture is well suited to precisely to properly represent the key features of the image quality, especially when the network can correctly reconstruct the input image. The proposed model consists of encoder and decoder successive networks. The encoder will be used for representing the features of the input image. In turn , the decoder will be used for reconstruct the input image. The features get from encoder network will then be fed to a classifier in order to classify the quality of retinal image to two classes: gradable or ungradable. The experimental results revealed more useful assessment and the proposed deep model provides a superior performance for RIQA. Thus, our model can serve real-world Clinical Decision Support Systems in the healthcare domain. © 2021 The authors and IOS Press.",Autoencoder Network; Deep Learning; Ocular Diseases; Quality Assessment; Retinal Image
Article,"Keel S., Wu J., Lee P.Y., Scheetz J., He M.",Visualizing Deep Learning Models for the Detection of Referable Diabetic Retinopathy and Glaucoma,JAMA Ophthalmology,2019,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85059134308&doi=10.1001%2fjamaophthalmol.2018.6035&partnerID=40&md5=8f7c87dce5b94ba385bbb5e16ede7ae2,"Importance: Convolutional neural networks have recently been applied to ophthalmic diseases; however, the rationale for the outputs generated by these systems is inscrutable to clinicians. A visualization tool is needed that would enable clinicians to understand important exposure variables in real time. Objective: To systematically visualize the convolutional neural networks of 2 validated deep learning models for the detection of referable diabetic retinopathy (DR) and glaucomatous optic neuropathy (GON). Design, Setting, and Participants: The GON and referable DR algorithms were previously developed and validated (holdout method) using 48116 and 66790 retinal photographs, respectively, derived from a third-party database (LabelMe) of deidentified photographs from various clinical settings in China. In the present cross-sectional study, a random sample of 100 true-positive photographs and all false-positive cases from each of the GON and DR validation data sets were selected. All data were collected from March to June 2017. The original color fundus images were processed using an adaptive kernel visualization technique. The images were preprocessed by applying a sliding window with a size of 28 × 28 pixels and a stride of 3 pixels to crop images into smaller subimages to produce a feature map. Threshold scales were adjusted to optimal levels for each model to generate heat maps highlighting localized landmarks on the input image. A single optometrist allocated each image to predefined categories based on the generated heat map. Main Outcomes and Measures: Visualization regions of the fundus. Results: In the GON data set, 90 of 100 true-positive cases (90%; 95% CI, 82%-95%) and 15 of 22 false-positive cases (68%; 95% CI, 45%-86%) displayed heat map visualization within regions of the optic nerve head only. Lesions typically seen in cases of referable DR (exudate, hemorrhage, or vessel abnormality) were identified as the most important prognostic regions in 96 of 100 true-positive DR cases (96%; 95% CI, 90%-99%). In 39 of 46 false-positive DR cases (85%; 95% CI, 71%-94%), the heat map displayed visualization of nontraditional fundus regions with or without retinal venules. Conclusions and Relevance: These findings suggest that this visualization method can highlight traditional regions in disease diagnosis, substantiating the validity of the deep learning models investigated. This visualization technique may promote the clinical adoption of these models. © 2018 American Medical Association. All rights reserved.","Article; cross-sectional study; deep learning; diabetic retinopathy; false positive result; glaucomatous optic neuropathy; human; major clinical study; photography; priority journal; retinal nerve fiber layer; algorithm; artificial neural network; diabetic retinopathy; diagnostic imaging; female; glaucoma; male; middle aged; retina blood vessel; visual system examination; Algorithms; Cross-Sectional Studies; Deep Learning; Diabetic Retinopathy; Diagnostic Techniques, Ophthalmological; Female; Glaucoma; Humans; Male; Middle Aged; Neural Networks (Computer); Retinal Vessels"
Article,"Bhatia K.K., Graham M.S., Terry L., Wood A., Tranos P., Trikha S., Jaccard N.","DISEASE CLASSIFICATION OF MACULAR OPTICAL COHERENCE TOMOGRAPHY SCANS USING DEEP LEARNING SOFTWARE: Validation on Independent, Multicenter Data","Retina (Philadelphia, Pa.)",2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85089125670&doi=10.1097%2fIAE.0000000000002640&partnerID=40&md5=ce3a33aebe89f050643f0156a4ed4cb9,"PURPOSE: To evaluate Pegasus optical coherence tomography (OCT), a clinical decision support software for the identification of features of retinal disease from macula OCT scans, across heterogenous populations involving varying patient demographics, device manufacturers, acquisition sites, and operators. METHODS: Five thousand five hundred and eighty-eight normal and anomalous macular OCT volumes (162,721 B-scans), acquired at independent centers in five countries, were processed using the software. Results were evaluated against ground truth provided by the data set owners. RESULTS: Pegasus-OCT performed with areas under the curve of the receiver operating characteristic of at least 98% for all data sets in the detection of general macular anomalies. For scans of sufficient quality, the areas under the curve of the receiver operating characteristic for general age-related macular degeneration and diabetic macular edema detection were found to be at least 99% and 98%, respectively. CONCLUSION: The ability of a clinical decision support system to cater for different populations is key to its adoption. Pegasus-OCT was shown to be able to detect age-related macular degeneration, diabetic macular edema, and general anomalies in OCT volumes acquired across multiple independent sites with high performance. Its use thus offers substantial promise, with the potential to alleviate the burden of growing demand in eye care services caused by retinal disease.","area under the curve; classification; clinical decision making; clinical trial; computer assisted diagnosis; diabetic retinopathy; diagnostic imaging; human; macular degeneration; macular edema; multicenter study; optical coherence tomography; receiver operating characteristic; software; Area Under Curve; Clinical Decision-Making; Deep Learning; Diabetic Retinopathy; Diagnosis, Computer-Assisted; Humans; Macular Degeneration; Macular Edema; ROC Curve; Software; Tomography, Optical Coherence"
Conference Paper,"Joshi P., Masilamani V.",An Efficient Transfer Learning Based Approach for Detecting the Abnormal Fundus Images,"2021 5th Conference on Information and Communication Technology, CICT 2021",2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85125292303&doi=10.1109%2fCICT53865.2020.9672382&partnerID=40&md5=1a9404dd3eb8b3f8d22ad1807908f981,"The vision disabilities are seemingly increasing and prevalent across the world. The current diagnosis require a manual expert for diagnosis. The advancement regarding research in AI for healthcare applications has been focused in recent years. The retinal fundus imaging system is used to capture the retinal images. Those retinal fundus images can be used to detect the vision impairments. Prior research has thoroughly investigated regarding detecting the particular type of disease such as diabetic retinopathy, cataract, glaucoma etc. However, only a little research has been conducted to classify a given retinal image into normal and abnormal fundus image. In this paper, a novel transfer learning based method to detect the abnormal fundus image has been proposed. The EfficientNetV2 has been used as classification model, which aids in classifying the normal and abnormal fundus images. To our knowledge, the EfficientNetV2 has not been used as a transfer learning model before. The proposed model has been evaluated against the recent state-of-The-Art models including transformers and multi layer perceptron(MLP) based models which have been found to be working well on the image classification task. It has been observed that convolutional neural networks are still performing better than the recent transformer based models and MLP based models for detecting abnormal fundus images. The proposed model has achieved 95 % accuracy on the dataset received from a hospital. © 2021 IEEE.",Deep Learning; EfficientNetV2; Retinal Fundus Images; Transfer Learning
Article,"Escorcia-Gutierrez J., Torrents-Barrena J., Gamarra M., Romero-Aroca P., Valls A., Puig D.",Convexity shape constraints for retinal blood vessel segmentation and foveal avascular zone detection,Computers in Biology and Medicine,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85095432247&doi=10.1016%2fj.compbiomed.2020.104049&partnerID=40&md5=bcf545bd40c19b2c4428582f79e696f1,"Diabetic retinopathy (DR) has become a major worldwide health problem due to the increase in blindness among diabetics at early ages. The detection of DR pathologies such as microaneurysms, hemorrhages and exudates through advanced computational techniques is of utmost importance in patient health care. New computer vision techniques are needed to improve upon traditional screening of color fundus images. The segmentation of the entire anatomical structure of the retina is a crucial phase in detecting these pathologies. This work proposes a novel framework for fast and fully automatic blood vessel segmentation and fovea detection. The preprocessing method involved both contrast limited adaptive histogram equalization and the brightness preserving dynamic fuzzy histogram equalization algorithms to enhance image contrast and eliminate noise artifacts. Afterwards, the color spaces and their intrinsic components were examined to identify the most suitable color model to reveal the foreground pixels against the entire background. Several samples were then collected and used by the renowned convexity shape prior segmentation algorithm. The proposed methodology achieved an average vasculature segmentation accuracy exceeding 96%, 95%, 98% and 94% for the DRIVE, STARE, HRF and Messidor publicly available datasets, respectively. An additional validation step reached an average accuracy of 94.30% using an in-house dataset provided by the Hospital Sant Joan of Reus (Spain). Moreover, an outstanding detection accuracy of over 98% was achieved for the foveal avascular zone. An extensive state-of-the-art comparison was also conducted. The proposed approach can thus be integrated into daily clinical practice to assist medical experts in the diagnosis of DR. © 2020",Blood vessel segmentation; Convexity shape prior; Diabetic retinopathy; Foveal avascular zone detection
Article,"Ju L., Wang X., Zhao X., Bonnington P., Drummond T., Ge Z.",Leveraging Regular Fundus Images for Training UWF Fundus Diagnosis Models via Adversarial Learning and Pseudo-Labeling,IEEE Transactions on Medical Imaging,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85100804767&doi=10.1109%2fTMI.2021.3056395&partnerID=40&md5=9c8b249cd1b3da7e6e84c16d69180ee2,"Recently, ultra-widefield (UWF) 200° fundus imaging by Optos cameras has gradually been introduced because of its broader insights for detecting more information on the fundus than regular 30° - 60° fundus cameras. Compared with UWF fundus images, regular fundus images contain a large amount of high-quality and well-annotated data. Due to the domain gap, models trained by regular fundus images to recognize UWF fundus images perform poorly. Hence, given that annotating medical data is labor intensive and time consuming, in this paper, we explore how to leverage regular fundus images to improve the limited UWF fundus data and annotations for more efficient training. We propose the use of a modified cycle generative adversarial network (CycleGAN) model to bridge the gap between regular and UWF fundus and generate additional UWF fundus images for training. A consistency regularization term is proposed in the loss of the GAN to improve and regulate the quality of the generated data. Our method does not require that images from the two domains be paired or even that the semantic labels be the same, which provides great convenience for data collection. Furthermore, we show that our method is robust to noise and errors introduced by the generated unlabeled data with the pseudo-labeling technique. We evaluated the effectiveness of our methods on several common fundus diseases and tasks, such as diabetic retinopathy (DR) classification, lesion detection and tessellated fundus segmentation. The experimental results demonstrate that our proposed method simultaneously achieves superior generalizability of the learned representations and performance improvements in multiple tasks. © 1982-2012 IEEE.",adversarial learning; Annotation-efficient deep learning; domain adaptation; ultra-widefield fundus images
Article,"Lin G., Bai H., Zhao J., Yun Z., Chen Y., Pang S., Feng Q.",Improving sensitivity and connectivity of retinal vessel segmentation via error discrimination network,Medical Physics,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85130494128&doi=10.1002%2fmp.15627&partnerID=40&md5=60eac1bb1a89c9079e44c547bf3195ba,"Purpose: Automated retinal vessel segmentation is crucial to the early diagnosis and treatment of ophthalmological diseases. Many deep-learning-based methods have shown exceptional success in this task. However, current approaches are still inadequate in challenging vessels (e.g., thin vessels) and rarely focus on the connectivity of vessel segmentation. Methods: We propose using an error discrimination network (D) to distinguish whether the vessel pixel predictions of the segmentation network (S) are correct, and S is trained to obtain fewer error predictions of D. Our method is similar to, but not the same as, the generative adversarial network. Three types of vessel samples and corresponding error masks are used to train D, as follows: (1) vessel ground truth; (2) vessel segmented by S; (3) artificial thin vessel error samples that further improve the sensitivity of D to wrong small vessels. As an auxiliary loss function of S, D strengthens the supervision of difficult vessels. Optionally, we can use the errors predicted by D to correct the segmentation result of S. Results: Compared with state-of-the-art methods, our method achieves the highest scores in sensitivity (86.19%, 86.26%, and 86.53%) and G-Mean (91.94%, 91.30%, and 92.76%) on three public datasets, namely, STARE, DRIVE, and HRF. Our method also maintains a competitive level in other metrics. On the STARE dataset, the F1-score and area under the receiver operating characteristic curve (AUC) of our method rank second and first, respectively, reaching 84.51% and 98.97%. The top scores of the three topology-relevant metrics (Conn, Inf, and Cor) demonstrate that the vessels extracted by our method have excellent connectivity. We also validate the effectiveness of error discrimination supervision and artificial error sample training through ablation experiments. Conclusions: The proposed method provides an accurate and robust solution for difficult vessel segmentation. © 2022 American Association of Physicists in Medicine.",error discrimination; retinal vessel segmentation; vessel connectivity; vessel sensitivity
Article,"Zago G.T., Andreão R.V., Dorizzi B., Teatini Salles E.O.",Retinal image quality assessment using deep learning,Computers in Biology and Medicine,2018,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85054801284&doi=10.1016%2fj.compbiomed.2018.10.004&partnerID=40&md5=2096d9a9c73a8951db5b2bbfa0d21c69,"Poor-quality retinal images do not allow an accurate medical diagnosis, and it is inconvenient for a patient to return to a medical center to repeat the fundus photography exam. In this paper, a robust automatic system is proposed to assess the quality of retinal images at the moment of the acquisition, aiming at assisting health care professionals during a fundus photography exam. We propose a convolutional neural network (CNN) pretrained on non-medical images for extracting general image features. The weights of the CNN are further adjusted via a fine-tuning procedure, resulting in a performant classifier obtained only with a small quantity of labeled images. The CNN performance was evaluated on two publicly available databases (i.e., DRIMDB and ELSA-Brasil) using two different procedures: intra-database and inter-database cross-validation. The CNN achieved an area under the curve (AUC) of 99.98% on DRIMDB and an AUC of 98.56% on ELSA-Brasil in the inter-database experiment, where training and testing were not performed on the same database. These results show the robustness of the proposed model to various image acquisitions without requiring special adaptation, thus making it a good candidate for use in operational clinical scenarios. © 2018 Elsevier Ltd",Convolutional neural networks; Deep learning; Diabetic retinopathy; Image quality; Retinal images
Article,"Balasubramanian K., Ananthamoorthy N.P.",Ann classification and modified otsu labeling on retinal blood vessels,Current Signal Transduction Therapy,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85105882974&doi=10.2174%2f1574362414666191018104225&partnerID=40&md5=96c9665293842846d56cf60c5fb45c22,"Background: Diagnosis of ophthalmologic and cardiovascular systems most often rely on the prerequisite step of segmentation of retinal blood vessels. Analysis of vascular structures in the retinal fundus images can aid in the early screening or detection of many ophthalmological diseases like glaucoma, diabetic retinopathy, vein occlusions, hemorrhages etc. In most cases, optic nerve gets damaged causing a blind spot. In this paper, a method of blood vessel segmentation using improved SOM (iSOM) and ANN classifier is presented. Methods: Morphological operations are carried out to enhance the input image. Clustering of pix-els is done using improved Kohonen Self-Organizing Map (SOM) based on texture feature where-in a new node is introduced and new learning methodology is adopted using constrained weight updation. Finally, modified Otsu method is designed to label the output neuron class as vessel and non-vessel. Results: Segmentation is tested on public image sets, High Resolution Fundus (HRF) images and DRIONS-DB databases for Accuracy, Recall rate, Precision, F-Score, AUC and JC. The results achieve an appreciable level of accuracy (~97%) as compared to other similar methods of classifi-cation. The average time taken is less in estimating the neuron class and is about 12.1 sec per image when evaluated on Intel Core i5 CPU running at 2.30 GHz coupled with 4 GB RAM. The mean squared error for the segmented images is found to be in the range of 4-5%. Conclusion: Segmentation of retinal blood vessels based on artificial neural networks employing iSOM preserves the topology consuming less time for constrained weight updation achieving bet-ter results than SOM. A new model to detect vessels can be developed by concatenating iSOMs in parallel for multi class functions. © 2021 Bentham Science Publishers.",Fundus images; Morphological processing; Neural network; Otsu’s method; SOM; Vessel segmentation
Article,"Biswas R., Vasan A., Roy S.S.",Dilated Deep Neural Network for Segmentation of Retinal Blood Vessels in Fundus Images,Iranian Journal of Science and Technology - Transactions of Electrical Engineering,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85079702297&doi=10.1007%2fs40998-019-00213-7&partnerID=40&md5=07aff0913a6fbf30bcfd0d5e254d2a05,"Medical diagnosis is being assisted by numerous expert systems that have been developed to increase the accuracy of such diagnoses. The development of image processing techniques along with the rapid development in areas like machine learning and computer vision help in creating such expert systems that almost nearly match the accuracy of the expert human eye. The medical condition of diabetic retinopathy is diagnosed by analyzing the retinal blood vessels for damages, abnormal new growths and ruptures. Various techniques using convolutional neural networks have been used to segment retinal blood vessels from fundus images, but these techniques often do not segment the retinal blood vessels accurately and add additional noise due to the limited receptive field of the convolutional filters. The limited receptive field of the convolutional layer prevents the convolutional neural network from getting an accurate context of objects that extend beyond the size of the filter. The proposed architecture uses a dilated convolutional filter to obtain a larger receptive field which leads to a greater accuracy in segmenting the retinal blood vessels with near human accuracy. The convolutional neural networks were trained using the popular datasets. The proposed architecture produced an area under ROC curve (AUC) of 0.9794 and an accuracy of 95.61% and required very few iterations to train the network. © 2019, Shiraz University.",Blood vessel segmentation; Deep neural network; Dilated convolution; Medical imaging
Article,"Qayyum A., Sultani W., Shamshad F., Tufail R., Qadir J.",Single-shot retinal image enhancement using untrained and pretrained neural networks priors integrated with analytical image priors,Computers in Biology and Medicine,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85134433223&doi=10.1016%2fj.compbiomed.2022.105879&partnerID=40&md5=667646ba642497fa1f411935cfaaf7cf,"Retinal images acquired using fundus cameras are often visually blurred due to imperfect imaging conditions, refractive medium turbidity, and motion blur. In addition, ocular diseases such as the presence of cataracts also result in blurred retinal images. The presence of blur in retinal fundus images reduces the effectiveness of the diagnosis process of an expert ophthalmologist or a computer-aided detection/diagnosis system. In this paper, we put forward a single-shot deep image prior (DIP)-based approach for retinal image enhancement. Unlike typical deep learning-based approaches, our method does not require any training data. Instead, our DIP-based method can learn the underlying image prior while using a single degraded image. To perform retinal image enhancement, we frame it as a layer decomposition problem and investigate the use of two well-known analytical priors, i.e., dark channel prior (DCP) and bright channel prior (BCP) for atmospheric light estimation. We show that both the untrained neural networks and the pretrained neural networks can be used to generate an enhanced image while using only a single degraded image. The proposed approach is time and memory-efficient, which makes the solution feasible for real-world resource-constrained environments. We evaluate our proposed framework quantitatively on five datasets using three widely used metrics and complement that with a subjective qualitative assessment of the enhancement by two expert ophthalmologists. For instance, our method has achieved significant performance for untrained CDIPs coupled with DCP in terms of average PSNR, SSIM, and BRISQUE values of 40.41, 0.97, and 34.2, respectively, and for untrained CDIPs coupled with BCP, it achieved average PSNR, SSIM, and BRISQUE values of 40.22, 0.98, and 36.38, respectively. Our extensive experimental comparison with several competitive baselines on public and non-public proprietary datasets validates the proposed ideas and framework. © 2022 Elsevier Ltd",Retinal image enhancement; Retinal image generation; Single image analysis; Untrained neural network priors
Article,"Cavichini M., An C., Bartsch D.-U.G., Jhingan M., Amador-Patarroyo M.J., Long C.P., Zhang J., Wang Y., Chan A.X., Madala S., Nguyen T., Freeman W.R.",Artificial intelligence for automated overlay of fundus camera and scanning laser ophthalmoscope images,Translational Vision Science and Technology,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097425117&doi=10.1167%2ftvst.9.2.56&partnerID=40&md5=5282d25b7bc073d7e6607017c40699d5,Purpose: The purpose of this study was to evaluate the ability to align two types of retinal images taken on different platforms; color fundus (CF) photographs and infrared scanning laser ophthalmoscope (IR SLO) images using mathematical warping and artificial intelligence (AI). Methods: We collected 109 matched pairs of CF and IR SLO images. An AI algorithm utilizing two separate networks was developed. A style transfer network (STN) was used to segment vessel structures. A registration network was used to align the segmented images to each. Neither network used a ground truth dataset. A conventional image warping algorithm was used as a control. Software displayed image pairs as a 5 × 5 checkerboard grid composed of alternating subimages. This technique permitted vessel alignment determination by human observers and 5 masked graders evaluated alignment by the AI and conventional warping in 25 fields for each image. Results: Our new AI method was superior to conventional warping at generating vessel alignment as judged by masked human graders (P < 0.0001). The average number of good/excellent matches increased from 90.5% to 94.4% with AI method. Conclusions: AI permitted a more accurate overlay of CF and IR SLO images than conventional mathematical warping. This is a first step toward developing an AI that could allow overlay of all types of fundus images by utilizing vascular landmarks. Translational Relevance: The ability to align and overlay imaging data from multiple instruments and manufacturers will permit better analysis of this complex data helping understand disease and predict treatment. © 2020 The Authors.,"Artificial intelligence; Diagnosis; Multimodal images; Retina, imaging"
Article,"Luo Y., Chen K., Liu L., Liu J., Mao J., Ke G., Sun M.",Dehaze of Cataractous Retinal Images Using an Unpaired Generative Adversarial Network,IEEE Journal of Biomedical and Health Informatics,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097571046&doi=10.1109%2fJBHI.2020.2999077&partnerID=40&md5=81b8cbfe79837666bee4eda528ab7550,"Cataracts are the leading cause of visual impairment worldwide. Examination of the retina through cataracts using a fundus camera is challenging and error-prone due to degraded image quality. We sought to develop an algorithm to dehaze such images to support diagnosis by either ophthalmologists or computer-aided diagnosis systems. Based on the generative adversarial network (GAN) concept, we designed two neural networks: CataractSimGAN and CataractDehazeNet. CataractSimGAN was intended for the synthesis of cataract-like images through unpaired clear retinal images and cataract images. CataractDehazeNet was trained using pairs of synthesized cataract-like images and the corresponding clear images through supervised learning. With two networks trained independently, the number of hyper-parameters was reduced, leading to better performance. We collected 400 retinal images without cataracts and 400 hazy images from cataract patients as the training dataset. Fifty cataract images and the corresponding clear images from the same patients after surgery comprised the test dataset. The clear images after surgery were used for reference to evaluate the performance of our method. CataractDehazeNet was able to enhance the degraded image from cataract patients substantially and to visualize blood vessels and the optic disc, while actively suppressing the artifacts common in application of similar methods. Thus, we developed an algorithm to improve the quality of the retinal images acquired from cataract patients. We achieved high structure similarity and fidelity between processed images and images from the same patients after cataract surgery. © 2013 IEEE.",Cataract; dehaze; retinal image; unpaired generative adversarial network
Article,"Gao Z., Chen L.",Research on Semantic Segmentation Method of Macular Edema in Retinal OCT Images Based on Improved Swin-Unet,Electronics (Switzerland),2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85136799018&doi=10.3390%2felectronics11152294&partnerID=40&md5=9b6ed3df57073c2bed9a08cd1a5480f3,"Optical coherence tomography (OCT), as a new type of tomography technology, has the characteristics of non-invasive, real-time imaging and high sensitivity, and is currently an important medical imaging tool to assist ophthalmologists in the screening, diagnosis, and follow-up treatment of patients with macular disease. In order to solve the problem of irregular occurrence area of diabetic retinopathy macular edema (DME), multi-scale and multi-region cluster of macular edema, which leads to inaccurate segmentation of the edema area, an improved Swin-Unet networks model was proposed for automatic semantic segmentation of macular edema lesion areas in OCT images. Firstly, in the deep bottleneck of the Swin-Unet network, the Resnet network layer was used to increase the extraction of pairs of sub-feature images. Secondly, the Swin Transformer block and skip connection structure were used for global and local learning, and the regions after semantic segmentation were morphologically smoothed and post-processed. Finally, the proposed method was performed on the macular edema patient dataset publicly available at Duke University, and was compared with previous segmentation methods. The experimental results show that the proposed method can not only improve the overall semantic segmentation accuracy of retinal macular edema, but also further to improve the semantic segmentation effect of multi-scale and multi-region edema regions. © 2022 by the authors.",macular edema; OCT; Resnet; Swin-Unet
Article,"Qiu D., Cheng Y., Wang X.",Improved generative adversarial network for retinal image super-resolution,Computer Methods and Programs in Biomedicine,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85135864324&doi=10.1016%2fj.cmpb.2022.106995&partnerID=40&md5=547eeb45dde2272ce23532a4361e84c6,"Background and objective: The retina is the only organ in the body that can use visible light for non-invasive observation. By analyzing retinal images, we can achieve early screening, diagnosis and prevention of many ophthalmological and systemic diseases, helping patients avoid the risk of blindness. Due to the powerful feature extraction capabilities, many deep learning super-resolution reconstruction networks have been applied to retinal image analysis and achieved excellent results. Methods: Given the lack of high-frequency information and poor visual perception in the current reconstruction results of super-resolution reconstruction networks under large-scale factors, we present an improved generative adversarial network (IGAN) algorithm for retinal image super-resolution reconstruction. Firstly, we construct a novel residual attention block, improving the reconstruction results lacking high-frequency information and texture details under large-scale factors. Secondly, we remove the Batch Normalization layer that affects the quality of image generation in the residual network. Finally, we use the more robust Charbonnier loss function instead of the mean square error loss function and the TV regular term to smooth the training results. Results: Experimental results show that our proposed method significantly improves objective evaluation indicators such as peak signal-to-noise ratio and structural similarity. The obtained image has rich texture details and a better visual experience than the state-of-the-art image super-resolution methods. Conclusion: Our proposed method can better learn the mapping relationship between low-resolution and high-resolution retinal images. This method can be effectively and stably applied to the analysis of retinal images, providing an effective basis for early clinical treatment. © 2022 Elsevier B.V.",Convolutional neural network; Generative adversarial network; Residual learning; Retinal image; Super-resolution
Article,"Rehman A., Harouni M., Karimi M., Saba T., Bahaj S.A., Awan M.J.",Microscopic retinal blood vessels detection and segmentation using support vector machine and K-nearest neighbors,Microscopy Research and Technique,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85122739441&doi=10.1002%2fjemt.24051&partnerID=40&md5=c5753150aecf6b5d87548eae53aaafb1,"The retina is the deepest layer of texture covering the rear of the eye, recorded by fundus images. Vessel detection and segmentation are useful in disease diagnosis. The retina's blood vessels could help diagnose maladies such as glaucoma, diabetic retinopathy, and blood pressure. A mix of supervised and unsupervised strategies exists for the detection and segmentation of blood vessels images. The tree structure of retinal blood vessels, their random area, and different thickness have caused vessel detection difficulties at machine learning calculations. Since the green band of retinal images conveys more information about the vessels, they are utilized for microscopic vessels detection. The current research proposes an administered calculation for segmentation of retinal vessels, where two upgrading stages depending on filtering and comparative histogram were applied after pre-processing and image quality improvement. At that point, statistical features of vessel tracking, maximum curvature and curvelet coefficient are extracted for each pixel. The extracted features are classified by support vector machine and the k-nearest neighbors. The morphological operators then enhance the classified image at the final stage to segment with higher accuracy. The dice coefficient is utilized for the evaluation of the proposed method. The proposed approach is concluded to be better than different strategies with a normal of 92%. © 2022 Wiley Periodicals LLC.",blood vessels; healthcare; human and disease; microscopic retina; public health; segmentation; tracking
Article,"Zhao M., Lu Z., Zhu S., Wang X., Feng J.",Automatic generation of retinal optical coherence tomography images based on generative adversarial networks,Medical Physics,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85139686773&doi=10.1002%2fmp.15988&partnerID=40&md5=adfbfddc15ab215cc4dd6d931654d7c0,"Significance: The automatic generation algorithm of optical coherence tomography (OCT) images based on generative adversarial networks (GAN) can generate a large number of simulation images by a relatively small number of real images, which can effectively improve the classification performance. Aim: We proposed an automatic generation algorithm for retinal OCT images based on GAN to alleviate the problem of insufficient images with high quality in deep learning, and put the diagnosis algorithm toward clinical application. Approach: We designed a generation network based on GAN and trained the network with a data set constructed by 2014_BOE_Srinivasan and OCT2017 to acquire three models. Then, we generated a large number of images by the three models to augment age-related macular degeneration (AMD), diabetic macular edema (DME), and normal images. We evaluated the generated images by subjective visual observation, Fréchet inception distance (FID) scores, and a classification experiment. Results: Visual observation shows that the generated images have clear and similar features compared with the real images. Also, the lesion regions containing similar features in the real image and the generated image are randomly distributed in the image field of view. When the FID scores of the three types of generated images are lowest, three local optimal models are obtained for AMD, DME, and normal images, indicating the generated images have high quality and diversity. Moreover, the classification experiment results show that the model performance trained with the mixed images is better than that of the model trained with real images, in which the accuracy, sensitivity, and specificity are improved by 5.56%, 8.89%, and 2.22%. In addition, compared with the generation method based on variational auto-encoder (VAE), the method improved the accuracy, sensitivity, and specificity by 1.97%, 2.97%, and 0.99%, for the same test set. Conclusions: The results show that our method can augment the three kinds of OCT images, not only effectively alleviating the problem of insufficient images with high quality but also improving the diagnosis performance. © 2022 American Association of Physicists in Medicine.",age-related macular degeneration; diabetic macular edema; generative adversarial networks; image generation; retinal optical coherence tomography images
Article,"Vedanarayanan V., Aranganathan A., Gomathi T., Poonguzhali S., Megalan Leo L.",Blood Vessel Segmentation on Retinal Images Using Robust Random Walks (RRW) and Cardiovascular Disease Classification Using Deep Learning,Journal of Cardiovascular Disease Research,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85098950293&doi=10.31838%2fjcdr.2020.11.04.07&partnerID=40&md5=56be74ffc9c4cb93d854968acec699b9,"In the recent past, retinal image processing has become a popular biomedical modern computer aided diagnosis (CAD) system development technology for the detection and identification of eye related disease such as diabetic retinopathy, exudates, cardiovascular disease, glaucoma, etc. In present ophthalmology, the arrangement of retinal image with appropriate disease segmentation has attained greater attention for disease identification. Examining diameters of blood vessel inside vessels of retinal image during cardiac cycle (ECG gating) can assist cardiologists in the forecast of cardiovascular disease. Manual process of blood vessels on retinal image is a complex process due to risk handling of physician, noise occurrence on image and various types of acquisition execution. In this paper, we have proposed automatic diagnosis of cardiovascular disease using improved image processing methodologies using various CAD algorithms. The preprocessing steps are useful to improve the retinal image quality. The 2-Dimentional Adaptive Improved Bilateral Filter (2D-AIBF) is applied to remove noise interference on retinal image such as speckle noise, impulse noise and Gaussian noise. The contrast and brightness of retinal image is improved by applying Edge Preservation – Contrast Limited Adaptive Histogram Equalization (EP-CLAHE) algorithm. The blood vessel pixels are clustered by applying Arbitrary Robust Random Walks (ARRW) cluster algorithm. The Adaptive Otsu Threshold (AO) methodology is used to segment only Region Of Interest (ROI) blood vessels pixels and suppress other pixels. The Gray Level Co-Occurrence Matrix (GLCM) algorithm is used to extract the features on segmented image. The Deep Learning (DL) methodology is used to classify cardiovascular disease occurred or not. The Deep Convolutional Neural Network (CNN) is the type of DL technique that is applied for classification of cardiovascular disease. The experimental results are evaluated by comparing other conventional methods of retinal blood vessel segmentation with respect to accuracy, sensitivity and specificity using Confusion Matrix (CM) algorithm and the proposed methodology is proved to be more efficient and accurate in classification of cardiovascular disease classification. © 2020 EManuscript Technologies. All rights reserved.",2D-AIBF; AO; ARRW; DCNN; EP-CLAHE; GLCM
Article,"Feng S., Zhao H., Shi F., Cheng X., Wang M., Ma Y., Xiang D., Zhu W., Chen X.",Cpfnet: Context pyramid fusion network for medical image segmentation,IEEE Transactions on Medical Imaging,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85092680590&doi=10.1109%2fTMI.2020.2983721&partnerID=40&md5=e6221c4e2f7e67a4e2e236ab268e821f,"Accurate and automatic segmentation of medical images is a crucial step for clinical diagnosis and analysis. The convolutional neural network (CNN) approaches based on the U-shape structure have achieved remarkable performances in many different medical image segmentation tasks. However, the context information extraction capability of single stage is insufficient in this structure, due to the problems such as imbalanced class and blurredboundary. In thispaper,we proposea novel Context Pyramid FusionNetwork (named CPFNet) by combining two pyramidal modules to fuse global/multi-scale context information.Based on the U-shape structure,we first design multiple global pyramid guidance (GPG) modules between the encoder and the decoder, aiming at providing different levels of global context information for the decoder by reconstructing skip-connection.We further design a scaleaware pyramid fusion (SAPF) module to dynamically fuse multi-scale context information in high-level features. These two pyramidal modules can exploit and fuse rich context information progressively. Experimental results show that our proposed method is very competitive with other state-of-the-artmethods on four different challenging tasks, including skin lesionsegmentation, retinal linear lesion segmentation, multi-class segmentation of thoracic organs at risk and multi-class segmentation of retinal edema lesions. © 2020 Institute of Electrical and Electronics Engineers Inc.. All rights reserved.",Context pyramid fusion network; Convolutional neural network; Global pyramid guidance module; Medical image segmentation; Scale-aware pyramid fusion module
Conference Paper,"Gholami P., Sheikh Hassani M., Kuppuswamy Parthasarathy M., Zelek J.S., Lakshminarayanan V.",Classification of optical coherence tomography images for diagnosing different ocular diseases,Progress in Biomedical Optics and Imaging - Proceedings of SPIE,2018,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85046705682&doi=10.1117%2f12.2292520&partnerID=40&md5=ef0ae0e02f786a0610b0e54c2905a0d2,"Optical Coherence tomography (OCT) images provide several indicators, e.g., the shape and the thickness of different retinal layers, which can be used for various clinical and non-clinical purposes. We propose an automated classification method to identify different ocular diseases, based on the local binary pattern features. The database consists of normal and diseased human eye SD-OCT images. We use a multiphase approach for building our classifier, including preprocessing, Meta learning, and active learning. Pre-processing is applied to the data to handle missing features from images and replace them with the mean or median of the corresponding feature. All the features are run through a Correlation-based Feature Subset Selection algorithm to detect the most informative features and omit the less informative ones. A Meta learning approach is applied to the data, in which a SVM and random forest are combined to obtain a more robust classifier. Active learning is also applied to strengthen our classifier around the decision boundary. The primary experimental results indicate that our method is able to differentiate between the normal and non-normal retina with an area under the ROC curve (AUC) of 98.6% and also to diagnose the three common retina-related diseases, i.e., Age-related Macular Degeneration, Diabetic Retinopathy, and Macular Hole, with an AUC of 100%, 95% and 83.8% respectively. These results indicate a better performance of the proposed method compared to most of the previous works in the literature. © 2018 SPIE.",active learning; image classification; local binary pattern; Meta learning; ophthalmology; Optical Coherence Tomography; random forests; retina; support vector machine
Article,"Mahmood M.T., Lee I.H.",Optic disc localization in fundus images through accumulated directional and radial blur analysis,Computerized Medical Imaging and Graphics,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85127530301&doi=10.1016%2fj.compmedimag.2022.102058&partnerID=40&md5=1a2391e621f1b8931a1f591baf4507ae,"Optic disc localization, a key preprocessing step in the analysis of color fundus images for diagnoses of eye diseases and the localization of various anatomical structures, is particularly challenging when input retina images contain abnormalities. In such cases, the disc can be confused with other anatomical structures such as fovea, exudates, vessel tree extraction, and retinopathy-related lesions. Herein, we present a method for effective optic disc detection and localization based on color and blur analysis. In this method, the input color fundus image is converted to CIE L*a*b* color space to enhance optic disc appearance and contrast, and the accumulated directional blur and extended-maxima transform are then applied to precisely extract optic disc candidates. Subsequently, radial blur is applied to each candidate to obtain better profiles and thus distinguish the optic disc from other candidates. Finally, the full width at 80% maximum (FW80M) metric is used to select the optic disc. The performance of the proposed method is evaluated using well-studied data sets, and comparison of the obtained results with those of state-of-the-art techniques reveals the effectiveness of our method and shows that it can precisely locate the disc position not only in normal cases but also in the presence of exudates and abnormalities. © 2022 Elsevier Ltd",Accumulated directional blur; Optic disc detection; Optic disc localization; Radial blur
Article,"Zhu S., Lu B., Wang C., Wu M., Zheng B., Jiang Q., Wei R., Cao Q., Yang W.",Screening of Common Retinal Diseases Using Six-Category Models Based on EfficientNet,Frontiers in Medicine,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85126241776&doi=10.3389%2ffmed.2022.808402&partnerID=40&md5=cabb61b2732bf03630e2a0c3cde0a8fd,"Purpose: A six-category model of common retinal diseases is proposed to help primary medical institutions in the preliminary screening of the five common retinal diseases. Methods: A total of 2,400 fundus images of normal and five common retinal diseases were provided by a cooperative hospital. Two six-category deep learning models of common retinal diseases based on the EfficientNet-B4 and ResNet50 models were trained. The results from the six-category models in this study and the results from a five-category model in our previous study based on ResNet50 were compared. A total of 1,315 fundus images were used to test the models, the clinical diagnosis results and the diagnosis results of the two six-category models were compared. The main evaluation indicators were sensitivity, specificity, F1-score, area under the curve (AUC), 95% confidence interval, kappa and accuracy, and the receiver operator characteristic curves of the two six-category models were compared in the study. Results: The diagnostic accuracy rate of EfficientNet-B4 model was 95.59%, the kappa value was 94.61%, and there was high diagnostic consistency. The AUC of the normal diagnosis and the five retinal diseases were all above 0.95. The sensitivity, specificity, and F1-score for the diagnosis of normal fundus images were 100, 99.9, and 99.83%, respectively. The specificity and F1-score for RVO diagnosis were 95.68, 98.61, and 93.09%, respectively. The sensitivity, specificity, and F1-score for high myopia diagnosis were 96.1, 99.6, and 97.37%, respectively. The sensitivity, specificity, and F1-score for glaucoma diagnosis were 97.62, 99.07, and 94.62%, respectively. The sensitivity, specificity, and F1-score for DR diagnosis were 90.76, 99.16, and 93.3%, respectively. The sensitivity, specificity, and F1-score for MD diagnosis were 92.27, 98.5, and 91.51%, respectively. Conclusion: The EfficientNet-B4 model was used to design a six-category model of common retinal diseases. It can be used to diagnose the normal fundus and five common retinal diseases based on fundus images. It can help primary doctors in the screening for common retinal diseases, and give suitable suggestions and recommendations. Timely referral can improve the efficiency of diagnosis of eye diseases in rural areas and avoid delaying treatment. Copyright © 2022 Zhu, Lu, Wang, Wu, Zheng, Jiang, Wei, Cao and Yang.",computer simulation; fundus; optical imaging; retinal diseases; vision screening
Article,"Groza A., Toderean L., Muntean G.A., Nicoara S.D.",Agents that Argue and Explain Classifications of Retinal Conditions,Journal of Medical and Biological Engineering,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85114317218&doi=10.1007%2fs40846-021-00647-7&partnerID=40&md5=85cf0f060f642bb939e6faced54d0719,"Purpose: Expertise for auditing AI systems in medical domain is only now being accumulated. Conformity assessment procedures will require AI systems: (1) to be transparent, (2) not to rely decisions solely on algorithms, or (3) to include safety assurance cases in the documentation to facilitate technical audit. We are interested here in obtaining transparency in the case of machine learning (ML) applied to classification of retina conditions. High performance metrics achieved using ML has become common practice. However, in the medical domain, algorithmic decisions need to be sustained by explanations. We aim at building a support tool for ophthalmologists able to: (i) explain algorithmic decision to the human agent by automatically extracting rules from the ML learned models; (ii) include the ophthalmologist in the loop by formalising expert rules and including the expert knowledge in the argumentation machinery; (iii) build safety cases by creating assurance argument patterns for each diagnosis. Methods: For the learning task, we used a dataset consisting of 699 OCT images: 126 Normal class, 210 with Diabetic Retinopathy (DR) and 363 with Age Related Macular Degeneration (AMD). The dataset contains patients from the Ophthalmology Department of the County Emergency Hospital of Cluj-Napoca. All ethical norms and procedures, including anonymisation, have been performed. We applied three machine learning algorithms: decision tree (DT), support vector machine (SVM) and artificial neural network (ANN). For each algorithm we automatically extract diagnosis rules. For formalising expert knowledge, we relied on the normative dataset (Invernizzi et al. in Ophthalmol Retina 2(8):808–815, 2018). For arguing between agents, we used the Jason multi-agent platform. We assume different knowledge base and reasoning capabilities for each agent. The agents have their own optical coherence tomography (OCT) images on which they apply a distinct machine learning algorithm. The learned model is used to extract diagnosis rules. With distinct learned rules, the agents engage in an argumentative process. The resolution of the debate outputs a diagnosis that is then explained to the ophthalmologist, by means of assurance cases. Results: For diagnosing the retina condition, our AI solution deals with the following three issues: first, the learned models are automatically translated into rules. These rules are then used to build an explanation by tracing the reasoning chain supporting the diagnosis. Hence, the proposed AI solution complies with the requirement that “algorithmic decision should be explained to the human agent”. Second, the decision is not solely based on ML-algorithms. The proposed architecture includes expert knowledge. The diagnosis is taken based on exchanging arguments between ML-based algorithms and expert knowledge. The conflict resolution among arguments is verbalised, so that the ophthalmologist can supervise the diagnosis. Third, the assurance cases are generated to facilitate technical audit. The assurance cases structure the evidence among various safety goals such as: machine learning methodology, transparency, or data quality. For each dimension, the auditor can check the provided evidence against the current best practices or safety standards. Conclusion: We developed a multi-agent system for retina conditions in which algorithmic decisions are sustained by explanations. The proposed tool goes behind most software in medical domain that focuses only on performance metrics. Our approach helps the technical auditor to approve software in the medical domain. Interleaving knowledge extracted from ML-models with expert knowledge is a step towards balancing the benefits of ML with explainability, aiming at engineering reliable medical applications. © 2021, Taiwanese Society of Biomedical Engineering.",AgentSpeak; Argumentative agents; Explainable artificial intelligence; Machine learning; Retina conditions
Conference Paper,"Cai S., Parker F., Urias M.G., Goldberg M.F., Hager G.D., Scott A.W.",Deep Learning Detection of Sea Fan Neovascularization from Ultra-Widefield Color Fundus Photographs of Patients with Sickle Cell Hemoglobinopathy,JAMA Ophthalmology,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85098662899&doi=10.1001%2fjamaophthalmol.2020.5900&partnerID=40&md5=941b45e990eaa8e14d7443d27012b579,"Importance: Adherence to screening for vision-threatening proliferative sickle cell retinopathy is limited among patients with sickle cell hemoglobinopathy despite guidelines recommending dilated fundus examinations beginning in childhood. An automated algorithm for detecting sea fan neovascularization from ultra-widefield color fundus photographs could expand access to rapid retinal evaluations to identify patients at risk of vision loss from proliferative sickle cell retinopathy. Objective: To develop a deep learning system for detecting sea fan neovascularization from ultra-widefield color fundus photographs from patients with sickle cell hemoglobinopathy. Design, Setting, and Participants: In a cross-sectional study conducted at a single-institution, tertiary academic referral center, deidentified, retrospectively collected, ultra-widefield color fundus photographs from 190 adults with sickle cell hemoglobinopathy were independently graded by 2 masked retinal specialists for presence or absence of sea fan neovascularization. A third masked retinal specialist regraded images with discordant or indeterminate grades. Consensus retinal specialist reference standard grades were used to train a convolutional neural network to classify images for presence or absence of sea fan neovascularization. Participants included nondiabetic adults with sickle cell hemoglobinopathy receiving care from a Wilmer Eye Institute retinal specialist; the patients had received no previous laser or surgical treatment for sickle cell retinopathy and underwent imaging with ultra-widefield color fundus photographs between January 1, 2012, and January 30, 2019. Interventions: Deidentified ultra-widefield color fundus photographs were retrospectively collected. Main Outcomes and Measures: Sensitivity, specificity, and area under the receiver operating characteristic curve of the convolutional neural network for sea fan detection. Results: A total of 1182 images from 190 patients were included. Of the 190 patients, 101 were women (53.2%), and the mean (SD) age at baseline was 36.2 (12.3) years; 119 patients (62.6%) had hemoglobin SS disease and 46 (24.2%) had hemoglobin SC disease. One hundred seventy-nine patients (94.2%) were of Black or African descent. Images with sea fan neovascularization were obtained in 57 patients (30.0%). The convolutional neural network had an area under the curve of 0.988 (95% CI, 0.969-0.999), with sensitivity of 97.4% (95% CI, 86.5%-99.9%) and specificity of 97.0% (95% CI, 93.5%-98.9%) for detecting sea fan neovascularization from ultra-widefield color fundus photographs. Conclusions and Relevance: This study reports an automated system with high sensitivity and specificity for detecting sea fan neovascularization from ultra-widefield color fundus photographs from patients with sickle cell hemoglobinopathy, with potential applications for improving screening for vision-threatening proliferative sickle cell retinopathy. © 2021 American Medical Association. All rights reserved.","adult; African American; automation; Conference Paper; controlled study; convolutional neural network; cross-sectional study; deep learning; diabetic retinopathy; diagnostic test accuracy study; entropy; European American; eye photography; female; hemoglobin SC disease; Hispanic; human; major clinical study; male; medical specialist; ophthalmoscopy; priority journal; retina fluorescein angiography; retina neovascularization; retrospective study; sea fan neovascularization; sensitivity and specificity; sickle cell; sickle cell anemia; sickle cell beta thalassemia; sickle cell trait; ultra widefield color fundus photography; automated pattern recognition; complication; computer assisted diagnosis; diagnostic imaging; fluorescence angiography; middle aged; observer variation; photography; predictive value; reproducibility; retina blood vessel; retina neovascularization; sickle cell anemia; young adult; Adult; Anemia, Sickle Cell; Cross-Sectional Studies; Deep Learning; Female; Fluorescein Angiography; Humans; Image Interpretation, Computer-Assisted; Male; Middle Aged; Observer Variation; Pattern Recognition, Automated; Photography; Predictive Value of Tests; Reproducibility of Results; Retinal Neovascularization; Retinal Vessels; Retrospective Studies; Young Adult"
Article,"Prasad P.S., Beena Bethel G.N., Singh N., Kumar Gunjan V., Basir S., Miah S.",Blockchain-Based Privacy Access Control Mechanism and Collaborative Analysis for Medical Images,Security and Communication Networks,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85134180942&doi=10.1155%2f2022%2f9579611&partnerID=40&md5=38e7785b719f36c34ed62cf5ff444c46,"Medical image analysis technology based on deep learning has played an important role in computer-aided disease diagnosis and treatment. Classification accuracy has always been the primary goal pursued by researchers. However, the image transmission process also faces the problems of limited wireless ad-hoc network (WAN) bandwidth and increased security risks. Moreover, when user data are exposed to unauthorized users, platforms can easily leak personal privacy. Aiming at the abovementioned problems, a system model and an access control scheme for the collaborative analysis of the diagnosis of diabetic retinopathy (DR) are constructed in this paper. The system model includes two stages of data cleaning and lesion classification. In the data cleaning phase, the private cloud writes the model obtained after training into the blockchain, and other private clouds use the best-performing model on the chain to identify the image quality when cleaning data and pass the high-quality image to the lesion classification model for use. In the lesion classification stage, each private cloud trains the classification model separately; uploads its own model parameters to the public cloud for aggregation to obtain a global model; and then sends the global model to each private cloud to achieve collaborative learning, reduce the amount of data transmission, and protect personal privacy. Access control schemes include improved role-based access control (RAC) used within the private cloud and blockchain-based access control used during the interaction between the private cloud and the public cloud program (BAC). RAC grants both functional rights and data access rights to roles and takes into account object attributes for fine-grained level control. Based on certificateless public-key encryption technology and blockchain technology, BAC can realize the identity authentication and authority identification of the private cloud while requesting the transmission of model parameters from the private cloud to the public cloud and protect the security of the identity, authority, and model parameters of the private cloud to achieve the effect of lightweight access control. In the experimental part, two retinal datasets are used for DR classification analysis. The results show that data cleaning can effectively remove low-quality images and improve the accuracy of early lesion classification for doctors, with an accuracy rate of 90.2%. © 2022 Puja Sahay Prasad et al.",Access control; Classification (of information); Computer aided analysis; Computer aided diagnosis; Computer aided instruction; Deep learning; Image analysis; Image enhancement; Medical imaging; Quality control; Access control schemes; Block-chain; Collaborative analysis; Data cleaning; Lesion classification; Modeling parameters; Personal privacy; Private clouds; Public clouds; System models; Blockchain
